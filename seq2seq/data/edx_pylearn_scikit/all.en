this is an exclusive index used in the case that the template doesn't  end with a new line
an exclusive index in the case that the file didn't end with a  newline.
disable pragma can be at the start of the preceding line
matches output of jshint for simplicity
For parse rules, don't filter them because the comment could be a  part of the parse issue to begin with.
No uncommented code to search.
if we find another starting delim, consider this unparseable
Finds the line start index of the first uncommented line, including the current line.  No uncommented lines.  Current line is uncommented, so return original start_index.  Return start of first uncommented line.
No line comment delimeter, so this acts as a no-op.
check rules that shouldn't use concatenation
add final expression
If we can't find a starting quote, let's assume that what  we considered the end quote is really the start quote.
Attribute(expr value, identifier attr, expr_context ctx)
Store the caller, or left-hand-side node of the initial  format() call.
found Text() or HTML() call in arguments passed to format()
Do not continue processing child nodes of this format() node.
If format call has nested Text() or HTML(), then the caller,  or left-hand-side of the format() call, must be a call to  Text() or HTML().
skip this linter code (i.e. safe_template_linter.py)
Check rules specific to .py files only  Note that in template files, the scope is different, so you can make  different assumptions.  check format() rules that can be run on outer-most format() calls
check illegal concatenation and interpolation  check rules parse with regex
Finds Python blocks such as <% ... %>, skipping other Mako start tags  such as <%def> and <%page>.
Example: finds "| n, h}" when given "${x | n, h}"
get media type (e.g. get text/javascript from  type="text/javascript")
If start of mako expression is commented out, skip it.
for parsing error, restart search right after the start of the  current expression
restart search after the current expression
pylint: disable=line-too-long
Run as a django test suite
!/usr/bin/python  -*- coding: utf-8 -*-  Testing encoding on second line does not cause violation
Print violations if the lengths are different.
switch to JavaScript context
switch to JavaScript context
Line comment with ' to throw off parser
uncacheable. a list, for instance.  better to not cache than blow up.
no merge commit!
A bogus GitHub address, look up their GitHub name in  people.yaml
user passed in a custom date, so we need to parse it
This should not clear the directories list
Use RequireJS optimized storage
Redirect to the test_root folder within the repo
Store the static files under test root so that they don't overwrite existing static assets
Disable uglify when tests are running (used by build.js).  1. Uglify is by far the slowest part of the build process  2. Having full source code makes debugging tests easier for developers
SERVICE_VARIANT specifies name of the variant used, which decides what JSON  configuration files are read during startup.
CONFIG_ROOT specifies the directory where the JSON configuration  files are expected to be found. If not specified, use the project  directory.
CONFIG_PREFIX specifies the prefix of the JSON configuration files,  based on the service variant. If no variant is use, don't use a  prefix.
Don't use a connection pool, since connections are dropped by ELB.
For the Result Store, use the django cache named 'celery'
When the broker is behind an ELB, use a heartbeat to refresh the  connection and to detect if it has been dropped.
Each worker should only fetch one message at a time
STATIC_ROOT specifies the directory where static files are  collected
DEFAULT_COURSE_ABOUT_IMAGE_URL specifies the default image to show for courses that don't provide one
MEDIA_ROOT specifies the directory where user-uploaded files are stored.
For displaying on the receipt. At Stanford PLATFORM_NAME != MERCHANT_NAME, but PLATFORM_NAME is a fine default
Social media links for the page footer
Set the names of cookies shared with the marketing site  These have the same cookie domain as the session, which in production  usually includes subdomains.
Currency
Payment Report Settings
We can run smaller jobs on the low priority queue. See note above for why  we have to reset the value here.
Theme overrides
Marketing link overrides
Mobile store URL overrides
Timezone overrides
Additional installed apps
git repo loading  environment
Event Tracking
SSL external authentication settings
Video Caching. Pairing country codes with CDN URLs.  Example: {'CN': 'http://api.xuetangx.com/edx/video?s3_url='}
Credit notifications settings
Determines whether the CSRF token can be transported on  unencrypted channels. It is set to False here for backward compatibility,  but it is highly recommended that this is True for enviroments accessed  by end users.
Field overrides. To use the IDDE feature, add  'courseware.student_field_overrides.IndividualStudentOverrideProvider'.
Disabling querystring auth instructs Boto to exclude the querystring parameters (e.g. signature, access key) it  normally appends to every returned URL.
Specific setting for the File Upload Service to store media in a bucket.
If there is a database called 'read_replica', you can use the use_read_replica_if_available  function in util/query.py, which is useful for very large database reads
Datadog for events!
Analytics dashboard server
Analytics data source
Analytics Dashboard
Mailchimp New User List
Zendesk
API Key for inbound requests from Notifier service
upload limits
Student identity verification settings
Grades download
financial reports
Prefix for uploads of example-based assessment AI classifiers  This can be used to separate uploads for different environments  within the same S3 bucket.
The reduced session expiry time during the third party login pipeline. (Value in seconds)
third_party_auth config moved to ConfigurationModels. This is for data migration only:
The following can be used to integrate a custom login form with third_party_auth.  It should be a dict where the key is a word passed via ?auth_entry=, and the value is a  dict with an arbitrary 'secret_key' and a 'url'.
REGISTRATION CODES DISPLAY INFORMATION
Which access.py permission names to check;  We default this to the legacy permission 'see_exists'.
Enrollment API Cache Timeout
Use ElasticSearch as the search engine herein
Facebook app
For more info on this, see the notes in common.py
this setting specify which backend to be used when pulling microsite specific configuration  this setting specify which backend to be used when loading microsite specific templates  TTL for microsite database template cache
Course Content Bookmarks Settings
Offset for pk of courseware.StudentModuleHistoryExtended
Cutoff date for granting audit certificates
The extended StudentModule history table
Mobile App Version Upgrade config
The display name of the platform to be used in templates/emails/etc.  Shows up in the platform footer, eg "(c) COPYRIGHT_YEAR"
Features
for consistency in user-experience, keep the value of the following 3 settings  in sync with the corresponding ones in cms/envs/common.py
discussion home panel, which includes a subscription on/off setting for discussion digest emails.  this should remain off in production until digest notifications are online.
extrernal access methods  Even though external_auth is in common, shib assumes the LMS views / urls, so it should only be enabled  in LMS
This flag disables the requirement of having to agree to the TOS for users registering  with Shib.  Feature was requested by Stanford's office of general counsel
Toggles OAuth2 authentication provider
Allows to enable an API endpoint to serve XBlock view, used for example by external applications.  See jquey-xblock: https://github.com/edx-solutions/jquery-xblock
Allows to configure the LMS to provide CORS headers to serve requests from other domains
Can be turned off if course lists need to be hidden. Effects views and templates.
Enables ability to restrict enrollment in specific courses by the user account login method
enable analytics server.  WARNING: THIS SHOULD ALWAYS BE SET TO FALSE UNDER NORMAL  LMS OPERATION. See analytics.py for details about what  this does.
Flip to True when the YouTube iframe API breaks (again)
Give a UI to show a student's submission history in a problem by the  Staff Debug tool.
Provide a UI to allow users to submit feedback from the LMS (left-hand help modal)
Turn on a page that lets staff enter Python code to be run in the  sandbox, for testing whether it's enabled properly.
Enable URL that shows information about the status of variuous services
Toggle to indicate use of the Stanford theming system
Don't autoplay videos for students
Enable instructor dash to submit background tasks
Enable instructor to assign individual due dates  Note: In order for this feature to work, you must also add  'courseware.student_field_overrides.IndividualStudentOverrideProvider' to  the setting FIELD_OVERRIDE_PROVIDERS, in addition to setting this flag to  True.
Enable Custom Courses for EdX
Toggle to enable certificates of courses on dashboard
for load testing
Toggle the availability of the shopping cart page
Toggle storing detailed billing information
Enable flow for payments for course registration (DIFFERENT from verified student flow)
Enable the display of cosmetic course price display (set in course advanced settings)
Automatically approve student identity verification attempts
Disable instructor dash buttons for downloading course data  when enrollment exceeds this number
Grade calculation started from the new instructor dashboard will write  grades CSV files to S3 and give links for downloads.
whether to use password policy enforcement or not
Give course staff unrestricted access to grade downloads (if set to False,  only edX superusers can perform the downloads)
Turn off account locking if failed login attempts exceeds a limit
Hide any Personally Identifiable Information from application logs
Toggles the embargo functionality, which blocks users from  the site or courses based on their location.
Whether the Wiki subsystem should be accessible via the direct /wiki/ paths. Setting this to True means  that people can submit content and modify the Wiki in any arbitrary manner. We're leaving this as True in the  defaults, so that we maintain current behavior
Turn on/off Microsites feature
Turn on third-party auth. Disabled for now because full implementations are not yet available. Remember to syncdb  if you enable this; we don't create tables by default.
Toggle to enable alternate urls for marketing links
Prevent concurrent logins per user
Turn on Advanced Security by default
When a logged in user goes to the homepage ('/') should the user be  redirected to the dashboard - this is default Open edX behavior. Set to  False to not redirect the user
When a user goes to the homepage ('/') the user see the  courses listed in the announcement dates order - this is default Open edX behavior.  Set to True to change the course sorting behavior by their start dates, latest first.
Expose Mobile REST API. Note that if you use this, you must also set  ENABLE_OAUTH2_PROVIDER to True
Enable the combined login/registration form
Enable organizational email opt-in
Show a section in the membership tab of the instructor dashboard  to allow an upload of a CSV file that contains a list of new accounts to create  and register for course.
Enable display of enrollment counts in instructor dash, analytics section
Show the mobile app links in the footer
Let students save and manage their annotations
Milestones application flag
Organizations application flag
Prerequisite courses feature flag
For easily adding modes to courses during acceptance testing
Courseware search feature
Dashboard search feature
log all information from cybersource callbacks
enable beacons for video timing statistics
enable beacons for lms onload event statistics
Toggle platform-wide course licensing
Certificates Web/HTML Views
Batch-Generated Certificates from Instructor Dashboard
Course discovery feature
Software secure fake page feature flag
Teams feature
Show video bumper in LMS
How many seconds to show the bumper again, default is 7 days:
Special Exams, aka Timed and Proctored Exams
Enable OpenBadge support. See the BADGR_* settings later in this file.
The block types to disable need to be specified in "x block disable config" in django admin.
Enable the max score cache to speed up grading
Enable LTI Provider feature.
Show Language selector.
Write new CSM history to the extended table.  This will eventually default to True and may be  removed since all installs should have the separate  extended history table.
Read from both the CSMH and CSMHE history tables.  This is the default, but can be disabled if all history  lives in the Extended table, saving the frontend from  making multiple queries.
Ignore static asset files on import which match this pattern
Used for A/B testing
If this is true, random scores will be generated for the purpose of debugging the profile graphs
comprehensive theming system
For geolocation ip database
Where to look for a status message
Hack to get required link URLs to password reset templates
Shoppingcart processor (detects if request.user has a cart)
Allows the open edX footer to be leveraged in Django Templates.
Online contextual help
Change 'debug' in your environment settings files - not here.
use the ratelimit backend to prevent brute force attacks
Configuration option for when we want to grab server error pages
FIXME: Should we be doing this truncation?
We're already logging events, and we don't want to capture user  names/passwords.  Heartbeat events are likely not interesting.
Import after sys.path fixup
These are the Mixins that should be added to every XBlock.  This should be moved into an XBlock Runtime/Application object  once the responsibility of XBlock creation is moved out of modulestore - cpennington
Allow any XBlock in the LMS
Paths to wrapper methods which should be applied to every XBlock's FieldData.
Path to a sandboxed Python executable.  None means don't bother.  User to run as in the sandbox.
Configurable limits.  How many CPU seconds can jailed code use?
Some courses are allowed to run unsafe code. This is a list of regexes, one  of them must match the course id for that course to run unsafe code.  For example:    COURSES_WITH_UNSAFE_CODE = [        r"Harvard/XY123.1/.*"    ]
Change DEBUG in your environment settings files, not here
CMS base
Site info  NOTE: Please set ALLOWED_HOSTS to some sane value, as we do not allow the default '*'
Platform mailing address
Get git revision of the current file
Not a git repository
Static content
User-uploaded content
these languages display right to left
Sourced from http://www.localeplanet.com/icu/ and wikipedia
Messages
Setting for PAID_COURSE_REGISTRATION, DOES NOT AFFECT VERIFIED STUDENTS
Members of this group are allowed to generate payment reports
Configure the LMS to use our stub EdxNotes implementation
The age at which a learner no longer requires parental consent, or None  if parental consent is never required.
URL for OpenEdX displayed in the footer
This is just a placeholder image.  Site operators can customize this with their organization's image.
Cache expiration for the version of the footer served  by the branding API.
Max age cache control header for the footer (controls browser caching).
Credit api notification cache timeout
Ignore deprecation warnings (so we don't clutter Jenkins builds/production)
Instead of SessionMiddleware, we use a more secure version  'django.contrib.sessions.middleware.SessionMiddleware',
Instead of AuthenticationMiddleware, we use a cached backed version  Enable SessionAuthenticationMiddleware in order to invalidate  user sessions after a password change.
Adds user tags to tracking events  Must go before TrackMiddleware, to get the context set up
CORS and CSRF
Allows us to set user preferences
Allows us to dark-launch particular languages.  Must be after LangPrefMiddleware, so ?preview-lang query params can override  user's language preference. ?clear-lang resets to user's language preference.
Detects user-requested locale from 'accept-language' header in http request.  Must be after DarkLangMiddleware.
catches any uncaught RateLimitExceptions and returns a 403 instead of a 500  needs to run after locale middleware (or anything that modifies the request context)
for expiring inactive sessions
use Django built in clickjacking protection
to redirected unenrolled students to the course info page
This must be last
Clickjacking protection can be enabled by setting this to 'DENY'
Platform for Privacy Preferences header
Setting that will only affect the edX version of django-pipeline until our changes are merged upstream
Don't wrap JavaScript as there is code that depends upon updating the global namespace
Specify the UglifyJS binary to use
Make some edX UI Toolkit utilities available in the global "edx" namespace
Finally load RequireJS and dependent vendor libraries
Ignore tests
Symlinks used by js-test-tool
The baseUrl to pass to the r.js optimizer, relative to STATIC_ROOT.
The name of the require.js script used by your project, relative to REQUIRE_BASE_URL.
A dictionary of standalone modules to build with almond.js.
Whether to run django-require in debug mode.
A tuple of files to exclude from the compilation result of r.js.
Celery's task autodiscovery won't find tasks nested in a tasks package.  Tasks are only registered when the module they are defined in is imported.
let logging work as configured:
Suffix used to construct 'from' email address for bulk emails.  A course-specific identifier is prepended.
Parameters for breaking down course enrollment into subtasks.
Initial delay used for retrying tasks.  Additional retries use  longer delays.  Value is in seconds.
Maximum number of retries per task for errors that are not related  to throttling.
Maximum number of retries per task for errors that are related to  throttling.  If this is not set, then there is no cap on such retries.
We want Bulk Email running on the high-priority queue, so we define the  routing key that points to it.  At the moment, the name is the same.
We also define a queue for smaller jobs so that large courses don't block  smaller emails (see BULK_EMAIL_JOB_SIZE_THRESHOLD setting)
For emails with fewer than these number of recipients, send them through  a different queue to avoid large courses blocking emails that are meant to be  sent to self and staff
Flag to indicate if individual email addresses should be logged as they are sent  a bulk email message.
Delay in seconds to sleep between individual mail messages being sent,  when a bulk email task is retried for rate-related reasons.  Choose this  value depending on the number of workers that might be sending email in  parallel, and what the SES rate is.
Minimum age for organization-wide email opt in
YouTube JavaScript API
URL to get YouTube metadata
Common views
History tables
Database-backed configuration
Monitor the status of services
Display status message to students
For asset pipelining
For content serving
Theming
Site configuration for theming and behavioral modification
Our courseware
Student support tools
External auth (OpenID, shib)
django-oauth2-provider (deprecated)
django-oauth-toolkit
Notifications were enabled, but only 11 people used it in three years. It  got tangled up during the Django 1.8 migration, so we are disabling it.  See TNL-3783 for details.
Discussion forums
Splash screen
Monitoring
User API
Shopping cart
Notification preferences setting
Different Course Modes
Enrollment API
Student Identity Verification
Dark-launching languages
Microsite configuration
RSS Proxy
Student Identity Reverification
Monitoring functionality
Course action state
Country list
edX Mobile API
Surveys
Course data caching
Old course structure API
Mailchimp Syncing
CORS and cross-domain CSRF
Credit courses
Course teams
Bookmarks
programs support
Self-paced course configuration
Credentials support
edx-milestones service
Gating of course content
Static i18n support
Review widgets
API access administration
Verified Track Content Cohorting
Learner's dashboard
Needed whether or not enabled, due to migrations
Migrations which are not in the standard module "migrations"
Forwards-compatibility with Django 1.7  It is highly recommended that you override this in any environment accessed by  end users
Verified Certificates
The names list controls the order of social media  links in the footer.
The footer URLs dictionary maps social footer names  to URLs defined in configuration.
These are URLs to the app store for mobile.
Default cache expiration for the cross-domain proxy HTML page.  This is a static page that can be iframed into an external page  to simulate cross-domain requests.
Optional setting to restrict registration / account creation to only emails  that match a regex in this list. Set to None to allow any email (default).
Be sure to set up images for course modes using the BadgeImageConfiguration model in the certificates app.  Do not add the trailing slash here.  Number of seconds to wait on the badging server when contacting it before giving up.
These keys are used for all of our asynchronous downloadable files, including  the ones that contain information other than grades.
By default, don't use a file prefix
Default File Upload Storage bucket and prefix. Used by the FileUpload Service.
edx-ora2
edxval
edX Proctoring
Organizations App (http://github.com/edx/edx-organizations)
First attempt to only find the module rather than actually importing it,  to avoid circular references - only try to import if it can't be found  by find_module, which doesn't work with import hooks
Empty by default
REGISTRATION CODES DISPLAY INFORMATION SUBTITUTIONS IN THE INVOICE ATTACHMENT
Country code overrides  Used by django-countries  Taiwan is specifically not translated to avoid it being translated as "Taiwan (Province of China)"
which access.py permission name to check in order to determine if a course is visible in  the course catalog. We default this to the legacy permission 'see_exists'.
which access.py permission name to check in order to determine if a course about page is  visible. We default this to the legacy permission 'see_exists'.
Enrollment API Cache Timeout
These tabs are currently disabled
CDN experiment/monitoring flags
Page onload event sampling rate (min 0.0, max 1.0)
The configuration visibility of account fields.  Default visibility level for accounts without a specified value  The value is one of: 'all_users', 'private'
The list of all fields that can be shared with other users  Not an actual field, but used to signal whether badges should be public.
The list of account fields that are always public
E-Commerce API Configuration
Reverification checkpoint name pattern
For the fields override feature  If using FEATURES['INDIVIDUAL_DUE_DATES'], you should add  'courseware.student_field_overrides.IndividualStudentOverrideProvider' to  this setting.
Modulestore-level field override providers. These field override providers don't  require student context.
Sets the maximum number of courses listed on the homepage  If set to None, all courses will be listed on the homepage
Initial delay used for retrying tasks.  Additional retries use longer delays.  Value is in seconds.
Maximum number of retries per task for errors that are not related  to throttling.
Dummy secret key for dev/test
Secret keys shared with credit providers.  Used to digitally sign credit requests (us --> provider)  and validate responses (provider --> us).  Each key in the dictionary is a credit provider ID, and  the value is the 32-character key.
Maximum age in seconds of timestamps we will accept  when a credit provider notifies us that a student has been approved  or denied for credit.
The Help link to the FAQ page about the credit
Default domain for the e-mail address associated with users who are created  via the LTI Provider feature. Note that the generated e-mail addresses are  not expected to be active; this setting simply allows administrators to  route any messages intended for LTI users to a common domain.
For help generating a key pair import and run `openedx.core.lib.rsa_key_utils.generate_rsa_key_pair()`
Credit notifications settings
This is an arbitrary hard limit.  The reason we introcuced this number is because we do not want the CCX  to compete with the MOOC.
Maximum and minimum length of answers, in characters, for the  financial assistance form
Course Content Bookmarks Settings
Identifier included in the User Agent from open edX mobile apps.
cache timeout in seconds for Mobile App Version Upgrade
Deprecated xblock types
Dafault site id to use in case there is no site that matches with the request headers.
Affiliate cookie tracking
https://stackoverflow.com/questions/2890146/how-to-force-pyyaml-to-load-strings-as-unicode-objects
SERVICE_VARIANT specifies name of the variant used, which decides what YAML  configuration files are read during startup.
CONFIG_ROOT specifies the directory where the YAML configuration  files are expected to be found. If not specified, use the project  directory.
CONFIG_PREFIX specifies the prefix of the YAML configuration files,  based on the service variant. If no variant is use, don't use a  prefix.
SSL external authentication settings
Don't use a connection pool, since connections are dropped by ELB.
For the Result Store, use the django cache named 'celery'
When the broker is behind an ELB, use a heartbeat to refresh the  connection and to detect if it has been dropped.
Each worker should only fetch one message at a time
Works around an Ansible bug
Delete keys from ENV_TOKENS so that when it's imported  into settings it doesn't override what was set above
Update the token dictionary directly into settings
NOTE, there's a bug in Django (http://bugs.python.org/issue18012) which necessitates this being a str()
We can run smaller jobs on the low priority queue. See note above for why  we have to reset the value here.
Additional installed apps
Works around an Ansible bug
Grades download
pretend we are behind some marketing site, we want to be able to assert that the Microsite config values override  this global setting
Mongo perf stats
HOSTNAME_MODULESTORE_DEFAULT_MAPPINGS defines, as dictionary of regex's, a set of mappings of HTTP request hostnames to  what the 'default' modulestore to use while processing the request  for example 'preview.edx.org' should use the draft modulestore
Dummy secret key for dev
Disable transaction management because we are using a worker. Views  that request a task and wait for the result will deadlock otherwise.
This patch disables the commit_on_success decorator during tests  in TestCase subclasses.
mongo connection settings
can't test start dates with this True, but on the other hand,  can test everything else :)
Enable this feature for course staff grade downloads, to enable acceptance tests
Toggles embargo on for testing
Enable a parental consent age limit for testing
Nose Test Runner
Local Directories  Want static files in the same dir for running on jenkins.
Where the content data is checked out.  This may not exist on jenkins.
Don't rely on a real staff grading backend
Avoid having to run collectstatic before the unit test suite  If we don't add these settings, then Django templates that can't  find pipelined assets will raise a ValueError.  http://stackoverflow.com/questions/12816941/unit-testing-with-django-pipeline
Don't use compression during tests
Create tables directly from apps' models. This can be removed once we upgrade  to Django 1.9, which allows setting MIGRATION_MODULES to None in order to skip migrations.
Make sure we test with the extended history table
This is the cache used for most things.  In staging/prod envs, the sessions also live here.
Dummy secret key for dev
hide ratelimit warnings while running tests
Ignore deprecation warnings (so we don't clutter Jenkins builds/production)  https://docs.python.org/2/library/warnings.htmlthe-warnings-filter  Change to "default" to see the first instance of each hit  or "error" to convert all into errors
Default to advanced security in common.py, so tests can reset here to use  a simpler security model
don't cache courses for testing
Enable fake payment processing page
Configure the payment processor to use the fake processing page  Since both the fake payment page and the shoppingcart app are using  the same settings, we can generate this randomly and guarantee  that they are using the same secret.
Verified Certificates
Strip out any static files that aren't in the repository root  so that the tests can run with only the edx-platform directory checked out  Handle both tuples and non-tuple directory definitions
These ports are carefully chosen so that if the browser needs to  access them, they will be available through the SauceLabs SSH tunnel
'django.contrib.auth.hashers.PBKDF2PasswordHasher',  'django.contrib.auth.hashers.PBKDF2SHA1PasswordHasher',  'django.contrib.auth.hashers.BCryptPasswordHasher',  'django.contrib.auth.hashers.CryptPasswordHasher',
Setting for the testing of Software Secure Result Callback
Enable EdxNotes for tests.
Enable teams feature for tests.
Enable courseware search for tests
Enable dashboard search for tests
Use MockSearchEngine as the search engine for test scenario
Enable the LTI provider feature for testing
ORGANIZATIONS
Financial assistance page
Disable the use of the plugin manager in the transformer registry for  better performant unit tests.
Set the default Oauth2 Provider Model so that migrations can run in  verbose mode
Enable debug so that static assets are served by Django
Set REQUIRE_DEBUG to false so that it behaves like production
Fetch static files out of the pipeline's static root
Needed for the reset database management command
Redirect to the test_root folder within the repo
Enable debug so that static assets are served by Django
Don't use compression during tests
Configure the LMS to use our stub XQueue implementation
Configure the LMS to use our stub EdxNotes implementation
Enable milestones app
Enable oauth authentication, which we test.
Enable pre-requisite course
Enable Course Discovery
Enable student notes
Enable teams feature
Enable custom content licensing
Use the auto_auth workflow for creating users and logging them in
Default to advanced security in common.py, so tests can reset here to use  a simpler security model
Enable courseware search for tests
Enable dashboard search for tests
Enable support for OpenBadges accomplishments
Use MockSearchEngine as the search engine for test scenario  Path at which to store the mock index
this secret key should be the same as cms/envs/bok_choy.py's
Make sure we test with the extended history table
Lastly, see if the developer has any local overrides.
Don't use S3 in devstack, fall back to filesystem
By default don't use a worker, execute tasks as if they were local functions
Set this to the dashboard URL in order to display the link from the  dashboard to the Analytics Dashboard.
ProfilingPanel has been intentionally removed for default devstack.py  runtimes for performance reasons. If you wish to re-enable it in your  local development environment, please create a new settings file  that imports and extends devstack.py.
Disable JavaScript compression in development
Whether to run django-require in debug mode.
Setting for overriding default filtering facets for Course discovery  COURSE_DISCOVERY_FILTERS = ["org", "language", "modes"]
Software secure fake page feature flag
Setting for the testing of Software Secure Result Callback
Skip enrollment start date filtering
See if the developer has any local overrides.
Lastly, run any migrations, if needed.
You need to start the server in debug mode,  otherwise the browser will not render the pages correctly
Output Django logs to a file
set root logger level
Use the auto_auth workflow for creating users and logging them in
Enable fake payment processing page
Enable special exams
Don't actually send any requests to Software Secure for student identity  verification.
HACK  Setting this flag to false causes imports to not load correctly in the lettuce python files  We do not yet understand why this occurs. Setting this to true is a stopgap measure
Include the lettuce app for acceptance testing, including the 'harvest' django-admin command
Where to run: local, saucelabs, or grid
See if the developer has any local overrides.
Use MockSearchEngine as the search engine for test scenario
Generate a random UUID so that different runs of acceptance tests don't break each other
We want to make sure that any new migrations are run  see https://groups.google.com/forum/!msg/django-developers/PWPj3etj3-U/kCl6pMsQYYoJ
Make the keyedcache startup warnings go away
Dummy secret key for dev
List of `university` landing pages to display, even though they may not  have an actual course with that org set
Organization that contain other organizations
By default don't use a worker, execute tasks as if they were local functions
If there's an environment variable set, grab it
Lastly, see if the developer has any local overrides.
Dummy secret key for dev
Import everything from .aws so that our settings are based on those.
You never migrate a read_replica
set the default Django settings module for the 'celery' program.
Using a string here means the worker will not have to  pickle the object when using Windows.
Uncomment the next two lines to enable the admin:
Use urlpatterns formatted as within the Django docs with first parameter "stuck" to the open parenthesis
Note: these are older versions of the User API that will eventually be  subsumed by api/user listed below.
Feedback Form endpoint
Enrollment API RESTful endpoints
Courseware search endpoints
Course content API
Course API
User API endpoints
Bookmarks API endpoints
Profile Images API endpoints
Video Abstraction Layer used to allow video teams to manage video assets  independently of courseware. https://github.com/edx/edx-val
Update session view
URLs for API access management
We need to explicitly include external Django apps that are not in LOCALE_PATHS.
sysadmin dashboard, to see what courses are loaded, to delete & load courses
Semi-static views (these need to be rendered and have the login bar, but don't change)
Press releases
Only enable URLs for those marketing links actually enabled in the  settings. Disable URLs by marking them as None.  Skip disabled URLs
These urls are enabled separately
The MKTG_URL_LINK_MAP key specifies the template filename  Append STATIC_TEMPLATE_VIEW_DEFAULT_FILE_EXTENSION if  no file extension was specified in the key
To allow theme templates to inherit from default templates,  prepend a standard prefix
Make the assumption that the URL we want is the lowercased  version of the map key
Multicourse wiki (Note: wiki urls must be above the courseware ones because of  the custom tab catch-all)
xblock View API  (unpublished) API that returns JSON with the HTML fragment and related resources  for the xBlock's requested view.
Survey associated with a course
Takes optional student_id for instructor use--shows profile as that student sees it.
For the instructor
LTI endpoints listing
Student account
Student profile
Student Notes
Embargo
Survey Djangoapp
enable automatic login
OAuth token exchange
Certificates
REST APIs
XDomain proxy
Access to courseware as an LTI provider
in debug mode, allow any template to be rendered (most useful for UX reference templates)
Custom error pages
display error page templates, for testing purposes
include into our URL patterns the HTTP REST API that comes with edx-proctoring.
This will make sure the app is always imported when  Django starts so that shared_task will use this app.
Patch the xml libs before anything else.
This application object is used by the development server  as well as any WSGI server configured to use this file.
To override the settings before executing the autostartup() for python-social-auth
Comprehensive theming needs to be set up before django startup,  because modifying django template paths after startup has no effect.
We currently use 2 template rendering engines, mako and django_templates,  and one of them (django templates), requires the directories be added  before the django.setup().
Mako requires the directories to be added after the django setup.
Initialize Segment analytics module by setting the write_key.
register InstructorService (for deleting student attempts and user staff access roles)
Workaround for setting THEME_NAME to an empty  string which is the default due to this ansible  bug: https://github.com/ansible/ansible/issues/4812
Calculate the location of the theme's files
Include the theme's templates in the template search paths
Namespace the theme's static files to 'themes/<theme_name>' to  avoid collisions with default edX static files
Include theme locale path for django translations lookup
from nose.tools import set_trace  set_trace()
if we have an org filter, only include results for this org filter
If we have a course filter we are ensuring that we only get those courses above
re-fetch video from draft store
re-fetch video from published store
metric_tag_fields are used by Datadog to record metrics about the model
initializable_fields are sent in POST requests
pylint: disable=unused-import
attempt to gracefully recover from a previous failure  to sync this user to the comments service.
automatically generate the stripped version of the text from the HTML markup:
create the task, then save it immediately:
Allowing null=True to support data migration from email->user.  We need to first create the 'user' column with some sort of default in order to run the data migration,  and given the unique index, 'null' is the best default value.
Defines the tag that must appear in a template, to indicate  the location where the email message body is to be inserted.
Substitute all %%-encoded keywords in the message body
finally, return the result, after wrapping long lines and without converting to an encoded byte array.
The course that these features are attached to.
Whether or not to enable instructor email
pylint: disable=no-member
boolean field 'enabled' inherited from parent ConfigurationModel
Turn off the action bar (we have no bulk actions)
Note that we get back a blank string in the Form for an empty 'name' field  we want those to be set to None in Python and NULL in the database
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-
Student module history table will fail this migration otherwise
Note this is not a perfect 1:1 backwards migration - targets can hold more information than to_option can.  We use the first valid value from targets, or 'myself' if none can be found
Student module history table will fail this migration otherwise
-*- coding: utf-8 -*-
Course should still be authorized (invalid attempt had no effect)
Munge course id
Validation shouldn't work
Validation shouldn't work
Munge course id - common  Validation shouldn't work
now inspect the database and make sure the blank name was stored as a NULL  Note this will throw an exception if it is not found
now inspect the database and make sure the whitespace only name was stored as a NULL  Note this will throw an exception if it is not found
now inspect the database and make sure the name is properly  stripped
now inspect the database and make sure the blank name was stored as a NULL  Note this will throw an exception if it is not found
try to submit form with the same name
load initial content (since we don't run migrations as part of tests):
Assert that self.student.email not in mail.to, outbox should only contain "myself" target
Response loads the whole instructor dashboard, so no need to explicitly  navigate to a particular email section  If this fails, it is likely because BulkEmailFlag.is_enabled() is set to False
load initial content (since we don't run migrations as part of tests):
We should get back a HttpResponseForbidden (status code 403)
Post the email to the instructor dashboard API
Post the email to the instructor dashboard API
Create a student with Unicode in their first & last names
Post the email to the instructor dashboard API
make display_name that's longer than 320 characters when encoded  to ascii and escaped, but shorter than 320 unicode characters
it's shorter than 320 characters when just encoded  escaping it brings it over that limit  when not escaped or encoded, it's well below 320 characters
Post the email to the instructor dashboard API
Post the email to the instructor dashboard API
load initial content (since we don't run migrations as part of tests):
Get the default template, which has name=None
Test that course is not authorized by default
Test that course is authorized by default, since auth is turned off
Use the admin interface to unauthorize the course
Now, course should STILL be authorized!
load initial content (since we don't run migrations as part of tests):
check return value
Test that celery handles permanent SMTPDataErrors by failing and not retrying.
Test that celery handles permanent SMTPDataErrors by failing and not retrying.
Test that celery handles permanent SMTPDataErrors by failing and not retrying.
Test that celery handles permanent SMTPDataErrors by failing and not retrying.
Test that celery handles permanent SMTPDataErrors by failing and not retrying.
Test bulk email with unicode characters in course image name
We also send email to the instructor:
Test that we retry upon hitting a 4xx error
(?i) is a regex for ignore case
Errors that an individual email is failing to be sent, and should just  be treated as a fail.
Exceptions that, if caught, should cause the task to be re-tried.  These errors will be caught a limited number of times before the task fails.
Errors that are known to indicate an inability to send any more emails,  and should therefore not be retried.  For example, exceeding a quota for emails.  Also, any SMTP errors that are not explicitly enumerated above.
Get inputs to use in this task from the entry.
Fetch the course object.
Get arguments that will be passed to every subtask.
if there are few enough emails, send them through a different queue  to avoid large courses blocking emails to self and staff
Update the InstructorTask object that is storing its progress.
If retrying, a RetryTaskError needs to be returned to Celery.  We assume that the the progress made before the retry condition  was encountered has already been updated before the retry call was made,  so we only log here.
return status in a form that can be serialized by Celery into JSON:
Only count the num_optout for the first time the optouts are calculated.  We assume that the number will not change on retries, and so we don't need  to calculate it each time.
For the email address, get the course.  Then make sure that it can be used  in an email address, by substituting a '_' anywhere a non-(ascii, period, or dash)  character appears.
If the encoded from_addr is longer than 320 characters, reformat,  but with the course name rather than course title.  Amazon SES's from address field appears to have a maximum length of 320.
It seems that this value is also escaped when set out to amazon, judging  from our logs
Get information from current task's request:
use the email from address in the CourseEmail, if it is present, otherwise compute it
use the CourseEmailTemplate that was associated with the CourseEmail
Define context values to use in all course emails:
Construct message content using templates and context:
Create email:
Pop the user that was emailed off the end of the list only once they have  successfully been processed.  (That way, if there were a failure that  needed to be retried, the user is still on the list.)
Increment the "retried_nomax" counter, update other counters with progress to date,  and set the state to RETRY:
Update counters with progress to date, counting unsent emails as failures,  and set the state to FAILURE:
All went well.  Update counters with progress to date,  and set the state to SUCCESS:  Successful completion is marked by an exception value of None.
Clean up at the end.
Skew the new countdown value by a random factor, so that not all  retries are deferred by the same amount.
we make sure that we update the InstructorTask with the current subtask status  *before* actually calling retry(), to be sure that there is no race  condition between this update and the update made by the retried task.
return match indexed by state
reloading based on commit_id is needed when running mutiple worker threads,  so that a given thread doesn't reload the same commit multiple times
The consumer may not exist, or its record may not have a guid
Search by consumer key instead of instance_guid. If there is no  consumer with a matching key, the LTI launch does not have permission  to access the content.
Add the instance_guid field to the model if it's not there already.
This is the first time that the user has been here. Create an account.
The user is not authenticated, or is logged in as somebody else.  Switch them to the LTI user
The random edx_user_id wasn't unique. Since 'created' is still  False, we will retry with a different random ID.
This shouldn't happen, since we've created edX accounts for any LTI  users by this point, but just in case we can return a 403.
LTI launch parameters that must be present for a successful launch
Check the LTI parameters, and return 400 if any required parameters are  missing
Get the consumer information from either the instance GUID or the consumer  key
Check the OAuth signature on the message
Create an edX account if the user identifed by the LTI launch doesn't have  one already, and log the edX account into the platform.
Store any parameters required by the outcome service in order to report  scores back later. We know that the consumer exists, since the record was  used earlier to verify the oauth signature.
return an HttpResponse object that contains the template and necessary context to render the courseware.
The oauthlib library assumes that headers are passed directly from the  request, but Django mangles them into its own format. The only header  that the library requires (for now) is 'Content-Type', so we  reconstruct just that one.
Both usage and course ID parameters are supplied in the LTI launch URL
Create a record of the outcome service if necessary
failed to send result. 'response' is None, so more detail will be  logged at the end of the method.
Pylint doesn't recognize members in the LXML module
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
Always accept the OAuth signature
Make sure that our body hash is now part of the test...
Get all assignments involving the current problem for which the campus LMS  is expecting a grade. There may be many possible graded assignments, if  a problem has been added several times to a course at different  granularities (such as the unit or the vertical).
Django Rest Framework v3.1 requires that we pass the request to the serializer  so it can construct hyperlinks.  To avoid changing the interface of this object,  we retrieve the request from the request cache.
Save the primary key so we can load the full objects easily after we search  Don't save the membership relations in elasticsearch
add generally searchable content
Don't emit changed events when these fields change.
Even though sorting is done outside of the serializer, sort_order needs to be passed  to the serializer so that the paginated results indicate how they were sorted.
Paginate and serialize topic data  BulkTeamCountPaginatedTopicSerializer will add team counts to the topics in a single  bulk operation per page.
Django Rest Framework v3 requires that we pass the request  into the serializer's context if the serialize contains  hyperlink fields.
Instantiate the paginator and use it to paginate the queryset
Serialize the page
OAuth2Authentication must come first to return a 401 for unauthenticated users
Ensure the course exists
MySQL does case-insensitive order_by.
Translators: 'ordering' is a string describing a way  of ordering a list. For example, {ordering} may be  'name', indicating that the user wants to sort the  list by lower case name.
Ensure the course exists
This code is taken from within the GenericAPIViewpaginate_queryset method.  We need need access to the page outside of that method for our paginate_search_results method
Note: list() forces the queryset to be evualuated before delete()
Ensure the course exists
Translators: 'ordering' is a string describing a way  of ordering a list. For example, {ordering} may be  'name', indicating that the user wants to sort the  list by lower case name.
Ensure the course exists
This is ugly, but there is a really strange circular dependency that doesn't  happen anywhere else that I can't figure out how to avoid it :(
-*- coding: utf-8 -*-
will be assigned to self.client by default
Enroll in the course and log in
Check the query count on the dashboard with no teams
Create some teams
Add the user to the last team
Check the query count on the dashboard again
Create teams in both courses
Add user to a course one team
Check that list of user teams in course one is not empty, it is one now
This student is enrolled in both test courses and is a member of a team in each course, but is not on the  same team as student_enrolled.
Make this student have a public profile
This student is enrolled in the other course, but not yet a member of a team. This is to allow  course_2 to use a max_team_size of 1 without breaking other tests on course_1
Check that initially list of user teams in course one is empty
Add user to a course one team
Check that list of user teams in course one is not empty now
Check that list of user teams in course two is still empty
Check that teams with the same name have unique IDs.
Verify expected truncation behavior with names > 20 characters.
First add the privileged user to a team.
Verify the id (it ends with a unique hash, which is the same as the discussion_id).
Remove date_created and discussion_topic_id because they change between test runs
Since membership is its own list, we want to examine this separately.
Verify that the creating user gets added to the team.
Verify that staff do not automatically get added to a team  when they create one.
Use the default user which is already private because to year_of_birth is set
Extending test classes should specify their serializer class.
Assert that the first save in the setUp sets a value.
Verify that we only change the last activity_at when it doesn't  already exist.
a list of all supported mobile platforms
pylint: disable=no-member
Create list of courses with various expected courseware_access responses and corresponding expected codes
Enroll in all the courses
override implementation to use PATCH method.
save something so we have an initial date
old modification date so skip update
The arguments are optional, so if there's no argument just succeed
identifiers
dates
notification info
access info
Set requested profiles
Testing when video_profiles='mobile_low,mobile_high,youtube'
Testing when there is no mobile_low, and that mobile_high doesn't show
Testing where youtube is the default video over mobile_high
add user to this cohort
remove user from this cohort
un-cohorted user should see no videos
staff user sees all videos
to be consistent with other edx-platform clients, return the defaulted display name
Get encoded videos
Get highest priority video to populate backwards compatible field
Then fall back to VideoDescriptor fields for video URLs
Get duration/size, else default
Transcripts...
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
pylint: disable=no-member
login and enroll as the test user
login and enroll as another user
now login and call the API as the test user
set user's role in the course
call API
verify static URLs are replaced in the content returned by the API
verify static URLs remain in the underlying content
but shouldn't finish with any
but shouldn't finish with any
but shouldn't finish with any
course_handouts_module could be None if there are no handouts
Translators: This message means that the user could not be authenticated (that is, we could  not log them in for some reason - maybe they don't have permission, or their password was wrong)
Translators: this means everything happened successfully, yay!
Translators: Domain is an email domain, such as "@gmail.com"
Grab logging output for debugging imports
Remove handler hijacks
Translators: "Git Commit" is a computer command; see http://gitref.org/basic/commit
Set mongodb defaults even if it isn't defined in settings
Require staff if not going to specific course
Positional arguments
Make a course dir that will be replaced with a symlink  while we are at it.
Test with all three args (branch)
Test successful import from command
Checkout non existent branch
Checkout new branch  Validate that it is different than master
Attempt to check out the same branch again to validate branch choosing  works
Build repo dir
Get logger for checking strings in logs
Translators: This is an error message when they ask for a  particular version of a git repository and that version isn't  available from the remote source they specified
Translators: Error message shown when they have asked for a git  repository branch, a specific version within a repository, that  doesn't exist, or there is a problem changing to it.
Get XML logging logger and capture debug to parse results
Remove handler hijacks
store import-command-run output in mongo
using XML store
Using mongo store
Create git loaded course
Make sure we don't have any git hashes on the page
Now add the course and make sure it does match
Check that our earlier import has a log with a link to details
Simulate a lack of git import logs
Add user as staff in course team
pylint: disable=missing-docstring
Will also run default tests for IDTokens and UserInfo
CourseAccessHandler uses the application cache.
create another course in the DB that only global staff have access to
Use the anonymous ID without any course as unique identifier.  Note that this ID is derived using the value of the `SECRET_KEY`  setting, this means that users will have different sub  values for different deployments.
Calling UserPreference directly because it is not clear which user made the request.
If the user has no language specified, return the default one.
If values was specified, filter out other courses.
pylint: disable=missing-docstring  Check the application cache and update if not present. The application  cache is useful since there are calls to different endpoints in close  succession, for example the id_token and user_info endpoints.
Global staff have access to all courses. Filter courses for non-global staff.
Don't return list of courses unless they are requested as essential.
Don't return list of courses unless they are requested as essential.
Guess content type from file extension
check response with branding
this is a two-step form: first look up the data, then issue the refund.  first time through, set the hidden "confirmed" field to true and then redisplay the form  second time through, do the unenrollment/refund.
pylint: disable=wildcard-import
pylint: disable=missing-docstring
In order to check the user's permission, he/she needs to be logged in.
users without the permission can't access support
Log out then try to retrieve the page
Expect a redirect to the login page
Check that all the expected links appear on the index page.
Check that an empty initial filter is passed to the JavaScript client correctly.
`self` isn't available from within the DDT declaration, so  assign the course ID here
pylint: disable=missing-docstring
Json request data for metrics for entire course
Json request data for metrics for particular section
For listing students that opened a sub-section
For listing of students' grade per problem
For generating metrics data as a csv
Only instructor for this particular course can request this information
Only instructor for this particular course can request this information
Only instructor for this particular course can request this information
Used to limit the length of list displayed to the screen.
Loop through resultset building data for each problem
Build set of grade distributions for each problem that has student responses
Build set of total students attempting each problem
Aggregate query on studentmodule table for "opening a subsection" data
Build set of "opened" data for each subsection that has "opened" data
Loop through resultset building data for each problem
Retrieve course object down to problems
Student data is at the problem level
Construct label to display for this problem
Only problems in prob_grade_distrib have had a student submission.
Get max_grade, grade_distribution for this problem
Get problem_name for tooltip
Compute percent of students with this grade
Construct data to be sent to d3
Retrieve course object down to subsection
Iterate through sections, subsections
Construct data for each subsection to be sent to d3
Tooltip parameters for subsection in open_distribution view
Retrieve course object down to problems
Retrieve grade distribution for these problems
Construct data for each problem to be sent to d3
Restrict screen list length  Adding 1 so can tell if list is larger than MAX_SCREEN_LIST_LENGTH  without doing another select.
Remove the last item so list length is exactly MAX_SCREEN_LIST_LENGTH
Subsection name is everything after 3rd space in tooltip
Remove the last item so list length is exactly MAX_SCREEN_LIST_LENGTH
tooltips array is array of dicts for subsections and  array of array of dicts for problems.  Append to results offsetting 1 column to the right.
Append to results offsetting 1 column to the right.
Only 2 students in the list and response_max_exceeded is True
Only 2 students in the list and response_max_exceeded is True
Check response contains 1 line for each user +1 for the header
Check response contains 1 line for header, 1 line for Section and 1 line for Subsection
Check response contains 1 line for header, 1 line for Sections and 2 lines for problems
If you try to subscribe with too many users at once  the transaction times out on the mailchimp side.
send the updates in batches of a fixed size
reset segments
shuffle and split emails
to avoid overly verbose output, this is off by default
bail early if no beta testing is set up
The date is shown in the title, no need to display it again.
Return `true` if user is not enrolled in course
Show the summary if user enrollment is in which allow user to upsell
If this is an inheritable field and an override is set above,  then we want to return False here, so the field_data uses the  override and not the original value for this block.
Key used to share state. This is the XBlock usage_id
Internal state of the object
We use the student_id instead of username to avoid a database hop.  This can actually matter in cases where we're logging many of  these (e.g. on a broken progress page).
This should be populated from the modified field in StudentModule
Django will sometimes try to join to courseware_studentmodule  so just do an in query
If we turn off reading from multiple history tables, then we don't want to read from  StudentModuleHistory anymore, we believe that all history is in the Extended table.  we want to save later SQL queries on the model which allows us to prefetch
When the extended studentmodulehistory table exists, don't save  duplicate history into courseware_studentmodulehistory, just retain  data for reading.
The name of the field
The value of the field. Defaults to None dumped as json
The definition id for the module
The type of the module for these preferences
Check for content which needs to be completed  before the rest of the content is made available
Check for gated content
The user may not actually have to complete the entrance exam, if one is required
Only show required content, if there is required content  chapter.hide_from_toc is read-only (bool)
Skip the current chapter if a hide flag is tripped
skip the section if it is gated/hidden from the user
call into edx_proctoring subsystem  to get relevant proctoring information regarding this  level of the courseware  This will return None, if (user, course_id, content_id)  is not applicable
safety net in case something blows up in edx_proctoring  as this is just informational descriptions, it is better  to log and continue (which is safe) than to have it be an  unhandled exception
yes, user has proctoring context about  this level of the courseware  so add to the accordion data context
Something has gone terribly wrong, but still not letting it turn into a 500.
Bin score into range and increment stats
Cycle through the milestone fulfillment scenarios to see if any are now applicable  thanks to the updated grading information that was just submitted
Send a signal out to any listeners who are waiting for score change  events.
now bind the module to the new ModuleSystem instance and vice-versa
Build a list of wrapping functions that will be applied in order  to the Fragment content coming out of the xblocks that are about to be rendered.
Rewrite urls beginning in /static to point to course-specific content
Allow URLs of the form '/course/' refer to the root of multicourse directory    hierarchy of this course
pass position specified in URL to module through ModuleSystem
make an ErrorDescriptor -- assuming that the descriptor's system is ok
Test xqueue package, which we expect to be:    xpackage = {'xqueue_header': json.dumps({'lms_key':'secretkey',...}),                'xqueue_body'  : 'Message from grader'}
Transfer 'queuekey' from xqueue response header to the data.  This is required to use the interface defined by 'handle_ajax'
We go through the "AJAX" path  So far, the only dispatch from xqueue will be 'score_update'  Can ignore the return value--not used for xqueue_callback  Save any state that has changed to the underlying KeyValueStore
For blocks that are inherited from a content library, we add some additional metadata:
Either permissions just changed, or someone is trying to be clever  and load something they shouldn't have access to.
Check submitted files
Make a CourseKey from the course_id, raising a 404 upon parse error.
Gather metrics for New Relic so we can slice data in New Relic Insights
If we can't find the module, respond with a 404
For XModule-specific errors, we log the error and respond with an error message
If any other error occurred, re-raise it to trigger a 500 response
Check number of files submitted
Check file sizes
Compute grades using real division, with no integer truncation
check for subtree_edited_on because old XML courses doesn't have this attribute
For the moment, we have to get scorable_locations from field_data_cache  and not from scores_client, because scores_client is ignorant of things  in the submissions API. As a further refactoring step, submissions should  be hidden behind the ScoresClient.
This next complicated loop is just to collect the totaled_scores, which is  passed to the grader
If there are no problems that always have to be regraded, check to  see if any of our locations are in the scores from the submissions  API. If scores exist, we have to calculate grades for this section.
If we haven't seen a single problem in the section, we don't have  to grade it at all! We can assume 0%
We simply cannot grade a problem that is 12/0, because we might need it as a percentage
Grading policy might be overriden by a CCX, need to reset it
We round the grade here, to make sure that the grade is an whole percentage and  doesn't get displayed differently than it gets grades
way to get all RAW scores out to instructor  so grader can be double-checked
Possible grades, sorted in descending order of score
For the moment, we have to get scorable_locations from field_data_cache  and not from scores_client, because scores_client is ignorant of things  in the submissions API. As a further refactoring step, submissions should  be hidden behind the ScoresClient.
Check for gated content
Don't include chapters that aren't displayable (e.g. due to error)  Skip if the chapter is hidden
Skip if the section is hidden
If there is no weighting, or weighting can't be applied, return input.
These are not problems, and do not have a score
Problem may be an error module (if something in the problem builder failed)  In which case total might be None  add location to the max score cache
Grading calls problem rendering, which calls masquerading,  which checks session vars -- thus the empty session dict below.  It's not pretty, but untangling that is currently beyond the  scope of this feature.
Deliberately return a non-specific error message to avoid  leaking info about access control settings
Verify that the user is either enrolled in the course or a staff  member.  If user is not enrolled, raise UserNotEnrolled exception  that will be caught by middleware.
Use an empty cache
Use an empty cache
Sort courses by how far are they from they start day
This is fragile, but unfortunately the problem is that within the LMS we  can't use the reverse calls from the CMS
This is fragile, but unfortunately the problem is that within the LMS we  can't use the reverse calls from the CMS
it will be a Mongo performance boost, if you pass in a depth=3 argument here  as it will optimize round trips to the database to fetch all children for the current node
Remove due dates  Remove release dates for course content
Check key for validity
If we're getting user data, we expect that the key matches the  user we were constructed for.
If we're getting user data, we expect that the key matches the  user we were constructed for.
If save is successful on these fields, add it to  the list of successful saves
If we're getting user data, we expect that the key matches the  user we were constructed for.
If we're getting user data, we expect that the key matches the  user we were constructed for.
If we're getting user data, we expect that the key matches the  user we were constructed for.
Translators: 'Textbooks' refers to the tab in the course that leads to the course' textbooks
Translators: 'Discussion' refers to the tab in the courseware that leads to the discussion forums
Add in any dynamic tabs, i.e. those that are not persisted
No default class--want to complain if it doesn't find plugins for any  module.
print course
dircmp doesn't do recursive diffs.  diff = dircmp(course_dir, export_dir, ignore=[], hide=[])
load into a CorrectMap, as done in LoncapaProblem.__init__():
calculate score the way LoncapaProblem.get_score() works, by deferring to  CorrectMap's get_npoints implementation.
NOTE: if xml store owns these, it won't import them into mongo
HACK: add discussion ids to list of items to export (AN-6696)
When calculating inherited metadata, don't include existing  locally-defined metadata
If filename is '-' save to a temp file
-*- coding: utf-8 -*-
Just in case user is passed in as None, make them anonymous
delegate the work to type-specific functions.  (start with more specific types, then get more general)
NOTE: any descriptor access checkers need to go above this
Passing an unknown object here is a coding error, so rather than  returning a default, complain.
Courselike objects (e.g., course descriptors and CourseOverviews) have an attribute named `id`  which actually points to a CourseKey. Sigh.
If the user appears in CourseEnrollmentAllowed paired with the given course key,  they may enroll. Note that as dictated by the legacy database schema, the filter  call includes a `course_id` kwarg which requires a CourseKey.
Short-circuit the process, since there are no defined user partitions that are not  user_partitions used by the split_test module. The split_test module handles its own access  via updating the children of the split_test module.
use merged_group_access which takes group access on the block's  parents / ancestors into account  check for False in merged_access, which indicates that at least one  partition's group list excludes all students.
look up the user's group for each partition
finally: check that the user has a satisfactory group assignment  for each partition.
all checks passed.
Delegate to the descriptor
Use this sample rate for DataDog events.
If the state is the empty dict, then it has been deleted, and so  conformant UserStateClients should treat it as if it doesn't exist.
The rest of this method exists only to submit DataDog events.  Remove it once we're no longer interested in the data.
We do a find_or_create for every block (rather than re-using field objects  that were queried in get_many) so that if the score has  been changed by some other piece of the code, we don't overwrite  that score.
Anonymous users cannot be persisted to the database, so let's just use  what we have.
We just read this object, so we know that we can do an update
The rest of this method exists only to submit DataDog events.  Remove it once we're no longer interested in the data.  Record whether a state row has been created or updated.
Event to record number of fields sent in to set/set_many.
Event to record number of new fields set in set/set_many.
Event to record number of existing fields updated in set/set_many.
We just read this object, so we know that we can do an update
Event for the entire delete_many call.
If no history records exist, raise an error
If the state is serialized json, then load it
If the state is empty, then for the purposes of `get_history`, it has been  deleted, and so we list that entry as `None`.
Only display the requirements on learner dashboard for  credit and verified modes.
If the user needs to take an entrance exam to access this course, then we'll need  to send them to that specific course module before allowing them into other areas
check to see if there is a required survey that must be taken before  the user can access the course.
link to where the student should go to enroll in the course:  about page if there is not marketing site, SITE_NAME if there is
Get the URL of the user's last position in order to display the 'where you were last' message
Disable student view button if user is staff and  course is not yet visible to students.
Translators: This will look like '$50', where {currency_symbol} is a symbol such as '$' and {price} is a  numerical amount in that currency. Adjust this display as needed for your language.
Translators: This refers to the cost of the course. In this case, the course costs nothing so it is free.
In any other case redirect to the course about page.
Note: this is a flow for payment for course registration, not the Verified Certificate flow.
Find the minimum price for the course across all course modes
Used to provide context to message to student if enrollment not allowed
Register button should be disabled if one of the following is true:  - Student is already registered for course  - Course is already full  - Student cannot enroll in course
get prerequisite courses display names
Overview
check to see if there is a required survey that must be taken before  the user can access the course.
always allowed to see your own profile
Requesting access to a different student's profile  Check for ValueError if 'student_id' cannot be converted to integer.
The pre-fetching of groups is done to make auth checks not require an  additional DB lookup (this kills the Progress page in particular).
checking certificate generation configuration
If credit eligibility is not enabled or this is not a credit course,  short-circuit and return `None`.  This indicates that credit requirements  should NOT be displayed on the progress page.
This indicates that credit requirements should NOT be displayed on the progress page.
Credit requirement statuses for which user does not remain eligible to get credit.
If the user has *failed* any requirements (for example, if a photo verification is denied),  then the user is NOT eligible for credit.
Otherwise, the user may be eligible for credit, but the user has not  yet completed all the requirements.
Permission Denied if they don't have staff access and are trying to see  somebody else's submission history.
if there is no Survey associated with this course,  then redirect to the course instead
verify the user has access to the course, including enrollment check
get the block, which verifies whether the user has access to the block.
Simple sanity check that the session belongs to the user  submitting an FA request
Thrown if JSON parsing fails
Thrown if course key parsing fails
Thrown if fields are missing
The call to Zendesk failed. The frontend will display a  message to the user.
let it propagate
Set the user in the request to the effective user.
User may be trying to access a child that isn't live yet
Pre-fetch all descendant data
Bind section to user
default tab
Only save if position changed  Save this new position to the underlying KeyValueStore
manually twiddle the is_staff bit, if needed
staff should fail because password expired
if we reset the password, we should be able to log in
now retry with a different password
now use different one
now try again with the first one
should be rejected
now use different one
now we should be able to reuse the first one
try to reset password, it should fail
try to reset password, it should fail
try to reset password with a long enough password
Enroll in the course before trying to access pages
Search for items in the course
Try to load each item in the course
fix was to allow get_items() to take the course_id parameter
have a course which explicitly sets visibility in catalog to False
have a course which explicitly sets visibility in catalog and about to true
assert that test course display name is visible
assert that test course with 'visible_in_catalog' to True is showing up
assert that test course that is outside microsite is not visible
assert that a course that has visible_in_catalog=False is not visible
assert that footer template has been properly overriden on homepage
assert that the edX partners section is not in the HTML
assert that the edX partners tag line is not in the HTML
assert that test course display name IS NOT VISIBLE, since that is a Microsite only course
assert that test course that is outside microsite IS VISIBLE
assert that footer template has been properly overriden on homepage
Access the microsite dashboard and make sure the right courses appear
Now access the non-microsite dashboard and make sure the right courses appear
Create ccx coach account
assign role to coach
user have access as coach on ccx
user dont have access as coach on ccx
Enroll user
Assert access of a student
Enroll student to the course
Course key is not None
Enroll student to the course
Staff can always enroll even outside the open enrollment period
User should be able access after completing required course
Masquerade staff
Masquerade instructor
get a fresh user object that won't have any cached role information
checks staff role
checks staff role and enrollment data
This explicitly sets the user_tag for self.student to ``user_tag``
Assert we see the proper icon in the top display  And proper tooltips
Assert that we can see the data from the appropriate test condition
Data is html encoded, because it's inactive inside the  sequence until javascript is executed
We define problem compenents that we need but don't explicitly call elsewhere.  pylint: disable=unused-variable
Data is html encoded, because it's inactive inside the  sequence until javascript is executed
We define problem compenents that we need but don't explicitly call elsewhere.  pylint: disable=unused-variable
Now that we have the course, change the position and save, nothing should explode!
Factories are self documenting  pylint: disable=missing-docstring
pylint: disable=super-method-not-called
make sure we can access courseware immediately
then wait a bit and see if we get timed out
re-request, and we should get a redirect to login page
Check that registration button is present
this text appears in that course's about page  common/test/data/2014/about/overview.html
Get the about page again and make sure that the page says that the course is full
Try to enroll as well
Check that registration button is not present
Check that registration button is not present
Check that registration button is present
Setup enrollment period to be in future
Check that registration button is not present
course price is not visible ihe course_about page when the course  mode is not set to honor
note that we can't call self.enroll here since that goes through  the Django student views, which doesn't allow for enrollments  for paywalled courses
course price is visible ihe course_about page when the course  mode is set to honor and it's price is set
note that we can't call self.enroll here since that goes through  the Django student views, which doesn't allow for enrollments  for paywalled courses
Create ccx coach account
create ccx
50 percent exam score should be achieved.
This user helps to cover a discovered bug in the milestone fulfillment logic
make sure toc is locked before allowing user to skip entrance exam
Login as member of staff
assert staff has access to all toc
Mocking get_required_content with empty list to assume user has passed entrance exam
pylint: disable=protected-access
Assert that orphan sequential is root of the discussion module.
not allowed to be passed in (i.e. was throwing exception)
fix was to allow get_items() to take the course_id parameter
create tab
name is as expected
link is as expected
verify active page name
validate tab
check get and set methods
check to_json and from_json methods
check equality methods
return tab for any additional tests
Test render works okay
this text appears in the test course's tab  common/test/data/2014/tabs/8e4cce2b4aaf4ba28b1220804619e41f.html
login as instructor hit skip entrance exam api in instructor app
tab types that should appear only once
add the unique tab multiple times
create 1 book per textbook type
initialize the course tabs to a list of all valid tabs
enumerate the tabs with no user
test including non-empty collections
test not including empty collections
get tab by type
get tab by id
Data from YAML common/lib/xmodule/xmodule/templates/NAME/default.yaml  METADATA must be overwritten for every instance that uses it. Otherwise,  if we'll change it in the tests, it will be changed for all other instances  of parent class.
Turn off cache.
username = robot{0}, password = 'test'
Regression test; LOC-85
Now try to access with dark lang
Clearing the language should go back to site default
Create a registration for the user
Create a profile for the user
Create the test client
Url and site lang vars for tests to use
Regression test; LOC-87
Visit the front page; verify we see site default lang
Regression test; LOC-87
Upload english transcript.
Upload non-english transcript.
Upload english transcript.
Upload non-english transcript.
Test different language to ensure we are just ignoring it since we can't  translate with static fallback
No language
No filename in request.GET
no self.sub, self.youttube_1_0 exist, but no file in assets
no self.sub and no self.youtube_1_0, no non-en transcritps
Use toy course from XML
refresh the course from the modulestore so that it has children
reload the chapter from the store so its children information is updated
disable the visibility of the sections in the chapter
Verify staff has been enrolled to the given course
Set up the edxmako middleware for this request to create the RequestContext
Set up the edxmako middleware for this request to create the RequestContext
depreciated function
Since registration_price is set, it overrides the cosmetic_display_price and should be returned
Since registration_price is not set, cosmetic_display_price should be returned
Since both prices are not set, there is no price, thus "Free"
Toy course has no course end date or about/end_date blob
test_end has a course end date, no end_date HTML blob
test_about_blob_end_date has both a course end date and an end_date HTML blob.  HTML blob wins
log into a staff account
Tests that we do not get an "Invalid x" response when passing correct arguments to view
log into a staff account
log into a staff account
store state via the UserStateClient
Verify that the email opt-in checkbox appears, and that the expected  organization name is displayed.
Verify that the email opt-in checkbox does not appear
This is a static page, so just assert that it is returned correctly
Ensure that the user can only apply for assistance in  courses which have a verified mode which hasn't expired yet,  where the user is not already enrolled in verified mode
Middleware is not supported by the request factory. Simulate a  logged-in user by setting request.user manually.
Set up the edxmako middleware for this request to create the RequestContext
assertRedirects would be great here, but it forces redirections to be absolute URLs.
Same for setting the due date to None
hide due date completely
Set up the edxmako middleware for this request to create the RequestContext
Set up the edxmako middleware for this request to create the RequestContext
The start date is set in the set_up_course function above.
The start date is set in common/test/data/two_toys/policies/TT_2012_Fall/policy.json
Set up the edxmako middleware for this request to create the RequestContext
Test that malicious code does not appear in html
Create new course with respect to 'default_store'
Create a new course, a user which will not be enrolled in course, admin user for staff access
Create and enable Credit course
Configure a credit provider for the course
Add a single credit requirement (final grade)
Enable the feature, but do not enable it for this course
Enable the feature, but do not enable it for this course
Enable certificate generation for this course
when course certificate is not active
Enable the feature, but do not enable it for this course
Enable certificate generation for this course
If user has not grade then false will return
Mocking the grades.grade  If user has above passing marks then True will return
Mocking the grades.grade  If user has below passing marks then False will return
Mocking the grades.grade  If user's achieved passing marks are equal to the required passing  marks then it will return True
If try to access a course with valid key pattern then it will return  bad request code with course is not valid message
If try to access a course with invalid key pattern then 404 will return
We don't need actual children to test this.
Set up the edxmako middleware for this request to create the RequestContext
Set up the edxmako middleware for this request to create the RequestContext
Set up the edxmako middleware for this request to create the RequestContext
Referencing a non-existent VAL ID in courseware won't cause an error --  it'll just fall back to the values in the VideoDescriptor.
make sure the desktop_mp4 url is included as part of the alternative sources.
make sure the urls for the various encodings are included as part of the alternative sources.
test with and without edx_video_id specified.
the video is associated in VAL so no cache miss should ever happen but test retrieval in both contexts
The video is not in VAL so in contexts that do and don't allow cache misses we should always get a fallback
arbitrary constant
Check whether the user has been enrolled in the course.  There was a bug in which users would be automatically enrolled  with is_active=False (same as if they enrolled and immediately unenrolled).  This verifies that the user doesn't have *any* enrollment record.
Create ccx coach account
create ccx
this text appears in that course's course info page  common/test/data/2014/info/updates.html
should redirect
Check both that the user is created, and inactive
and now we try to activate  Now make sure that the user is now actually activated
format the response dictionary to be sent in the post request by adding the above prefix to each key
Tell Django to clean out all databases, not just default  arbitrary constant
re-fetch the course from the database so the object is up to date
if we don't already have a chapter create a new one
now that we've added the problem and section to the course  we fetch the course from the database so the object we are  dealing with has these additions
list of grade summaries for each section
get the first section that matches the url (there should only be one)
Tell Django to clean out all databases, not just default
names for the problem in the homeworks
Now fetch the state entry for that problem.  count how many state history entries there are
now click "show answer"
check that we don't have more state history entries
problem isn't in the cache
problem is in the cache
Verify that the submissions API was sent an anonymized student ID
Get both parts correct
Enable the course for credit
Configure a credit provider for the course
Add a single credit requirement (final grade)
Tell Django to clean out all databases, not just default
re-fetch the course from the database so the object is up to date
Tell Django to clean out all databases, not just default
define the correct and incorrect responses to this problem
re-fetch the course from the database so the object is up to date
define the correct and incorrect responses to this problem
re-fetch the course from the database so the object is up to date
define the correct and incorrect responses to this problem
re-fetch the course from the database so the object is up to date
Just make sure we can process this without errors.
Throw in a non-ASCII answer
Now make more submissions by our original user
We'll submit one problem, and then muck with the student_answers  dict inside its state to try different data types (str, int, float,  none)
If there's a StudentModule entry for content that no longer exists,  we just quietly ignore it (because we can't display a meaningful url  or name for it).
It should be empty (ignored)
Submit p1
Now fetch the StudentModule entry for p1 so we can corrupt its state
Submit p2
Now add the student to the specified group.
Group 1 will have 1 problem in the section, worth a total of 1 point.
Submit answers for problem in Section 1, which is visible to all students.
Grade percent is .63. Here is the calculation
Grade percent is .75. Here is the calculation
Group 1 will have 1 problem in the section, worth a total of 1 point.
Grade percent is .25. Here is the calculation.
Grade percent is .75. Here is the calculation.
check word cloud response for every user
1.
2.  Invcemental state per user.
Final state after all posts.
3.
4.
The courseware url should redirect, not 200
Shouldn't be able to get to the instructor pages
Now should be able to get to self.course, but not  self.test_course
Now should be able to get to self.course, but not  self.test_course
First, try with an enrolled student
shouldn't be able to get to anything except the light pages
Enroll in the classescan't see courseware otherwise.
should now be able to get to everything for self.course
and now should be able to load both
First, try with an enrolled student
Then, try as an instructor
Then, try as global staff
student user shouldn't see it
now the student should see it
however we want to make sure we persist the course_id
Pass `emit_signals=True` so that these courses are cached with CourseOverviews.
Request filtering for an org distinct from the designated microsite org.
Request filtering for an org matching the designated microsite org.
Test render works okay
Verify staff initially can see staff debug
Toggle masquerade to student
Toggle masquerade back to staff
Verify that staff initially can see "Show Answer".
Toggle masquerade to student
Toggle masquerade back to staff
Log in as staff, and check we can see the info page.
Answer correctly as the student, and check progress.
Log in as staff, and check the problem is unanswered.
Masquerade as the student, and check we can see the student state.
Temporarily override the student state.
Reload the page and check we see the student state again.
Become the staff user again, and check the problem is still unanswered.
Verify the student state did not change.
Log in as staff, and check we can see the info page.
Masquerade as the student, and check we can see the info page.
Verify that there is no masquerading group initially
Verify that the masquerading group is returned
Configure course as a credit course
Create a user and log in
Enroll the user in the course as "verified"
The user hasn't satisfied any of the credit requirements yet, but she  also hasn't failed any.
Mark the user as eligible for all requirements
Mark the user as having failed both requirements
Verify the requirements are shown only if the user is in a credit-eligible mode.
Clear the internal staticfiles caches, to get test isolation.
This string comes from footer.html  This string comes from header.html
Test that a theme adds itself to the staticfiles search path.
pylint: disable=missing-docstring
Create a released discussion module
Create a scheduled discussion module
Create a `self_paced` course and add a beta tester in it
Verify course is `self_paced` and course has start date but not section.
Verify that non-staff user do not have access to the course
Verify beta tester can access the course as well as the course sections
Only the released module should be visible when the course is instructor-paced.
pylint: disable=missing-docstring
Since field_data is responsible for attribute access, you'd  expect it to raise AttributeError. In fact, it raises KeyError,  so we check for that.
Tell Django to clean out all databases, not just default
We only record block state history in DjangoUserStateClient  when the block type is 'problem'
We're skipping these tests because the iter_all_by_block and iter_all_by_course  are not implemented in the DjangoXBlockUserStateClient
delete the gray/worm groups from the partitions now so we can test scenarios  for user whose group is missing.
add a staff user, whose access will be unconditional in spite of group access.
this test isn't valid unless block_accessed is a descendant of  block_specified.
Initially, "red_cat" user can't view the vertical.
Change the vertical's user_partitions value to the empty list. Now red_cat can view the vertical.
Finally, add back in a cohort user_partition
make sure we redirect to the course about page
Tell Django to clean out all databases, not just default
There should be only one query to load a single descriptor with a single user_state field
This should only read from the cache, not the database
This should only read from the cache, not the database
because we're patching the underlying save, we need to ensure the  fields are in the cache
Tell Django to clean out all databases, not just default
The descriptor has no fields, so FDC shouldn't send any queries
Each field is stored as a separate row in the table,  but we can query them in a single query
Each field is a separate row in the database, hence  a separate query
Construct a mock module for the modulestore to return
get the rendered HTML output which should have the rewritten link
See if the url got rewritten to the target link  note if the URL mapping changes then this assertion will break
Verify that handle ajax is called with the correct data
get_score_bucket calls error cases 'incorrect'
check that _unwrapped_field_data is the same as the original  _field_data, but now _field_data as been reset.  pylint: disable=protected-access, no-member
now bind this module to a few other students
_field_data should now be wrapped by LmsFieldData  pylint: disable=protected-access, no-member
the LmsFieldData should now wrap OverrideFieldData  pylint: disable=protected-access, no-member
the OverrideFieldData should point to the original unwrapped field_data  pylint: disable=protected-access, no-member
Construct a mock module for the modulestore to return
We can't use `name` as a kwarg to Mock to set the name attribute  because mock uses `name` to name the mock itself
we expect there not to be a 'proctoring' key in the dict
refresh cache after update
No matter what data goes in, there should only be one close-script tag.
pylint: disable=attribute-defined-outside-init
The "set" here is to work around the bug that load_classes returns duplicates for multiply-delcared classes.
Use the xblock_class's bind_for_student method
This value is set by observation, so that later changes to the student  id computation don't break old data
This value is set by observation, so that later changes to the student  id computation don't break old data
This value is set by observation, so that later changes to the student  id computation don't break old data
Bind the module to another student, which will remove "correct_map"  from the module's _field_data_cache and _dirty_fields.
pylint: disable=no-member
pylint: disable=attribute-defined-outside-init, no-member
Validate direct XModule access as well
Validate direct XModule access as well
Create a child of each block type for each user
pylint: disable=no-member
But we should still have five gradesets
Even though two will simply be empty
The rest will have grade information in them
add score to cache
push to remote cache
create a new cache with the same params, fetch from remote cache
see cache is populated
Tell Django to clean out all databases, not just default
pylint: disable=protected-access
DOM elements that appear in an xBlock,  but are excluded from the xBlock-only rendering.
The key used to store a user's course-level masquerade information in the Django session.  The value is a dict from course keys to CourseMasquerade objects.
The key used to store temporary XBlock field data in the Django session.  This is where field  data is stored to avoid modifying the state of the user we are masquerading as.
All parameters to this function must be named identically to the corresponding attribute.  If you remove or rename an attribute, also update the __setstate__() method to migrate  old data from users' sessions.
Sentinel object to mark deleted objects in the session cache
We can't simply delete the key from the session, since it might still exist in the kvs,  which we are not allowed to modify, so we mark it as deleted by setting it to  _DELETED_SENTINEL in the session.
Prevent jQuery menu animations from interferring with the clicks
Open the 2nd section
Click on the subsection to see the content
Click on the 2nd subsection to see the content
Generate the problem XML using capa.tests.response_xml_factory  Since this is just a placeholder, we always use multiple choice.
Add the problem
Wait for the problem to reload
error is shown
iframe is not presented
link is not presented
iframe is visible
To start with you should only have one window/tab
Give it a few seconds for the LTI window to appear
Verify the LTI window
inside iframe test content is presented
First clear the modulestore so we don't try to recreate  the same course twice  This also ensures that the necessary templates are loaded
Create the course  We always use the same org and display name,  but vary the course identifier (e.g. 600x or 191x)
create beta tester
Enroll the user in the course and log them in
You should now have 2 browser windows open, the original courseware and the LTI
For verification, iterate through the window titles and make sure that  both are there.
First clear the modulestore so we don't try to recreate  the same course twice  This also ensures that the necessary templates are loaded
Create the course  We always use the same org and display name,  but vary the course identifier (e.g. 600x or 191x)
Add a chapter to the course to contain problems
Create the course
Create the user
Do we really use these 3 w/ a different course than is in the scenario_dict? if so, why? If not,  then get rid of the override arg
Make sure that the problem has been completely rendered before  starting to input an answer.
Correct answer is any two integers that sum to 10
If we want an incorrect answer, then change  the second addend so they no longer sum to 10
The other response types use random data,  which would be difficult to check  We trade input value coverage in the other tests for  input type coverage in this test.
Create a problem item using our generated XML  We set rerandomize=always in the metadata so that the "Reset" button  will appear.
this is necessary due to naming requirement for this problem type
If the input element doesn't exist, fail immediately
Retrieve the input element
Remove any trailing spaces that may have been added
Ensure that the course has this problem type
Go to the one section in the factory-created course  which should be loaded with the correct problem
Set the fake xqueue server to always respond  correct/incorrect when asked to grade a problem
Change the answer on the page
Submit the problem
Wait for the problem to finish re-rendering
first scroll down so the loading mathjax button does not  cover up the Check button
Wait for the problem to finish re-rendering
The label text is changed by static/xmodule_js/src/capa/display.js  so give it some time to change on the page.
The problem progress is changed by  cms/static/xmodule_js/src/capa/display.js  so give it some time to render on the page.
Determine which selector(s) to look for based on correctness
At least one of the correct selectors should be present
As soon as we find the selector, break out of the loop
Expect that we found the expected selector
Ensure all events are written out to mongo before querying.
Importing signals is necessary to activate the course publish/delete signal handlers.
Course identifier (opaque_keys.edx.keys.CourseKey)
User object (django.contrib.auth.models.User)
Cached value of whether the user has staff access (bool/None)
The countdown=0 kwarg ensures the call occurs after the signal emitter  has finished all operations.
Default list of transformers for manipulating course block structures  based on the user's access to the course blocks.
compute merged value of visible_to_staff_only from all parents
set the merged value for this block  merge visible_to_staff_only from all parents and this block
Users with staff access bypass the Visibility check.
compute merged value of start date from all parents
set the merged value for this block  no parents so just use value on block or default
no value on this block so take value from parents
max of merged-start-from-all-parents and this block
Users with staff access bypass the Start Date check.
update selected
publish events for analytics
Check and remove all non-selected children from course  structure.
Create dict of child location to group_id, using the  group_id_to_child field on the split_test module.
Set group access for each child using its group_access  field so the user partitions transformer enforces it.
The UserPartitionTransformer will enforce group access, so  go ahead and remove all extraneous split_test modules.
First have the split test transformer setup its group access  data for each block.
Because user partitions are course-wide, only store data for  them on the root block.
If there are no user partitions, this transformation is a  no-op, so there is nothing to collect.
{ partition.id: set(IDs of groups that can access partition) }  If partition id is absent in this dict, no group access  restrictions exist for that partition.
Get the group_access value that is directly set on the xblock.  Do not get the inherited value since field inheritance doesn't  take a union of them for DAGs.
Running list of all groups that have access to this  block, computed as a "union" from all parent chains.  Set the default to universal access, for the case when  there are no parents.
Set the default to most restrictive as we iterate  through all the parent chains.
Group access for this partition as stored on the xblock
Compute this block's access by intersecting the block's  own access with the merged access from its parent chains.
Add this partition's access only if group restrictions  exist.
If the user is not assigned to a group for this partition,  deny access.
If the user belongs to one of the allowed groups for this  partition, then move and check the next partition.
Else, deny access.
The user has access for every partition, grant access.
Enroll user in course.
Set up users.
First remove the block from the course.  It would be re-added to the course if the course was  explicitly listed in parents.
Add this to block to each listed parent.
recursively call the children
build the course tree
add additional parents if the course is a DAG or built  linearly (without specifying 'children' values)
Tree formed by parent_map:         0      /     \     1       2    / \     / \   3   4   /   5        \ /         6  Note the parents must always have lower indices than their  children.
create the course
an ordered list of block locations, where the index  corresponds to the block's index in the parents_map.
create all other blocks in the course
verify given test user has access to expected blocks
verify staff has access to all blocks
compute access results of the block
compare with expected value
Set up groups
Set up user partitions and groups.
Build course.
Enroll user in course.
Set up cohorts.
Set up multiple user partitions and groups.
Set up cohorts.
universal access throughout
partitions 1 and 2 requiring membership in list of groups
parent inheritance    1 parent allows
1 parent denies
1 parent denies, 1 parent allows
intersect with parent    child denies, 1 parent allows
child allows, 1 parent allows, 1 parent denies
use the course as the block to test
update block access
convert merged_parents_list to _MergedGroupAccess objects
convert group_id to groups in user_partition_groups parameter
Build course.
Enroll user in course.
user was randomly assigned to one of the groups
course is not visible to staff only
course becomes visible to staff only
Mode a badge was awarded for. Included for legacy/migration purposes.
Actual max is 256KB, but need overhead for badge baking. This should be more than enough.
pylint: disable=no-member
Fall back to default, if there is one.
Use the standard Configuration Model Admin handler for this model.
Make this unique to the course, and down to 64 characters.  We don't do this to badges without issuing_component set for backwards compatibility.
Will be 64 characters.
Should be the hashed result of test_slug as the slug, and test_component as the component
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
Can't preserve old badges without modes.
-*- coding: utf-8 -*-
We're not configured to make a badge for this course mode.
Badge already exists. Skip.
pylint: disable=no-member
pylint: disable=no-member
pylint: disable=no-member
pylint: disable=no-member
pylint: disable=no-member
pylint: disable=no-member
pylint: disable=no-member
We don't award badges until all three are set.  pylint: disable=no-member
Password defined by factory.
pylint: disable=no-member
pylint: disable=no-member
Also create a version of this badge under a different course.  Same badge class, but different user. Should not show up in the list.
Different badge class AND different user. Certainly shouldn't show up in the list!
pylint: disable=no-member
pylint: disable=no-member
pylint: disable=no-member
We might want to get all the matching course scoped badges to see how many courses  a user managed to get a specific award on.
Need to get all badges for the user.
Django won't let us use 'None' for querying a ForeignKey field. We have to use this special  'Empty' value to indicate we're looking only for badges without a course key set.
Run this twice to verify there wasn't a background creation of the badge.
Make sure wiki_plugin.py gets run.
Markdown 2.1.0 changed from 2.0.3. We try importing the new version first,  but import the 2.0.3 version if it fails
Needs to come before escape matching because \ is pretty important in LaTeX
Markdown 2.1.0 changed from 2.0.3. We try importing the new version first,  but import the 2.0.3 version if it fails
Override defaults with user settings
pylint: disable=no-member
pylint: disable=no-member
pylint: disable=no-member
pylint: disable=no-member
pylint: disable=no-member
pylint: disable=no-member
pylint: disable=no-member
We will create it in the next block
create it
Somehow we got a urlpath without an article. Just delete it and  recerate it.
Translators: this string includes wiki markup.  Leave the ** and the _ alone.
When not enrolled, we should get a 302
When not logged in, we should get a 302
and end up at the login page
This string comes from themes/red-theme/lms/templates/footer.html
Django-wiki expects article slug to be non-numerical. In case the  course number is numerical append an underscore.
Ancestors of /Phy101/Mechanics/Acceleration/ is a list of URLPaths  ['Root', 'Phy101', 'Mechanics']
See if we are able to view the course. If we are, redirect to it  Even though we came from the course, we can't see it. So don't worry about it.
we care only about requests to wiki urls
wiki pages are login required
This is a /courses/org/name/run/wiki request  HACK: django-wiki monkeypatches the reverse function to enable  urls to be rewritten
if a user is logged in, but not authorized to see a page,  we'll redirect them to the course about page  set the course onto here so that the wiki template can show the course navigation
Check to see if we don't allow top-level access to the wiki via the /wiki/xxxx/yyy/zzz URLs  this will help prevent people from writing pell-mell to the Wiki in an unstructured way
Temporarily remove the grant type to avoid triggering the super method's code that removes request.user.
Ensure the tokens get associated with the correct user since DOT does not normally  associate access tokens issued with the client_credentials grant to users.
Restore the original request attributes
Extracting order information
Extracting OrderItem information of unit_cost, list_price and status
if coupon is redeemed against the order, update the information in the order_item_dict
Extracting sale information
Report run date
For data extractions on the 'meta' field  the feature name should be in the format of 'meta.foo' where  'foo' is the keyname in the meta dictionary
now featch the requested meta fields
Note that we use student.course_groups.all() here instead of  student.course_groups.filter(). The latter creates a fresh query,  therefore negating the performance gain from prefetch_related().
Are we dealing with an "old-style" problem location?
we have to capture the redeemed_by value in the case of the downloading and spent registration  codes csv. In the case of active and generated registration codes the redeemed_by value will be None.   They have not been redeemed yet
Ensure that UsageKey.from_string returns a problem key that list_problem_responses can work with  (even when called with a dummy location):
Ensure that StudentModule.objects.filter returns a result set that list_problem_responses can work with  (this keeps us from having to create fixtures for this test):
Check if list_problem_responses called UsageKey.from_string to look up problem key:  Check if list_problem_responses called StudentModule.objects.filter to obtain relevant records:
This behaviour is somewhat inconsistent: None string fields  objects are converted to "None", but non-JSON serializable fields  are converted to an empty string.
get the updated item  get the redeemed coupon information
get the updated item
Create a paid course mode.
choices with a restricted domain, e.g. level_of_education  choices with a larger domain e.g. year_of_birth
to be set later
short name and display name (full) of the choices.
change none to no_data for valid json key  django does not properly count NULL values when using annotate Count  so      distribution['no_data'] = distribution.pop(None)  would always be 0.
Correctly count null values
now call the actual save method
first remove any answer the user might have done before
make sure the form is wrap in some outer single element  otherwise lxml can't parse it  NOTE: This wrapping doesn't change the ability to query it
adding the course_id where the end-user answered the survey question  since it didn't exist in the beginning, it is nullable
See if there is an answer stored for this user, form, field_name pair or not  this will allow for update cases. This does include an additional lookup,  but write operations will be relatively infrequent
Allow for update cases.
the result set from get_answers, has an outer key with the user_id  just remove that outer key to make the JSON payload simplier
support multi-SELECT form values, by string concatenating them with a comma separator
the URL we are supposed to redirect to is  in a hidden form field
scrub the answers to make sure nothing malicious from the user gets stored in  our database, e.g. JavaScript  only allow known input fields
The HTTP end-point for the payment processor.
-*- coding: utf-8 -*-
Create two accounts
is the SurveyForm html present in the HTML response?
however we want to make sure we persist the course_id
update
update with just a subset of the origin dataset
even though we have 2 users submitted answers  limit the result set to just 1
this will throw exception if not found, but a non existing survey name will  be trapped in the above is_survey_required_for_course() method
survey is required and it exists, let's see if user has answered the survey  course staff do not need to answer survey
this is here to support registering the signals in signals.py
if anything goes wrong rendering the receipt, it indicates a problem fetching order data.
don't assume the signal was fired with `send_robust`.  avoid blowing up other signal handlers by gracefully  trapping the Exception and logging an error.
this is a known limitation; commerce service does not presently  support the case of a non-superusers initiating a refund on  behalf of another user.
no other error is anticipated, so re-raise the Exception
at least one refundable order was found.
don't break, just log a warning
no refundable orders were found.
Copy the tags to avoid modifying the original list.
Remove duplicates
Encode the data to create a JSON payload
this is not presently supported with the external service.
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
LMS utilizes User.user_is_active to indicate email verification, not whether an account is active. Sigh!
log the error, return silently
If there is no audit or honor course mode, this most likely  a Prof-Ed course. Return an error so that the JS redirects  to track selection.
Accept either honor or audit as an enrollment mode to  maintain backwards compatibility with existing courses
Make the API call
Pass data to the client to begin the payment flow.
The order was completed immediately because there is no charge.
Ignore events fired from UserFactory creation
Verify that an audit message was logged
Validate the response content
Set user's active flag
Set user's active flag
Place an order
Remove SKU from all course modes
Validate the response
Ensure that the user is not enrolled and that no calls were made to the E-Commerce API
The view should return an error status code
Set SKU to empty string for all modes.
Enroll user in the course
NOTE (CCB): Ideally, the course modes table should only contain data for courses that exist in  modulestore. If that is not the case, say for local development/testing, carry on without failure.
Override the verification deadline for the course (not the individual modes)
Django Rest Framework v3 requires that we provide a queryset.  Note that we're overriding `get_object()` below to return a `Course`  rather than a CourseMode, so this isn't really used.
There is nothing to pre-save. The default behavior changes the Course.id attribute from  a CourseKey to a string, which is not desired.
In cases where upgrade_deadline is None (e.g. the verified professional mode), allow a verification  deadline to be set anyway.
Sanity check: The API should return HTTP status 200 for updates
Sanity check: Ensure no verification deadline is set
Generate the expected data
Sanity check: The API should return HTTP status 200 for updates
Verify the course and modes are returned as JSON
Verify the verification deadline is updated
Now set the deadline to None
The existing CourseMode should have been removed.
Verify the display names are correct
fake an ecommerce api request.
a key will be missing; we will not expect the receipt page to handle a cybersource decision
Verify that the header navigation links are hidden for the edx.org version
Verify that the logged message contains comma-separated  key-value pairs ordered alphabetically by key.
override this in subclasses.
override this in subclasses, using one of httpretty's method constants
if skip_refund is set to True in the signal, we should not try to initiate a refund.
if the course_enrollment is not refundable, we should not try to initiate a refund.
no HTTP request/user: auth to commerce service as the unenrolled student.
HTTP user is another server (AnonymousUser): do not try to initiate a refund at all.
See class docstring for description of status states
Where we place the uploaded image files (e.g. S3 URLs)
Randomly generated UUID so that external services can post back the  results of checking a user's photo submission without use exposing actual  user IDs or something too easily guessable.
If the review was done by an internal staff member, mark who it was.
Mark the name of the service used to evaluate this attempt (e.g  Software Secure).
If status is "denied", this should contain text explaining why.
Non-required field. External services can add any arbitrary codes as time  goes on. We don't try to define an exhuastive list -- this is just  capturing it so that we can later query for the common problems.
This should only be one at the most, but just in case we create more  by mistake, we'll grab the most recently created one.
user_has_valid_or_pending does include 'approved', but if we are  here, we know that the attempt is still pending
If someone is denied their original verification attempt, they can try to reverify.
If there's no deadline, then return the most recently created verification
Otherwise, look for a verification that was in effect at the deadline,  preferring recent verifications.  If no such verification is found, implicitly return `None`
At any point prior to this, they can change their names via their  student dashboard. But at this point, we lock the value into the  attempt.
If someone approves an outdated version of this, the first one wins
Upload this to S3
Update our record fields
find the messages associated with this category
if we can't parse the message as JSON or the category doesn't  match one of our known categories, show a generic error
Override the receipt ID if one is provided.  This allow us to construct S3 keys to images submitted in previous attempts  (used for reverification, where we send a new face photo with the same photo ID  from a previous attempt).
If we're copying the photo ID image from a previous verification attempt,  then we need to send the old image data with the correct image key.
The system prefers to set this automatically based on default settings. But  if the field is set manually we want a way to indicate that so we don't  overwrite the manual setting of the field.
Maintain a history of changes to deadlines for auditing purposes
Endpoint for in-course reverification  Users are sent to this end-point from within courseware  to re-verify their identities by re-submitting face photos.
These steps can be skipped using the ?skip-first-step GET param
Messages  Depending on how the user entered reached the page,  we will display different text messaging.  For example, we show users who are upgrading  slightly different copy than users who are verifying  for the first time.
Deadline types
Parse the course key  The URL regex should guarantee that the key format is valid.
Verify that the course exists
Check whether the user has access to this course  based on country access rules.
Redirect the user to a more appropriate page if the  messaging won't make sense based on the user's  enrollment / payment / verification status.
If the user set a contribution amount on another page,  use that amount to pre-fill the price selection form.
Remember whether the user is upgrading  so we can fire an analytics event upon payment.
Determine the photo verification status
get available payment processors  transaction will be conducted via ecommerce service  transaction will be conducted using legacy shopping cart
If the user is already enrolled but hasn't yet paid,  then the "upgrade" messaging is more appropriate.
If the user is NOT enrolled, then send him/her  to the first time verification page.
If the student has paid, but not verified, redirect to the verification flow.
IIf the user is trying to pay, has activated their account, and the ecommerce service  is enabled redirect him to the ecommerce checkout page.
Redirect if necessary, otherwise implicitly return None
Retrieve all the modes at once to reduce the number of database queries
Retrieve the first mode that matches the following criteria:   * Unexpired   * Price > 0   * Not credit
Otherwise, find the first non credit expired paid mode
Otherwise, return None and so the view knows to respond with a 404.
The "make payment" step doubles as an intro step,  so if we're showing the payment step, hide the intro step.
return 'expiration_datetime' of latest photo verification if found,  otherwise implicitly return ''
Make an API call to create the order and retrieve the results
Pass the payment parameters directly from the API response.
if request.POST doesn't contain 'processor' then the service's default payment processor will be used.
(XCOM-214) To be removed after release.  the absence of this key in the POST payload indicates that the request was initiated from  a stale js client, which expects a response containing only the 'payment_form_data' part of  the payment data result.
Validate the POST parameters
If necessary, update the user's full name
Retrieve the image data  Validation ensures that we'll have a face image, but we may not have  a photo ID image if this is a reverification.
If we have a photo_id we do not want use the initial verification image.
Submit the attempt
Send a URL that the client can redirect to in order  to return to the checkpoint in the courseware.
Pull out the parameters we care about.
The face image is always required.
Decode face image data (used for both an initial and re-verification)
Decode the photo ID image data if it's provided
We will always have face image data, so upload the face image
Submit the attempt
We catch all exceptions and log them.  It would be much, much worse to roll back the transaction due to an uncaught  exception than to skip sending the notification email.
Catch exception if unable to add credit requirement  status for user
This is what we should be doing...     return HttpResponseBadRequest("Signature is invalid")
This is what we're doing until we can figure out why we disagree on sigs
Trigger ICRV email only if ICRV status emails config is enabled
emit the reverification event
Set the attempts status to 'must_retry' so that we can re-submit it
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
Get-or-create the verification checkpoint
Avoid circular import
As a user skips the reverification it declines to fulfill the requirement so  requirement sets to declined.
Choose an uncommon number for the price so we can search for it on the page
Go to the course mode page, expecting a redirect to the intro step of the  payment flow (since this is a professional ed course). Otherwise, the student  would have the option to choose their track.
For professional ed courses, expect that the student is NOT enrolled  automatically in the course.
On the first page of the flow, verify that there's a button allowing the user  to proceed to the payment processor; this is the only action the user is allowed to take.
Longer string
Even though our AES key is only 32 bytes, RSA encryption will make it 256  bytes, and base64 encoding will blow that up to 344
This shouldn't happen if the student has been auto-enrolled,  but if they somehow end up on this page without enrolling,  treat them as if they need to pay
If unenrolled, treat them like they haven't paid at all  (we assume that they've gotten a refund or didn't pay initially)
Verify that the header navigation links are hidden for the edx.org version
We've already paid, and now we're trying to verify
Expect that *all* steps are displayed,  but we start after the payment step (because it's already completed).
These will be hidden from the user anyway since they're starting  after the payment step.
Already verified, so if we somehow end up here,  redirect immediately to the dashboard
Expect that *all* steps are displayed,  but we start at the payment confirmation step
These will be hidden from the user anyway since they're starting  after the payment step.  We're already including the payment  steps, so it's easier to include these as well.
Expect that *all* steps are displayed,  but we start on the first verify step
There are no other steps, so stay on the  payment confirmation step
If we've already paid, then the upgrade messaging  won't make much sense.  Redirect them to the  "verify later" page instead.
Already verified and paid, so redirect to the dashboard
Do NOT specify a contribution for the course in a session var.
Expect that the contribution amount is NOT pre-filled,
Specify a contribution amount for this course in the session
Expect that the contribution amount is pre-filled,
Set the upgrade deadline (course mode expiration) and verification deadline  to the same value.  This used to be the default when we used the expiration datetime  for BOTH values.
Need to be enrolled
Simulate paying for the course and enrolling
Enter the verification part of the flow  Expect that we are able to verify
Check that the mode selected is expired verified mode not the credit mode  because the direct enrollment to the credit mode is not allowed.
Enroll as verified (simulate purchasing the verified enrollment)
Simulate that we're embargoed from accessing this  course based on our IP address.
Set the course mode expiration (same as the "upgrade" deadline)
Set the verification deadline
setting a nonempty sku on the course will a trigger calls to  the ecommerce api to get payment processors.
ensure the mock api call was made.  NOTE: the following line  approximates the check - if the headers were empty it means  there was no last request.
mock out the payment processors endpoint
Call the function
Verify that an audit message was logged
Use the wrong HTTP method
Submit the photos
Verify that the attempt is created in the database
Verify that the user's name wasn't changed
Submit the photos, along with a name change
Check that the user's name was changed in the database
Error because invalid parameters, so no confirmation email  should be sent.
Mock the POST to Software Secure
Submit an initial verification attempt
Submit a face photo for re-verification
Verify that the initial attempt sent the same ID photo as the reverification attempt
Verify that the second attempt sent the updated face photo
Submit a new face photo and photo id for verification
Verify that the initial attempt sent a new ID photo for the reverification attempt
Missing face image parameter
Submit face image data, but not photo ID data.  Since the user doesn't have an initial verification attempt, this should fail
Create the initial verification attempt with some dummy  value set for field 'photo_id_key'
Now the request should succeed
Verify that photo submission confirmation email was sent
Verify that photo submission confirmation email was not sent
Verify that photo submission confirmation email was sent
Verify that ICRV status email was sent when config is enabled
Create the 'edx-reverification-block' in course tree
now check that '_send_email' method is called on result callback  with required parameters
Create checkpoint
Add a re-verification attempt
Add a re-verification attempt status for the user
User has a denied attempt, so can reverify
User has a verification attempt, but it's expired
Allow the student to reverify
User has submitted a verification attempt, but Software Secure has not yet responded
Can re-verify because an attempt has already been submitted.
Submitted attempt has been approved
Cannot reverify because the user is already verified.
Enroll the user in the default mode (honor) to emulate
mocking and patching for bi events
Retrieve a checkpoint that doesn't yet exist
Since the user has no initial verification and we're not sending the ID photo,  we should expect a 400 bad request
Check that the checkpoint status has been updated
Get the re-verification block to check the call made
Expect that the verification block is fetched
-*- coding: utf-8 -*-
The keys should be stored as Base64 strings, i.e. this should not explode
These should all fail because we're in the wrong starting state.
Now let's fill in some values so that we can pass the mark_ready() call
ready (can't approve or deny unless it's "submitted")
must_retry
submitted
approved
denied
Basic case, things go well.
We post, but Software Secure doesn't like what we send for some reason
We try to post, but run into an error (in this case a newtork connection error)
This user has no active at the moment...
Create an attempt and mark it ready...
A new user won't see this...
But if we create yet another one and mark it ready, it passes again.
And if we add yet another one with a later created time, we get that  one instead. We always want the most recent attempt marked ready()
We haven't marked attempt_3 ready yet, so attempt_2 still wins
Now we mark attempt_3 ready and expect it to come back
If it's any of these statuses, they don't have anything outstanding
Any of these, and we are. Note the benefit of the doubt we're giving  -- must_retry, and submitted both count until we hear otherwise
test for correct status when no error returned
test for when one has been created
create another one for the same user, make sure the right one is  returned
now delete the first one and verify that the denial is being handled  properly
Not active before the created date
Active immediately after created date
Active immediately before expiration date
Not active after the expiration date
No attempts in the query set, so should return None
Should also return None if no deadline specified
Make an attempt
Before the created date, should get no results
Immediately after the created date, should get the attempt
If no deadline specified, should return first available
Immediately after the expiration date, should not get the attempt
Create a second attempt in the same window
Now we should get the newer attempt
No initial verification for the user
Make an initial verification with 'photo_id_key'
Check that method 'get_initial_verification' returns the correct  initial verification attempt
Now create a second verification without 'photo_id_key'
Test method 'get_initial_verification' still returns the correct  initial verification attempt which have 'photo_id_key' set
create the 'VerificationCheckpoint' checkpoint
Retrieving a checkpoint that doesn't yet exist will create it
Create the checkpoint
create the VerificationCheckpoint checkpoint
test creating the VerificationCheckpoint checkpoint with same course  id and checkpoint name
adding two check points.
make an attempt for the 'first_checkpoint'
make another attempt for the 'first_checkpoint'
make new attempt for the 'second_checkpoint'
remove the attempt from 'second_checkpoint'
adding verification status
test the status from database
add initial verification status for checkpoints
now add verification status for multiple checkpoint points
creating software secure attempt against checkpoint
add initial verification status for checkpoint
add verification status
create skipped attempt for different user
Initially, no deadlines are set
Create the deadlines
Warm the cache
Load the deadlines from the cache
Delete the deadlines
Verify that the deadlines are updated correctly
Enroll in a verified mode
testing service for skipped attempt.
No longer enrolled in a verified track
Should be marked as "skipped" (opted out)
A bad book id will be a 404.
A bad page id will cause a 404.
If the book id isn't an int, we'll get a 404.
If we have no books, asking for the first book will fail with a 404.
The chapter in the URL used to go right on the page.  It's no longer possible to use a non-integer chapter.
The page in the URL used to go right on the page.  It's no longer possible to use a non-integer page.
The page in the URL used to go right on the page.  It's no longer possible to use a non-integer page and a non-integer chapter.
If we have no books, asking for the first book will fail with a 404.
The chapter in the URL used to go right on the page.  It's no longer possible to use a non-integer chapter.
then remap all the chapter URLs as well, if they are provided.
define custom states used by InstructorTask
create the task_id here, and pass it into celery:
create the task, then save it:
In future, there should be a check here that the resulting JSON  will fit in the column.  In the meantime, just return an exception.
truncate any traceback that goes into the InstructorTask model:
Just setting the content encoding and type above should work  according to the docs, but when experimenting, this was necessary for  it to actually take.
exclude states that are "ready" (i.e. not "running", e.g. failure, success, revoked):
Create log entry now, so that future requests will know it's running.
Assume we don't always save the InstructorTask entry if we don't have to,  but that in most cases we will update the InstructorTask in-place with its  current progress.
construct a status message directly from the task result's result:  it needs to go back with the entry passed in.
on revocation, the result's result doesn't contain anything  but we cannot rely on the worker thread to set this status,  so we set it here.
save progress and state into the entry, even if it's not being saved:  when celery is run in "ALWAYS_EAGER" mode, progress needs to go back  with the entry passed in.
if the task is not already known to be done, then we need to query  the underlying task's result object:
create the key value by using MD5 hash:
create the key value by using MD5 hash:
check to see if task is already running, and reserve it otherwise:
return status for completed tasks and tasks in progress
special message for providing progress updates:  Translators: {action} is a past-tense verb that is localized separately. {attempted} and {succeeded} are counts.
Translators: {action} is a past-tense verb that is localized separately. {succeeded} and {attempted} are counts.
Translators: {action} is a past-tense verb that is localized separately. {succeeded} and {attempted} are counts.
provide a default:  Translators: {action} is a past-tense verb that is localized separately. {succeeded} and {attempted} are counts.
Translators: {skipped} is a count.  This message is appended to task progress status messages.
Translators: {total} is a count.  This message is appended to task progress status messages.
Update status in task result object itself:
-*- coding: utf-8 -*-
exclude states that are "ready" (i.e. not "running", e.g. failure, success, revoked):
check arguments:  let exceptions return up to the caller.
check arguments:  let exceptions return up to the caller.
check to see if task is already running, and reserve it otherwise
check problems for rescoring:  let exceptions return up to the caller.
check to see if task is already running, and reserve it otherwise
check arguments:  make sure that the usage_key is defined  (since that's currently typed in).  If the corresponding module descriptor doesn't exist,  an exception will be raised.  Let it pass up to the caller.
check arguments:  make sure entrance exam(section) exists for given usage_key
check arguments:  make sure that the usage_key is defined  (since that's currently typed in).  If the corresponding module descriptor doesn't exist,  an exception will be raised.  Let it pass up to the caller.
check arguments:  make sure entrance exam(section) exists for given usage_key
Remove Content milestones that user has completed
Assume that the course is defined, and that the user has already been verified to have  appropriate access to the course. But make sure that the email exists.  We also pull out the targets argument here, so that is displayed in  the InstructorTask status.
create the key value by using MD5 hash:
define different loggers for use within tasks and on client side
define value to use when no task_id is provided:  define values for update functions to use to return status to perform_module_state_update
The setting name used for events when "settings" (account settings, preferences, profile information) change.
if the InstructorTask object does not exist, then there's no point  trying to update it.
Get the InstructorTask to be updated. If this fails then let the exception return to Celery.  There's no point in catching it here.
Get inputs to use in this task from the entry
Now do the work
Release any queries that the connection has been hanging onto
Log and exit, returning task_progress info as task result
if problem_url is present make a usage key from it
find the problem descriptor:
if entrance_exam is present grab all problems in it
find the modules in question
get request-related tracking information from args passthrough, and supplement with task-specific  information:
reconstitute the problem's corresponding XModule:
get request-related tracking information from args passthrough, and supplement with task-specific  information:
This module isn't being used for front-end rendering  pass in a loaded course for override enabling
unpack the StudentModule:
Either permissions just changed, or someone is trying to be clever  and load something they shouldn't have access to.
This should also not happen, since it should be already checked in the caller,  but check here to be sure.
get request-related tracking information from args passthrough,  and supplement with task-specific information:
Use the data dict and html template to generate the output buffer
Loop over all our students and build our CSV lists in memory
Periodically update task status (this is a cache write)
An empty gradeset means we failed to grade a student.
Perform the actual upload
If there are any error rows (don't count the header), write them out as well
One last update before we close out...
First, sort out all the blocks into their correct assignments and all the  assignments into their correct types.  Put the assignments in order into the assignments list.
Compute result table and format it
Perform the upload
This struct encapsulates both the display names of each static item in the  header row as values as well as the django User field names of those items  as the keys.  It is structured in this way to keep the values related.
There was an error grading this student.  Generally there will be a non-empty err_msg, but that is not always the case.
compute the student features table and format it
Perform the upload
Periodically update task status (this is a cache write)
translate header into a localizable display string
Perform the actual upload
One last update before we close out...
Compute result table and format it
Perform the upload
get the course executive summary report information.
Perform the upload
Compute result table and format it
Perform the upload
Generate Certificates for all white listed students.
Whitelist students who did not get certificates already.
We want to skip 'filtering students' only when students are given and statuses to regenerate are not
Mark existing generated certificates as 'unavailable' before regenerating  We need to call this method after "students_require_certificate" otherwise "students_require_certificate"  would return no results.
Generate certificate for each student
Iterate through rows to get total assignments for task progress
cohorts_status is a mapping from cohort_name to metadata about  that cohort.  The metadata will include information about users  successfully added to the cohort, users not found, and a cached  reference to the corresponding cohort object to prevent  redundant cohort queries.
Try to use the 'email' field to identify the user.  If it's not present, use 'username'.
Raised when the user is already in the given cohort
Return Students that have Generated Certificates and the generated certificate status  lies in 'statuses_to_regenerate'  Fetch results otherwise subsequent operations on table cause wrong data fetch
compute those students whose certificates are already generated
Return all the enrolled student skipping the ones whose certificates have already been generated
Mark generated certificates as 'unavailable' and update download_url, download_uui, verify_uuid and  grade with empty string for each row
check status returned:
set up test user for performing test operations
get descriptor:
update the data in the problem definition  confirm that simply rendering the problem again does not result in a change  in the grade:
redefine the problem (as stored in Mongo) so that the definition of correct changes  confirm that simply rendering the problem again does not result in a change  in the grade (or the attempts):
rescore the problem for all students
all grades should change to being wrong (with no change in attempts)
student A will get 100%, student B will get 50% because  OPTION_1 is the correct option, and OPTION_2 is the  incorrect option
test resubmitting, by updating the existing record:
Validate that record was added to CertificateGenerationHistory
Validate that record was added to CertificateGenerationHistory
view task entry for task failure
Add a chapter to the course
add a sequence to the course to which the problems can be added
Expand the dict reader generator so we don't lose it's content
get status for a task that is still running:
check for missing task_output
Check number of items for each subtask
Check number of items for each subtask
check that entries were set correctly  run the task  check that entries were reset
check that entries were set correctly  run the task  check that entries were reset
In auto cohorting a group will be assigned to a user only when user visits a problem  In grading calculation we only add a group in csv if group is already assigned to  user rather than creating a group automatically at runtime
Create course with group configurations
Assign user_a to a group in the 'cohort'-schemed user  partition (by way of a cohort) to verify that the user  partition group does not show up in the "Experiment Group"  cell.
check button text
check button text
check button text
Expand the dict reader generator so we don't lose it's content
Add a sequence to the course to which the problems can be added
Create a vertical
Verify generated grades and expected grades match
Course is cohorted
Verify user enrollment
Verify generated grades and expected grades match
check button text
apply the coupon code to the item in the cart
This assertion simply confirms that the generation completed with no errors
This assertion simply confirms that the generation completed with no errors
create 10 students
mark 2 students to have certificates generated already
white-list 5 students
whitelist 3
generate certs for 2
the first 3 students (who were whitelisted) have passing  certificate statuses
The last 2 students still don't have certs
create 5 students
mark 2 students to have certificates generated already
white-list 4 students
the first 4 students have passing certificate statuses since  they either were whitelisted or had one before
The last student still doesn't have a cert
create 10 students
mark 2 students to have certificates generated already
mark 3 students to have certificates generated with status 'error'
mark 6th students to have certificates generated with status 'deleted'
white-list 7 students
Certificates should be regenerated for students having generated certificates with status  'downloadable' or 'error' which are total of 5 students in this test case
Default grade for students
create 10 students
mark 2 students to have certificates generated already
mark 3 students to have certificates generated with status 'error'
mark 6th students to have certificates generated with status 'deleted'
white-list 7 students
Regenerated certificates for students having generated certificates with status  'deleted' or 'generating'
grades will be '0.0' as students are either white-listed or ending in error  grades will be '-1' for students that were skipped
Default grade for students
create 10 students
mark 2 students to have certificates generated already
mark 3 students to have certificates generated with status 'error'
mark 2 students to have generated certificates with status 'unavailable'
mark 3 students to have generated certificates with status 'generating'
white-list all students
Regenerated certificates for students having generated certificates with status  'downloadable', 'error' or 'generating'
Verify from results from database  Certificates are being generated for 8 students that had statuses in 'downloadable', 'error' and 'generating'  2 students are skipped that had Certificate Status 'unavailable'
grades will be '0.0' as students are white-listed and have not completed any tasks  grades will be '-1' for students that have not been processed
Verify that students with status 'unavailable were skipped
create 10 students
mark 2 students to have certificates generated already
mark 3 students to have certificates generated with status 'error'
mark 6th students to have certificates generated with status 'deleted'
mark 7th students to have certificates generated with status 'norpassing'
white-list 7 students
Certificates should be regenerated for students having generated certificates with status  'downloadable' or 'error' which are total of 5 students in this test case
Number of times to retry if a subtask update encounters a lock on the InstructorTask.  (These are recursive retries, so don't make this number too large.)
yield remainder items for task, if any
and save the entry immediately, before any subtasks actually start work:
Calculate the number of tasks that will be created, and create a list of ids for each task.
Construct a generator that will return the recipients to use for each subtask.  Pass in the desired fields to fetch for each recipient.
Return the task progress as stored in the InstructorTask object.
According to Celery task cookbook, "Memcache delete is very slow, but we have  to use it to take advantage of using add() for atomic locking."
Update status:
Translators: This is a past-tense verb that is inserted into task progress messages as {action}.
Translators: This is a past-tense verb that is inserted into task progress messages as {action}.
Translators: This is a past-tense verb that is inserted into task progress messages as {action}.
Translators: This is a past-tense verb that is inserted into task progress messages as {action}.
Translators: This is a past-tense verb that is inserted into task progress messages as {action}.
Translators: This is a past-tense verb that is inserted into task progress messages as {action}.
Translators: This is a past-tense verb that is inserted into task progress messages as {action}.
Translators: This is a past-tense verb that is inserted into task progress messages as {action}.
Translators: This is a past-tense verb that is inserted into task progress messages as {action}.
Translators: This is a past-tense verb that is inserted into task progress messages as {action}.
Translators: This is a past-tense verb that is inserted into task progress messages as {action}.  An example of such a message is: "Progress: {action} {succeeded} of {attempted} so far"
Patching the ENABLE_DISCUSSION_SERVICE value affects the contents of urls.py,  so we need to call super.setUp() which reloads urls.py (because  of the UrlResetMixin)
create a course
Patch the comment client user save method so it does not try  to create a new cc user when creating a django user
Create the student
Enroll the student in the course
Log the student in
Mock the code that makes the HTTP requests to the cs_comment_service app  for the profiled user's active threads
Mock the code that makes the HTTP request to the cs_comment_service app  that gets the current user's info
Mock the code that makes the HTTP requests to the cs_comment_service app  for the profiled user's active threads
Mock the code that makes the HTTP request to the cs_comment_service app  that gets the current user's info
comments service adds these attributes when course_id param is present
strip_none is being used to perform the same transform that the  django view performs prior to writing thread data to the response
strip_none is being used to perform the same transform that the  django view performs prior to writing thread data to the response
Test uncached first, then cached now that the cache is warm.
Verify that the group name is correctly included in the HTML
Beta user does not have access to alpha_module.
If a thread returns context other than "course", the access check is not done, and the beta user  can see the alpha discussion module.
avoid causing a server error when the LMS chokes attempting  to find a group name for the group_id, when we're testing with  an invalid one.
Should never have a group_id if course_id was not included in the request.
In all these test cases, the requesting_user is the student (non-privileged user).  The profile returned on behalf of the student is for the profiled_user.
If the group_id is explicitly passed, it will be present in the request.
If the group_id is not explicitly passed, it will not be present because the requesting_user  has discussion moderator privileges.
pylint: disable=super-method-not-called
pylint: disable=super-method-not-called
pylint: disable=super-method-not-called
pylint: disable=super-method-not-called
pylint: disable=super-method-not-called
pylint: disable=super-method-not-called
If provided with a discussion id, filter by discussion id in the  comments_service.  Use the discussion id/commentable id to determine the context we are going to pass through to the backend.
If the user clicked a sort key, update their default sort key
patch for backward compatibility to comments service
print "start rendering.."
Verify that the student has access to this thread if belongs to a course discussion module
patch for backward compatibility with comments service
'content': content,
seed the forums permissions and roles
Patch the comment client user save method so it does not try  to create a new cc user when creating a django user
Enroll the student in the course
Enroll the moderator and give them the appropriate roles
seed the forums permissions and roles
Patching the ENABLE_DISCUSSION_SERVICE value affects the contents of urls.py,  so we need to call super.setUp() which reloads urls.py (because  of the UrlResetMixin)
Patch the comment client user save method so it does not try  to create a new cc user when creating a django user
Enroll the student in the course
Enroll the moderator and give them the appropriate roles
Add the student to the team so they can post to the commentable.
create_thread_helper verifies that extra data are passed through to the comments service
pylint: disable=super-method-not-called
pylint: disable=super-method-not-called
pylint: disable=super-method-not-called
pylint: disable=super-method-not-called
pylint: disable=super-method-not-called
pylint: disable=super-method-not-called
Create a team.
Dummy commentable ID not linked to a team
thread_author is who is marked as the author of the thread being updated.
pylint: disable=super-method-not-called
pylint: disable=super-method-not-called
unenroll self.student from the course.
There is a stated desire for an 'origin' property that will state  whether this thread was created via courseware or the forum.  However, the view does not contain that data, and including it will  likely require changes elsewhere.
Check for whether this commentable belongs to a team, and add the right context
Cohort the thread if required
patch for backward compatibility to comments service
course didn't exist, or requesting user does not have access to it.
400 is default status for JsonError
N.B. This will trigger a comments service query
We do not expect KeyError in production-- it usually indicates an improper test mock.
-*- coding: utf-8 -*-
Create a discussion module.
Assert that created discussion module is not an orphan.
Assert that there is only one discussion module in the course at the moment.
Assert that the discussion module is an orphan.
This test needs to use a course that has already started --  discussion topics only show up if the course has already started,  and the default start date for courses is Jan 1, 2030.
Courses get a default discussion topic on creation, so remove it
unlikely case, but make sure it works.
empty / default config
explicitly disabled cohorting
explicitly enabled cohorting
no topics
not cohorted
cohorted, but top level topics aren't
cohorted, including "Feedback" top-level topics aren't
Verify that team discussions are not cohorted, but other discussions are
This is a test of the test setup,  so it does not need to run as part of the unit test suite  You can re-enable it by commenting out the line below
Create the server
Start the server in a separate daemon thread
Send the request to the mock cs server
Receive the reply from the mock cs server
You should have received the response specified in the setup above
Retrieve the POST data into a dict.  It should have been sent in json format
Log the request  pylint: disable=logging-format-interpolation
Every good post has at least an API key  Log the response
Send a response back to the client
Respond with failure
Retrieve the PUT data into a dict.  It should have been sent in json format
Log the request  pylint: disable=logging-format-interpolation
Every good post has at least an API key  Log the response
Send a response back to the client
Respond with failure
First call superclass shutdown()
We also need to manually close the socket
Despite being from 2 different courses, TA_role_2 can still inherit  permissions from TA_role without error
get_role_ids returns a dictionary of only admin, moderator and community TAs.
Find the earliest start date for the entries in this category
If we've already seen this title, append an incrementing number to disambiguate  the category from other categores sharing the same title in the course discussion UI.
django-debug-toolbar monkeypatches the connection  cursor wrapper and adds extra information in each  item in connection.queries. The query time is stored  under the key "duration" rather than "time" and is  in milliseconds, not seconds.
Augment the specified thread info to include the group name if a group id is present.
Remove any cohort information that might remain if the course had previously been cohorted.
regular users always query with their own id.
Never pass a group_id to the comments service for a non-cohorted  commentable
this is the easy case :)
top level discussions have to be manually configured as cohorted  (default is not).  Same thing for inline discussions if the default is explicitly set to False in settings
inline discussions are cohorted by default
Tell Django to clean out all databases, not just default
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
This is a hack to force sqlite to add new rows after the earlier rows we  want to migrate.
Pg's bigserial is implicitly unsigned (doesn't allow negative numbers) and  goes 1-9.2x10^18
Import here instead of top of file since this module gets imported before  the course_modes app is loaded, resulting in a Django deprecation warning.
Only returns eligible certificates. This should be used in  preference to the default `objects` manager in most cases.
Normal object manager, which should only be used when ineligible  certificates (i.e. new audit certs) should be included in the  results. Django requires us to explicitly declare this.
Translators: This is a past-tense verb that is used for task action messages.
if task input is empty, it means certificates were generated for all learners  Translators: This string represents task was executed for all learners.
Import here instead of top of file since this module gets imported before  the course_modes app is loaded, resulting in a Django deprecation warning.
Short term fix to make sure old audit users with certs still see their certs  only do this if there if no honor mode
Import here instead of top of file since this module gets imported before  the course_modes app is loaded, resulting in a Django deprecation warning.
Statuses
Dummy full name for the generated certificate
Certificates HTML view end point to render web certs by user and course
Certificates HTML view end point to render web certs by certificate_uuid
this is here to support registering the signals in signals.py
anonymous user
set the expiration date in the past
prefetch all chapters/sequentials by saying depth=2
Add the certificate request to the queue
Add the certificate request to the queue
all states we have seen far all courses
print the heading for the report
Re-submit certificates for *all* courses
Re-submit certificates for particular courses
Retrieve the IDs of generated certificates with  error status in the set of courses we're considering.
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
NOTE: the download URL is not currently being set for webview certificates.  In the future, we can update this to construct a URL to the webview certificate  for courses that have this feature enabled.
If the feature is disabled, then immediately return a False
Return the flag on the course object
fetch organization of the course
get Terms of Service and Honor Code page url
get Privacy Policy page url
get About page url
The caller can optionally pass a course in to avoid  re-fetching it from Mongo. If they have not provided one,  get it from the modulestore.
Needed for access control in grading.
For credit mode generate verified certificate
honor code and audit students
Log if the student is whitelisted
Check to see whether the student is on the the embargoed  country restricted list. If so, they should not receive a  certificate -- set their status to restricted and log it.
Finally, generate the certificate and send it off.
We send this extra parameter to differentiate  example certificates from other certificates.  This is not used by the certificates workers or XQueue.
The callback for example certificates is different than the callback  for other certificates.  Although both tasks use the same queue,  we can distinguish whether the certificate was an example cert based  on which end-point XQueue uses once the task completes.
Check the POST parameters, returning a 400 response if they're not valid.
Attempt to regenerate certificates
Check the POST parameters, returning a 400 response if they're not valid.
Check that the course exists
Attempt to generate certificate
pylint: disable=wildcard-import
Populate dynamic output values using the course/certificate data loaded above
Translators:  This text is bound to the HTML 'title' element of the page and appears in the browser title bar
Update the view context with the default ConfigurationModel settings
Translators:  'All rights reserved' is a legal term used in copyrighting to protect published content
Translators:  This text is bound to the HTML 'title' element of the page and appears  in the browser title bar when a requested certificate is not found or recognized
Translators: The &amp; characters represent an ampersand character and can be ignored
Translators: A 'Privacy Policy' is a legal document/statement describing a website's use of personal information
Translators: This line appears as a byline to a header image and describes the purpose of the page
Translators: Accomplishments describe the awards/certifications obtained by students on this platform
Translators:  This line appears on the page just before the generation date for the certificate
Translators:  The Certificate ID Number is an alphanumeric value unique to each individual certificate
Translators:  This text describes (at a high level) the mission and charter the edX platform and organization
Translators:  This text appears near the top of the certficate and describes the guarantee provided by edX
Translators:  This text represents the description of course
Translators: This line is displayed to a user who has completed a course and achieved a certification
Translators: This line leads the reader to understand more about the certificate that a student has been awarded
certificate is being viewed by learner or public
Badge Request Event Tracking Logic
Create the initial view context, bootstrapping with Django settings and passed-in values
Kick the user back to the "Invalid" screen if the feature is disabled
Load the course and user objects
Append/Override the existing view context values with any mode-specific ConfigurationModel values
Append organization info
Append course info
Append user info
Append social sharing info
Append/Override the existing view context values with certificate specific values
Append badge info
Append microsite overrides
Add certificate header/footer data to current context
Append/Override the existing view context values with any course-specific static values from Advanced Settings
Track certificate view events
FINALLY, render appropriate certificate
Check the parameters and rate limits  If these are invalid, return an error response.
Let the XQueue know that we handled the response
Verify that the certificate has status 'downloadable'
Since model-based configuration is cached, we need  to clear the cache before each test.
Enable the feature
Enable for the course
Disable for the course
Enable the feature
Enable for one course
Should be disabled for another course
Generate certificates for the course
Verify that the appropriate certs were added to the queue
Verify that the certificate status is "started"
Create verified and honor modes for the course
Generate certificates for the course
Verify that the appropriate certs were added to the queue
Generate certificates for the course
Generate certificates for the course
Make sure there are not unexpected keys in dict returned by 'get_certificate_footer_context'
ABOUT is present in MICROSITE_CONFIGURATION['test_microsite']["urls"] so web certificate will use that url
PRIVACY is present in MICROSITE_CONFIGURATION['test_microsite']["urls"] so web certificate will use that url
TOS_AND_HONOR is present in MICROSITE_CONFIGURATION['test_microsite']["urls"],  so web certificate will use that url
set pre-requisite course  get milestones collected by user before completing the pre-requisite course
Enroll as audit  Whitelist student
Verify that the task was sent to the queue with the correct callback URL
Ensure the certificate was not generated
Verify that the correct payload was sent to the XQueue
Verify the certificate status
Verify the error status of the certificate
Factories are self documenting  pylint: disable=missing-docstring
Since rate limit counts are cached, we need to clear  this before each test.
Exceed the rate limit for invalid requests  (simulate a DDOS with invalid keys)
The final status code should indicate that the rate  limit was exceeded.
Override with the command module you wish to test.
Enroll the user in the course
Create the certificate
Create a certificate with status 'error'
Re-submit all certificates with status 'error'
Expect that the certificate was re-submitted
Create a certificate with status 'error'  in three courses.
Re-submit certificates for two of the courses
Create certificates with an error status and some other status
Re-submit certificates for all courses
Only the certificate with status "error" should have been re-submitted
Verify that we make only one Mongo query  because the course is cached.
Expect that the certificate was NOT resubmitted  since the course doesn't actually exist.
Create the support staff user
Create a student
Create certificates for the student
Login as support staff
Assign the user to the role
Retrieve the page
Assign the user to the role
Make a POST request  Since we're not passing valid parameters, we'll get an error response  but at least we'll know we have access
Check that the user's certificate was updated  Since the student hasn't actually passed the course,  we'd expect that the certificate status will be "notpassing"
Missing username
Missing course key
Unenroll the user
Can no longer regenerate certificates for the user
Delete the user's certificate
Should be able to regenerate
A new certificate is created
Assign the user to the role
Make a POST request  Since we're not passing valid parameters, we'll get an error response  but at least we'll know we have access
Missing username
Missing course key
Unenroll the user
Can no longer regenerate certificates for the user
Delete the user's certificate
Should be able to generate
A new certificate is created
pylint: disable=invalid-name
Delete any existing statuses
Verify that the "latest" status is None
Now save asset with same file again, New file will be uploaded after deleting the old one with the same name.
Now replace the asset with another file
Validate certificate
Convert the cert to audit, with the specified eligibility
Validate certificate
make sure response html has only one organization logo container for edX
accessing certificate web view in preview mode without  staff or instructor access should show invalid certificate
Verify that Exception is raised when certificate is not in the preview mode
Enable the feature
pylint: disable=missing-docstring,invalid-name,maybe-no-member,attribute-defined-outside-init
Use mongo so that we can get a test with a SlashSeparatedCourseKey
Return the response so child classes do not have to repeat the request.
HTTP 401 should be returned if the user is not authenticated.
Access should be granted if the proper access token is supplied.
Access should be denied if the user is not course staff.
Data should be returned if the user is authorized.
Ensure course structure exists for the course
Course structure generation shouldn't take long. Generate the data and try again.
Ensure only course descriptors are returned.
Ensure only courses accessible by the user are returned.
Sort the results in a predictable manner.
If we don't have data stored, we will try to regenerate it, so  return a 503 and as them to retry in 2 minutes.
Determine the URL to redirect to following login/registration/third_party_auth
If we're already logged in, redirect to the dashboard
Retrieve the form descriptions from the user API
Allow external auth to intercept and handle the request
Prefer logged-in user's email
Increment the rate limit counter
As a reliable way of "skipping" the registration form, we just submit it automatically
Check for any error messages we may want to display:  msg may or may not be translated. Try translating [again] in case we are able to:
Since the user API is currently run in-process,  we simulate the server-server API call by constructing  our own request object.  We don't need to include much  information in the request except for the session  (to get past through CSRF validation)
Call the Django view function, simulating  the server-server API call
Return the content of the response
If the account on the third party provider is already connected with another edX account,  we display a message to the user.
Long email -- subtract the length of the @domain  except for one character (so we exceed the max length limit)
Create/activate a new account
Login
Request a password change while logged in, simulating  use of the password reset link from the account page
Check that an email was sent
Visit the activation link
Log the user out to clear session data
Verify that the new password can be used to log in
Verify that the old password cannot be used to log in
Verify that the new password continues to be valid
Log the user out
Log out the user created during test setup
Create a second user, but do not activate it
Send the view the email address tied to the inactive user
Expect that the activation email is still sent,  since the user may have lost the original activation email.
Log out the user created during test setup
Send the view an email address not tied to any user
Log out the user created during test setup, to prevent the view from  selecting the logged-in user's email address over the email provided  in the POST data
Make many consecutive bad requests in an attempt to trigger the rate limiter
Verify that we're redirected to the dashboard
The response should have a "Sign In" button with the URL  that preserves the querystring params
Verify that this parameter is also preserved
Do NOT simulate a running pipeline
For these tests, two third party auth providers are enabled by default:
Patch Milestones feature flag
create chapter
create vertical
create problem
create orphan
Setup gating milestones data
In case the transaction actually was not committed before the celery task runs,  run it again after 5 minutes. If the first completed successfully, this task will be a no-op.
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
Test when no configuration exists
Enable for a course
Disable for the course
Spy on number of calls to celery task.
Enable cohorting and create a verified cohort.  But do not enable the verified track cohorting feature.  No logging occurs if feature is disabled for course.
Enable cohorting and create a verified cohort.  Enable verified track cohorting feature
Enable cohorting, and create the verified cohort.  Create two random cohorts.  Enable verified track cohorting feature
Un-enroll from the course. The learner stays in the verified cohort, but is no longer active.
Change the name of the "default" cohort.
Note that this will enroll the user in the default cohort on initial enrollment.  That's good because it will force creation of the default cohort if necessary.
if not empty, this field contains a json serialized list of  the master course modules
avoid circular import problems
avoid circular import problems
avoid circular import problems
pylint: disable=protected-access
pylint: disable=protected-access
if user is staff or instructor then he can view ccx coach dashboard.
At this point we are done with verification that current user is ccx coach.
if ccx connector url is set in course settings then inform user that he can  only create ccx by using ccx connector url.
Make sure start/due are overridden for entire course
Enforce a static limit for the maximum amount of students that can be enrolled
Enroll the coach in the course
In case of section aka chapter we do not have due date.
in case the children are visible to staff only, skip them
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
prevent migration for deprecated course ids or invalid ids.
prevent migration for deprecated course ids or invalid ids.
the ccx detail view cannot call this function with a "None" value  so the following `error_code` should be never used, but putting it  to avoid a `NameError` exception in case this function will be used  elsewhere in the future
checking first if all the fields are present and they are not null
case if the user actually passed null as input
validating the rest of the input
prepare the course_modules to be stored in a json stringified field
Make sure start/due are overridden for entire course
Enforce a static limit for the maximum amount of students that can be enrolled
make the coach user a coach on the master course
get the master course key and master course object
Add the current page to the response.
This field can be derived from other fields in the response,  so it may make sense to have the JavaScript client calculate it  instead of including it in the response.
adding instructor to master course.
create a staff user  add staff role to the staff user
create an instructor user  add instructor role to the instructor user
create an coach user  add coach role to the coach user
there are no CCX courses
add sort order desc  the only thing I can check is that the display name is in alphabetically reversed order  in the same way when the field has been updated above, so with the id asc
check if the response has at least the same data of the request
check that only one email has been sent and it is to to the coach
create a staff user  add staff role to the staff user
create an instructor user  add instructor role to the instructor user
create an coach user  add coach role to the coach user
If ccx is not enable do not show ccx coach tab.
if user is staff or instructor then he can always see ccx coach tab.  check if user has coach access.
Create instructor account
One outer SAVEPOINT/RELEASE SAVEPOINT pair around everything caused by the  transaction.atomic decorator wrapping override_field_for_ccx.  One SELECT and one INSERT.  One inner SAVEPOINT/RELEASE SAVEPOINT pair around the INSERT caused by the  transaction.atomic down in Django's get_or_create()/_create_object_from_params().
One outer SAVEPOINT/RELEASE SAVEPOINT pair around everything caused by the  transaction.atomic decorator wrapping override_field_for_ccx.  One SELECT and one INSERT.  One inner SAVEPOINT/RELEASE SAVEPOINT pair around the INSERT caused by the  transaction.atomic down in Django's get_or_create()/_create_object_from_params().
I think Django already does this for you in their TestClient, except  we're bypassing that by using edxmako.  Probably edxmako should be  integrated better with Django's rendering and event system.
Login with the instructor account
adding staff to master course.
adding instructor to master course.
Get the ccx_key
check if the max amount of student that can be enrolled has been overridden
assert ccx creator has role=ccx_coach
assert that staff and instructors of master course has staff and instructor roles on ccx
we were redirected to our current location
a CcxMembership exists for this student
create ccx and limit the maximum amount of students that can be enrolled to 2
create some users
we were redirected to our current location
a CcxMembership does not exists for this student
we were redirected to our current location
some error messages are returned for one of the views only
Trying to wrap the whole thing in a bulk operation fails because it  doesn't find the parents. But we can at least wrap this part...
Create instructor account  create an instance of modulestore
Login with the instructor account
adding staff to master course.
adding instructor to master course.
Create instructor account
Create CCX
Are the grades downloaded as an attachment?
Create a CCX coach.
Create a CCX course and enroll the user in it.
build a fake key
Create instructor account
create an instance of modulestore
adding staff to master course.
adding instructor to master course.
assert that staff and instructors of master course has staff and instructor roles on ccx
adding instructor to master course.
adding instructor to master course.
adding instructor to master course.
assert that role of staff and instructors of master course removed from ccx.
Run again
Tell Django to clean out all databases, not just default
TEST_DATA must be overridden by subclasses
Switch to published-only mode to simulate the LMS  Clear all caches before measuring
Refill the metadata inheritance cache
We clear the request cache to simulate a new request in the LMS.
Reset the list of provider classes, so that our django settings changes  can actually take affect.
Trying to wrap the whole thing in a bulk operation fails because it  doesn't find the parents. But we can at least wrap this part...
Create instructor account  create an instance of modulestore
Setting override date [start or due]
Setting date from master course
Set parent date (vertical has same dates as subsections)
XXX: In the future, it would be nice to support more than one ccx per  coach per course.  This is a place where that might happen.
this call should be idempotent  Enroll the staff in the ccx
allow 'staff' access on ccx to staff of master course
this call should be idempotent  Enroll the instructor in the ccx
allow 'instructor' access on ccx to instructor of master course
revoke 'staff' access on ccx.
Unenroll the staff on ccx.
revoke 'instructor' access on ccx.
Unenroll the instructor on ccx.
-*- coding: utf-8 -*-
is_active is `None` if the user is not enrolled in the course
Calling UserPreference directly instead of get_user_preference because the user requesting the  information is not "user" and also may not have is_staff access.
for now, White Labels use 'shoppingcart' which is based on the  "honor" course_mode. Given the change to use "audit" as the default  course_mode in Open edX, we need to be backwards compatible with  how White Labels approach enrollment modes.
Since no User object exists for this student there is no "full_name" available.
load the state json  old_number_of_attempts = problem_state["attempts"]
save
add some helpers and microconfig subsitutions
see if we are running in a microsite and that there is an  activation email template definition available as configuration, if so, then render that
Remove leading and trailing whitespace from body
Email subject *must not* contain newlines
extended user profile fields are stored in the user_profile meta column
get the registration_code_redemption object if exists  get the paid_course registration item if exists
this happens when the registration code is not created via invoice or bulk purchase  scenario.
amount greater than 0 is invoice has bee paid  amount less than 0 is invoice has been refunded
proctored exam downloads...
Financial Report downloads..
Coupon Codes..
spoc gradebook
Cohort management
Certificates
Grade book: max students per page
calculate offsets for next and previous pages.
calculate current page number.
calculate total number of pages.
We are at first page, so there's no previous page.
We've reached the last page, so there's no next page.
Apply limit on queryset only if total number of students are greater then MAX_STUDENTS_PER_PAGE_GRADE_BOOK.
Checked above
Pass along email as an object with the information we desire
Get progress status message & success information
for white labels we use 'shopping cart' which uses CourseMode.DEFAULT_SHOPPINGCART_MODE_SLUG as  course mode for creating course enrollments.
Iterate each student in the uploaded csv file.
Email address already exists. assume it is the correct user  and just register the user in the course and send an enrollment email.
This email does not yet exist, so we need to create a new account  If username already exists in the database, then create_and_enroll_user  will raise an IntegrityError exception.
Create a new user
Enroll user to the course and add manual enrollment audit trail
First try to get a user object from the identifer
Flag this email as an error if invalid, but continue checking  the remaining in the list
catch and log any exceptions  so that one error doesn't cause a 500.
If no exception thrown, see if we should send an email  See if we should autoenroll the student  Check if student is already enrolled
Tabulate the action result of this email address
Check that user is active, because add_users  in common/djangoapps/student/roles.py fails  silently when we try to add an inactive user.
Are we dealing with an "old-style" problem location?
Allow for microsites to be able to define additional columns (e.g. )
Translators: 'Cohort' refers to a group of students within a course.
The task will assume the default file storage.
check if the generated code is in the Coupon Table
covert the course registration code number into integer
composes registration codes invoice email
append the finance email into the recipient_list
find all the registration codes in this course
parameter combinations
instructor authorization
Trust the submissions API to log the error
instructor authorization
Specifying for the history of a single task type
First get tasks list of bulk emails sent
Specifying for a single student's history on this problem
Specifying for single problem's history
If no problem or student, just get currently running tasks
Specifying for a single student's entrance exam history
Specifying for all student's entrance exam history
default roles require either (staff & forum admin) or (instructor)
EXCEPT FORUM_ROLE_ADMINISTRATOR requires (instructor)
filter out unsupported for roles
Create the CourseEmail object.  This is saved immediately, so that  any transaction that has been pending up to this point will also be  committed.
Submit the task, so that the correct InstructorTask object gets created (for monitoring purposes)
default roles require either (staff & forum admin) or (instructor)
EXCEPT FORUM_ROLE_ADMINISTRATOR requires (instructor)
It's possible the normal due date was deleted after an extension was granted:
Validate request data and return error response in case of invalid data
Certificate has not been generated yet, so just remove the certificate exception from white list
Generate Certificates for all white listed students
Invalid data, generate_for must be present for all certificate exceptions
verify that we have exactly two column in every row either email or username and notes but allow for  blank lines
Validate request data and return error response in case of invalid data
Re-Validate student certificate for the course course
Fetch CertificateInvalidation object
Deactivate certificate invalidation if it was fetched successfully.
We need to generate certificate only for a single student here
Temporarily show the "Analytics" section until we have a better way of linking to Insights
Gate access to course email by feature flag & by course-specific authorization
Gate access to Metrics tab by featue flag and staff authorization
Gate access to Ecommerce tab
Certificates panel  This is used to generate example certificates  and enable self-generated certificates for a course.
remove the redemption entry from the database.
Check that the new due date is valid:
We are deleting a due date extension. Check that it exists:
Create a course with mode 'audit'
Create a course with mode 'honor' and with price
test the log for email that's send to new created user.
test the log for email that's send to new created user.
test the log for email that's send to new created user.
Login Audit Course instructor
Verify enrollment modes to be 'audit'
Remove white label course price
Login Audit Course instructor
Verify enrollment modes to be 'honor'
Login white label course instructor
Verify enrollment modes to be CourseMode.DEFAULT_SHOPPINGCART_MODE_SLUG
Create invited, but not registered, user
test that the user is now enrolled
Check the outbox
test that the user is now enrolled
test that the user is now unenrolled
Check the outbox
test that the user is now unenrolled
Try with marketing site enabled and shib on
make this enrollment "verified"
now re-enroll the student through the instructor dash
upgrade enrollment
test the response data
Check the outbox
Check the outbox
Works around a caching bug which supposedly can't happen in prod. The instance here is not ==  the instance fetched from the email above which had its cache cleared
Check the outbox
Works around a caching bug which supposedly can't happen in prod. The instance here is not ==  the instance fetched from the email above which had its cache cleared
Seed forum roles for course.
Status code should be 200.
check button text
Now invalidate the same invoice number and expect an Bad request
now re_validate the invoice number
Now re_validate the same active invoice number and expect an Bad request
add the coupon code for the course
Coupon Redeem Count only visible for Financial Admins.
apply the coupon code to the item in the cart
now make the payment of your cart items  visit the instructor dashboard page and  check that the coupon redeem count should be 1
create a new user/student and enroll  in the course using a registration code  and then validates the generated detailed enrollment report
make sure problem attempts have been reset.
make sure the module has been deleted  module_id=self.module_to_reset.module_id,
Add instructor to invalid ee course
make sure problem attempts have been reset.
make sure the module has been deleted
check response
post again with same student
This time response message should be different
This should be given the value of 'unknown' if the task output  can't be properly parsed
Emails list should have one email
Email content should be what's expected
Emails list should be empty
firstly generating downloadable certificates with 'honor' mode
firstly generating downloadable certificates with 'honor' mode
Now generating downloadable certificates with 'verified' mode
total certificate count should be 2 for 'verified' mode.
retrieve the second certificate from the list
firstly generating downloadable certificates with 'honor' mode
Spent(used) Registration Codes
check for the last mail.outbox, The FINANCE_EMAIL has been appended at the  very end, when generating registration codes
get user invoice copy preference.
get user invoice copy preference.
Spent(used) Registration Codes
now check that the registration code should be marked as invalid in the db.
now the student course enrollment should be false.
now the student course enrollment should be false.
now check that the registration code should be marked as valid in the db.
Student is unknown, so the platform language should be used
Coupons should show up for White Label sites with priced honor modes.
removing the course finance_admin role of login user
Total amount html should render in e-commerce page, total amount will be 0
removing the course finance_admin role of login user
Course A updated total amount should be visible in e-commerce page if the user is finance admin
Value Error course price should be a numeric value
validation check passes and course price is successfully added
Get the response value, ensure the Coupon section is not included.  Coupons should show up for White Label sites with priced honor modes.
parent of the BaseEnrollmentReportProvider is EnrollmentReportProvider
Create instructor account
The course is Mongo-backed but the flag is disabled (should not work)  Assert that the URL for the email view is not in the response
Authorize the course to use email
Assert that instructor email is enabled for this course  Assert that the URL for the email view is in the response
Flag is disabled, but course is authorized  Authorize the course to use email
URL for instructor dash  URL for email view
Create instructor account
URL for instructor dash  URL for email view
enrollment objects
initialize & check before
do action
check after
Create a student module for the user
Delete student state using the instructor dash
Verify that the student's scores have been reset in the submissions API
For a CCX, what do we expect to get for the URLs?  Also make sure `auto_enroll` is properly passed through.
For a normal site, what do we expect to get for the URLs?  Also make sure `auto_enroll` is properly passed through.
For a site with a marketing front end, what do we expect to get for the URLs?  Also make sure `auto_enroll` is properly passed through.
Create instructor account
I think Django already does this for you in their TestClient, except  we're bypassing that by using edxmako.  Probably edxmako should be  integrated better with Django's rendering and event system.
Create instructor account
URL for instructor dash
no enrollment information should be visible
dashboard link hidden
Check that the number of professional enrollments is two
link to dashboard shown
link to dashboard shown
Create instructor account
prepare course structure
Create a course with the desired grading policy (from our class attribute)
Default >= 50% passes, so Users 5-10 should be passing for Homework 1 [6]  One use at the top of the page [1]
Users 1-5 attempted Homework 1 (and get Fs) [4]  Users 1-10 attempted any homework (and get Fs) [10]  Users 4-10 scored enough to not get rounded to 0 for the class (and get Fs) [7]  One use at top of the page [1]
All other grades are None [29 categories * 11 users - 27 non-empty grades = 292]  One use at the top of the page [1]
Users 9-10 have >= 90% on Homeworks [2]  Users 9-10 have >= 90% on the class [2]  One use at the top of the page [1]
User 8 has 80 <= Homeworks < 90 [1]  User 8 has 80 <= class < 90 [1]  One use at the top of the page [1]
User 7 has 70 <= Homeworks < 80 [1]  User 7 has 70 <= class < 80 [1]  One use at the top of the page [1]
User 6 has 60 <= Homeworks < 70 [1]  User 6 has 60 <= class < 70 [1]  One use at the top of the page [1]
Users 1-5 have 60% > grades > 0 on Homeworks [5]  Users 1-5 have 60% > grades > 0 on the class [5]  One use at top of the page [1]
User 0 has 0 on Homeworks [1]  User 0 has 0 on the class [1]  One use at the top of the page [1]
Need to clear the cache for model-based configuration
Enable the certificate generation feature
Instructors don't see the certificates section
Global staff can see the certificates section
Disable the feature flag
Now even global staff can't see the certificates section
Initially, no example certs are generated, so  the enable button should be disabled
Certs are disabled for the course, so the enable button should be shown
Enable certificates for the course
Now the "disable" button should be shown
When certs are disabled for a course, then don't allow them  to be enabled if certificate generation doesn't complete successfully
However, if certificates are already enabled, allow them  to be disabled even if an error has occurred
Enable certificate generation
Instructors do not have access
Global staff have access
Expect a redirect back to the instructor dashboard
Expect that certificate generation started  Cert generation will fail here because XQueue isn't configured,  but the status should at least not be None.
Expect a redirect back to the instructor dashboard
Expect that certificate generation is now enabled for the course
Create a generated Certificate of some user with status 'downloadable'
Assert 200 status code in response
Assert request is successful
Create a dummy course and GeneratedCertificate with the same status as the one we will use to access  'start_certificate_regeneration' but their error message should be displayed as GeneratedCertificate  belongs to a different course
Assert 400 status code in response
Assert Error Message
Assert 400 status code in response
Assert Error Message
Enable certificate generation
Assert successful request processing
Assert Certificate Exception Updated data
Assert 400 status code in response
Assert Request not successful
Assert Error Message
Assert 400 status code in response
Assert Request not successful
Assert 400 status code in response
Assert Request not successful
Assert Error Message
Assert Certificate Exception Updated data
add certificate exception for same user in a different course
Assert Certificate Exception Updated data
Assert 400 status code in response
Assert Request not successful
Assert Error Message
Assert successful request processing
Try to delete certificate exception without passing valid data  Assert error on request
Assert error on request
Enable certificate generation
Assert Success
Assert Request is successful  Assert Message
Assert Success
Assert Request is successful  Assert Message
Assert Failure
Assert Request is not successful  Assert Message
Global staff can see the certificates section
Global staff can see the certificates section
Assert successful request processing
Verify that CertificateInvalidation record has been created in the database i.e. no DoesNotExist error
Validate generated certificate was invalidated
Assert 400 status code in response
Assert 400 status code in response
Assert Error Message
Assert 400 status code in response
Assert 400 status code in response
Invalidate user certificate
Assert 400 status code in response
Invalidate user certificate
Assert 400 status code in response
Invalidate user certificate
Assert 204 status code in response
Verify that certificate invalidation successfully removed from database
Invalidate user certificate
Assert 400 status code in response
Assert Error Message
make sure the attempt is there
make sure the module has been deleted
Store the role
Clear existing courses to avoid conflicts
Create a new course
Log in as the an instructor or staff for the course  Make & register an instructor for the course
Make & register a staff member
Go to the data download section of the instructor dash
Click generate grade report button
Go to the data download section of the instructor dash
Go to the data download section of the instructor dash
Go to the data download section of the instructor dash
Find the grading configuration display
Wait for the data table to be populated
pylint: disable=no-member
module not enabled in the course
setting not enabled and the module is not enabled
module is enabled and the setting is not enabled
Mocks
Make sure no note with this ID ever exists for testing purposes
-*- coding: utf-8 -*-
Cap the number of notes that can be returned in one request
Wrapper class for HTTP response and data. All API actions are expected to return this.
Verify that the api should be accessible to this course
Locate the requested resource
not doing a strict boolean check on data becuase it could be an empty list
validate search parameters
set filters
Users have different sets of enrollments
The number of queries is one for the users plus one for each prefetch  in NotifierUsersViewSet (roles__permissions does one for each table).
See NotifierUserSerializer for notes about related tables
now coerce username to utf-8 encoded str, since we test with non-ascii unicdoe above and  the unittest framework has hard time coercing to unicode.  decrypt also can't take a unicode input, so coerce its input to str
Token not long enough to contain initialization vector
Token length not a multiple of AES block length
Invalid padding (ends in 0 byte)  Encrypted value: "testuser" + "\x00" * 8
Invalid padding (ends in byte > 16)  Encrypted value: "testusertestuser"
Invalid padding (entire string is padding)  Encrypted value: "\x10" * 16
Nonexistent user  Encrypted value: "nonexistentuser\x01"
start without a pref key
Calling UserPreference directly because this method is called from a couple of places,  and it is not clear that user is always the user initiating the request.
Compensate for the fact that some threads in the comments service do  not have the pinned field set
for multiple fields in a list
Avoid revealing the identity of an anonymous non-staff question  author who has endorsed a comment in the thread
Django Rest Framework v3 no longer includes None values  in the representation.  To maintain the previous behavior,  we do this manually instead.
params are validated at a higher level, so the only possible request  error is if the thread doesn't exist
The comments service returns the last page of results if the requested  page is beyond the last page, but we want be consistent with DRF's general  behavior and return a PageNotFoundError in that case
if a thread is closed; no new comments could be made to it
Shared fields
Test page past the last one
N.B. The mismatch between the number of children and the listed total  number of responses is unrealistic but convenient for this test
Only page
First page of many
Middle page of many
Last page of many
Page past the end
Matches paths like 'programs/123/' and 'programs/123/foo/', but not 'programs/123/foo/bar/'.
mock programs and credentials apis
mock programs and credentials apis
The user is selecting what he/she wants to purchase.
The user has been sent to the external payment processor.  At this point, the order should NOT be modified.  If the user returns to the payment flow, he/she will start a new order.
The user has successfully purchased the items in the order.
The user's order has been refunded.
The user's order went through, but the order was erroneously left  in 'cart'.
The user's order went through, but the order was erroneously left  in 'paying'.
maps order statuses to their defunct states
we need a tuple to represent the primary key of various OrderItem subclasses
a JSON dump of the CC processor response, for completeness
check to see if the cart has at least some item in it
if the caller is explicitly asking to check for particular types
remove any redemption entry associated with the item
Only the business order is HTML formatted. A single seat order confirmation is plain text.
save these changes on the order, then we can tell when we are in an  inconsistent state  this should return all of the objects with the correct types of the  subclasses
Generate the CSV file that contains all of the RegistrationCodes that have already been  generated when the purchase has transacted
Catch all exceptions here, since the Django view implicitly  wraps this in a transaction.  If the order completes successfully,  we don't want to roll back just because we couldn't send  the confirmation email.
Capturing all exceptions thrown while tracking analytics events. We do not want  an operation to fail because of an analytics event, so we will capture these  errors in the logs.
if an order is already retired, no-op:
general purpose field, not user-visible.  Used for reporting
This field has been deprecated.  The total amount can now be calculated as the sum  of each invoice item associated with the invoice.  For backwards compatibility, this field is maintained  and written to during invoice creation.
This field has been deprecated in order to support  invoices for items that are not course-related.  Although this field is still maintained for backwards  compatibility, you should use CourseRegistrationCodeInvoiceItem  to look up the course ID for purchased redeem codes.
A payment/refund is in process, but money has not yet been transferred
A payment/refund has completed successfully  This should be set ONLY once money has been successfully exchanged.
A payment/refund was promised, but was cancelled before  money had been transferred.  An example would be  cancelling a refund check before the recipient has  a chance to deposit it.
JSON-serialized representation of the current state  of the invoice, including its line items and  transactions (payments/refunds).
For backwards compatibility, we maintain the FK to "invoice"  In the future, we will remove this in favor of the FK  to "invoice_item" (which can be used to look up the invoice).
theoretically there could be more than one (e.g. someone self-unenrolls  then re-enrolls with a different regcode)  return the first one. In all normal use cases of registration codes  the user will only have one
user could have specified a mode that's not set, in that case return the DEFAULT_MODE
enroll in course and link to the enrollment_id
user could have specified a mode that's not set, in that case return the DEFAULT_SHOPPINGCART_MODE
we need to import here because of a circular dependency  we should ultimately refactor code to have save_registration_code in this models.py  file, but there's also a shared dependency on a random string generator which  is in another PR (for another feature)
pylint: disable=no-member
pylint: disable=no-member
Only refund verified cert unenrollments that are within bounds of the expiration date
Need this to be unicode in case the reminder strings  have been translated and contain non-ASCII unicode
Types of donations
The type of donation
If a donation is made for a specific course, then store the course ID here.  If the donation is made to the organization as a whole,  set this field to CourseKeyField.Empty
This will validate the currency but won't actually add the item to the order.
Create a line item description, including the name of the course  if this is a per-course donation.  This will raise an exception if the course can't be found.
The donation is for the organization as a whole, not a specific course
user is logged in and  do we have the feature turned on  does the user actually have a cart (optimized query to prevent creation of a cart when not needed)  user's cart has PaidCourseRegistrations or CourseRegCodeItem
Draw Order/Invoice No.
Draw Date
Amount header
Amount column (header + data items)
Quantity, List Price, Discount header
Description header
Quantity data items
Innergrid around the data rows.
The entire Table won't fit in the available space and requires splitting.  Draw the part that can fit, start a new page  and repeat the process with the rest of the table.
Table will fit without the need for splitting.
only print TaxID if we are generating an Invoice
if space left on page is smaller than the rendered height, render the table on the next page.
Billing Address Header styling
Billing Address Body styling
Disclaimer Body styling
TERMS AND CONDITIONS body styling
tick the rate limiter counter
Restrict the user from enrolling based on country access rules
Restrict the user from enrolling based on country access rules
remove the course from the cart if it was added there.
Any amount is okay as long as it's greater than 0  Since we've already quantized the amount to 0.01  and rounded down, we can check if it's less than 0.01
Add the donation to the user's cart
Course ID may be None if this is a donation to the entire organization
Start the purchase.  This will "lock" the purchase so the user can't change  the amount after we send the information to the payment processor.  If the user tries to make another donation, it will be added  to a new cart.
Construct the response params (JSON-encoded)
Add extra to make it easier to track transactions
The HTTP end-point for the payment processor.
Parameters the client should send to the payment processor
See if the order contained any certificate items  If so, the user is coming from the payment/verification flow.
Add a query string param for the order ID  This allows the view to query for the receipt information later.
Otherwise, send the user to the receipt page
We want to have the ability to override the default receipt page when  there is only one item in the order.
Error case: there was a badly formatted user-input date string
set up test carts
SUCCESS CASE first, rest are some sort of oddity
Moved reading of charged_amount here from the valid_params loop above because  only 'ACCEPT' messages have a 'ccAuthReply_amount' parameter
see if we have an override in the microsites
fallthrough case, which basically never happens
Import the processor implementation, using `CC_PROCESSOR_NAME`  as the name of the Python module in `shoppingcart.processors`
Translators: this text appears when an unfamiliar error code occurs during payment,  for which we don't know a user-friendly message to display in advance.
if we have the order and the id, log it
First see if the user cancelled the transaction  if so, then not all parameters will be passed back so we can't yet verify signatures
if the user decline the transaction  if so, then auth_amount will not be passed back so we can't yet verify signatures
CyberSource allows us to send additional data in "merchant defined data" fields
Retrieve the configuration settings for the active credit card processor
Check whether we're in a microsite that overrides our configuration  If so, find the microsite-specific configuration in the 'microsites'  sub-key of the normal processor configuration.
if the above verify_signature fails it will throw an exception, so basically we're just  testing for the absence of that exception.  the trivial assert below does that
if the above verify_signature fails it will throw an exception, so basically we're just  testing for the absence of that exception.  the trivial assert below does that
test base case
tests for missing key
tests for keys with value that can't be converted to proper type
tests for an order number that doesn't match up
tests for a reply amount of the wrong type
tests for a reply amount of the wrong type
tests for a not accepted order
finally, tests an accepted order
Check the callback URL override
Parameters determined by the Django (test) settings
Some fields will change depending on when the test runs,  so we just check that they're set to a non-empty string
Check the signature
We patch the purchased callback because  we're using the OrderItem base class, which throws an exception  when item doest not have a course id associated
We patch the purchased callback because  (a) we're using the OrderItem base class, which doesn't implement this method, and  (b) we want to verify that the method gets called on success.
Simulate a callback from CyberSource indicating that payment was successful
Expect that the item's purchased callback was invoked
Expect that the order has been marked as purchased
Simulate a callback from CyberSource indicating that the payment was rejected
Expect that we get an error message
Simulate a callback from CyberSource indicating that the payment was rejected
Expect that we get an error message
Use an invalid order ID
Expect an error
Change the payment amount (no longer matches the database order record)
Change the payment amount to a non-decimal
Expect an error
Change the payment amount to a non-decimal
Expect an error
Use a credit card number with no digits provided
Expect that the order has placeholders for the missing credit card digits
Remove a required parameter
Recalculate the signature with no signed fields so we can get past  signature validation.
Expect an error
Verify that this executes without a unicode error
if decision is in FAILED_DECISIONS list then remove  auth_amount from  signed_field_names list.
Parameters that change based on the test
Calculate the signature
Simulate a callback from CyberSource indicating that the payment was declined
Expect that we get an error message
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
Fifth Order with course not attributed to any microsite but with a Donation
also add a donation not associated with a course to make sure the None case works OK
User 1 & 2 will be verified
User 6 is honor
check that we have the right number
Using excel mode csv, which automatically ends lines with \r\n, so need to convert to \n
since there's not many purchases, just run through the generator to make sure we've got the right number
Using excel mode csv, which automatically ends lines with \r\n, so need to convert to \n
delete the matching annotation
Saving another testing course mode
And for the XSS course
And the verified course
page not found error because order_type is not business
check for the default currency in the context
check for the override currency settings in the context
unit price should be updated for that course
after getting 10 percent discount
unit price should be updated for that course
unit price should be updated for that course
check button text
Ensure the course has a verified mode
check button text
Once upgraded, should be "verified"
Delete the discounted item, corresponding coupon redemption should  be removed for that particular discounted item
Delete the discounted item, corresponding coupon redemption should be removed for that particular discounted item
check for the default currency in the context
check for the override currency settings in the context
Should have gotten a successful response
One courses in user shopping cart
Should have gotten a successful response
Parse the response as JSON and check the contents
Total amount of a particular course that is purchased by different users
One courses in user shopping cart
check button text
check button text
make sure the enrollment_ids were stored in the PaidCourseRegistration items  refetch them first since they are updated  item1 has been deleted from the the cart.   User has been enrolled for the item1
check for the default currency settings in the context
check for the override currency settings in the context
mail is sent to these emails recipient_email, company_contact_email, order.user.email
fetch the newly generated registration codes
now redeem one of registration code from the previous order
now view the receipt page again to see if any registration codes  has been expired or not
now check for all the registration codes in the receipt  and one of code should be used at this point
add verified mode
Purchase a verified certificate
setting the attempting upgrade session value.
Create other carts first  This ensures that the order ID and order item IDs do not match
Purchase a verified certificate
update the testing_course enrollment dates
update the testing_course enrollment dates
update the testing_course enrollment dates
then the rate limiter should kick in and give a HttpForbidden response
now reset the time to 5 mins from now in future in order to unblock
then the rate limiter should kick in and give a HttpForbidden response
now reset the time to 5 mins from now in future in order to unblock
Registration Code Generation only available to Sales Admins.
get the first registration from the newly created registration codes
check button text
Create a valid registration code
The registration code should NOT be redeemed
The user should NOT be enrolled
Enable donations
Donate to our course
Verify the receipt page
Logged in -- should be a 404
Logged out -- should still be a 404
Purchase a single donation item  Optionally specify a particular course for the donation
Use the fake payment implementation to simulate the parameters  we would receive from the payment processor.
Use the response parameters to simulate a successful payment
PDF_RECEIPT_TERMS_AND_CONDITIONS not displayed in the receipt pdf
Reset the view state
Generate shoppingcart signatures
Simulate a POST request from the payment workflow  page to the fake payment page.
Expect that the response was successful
Expect that we were served the payment page  (not the error page)
Generate shoppingcart signatures
Tamper with the signature
Simulate a POST request from the payment workflow  page to the fake payment page.
Expect that we got an error
Generate shoppingcart signatures
Get the POST params that the view would send back to us
Check that the client accepts these
Generate shoppingcart signatures
Configure the view to declined payments
Check that the decision is "DECLINE"
Configure the view to fail payments
Check that the decision is "REJECT"
Configure the view to accept payments
Check that the decision is "ACCEPT"
Add mock tracker for event testing.
If we retrieve the cart for the user, we should get a different order
purchase the cart more than once
Simulate an error when sending the confirmation  email.  This should NOT raise an exception.  If it does, then the implicit view-level  transaction could cause a roll-back, effectively  reversing order fulfillment.
Verify that the purchase completed successfully
Verify that the user is enrolled as "verified"
check that the registration codes are generated against the order
If the expiration date has not yet passed on a verified mode, the user can be refunded
If there's an error sending an email to billing, we need to log this error
If the expiration date has passed, the user cannot get a refund
If there is no paid certificate, the refund callback should return nothing
No course ID provided, so this is a donation to the entire organization
Create a test course
Pay for a donation
Verify that the donation is in the cart
Purchase the item
Verify that the donation is marked as purchased
Delete the transactions
We use the same hashing function as the software under test,  because it mainly uses standard libraries, and I want  to avoid duplicating that code.
We store the payment status to respond with in a class  variable.  In a multi-process Django app, this wouldn't work,  since processes don't share memory.  Since Lettuce  runs one Django server process, this works for acceptance testing.
Configure all views to respond with the new status
Retrieve the list of signed fields
Calculate the public signature
Indicate whether the payment was successful
Add the list of signed fields
Calculate the public signature
URL to send the POST request to
POST params embedded in the HTML success form
POST params embedded in the HTML decline form
Create a PDF parser object associated with the file object.  Create a PDF document object that stores the document structure.  Supply the password for initialization.
receive the LTPage object for this page  layout is an LTPage object which may contain   child objects like LTTextBox, LTFigure, LTImage, etc.
text
We have to escape ';', because that is our  escape sequence identifier (otherwise, the escaping)  couldn't distinguish between us adding ';_' to the string  and ';_' appearing naturally in the string
Be sure this is really a handler.  We're checking the .__class__ instead of the block itself to avoid  auto-proxying from Descriptor -> Module, in case descriptors want  to ask for handler URLs without a student context.
Is the following necessary? ProxyAttribute causes an UndefinedContext error  if trying this without the module system.     raise ValueError("{!r} is not a handler name".format(handler_name))
If suffix is an empty string, remove the trailing '/'
If there is a query string, append it
If third-party, return fully-qualified url
test for when we haven't set the tag yet
Try to set tag in wrong scope
Try to get tag in wrong scope
Make sure that we don't repeatedly nest LmsFieldData instances
-*- coding: utf-8 -*-
Please do not remove, this is a workaround for Django 1.8.  more information can be found here: https://openedx.atlassian.net/browse/PLAT-902
Translators: "TOC" stands for "Table of Contents"
special case - means somewhere up the hierarchy, merged access rules have eliminated  all group_ids from this partition, so there's no possible intersection.  otherwise, if the parent defines group access rules for this partition,  intersect with the local ones.
add the group access rules for this partition to the merged set of rules.
Specified here so we can see what the value set at the course-level is.
Skip the validation check if the partition has been disabled
When called in the context of a microsite, return an empty result if the org  passed by the caller does not match the designated microsite org.
We only make it to this point if one of org or microsite_org is defined.  If both org and microsite_org were defined, the code would have fallen into the  first branch of the conditional above, wherein an equality check is performed.
When called in the context of a microsite, filtering can stop here.
See if we have filtered course listings in this domain
Filter out any courses belonging to a microsite, to avoid leaking these.
keep specialized logic for Edge until we can migrate over Edge to fully use  microsite definitions
we do not expect this case to be reached in cases where   marketing and edge are enabled
we do not expect this case to be reached in cases where   marketing is enabled or the courses are not browsable
Use the content type to decide what representation to serve
Show the OpenEdX logo in the footer
Include JS and CSS dependencies  This is useful for testing the end-point directly.
Override the language if necessary
-*- coding: utf-8 -*-
Translators: 'EdX', 'edX', and 'Open edX' are trademarks of 'edX Inc.'.  Please do not translate any of these trademarks and company names.
Translators: 'Open edX' is a brand, please keep this untranslated.  See http://openedx.org for more information.
In production, the static files URL will be an absolute  URL pointing to a CDN.  If this happens, we can just  return the URL.
For local development, the returned URL will be relative,  so we need to make it absolute.
If a microsite URL override exists, return it.  Otherwise return the marketing URL.
get marketing link, if marketing is disabled then platform url will be used instead.
if the MicrositeConfiguration has a value for the logo_image_url  let's use that
otherwise, use the legacy means to configure this
check to see that the default setting is to ALLOW iframing
check to see that the override value is honored
HTTP Host changed to edge.
Response should be instance of HttpResponseRedirect.  Location should be "/login".
make sure both courses are visible in the catalog
assert that the course discovery UI is not present
check the /courses view
assert that the course discovery UI is not present
make sure we have the special css class on the section
assert that the course discovery UI is not present
check the /courses view
check the /courses view
check the /courses view as well
Logo
Copyright
Load the footer with the specified language
Verify that the translation occurred
OpenEdX
EdX.org
OpenEdX
EdX.org
OpenEdX
EdX.org
url ends with "/"
url doesn't have "/" at the end
url with path that starts with "/"
url with path without "/"
url is not configured
if api url is None then constructed url should also be None  constructed url should startswith notes view url instead of api view url
constructed url should not contain extra params
constructed url should only has these params if present in api url
extract query params from constructed url
verify that constructed url has only correct params and params have correct values
disable course.edxnotes
reenable course.edxnotes
OAuth2 Client name for edxnotes
pylint: disable=method-hidden
Add a course run if necessary.
course is a locator w/o branch and version  so for uniformity we replace it with one that has them
Relying on default of returning first child
Open and parse the configuration file when the module is initialized
'course_id' is a deprecated field, please use 'id' instead.
Note: This makes a call to the modulestore, unlike the other  fields from CourseSerializer, which get their data  from the CourseOverview object in SQL.
AnonymousUser has no username, so we test for requesting_user's own  username before prohibiting an empty target_username.
This endpoint requires the usage_key for the starting block.
This endpoint is an alternative to the above, but requires course_id as a parameter.
convert the requested course_key to the course's root block's usage_key
add default requested_fields
Add additional requested_fields that are specified as separate  parameters, if they were requested.
Verify that access to all blocks is requested  (and not unintentionally requested).
return None for user
Verify user exists.
create ordered list of transformers, adding BlocksAPITransformer at end.
transform
serialize
return serialized data
collect basic xblock fields
collect basic xblock fields
add self to parent's descendants
This section is an exam.  It should be excluded unless the  user is not a verified student or has declined taking the exam.
'student_view_data'  'student_view_multi_device'
set the block_field_name to None so the entire data for the transformer is serialized
Provide the staff visibility info stored when VisibilityTransformer ran previously
collect basic xblock fields
collect basic xblock fields
collect data from containing transformers
collect phase
transform phase
collect phase
transform phase
pylint: disable=protected-access
collect phase
transform phase
verify count of chapters
verify count of problems
verify other block types are not counted
Build course.
Enroll user in course.
add requested fields
add higher order fields
verify the requested_fields in cleaned_data includes all fields
create a user, enrolled in the toy course
video blocks should have student_view_data
html blocks should have student_view_multi_device set to True
Create a staff user to be able to test visible_to_staff_only
verify root
verify blocks
Create a second course to be filtered out of queries.
Create a second course to be filtered out of queries.
Create a second course to be filtered out of queries.
No filtering.
With filtering.
Create a second course to be filtered out of queries.
'course_id' is a deprecated field, please use 'id' instead.
1 mongo call is made to get the course About overview text.
update the expected_data to include the 'overview' data.
Patch the xml libs
Disable PyContract contract checking when running as a webserver
Trigger a forced initialization of our modulestores since this can take a  while to complete and we want this done before HTTP requests are accepted.
This application object is used by the development server  as well as any WSGI server configured to use this file.
The next page is the dashboard; make sure it loads
These are the parameters that would be included if the user  were trying to enroll in a course.
Wait for the form to change before returning
Submit it
Submit it
Click the password reset link on the login page
Wait for the password reset form to load
Fill in the form
Submit it
Now also verify that focus has moved to this title (for screen readers):
Frontend will automatically switch to Search results tab when search  is running, so the view also needs to be changed.
Find the index of the section in the chapter
Retrieve the scores for the section
CSS indices are 1-indexed, so add one to the list index
The section titles also contain "n of m possible points" on the second line  We have to remove this to find the right title
Some links are blank, so remove them
CSS indices are 1-indexed, so add one to the list index
This is CSS selector means:  Get the scores for the chapter at `chapter_index` and the section at `section_index`  Example text of the retrieved elements: "0/1"
Convert text scores to tuples of (points, max_points)
Filter elements by course name, only returning the relevant course item
Filter elements by course name, only returning the relevant course item
There should only be one course listing corresponding to the provided course name.
Click the upgrade button
Get the link hrefs for all courses
Search for the first link that matches the course id
The only identifier for individual tabs is the link href  so we find the tab with `tab_name` in its text.
Use the private version of _is_on_tab to skip the page check
Get the URL of the instance under test
The URL used for user auth in testing
Check that the next_step_button is enabled before returning control to the caller
Out of the possible poll answers, we want  to select the one that matches POLL_ANSWER and click it.
The first time cohort management is selected, an ajax call is made.
Get rid of the last 4 elements: 'acceptance', 'pages', 'lms', and 'instructor_dashboard.py'  to point to the 'test' folder, a shared point in the path's tree.
Append the folders in the asset's path
Return the joined path of the required asset.
The page may be in either the traditional management state, or an 'add new cohort' state.  Confirm the CSS class is visible because the CSS class can exist on the page even in different states.
Both the edit and create forms have an element with id="cohort-name". Verify that the create form  has been rendered.
Manual assignment type will be selected by default for a new cohort  if we are not setting the assignment type explicitly
Expect the confirmation message substring. (The full message will differ depending on 1 or >1 students added)
Fill the email addresses after the email selector is visible.
Verify enrollment button is present before clicking
This will be present if exam is proctored  This will be present if exam is timed
The next page is the dashboard; make sure it loads
Check the first contribution option, then click the enroll button
Fill the ccx_name.
Verify create ccx button is present before clicking.
Overridden by subclasses to provide the relative path within the course  Paths should not include the leading forward slash.
pylint: disable=attribute-defined-outside-init
Make sure that the transcript button is there
toggle captions visibility state if needed
Verify that captions state is toggled/changed
Make sure that the captions are visible
Click triggers an ajax event
If we are going to click pause button, Ensure that player is not in buffering state
Width of the video container in css equal 75% of window if transcript enabled
Wait for browser to resize completely  Currently there is no other way to wait instead of explicit wait
Wait for browser to resize completely  Currently there is no other way to wait instead of explicit wait
Restore initial window size
check if we have a transcript with correct format
mouse over to transcript button
Sometimes language is not clicked correctly. So, if the current language code  differs form the expected, we try to change it again.
Make sure that all ajax requests that affects the display of captions are finished.  For example, request to get new translation etc.
For troubleshooting purposes show what the current state is.  The debug statements will only be displayed in the event of a failure.
The full time has the form "0:32 / 3:14" elapsed/duration
Dict to store the result
Get the section titles for each chapter
Add one to convert list index (starts at 0) to CSS index (starts at 1)
For test stability, disable JQuery animations (opening / closing menus)
Get the section by index
Click the section to ensure it's open (no harm in clicking twice if it's already open)  Add one to convert from list index to CSS index
Convert list indices (start at zero) to CSS indices (start at 1)
Click the subsection and ensure that the page finishes reloading
Get the index of the item in the sequence
Click on the sequence item at the correct index  Convert the list index (starts at 0) to a CSS index (starts at 1)  Click triggers an ajax event
Retrieve the subsection title for the section  Add one to the list index to get the CSS index, which starts at one
Regular expression to remove HTML span tags from a string
The modal is on the page at large, and not a subelement of the badge div.
This will eventually hold the details about the user account
Create query string parameters if provided
Get the URL of the instance under test
The URL used for user auth in testing
The footer element itself is non-generic, so check above it
Only make the call to size once (instead of once for the height and once for the width)  because otherwise you will trigger a extra query on a remote element.
Disable all animations for faster testing with more reliable synchronization  Click on the element in the browser
Some buttons trigger ajax posts  (e.g. .add-missing-groups-button as configured in split_test_author_view.js)  so after you click anything wait for the ajax call to finish
First make sure that an element with the view-container class is present on the page,  and then wait to make sure that the xblock has finished initializing.
Wait for the xblock javascript to finish initializing
Set content in the CodeMirror editor.
If the pdf upload section has not yet been toggled on, click on the upload pdf button
Clicking on the course will trigger an ajax event
Helpers
Look for the license text that will be displayed by default,  if no button is yet explicitly selected
Get rid of the last 4 elements: 'acceptance', 'pages', 'lms', and 'instructor_dashboard.py'  to point to the 'test' folder, a shared point in the path's tree.
Append the folders in the asset's path
Return the joined path of the required asset.
wait for upload button
wait for popup
upload image
wait for popup closed
Get the URL of the instance under test
This is a page section and can not be accessed directly
This is a page section and can not be accessed directly
Should grab common point between this page module and the data folder.
Click on the save button.
There are prefixes like 'Tools' and '>', but the text itself is not in a span.
pylint: disable=no-member
Should grab common point between this page module and the data folder.
Makes no sense to include this if the tasks haven't run.
CourseOutlineItem is also used as a mixin for CourseOutlinePage, which doesn't have a locator  Check for the existence of a locator so that errors when navigating to the course outline page don't show up  as errors in the repr method instead.
pylint: disable=no-member
pylint: disable=no-member
pylint: disable=no-member
pylint: disable=no-member
Now remove any non-direct descendants.
The None radio button
The Timed exam radio button
The Proctored exam radio button
The Practice exam radio button
The Prerequisite checkbox is visible
The Prerequisite checkbox is checked
The Prerequisites dropdown is visible
The Prerequisites dropdown is visible
Clicking on course with run will trigger an ajax event
Clear the current value, set the new one, then  Tab to move to the next field (so change event is triggered).
Ensure that we make it to another page
Sometimes get stale reference if I hold on to the array of elements
Switch to browser window that shows HTML Unit in LMS  The last handle represents the latest windows opened
Click the delete button  Click the confirmation dialog button
Wait until all xblocks rendered.
Now remove any non-direct descendants.
Overridden by subclasses to provide the relative path within the course  Does not need to include the leading forward or trailing slash
Click on the Advanced icon.
Make sure that the menu of advanced components is visible before clicking (the HTML is always on the  page, but will have display none until the large-advanced-icon is clicked).
Now click on the component to add it.
Adding some components, e.g. the Discussion component, will make an ajax call  but we should be OK because the click_css method is written to handle that.
"Common Problem Types" are shown by default.  For advanced problem types you must first select the "Advanced" tab.
Click on the HTML icon.
Make sure that the menu of HTML components is visible before clicking
Now click on the component to add it.
Adding some components will make an ajax call but we should be OK because  the click_css method is written to handle that.
Click in the input to give it the focus  Select all, then input the value  Return the input_element for chaining
Labels used to identify the fields on the edit modal:
And wait to make sure the ajax post has finished.
basic
We should wait 300 ms for event handler invocation + 200ms for safety.
Create video
Create query string parameters if provided
Pip 1.5 will try to install this package from outside  the directory containing setup.py, so we need to use an absolute path.
Install a course with sections/problems, tabs, updates, and handouts
Logout previously logged in user to be able to see Login page.
Get the URL of the Studio instance under test
Get the URL of the LMS instance under test
Get the URL of the XQueue stub used in the test
Get the URL of the Ora stub used in the test
Get the URL of the comments service stub used in the test
Get the URL of the EdxNotes service stub used in the test
Get the URL of the Programs service stub used in the test
Use auto-auth to retrieve the session for a logged in user
Info about the auto-auth user used to create the course/library.
Use auto-auth to retrieve the session for a logged in user
Create the new XBlock
Configure the XBlock
Create the new XBlock
Description of course updates to add to the course  `date` is a str (e.g. "January 29, 2014)  `content` is also a str (e.g. "Test course")
Set a default start date to the past, but use Studio's  default for the end date (meaning we don't set it here)
If the course already exists, this will respond  with a 200 and an error message, which we ignore.
This will occur if the course identifier is not unique
First, get the current values
Update the old details with our overrides
POST the updated details to Studio
Update the course's handouts HTML
POST advanced settings to Studio
Configure the stub to respond to submissions to our queue
Disable publishing for library XBlocks:
The discussion code assumes that user_id is a string. This ensures that it always will be.
go to the membership page on the instructor dashboard
create course with single cohort and two content groups (user_partition of type "cohort")
go to the membership page on the instructor dashboard
click on the inline save button.
verifies that changes saved successfully.
save button disabled again.
enable always inline discussion topics.
enable some inline discussion topic radio button.  I see that save button is enabled  I see that inline discussion topics are enabled
select some inline discussion topics radio button.
check the discussion topic.
Save button enabled.
verifies that changes saved successfully.
enable some inline discussion topics.
category should not be selected.
check the discussion topic.
verify that category is selected.
enable some inline discussion topics.
category should not be selected.
check the discussion topic.
verify that category is selected.
un-check the discussion topic.
category should not be selected.
enable some inline discussion topics.
category should not be selected.
verifies that changes saved successfully.
verify changes after reload.
go to the membership page on the instructor dashboard
Disable cohorts and verify that the post now shows as visible to everyone.
pylint: disable=unused-argument
Actual test method(s) defined in CohortedDiscussionTestMixin.
Actual test method(s) defined in NonCohortedDiscussionTestMixin.
Actual test method(s) defined in CohortedDiscussionTestMixin.
Actual test method(s) defined in NonCohortedDiscussionTestMixin.
verify threads are rendered on the page
From the thread_page_1 open & verify next thread
Verify that the focus is changed
Check if 'thread-wrapper' is focused after expanding thread
click all the way up through each page
click all the way back down
Create a course to register for.
Create a student who will be in "Cohort A"
Create a student who will be in "Cohort B"
Create a student who will end up in the default cohort group
Start logged in as the staff user.
After adding the cohort, it should automatically be selected
create test file in which index for this test will live
create a unit in course outline
Do the search again, this time we expect results from courses A & B, but not C
Some state is constructed by the parent setUp() routine
Load page objects for use by the tests
Navigate to the index page and get testing!
Useful to capture the current datetime for our tests
Ensure the introduction video element is not shown
Sadly, this sleep is necessary in order to ensure that  sorting by last_activity_at works correctly when running  in Jenkins.
We are doing these operations on this top-level page object to avoid reloading the page.
Get the base URL (the URL without any trailing fragment)
pylint: disable=no-member
Verify the new team was added to the topic list
Verify that if one switches to "My Team" without reloading the page, the newly created team is shown.
Verify that if one switches to "My Team" without reloading the page, the newly joined team is shown.
Verify that if one switches to "My Team" without reloading the page, the old team no longer shows.
Login as staff
Make the first subsection a prerequisite
Login as staff
Gate the second subsection based on the score achieved in the first subsection
Install a course with library content xblock
Missing problem type test
Some parameters are provided by the parent setUp() routine, such as the following:  self.course_id, self.course_info, self.unique_id
Load page objects for use by the tests
Navigate the authenticated, enrolled user to the dashboard page and get testing!
now datetime for usage in tests
reload the page for changes to course date changes to appear in dashboard
Test that proper course date with 'ended' message is displayed if a course has already ended
reload the page for changes to course date changes to appear in dashboard
Test that proper course date with 'started' message is displayed if a course is in running state
reload the page for changes to course date changes to appear in dashboard
Test that proper course date with 'starts' message is displayed if a course is about to start in future,  and course does not start within 5 days
reload the page for changes to course date changes to appear in dashboard
Test that proper course date with 'starts' message is displayed if a course is about to start in future,  and course starts within 5 days
create test file in which index for this test will live
Install a course with a hierarchy and problems
Auto-auth register for the course.
The hint button rotates through multiple hints
Rotate the hint and check the problem hint
Assert that new ccx is created and we are on ccx dashboard/enrollment tab.
Ensure that the superclass sets up
This redirects to an invalid URI.
Enter a submission, which will trigger a pre-defined response from the XQueue stub.
Configure the XQueue stub's response for the text we will submit
Wait 5 seconds for xqueue stub server grader response sent back to lms.
Install a course with sections/problems, tabs, updates, and handouts
Auto-auth register for the course.  Do this as global staff so that you will see the Staff View
After adding the cohort, it should automatically be selected
Masquerade as student in alpha cohort:
Masquerade as student in beta cohort:
pylint: disable=attribute-defined-outside-init
NOTE the first email change was never confirmed, so old has not changed.
Email is not saved until user confirms, so no events should have been  emitted.
Like email, since the user has not confirmed their password change,  the field has not yet changed, so no events will have been emitted.
Note that when we clear the year_of_birth here we're firing an event.
Navigate to the password reset page
Expect that reset password form is visible on the page
Navigate to the password reset page
Navigate to the password reset form and try to submit it
Expect that we're shown a success message
Create a course to enroll in
Create a user account
Navigate to the login page and try to log in
Expect that we reach the dashboard and we're auto-enrolled in the course
Navigate to the login page
User account does not exist
Verify that an error is displayed
Navigate to the password reset form and try to submit it
Expect that we're shown a success message
Navigate to the password reset form
User account does not exist
Expect that we're shown a failure message
Create a user account
Navigate to the login page  Baseline screen-shots are different for chrome and firefox.
Try to log in using "Dummy" provider
Now login with username and password:
Expect that we reach the dashboard and we're auto-enrolled in the course
Now logout and check that we can log back in instantly (because the account is linked):
Create a user account and link it to third party auth with the dummy provider:
When not logged in, try to load a course URL that includes the provider hint ?tpa_hint=...
We should now be redirected to the course page
switch to "Linked Accounts" tab
make sure we are on "Linked Accounts" tab after the account settings  page is reloaded
This must be done after linking the account, or we'll get cross-test side effects  switch to "Linked Accounts" tab
Create the user (automatically logs us in)
Log out
Create a course to enroll in
Navigate to the registration page
Expect that we reach the dashboard and we're auto-enrolled in the course
Navigate to the registration page
Navigate to the register page  Baseline screen-shots are different for chrome and firefox.
Try to authenticate using the "Dummy" provider
Set country, accept the terms, and submit the form:
Expect that we reach the dashboard and we're auto-enrolled in the course
Now logout and check that we can log back in instantly (because the account is linked):
Now unlink the account (To test the account settings view and also to prevent cross-test side effects)  switch to "Linked Accounts" tab
Create a course
Add an honor mode to the course
Add a verified mode to the course
Create a user and log them in
Navigate to the track selection page
Enter the payment and verification flow by choosing to enroll as verified
Proceed to the fake payment page
Submit payment
Proceed to verification
Take face photo and proceed to the ID photo step
Take ID photo and proceed to the review photos step
Submit photos and proceed to the enrollment confirmation step
Navigate to the dashboard
Expect that we're enrolled as verified in the course
Create a user and log them in
Navigate to the track selection page
Enter the payment and verification flow by choosing to enroll as verified
Proceed to the fake payment page
Submit payment
Navigate to the dashboard
Expect that we're enrolled as verified in the course
Create a user, log them in, and enroll them in the honor mode
Navigate to the dashboard
Expect that we're enrolled as honor in the course
Click the upsell button on the dashboard
Select the first contribution option appearing on the page
Proceed to the fake payment page
Submit payment
Navigate to the dashboard
Expect that we're enrolled as verified in the course
self.course_info['number'] must be shorter since we are accessing the wiki. See TNL-1751
Auto-auth register for the course
Access course wiki page
self.course_info['number'] must be shorter since we are accessing the wiki. See TNL-1751
Install a course with sections/problems, tabs, updates, and handouts
Auto-auth register for the course
Navigate to the course info page from the progress page
Expect just one update
Expect a link to the demo handout pdf
Navigate to the progress page from the info page
We haven't answered any problems yet, so assume scores are zero  Only problems should have scores; so there should be 2 scores.
From the course info page, navigate to the static tab
From the course info page, navigate to the static tab
Verify that Mathjax has rendered
From the course info page, navigate to the wiki tab
Navigate to the course page from the info page
Check that the course navigation appears correctly
Navigate to a particular section
Check the sequence items
Install a course with TextBooks
Auto-auth register for the course
Verify each PDF textbook tab by visiting, it will fail if correct tab is not loaded.
Auto-auth register for the course
Auto-auth register for the course
visit dashboard page and make sure there is not pre-requisite course message
Logout and login as a staff.
visit course settings page and set pre-requisite course
Logout and login as a student.
Install a course with sections and problems.
Auto-auth register for the course
Navigate to the problem page
Does the page have computation results?
Fill in the answer correctly.
Fill in the answer incorrectly.
Auto-auth register for the course
visit course page and make sure there is not entrance exam chapter.
Logout and login as a staff.
Logout and login as a student.
visit course info page and make sure there is an "Entrance Exam" section.
Add an honor mode to the course
Add a verified mode to the course
changed back to English language.
Initialize the page objects
Add a verified mode to the course
Auto-auth register for the course.
the track selection page cannot be visited. see the other tests to see if any prereq is there.  Navigate to the track selection page
Enter the payment and verification flow by choosing to enroll as verified
Proceed to the fake payment page
Submit payment
Visit the course outline page in studio
open the exam settings to make it a proctored exam.
select advanced settings tab
login as a verified student and visit the courseware.
Start the proctored exam.
Visit the course outline page in studio
open the exam settings to make it a proctored exam.
select advanced settings tab
login as a verified student and visit the courseware.
Start the timed exam.
Stop the timed exam.
Given that an exam has been configured to be a timed exam.
When I log in as an instructor,
And visit the Allowance Section of Instructor Dashboard's Special Exams tab
Then I can add Allowance to that exam for a student
When I click the Add Allowance button
Then popup should be visible
When I fill and submit the allowance form
Then, the added record should be visible
Given that an exam has been configured to be a proctored exam.
When I log in as an instructor,
And visit the Student Proctored Exam Attempts Section of Instructor Dashboard's Special Exams tab
Then I can see the search text field
And I can see one attempt by a student.
And I can remove the attempt by clicking the "x" at the end of the row.
Create the user (automatically logs us in)
go to the student admin page on the instructor dashboard
then we have alert confirming action
Verify that added exceptions are also synced with backend  Revisit Page
wait for the certificate exception section to render
validate certificate exception synced with server is visible in certificate exceptions list
Remove Certificate Exception
Verify that added exceptions are also synced with backend  Revisit Page
wait for the certificate exception section to render
validate certificate exception synced with server is visible in certificate exceptions list
Add a student to Certificate exception list
Add duplicate student to Certificate exception list
Click 'Add Exception' button without filling username/email field
Click 'Add Exception' button with invalid username/email field
Click 'Add Exception' button with invalid username/email field
Add a student to Certificate exception list
Click 'Generate Exception Certificates' button
Revisit Page & verify that added exceptions are also synced with backend
Wait for the certificate exception section to render
Validate certificate exception synced with server is visible in certificate exceptions list
Create course fixture once each test run
set same course number as we have in fixture json
we have created a user with this id in fixture, and created a generated certificate for it.
Enroll above test user in the course
Validate success message
Verify that added invalidations are also synced with backend  Revisit Page
wait for the certificate invalidations section to render
validate certificate invalidation is visible in certificate invalidation list
Verify that added invalidations are also synced with backend  Revisit Page
wait for the certificate invalidations section to render
click "Remove from Invalidation Table" button next to certificate invalidation
validate certificate invalidation is removed from the list
Click "Invalidate Certificate" with empty student username/email field
Click "Invalidate Certificate" with invalid student username/email
Click 'Invalidate Certificate' button with not enrolled student
Load certificate web view page for use by the tests
set same course number as we have in fixture json
Verify that their is no padding around the box containing certificate info.
Navigate to Test Subsection in Test Section Section
Navigate to Test Problem 1
Select correct value for from select menu
Select correct radio button for the answer
Submit the answer
Navigate to the 'Test Subsection 2' of 'Test Section 2'
Navigate to Test Problem 2
Fill in the answer of the problem
Submit the answer
create test file in which index for this test will live
Create a student who will end up in the default cohort group
After adding the cohort, it should automatically be selected
Install a course with sections/problems, tabs, updates, and handouts
Auto-auth register for the course.
Visit problem page as a student.
Logout and login as a staff user.
Visit course outline page in studio.
Set release date for subsection in future.
Logout and login as a student.
Visit courseware as a student.  Problem name should be "Test Problem 2".
Add a verified mode to the course
Auto-auth register for the course.
the track selection page cannot be visited. see the other tests to see if any prereq is there.  Navigate to the track selection page
Enter the payment and verification flow by choosing to enroll as verified
Proceed to the fake payment page
Submit payment
Install a course with sections/problems, tabs, updates, and handouts
start in first section
next takes us to next tab in sequential
go to last sequential position
next takes us to next sequential
next takes us to next chapter
previous takes us to previous chapter
previous takes us to last tab in previous sequential
previous takes us to previous tab in sequential
test UI events emitted by navigation
test UI events emitted by navigating via the course outline
Set the scope to the sequence navigation
Install a course with section, tabs and multiple choice problems.
Auto-auth register for the course.
Go to sequential position 1 and assert that we are on problem 1.
Update problem 1's content state by clicking check button.
Save problem 1's content state as we're about to switch units in the sequence.
Go to sequential position 2 and assert that we are on problem 2.
Come back to our original unit in the sequence and assert that the content hasn't changed.
Go to sequential position 1 and assert that we are on problem 1.
Update problem 1's content state by clicking save button.
Save problem 1's content state as we're about to switch units in the sequence.
Go to sequential position 2 and assert that we are on problem 2.
Come back to our original unit in the sequence and assert that the content hasn't changed.
Go to sequential position 1 and assert that we are on problem 1.
Save problem 1's content state as we're about to switch units in the sequence.
Go to sequential position 2 and assert that we are on problem 2.
Come back to our original unit in the sequence and assert that the content hasn't changed.
Change the privacy if requested by loading the page and  changing the drop down
Change the privacy setting if it is not the desired one already
Verify the current setting is as expected
Load the page
Set the privacy for the new user
Set the user's year of birth
Log the user out
Reload the page and verify that the profile is now public
Reload the page and verify that the profile is now private
Run the search  No error message appears
Tag group "cool"
Tag group "review"
Notes with no tags
visiting the page results in an ajax request to fetch the notes
visiting the page results in an ajax request to fetch the notes
visiting the page results in an ajax request to fetch the notes
visiting the page results in an ajax request to fetch the notes
Because all the notes (with tags) have the same tags, they will end up ordered alphabetically.
test pagination with valid page number
test pagination with invalid page number
test pagination with valid page number
test pagination with invalid page number
create test file in which index for this test will live
create a unit in course outline
Create content in studio without publishing.
Do a search, there should be no results shown.
Publish in studio to trigger indexing.
Do the search again, this time we expect results.
Create content in studio without publishing.
Do a search, there should be no results shown.
Publish in studio to trigger indexing, and edit chapter name afterwards.
Do a ReIndex from studio to ensure that our stuff is updated before the next stage of the test
Search after publish, there should still be no results shown.
Do a ReIndex from studio to ensure that our stuff is updated before the next stage of the test
Do the search again, this time we expect results.
Generate the problem XML using capa.tests.response_xml_factory
Make sure we're looking at the right problem
Answer the problem correctly
Answer the problem incorrectly
Set the scope to the problem container
Run the accessibility audit.
Correct answer is any two integers that sum to 10
If we want an incorrect answer, then change  the second addend so they no longer sum to 10
Auto-auth register for the course.
create index file
Fill in the conditional page poll  The conditional does not update on its own, so we need to reload the page.
Auto-auth register for the course.
Logout and login as staff
Visit course outline page in studio.
Logout and login as a student.
Visit courseware as a student.
Verify bookmarked breadcrumbs.
Install a course with two annotations and two annotations problems.
Auto-auth register for the course.
This will avoid scrolling related problems on different browsers and instead directly jump on the problem
For transcripts, you need to check an actual video, so we will  just specify our default video and see if that one is available.
if value is not an option choice then it should return false
Make sure specified option is actually selected
allow the filters to use "assert" to filter out events
Auto-auth register for the course.
Validate the event payload
A weak assertion for the timestamp as well
Validate the event payload
A weak assertion for the timestamp as well
go to video
go to video
wait until video stop playing
go to video
wait until video stop playing
go to video
wait until video stop playing
If there is only one language then there will be no subtitle/captions menu
reset youtube stub server
Video tests require at least one vertical with a single video.
Verify that video has rendered in "Youtube" mode
Verify that we see " " text in the transcript
Hide captions and make sure they're hidden and cookie is unset
Verify that we see "Welcome to edX." text in the captions
click video button "fullscreen"
check if video aligned correctly without enabled transcript
go to video
check if we can download transcript in "srt" format that has text " "
go to video
check if "Welcome to edX." text in the captions
check if we can download transcript in "srt" format that has text "Welcome to edX."
select language with code "zh"
check if we see " " text in the captions
check if we can download transcript in "srt" format that has text " "
go to video
make sure captions are opened
click video button "fullscreen"
check if video aligned correctly with enabled transcript
click video button "transcript"
check if video aligned correctly without enabled transcript
configure youtube server
configure youtube server
configure youtube server
The video should only be loaded once
configure youtube server
The video should only be loaded once
configure youtube server
check if caption button is visible
open the section with videos (open vertical containing video "A")
check if we can download transcript in "srt" format that has text "00:00:00,260"
select the transcript format "txt"
check if we can download transcript in "txt" format that has text "Welcome to edX."
open vertical containing video "B"
check if we can download transcript in "txt" format that has text "Equal transcripts"
open vertical containing video "C"
menu "download_transcript" doesn't exist
go to video
go to video
we start the video, then pause it to activate the transcript
go to video
go to second sequential position  import ipdb; ipdb.set_trace()
go back to first sequential position  we are again playing tab 1 videos to ensure that switching didn't broke some video functionality.  import ipdb; ipdb.set_trace()
select the "2.0" speed on video "A"
select the "0.50" speed on video "B"
open video "C"
go to the vertical containing video "A"
Video "A" should still play at speed 2.0 because it was explicitly set to that.
reload the page
go to the vertical containing video "A"
check if video "A" should start playing at speed "2.0"
select the "1.0" speed on video "A"
go to the vertical containing "B"
Video "B" should still play at speed .5 because it was explicitly set to that.
go to the vertical containing video "C"
The change of speed for Video "A" should  impact Video "C" because it still has  not been explicitly set to a speed.
go to video
no autoplay here, maybe video is too small, so pause is not switched
go to second sequential position
go back to first sequential position  we are again playing tab 1 videos to ensure that switching didn't broke some video functionality.
Verify that the video has rendered in "Youtube" mode
Verify that the video has autoplay mode disabled
Verify that error message is shown
Verify that error message has correct text
Verify that spinner is not shown
go to video
check if we see " " text in the captions
check if we can download transcript in "srt" format that has text " "
go to video
check if "Welcome to edX." text in the captions
check if we can download transcript in "srt" format that has text "Welcome to edX."
select language with code "zh"
check if we see " " text in the captions
Then I can download transcript in "srt" format that has text " "
go to video
make sure captions are opened
click video button "fullscreen"
check if video aligned correctly with enabled transcript
go to video
make sure captions are opened
check if we see "Welcome to edX." text in the captions
go to video
make sure captions are opened
check if we see " " text in the captions
go to video
limit the scope of the audit to the video player only.
This will be initialized later
Total video xblock components count should be equals to 2  Why 2? One video component is created by default for each test. Please see  test_studio_video_module.py:CMSVideoTest._create_course_unit  And we are creating second video component here.
Visit Course Outline page
Visit Unit page
The 0th entry is the unit page itself.
The 0th entry is the unit page itself.
The 0th entry is the unit page itself.
This will create a video by doing a single click and then ensure that video is created
change id of first default video
again open unit page and check that video controls show for both videos
verify that the error message isn't shown by default
we're loading a shorter transcript to ensure both skip links are available
limit the scope of the audit to the video player only.
Verify that each page is available
Add a verified mode to the course
Set the certificate properties
Save the certificate
Edit the certificate
Delete the certificate we just created
Reload the page and confirm there are no certificates
Edit the signatory in certificate
Make sure certificate is created
Make sure certificate is created
Make sure certificate is created
set up course number override in Advanced Settings Page
Add a video component to Group 1  Duplicate the first item in Group A
Drag newly added video component to top.  Drag duplicated component to top.
Group A itself has a delete icon now, so item_1 is index 1 instead of 0.
If anything other than 'All Students and Staff', is selected,  'Specific Content Groups' should be selected as well.
Make initial edit(s) and save
Re-open the modal and inspect its selected inputs
Will initially be in staff view, locked component should be visible.  Switch to student view and verify not visible
Will initially be in staff view, components always visible.  Switch to student view and verify visible.
Unfortunately no blocks in the core platform implement display_name_with_default  in an interesting way for this test, so we are just testing for consistency and not  the actual value.
The next page is the library edit view; make sure it loads:
Then go back to the home page and make sure the new library is listed there:
precondition check - the library block should be configured before we remove the library setting
Formerly flaky: see TE-745
Removed this assert until a summary message is added back to the author view (SOL-192)
Removed this assert until a summary message is added back to the author view (SOL-192)
precondition check - assert library has children matching filter criteria
Library should contain single Dropdown problem, so now there should be no errors again
precondition check - assert block is configured fine
Create a new block, causing a new library version:
Reset:
Get the time when the import has started.  import_page timestamp is in (MM/DD/YYYY at HH:mm) so replacing (second, microsecond) to  keep the comparison consistent
Get the time when the import has finished.  import_page timestamp is in (MM/DD/YYYY at HH:mm) so replacing (second, microsecond) to  keep the comparison consistent
Successful creation of course takes user to course outline page
Go back to dashboard and verify newly created course exists there
Successful creation of course takes user to course outline page
Go back to dashboard and verify newly created course exists there
Reload the page and expand all subsections to see that the change was persisted.
with collapsed outline
with first sequential expanded
expand first subsection
Define the dimensions that map to the UnitState constructor
Add a fixture for every state in the product of features
Verify that Release date visible by default  Verify that Due date and Policy hidden by default
Set new values
Verify that Release date visible by default  Verify that Due date and Policy are not present
Verify fields
Verify initial value
Set new value
Verify that Due date and Policy are not present
Set new values
Create a deprecated component with display_name to be empty and make sure  the deprecation warning is displayed with
Edit the second content group
Delete content group
Waiting for the page load and verify that we've landed on course outline page
Before every test, make sure to visit the page first
Feed an integer value for String field.  .set method saves automatically after setting a value
Test Modal
Save original values and feed wrong inputs
Test Modal
Save original values and feed wrong inputs
Let modal popup
Click Undo Changes button
Check that changes are undone
Check that the validation modal went away.
Check presence of modal
List of wrong settings item & what is presented in the modal should be the same
The course_license text will include a bunch of screen reader text to explain  the selected options
There are several existing color contrast errors on this page,  we will ignore this error in the test until we fix them.
limit the scope of the audit to the special exams tab on the modal dialog
from nose.tools import set_trace; set_trace()
Ensure jquery is loaded before running a jQuery  This text appears towards the end of the work that jQuery is performing on the page
upload image
upload image
upload image
First xblock is the container for the page, subtract 1.
Verify inactive xblocks appear after active xblocks
Wait for the xblock to be fully initialized so that the add button is rendered
Click the add button and verify that the groups were added on the page
Reload the page to make sure the groups were persisted.
The inactive group is the 2nd group, but it is the first one  with a visible delete button, so use index 0
To make sure that id is present on the page and it is not an empty.  We do not check the value of the id, because it's generated randomly and we cannot  predict this value
Expand the configuration
Collapse the configuration
Go to the Group Configuration Page
I publish and view in LMS and it is rendered correctly
Save the configuration
Remove group with name "New Group Name"  Rename Group A  Save the configuration
Add split test to vertical and assign newly created group configuration to it
`Group C` -> `Second Group`  Add new group
Remove Group A  Save the configuration
Click the add button and verify that the groups were added on the page
Create new group configuration
Cancel the configuration
Cancel the configuration
Try to save  Verify that configuration is still in editing mode  Verify error message
Create new group configuration  Leave empty required field
Save the configuration
Go to the Group Configuration Page and click on outline anchor
Waiting for the page load and verify that we've landed on course outline page
Go to the Group Configuration Page and click unit anchor
Waiting for the page load and verify that we've landed on the unit page
Delete first group configuration via detail view
Delete first group configuration via edit view
Appropriate Group Configuration is expanded.
Create group configuration and associated experiment
Display details view  Check that error icon and message are not present
Add a group
Display details view  Check that warning icon and message are not present
Remove a group
render in LMS correctly
render in LMS to see how inactive vertical is rendered
I go to split test and delete inactive vertical
render in LMS again
Create a new block:
Delete the first block:
Check that the save worked:
Create a second user for use in these tests:
There are several existing color contrast errors on this page,  we will ignore this error in the test until we fix them.
Ensure that the superclass sets up
The 0th entry is the unit page itself.
Reload the page to see that the change was persisted.
Before every test, make sure to visit the page first
Refresh the page again and confirm the prerequisite course selection is properly reflected
Refresh the page again to confirm the None selection is properly reflected
Re-pick the prerequisite course and confirm no errors are thrown (covers a discovered bug)
Refresh the page again to confirm the prerequisite course selection is properly reflected
getting the course outline page.
title with text 'Entrance Exam' should be present on page.
Delete the currently created entrance exam.
button with text 'New Unit' should be present.
button with text 'New Subsection' should not be present.
Set the course start date to tomorrow in order to allow setting pacing
Ensure that the superclass sets up
Make '_' a no-op so we can scrape strings. Using lambda instead of   `django.utils.translation.ugettext_noop` because Django cannot be imported in this file
don't display irrelevant gunicorn sync error
NOTE: we are importing this method so that any module that imports us has access to get_current_request
This is a tuple for holding scores, either from problems or sections.  Section either indicates the name of the problem or the name of the section
A special message type indicating that the xblock is not yet configured. This message may be rendered  in a different way within Studio.
HACK: This shouldn't be hard-coded to two types  OBSOLETE: This obsoletes 'type'
Stats event sent to DataDog in order to determine if old XML parsing can be deprecated.
This is the view that will be rendered to display the XBlock in the LMS.  It will also be used to render the block in "preview" mode in Studio, unless  the XBlock also implements author_view.
An optional view of the XBlock similar to student_view, but with possible inline  editing capabilities. This view differs from studio_view in that it should be as similar to student_view  as possible. When previewing XBlocks within Studio, Studio will prefer author_view to student_view.
The view used to render an editor in Studio. The editor rendering can be completely different  from the LMS student_view, and it is only shown when the author selects "Edit".
Views that present a "preview" view of an xblock (as opposed to an editing view).
cdodge: We've moved the xmodule.coffee script from an outside directory into the xmodule area of common  this means we need to make sure that all xmodules include this dependency which had been previously implicitly  fulfilled in a different area of code
Added xmodule.js separately to enforce 000 prefix for this only.
it'd be nice to have a useful default but it screws up other things; so,  use display_name_with_default for those
This indicates whether the xmodule is a problem-type.  It should respond to max_score() and grade(). It can be graded or ungraded  (like a practice problem).
Whether this module can be displayed in read-only mode.  It is safe to set this to True if  all user state is handled through the FieldData API.
if caller wants kvs, caller's assuming it's up to date; so, decache it
Be backwards compatible with callers using usage_key_filter
Skip rebinding if we're already bound a user, and it's this user.
If we are switching users mid-request, save the data from the old user.
Update scope_ids to point to the new user.
Clear out any cached instantiated children.
Clear out any cached field data scoped to the old user.
not the most elegant way of doing this, but if we're removing  a field from the module's field_data_cache, we should also  remove it from its _dirty_fields
Set the new xmodule_runtime and field_data (which are user-specific)
We are not allowing editing of xblock tag and name fields at this time (for any component).
Only use the fields from this class, not mixins
Set the descriptor first so that we can proxy to it
Take advantage of the children cache that the descriptor might have
VS[compat].  Backwards compatibility code that can go away after  importing 2012 courses.  A set of metadata key conversions that we want to make
update_version is the version which last updated this xblock v prev being the penultimate updater  leaving off original_version since it complicates creation w/o any obv value yet and is computable  by following previous until None  definition_locator is only used by mongostores which separate definitions from blocks
It'd be great to not reserialize and deserialize the xml
xmodule_instance is set by the XModule.__init__. If we had an error after that,  we need to clean it out so that we can set up the ErrorModule instead
NOTE: we generally don't want content errors logged as errors  work around
This is used by XModules to write out separate files during xml export
Currently, Modulestore is responsible for instantiating DescriptorSystems  This means that LMS/CMS don't have a way to define a subclass of DescriptorSystem  that implements the correct local_resource_url. So, for now, instead, we will reference a  global function that the application can override.
A stub publish method that doesn't emit any events from XModuleDescriptors.
getting the service from parent module. making sure of block service declarations.  Passing the block to service if it is callable e.g. ModuleI18nService. It is the responsibility of calling  service to handle the passing argument.
remove xblock-family from elements
get xblock-family from node  now process them & remove them from the xml payload
Remove value set transiently by XBlock
getting the service from parent module. making sure of block service declarations.  Passing the block to service if it is callable e.g. ModuleI18nService. It is the responsibility of calling  service to handle the passing argument.
First we try a lookup in the module system...
filter removes possible Nones in texts and tails
get numerators + denominators
This escaping is incomplete.  However, rather than switching this to use  markupsafe.escape() and fixing issues, better to put that energy toward  migrating away from this method altogether.
Translators: TBD stands for 'To Be Determined' and is used when a course  does not yet have an announced start date.
Make courses that have an announcement date have a lower  score than courses than don't, older courses should have a  higher score.
Youtube case:
HTML5 case
Only do redirect for English
If this video lives in library, the code below is not relevant and will error.
Try to return static URL redirection as last resort  if no translation is required
Make '_' a no-op so we can scrape strings. Using lambda instead of   `django.utils.translation.ugettext_noop` because Django cannot be imported in this file
To make sure that js files are called in proper order we use numerical  index. We do that to avoid issues that occurs in tests.
OrderedDict for easy testing of rendered context in tests
Determine if there is an alternative source for this video  based on user locale.  This exists to support cases where  we leverage a geography specific CDN, like China.
If we have an edx_video_id, we prefer its values over what we store  internally for download links (source, html5_sources) and the youtube  stream.
set the youtube url
If the user comes from China use China CDN for html5 videos.  'CN' is China ISO 3166-1 country code.  Video caching is disabled for Studio. User_location is always None in Studio.  CountryMiddleware disabled for Studio.
If there was no edx_video_id, or if there was no download specified  for it, we fall back on whatever we find in the VideoDescriptor
This won't work when we move to data that  isn't on the filesystem
This is the server's guess at whether youtube is available for  this user, based on what was recorded the last time we saw the  user, and defaulting to True.
For backwards compatibility -- if we've got XML data, parse it out and set the metadata fields
If `source` field value exist in the `html5_sources` field values,  then delete `source` field value and use value from `html5_sources` field.
Force download_video field to default value if it's not explicitly set for backward compatibility.
for backward compatibility.  If course was existed and was not re-imported by the moment of adding `download_track` field,  we should enable `download_track` if following is true:
We're loading a descriptor, so student_id is meaningless  We also don't have separate notions of definition and usage ids yet,  so we use the location for both
handle license specifically
First try a lookup in VAL. If we have a YouTube entry there, it overrides the  one passed in.
Handle the fact that youtube IDs got double-quoted for a period of time.  Note: we pass in "VideoFields.youtube_id_1_0" so we deserialize as a String--  it doesn't matter what the actual speed is for the purposes of deserializing.
Convert between key types for certain attributes --  necessary for backwards compatibility.  example: 'start_time': cls._example_convert_start_time
We export values with json.dumps (well, except for Strings, but  for about a month we did it for Strings also).
For backwards compatibility: Add `source` if XML doesn't have `download_video`  attribute.
For backwards compatibility: if XML doesn't have `download_track` attribute,  it means that it is an old format. So, if `track` has some value,  `download_track` needs to have value `True`.
Allow ValCannotCreateError to escape
load license if it exists
Check to see if there are transcripts in other languages besides default transcript
If the "only_on_web" field is set on this video, do not return the rest of the video's data  in this json view, since this video is to be accessed only through its web view."
Check in VAL data first if edx_video_id exists
get and cache bulk VAL data for course
Get the encoded videos if data from VAL is found
Fall back to other video URLs in the video module if not found in VAL
Include youtube link if there is no encoding for mobile- ie only a fallback URL or no encodings at all  We are including a fallback URL for older versions of the mobile app that don't handle Youtube urls
Make '_' a no-op so we can scrape strings. Using lambda instead of   `django.utils.translation.ugettext_noop` because Django cannot be imported in this file
`source` is deprecated field and should not be used in future.  `download_video` is used instead.
Data format: {'de': 'german_translation', 'uk': 'ukrainian_translation'}
2 convert /static/filename.srt  to filename.srt in self.transcripts.
2.
3.
remove key from transcripts because proper srt file does not exist in assets.
Used utf-8-sig encoding type instead of utf-8 to remove BOM(Byte Order Mark), e.g. U+FEFF
If we're not verifying the assets, we just trust our field values
clean up /static/ prefix from bumper transcripts
if no bumper sources, nothing will be showed
Contruction of the rewrite url is intentionally very flexible of input.  For example, https://www.edx.org/ + /foo.html will be rewritten to  https://www.edx.org/foo.html.
Mimic the behavior of removed get_video_from_cdn in this regard and  return None causing the caller to use the original URL.
If credentials were provided, authenticate the user.
Make '_' a no-op so we can scrape strings. Using lambda instead of   `django.utils.translation.ugettext_noop` because Django cannot be imported in this file
Class property that specifies the type of the tab.  It is generally a constant value for a  subclass, shared by all instances of the subclass.
The title of the tab, which should be internationalized using  ugettext_noop since the user won't be available in this context.
Class property that specifies whether the tab can be hidden for a particular course
Class property that specifies whether the tab is hidden for a particular course
The relative priority of this view that affects the ordering (lower numbers shown first)
Class property that specifies whether the tab can be moved within a course's list of tabs
Class property that specifies whether the tab is a collection of other tabs
True if this tab is dynamically added to the list of tabs
True if this tab is a default for the course (when enabled)
True if this tab can be included more than once for a course.
If there is a single view associated with this tab, this is the name of it
'other' is a dict-type tab and did not validate
allow tabs without names; if a name is required, its presence was checked in the validator.
only compare the persisted/serialized members: 'type' and 'name'
Presence of syllabus tab is indicated by a course attribute
If the course has a discussion link specified, use that even if we feature  flag discussions off. Disabling that is mostly a server safety feature  at this point, and we don't need to worry about external sites.
the discussion_link setting overrides everything else, even if there is a discussion tab in the course tabs
find one of the discussion tab types in the course tabs
If rendering inline that add each item in the collection,  else just show the tab itself as long as it is not empty.
Make '_' a no-op so we can scrape strings. Using lambda instead of   `django.utils.translation.ugettext_noop` because Django cannot be imported in this file
it'd be nice to have a useful default but it screws up other things; so,  use display_name_with_default for those
When we switch this to an XBlock, we can merge this with student_view,  but for now the XModule mixin requires that this method be defined.  pylint: disable=no-member
also look for .html versions instead of .xml
Add some specific HTML rendering context when editing HTML modules where we pass  the root /c4x/ url for assets. This allows client-side substitutions to occur.
log.debug("candidates = {0}".format(candidates))
add more info and re-raise
Write html to file, return an empty tag
write out the relative name
statuses
VS[compat]  backwards compatibility with old nested customtag structure
cdodge: look up the template as a module
in case we want to add to this class, a version will be handy  for deserializing old versions.  (This will be serialized in courses)
The Stevedore extension point namespace for user partition scheme plugins.
The collection of user partition scheme extensions.
The default scheme to be used when upgrading version 1 partitions.
If no scheme was provided, set it to the default ('random')
Version changes should be backwards compatible in case the code  gets rolled back.  If we see a version number greater than the current  version, we should try to read it rather than raising an exception.
Be sure to clean up the global scheme_extensions after the test.
Create a test partition
Make sure the names are set on the schemes (which happens normally in code, but may not happen in tests).
Derive a "user_id" from the username, just so we don't have to add an  extra param to this method. Just has to be unique per user.
assign the first group to be returned
get a group assigned to the user
switch to the second group and verify that it is returned for the user
Two StaticPartitionService objects that share the same cache:
A StaticPartitionService with its own local cache
A StaticPartitionService that never uses caching.
Set the group we expect users to be placed into
Make sure our partition services all return the right thing, but skip  ps_shared_cache_2 so we can see if its cache got updated anyway.
Now select a new target group
Both of the shared cache entries should return the old value, even  ps_shared_cache_2, which was never asked for the value the first time  Likewise, our separately cached piece should return the original answer
Our uncached service should be accurate.
And a newly created service should see the right thing
assign first group and verify that it is returned for the user
switch to the second group and verify that it is returned for the user
Make '_' a no-op so we can scrape strings. Using lambda instead of   `django.utils.translation.ugettext_noop` because Django cannot be imported in this file
All available user partitions (with value and display name). This is updated each time  editable_metadata_fields is called.  Default value used for user_partition_id
Specified here so we can see what the value set at the course-level is.
group_id is an int  child is a serialized UsageId (aka Location).  This child  location needs to actually match one of the children of this  Block.  (expected invariant that we'll need to test, and handle  authoring tools that mess this up)
Peak confusion is great.  Now that we set child_descriptor,  get_children() should return a list with one element--the  xmodule for the child
Sort active and inactive contents by group name.
raise error instead?  In fact, could complain on descriptor load...
the editing interface can be the same as for sequences -- just a container
Any existing value of user_partition_id will be in "old_content" instead of "old_metadata"  because it is Scope.content.
Don't need to call update_item in the modulestore because the caller of this method will do it.  If children referenced in group_id_to_child have been deleted, remove them from the map.
Update the list of partitions based on the currently available user_partitions.
Explicitly add user_partition_id, which does not automatically get picked up because it is Scope.content.  Note that this means it will be saved by the Studio editor as "metadata", but the field will  still update correctly.
Compute the inactive children in the order they were added to the split test
user.id - to be fixed by Publishing team
Make '_' a no-op so we can scrape strings. Using lambda instead of   `django.utils.translation.ugettext_noop` because Django cannot be imported in this file
The last page should be the last element in the table of contents,  but it may be nested. So recurse all the way down the last element
If we can't get to S3 (e.g. on a train with no internet), don't break  the rest of the courseware.
Ensure that courses imported from XML keep their image
Ensure that courses imported from XML keep their image
Ensure that courses imported from XML keep their image
Translators: This field is the container for course-specific certifcate configuration values  Translators: These overrides allow for an alternative configuration of the certificate web view
Specific certificate information managed via Studio (should eventually fold other cert settings into this)  Translators: This field is the container for course-specific certifcate configuration values  Translators: These overrides allow for an alternative configuration of the certificate web view
NOTE (THK): This is a last-minute addition for Fall 2012 launch to dynamically    disable the syllabus content for courses that do not provide a syllabus
Override any global settings with the course settings
Default to a blank policy dict
if we successfully read the file, stop looking at backups
bleh, have to parse the XML here to just pull out the url_name attribute  I don't think it's stored anywhere in the instance.
Try to load grading policy
now set the current instance. set_grading_policy() will apply some inheritance rules
Load the wiki tag if it exists
load license if it exists
handle license specifically. Default the course to have a license  of "All Rights Reserved", if a license is not explicitly set.
force the caching of the xblock value so that it can detect the change  pylint: disable=pointless-statement
NOTE WELL: this change will not update the processed graders. If we need that, this needs to call grader_from_conf
XBlock fields don't update after mutation
If this descriptor has been bound to a student, return the corresponding  XModule. If not, just use the descriptor itself
The xmoduledescriptors included here are only the ones that have scores.
HACK: This shouldn't be hard-coded to two types  OBSOLETE: This obsoletes 'type'
pylint: disable=no-member
Make '_' a no-op so we can scrape strings. Using lambda instead of   `django.utils.translation.ugettext_noop` because Django cannot be imported in this file
Make '_' a no-op so we can scrape strings. Using lambda instead of   `django.utils.translation.ugettext_noop` because Django cannot be imported in this file
Determine which of our children we will show:  Remove any selected blocks that are no longer valid:
If max_count has been decreased, we may have to drop some previously selected blocks:
Do we have enough blocks now?
reason "invalid" means deleted from library or a different library is now being used.
Save our selections to the user state, to ensure consistency:
The following JS is used to make the "Update now" button work on the unit page and the container view:
The only supported mode is currently 'random'.  Add the mode field to non_editable_metadata_fields so that it doesn't  render in the edit form.
May be None when creating bok choy test fixtures
Children have been handled.
Make '_' a no-op so we can scrape strings. Using lambda instead of   `django.utils.translation.ugettext_noop` because Django cannot be imported in this file
Name of poll to use in links to this poll
List of answers, in the form {'id': 'some id', 'text': 'the answer text'}
FIXME: fix this, when xblock will support mutable types.  Now we use this hack.
FIXME: fix this, when xblock will support mutable types.  Now we use this hack.
FIXME: hack for resolving caching `default={}` during definition  poll_answers field
FIXME: fix this, when xblock support mutable types.  Now we use this hack.
Check for presense of required tags in xml.
Make '_' a no-op so we can scrape strings. Using lambda instead of   `django.utils.translation.ugettext_noop` because Django cannot be imported in this file
The discussion XML format uses `id` and `for` attributes,  but these would overload other module attributes, so we prefix them  for actual use in the code
We may choose to enable sort_keys in the future, but while Kevin is investigating....
Make '_' a no-op so we can scrape strings  Using lambda instead of `django.utils.translation.ugettext_noop` because Django cannot be imported in this file
add any of descriptor's explicitly set fields to the inheriting list  inherited_settings values are json repr
xml backed courses are read-only, but they do have some computed fields
When blacklists are this, all children should be excluded
dict(version_guid, dict(BlockKey, module))
If no course index has been set, then no branches have changed
If there was no index in the database to start with, then all branches  are dirty by definition
handle split specific things and defer to super otherwise
handle version_guid based retrieval locally
handle ignore case and general use
Ensure that any edits to the index don't pollute the initial_index
If the content is dirty, then update the database
The structure hasn't been loaded from the db yet, so load it
cast string to ObjectId if necessary
The definition hasn't been loaded from the db yet, so load it
cast string to ObjectId if necessary
Only query for the definitions that aren't already cached.
If we have an active bulk write, and it's already been edited, then just use that structure
If we're in a bulk write, update the structure used there, and mark it as dirty
add any being built but not yet persisted or in the process of being updated
if we've specified a filter by org,  make sure we've honored that filter when  integrating in-transit records
drop the assets
This method supports lazy loading, where the descendent definitions aren't loaded  until they're actually needed.  Non-lazy loading: Load all descendants by id.  Turn definitions into a map.
convert_fields gets done later in the runtime's xblock_from_json
use the course id
This may be a bit too touchy but it's hard to infer intent
collect ids and then query for those
get the blocks for each course index (s/b the root)
The supplied CourseKey is of the wrong type, so it can't possibly be stored in this modulestore.
The supplied CourseKey is of the wrong type, so it can't possibly be stored in this modulestore.
The supplied CourseKey is of the wrong type, so it can't possibly be stored in this modulestore.
The supplied UsageKey is of the wrong type, so it can't possibly be stored in this modulestore.
this error only occurs if the course does not exist
The supplied UsageKey is of the wrong type, so it can't possibly be stored in this modulestore.
The supplied courselike key is of the wrong type, so it can't possibly be stored in this modulestore.
don't expect caller to know that children are in fields
No need of these caches unless include_orphans is set to False
Found, xblock has the path to the root
The supplied locator is of the wrong type, so it can't possibly be stored in this modulestore.
Check and verify the found parent_ids are not orphans; Remove parent which has no valid path  to the course root
find alphabetically least
The supplied CourseKey is of the wrong type, so it can't possibly be stored in this modulestore.
The supplied CourseKey is of the wrong type, so it can't possibly be stored in this modulestore.
The supplied CourseKey is of the wrong type, so it can't possibly be stored in this modulestore.
The supplied locator is of the wrong type, so it can't possibly be stored in this modulestore.
The supplied CourseKey is of the wrong type, so it can't possibly be stored in this modulestore.
if this looks in cache rather than fresh fetches, then it will probably not detect  actual change b/c the descriptor and cache probably point to the same objects
find course_index entry if applicable and structures entry
copy the structure and modify the new one
reconstruct the new_item from the cache
don't version the structure as create_item handled that already.
add new block as child and update parent's version
if the parent hadn't been previously changed in this bulk transaction, indicate that it's  part of the bulk transaction
db update
don't need to update the index b/c create_item did it for this version
don't copy assets until we create the course in case something's awry
build from inside out: definition, structure, index entry  if building a wholly new structure  create new definition and structure
check metadata
if updated, rev the structure
source_version records which revision a block was copied from. In this method, we're updating  the block, so it's no longer a direct copy, and we can remove the source_version reference.
fetch and return the new item--fetching is unnecessary but a good qc step
If no parent, then nothing to inherit.
decache pending children field settings
update the index entry if appropriate
fetch and return the new item--fetching is unnecessary but a good qc step
get the destination's index, and source and destination structures.
brand new course
update the db
Update the edit info:
Update the edit_info:
Return usage locators for all the new children:
Now clone block_key to new_block_key:  Note that new_block_info now points to the same definition ID entry as source_block_info did  Inherit the Scope.settings values from 'fields' to 'defaults'
And add new_block_key to the list of new_parent_block_key's new children:
Update the children of new_parent_block_key
The supplied UsageKey is of the wrong type, so it can't possibly be stored in this modulestore.
remove the source_version reference
update index if appropriate and structures
update the index entry if appropriate
Make sure we want to delete all of the child's parents  before slating it for deletion
this is the only real delete in the system. should it do something else?
the currently passed down values take precedence over any previously cached ones  NOTE: this should show the values which all fields would have if inherited: i.e.,  not set to the locally defined value but to value set by nearest ancestor who sets it
update the inheriting w/ what should pass to children
here's where we need logic for looking up in other structures when we allow cross pointers  but it's also getting this during course creation if creating top down w/ children set or  migration where the old mongo published had pointers to privates
Assets should be pre-sorted, so add them efficiently without sorting.  extend() will raise a ValueError if the passed-in list is not sorted.
update index if appropriate and structures
update the index entry if appropriate
Determine course key to use in bulk operation. Use the first asset assuming that  all assets will be for the same course.
update index if appropriate and structures
update the index entry if appropriate
Form an AssetMetadata.
Generate a Mongo doc from the metadata and update the course asset info.
update index if appropriate and structures
update the index entry if appropriate
update the index entry if appropriate
if this was taken from cache, then its fields are already converted
explicitly_set_fields_by_scope converts to json; so, avoiding it  the existing partition_fields_by_scope works on a dict not an xblock
perhaps replace by fixing the views or Field Reference*.from_json to return a Key
Extend the block's new edit_info with any extra edit_info fields from the source (e.g. original_usage):
If the block we are copying from was itself a copy, then just  reference the original source, rather than the copy.
any other value is hopefully only cloning or doing something which doesn't want this value add
version_agnostic b/c of above assumption in docstring
Publish both the child and the parent, if the child is a direct-only category
Libraries don't yet have draft/publish support:
check if the draft has changed since the published was created
check the children in the draft
create a new versioned draft structure
remove the block and its descendants from the new structure
This is a no-op in Split since a draft version of the data always remains
There is no published version xblock container, e.g. Library
hardcode course root block id
do the import
pylint: disable=protected-access
Always log cache misses, because they are unexpected
1 = Fastest (slightly larger results)
Stuctures are immutable, so we set a timeout of "never"
Set a write concern of 1, which makes writes complete successfully to the primary  only before returning. Also makes pymongo report write errors.
Always log cache misses, because they are unexpected
last_update not only tells us when this course was last updated but also helps  prevent collisions
set course_id attribute to avoid problems with subsystems that expect  it here. (grading, for example)
usage_key is either a UsageKey or just the block_key. if a usage_key,
trust the passed in key to know the caller's expectations of which fields are filled in.  particularly useful for strip_keys so may go away when we're version aware
look in cache
deeper than initial descendant fetch or doesn't exist
most recent retrieval is most likely the right one for next caller (see comment above fn)
If no usage id is provided, generate an in-memory id
If no definition id is provide, generate an in-memory id
Construct the Block Usage Locator:
for the situation if block_data has no asides attribute  (in case it was taken from memcache)
decache any pending field settings
If this is an in-memory block, store it in this system
pylint: disable=protected-access
a LocalId indicates that this block hasn't been persisted yet, and is instead stored  in-memory in the local_modules dictionary.
id is a BlockUsageLocator, def_id is the definition's guid
deepcopy so that manipulations of fields does not pollute the source
a decorator function for field values (to be called when a field is accessed)
load the definition to see if it has the aside_fields
load the field, if needed
return the "decorated" field value
handle any special cases
set the field
handle any special cases
delete the field value
handle any special cases
it's not clear whether inherited values should return True. Right now they don't  if someone changes it so that they do, then change any tests of field.name in xx._field_data
If not, try inheriting from a parent, then use the XBlock type's normal default value:
Things w/ these categories should never be marked as version=DRAFT
cache the branch setting on a local thread to support a multi-threaded environment
first check the thread-local cache  return the default value
We remove the branch, because publishing always means copying from draft to published
create the course: set fields to explicitly_set for each scope, id_root = new_course_locator, master_branch = 'production'
create a new version for the drafts
clean up orphans in published version: in old mongo, parents pointed to the union of their published and draft  children which meant some pointers were to non-existent locations in 'direct'
this only occurs if the parent was also awaiting adoption: skip this one, go to next  find index for module: new_parent may be missing quite a few of old_parent's children
sibling may move cursor
accumulate tuples of draft_modules and their parents in  this list:
if module has no parent, set its parent_url to `None`
ensure module has "xml_attributes" attr
Don't try to export orphaned items  and their descendents
change all of the references inside the course to use the xml expected key type w/o version & branch
Make any needed adjustments to the root node.
Process extra items-- drafts, assets, etc
Any last pass adjustments
export the static tabs
export the custom tags
export the course updates
export the 'about' data (e.g. overview, etc.)
Use url_name for split mongo because course_run is not used when loading policies.
export the grading policy
export the static assets
Create the Library.xml file, which acts as the index of all library contents.
don't change the children field but do recurse over the children
export content fields other then metadata and data in json format in current directory
Save the data in a multi-level dict - { phase1: { amount1: {ms1->ms2: duration, ...}, ...}, ...}.
Output comparison of each phase to a different table.
Add the table title and the table.
Name of the asset metadata XML schema definition file.
Characters used in name generation below.
Now - validate the XML against the XSD.
The dependency below needs to be installed manually from the development.txt file, which doesn't  get installed during unit tests!
Number of assets saved in the modulestore per test run.
Use only this course in asset metadata performance testing.
A list of courses to test - only one.
pylint: disable=invalid-name
Path where generated asset file is saved.
Path where asset XML schema definition file is located.
Use this attribute to skip this test on regular unittest CI runs.
First, make the fake asset metadata.
Use this attr to skip this test on regular unittest CI runs.
First, make the fake asset metadata.
More correct would be using the AssetManager.find() - but since the test  has created its own test modulestore, the AssetManager can't be used.
Use this attribute to skip this test on regular unittest CI runs.
First, make the fake asset metadata.
Ensure the asset collection exists.
List of names of computed fields on xmodules that are of type usage keys.  This list can be used to determine which fields need to be stripped of  extraneous usage key data when entering/exiting modulestores.
both DRAFT and PUBLISHED versions are queried, with preference to DRAFT versions
only DRAFT versions are queried and no PUBLISHED versions
only PUBLISHED versions are queried and no DRAFT versions
all revisions are queried
user ID to use for all management commands
user ID to use for primitive commands
user ID to use for tests that do not have a django user available
user ID for automatic update by the system
the relevant type of bulk_ops_record for the mixin (overriding classes should override  this variable)
Increment the number of active bulk operations (bulk operations  on the same course can be nested)
If this is the highest level bulk operation, then initialize it
If no bulk op is active, return
Send the pre-publish signal within the context of the bulk operation.  Writes performed by signal handlers will be persisted when the bulk  operation ends.
If this wasn't the outermost context, then don't close out the  bulk operation.
The bulk op has ended. However, the signal tasks below still need to use the  built-up bulk op information (if the signals trigger tasks in the same thread).  So re-nest until the signals are sent.
Signals are sent. Now unnest and clear the bulk op for good.
We remove the branch, because publishing always means copying from draft to published
For details, see caching_descriptor_system.py get_subtree_edited_by/on.
Guid for the structure which previously changed this XBlock.  (Will be the previous value of 'update_version'.)
Guid for the structure where this XBlock got its current field values.  May point to a structure not in this structure's history (e.g., to a draft  branch from which this version was published).
Datetime when this XBlock's fields last changed.  User ID which changed this XBlock last.
If this block has been copied from a library using copy_from_template,  these fields point to the original block in the library, for analytics.
Has the definition been loaded?
Contains the Scope.settings and 'children' field values.  'children' are stored as a list of (block_type, block_id) pairs.
XBlock type ID.
DB id of the record containing the content of this XBlock.
Scope.settings default values copied from a template block (used e.g. when  blocks are copied from a library to a course)
Additional field data that stored in connected XBlockAsides
EditInfo object containing all versioning/editing data.
Add new metadata sorted into the list.
Replace existing metadata.
Assets should be pre-sorted, so add them efficiently without sorting.  extend() will raise a ValueError if the passed-in list is not sorted.
Add assets of all types to the sorted list.
Add assets of a single type to the sorted list.
No limit on the results.
Flip the indices and iterate backwards.
Lazily create a sorted list if not already created.
pylint: disable=logging-format-interpolation
If an XBlock is passed-in, just match its fields.
BlockData is an object - compare its attributes in dict form.
note isn't handling any other things in the dict other than in
note isn't handling any other things in the dict other than nin
pylint: disable=invalid-name
temporary parms to enable backward compatibility. remove once all envs migrated  allow lower level init args to pass harmlessly
default is to say yes by not raising an exception
clone a default 'about' overview module as well
copy the assets
delete the assets
Backwards compatibility for prod systems that refererence  xmodule.modulestore.mongo.DraftMongoModuleStore
return the published version if ModuleStoreEnum.RevisionOption.published_only is requested
if the item is direct-only, there can only be a published version
return the draft version (without any fallback to PUBLISHED) if DRAFT-ONLY is requested
could use a single query wildcarding revision and sorting by revision. would need to  use prefix form of to_deprecated_son  first check for a draft version  otherwise, fall back to the published version
Note: does not need to inform the bulk mechanism since after the course is deleted,  it can't calculate inheritance anyway. Nothing is there to be dirty.  delete the assets
delete all of the db records for the course
check to see if the source course is actually there
clone the assets
repoint children
create a query to find all items in the course that have the given location listed as a child
find all the items that satisfy the query
filters out items that are not already in draft_items
return the new draft item (does another fetch)  get_item will wrap_draft so don't call it here (otherwise, it would override the is_draft attribute)
verify input conditions: can only convert to draft branch; so, verify that's the setting
ensure we are not creating a DRAFT of an item that is direct-only
delete the old PUBLISHED version if requested
convert the subtree using the original item as the root
ignore any descendants which are already draft
ignore the exception only if allow_not_found is True and  the item that wasn't found is the one that was passed in  we make this extra location check so we do not hide errors when converting any children to draft
single parent can have 2 versions: draft and published  get draft parents only while deleting draft module
recompute (and update) the metadata inheritance tree which is cached
handle child does not exist w/o killing publish
publish the children first
ignore noop attempt to publish something that can't be or isn't currently draft
try to find the originally PUBLISHED version, if it exists
update the published (not draft) item (ignoring that item is "draft"). The published  may not exist; (if original_published is None); so, allow_not_found
verify input conditions
ensure we are not creating a DRAFT of an item that is direct-only
first get non-draft in a round-trip
now we have to go through all drafts and replace the non-draft  with the draft. This is because the semantics of the DraftStore is to  always return the draft - if available
does non-draft exist in the collection  if so, replace it
convert the dict - which is used for look ups - back into a list
sort order that returns DRAFT items first
sort order that returns PUBLISHED items first
at module level, cache one instance of OSFS per filesystem root.
cdodge: other Systems have a course_id attribute defined. To keep things consistent, let's  define an attribute here as well, even though it's None
load the module and apply the inherited metadata
try looking it up just-in-time (but not if we're working with a detached block).
parent container pointers don't differentiate between draft and non-draft  so when we do the lookup, we should do so with a non-draft location
Convert the serialized fields values in self.cached_metadata  to python values
decache any computed pending field settings
"old" mongo does support asides yet
don't allow wildcards on revision, since public is set as None, so  its ambiguous between None as a real value versus None=wildcard
ensure it starts clean
If no name is specified for the asset metadata collection, this name is used.
Set a write concern of 1, which makes writes complete successfully to the primary  only before returning. Also makes pymongo report write errors.
Collection which stores asset metadata.
drop the assets
just get the inheritable metadata since that is all we need for the computation  this minimizes both data pushed over the wire
call out to the DB
it's ok to keep these as deprecated strings b/c the overall cache is indexed by course_key and this  is a dictionary relative to that course
now go through the results and order them by the location url  manually pick it apart b/c the db has tag and we want as_published revision regardless
now traverse the tree and compute down the inherited metadata
if not in subsystem, or we are on force refresh, then we have to compute
now write out computed tree to caching subsystem (e.g. memcached), if available
below is done for side effects when runtime is None
Load all children by id. See  http://www.mongodb.org/display/DOCS/Advanced+QueriesAdvancedQueries-%24or  for or-query syntax
If depth is None, then we just recurse until we hit all the descendents
if we are loading a course object, if we're not prefetching children (depth != 0) then don't  bother with the metadata inheritance
create any other necessary things as a side effect
@Cale, should this use LocalId like we do in split?
We're loading a descriptor, so student_id is meaningless  We also don't have separate notions of definition and usage ids yet,  so we use the location for both.
decache any pending field settings from init
attach to parent if given
See http://www.mongodb.org/display/DOCS/Updating for  atomic update syntax
update the edit info of the instantiated xblock
recompute (and update) the metadata inheritance tree which is cached  fire signal that we've written to DB
get bulk_record once rather than for each iteration
create a query with tag, org, course, and the children field set to the given location
if only looking for the PUBLISHED parent, set the revision in the query to None
query the collection, sorting by DRAFT first  no parents were found
no actual parent found
should never have multiple PUBLISHED parents
return the single PUBLISHED parent
there could be 2 different parents if    (1) the draft item was moved or    (2) the parent itself has 2 versions: DRAFT and PUBLISHED   if there are multiple parents with version PUBLISHED then choose from non-orphan parents
since we sorted by SORT_REVISION_FAVOR_DRAFT, the 0'th parent is the one we want
don't disclose revision outside modulestore
It would be nice to change this method to return UsageKeys instead of the deprecated string.
the course's run == its name. It's the only xblock for which that's necessarily true.
This record is in the old course assets format.  Ensure that no data exists before updating the format.  Update the format to a dict.
Pass back wrapped 'assets' dict with the '_id' key added to it for document update purposes.
Build an update set with potentially multiple embedded fields.
Update the document.
Update the document.
Form an AssetMetadata.
Generate a Mongo doc from the metadata and update the course asset info.
Update the document.
Using the course_id, find the course asset metadata document.  A single document exists per course to store the course asset metadata.  When deleting asset metadata, if a course's asset metadata is not present, no big deal.
Because we often scan for all category='course' regardless of the value of the other fields:
Because lms calls get_parent_locations frequently (for path generation):
To allow prioritizing draft vs published material
Some overrides that still need to be implemented by subclasses
pylint: disable=unused-import
OS X "companion files". See  http://www.diigo.com/annotated/0c936fda5da4aa1159c189cea227e174  Not a 'hidden file', then re-raise exception
strip away leading path from the name
Check extracted contentType in list of all valid mimetypes
first let's save a thumbnail so we can get back a thumbnail location
then commit the content
store the remapping information which will be needed  to subsitute in the module data
If we're going to remap the ID, then we can only do that with  a single target
first pass to find everything in /static/
Construct the asset key.
Now add all asset metadata to the modulestore.
Quick scan to get course module as we need some info from there.  Also we need to make sure that the course module is committed  first into the store
for old-style xblock where this was actually linked to kvs
tolerate same child occurring under 2 parents such as in  ContentStoreTest.test_image_import
This bulk operation wraps all the operations to populate the published branch.  Retrieve the course itself.
Import all static pieces.
Import asset metadata stored in XML.
Import all children
STEP 1: find and import course module
Note that dest_course_id will be in the format for the default modulestore.
store.has_course will return the course_key in the format for the modulestore in which it was found.  This may be different from dest_course_id, so correct to the format found.
The branch setting of published_only forces an overwrite of all draft modules  during the course import.
Importing the drafts potentially triggered a new structure version.  If so, the HEAD version_guid of the passed-in courselike will be out-of-date.  Fetch the course to return the most recent course version.
remove any export/import only xml_attributes  which are used to wire together draft imports
we want to convert all 'non-portable' links in the module_data  (if it is a string) to portable strings (e.g. /static/)
create a new 'System' object which will manage the importing
IMPORTANT: Be sure to update the module location in the NEW namespace  Update the module's location to DRAFT revision  We need to call this method (instead of updating the location directly)  to ensure that pure XBlock field data is updated correctly.
make sure our parent has us in its list of children  this is to make sure private only modules show up  in the list of children since they would have been  filtered out from the non-draft store export.
IMPORTANT: Be sure to update the parent in the NEW namespace
Sort drafts by `index_in_children_list` attribute.
everything is allowed
handle deprecated old attr
translate obsolete attr
now cache it on module where it's expected
get all modules of parent_category
check all data source path information
Adding the course_id as passed in for later reference rather than  having to recombine the org/course/url_name
tags that really need unique names--they store (or should store) state.
We're about to re-hash, in case something changed, so get rid of the tag_ and hash  append the hash of the content--the first 12 bytes should be plenty.
Fallback if there was nothing we could use:  Don't log a warning--we don't need this in the log.  Do  put it in the error tracker--content folks need to see it.
Normally, we don't want lots of exception traces in our logs from common  content problems.  But if you're debugging the xml loading code itself,  uncomment the next line.  exc_info=True
parent is alphabetically least
After setting up the descriptor, save any changes that we have  made to attributes on the descriptor to the underlying KeyValueStore.
id_generator is ignored, because each ImportSystem is already local to  a course, and has it's own id_generator already in place
All field data will be stored in an inheriting field data.
Special-case code here, since we don't have a location for the  course before it loads.  So, make a tracker to track load-time errors, then put in the right  place after the course loads and we have its location
Didn't load course.  Instead, save the errors elsewhere.
Parent XML should be something like 'library.xml' or 'course.xml'
VS[compat]: remove once courses use the policy dirs.
VS[compat] : 'name' is deprecated, but support it for now...
If we fail to load the course, then skip the rest of the loading steps
NOTE: The descriptors end up loading somewhat bottom up, which  breaks metadata inheritance via get_children().  Instead  (actually, in addition to, for now), we do a final inheritance pass  after we have the course descriptor.
now import all pieces of course_info which is expected to be stored  in <content_dir>/info or <content_dir>/info/<url_name>
now import all static tabs which are expected to be stored in  in <content_dir>/tabs or <content_dir>/tabs/<url_name>
Have to use SlashSeparatedCourseKey here because it makes sure the same format is  always used, preventing duplicate keys.
then look in a override folder based on the course run
ignore this exception  only new exported courses which use content fields other than 'metadata' and 'data'  will have this file '{dirname}.{field_name}.json'
We're loading a descriptor, so student_id is meaningless  We also don't have separate notions of definition and usage ids yet,  so we use the location for both
VS[compat]:  Hack because we need to pull in the 'display_name' for static tabs (because we need to edit them)  from the course policy
Support for passing a list as the name qualifier
here just to quell the abstractmethod. someone could write the impl if needed
return ModuleStoreEnum.Type.xml
if set, invalidate '_unwrapped_field_data' so it will be reset  the next time it will be called  pylint: disable=protected-access
here just to quell the abstractmethod. someone could write the impl if needed
This configuration must be executed BEFORE any additional Django imports. Otherwise, the imports may fail due to  Django not being configured properly. This mostly applies to tests.
We may not always have the request_cache module available
We also may not always have the current request user (crum) module available
A singleton instance of the Mixed Modulestore
Fall back to the default Django translator if the XBlock translator is not found.
get mapping information which is defined in configurations
compare hostname against the regex expressions set of mappings which will tell us which branch to use
leaving this in code structured in closure-friendly format b/c we might eventually cache this (again)  using request_cache
To keep track of where we came from, the work queue has  tuples (location, path-so-far).  To avoid lots of  copying, the path-so-far is stored as a lisp-style  list--nested hd::tl tuples, and flattened at the end.
get_parent_location raises ItemNotFoundError if location isn't found
print 'Processing loc={0}, path={1}'.format(next_usage, path)  Found it!  Orphaned item.
otherwise, add parent locations at the end
pull out the location names  Figure out the position
Load the course, but don't make error modules.  This will succeed,  but will record the errors.
Look up the errors during load. There should be none.
now set toy course to share the wiki with simple course
XML store allows published_only branch setting
XML store does NOT allow draft_preferred branch setting  verify that the above context manager raises a ValueError
ensure it's still a child of the other parent even tho it doesn't claim the other parent as its parent  children rather than get_children b/c the instance returned by get_children != shared_item
These tests won't work with courses, since they're creating blocks inside courses
Verify course summaries
Verify that all course summary objects have the required attributes.
Verify fetched accessible courses list is a list of CourseSummery instances
N.B. This block is being left as an orphan in old-mongo. This test will  fail when that is fixed. At that time, this condition should just be removed,  as SplitMongo and OldMongo will have the same semantics.
pass a copy of the old setting since the migration modifies the given setting
check whether the configuration is encapsulated within Mixed.
check whether the stores are in an ordered list
exclude split when comparing old and new, since split was added as part of the migration
compare each store configured in mixed
make sure there is no migration done on an already updated config
define attrs which get set in initdb to quell pylint
create chapter
try an unknown mapping, it should be the 'default' store
unset mappings
try negative cases
verify that an error is raised when the revision is not valid
try negative cases
verify that an error is raised when the revision is not valid
verify that an error is raised when the revision is not valid
Check that orphans are not found
Add an orphan to test course
Check that now an orphan is found
Check now `get_items` retrieves an extra item added above which is an orphan.
Check now `get_items` with `include_orphans` kwarg does not retrieves an orphan block.
Create dummy direct only xblocks
Check that neither xblock has changes
Create a dummy component to test against
Not yet published, so changes are present
Publish and verify that there are no unpublished changes
Change the component, then check that there now are changes
Publish and verify again
Create a dummy component to test against
Not yet published, so changes are present
Publish and verify that there are no unpublished changes
Publish and verify again
Create a dummy component to test against
Not yet published, so changes are present
Publish and verify that there are no unpublished changes
Discard changes and verify that there are no changes
Change the component, then check that there now are changes
Verify that changes are present
publish vertical changes
Discard changes and verify that there are no changes
Delete the component and verify that the unit has changes
publish sequential changes
delete vertical and check sequential has no changes
Publish the vertical units
Verify that there are no unpublished changes
Change the child
Publish the unit with changes
Verify that there are no unpublished changes
Verify that there are no unpublished changes
Verify that ancestors have changes
Publish one child
Verify that ancestors still have changes
Publish the other child
Verify that ancestors now have no changes
Test that the ancestors don't have changes
Create a new child and attach it to parent
Verify that the ancestors now have changes
Verify that ancestors now have no changes
Verify that there are no changes
Change the child
Verify that both parent and child have changes
Check the parent for changes should return True and not throw an exception
verify it's gone  verify it's gone from published too
verify that an error is raised when the revision is not valid
create a static tab of the course
now check that the course has same number of children
Now load with get_library and make sure it works:
Clear the mappings so we can test get_library code path without mapping set:
publish the course
make drafts of verticals
move child problem_x1a_1 to vertical_y1a
publish the course
make draft of vertical
delete child problem_y1a_1
Note: The following could be an unexpected result, but we want to avoid an extra database call
create parented children
add another parent (unit) "vertical_x1b" for problem "problem_x1a_1"
convert first parent (unit) "vertical_x1a" of problem "problem_x1a_1" to draft
now problem "problem_x1a_1" has 3 parents [vertical_x1a (draft),  vertical_x1a (published), vertical_x1b (published)]  check that "get_parent_location" method of draft branch returns first  published parent "vertical_x1a" without raising "AssertionError" for  problem location revision
each iteration has different find count, pop this iter's find count
Orphaned items should not be found.
delete leaf problem (will make parent vertical a draft)
Change display name of problem and update just it (so parent remains published)
It does not discard the child vertical, even though that child is a draft (with no published version)
create parented children
detached items (not considered as orphans)
create parented children
Test Mongo wiki
unpublish
make sure draft version still exists
Private -> Public
Public -> Private
Private -> Public
Public -> Draft with NO changes
Verify that all nodes were last edited in the past by create_user
Change the component, then check that there now are changes
but child didn't change
Change the child
Verify that child was last edited between after_create and after_edit by edit_user
Verify that ancestors edit info is unchanged, but their subtree edit info matches child
Verify that others have unchanged edit info
Create a dummy component to test against
Store the current edit time and verify that user created the component
Change the component
Verify the ordering of edit times and that dummy_user made the edit
Create a dummy component to test against
Store the current time, then publish
Verify the time order and that publish_user caused publication
test create_course to make sure we are autopublishing
test update_item of direct-only category to make sure we are autopublishing
test create_child of NOT direct-only category to make sure we aren't autopublishing
test create_item of NOT direct-only category to make sure we aren't autopublishing
test update_item of NOT direct-only category to make sure we aren't autopublishing
verify initial state - initially, we should have a wiki for the Mongo course
set Mongo course to share the wiki with simple course
now mongo_course should not be retrievable with old wiki_slug
check the display_name of the problem
there should be only 1 problem with the expected_display_name
verify Draft problem
PUBLISH the problem
verify Published problem
verify Draft-preferred
EDIT name
verify Draft problem has new name
verify Published problem still has old name  there should be no published problems with the new name
PUBLISH the problem
verify Published problem has new name  there should be no published problems with the old name
initialize the mixed modulestore
initialize the mixed modulestore
initialize the mixed modulestore
initialize the mixed modulestore
pylint: disable=protected-access
Course creation and publication should fire the signal
Course creation and publication should fire the signal
Course creation and publication should fire the signal
Test a draftable block type, which needs to be explicitly published, and nest it within the  normal structure - this is important because some implementors change the parent when adding a  non-published child; if parent is in DIRECT_ONLY_CATEGORIES then this should not fire the event
'units' and 'blocks' are draftable types
Course creation and publication should fire the signal
Course creation and publication should fire the signal
'units' and 'blocks' are draftable types
Create a course
Delete the course
Verify that the signal was emitted
No orphans in course
No published oprhans after delete, except  in old mongo, which still creates orphans
No orphans in course
No published orphans after delete, except  in old mongo, which still creates them
Verify that the imported block still is a draft, i.e. has changes.
Retrieve the published block and make sure it's published.
Get the published xblock from the imported course.  Verify that it still is published, i.e. has no changes.
Retrieve the published block and make sure it's published.
Get the published xblock from the imported course.  Verify that the published block still has a draft block, i.e. has changes.
Verify that the changes in the draft vertical still exist.
create sequential
create vertical - don't publish it!
Get the published xblock from the imported course.  Verify that the published block still has a draft block, i.e. has changes.
create sequential
Export the course - then import the course export.
Verify that the changes in the draft unit still exist.
create sequential
Export the course - then import the course export.
Verify that the published changes exist in the published unit.
create a new block and ensure its aside magically appears with the right fields
now update the values
update the values the second time
export course to xml
and restore the new one from the exported xml
export course to xml
and restore the new one from the exported xml
check that aside for the new chapter was exported/imported properly
the first aside item
the second aside item
create new item with two asides
initialize the mixed modulestore
after clone get connected aside and check that it was cloned correctly
remove item
create item again
check that aside has default values
Private -> Public
Public -> Private
We have to give a model for Factory.  However, the class that we create is actually determined by the category  specified in the factory
Pass the metadata just as field=value pairs
This error is raised if the caller hasn't provided either parent or parent_location  In this case, we'll just return the default parent_location
This code was based off that in cms/djangoapps/contentstore/views.py
replace the display name with an optional parameter passed in from the caller
pylint: disable=missing-docstring
verify the counter actually worked by ensuring we have counted greater than (or equal to) the minimum calls
now verify the number of actual calls is less than (or equal to) the expected maximum
Snippet of what would be in the django settings envs file
split requires the course to be created separately from creating items
Inherit the vertical and the problem from the library into the course:
Check that when capa modules are copied, their "markdown" fields (Scope.settings) are removed.  (See note in split.py:copy_from_template())
Override the display_name and weight:
Test that "Any previously existing children of `dest_usage`  that haven't been replaced/updated by this copy_from_template operation will be deleted."
Reload source_course since we need its branch and version to use copy_from_template:
Check that the auto-publish blocks have been published:  We can't use has_changes because it includes descendants
add direct children
Don't save assets 5 and 6.
Find existing asset metadata.
Find existing asset metadata.
Find asset metadata from non-existent course.
pylint: disable=bad-continuation
pylint: disable=bad-continuation
Save 'em.
pylint: disable=bad-continuation
Save 'em.
don't create django dependency; so, duplicates common.py in envs
drop the modulestore to force re init
Should have gotten 3 draft courses.
should have gotten 1 draft courses
should have gotten 2 draft courses
although this is already covered in other tests, let's  also not pass in org= parameter to make sure we get back  3 courses
check dates and graders--forces loading of descriptor
check dates and graders--forces loading of descriptor
first and second problem may show as same usage_id; so, need to ensure their histories are right
use the default cache, since the `course_structure_cache`  is a dummy cache during testing
make sure we clear the cache before every test...  ... and after
make a new course:
force get_cache to return the default cache so we can test  its caching behavior
when cache is warmed, we should have one fewer mongo call
now make sure that you get the same structure
if the cache isn't configured, we expect to have to make  another mongo call here if we want the same course structure
now make sure that you get the same structure
Since the test is using the dummy cache, it's not actually caching  anything
now make sure that you get the same structure
positive tests of various forms
not a course obj
check dates and graders--forces loading of descriptor
try to look up other branches
check that course version changed and course's previous is the other one
ensure trying to continue the old one gives exception
reorder children
now begin the test
delete a subtree  check subtree
Clean up the data so we don't break other tests which apparently expect a particular state
create 3 courses before bulk operation
now get_courses
unset on parent, retrieve child, verify unset
pylint: disable=star-args
pylint: disable=unused-argument, missing-docstring
used to create course subtrees in ModuleStoreTestCase.create_test_course  adds to self properties w/ the given block_id which hold the UsageKey for easy retrieval.  fields is a dictionary of keys and values. sub_tree is a collection of BlockInfo
pylint: disable=star-args
pylint: disable=unused-argument
Set the XBlock's location
Explicitly set the content and settings fields
Check the XBlock's location
Check the values of the fields.  The content and settings fields should be preserved
Expect that these fields are marked explicitly set
Set the XBlock's location
Do NOT set any values, so the fields should use the defaults
Check the values of the fields.  The content and settings fields should be the default values
The fields should NOT appear in the explicitly set fields
Set the XBlock's location
Inherited fields should NOT be explicitly set
Set the XBlock's location
Update location
Check the XBlock's location
Expect these fields pass "is_set_on" test
Explicitly list the courses to load (don't want the big one)
connect to the db
also test a course with no importing of static content
also import a course under a different course_id (especially ORG)
Destroy the test db.
now toy_course should not be retrievable with old wiki_slug
This will raise if the course image is missing
Retrieve the block and verify its fields
Clean up the data so we don't break other tests which apparently expect a particular state
Confirm that no specified asset collection name means empty asset metadata.
Confirm that invalid course key raises ItemNotFoundError
pylint: disable=W0613
don't use these 2 class vars as they restore behavior once the tests are done
since MongoModuleStore and MongoContentStore are basically assumed to be together, create this class  as well
ensure deleting a non-existent file is a noop
ensure it didn't remove any from other course
check that we return the expected urls
Writing a definition when no bulk operation is active should just  call through to the db_connection.
Writing a course index when no bulk operation is active should just call  through to the db_connection
Calling _end_bulk_operation without a corresponding _begin...  is a noop
If no definitions to get, then get_definitions() should *not* have been called.
An extra import write occurs in the first Split import due to the mismatch between  the course id and the wiki_slug in the test XML course. The course must be updated  with the correct wiki_slug during import.
First, import a course.
Read the fields on each block in order to ensure each block and its definition is loaded.
should find the course with exact locator
replace value for one of the keys  add a character at the end  add a character in the beginning
Set up a temp directory for storing filesystem content created during import
Delete the created directory on the filesystem
Set up a temp directory for storing filesystem content created during import
Delete the created directory on the filesystem
Make the modulestore creation function just return the already-created modulestores
Generate a fake list of stores to give the already generated stores appropriate names
Mongo modulestore beneath mixed.  Returns the entire collection with *all* courses' asset metadata.
Split modulestore beneath mixed.  Split stores all asset metadata in the structure collection.
VersioningModulestoreBuilder(),   FUTUREDO: LMS-11227
There are 12 created items and 7 parent updates  create course: finds: 1 to verify uniqueness, 1 to find parents  sends: 1 to create course, 1 to create overview
verify status  however, children are still draft, but I'm not sure that's by design
delete the draft version of the discussion
Create a list of all verticals for convenience.
Create a list of all html units for convenience.
For convenience, maintain a list of (block_type, block_id) pairs for all verticals/units.
Course block database is keyed on (block_type, block_id) pairs.  It's built during the course creation below and contains all the parent/child  data needed to check the OLX.
Form the checked attributes based on the block type.
Draft items are expected to have certain XML attributes.
If children exist, construct regular expressions to check them.  Grab the type of the first child as the type of all the children.  Construct regex out of all the child_ids that are included.
Construct the contentstore for storing the first import  Construct the modulestore for storing the first import (using the previously created contentstore)  Create the course.
Export the course.
MODULESTORE_DIFFERENCE:  In old Mongo, you can successfully publish an item whose parent  isn't published.
MODULESTORE_DIFFERENCE:  In Split, you cannot publish an item whose parents are unpublished.  Split will raise an exception when the item's parent(s) aren't found  in the published branch.
Ensure that both groups of verticals and children are drafts in the exported OLX.
Publish both vertical03 and vertical 04.
Ensure that the published verticals and children are indeed published in the exported OLX.  Ensure that the untouched vertical and children are still untouched.
The unit is a draft.  Since there's no published version, attempting an unpublish throws an exception.
The vertical is a draft.  Since there's no published version, attempting an unpublish throws an exception.
MODULESTORE_DIFFERENCE: This first line is different between old Mongo and Split for verticals.  Old Mongo deletes the draft vertical even when published_only is specified.
MODULESTORE_DIFFERENCE: This first line is different between old Mongo and Split for verticals.  Split does not delete the draft vertical when a published_only revision is specified.
Sequentials are auto-published.
Chapters are auto-published.
At first, no vertical is published.  Now, without publishing anything first, revert the same vertical to published.  Since no published version exists, an exception is raised.
At first, no vertical is published.  Then publish a vertical.  The vertical will be published.  Now, revert the same vertical to published.  Basically a no-op - there was no draft version to revert.
At first, no vertical is published.  Then publish a vertical.  The vertical will be published.
The vertical now has a draft -and- published version.  Now, revert the same vertical to published.  The draft version is now gone.
allow for additional options that can be keyed on a name, e.g. 'trashcan'
Do not create the modulestore if it does not exist.
All store requests now go through mixed  Use this modulestore if you specifically want to test mongo and not a mocked modulestore.
All store requests now go through mixed  Use this modulestore if you specifically want to test split-mongo and not a mocked modulestore.
Tell Django to clean out all databases, not just default
Now yield to allow the test class to run its setUpClass() setup code.  Now call the base class, which calls back into the test class's setUpTestData().
OverrideFieldData.provider_classes is always reset to `None` so  that they're recalculated for every test
Tell Django to clean out all databases, not just default
When testing CCX, we should make sure that  OverrideFieldData.provider_classes is always reset to `None` so  that they're recalculated for every test
Create the user so we can log them in.
Staff has access to view all courses
copy the old configurations into the new settings
Convert from dict, if needed
convert old-style (unordered) dict to (an ordered) list
move the found store to the top of the list
it'd be useful to add init args such as support_deprecated, force_deprecated
don't call super as base.BaseField.to_mongo calls to_python() for some odd reason
remove version and branch, by default
call the decorated function
strip the return value
replace all named pointers to the store into actual pointers
return the default store
Check if course is indeed unique. Save it in result if unique
filter out ones which were fetched from earlier stores but locations may not be ==  course is indeed unique. save it in result
filter out ones which were fetched from earlier stores but locations may not be ==  library is indeed unique. save it in result
If there is a mapping that match this org/course/run, use that
Otherwise, return the key created by the default store
Courses in the same modulestore can be handled by the modulestore itself.
first make sure an existing course doesn't already exist in the mapping
create the course
add new course to the mapping
first make sure an existing course/lib doesn't already exist in the mapping
create the library
add new library to the mapping
for a temporary period of time, we may want to hardcode dest_modulestore as split if there's a split  to have only course re-runs go to split. This code, however, uses the config'd priority
the super handles assets and any other necessities
drop database if the store supports it (read-only stores do not)
could be done in parallel threads if needed
return the thread-local cache, if found
else return the default store
read in and convert to XML
insert  new XML into tree in place of include
Log error  tell the tracker
Prepend _ so that sass just includes the files into a single file
assume all XML files are persisted as utf-8.
Support older serialized version.
Extension to append to filename paths
VS[compat].  Backwards compatibility code that can go away after  importing 2012 courses.  A set of metadata key conversions that we want to make
VS[compat] -- remove the below attrs once everything is in the CMS  Used for storing xml attributes between import and export, for roundtrips
Add info about where we are, but keep the traceback
Add the attributes from the pointer node
VS[compat].  Remove after all key translations done
don't load these
Store unknown attributes coming from policy.json  in such a way that they will export to xml unchanged
Note: removes metadata.
VS[compat] -- make Ike's github preview links work in both old and  new file layouts  new style -- contents actually at filepath
Set/override any metadata specified by policy
We're loading a descriptor, so student_id is meaningless
Set the tag on both nodes so we get the file path right.
Special case for course pointers:  add org and course attributes on the pointer tag
Shim from from_xml to the parse_xml defined in XmlParserMixin.  This only exists to satisfy subclasses that both:     a) define from_xml themselves     b) call super(..).from_xml(..)
Shim from export_to_xml to the add_xml_to_node defined in XmlParserMixin.  This only exists to satisfy subclasses that both:     a) define export_to_xml themselves     b) call super(..).export_to_xml(..)
Type for assets uploaded by a course author in Studio.
Asset section XML tag for asset metadata as XML.
Individual asset XML tag for asset metadata as XML.
Top-level directory name in exported course XML which holds asset metadata.
Filename of all asset metadata exported as XML.
created_by, created_by_email, and created_on should only be set here.
An AssetLocator is constructed separately from these parts.
Boolean.
None.
ISO datetime.
Integer representing user id.
Dictionary.
Get the value.
If this line does *not* raise, the XML is valid.
Map  key: <tag attribute in xml>  value: <name of module attribute>
if problem is full points
We don't throw an exception here because it is possible for  the descriptor of a required module to have a property but  for the resulting module to be a (flavor of) ErrorModule.  So just log and return false.
Calculate html ids of dependencies
HACK: This shouldn't be hard-coded to two types  OBSOLETE: This obsoletes 'type'
Overwrite the original sources attribute with the value from sources_list, as  Locations may have been changed to Locators.
We don't want to force a dependency on datadog, so make the import conditional
Make '_' a no-op so we can scrape strings. Using lambda instead of   `django.utils.translation.ugettext_noop` because Django cannot be imported in this file
Generate this many different variants of problems with rerandomize=per_student  Never produce more than this many different seeds, no matter what.
get the first few digits of the hash, convert to an int, then mod.
it'd be nice to have a useful default but it screws up other things; so,  use display_name_with_default for those
Need the problem location in openendedresponse to send out.  Adding  it to the system here seems like the least clunky way to get it  there.
see comment on randomization_bin
So that sandboxed code execution can be cached, but still have an interesting  number of possibilities, cap the number of different random seeds.
Progress objects expect total > 0
scale score and total by weight/total:
The logic flow is a little odd so that _('xxx') strings can be found for  translation while also running _() just once for each string.
Apply customizations if present
Apply customizations if present
If the problem is closed (past due / too many attempts)  then we do NOT show the "check" button  Also, do not show the "check" button if we're waiting  for the user to reset a randomized problem
If the problem is closed (and not a survey question with max_attempts==0),  then do NOT show the reset button.
Button only shows up for randomized problems if the question has been submitted  Do NOT show the button if the problem is correct
If the user has forced the save button to display,  then show it as long as the problem is not closed  (past due / too many attempts)
If the problem is closed (and not a survey question with max_attempts==0),  then do NOT show the save button  If we're waiting for the user to reset a randomized problem  then do NOT show the save button
Presumably, student submission has corrupted LoncapaProblem HTML.    First, pull down all student answers
Next, generate a fresh LoncapaProblem
Translators: Following this message, there will be a bulleted list of items.
Couldn't do it. Give up.
Translators: e.g. "Hint 1 of 3" meaning we are showing the first of three hints.
We report the index of this hint, the client works out what index to use to get the next hint
The convention is to pass the name of the check button if we want  to show a check button, and False otherwise This works because  non-empty strings evaluate to True.  We use the same convention  for the "checking" state text.
If demand hints are available, emit hint button and div.
Some of these tags span multiple lines  Note: could probably speed this up by calling sub() once with a big regex  vs. simply calling sub() many times as we have here.
used by conditional module
This is after the 'never' check because admins can see the answer  unless the problem explicitly prevents it
NOTE: this is slightly different from 'attempted' -- resetting the problems  makes lcp.done False, but leaves attempts unchanged.
pass along the xqueue message to the problem
save any state changes that may occur
If key has no underscores, then partition  will return (key, '', '')  We detect this and raise an error
If the submission wasn't deserializable, raise an error.
If the name already exists, then we don't want  to override it.  Raise an error instead
Can override current time
Problem queued. Students must wait a specified waittime before they are allowed to submit  IDEA: consider stealing code from below: pretty-print of seconds, cueing of time remaining
Save the user's state before failing
If the user is a staff member, include  the full exception, including traceback,  in the response
Otherwise, display just an error message,  without a stack trace  Translators: {msg} will be replaced with a problem's error message.
Save the user's state before failing
success = correct if ALL questions in this problem are correct
render problem into HTML
Do the unmask translates on a copy of event_info,  avoiding problems where an event_info is unmasked twice.
Look for answers/id
Add 'permutation' to event_info for permuted responses.
Add permutation record tuple: (one of:'shuffle'/'answerpool', [as-displayed list])
NOTE: The above process requires deep inspection of capa structures that may break for some  uncommon problem types.  Ensure that it does not prevent answer submission in those  cases.  Any occurrences of errors in this block should be investigated and resolved.
Translators: 'rescoring' refers to the act of re-submitting a student's solution so it can get a new score.
get old score, for comparison:
rescoring should have no effect on attempts, so don't  need to increment here, or mark done.  Just save.
success = correct if ALL questions in this problem are correct
NOTE: We are logging both full grading and queued-grading submissions. In the latter,        'success' will always be incorrect
Translators: 'closed' means the problem's due date has passed. You may no longer attempt to solve the problem.
Translators: A student must "make an attempt" to solve the problem on the page before they can reset it.
Reset random number generator seed.
Generate a new problem with either the previous seed or a new seed
Pull in the new problem seed
Make '_' a no-op so we can scrape strings. Using lambda instead of   `django.utils.translation.ugettext_noop` because Django cannot be imported in this file
parsing custom parameters to dict
LTI specs: 'custom_' should be prepended before each custom parameter, as pointed in link above.
Parameters required for grading:
Appending custom parameter for signing.
This is needed for body encoding:
Parse headers to pass to template as part of context:
oauthlib encodes signature with  'Content-Type': 'application/x-www-form-urlencoded'  so '='' becomes '%3D'.  We send form via browser, so browser will encode it again,  So we need to decode signature back:
Add LTI parameters to OAuth parameters for sending in form.
Raise exception if score is not float or not in range 0.0-1.0 regarding spec.
NOTE: calling self.get_children() doesn't work until we've picked a choice
Oops.  Children changed. Reset.
Now get_children() should return a list with one element
raise error instead?  In fact, could complain on descriptor load...
the editing interface can be the same as for sequences -- just a container
staff get to see all the details
staff get to see all the details
this string is not marked for translation because we don't have  access to the user context, and this will only be seen by staff
Save the error to display later--overrides other problems
We need to know the library's version so ensure it's set in library.location.library_key.version_guid
Apply simple filtering based on CAPA problem types:
should this move to cms since it's really only for module crud?
The capa format specifies that what we call max_attempts in the code  is the attribute `attempts`. This will do that conversion
pylint: disable=no-member
we should verify against get_outcome_service_url not  request url proxy and load balancer along the way may  change url presented to the method
-*- coding: utf-8 -*-
return anything except None to test LMS
test to make sure that role is checked in LMS
Make sure that answer for incorrect request is error json.
Make sure that ajax request works correctly.
Even though the minimum number is 3, this should grade correctly when 7 assignments are found
Test that graders can also be used instead of lists of dictionaries
construct module
Make sure the runtime knows that the block's children vary per-user:
Check how many children each user will see:  Check that get_content_titles() doesn't return titles for hidden/unused children
When source_library_id is blank, the validation summary should say this block needs to be configured:
When source_library_id references a non-existent library, we should get an error:
When source_library_id is set but the block needs to be updated, the summary should say so:
Now if we update the block, all validation should pass:
Set max_count to higher value than exists in library  In the normal studio editing process, editor_saved() calls refresh_children at this point
Add some capa problems so we can check problem type validation messages
Existing problem type should pass validation
... unless requested more blocks than exists in library
Missing problem type should always fail validation
Reload lc_block and set it up for a student:
Get the keys of each of our blocks, as they appear in the course:
Trigger a publish event:
Clear the cache (only needed because we skip saving/re-loading the block) pylint: disable=protected-access
Clear the cache (only needed because we skip saving/re-loading the block) pylint: disable=protected-access
deleted so that info can no longer be retrieved
load it
export it
Now make sure the exported xml is a sequential
pylint: disable=protected-access
Now export and check things
Does the course still have unicorns?
the course and org tags should be _only_ in the pointer
did we successfully strip the url_name from the definition contents?
Run the checks on the course node instead.
Check that the child does not inherit a value for due
Check that the child hasn't started yet
Test inherited metadata. Due does not appear here (because explicitly set on child).
pylint: disable=protected-access
Also check that the grading policy loaded
Also check that keys from policy are run through the  appropriate attribute maps -- 'graded' should be True, not 'true'
Not using get_courses because we need the modulestore object too afterward
Name should be 'video_{hash}'
No config -> False
empty config -> False
false config -> False
and finally...
Mock is_condition_satisfied
Tracking strange content repeating bug  Should appear once
Test with a Mongo course and '=' as padding.  Test with a Split course and '~' as padding.
Test course with no display name.  Test course with a display name that contains characters that need escaping.
Test course with no display name.  Test course with a display name that contains characters that need escaping.
Even though we don't care about testing mock_strftime_localized,  we still need to test it with a bad format string in order to  satisfy the coverage checker.
Location of common test DATA directory  '../../../../edx-platform/common/test/data/'
Disable XBlockAsides in most tests
Unlike XBlock Runtimes or DescriptorSystems,  each XModule is provided with a new ModuleSystem.  Construct one for the new XModule.
Use __ to not pollute the namespace of subclasses with what could be a fairly generic name.
Only wrap the first layer of assert functions by stashing away the manager  before executing the assertion.
Reconstruct the stack in which the error was thrown (so that the traceback)  isn't cut off at `assertion(*args, **kwargs)`.
Count the number of stack frames before you get to a  unittest context (walking up the stack from here).  This is the same criterion used by unittest to decide if a  stack frame is relevant to exception printing.
Run the assertion, and capture any raised assertionErrors
Handle the assertRaises family of functions by returning  a context manager that surrounds the assertRaises  with our assertion capturing context manager.
Formatting the message slows down tests of large courses significantly, so only do it if it would be used
compare fields
Children are handled specially
edited_on is updated upon import.
Policy files are json, and thus the values aren't passed through 'deserialize_field'  Therefor, the string 'null' is passed unchanged to the Float field, which will trigger  a ValueError
Extract all argument names used to construct XmlImportData objects,  so that the factory doesn't treat them as XML attributes
Make sure that the xml_module doesn't try and open a file to find the contents  of this node.
Test that the string inherited fields are passed through 'deserialize_field',  which converts the string "null" to the python value None
Use super(BulkAssertionTest) to make sure we get un-adulturated assertions
construct module
If user_tag has a missing value, we should still get back a valid child url
Patch the definition_to_xml for the html children.  The HtmlDescriptor definition_to_xml tries to write to the filesystem  before returning an xml object. Patch this to just return the xml.
Mock out the process_xml  Expect it to return a child descriptor for the SplitTestDescriptor when called.
Write out the xml.
user_partition_id will always appear in editable_metadata_settings, regardless  of the selected value.
user_partitions is empty, only the "Not Selected" item will appear.
Try again with a selected partition and verify that there is no option for "No Selection"
Finally try again with an invalid selected partition and verify that "No Selection" is an option
Verify that a split test has no active children if it has no specified user partition.
Verify that a split_test referring to a non-existent user partition has no active children
converting to int here because I keep putting "0" and "1" in the tests  since everything else is a string.
in the capa grace period format, not in time delta format
default, no due date, showanswer 'closed', so problem is open, and show_answer  not visible.
can see after attempts used up, even with due date in the future
can see after due date
can't see because attempts left
Can't see because grace period hasn't expired
can see because answer is correct, even with due date in the future
can see after due date, even when answer isn't correct
can also see after due date when answer _is_ correct
Can't see because grace period hasn't expired and answer isn't correct
can't see after attempts used up, even with due date in the future
can see after due date
can't see because attempts left
Can't see because grace period hasn't expired, even though have no more  attempts.
can see after attempts used up, even with due date in the future
can see after due date
can't see because attempts left and wrong
_can_ see because attempts left and right
Can see even though grace period hasn't expired, because have no more  attempts.
Attempts < Max attempts --> NOT closed
Attempts < Max attempts --> NOT closed
Attempts = Max attempts --> closed
Attempts > Max attempts --> closed
Max attempts = 0 --> closed
Past due --> closed
If we use [] at the end of a key name, we should always  get a list, even if there's just one value
If we have no underscores in the name, then the key is invalid
Check the problem
Expect that the problem is marked correct
Expect that we get the (mocked) HTML
Expect that the number of attempts is incremented by 1
Simulate marking the input incorrect
Check the problem
Expect that the problem is marked correct
Expect that the number of attempts is incremented by 1
Expect that number of attempts NOT incremented
Randomize turned on
Simulate that the problem is completed
Expect that we cannot submit
Expect that number of attempts NOT incremented
Randomize turned off
Expect that we can submit successfully
Expect that number of attempts IS incremented
Expect an AJAX alert message in 'success'
Expect that the number of attempts is NOT incremented
Create a request dictionary for check_problem.
Try each exception that capa_module should handle
Create the module
Ensure that the user is NOT staff
Simulate answering a problem that raises the exception
Expect an AJAX alert message in 'success'
Expect that the number of attempts is NOT incremented
Create the module
Ensure that the user is NOT staff
Ensure that DEBUG is on
Simulate answering a problem that raises the exception
Expect an AJAX alert message in 'success'
Create the module
Override the problem score to have a total of zero.
Check the problem
Try each exception that capa_module should handle
Create the module
Ensure that the user is NOT staff
Simulate answering a problem that raises the exception
Expect an AJAX alert message in 'success'
Expect that the number of attempts is NOT incremented
Try each exception that capa module should handle
Create the module
Ensure that the user IS staff
Simulate answering a problem that raises an exception
Expect an AJAX alert message in 'success'
We DO include traceback information for staff users
Expect that the number of attempts is NOT incremented
Stub out HTML rendering
Reset the problem
Expect that the request was successful
Expect that the problem HTML is retrieved
Expect that the problem was reset
pre studio default
Simulate that the problem is closed
Try to reset the problem
Expect that the problem was NOT reset
Simulate that the problem is NOT done
Try to reset the problem
Expect that the problem was NOT reset
Simulate that all answers are marked correct, no matter  what the input is, by patching LoncapaResponse.evaluate_answers()
Expect that the problem is marked correct
Expect that we get no HTML
Expect that the number of attempts is not incremented
make sure it also works when attempts have been reset,  so add this to the test:
Simulate that all answers are marked incorrect, no matter  what the input is, by patching LoncapaResponse.evaluate_answers()
Expect that the problem is marked incorrect
Expect that the number of attempts is not incremented
Simulate that the problem is NOT done
Try to rescore the problem, and get exception
Try to rescore the problem, and get exception
Create the module
Simulate answering a problem that raises the exception
Expect an AJAX alert message in 'success'
Expect that the number of attempts is NOT incremented
Save the problem
Expect that answers are saved to the problem
Expect that the result is success
Simulate that the problem is closed
Try to save the problem
Expect that the result is failure
Capa XModule treats 'always' and 'true' equivalently
Try to save
Expect that we cannot save
Capa XModule treats 'false' and 'per_student' equivalently
Try to save
Expect that we succeed
If last attempt, button name changes to "Final Check"  Just in case, we also check what happens if we have  more attempts than allowed.
Otherwise, button name is "Check"
If no limit on attempts, then always show "Check"
If we're after the deadline, do NOT show check button
If user is out of attempts, do NOT show the check button
If survey question (max_attempts = 0), do NOT show the check button
If user submitted a problem but hasn't reset,  do NOT show the check button  Note:  we can only reset when rerandomize="always" or "true"
Otherwise, DO show the check button
If the user has submitted the problem  and we do NOT have a reset button, then we can show the check button  Setting rerandomize to "never" or "false" ensures that the reset button  is not shown
If we're after the deadline, do NOT show the reset button
If the user is out of attempts, do NOT show the reset button
pre studio default value, DO show the reset button
If survey question for capa (max_attempts = 0),  DO show the reset button
If the question is not correct  DO show the reset button
If the question is correct and randomization is never  DO not show the reset button
If the question is correct and randomization is always  Show the reset button
Don't show reset button if randomization is turned on and the question is not done
Show reset button if randomization is turned on and the problem is done
If we're after the deadline, do NOT show the save button
If the user is out of attempts, do NOT show the save button
If user submitted a problem but hasn't reset, do NOT show the save button
If the user has unlimited attempts and we are not randomizing,  then do NOT show a save button  because they can keep using "Check"
pre-studio default, DO show the save button
If we're not randomizing and we have limited attempts,  then we can save
If survey question for capa (max_attempts = 0),  DO show the save button
If we're after the deadline, do NOT show the save button  even though we're forcing a save
If the user is out of attempts, do NOT show the save button
Otherwise, if we force the save button,  then show it even if we would ordinarily  require a reset first
Mock the system rendering function
Patch the capa problem's HTML rendering
Render the problem HTML
Also render the problem encapsulated in a <div>
Expect that we get the rendered template back
Check the rendering context
Assert that the encapsulated html contains the original html
HTML generation is mocked out to be meaningless here, so instead we check  the context dict passed into HTML generation.
Re-mock the module_id to a fixed string, so we can check the logging
check to make sure that the input_state and the keys have the same values
Save the original problem so we can compare it later
Simulate throwing an exception when the capa problem  is asked to render itself as HTML
Stub out the get_test_system rendering function
Turn off DEBUG
Try to render the module with DEBUG turned off
Check the rendering context
Expect that the module has created a new dummy problem with the error
Simulate throwing an exception when the capa problem  is asked to render itself as HTML
Stub out the get_test_system rendering function
Make sure DEBUG is on
Try to render the module with DEBUG turned on
Check the rendering context
Get the seed  By this point, the module should have persisted the seed
If we're not rerandomizing, the seed is always set  to the same value (1)
Check the problem
Expect that the seed is the same
Save the problem
Expect that the seed is the same
Reset the problem
Return the seed
Get the seed  By this point, the module should have persisted the seed
We do NOT want the seed to reset if rerandomize  is set to 'never' -- it should still be 1  The seed also stays the same if we're randomizing  'per_student': the same student should see the same problem
Otherwise, we expect the seed to change  to another valid seed
Since there's a small chance we might get the  same seed again, give it 5 chances  to generate a different seed
Reset the problem  By default, the problem is instantiated as unsubmitted
Return the seed
Get the seed  By this point, the module should have persisted the seed
Assert that we are limiting the number of possible seeds.  Get a bunch of seeds, they should all be in 0-999.
Whitespace screws up comparisons
There are potentially 2 track logs: answers and hint. [-1]=answers.
Mock the XQueueInterface.
converting to int here because I keep putting "0" and "1" in the tests  since everything else is a string.
Could set the internal state formally, but here we just jam in the score.
Successfully submitted and answered  Also, the number of attempts should increment by 1
Prior to TNL-4115, an exception would be raised when trying to parse invalid dates in this method
These shouldn't
check complex numbers just for the heck of it :)
only true if working on it
But None should be encoded as 0
Check != while we're at it
'download_track': True,
'download_track': True,
'download_track': True,
Export should succeed without VAL data if video does not exist
Check that download_video field is also set to default (False) in xml for backward compatibility
YouTube JavaScript API
URL to get YouTube metadata
allow for additional options that can be keyed on a name, e.g. 'trashcan'
No end date set, returns empty string.
No end date set, returns empty string.
Make sure we can detect when no teams exist.
add topics
remove them again
Add one HTML block to the library:
Call RandomizeModule which will select an element from the list of available items
export to the same directory--that way things like the custom_tags/ folder  will still be there.
HACK: filenames change when changing file formats  during imports from old-style courses.  Ignore them.
These modules are not editable in studio yet
pylint: disable=no-member
pylint: disable=no-member
Test that when an xmodule is generated from descriptor_cls  with mixed xmodule and xblock children, the test property holds
Test that when an xmodule is generated from descriptor_cls  with only xblock children, the test property holds
-*- coding: utf-8 -*-
return anything except None to test LMS
test to make sure that role is checked in LMS
We just want the above call to complete without exceptions, and to have called verify_oauth_body_sign
(bad inputs, error message expected)
@context missing
return anything except None to test LMS
test to make sure that role is checked in LMS
Blocks with nothing set with return the fields' defaults.
A child with get a value inherited from the parent.
Fields not in the inherited_names list won't be inherited.
Tests that the xblock fields (currently tags and name) get filtered out.  Also tests that xml_attributes is filtered out of XmlDescriptor.
Start of helper methods
False can be parsed as a int (converts to 0)  True can be parsed as a int (converts to 1)  2.78 can be converted to int, so the string will be deserialized
False can be parsed as a float (converts to 0)  True can be parsed as a float (converts to 1)
'false' cannot be converted to float, so input value is returned
json.loads converts the value to Python bool
json.loads fails, string value is returned.
2.78 can be converted to a bool, so the string will be deserialized
test that from_json produces no exceptions
Rerandomize isn't a basic attribute of Sequence
Rerandomize is added to the constructed sequence via the InheritanceMixin
Rerandomize is a known value coming from policy, and shouldn't appear  in xml_attributes
attempts isn't a basic attribute of Sequence
attempts isn't added to the constructed sequence, because  it's not in the InheritanceMixin
attempts is an unknown attribute, so we should include it  in xml_attributes so that it gets written out (despite the misleading  name)
`attribute` isn't a basic attribute of Sequence
`attribute` is added by InheritanceMixin
InheritanceMixin will be used when processing the XML
`attribute` is added to the constructed sequence, because  it's in the InheritanceMixin
`attribute` is a known attribute, so we shouldn't include it  in xml_attributes
We had a bug where a thumbnail location of None was getting transformed into a Location tuple, with  all elements being None. It is important that the location be just None for rendering.
return dict:
edx - HarvardX  cond_test - ER22x
Test ajax url is just usage-id / handler_name
Now change state of the capa problem to make it completed  Save our modifications to the underlying KeyValueStore so they can be persisted
pylint: disable=abstract-method
HACK: This shouldn't be hard-coded to two types  OBSOLETE: This obsoletes 'type'
Make '_' a no-op so we can scrape strings. Using lambda instead of   `django.utils.translation.ugettext_noop` because Django cannot be imported in this file
If position is specified in system, then use that instead.
We do this up here because proctored exam functionality could bypass  rendering after this section.
Is this sequential part of a timed or proctored exam?
Do we have an alternate rendering  from the edx_proctoring subsystem?
Get all descendant XBlock types and counts
Basic count of the number of Units (a.k.a. VerticalBlocks) we have in  this learning sequence
Count of all modules (leaf nodes) in this sequence (e.g. videos,  problems, etc.) The units (verticals) themselves are not counted.
None = no overridden view rendering
inject the user's credit requirements and fulfillments
See if the edx-proctoring subsystem wants to present  a special view to the student rather  than the actual sequence content  This will return None if there is no  overridden view to display given the  current state of the user
Make '_' a no-op so we can scrape strings. Using lambda instead of   `django.utils.translation.ugettext_noop` because Django cannot be imported in this file
fall-through handles all error cases
Fall through to returning grade and comment
According to http://www.imsglobal.org/lti/ltiv2p0/ltiIMGv2p0.html_Toc361225514  PUTting a JSON object with no "resultScore" field is equivalent to a DELETE.
Fall-through record the score and the comment in the module
if present, 'resultScore' must be a number between 0 and 1 inclusive
struct_times are always utc
strftime doesn't work for pre-1900 dates, so use  isoformat instead  isoformat adds +00:00 rather than Z
Timedeltas are immutable, see http://docs.python.org/2/library/datetime.htmlavailable-types
Timedeltas are immutable, see http://docs.python.org/2/library/datetime.htmlavailable-types
We've seen serialized versions of float in this field
Make '_' a no-op so we can scrape strings. Using lambda instead of   `django.utils.translation.ugettext_noop` because Django cannot be imported in this file
Student words from client.  FIXME: we must use raw JSON, not a post data (multipart/form-data)
FIXME: fix this, when xblock will support mutable types.  Now we use this hack.  speed issues
Save in all_words.
Update top_words.
Save all_words in database.
optional information about where this file was imported from. This is needed to support import/export  cycles
create a dummy asset location with a fake but unique name. strip off the name, and return it
Clean up the path, removing any static prefix and any leading slash.
If we couldn't parse the path, just let compute_location figure it out.  It's most likely a path like /image.png or something.
Break down the input path.
Convert our path to an asset key if it isn't one already.
See if this is an allowed file extension to serve.  Some files aren't served through the  CDN in order to avoid same-origin policy/CORS-related issues.
use a naming convention to associate originals with the thumbnail
I've seen some exceptions from the PIL library when trying to save palletted  PNG files to JPEG. Per the google-universe, they suggest converting to RGB first.
store this thumbnail as any other piece of content
log and continue as thumbnails are generally considered as optional
GridFS will throw an exception if the Database is wrapped in a MongoProxy. So don't wrap it.  The appropriate methods below are marked as autoretry_read - those methods will handle  the AutoReconnect errors.
getattr b/c caching may mean some pickled instances don't have attr
Deletes of non-existent files are considered successful
Escape invalid char from filename.
thumbnail is not technically correct but will be functionally correct as the code  only looks at the name which is not course relative.  getattr b/c caching may mean some pickled instances don't have attr
codifying the original order which pymongo used for the dicts coming out of location_to_dict  stability of order is more important than sanity of order as any changes to order make things  unfindable
NOTE, there's no need to state that run doesn't exist in the negative case b/c access via  SON requires equivalence (same keys and values in exact same order)
NOTE, there's no need to state that run doesn't exist in the negative case b/c access via  SON requires equivalence (same keys and values in exact same order)
first delete all of the thumbnails
then delete all of the assets
ok, save the content into the courseware
see if there is a thumbnail as well, if so move that as well
Make '_' a no-op so we can scrape strings. Using lambda instead of   `django.utils.translation.ugettext_noop` because Django cannot be imported in this file
Make '_' a no-op so we can scrape strings. Using lambda instead of   `django.utils.translation.ugettext_noop` because Django cannot be imported in this file
msg += "<p/> dot test " + to_latex(dot(sympy.Symbol('x'),sympy.Symbol('y')))
msg = msg.replace('<p>','<p><span class="inline-error">').replace('</p>','</span></p>')
options
if expected answer is a number, try parsing provided answer as a number also
exactly the same?
Used to return more keys: 'ex': fexpect, 'got': fsym
substitute back into latex form for scripts  literally something of the form  'scriptN' becomes '\\mathcal{N}'  note: can't use something akin to the _print_hat method above because we  sometimes get 'script(N)__B' or more complicated terms
make all lowercase real?
match things like the last example--  the second item in msub is an mrow with the first  character equal to \u200b
match things like the middle example-  the third item in msubsup is an mrow with the first  character equal to \u200b
pre-process the presentation mathml before sending it to snuggletex to convert to content mathml
convert to cmathml
parser tree for Content MathML
Expect that the exact same symbolic string is marked correct
Expect that equivalent symbolic strings are marked correct
for readability later
wrap
process the expression
success?
wrap
process the expression
success?
wrap
process the expression
success?
wrap
process the expression
success?
Subtract 1 second to help comparisons with file-modify time succeed,  since os.path.getmtime() is not millisecond-accurate
Find first number in the list
`reduce` will go from left to right; reverse the list.
Having reversed it, raise `b` to the power of `a`.
No need to go further.
Parse the tree.
Get our variables together.
...and check them
Create a recursion to evaluate the tree.
0.33 or 7 or .34 or 16.  pyparsing allows spaces between tokens--`Combine` prevents that.
SI suffixes and percent.
Predefine recursive variables.
Handle variables passed in. They must start with letters/underscores  and may contain numbers afterward.
Same thing for functions.
Do the following in the correct order to preserve order of operation.
Then treat it as a terminal node.
Find the value of the entire tree.
Generate parens and overwrite `self.latex`.
add capital greek letters
add hbar for QM
add infinity
Then 'a_b' must become 'a_{b}'
Put it together.  Return the function within the closure.
Switch to denominator mode.
Switch back to numerator mode.  First, render the current fraction and add it to the latex.
Reset back to beginning state
Add the fraction/numerator that we ended on.  We ended on a numerator--act like normal multiplication.
No need to go further
Parse tree
Get our variables together.
Create a recursion to evaluate the tree.
the following functions do not have 0 in their domain
Test sqrt
Test abs
Test a simple equation
Recall 'T' is a default constant, with value 298.15
Use 'x' as the first term (instead of, say, '1'), so it can't be  interpreted as a negative number.
If there is no exception thrown, this is a problem
Make complex value:  Example:  Create like 'p_l[p][first]' from {'first': {'p': 'p_l'}
checks if self or other is not empty list (empty lists  = false)
probably xml content mistake - wrong rules names
same as upper -  if we found element from 'user' list,  that not in 'correct' list - we return False.
Convert string `user_answer` to object.
Convert nested `user_answer` to flat format.
Step 1: Discount things which are not numbers
Special case: 0 is an okay resistor
Step 2: Move into the range [100, 1000)
Step 3: Discount things which are not integers, and cast to int
Step 4: Check if we're a valid EIA value
We can handle 1% components correctly; 2.2k is EIA24, but not EIA48.
Do all checks and complain before changing any state.
registering the same class multiple times seems silly, but ok
Ok, should be good to change state now.
Returning the cls means we can use this as a decorator.
extra things displayed after "show answers" is pressed
these get captured as student responses
These should be removed from HTML output, including all subelements
Set seed according to the following priority:        1. Contained in problem's state        2. Passed into capa_problem via constructor
Convert startouttext and endouttext to proper <text></text>
parse problem XML file into an element tree
handle any <include file="foo"> tags
construct script processor context (eg for customresponse problems)
dictionary of InputType objects associated with this problem    input_id string -> InputType object
Each LoncapaResponse will update its specific entries in cmap    cmap is passed by reference
check against each inputtype  if the input type has an ungraded function, pass in the values
if answers include File objects, convert them to filenames.
old CorrectMap
dict of (id, correct_answer)
Note that the modifications has been done, avoiding problems if called twice.
Grab the first choicegroup (there should only be one within each <multiplechoiceresponse> tag)
Find the student answer key that matches our <choicegroup> id
Do not displace the solution under these circumstances
If could not find the solution element, then skip the remaining steps below
Change our correct-choice explanation from a "solution explanation" to within  the set of targeted feedback, which means the explanation will render on the page  without the student clicking "Show Answer" or seeing a checkmark next to the correct choice
Add our solution instead to the targetedfeedbackset and change its tag name
open using LoncapaSystem OSFS filestore
read in and convert to XML
Separate paths by :, like the system path.
find additional comma-separated modules search path
An asset named python_lib.zip can be imported by Python code.
Store code source in context, along with the Python path needed to run it correctly.
Comment and ProcessingInstruction nodes are not Elements,  and we're ok leaving those behind.  BTW: etree gives us no good way to distinguish these things  other than to examine .tag to see if it's a string. :(
leave javascript intact.
save the input type so that we can make ajax calls on it if we need to
let each Response render itself
otherwise, render children recursively, and copy over attributes
copy attributes over if not innocufying
create and save ID for this response
instantiate capa Response  save in list in self
We're going to trap stdout/stderr from the problems (yes, some print)
These are actual answers we get from the responsetypes
all_answers is real_answers + blanks for other answer_ids for which the  responsetypes can't provide us pre-canned answers (customresponse)
Make '_' a no-op so we can scrape strings. Using lambda instead of   `django.utils.translation.ugettext_noop` because Django cannot be imported in this file
Overridable field that specifies whether this capa response type has support for  for rendering on devices of different sizes and shapes.  By default, we set this to False, allowing subclasses to override as appropriate.
ordered list of answer_id values for this response  for convenience
Does this problem have partial credit?  If so, what kind? Get it as a list of strings.
render ourself as a <span> + our content
problem author can make this span display:inline
Add a <div> for the message at the end of the response
self.runtime.track_function('get_demand_hint', event_info)  This this "feedback hint" event
Establish the outer style
Ready to go
We need the CorrectMap code for hint functions. No, this is not great.
make the hint appear after the last answer box in this  response
If no other hint form matches, try extended hints.
First try wrapping the text in a <div> and parsing  it as an XHTML tree
Set the css class of the message <div>
Sets up generator, grader, display, and their dependencies.
If a choice does not have an id, assign 'A' 'B', .. used by CompoundHint
No partial credit? Get grade right now.
Translators: 'partial_credit' and the items in the 'graders' object  are attribute names or values and should not be translated.
Only one type of credit at a time.
Make sure we're using an approved style.
Run the appropriate grader.
Compound hints are a special thing just for checkboxgroup, trying  them first before the regular extended hints.
Selector words are space separated and not case-sensitive
call secondary setup for MultipleChoice questions, to set name  attributes
define correct choices (after calling secondary setup)
Warning: mostly student_answer is a string, but sometimes it is a list of strings.
No partial credit? Grade it right away.
Translators: 'partial_credit' and the items in the 'graders' object  are attribute names or values and should not be translated.
Only one type of credit at a time.
Make sure we're using an approved style.
Run the appropriate grader.
With masking disabled, this computation remains interesting to see  the displayed order, even though there is no unmasking.
Translators: 'answer-pool' is an attribute name and should not be translated.
Note in the response that answerpool is done.  Both to avoid double-processing, and to feed the logs.
Remove all choices in the choices_list (we will add some back in later)
Sample from the answer pool to get the subset choices and solution id
Add back in randomly selected choices
Limit the number of incorrect choices to what we actually have
Select the one correct choice
Put together the result, pushing most of the work onto rng.shuffle()
convert val into unicode because student answer always be a unicode string  even it is a list, dict etc.
Find the tolerance
What multiple of the tolerance is worth partial credit?
Translators: This is an error message for a math problem. If the instructor provided a  boundary (end limit) for a variable that is a complex number (a + bi), this message displays.
Translators: This is an error message for a math problem. If the instructor did not  provide a boundary (end limit) for a variable, this message displays.
backward compatibility, can be removed in future, it is up to @Lyla Fisher.  end of backward compatibility
Note the atypical case of using self.id instead of self.answer_id
We follow the check_string convention/exception, adding ^ and $
if given answer is empty.
backward compatibility, should be removed in future.  end of backward compatibility
Translators: Separator used in StringResponse to display multiple answers.  Example: "Answer: Answer_1 or Answer_2 or Answer_3".
Standard amount for partial credit if not otherwise specified:
if <customresponse> has an "expect" (or "answer") attribute then save  that
the <answer>...</answer> stanza should be local to the current <customresponse>.  So try looking there first.  print "xml = ",etree.tostring(xml,pretty_print=True)
if we have a "cfn" attribute then look for the function specified by cfn, in  the problem context ie the comparison function is defined in the  <script>...</script> stanza instead
global variable in context which holds the Presentation MathML from dynamic math input  ordered list of dynamath responses
NOTE: correct = 'unknown' could be dangerous. Inputtypes such as textline are  not expecting 'unknown's
put these in the context of the check function evaluator  note that this doesn't help the "cfn" version - only the exec version  my ID
expected answer (if given as attribute)
ordered list of student answers from entry boxes in our subtree
ordered list of ID's of all entry boxes in our subtree
ordered list of all javascript inputs in our subtree
dict of student's responses, with keys being entry box IDs
the list to be filled in by the check function
the list of messages to be filled in by the check function
a message that applies to the entire response  instead of a particular input
any options to be passed to the cfn
Pass DEBUG to the check function.
Run the check function
If there is only one input, apply the message to that input  Otherwise, apply the message to the whole problem
Otherwise, we do not recognize the dictionary  Raise an exception
If *msg* is an empty string, then the code below  will return "</html>".  To avoid this, we first check  that *msg* is a non-empty string.
When we parse *msg* using etree, there needs to be a root  element, so we wrap the *msg* text in <html> tags
Replace < characters
Use etree to prettify the HTML
Remove the <html> tags we introduced earlier, so we're  left with just the prettified message markup
Strip leading and trailing whitespace
If we start with an empty string, then return an empty string
Log the error if we are debugging
Notify student with a student input error
Symbolic response always uses symmath_check()  If the XML did not specify this, then set it now  Otherwise, we get an error from the superclass
Let CustomResponse do its setup
Since we have limited max_inputfields to 1,  we can assume that there is only one submission
Translators: 'SymbolicResponse' is a problem type and should not be translated.
VS[compat]:  Check if XML uses the ExternalResponse format or the generic  CodeResponse format
Note that submission can be a file
Prepare xqueue request
State associated with the queueing request
Queueing mechanism flags:    1) Backend: Non-null CorrectMap['queuestate'] indicates that       the problem has been queued    2) Frontend: correctness='incomplete' eventually trickles down       through inputtypes.textbox and .filesubmission to inform the       browser to poll the LMS
Translators: 'grader' refers to the edX automatic code grader.
FIXME - hardcoded URL
response is XML; parse it
Find the tolerance
Case insensitive
Case sensitive
Default
pylint: disable=broad-except
Untested; never used
Translators: 'SchematicResponse' is a problem type and should not be translated.
use answers provided in input elements
answer is correct if (x,y) is within the specified  rectangle
Check the binary choices first.  Only return correct if the student got both the binary  and numtolerance_inputs are correct
Initialize the two dictionaries that are returned
`selected_choices` is a list of binary choices which were "checked/selected"  when the student submitted the problem.  Keys in a_dict ending with 'bc' refer to binary choices.
Convert the name of a numtolerance_input into the name of the binary  choice that it is contained within, and append it to the list if  the numtolerance_input's parent binary_choice is contained in  `selected_choices`.
If `self.corrrect_inputs` does not contain an entry for  `answer_name`, this means that answer_name is a decoy  input's value, and validation of its numericality is the  only thing of interest from the later call to  `compare_with_tolerance`.
Ignore the results of the comparisons which were just for  Numerical Validation.  If any input is not correct, set the return value to False
pylint: disable=invalid-all-object  pylint: enable=invalid-all-object
LMS Interface to external queueing system (xqueue)
Attempt to send to queue
Utility functions used in CAPA responsetypes
If an input is infinite, we can end up with `abs(student_complex-instructor_complex)` and  `tolerance` both equal to infinity. Then, below we would have  `inf <= inf` which is a fail. Instead, compare directly.
because student_complex and instructor_complex are not necessarily  complex here, we enforce it here:
v1 and v2 are, in general, complex numbers:  there are some notes about backward compatibility issue: see responsetypes.get_staff_ans()).
Files are stored as a list, even if one file
start with empty dict
See the documentation for 'set_dict' for the use of kwargs
empty current dict
if not correct and no points have been assigned, return 0
Subclasses override this to specify the file name of the template  to be loaded from capa/templates.  The template name should include the .html extension:  for example: choicegroup.html
add dummy STATIC_URL to template context
Should mark the entire problem correct
Should NOT mark individual options
Should NOT mark individual options
Should NOT mark individual options
Should NOT mark the whole problem
Should NOT mark the whole problem
Should NOT mark the entire problem correct/incorrect
Should NOT mark individual options
Expect to see the message
Expect that we do NOT see the message yet
Expect that we get a <div> with correct class
Expect that we get a <span> with class="status"  (used to by CSS to draw the green check / red x)
Expect that we get a <div> with correct class
If return_to_annotation set, then show the link
Otherwise, do not show the links
Expect that the correct option is selected
Test cases of `(input_status, expected_css_class)` tuples
Because the HTML is unescaped, we should be able to  descend to the <b> tag
Because the HTML is unescaped, we should be able to  descend to the <b> tag
HTML from `tail` should NOT be escaped.  We should be able to traverse it as part of the XML tree
Create options 0-4, and select option 2
Should have a dummy default
Should have the correct option selected
Expect a <div> with the status
Expect a <p> with the status
Assert that the JSON-encoded string was inserted without  escaping the HTML.  We should be able to traverse the XML tree.
Should mark the entire problem correct
Should NOT mark individual options
Should NOT mark individual options
Should NOT mark individual options
Should NOT mark the whole problem
Should NOT mark the whole problem
The following comes into existence by virtue of being called  capa_module.runtime.track_function
just a handy shortcut
check that escaping single quotes with leading backslash (\') properly works  note: actual input by user will be hasn\'t but json parses it as hasn\\'t
'label': '',
check that exception is raised during parsing for html.
Check that compensating for the dot size works properly.
'label': '',
'label': '',
status is in the mapping
Check that calling it multiple times yields the same thing
New problem with same XML -- try the correct choice.
Check that calling it multiple times yields the same thing
The student choses one with no feedback, but alwaysShowCorrectChoiceExplanation  is in force, so we should see the correct solution feedback.
The student chooses one with no feedback set, so we check that there's no feedback.
Q1 has feedback1 and Q2 has nothing
If something is wrong, show it to us.
Ensure that we get the expected number of points  Using assertAlmostEqual to avoid floating point issues
Invalid choices should be marked incorrect (we have no choice 3)
Invalid choices should be marked incorrect
Define a rectangle with corners (10,10) and (20,20)
Define two rectangles
Define a triangular region with corners (0,0), (5,10), and (0, 10)
Define multiple regions that the user can select
Should not allow multiple inputs, since we specify  only one "expect" value
Simulate what the Snuggletex server would respond
Options not in the list should be marked incorrect
Test that option response properly escapes quotes inside options strings
Sample variables x and y in the range [-10, 10]
The expected solution is numerically equivalent to x+2y
Expect an equivalent formula to be marked correct  2x - x + y + y = x + 2y
Expect an incorrect formula to be marked incorrect  x + y != x + 2y
Sample variables x and y in the range [-10, 10]
The expected solution is numerically equivalent to x+2y
Calculate the answer using a script
Sample x in the range [-10,10]
The expected solution is numerically equivalent to 2*x
Expect that the inputs are graded correctly
Exact string should be correct  Other strings and the lowercase version of the string are incorrect
Exact string should be correct
test with case_sensitive not specified
Test single answer
should also be case_sensitive if case sensitivity is not specified
Exact string should be correct
Other strings and the lowercase version of the string are incorrect
Test multiple answers
Other strings and the lowercase version of the string are incorrect
right way to search for \
Test single answer
Both versions of the string should be allowed, regardless  of capitalization
Other strings are not allowed
Test multiple answers
Exact string should be correct
Other strings and the lowercase version of the string are incorrect
We should NOT get a hint for Michigan (the correct answer)
We should NOT get a hint for any other string
We should NOT get a hint for Michigan (the correct answer)
We should NOT get a hint for any other string
CodeResponse requires internal CorrectMap state. Build it now in the unqueued state
Incorrect queuekey, state should not be updated
CodeResponse requires internal CorrectMap state. Build it now in the unqueued state
Queue state only tracks up to second
No choice 3 exists --> mark incorrect
No choice 3 exists --> mark incorrect
First: Every Decision Counts grading style
Second: Halves grading style
Third: Halves grading style with more options
Ensure that we get the expected number of points  Using assertAlmostEqual to avoid floating point issues  First: Every Decision Counts grading style
Second: Halves grading style
Third: Halves grading style with more options
Compile coffee files into javascript used by the response
Test that we get graded correctly
If the system says to disallow unsafe code execution, then making  this problem will raise an exception.
no complex number in range tolerance staff answer
test invalid range tolerance answer
test empty boundaries
Check results
Check that the message for the particular input was received
Check that the overall message (for the whole response) was received
Make sure the seed from the problem gets fed into the script execution.
Correct answer
Partially Credit answer
Incorrect answer
CustomResponse also adds 'expect' to the problem context; check that directly first:
Also make sure the problem was graded correctly:
Correct answer -- expect both inputs marked correct
One answer incorrect -- expect both inputs marked partially correct
Both answers incorrect -- expect both inputs marked incorrect
Expect that we receive the overall message (for the whole response)
Correct answer
Partially Correct answer
Incorrect answer
Grade the inputs (one input incorrect)
Grade the inputs (one input partially correct)
Grade the inputs (everything correct)
Message is interpreted as an "overall message"
Expect that an exception gets raised when we check the answer
Construct a script that will raise an exception
Expect that an exception gets raised when we check the answer
Expect that an exception gets raised when we check the answer
Create the problem
Expect that we can grade an answer without  getting an exception
Create the problem
Expect that we can grade an answer without  getting an exception
euqal to correct order after sorting at get_score
To test that the context is set up correctly,  we create a script that sets *correct* to true  if and only if we find the *submission* (list)
The actual dictionary would contain schematic information  sent from the JavaScript simulation
Expect that the problem is graded as true  (That is, our script verifies that the context  is what we expect)
Construct a script that will raise an exception
Expect that an exception gets raised when we check the answer
Choice is whether this choice is correct  Answers contains a list of answers to textinpts for the choice
Radio/Checkbox inputs in choicetext problems follow  a naming convention that gives them names ending with "bc"  Build the names for the numtolerance_inputs and add their answers  to `answer_dict`.
In `answer_id` `index` represents the ordinality of the  choice and `ind` represents the ordinality of the  numtolerance_input inside the parent choice.
Test that error is raised for input in selected correct choice.
Test that error is raised for input in selected incorrect choice.
Dictionary from name of test_scenario to (problem_name, correctness)  Correctness is used to test whether the problem was graded properly
Dictionary problem_name: problem
Load the test problem's name and desired correctness  Load the problem
Make sure the actual grade matches the expected grade
Check about masking
attributes *not* present
NOTE: not testing get_html yet because I don't understand why it's doing what it's doing.
just a handy shortcut
Our test_capa_system "renders" templates to a div with the repr of the context.
The root is <problem>
Add a script if there is one
The problem has a child <p> with question text
Add the response(s)
Set partial credit
Add input elements
Names of group elements
Create the <choicegroup>, <checkboxgroup>, or <radiogroup> element
Add a name identifying the choice, if one exists  For simplicity, we use the same string as both the  name attribute and the text of the element
Add point values for partially-correct choices.
The line below throws a false positive pylint violation, so it's excepted.
Create the response element
Create the <schematicresponse> element
Insert the <answer> script if one is provided
Since we are providing an <answer> tag,  we should override the default behavior  of including a <solution> tag as well
Create the <coderesponse> element
Create the <codeparam> element.
Set the initial display text
Set the answer display text
Set the grader payload string
Create the input within the response
Since we create this in create_response_element(),  return None here
Create the <formularesponse> element
Set the sample information
Set the tolerance
Set the answer
Include hints, if specified
For each hint, create a <formulahint> element
We could sample a different range, but for simplicity,  we use the same sample string for the hints  that we used previously.
Both display_src and display_class given,  or neither given
Create the <javascriptresponse> element
Create the <optioninput> element
Set the "correct" attribute
Create the <stringresponse> element
Set the answer attribute
Retrieve **kwargs
Symmath check expects a string of options
Construct the <symbolicresponse> element
Ensure that the first element of choices is an ordered  collection. It will start as a list, a tuple, or not a Container.
If the current `choice` contains any("answer": number)  elements, turn those into numtolerance_inputs  `answers` will be a list or tuple of answers or a single  answer, representing the answers for numtolerance_inputs  inside of this specific choice.
Make sure that `answers` is an ordered collection for  convenience.
Default type is 'radiotextgroup'
Give each choice text equal to it's position(0,1,2...)
Add all of the inputs as children of this choice
Create the problem
Create a test file to include
Create the problem
Render the HTML
Expect that the include file was embedded in the problem
Create the problem
Render the HTML
Expect that the <startouttext /> and <endouttext />  were converted to <span></span> tags
Create the problem
Render the HTML
Expect that the anonymous_student_id was converted to "student"
Create the problem
Render the HTML
Expect that the script element has been removed from the rendered HTML
Create the problem
Render the HTML
expect the javascript is still present in the rendered html
Mock out the template renderer
Create the problem and render the HTML
Expect problem has been turned into a <div>
Expect question text is in a <p> child
Expect that the response has been turned into a <span>
Expect that the response <span>  that contains a <div> for the textline
Expect a child <div> for the solution  with the rendered template
Generate some XML for a CustomResponse
Create the problem and render the html
Grade the problem
Render the html
Expect that the <div> contains our message (as part of the XML tree)
Create the problem and render the HTML
Expect that the variable $test has been replaced with its value
Create the problem
Render the HTML
Intentionally testing an item that's not in cmap.
Default is an empty string string
Set a message that applies to the whole question
Retrieve the message
Setting the message to None --> empty string
Create a second cmap, then update it to have the same properties  as the first cmap
Assert that it has all the same properties
Should get an exception if we try to update() a CorrectMap  with a non-CorrectMap value
We'll need the code from lazymod.py for use in safe_exec, so read it now.
Create the complete code we'll run.
Decide which code executor to use.
Run the code!  Results are side effects in globals_dict.
Put the result back in the cache.  This is complicated by the fact that  the globals dict might not be entirely serializable.
If an exception happened, raise it now.
Future division: 1/2 is 0.5.
Math is always available.
Without a seed, the results are unpredictable
With a seed, the results are predictable
Can't test for forbiddenness if CodeJail isn't configured for python.
Actual cache implementations have limits on key length
Actual cache implementations have limits on key length
Fiddle with the cache, then try it again.
Caching used to die on memcache with more than 250 bytes of code.  Check that it doesn't any more.
Used to be that running code that raised an exception didn't cache  the result.  Check that now it does.
The exception should be in the cache now.
Change the value stored in the cache, the result should change.
Check that using non-ASCII unicode does not raise an encoding error.  Try several non-ASCII unicode characters.
Check that our dicts are equal, but with different key order.
Save all the names of all the imported modules.
Get a list of modules that didn't exist when we were created  and delete them all so another import will run code for real again.
Each test will remove modules that it imported.
wsgiref is a module with submodules that is not already imported.  Any similar module would do. This test demonstrates that the module  is not already im
We must include any text that was following our original <clarification>...</clarification> XML node.:
status: css class
want to allow default to be None, but also allow required objects
not required, so return default
put hint above msg if it should be displayed
Pre-parse and process all the declared requirements.
Call subclass "constructor" -- means they don't have to worry about calling  super().__init__, and are isolated from changes to the input  constructor interface.
Something went wrong: add xml to message, but keep the traceback
If `html` contains attrs with no values, like `controls` in <audio controls src='smth'/>,  XML parser will raise exception, so wee fallback to html5parser, which will set empty "" values for such attrs.
convert single quotes inside option values to html encoded string
parse the set of possible options  Allow options to be separated by whitespace as well as commas
remove quotes  convert escaped single quotes (html encoded string) back to single quotes
make list of (option_id, option_description), with description=id
Translators: '<choice>' and '<compoundhint>' are tag names and should not be translated.
Need to provide a value that JSON can parse if there is no  student-supplied value yet.
attribute is set to false.
Check if problem has been queued  Flag indicating that the problem has been queued, 'msg' is length of  queue
Another (older) name--at some point we may want to make it use a  non-codemirror editor.
For CodeMirror  Template expects tabsize to be an int it can do math with
if no student input yet, then use the default input given by the  problem
If neither can parse queue_msg, it contains invalid xml.
only send data if xqueue exists
pull relevant info out of get
save the input state if successful
Note: we subtract 15 to compensate for the size of the dot on the screen.  (is a 30x30 image--lms/static/images/green-pointer.png).
this is unexpected, so log
this is unexpected, so log
add labels to images?:
image drag and drop onto
custom background color for labels:
Need to provide a value that JSON can parse if there is no  student-supplied value yet.
Make `value` an empty dictionary, if it currently has an empty  value. This is necessary because the template expects a  dictionary.
Translators: a "tag" is an XML element, such as "<b>" in HTML
Initialize our dict for the next content
Add any tail text("is the mean" in the example)
Add the tuple for the current choice to the list of choices
open render.html to look at rendered equations
factors don't match
order still doesn't matter
Phases tests
round point to closes 0.05 value
if suffix is explicitly 1, like ^1-  strip 1, leave only sign: ^-
And recurse
If an integer, return that integer  If a fraction, return the fraction
this won't be reached unless we add more arrow types, but keep it to avoid explosions when  that happens.
only one side
Also for lists of multimolecules without factors and phases  sorting seems to work fine.
parsed final trees
check if expressions are correct without factors
factors are not proportional
return ratio
order matters -- need to try <-> first
left sides don't match
right sides don't match
factors don't match (molecule counts to add up)
want an exact match.
Don't want external users to have to deal with parsing exceptions.  Just return False.
This should be imported after lxml.etree so that it overrides the following attributes.
This part is for ability to get xblock instance in xblock_noauth handlers, where user is unauthenticated.
Another thread has already created this entry, so  continue
cache key format e.g user.<user_id>.profile.country = 'SG'
Location is no longer used, but is held here for backwards compatibility  for users imported from our first class.
There are legal implications regarding how we can contact users and what information we can make public  based on their age, so we must take the most conservative estimate.
Remove profile images for users who require parental consent
Cache "old" field values on the model instance so that they can be  retrieved in the post_save callback when we emit an event with new and  old field values.
pylint: disable=protected-access
pylint: disable=protected-access
Setting course_id to '' makes it not affect the generated hash,  and thus produce the old per-student anonymous id
first element should be the last time we reset password
no history, then let's take the date the user joined
just limit the result set to the number of different  password we need
did we go over the limit in attempts  yes, then store when this account is locked out until
To avoid circular imports.
If is_active is False, then the student is not considered to be enrolled  in the course (is_enrolled() will return False)
Represents the modes that are possible. We'll update this later with a  list of possible values.
Maintain a history of requirement status updates for auditing purposes
cache key format e.g enrollment.<username>.<course_key>.mode = 'honor'
Private variable for storing course_overview to minimize calls to the database.  When the property .course_overview is accessed for the first time, this variable will be set.
If we *did* just create a new enrollment, set some defaults
if is_active is None, then the call to update_enrollment didn't specify  any value, so just leave is_active as it is
if mode is None, the call to update_enrollment didn't specify a new  mode, so leave as-is
Only emit mode change events when the user's enrollment  mode has changed from its previous setting
User is allowed to enroll if they've reached this point.
If the student has already been given a certificate they should not be refunded
If it is after the refundable cutoff date they should not be refunded.
Deprecated. Please use the `course_overview` property instead.
blank org is for global group based roles such as course creator (may be deprecated)  blank course_id implies org wide role
Don't try--it won't work, and it will fill the logs with lots of errors
Deprecated
if skip_entrance_exam is True, then student can skip entrance exam  for the course
Ensure that at most one value exists for a given user/name.
Studio permissions:  In addition to the above, one is always allowed to "demote" oneself to a lower role within a course, or remove oneself
if not, then check inferred permissions
can always remove self (at this layer)
superuser
Note that this lives in LMS, so this dependency should be refactored.
This appears to be an unused context parameter, at least for the master templates...
TO DISPLAY A YOUTUBE WELCOME VIDEO  1) Change False to True
2) Add your video's YouTube ID (11 chars, eg "123456789xX"), or specify via microsite config  Note: This value should be moved into a configuration setting and plumbed-through to the  context via the microsite configuration workflow, versus living here
allow for microsite override of the courses list
Insert additional context for use in the template
Sort the data by the reverification_end_date
If the course is missing or broken, log an error and skip it.
If we are in a Microsite, then filter out anything that is not  attributed (by ORG) to that Microsite.
Conversely, if we are not in a Microsite, then filter out any enrollments  with courses attributed (by ORG) to Microsites.
Else, include the enrollment.
If enabled, show the LinkedIn "add to profile" button  Clicking this button sends the user to LinkedIn where they  can add the certificate information to their profile.
Determine the URL to redirect to following login:
Determine the URL to redirect to following login:
for microsites, we want to filter and only show enrollments for courses within  the microsites 'ORG'
Let's filter out any courses in an "org" that has been declared to be  in a Microsite
remove our current Microsite from the "filter out" list, if applicable
Build our (course, enrollment) list for the user, but ignore any courses that no  longer exist (because the course IDs have changed). Still, we don't delete those  enrollments, because it could have been a data push snafu.
sort the enrollment pairs by the enrollment date
Check to see if the student has recently enrolled in a course.  If so, display a notification message confirming the enrollment.
Global staff can see what courses errored on their dashboard  Show any courses that errored on load
Get any programs associated with courses being displayed.  This is passed along in the template context to allow rendering of  program-related information on the dashboard.
Construct a dictionary of course mode information  used to render the course list.  We re-use the course modes dict  we loaded earlier to avoid hitting the database.
only show email settings for Mongo course and when bulk email is turned on
Verification Attempts  Used to generate the "you must reverify for course x" banner
Gets data for midcourse reverifications, if any are necessary or have failed
If there are *any* denied reverifications that have not been toggled off,  we'll display the banner
Populate the Order History for the side-bar.
get list of courses having pre-requisites yet to be completed
If the enrollment has no created date, we are explicitly excluding the course  from the list of recent enrollments.
Feature flag off
Get the user
Ensure the user is authenticated
Ensure we received a course_id
Record the user's email opt-in preference
Check whether the user is blocked from enrolling in this course  This can occur if the user's IP is on a global blacklist  or if the user is enrolling in a country in which the course  is not available.
Otherwise, there is only one mode available (the default)
Need different levels of logging
This is actually the common case, logging in user without external linked login
if the user doesn't exist, we want to set the username to an invalid  username so that authentication is guaranteed to fail and we can take  advantage of the ratelimited backend
this occurs when there are too many attempts from the same IP address
tick the failed login counters if the user exists in the database
successful login, clear failed login attempts counters, if applicable
Ensure that the external marketing site can  detect that the user is logged in.
add this account creation to password history  NOTE, this will be a NOP unless the feature has been turned on in configuration
Copy params so we can modify it; we can't just do dict(params) because if  params is request.POST, that results in a dict containing lists of values
allow for microsites to define their own set of required/optional/hidden fields
Perform operations within a transaction that are critical to account creation  first, create the account
Perform operations that are non-critical parts of account creation
If the user is registering via 3rd party auth, track which provider they use
Track the user's registration
composes activation email  Email subject *must not* contain newlines
Immediately after a user creates an account, we log them in. They are only  logged in until they close the browser. They can't log in again until they click  the activation link from the email.
get the enrolled by user and reason from the ManualEnrollmentAudit table.  then create a new ManualEnrollmentAudit table entry for the same email  different transition state.
Resume the third-party-auth pipeline if necessary.
Generate a unique name to use if none provided
mode has to be one of 'honor'/'professional'/'verified'/'audit'/'no-id-professional'/'credit'
Set the user's global staff bit
Activate the user
ensure parental consent threshold is met
Enroll the user in a course
Apply the roles
Log in as the user
Enroll student in any pending courses he/she may have if auto_enroll flag is set
Add some rate limiting here by re-using the RateLimitMixin as a helper class
When password change is complete, a "edx.user.settings.changed" event will be emitted.  But because changing the password is multi-step, we also emit an event here so that we can  track where the request was initiated.
bad user? tick the rate limiter counter
cribbed from django.contrib.auth.views.password_reset_confirm
tie in password strength enforcement as an optional level of  security protection
we also want to pass settings.PLATFORM_NAME in as extra_context
Support old password reset URLs that used base36 encoded user IDs.  https://github.com/django/django/commit/1184d077893ff1bc947e45b00a4d565f3df81776diff-c571286052438b2e3190f8db8331a92bR231
remember what the old password hash is before we call down
get the updated user
did the password hash change, if so record it in the PasswordHistory
if activation_key is not passing as an argument, generate a random key
Send it to the old email...
And send it to the new email...
Exclude deprecated fields
We must first un-register the User model since it may also be registered by the auth app.
A list of registered access roles.
don't check is_authenticated nor is_active on purpose
pylint: disable=protected-access  Cache a list of tuples identifying the particular roles that a user has  Stored as tuples, rather than django models, to make it cheaper to construct objects for comparison
Org roles don't query by CourseKey, so use CourseKeyField.Empty for that query
pylint: disable=protected-access
python manage.py assigngroups skip_capacitor:0.3,capacitor:0.7 log.txt "Do we show capacitor in linearity tutorial?"
Transfer students from the old demoX class to a new one.
Transfer students from old course to new, with original certificate items.
Transfer students from the old demoX class into two new classes.
Find the old enrollment.
Un Enroll from source course but don't mess  with the enrollment in the destination course.
Un-enroll from the new course if the user had un-enrolled  form the old course.
parse out the course into a coursekey  if it's not a new-style course key, parse it from an old-style  course key
Generate the output filename from the course ID.  Change slashes to dashes first, and then append .csv extension.
Figure out which students are enrolled in the course
parse out the course into a coursekey  if it's not a new-style course key, parse it from an old-style  course key
The passed email address doesn't match this username's email address.  Assume a problem and fail.
resolve the specified groups
warn, but move on.
Needed for sqlite backend (i.e. in tests) because  name.max_length won't be enforced by the db.  See also http://www.sqlite.org/faq.htmlq9
give a more helpful error
give a more helpful error  this will raise a LookupError if it fails.
check idempotency
check idempotency
check idempotency
check removing a permission
check removing all permissions
check idempotency
Verify users are not in honor mode yet
Verify correct number of users are now in honor mode
Verify users are not in honor mode yet
Verify correct number of users are now in honor mode
Create and purchase a verified cert for the original course.
New Course 1
Run the actual management command
When there is no expiration date on a verified mode, the user can always get a refund
Enumeration of per-course verification statuses  we display on the student dashboard.
Retrieve all verifications for the user, sorted in descending  order by submission datetime
Check whether the user has an active or pending verification attempt  To avoid another database hit, we re-use the queryset we have already retrieved.
Retrieve verification deadlines for the enrolled courses
If the user hasn't enrolled as verified, then the course  won't display state related to its verification status.
Retrieve the verification deadline associated with the course.  This could be None if the course doesn't have a deadline.
Picking the max verification datetime on each iteration only with approved status
By default, don't show any status related to verification
Check whether the user was approved or is awaiting approval
Otherwise, the student missed the deadline, so show  them as "honor" (the kind of certificate they will receive).
Set the status for the course only if we're displaying some kind of message  Otherwise, leave the course out of the dictionary.
Query string parameters that can be passed to the "finish_auth" view to manage  things like auto-enrollment.
Before we redirect to next/dashboard, we need to handle auto-enrollment:
Note: if we are resuming a third party auth pipeline, then the next URL will already  be saved in the session as part of the pipeline state. That URL will take priority  over this one.
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
if feature is disabled user can keep reusing same password
also create a user who doesn't have any history
Status code should be 400.
Status code should be 400.
Explicitly import the cache from ConfigurationModel so we can reset it after each test
test when the display is unavailable or notpassing, we get the correct results out
Simulate a successful verification attempt
Simulate a successful verification attempt
Audit mode does not have a banner.  Assert no banner element.
check button text
Now re-validating the invoice
Without linked-in config don't show Add Certificate to LinkedIn button
If user has a certificate with valid linked-in config then Add Certificate to LinkedIn button  should be visible. and it has URL value with valid parameters.
Create a course and log in the user.  Creating a new course will trigger a publish event and the course will be cached
"Explore courses" is shown in the side panel
But other links are hidden in the navigation
Enrolling them again should be harmless
Unenrolling them again should also be harmless
The enrollment record should still exist, just be inactive
Testing enrollment of newly unsaved user (i.e. no database entry)
Unenroll does nothing
Implicit save() happens on new User object when enrolling, so this  should still work
This won't throw an exception, even though the user is not found
Now unenroll them by email
Harmless second unenroll
Unenroll on non-existent user shouldn't throw an error
Creating an enrollment doesn't actually enroll a student  (calling CourseEnrollment.enroll() would have)
Until you explicitly activate it
Activating something that's already active does nothing
Now deactive
Deactivating something that's already inactive does nothing
A deactivated enrollment should be activated if enroll() is called  for that user/course_id combination
same enrollment mode does not emit an event
now try to enroll that student
count total courses appearing on student dashboard
for verified enrollment view the program detail button will have  the class 'base-btn'  for other modes view the program detail button will have have the  class border-btn
ensure that our course id was included in the API call regardless of start/end dates  count total courses appearing on student dashboard
count total courses appearing on student dashboard
verify that only normal courses (non-programs courses) appear on  the student dashboard.
Call add_users a second time, then remove just once.
get dashboard
get dashboard
Invalidate (e.g., delete) the corresponding CourseOverview, forcing get_course to be called.
Make user staff. This will cause CourseCreatorRole().has_user to return True.
check that a user who has not been added to the group still returns false
remove first user from the group and verify that CourseCreatorRole().has_user now returns false
Add user to creator group.
DISABLE_COURSE_CREATION overrides (user is not marked as staff).
Mark as staff. Now CourseCreatorRole().has_user returns true.
Remove user from creator group. CourseCreatorRole().has_user still returns true because is_staff=True
Explicitly import the cache from ConfigurationModel so we can reset it after each test
Assert that can_refund overrides this and allows refund
Assert that can_refund overrides this and allows refund
adding new role from django admin page
adding new role from django admin page
adding new role from django admin page
adding new role from django admin page
In the year that your turn a certain age you will also have been a  year younger than that in that same year.  We calculate age based off of  the youngest you could be that year.
New Course
get courses through iterating all courses
Check if response is escaped
Enable the enrollment success message
Enable donations
Create the course mode(s)
Check that the donate button is or is not displayed
Enable the enrollment success message and donations
Create a white-label course mode  (honor mode with a price set)
Create student account
Assert that the URL for the email view is in the response
Assert that the URL for the email view is not in the response
Assert that instructor email is not enabled for this course  Assert that the URL for the email view is not in the response  if this course isn't authorized
Create student account
The flag is enabled, and since REQUIRE_COURSE_EMAIL_AUTH is False, all courses should  be authorized to use email. But the course is not Mongo-backed (should not work)
Email disabled, shouldn't see link.
Invoke UrlResetMixin
Expect that the course appears on the dashboard  without any verification messaging
Enroll the student in a verified mode, but don't  create any verified course mode.  This won't happen unless someone deletes a course mode,  but if so, make sure we handle it gracefully.
Since the student has not submitted a photo verification,  the student should see a "need to verify" message
Start the photo verification process, but do not submit  Since we haven't submitted the verification, we should still  see the "need to verify" message
Upload images, but don't submit to the verification service  We should still need to verify
The student has submitted a photo verification
Now the student should see a "verification submitted" message
The student has an approved verification
Expect that the successfully verified message is shown
Check that the "verification good until" date is displayed
Expiration date in the past
The student does NOT have an approved verification  so the status should show that the student missed the deadline.
Expiration date in the past
The student didn't have an approved verification at the deadline,  so we should show that the student missed the deadline.
Expiration date in the past
The student didn't have an approved verification at the deadline,  so we should show that the student missed the deadline.
Expiration date in the future
Create a verification with the specified status
Since this is not a status we handle, don't display any  messaging relating to verification
Expiration date in the future
Create a verification with the specified status
Since this is not a status we handle, don't display any  messaging relating to verification
Expiration date in the future
Create a verification attempt that:  1) Is current (submitted in the last year)  2) Will expire by the deadline for the course
This attempt will expire tomorrow, before the course deadline
Expect that the "verify now" message is hidden  (since the user isn't allowed to submit another attempt while  a verification is active).
Expiration date in the past
The deadline has passed, and we've asked the student  to reverify (through the support team).
Expect that the user's displayed enrollment mode is verified.
Expect that the successfully verified message is shown
Check that the "verification good until" date is displayed
Adding another verification with different course.  Its created_at is greater than course deadline.
The student has an approved verification
Sanity check: verify that the course is on the page
Verify that the correct banner is rendered on the dashboard
Verify that the correct banner color is rendered
Verify that the correct copy is rendered on the dashboard  Different states might have different messaging  so in some cases we check several possibilities  and fail if none of these are found.
Combine all possible messages into a single list
Verify that none of the messages are displayed
create clients
set stock url to test disabled accounts' access to site
This simulates any db access in the templates.
Thorough tests for safe_get_host are elsewhere; here we just want a quick URL sanity check
New emails for the users
Create a another user 'user2' & make request for change email
Send requests & ensure no error was thrown
Thorough tests for safe_get_host are elsewhere; here we just want a quick URL sanity check
Set Up Registration
Ensure that the user starts inactive
Until you explicitly activate it
Ensure that the user starts inactive
Until you explicitly activate it
Default (no course modes in the database)  Expect that we're redirected to the dashboard  and automatically enrolled
Audit / Verified  We should always go to the "choose your course" page.  We should also be enrolled as the default mode.
Audit / Verified / Honor  We should always go to the "choose your course" page.  We should also be enrolled as the honor mode.  Since honor and audit are currently offered together this precedence must  be maintained.
Create the course modes (if any) required for this test case
Reverse the expected next URL, if one is provided  (otherwise, use an empty string, which the JavaScript client  interprets as a redirect to the dashboard)
Enroll in the course and verify the URL we get sent to
If we're not expecting to be enrolled, verify that this is the case
Enroll the student in the course
Attempt to unenroll the student
Expect that we're no longer enrolled
Create the course modes (if any) required for this test case
Enroll in the course
Verify that the profile API has been called as expected
Verify that we weren't enrolled
Verify that we were enrolled
Log out, so we're no longer authenticated
Try to enroll, expecting a forbidden response
Try unenroll without first enrolling in the course
create staff on course.
create instructor on course.
Verify that even a child does not require parental consent
Verify that an image cannot be set for a user with no year of birth set
verify that a user's profile image is removed when they switch to requiring parental controls
Verify that we remove the temporary `_changed_fields` property from  the model after we're done emitting events.
Patching the settings.FEATURES['AUTOMATIC_AUTH_FOR_TESTING']  value affects the contents of urls.py,  so we need to call super.setUp() which reloads urls.py (because  of the UrlResetMixin)
Check that the user has a profile
By default, the user should not be global staff
Create a user and enroll in a course
Check that a course enrollment was created for the user
Create a user and enroll in a course
Make the same call again, re-enrolling the student in the same course
Check that only one course enrollment was created for the user
Create a user and enroll in a course
Check that a course enrollment was created for the user
Check that the redirect was to the course info/outline page
Create user and redirect to 'home' (cms) or 'dashboard' (lms)
Check that the redirect was to either /dashboard or /home
Create user and redirect to specified url
Check that session and CSRF are set in the response
Patching the settings.FEATURES['AUTOMATIC_AUTH_FOR_TESTING']  value affects the contents of urls.py,  so we need to call super.setUp() which reloads urls.py (because  of the UrlResetMixin)
Create a course and configure it as a credit course
Configure a credit provider
Configure a single credit requirement (minimum passing grade)
Enroll the user in the course as "verified"
The user is not yet eligible for credit, so no additional information should be displayed on the dashboard.
Simulate that the user has completed the only requirement in the course  so the user is eligible for credit.
The user should have the option to purchase credit
Move the eligibility deadline so it's within 30 days
Simulate that the user has purchased credit, but has not  yet initiated a request to the credit provider
Simulate that the user has purchased credit and initiated a request,  but we haven't yet heard back from the credit provider.
Expect that the user's status is "pending"
Simulate that the user has purchased credit and initiated a request,  and had that request approved by the credit provider
Expect that the user's status is "approved"
Simulate that the user has purchased credit and initiated a request,  and had that request rejected by the credit provider
Expect that the user's status is "approved"
Simulate an error condition: the user has a credit enrollment  but no enrollment attribute indicating which provider the user  purchased credit from.
Expect an error message
Simulate that the user has completed the only requirement in the course  so the user is eligible for credit.
The user should have the option to purchase credit
Create one user and save it to the database
Create a registration for the user
Create a profile for the user
Create the test client
Store the login url
De-activate the user
De-activate the user
Verify the format of the "user info" cookie set on login
Check that the version is set
Check that the username and email are set
Check that the URLs are absolute
Check that the marketing site cookies have been set
Log out
Check that the marketing site cookies have been deleted  (cookies are deleted by setting an expiration date in 1970)
When logged in cookie names are loaded from JSON files, they may  have type `unicode` instead of `str`, which can cause errors  when calling Django cookie manipulation functions.
Reload the user from the database
second login should log out the first
this test can be run with either lms or studio settings  since studio does not have a dashboard url, we should  look for another url that is login_required, in that case
client1 will be logged out
Assert that no profile is created.
Reload the user from the database
Assert that profile is created.
second login should log out the first
this test can be run with either lms or studio settings  since studio does not have a dashboard url, we should  look for another url that is login_required, in that case
client1 will be logged out
Reload the user from the database
second login should log out the first
check that send_mail is called
Missing
Empty, too short
Too long
Invalid
Missing
Empty, too short
Too long
Invalid
Missing
Empty, too short
Matching username
Missing
Empty, too short
Missing
Empty, invalid
True
Missing  Need to change username/email because user was created above
Missing
Empty, invalid
True
Missing
Empty
Too short
This relies on third party auth being enabled in the test  settings with the feature flag `ENABLE_THIRD_PARTY_AUTH`
Provide a course ID to the login page, simulating what happens  when a user tries to enroll in a course without being logged in
Expect that the course ID is added to the third party auth entry  point, so that the pipeline will enroll the student and  redirect the student to the track selection page.
Verify that the third party auth URLs include the redirect URL  The third party auth pipeline will redirect to this page  once the user successfully authenticates.
Get the login page
Verify that the parameters are sent on to the next page correctly
Get the login page
Verify that the parameters are sent on to the next page correctly
until we set up the configuration, the LinkedIn action  button should not be visible
now we should see it
now we should not see it because we are in a microsite
Convert relative URL paths to absolute URIs
Default cache timeout
Always use the cached "real" instance if available
Lookup cached instance
Already patched
Try and construct a User instance from data stored in the cache
Raise an exception to fall through to the except clause below.
Fallback to constructing the User from the database.
Try and construct instance from dictionary
Ensure instance knows that it already exists in the database,  otherwise we will fail any uniqueness checks when saving the  instance.
Specify database so that instance is setup correctly. We don't  namespace cached objects by their origin database, however.
Error when deserialising - remove from the cache; we will  fallback and return the underlying instance
Harmless to save, but saves space in the dictionary - we already know  the primary key when we lookup
Avoid problems with serializing FileFields  by only serializing the file name
pylint: disable=protected-access
although deprecated keys allowed run=None, new keys don't if there is no version.
If we can't find a 'general' CACHE defined in settings.py, we simply fall back  to returning the default cache. This will happen with dev machines.
Don't use the cache.
Skip the throttle check entirely if we've disabled rate limiting.  Otherwise, perform the checks (as usual)
No-op if the class isn't a Django Rest Framework view.
If we ARE explicitly disabling rate limiting,  modify the class to always allow requests.  Note that this overrides both rate limiting applied  for the particular view, as well as global rate limits  configured in Django settings.
Resolve a URL so that the new urlconf gets loaded
Reload only the root urls.py
Reload urls from my_app
Reload urls from my_app and another_app
pylint: disable=protected-access
Clean for whitespace and control characters, which  cause memcache to raise an exception
Attempt to combine the prefix, version, and key
If the total length is too long for memcache, hash it
Return the result
Translators: the translation for "LONG_DATE_FORMAT" must be a format  string for formatting dates in a long form.  For example, the  American English form is "%A, %B %d %Y".  See http://strftime.org for details.
Translators: the translation for "DATE_TIME_FORMAT" must be a format  string for formatting dates with times.  For example, the American  English form is "%b %d, %Y at %H:%M".  See http://strftime.org for details.
This only happens if the string ends with a %, which is not legal.
All the other format codes: just let built-in strftime take  care of them.
Now that we are done defining constants, we have to restore the real pgettext  so that the functions in this module will have the right definition.
add requirement course milestone
add fulfillment course milestone
add milestones if pre-requisite course is selected
If there are required courses, add them to the result dict.
we have not seeded milestone relationship types
Get all of the outstanding milestones for this course, for this user
In debug mode let django process the 500 errors and display debug info for the developer
Display custom 500 page if either    1. test_func is None (meaning nothing to test)    2. or test_func(request) returns True
Do not show custom 500 error when test fails
As of 2012-05-08, Zendesk is using a CA that is not  installed on our servers
Tag all issues with LMS to distinguish channel in Zendesk; requested by student support team
Per edX support, we would like to be able to route white label feedback items  via tagging
Support uses Zendesk groups to track tickets. In case we  haven't been able to correctly group this ticket, log its ID  so it can be found later.
Do not proceed without parameters: Compatibility check with existing tests  that do not supply these parameters
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
TransactionManagementError used below actually *does* derive from the standard "Exception" class.  pylint: disable=nonstandard-exception
Tests in TestCase subclasses are wrapped in an atomic block to speed up database restoration.  So we must disabled this manager.  https://github.com/django/django/blob/1.8.5/django/core/handlers/base.pyL129-L132
This will set the transaction isolation level to READ COMMITTED for the next transaction.
Commit transaction  An error during rollback means that something  went wrong with the connection. Drop it.
Roll back transaction  An error during rollback means that something  went wrong with the connection. Drop it.
Outermost block exit when autocommit was enabled.
Decorator: @commit_on_success(...) or context manager: with commit_on_success(...): ...
Otherwise, this shouldn't be nested in any atomic block.
This will set the transaction isolation level to READ COMMITTED for the next transaction.
Decorator: @outer_atomic(...) or context manager: with outer_atomic(...): ...
If a file already exists with the supplied name, file_storage will make the filename unique.
The setting name used for events when "settings" (account settings, preferences, profile information) change.
Object is new, so fields haven't technically changed.  We'll return  an empty dict as a default value.
Country is not JSON serializable.  Return the country code.
Remove the now inaccurate _changed_fields attribute.
Compute the maximum value length so that two copies can fit into the maximum event size  in addition to all the other fields recorded.
do not rebind the module if it's already bound to a user.
If ALLOWED_HOSTS is set properly, and the host is valid, we just return the user-provided host
If ALLOWED_HOSTS is set properly but the host is invalid, we should get a SuspiciousOperation
Test whitespace, control characters, and some non-ASCII UTF-16
Numeric key
Numeric prefix
Numeric version
Choose lengths close to memcached's cutoff (250)
Generate a key of that length
Make the key safe
The key should now be valid
Long key
Long prefix
Long version
Generate a key with that character
Make the key safe
The key should now be valid
Generate a prefix with that character
Make the key safe
The key should now be valid
Generate a version with that character
Make the key safe
The key should now be valid
Check the length
Check that there are no spaces or control characters
Verify the file was deleted.
Verify the file still exists
strftime doesn't like Unicode, so do the work in UTF8.
fetch non existing org
Enable rate limiting using model-based config
By default, should enforce rate limiting  Since our fake throttle always rejects requests,  we should expect the request to be rejected.
Disable rate limiting using model-based config
With rate-limiting disabled, the request  should get through.  The `check_throttles()` call  should return without raising an exception.
There should be absolutely no interaction with Zendesk
There should be absolutely no interaction with Zendesk
We'll make assets named this be importable by Python code in the sandbox.
accommodates course api urls, excluding any course api routes that do not fall under v*/courses, such as v1/blocks.
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
Try and load the asset.
Set the basics for this request. Make sure that the course key for this  asset has a run, which old-style courses do not.  Otherwise, this will  explode when the key is serialized to be sent to NR.
Figure out if this is a CDN using us as the origin.
Check if this content is locked or not.
Check that user has access to the content.
Figure out if the client sent us a conditional request, and let them know  if this asset has changed since then.
If the header field is syntactically invalid it should be ignored.
Only accept ranges in bytes
According to Http/1.1 spec content for multiple ranges should be sent as a multipart message.  http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.htmlsec14.16  But we send back the full content.
If Range header is absent or syntactically invalid return a full content response.
"Accept-Ranges: bytes" tells the user that only "bytes" ranges are allowed
This is a CDN request.
See if we can load this item from cache.  Not in cache, so just try and load it from the asset manager.
Parse the byte ranges.  Case 0:
Merge settings list with one in the admin config;
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
Initialize the deprecated modules settings with empty list
pylint: disable=missing-docstring
Monkey-patch some social auth models' Meta class to squelch Django19 warnings.  pylint: disable=protected-access
Use this key to store a reference to the unpatched copy
Patch constants as a set instead of a list.
Do we have this feature enabled?  what time is it now?
Get the last time user made a request to server, which is stored in session data
have we stored a 'last visited' in session? NOTE: first time access after login  this key will not be present in the session data  compute the delta since last time user came to the server
did we exceed the timeout limit?  yes? Then log the user out
django_url is assigned late in the process of loading lettuce,  so we import this as a module, and then read django_url from  it to get the correct value
Unlock XBlock factories, because we're randomizing the collection  name above to prevent collisions
There is an issue with ChromeDriver2 r195627 on Ubuntu  in which we sometimes get an invalid browser session.  This is a work-around to ensure that we get a valid session.
If we were unable to get a valid session within the limit of attempts,  then we cannot run the tests.
For transcripts, you need to check an actual video, so we will  just specify our default video and see if that one is available.
A hackish way to skip a test in lettuce as there is no proper way to skip a test conditionally
No need to check all the URLs
Choose the list of handlers based on the HTTP method
Check the path (without querystring params) against our list of handlers  If we don't have a handler for this URL and/or HTTP method,  respond with a 404.
Get notes from range
Respond to request with correct lti endpoint
Send request ignoring verifirecation of SSL certificate
Show roles only for LTI launch.
Currently LTI module doublequotes the lis_result_sourcedid parameter.  Unquote response two times.
This is needed for body encoding:
Log to stdout, including debug messages
Default number of seconds to delay the response to simulate network latency.
Delay the response to simulate network latency
Construct the response content
django_comment_client calls GET comment before doing a DELETE, so that's what this is here to support.
add some configuration data
reset server configuration
ensure that server config dict is empty after successful reset
Without user
Without user
Without any pagination parameters
With pagination parameters
Delete all notes
Patch the timer async calls
Patch POST requests
Check the response we receive  (Should be the default grading response)
Configure the default response for submissions to any queue
Check the response we receive  (Should be the default grading response)
Configure the XQueue stub response to any submission to the test queue
Check that we receive the response we configured
Configure the XQueue stub with two responses that  match the same submission
Expect that we do NOT receive a response  and that an error message is logged
Expect that the response is success
Return back the header, so we can authenticate the response we receive
Check the response posted back to us  This is the default response
Check that the POST request was made with the correct params
JSON-encode each parameter
Check that the expected values were set in the configuration
Send unicode without json-encoding it
Expect success when we provide the required param
Expect failure when we do not proivde the param
Expect failure when we provide an empty param
Expect success when we provide the required param
Expect failure when we do not proivde the param
Expect failure when we provide an empty param
Check for required values
If nothing is missing, execute the function as usual
The POST dict will contain a list of values for each key.  None of our parameters are lists, however, so we map [val] --> val  If the list contains multiple entries, we pick the first one
By default, `parse_qs` returns a list of values for each param  For convenience, we replace lists of 1 element with just the element
Decode the params as UTF-8
No parameters sent to configure, so return success by default
Subclasses override this to provide the handler class to use.  Should be a subclass of `StubHttpRequestHandler`
Create a dict to store configuration values set by the client
Start the server in a separate thread
Log the port we're using to help identify port conflict errors
First call superclass shutdown()
We also need to manually close the socket
Respond only to grading requests
If the message doesn't have a header or body,  then it's malformed.  Respond with failure
If we could not decode the body or header,  respond with failure
Send an immediate response of success  The grade request is formed correctly
Wait a bit before POSTing back to the callback url with the  grade result configured by the server  Otherwise, the problem will not realize it's  queued and it will keep waiting for a response indefinitely
If we get a request that's not to the grading submission  URL, return an error
Send the response indicating success/failure
First check if we have a configured response that matches the submission body
Multiple matches, so abort and log an error
Fall back to the default grade response configured for this queue,  then to the default response.
Wrap the message in <div> tags to ensure that it is valid XML
If not configured, do not need to send anything
Retrieve the grader payload, which should be a JSON-encoded dict.  We pass the payload directly to the service we are notifying, without  inspecting the contents.
django_url is assigned late in the process of loading lettuce,  so we import this as a module, and then read django_url from  it to get the correct value
Settings - Schedule & Details
Settings - Advanced Settings
Content - Outline  Note that calling your org, course number, or display name, 'course' will mess this up
Pages
we ran this on the wrong page. Wait a bit, and try again, when the  browser has loaded the next page.
we ran this on the wrong page. Wait a bit, and try again, when the  browser has loaded the next page.
We got a require.js error  Sometimes requireJS will throw an error with requireType=require  This doesn't seem to cause problems on the page, so we ignore it
stick jquery at the front
Wait a bit, and try again, when the browser has reloaded the page.
If we're expecting a non-empty string, give the page  a chance to fill in text fields.
If we're expecting a non-empty string, give the page  a chance to fill in text fields.
If we're expecting a non-empty string, give the page  a chance to fill in values
Wait for the css selector to appear
Wait for the css selector to appear
Ensure that jquery is loaded
Disable jQuery animations
If the user already exists, don't try to create it again
Save the user info in the world scenario_dict for use in the tests
Note: this flag makes the user global staff - that is, an edX employee - not a course staff.  See courseware.tests.factories for StaffFactory and InstructorFactory.
Activate user  Enroll them in the course
Put in alphabetical order
We will munge 'rel-ter' to be 'rel', so the 'rel-ter'  user will actually receive the released language 'rel'  (Otherwise, the user will actually end up getting the server default)
Since we have only released "rel-ter", the requested code "rel" will  fuzzy match to "rel-ter", in addition to "rel-ter" exact matching "rel-ter"
Release es-419
If I release 'es', 'es-AR' should get 'es', not English
Release 'es-419, es, es-es'
Preview lang should always override selection.
this is the UserPreference key for the currently-active dark language, if any
-*- coding: utf-8 -*-
Converted from the original South migration 0002_enable_on_install.py
-*- coding: utf-8 -*-
If django 1.7 or higher is used, the right-side can be updated with new-style codes.  The following are the new-style language codes for chinese language
delete the session language key (if one is set)
Reset user's dark lang preference to null  Get & set user's preferred language
Get the user's preview lang - this is either going to be set from a query  param `?preview-lang=xx`, or we may have one already set as a dark lang preference.  Get the request user's dark lang preference
User doesn't have a dark lang preference, so just return
Set the session key to the requested preview lang
Make sure that we set the requested preview lang as the dark lang preference for the  user, so that the lang_pref middleware doesn't clobber away the dark lang preview.
the course that this mode is attached to
the reference to this mode that can be used by Enrollments to generate  similar behavior for the same slug across courses
The 'pretty' name that can be translated and displayed
the currency these prices are in, using lower case ISO currency codes
The system prefers to set this automatically based on default settings. But  if the field is set manually we want a way to indicate that so we don't  overwrite the manual setting of the field.
DEPRECATED: the `expiration_date` field has been replaced by `expiration_datetime`
DEPRECATED: the suggested prices for this mode  We used to allow users to choose from a set of prices, but we now allow only  a single price.  This field has been deprecated by `min_price`
optional description override  WARNING: will not be localized
Optional bulk order SKU for integration with the ecommerce service
Modes that allow a student to pursue a verified certificate
Modes that allow a student to pursue a non-verified certificate
Modes that allow a student to earn credit with a university partner
Modes that are allowed to upsell
Courses purchased through the shoppingcart  should be "honor". Since we've changed the DEFAULT_MODE_SLUG from  "honor" to "audit", we still need to have the shoppingcart  use "honor"
Only set explicit flag if we are setting an actual date.
Assign default modes if nothing available in the database
Filter out expired course modes if include_expired is not set
we prefer professional over verify
Professional and no-id-professional mode courses are always behind a paywall
White-label uses course mode honor with a price  to indicate that the course is behind a paywall.
Check that a free mode is available.
the course that this mode is attached to
the reference to this mode that can be used by Enrollments to generate  similar behavior for the same slug across courses
The 'pretty' name that can be translated and displayed
minimum price in USD that we would like to charge for this mode of the course
the suggested prices for this mode
the currency these prices are in, using lower case ISO currency codes
turn this mode off after the given expiration date
pylint seems to dislike as_view() calls because it's a `classonlymethod` instead of `classmethod`, so we disable the warning
Check whether the user has access to this course  based on country access rules.
If a user has already paid, redirect them to the dashboard.
The user will have already been enrolled in the audit mode at this  point, so we just redirect them to the dashboard, thereby avoiding  hitting the database a second time attempting to enroll them.
Validate the amount passed in and force it into two digits
Check for minimum pricing
Try pulling querystring parameters out of the request
Attempt to create the new mode for the given course
Return a success message and a 200 response
need to keep legacy modes around for awhile
django admin saving the date with default timezone to avoid time conversion from form to db  changes its tzinfo to UTC
Verification deadlines are allowed only for verified modes
Verification deadline must be after the upgrade deadline,  if an upgrade deadline is set.  There are cases in which we might want to set a verification deadline,  but not an upgrade deadline (for example, a professional education course that requires verification).
Since the verification deadline is stored in a separate model,  we need to handle saving this ourselves.  Note that verification deadline can be `None` here if  the deadline is being disabled.
Display a more user-friendly name for the custom expiration datetime field  in the Django admin list view.
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
Create a new course mode from django admin page
Verify that the expiration datetime is the same as what we set  (hasn't changed because of a timezone translation).
Configure a verification deadline for the course
Configure a course mode with both an upgrade and verification deadline  and load the form to edit it.
Configure a verification deadline for the course
Create the course mode Django admin form
Update the verification deadline form data  We need to set the date and time fields separately, since they're  displayed as separate widgets in the form.
Check that the deadline was updated
Configure a verification deadline for the course
Create the course mode Django admin form
Use the form to disable the verification deadline
Check that the deadline was disabled
Only the verified mode should have a verification deadline set.  Any other course mode should raise a validation error if a deadline is set.
Factories are self documenting  pylint: disable=missing-docstring
Create the course modes
Enroll the user in the test course
Configure whether we're upgrading or not
Check whether we were correctly redirected
Create the course modes
Enroll the user in the test course
Create the course modes
User visits the track selection page directly without ever enrolling
Create the course modes
Enroll the user in the test course to emulate  automatic enrollment
Verify that the prices render correctly
Create the course modes
Check whether credit upsell is shown on the page  This should *only* be shown when a credit mode is available
The only course mode is professional ed
Go to the "choose your track" page
Since the only available track is professional ed, expect that  we're redirected immediately to the start of the payment flow.
Now enroll in the course
Expect that this time we're redirected to the dashboard (since we're already registered)
Choose the mode (POST request)
Create the course modes
Choose the mode (POST request)
Expect that the contribution amount is stored in the user's session
Create the course modes
Enroll the user in the default mode (honor) to emulate  automatic enrollment
Explicitly select the honor mode (POST request)
Verify that the user's enrollment remains unchanged
Create the supported course modes
Choose an unsupported mode (POST request)
Hit the mode creation endpoint with no querystring params, to create an honor mode
Create an honor mode
Create a verified mode
Create the course modes
Load the track selection page
Verify that the header navigation links are hidden for the edx.org version
URL-encoded version of 1/1/15, 12:00 AM
Construct the URL for the track selection page
shouldn't be able to find a corresponding course
no modes, should get 0
verify that the professional mode is preferred
Has no payment options.
Now we do have a payment option.
Remove the verified option.
Finally, give the honor mode payment options
Has payment options.
Create the modes and min prices
Verify that we can or cannot auto enroll
Verify that the proper auto enroll mode is returned
Unexpired, no expiration date
Unexpired, expiration date in future
Expired
Check that we get a default mode for when no course mode is available
check that tuple has professional mode with None
check that mode slug is verified or not
Create the course modes
Check the selectable modes, which should exclude credit
When we get all unexpired modes, we should see credit as well
The following assumes that the rows with the most recent date also have the highest IDs
The number of seconds
Translators: this label indicates the name of the user who made this change:
Disable caching while testing the API
When a view call fails due to a permissions error, it raises an exception.  An uncaught exception breaks the DB transaction for any following DB operations  unless it's wrapped in a atomic() decorator or context manager.
Return the currently active configuration
Set the requesting user as the one who is updating the configuration
Don't allow deletion of configuration
Make all fields read-only when editing an object
Show only the most recent row for each key.
Don't add the message if course_message is blank.
We don't have a course-specific message, so pass.
Clear the cache between test runs.
When we don't have any data set.
-*- coding: utf-8 -*-
The current() value for GlobalStatusMessage is cached.
Check that the user specified is either the same user, or this is a server-to-server request.  Return a 404 instead of a 403 (Unauthorized). If one user is looking up  other users, do not let them deduce the existence of an enrollment.
Lookup the user, instead of using request.user, since request.user may not match the username POSTed.
Will reactivate inactive enrollments.
Enroll a user test@example.com into the demo course
If the user is already enrolled in the course, do nothing.
Second run does not impact the first run (i.e., the  user is still enrolled, no exception was raised, etc)
The cache backend could raise an exception (for example, memcache keys that contain spaces)
Catch any unexpected errors during caching.
If the client has requested an enrollment deactivation, we want to include expired modes  in the set of available modes. This allows us to unenroll users from expired modes.
We retrieve the settings in-line here (rather than using the  top-level constant), so that @override_settings will work  in the test suite.
Find deleted courses and filter them out of the results
Corresponding information to help resolve the error.
Default (no course modes in the database)  Expect automatically being enrolled as "honor".
Audit / Verified / Honor  We should always go to the "choose your course" page.  We should also be enrolled as "honor" by default.
Check for professional ed happy path.
Add a fake course enrollment information to the fake data API  Enroll in the course and verify that we raise CourseModeNotFoundError
Add a fake course enrollment information to the fake data API  Enroll in the course and verify the URL we get sent to
Default (no course modes in the database)  Expect that users are automatically enrolled as "honor".
Audit / Verified / Honor  We should always go to the "choose your course" page.  We should also be enrolled as "honor" by default.
Check for professional ed happy path.
Add a fake course enrollment information to the fake data API
No enrollments
Enroll in the course and verify the URL we get sent to
Add fake course enrollment information to the fake data API
Hit the fake data API.
Reset the fake data API, should rely on the cache.
The data matches
Default (no course modes in the database)  Expect that users are automatically enrolled as "honor".
Audit / Verified / Honor  We should always go to the "choose your course" page.  We should also be enrolled as "honor" by default.
Create the course modes (if any) required for this test case
Confirm the returned enrollment and the data match up.
Enroll the user in the course
Determine that the returned enrollment is inactive.
Expect that we're no longer enrolled
No course modes, no course enrollments.
Audit / Verified / Honor course modes, with three course enrollments.
No course modes, no course enrollments.
Audit / Verified / Honor course modes, with three course enrollments.
Create all the courses
Create the original enrollment.
Compare the created enrollments with the results  from the get enrollments request.
Default (no course modes in the database)  Expect that users are automatically enrolled as "honor".
Audit / Verified / Honor  We should always go to the "choose your course" page.  We should also be enrolled as "honor" by default.
Try to get an enrollment before it exists.
Default (no course modes in the database)  Expect that users are automatically enrolled as "honor".
Audit / Verified / Honor  We should always go to the "choose your course" page.  We should also be enrolled as "honor" by default.
Verify that an audit message was logged.
If multiple enrollment calls are made in the scope of a  single test, we want to validate that audit messages are  logged for each call.
Pass emit_signals when creating the course so it would be cached  as a CourseOverview.
Default (no course modes in the database)  Expect that users are automatically enrolled as the default
Audit / Verified  We should always go to the "choose your course" page.  We should also be enrolled as the default.
Create the course modes (if any) required for this test case
Create an enrollment
Create the prod ed mode.
Enroll in the course, this will fail if the mode is not explicitly professional.
Log out, so we're no longer authenticated
Try to enroll, this should fail.
Log out the default user, Bob.
Create a user account
Log in with the unactivated account
Deactivate the user. Has to be done after login to get the user into the  request and properly logged in.
Enrollment should succeed, even though we haven't authenticated.
Verify that the server still has access to this endpoint.
Load a CourseOverview. This initial load should result in a cache  miss; the modulestore is queried and course metadata is cached.
Check enrollment list course details
Create a professional ed course mode.
Create an enrollment
Create a honor mode for a course.
Create a verified mode for a course.
Ensure that both course modes are returned
Ensure that only one course mode is returned and that it is honor
Create an honor and verified mode for a course. This allows an update.
Create an enrollment
Create an enrollment
Create an enrollment
Create an honor and verified mode for a course. This allows an update.
Create a 'verified' enrollment
Configure a set of modes for the course.
Create an enrollment with the selected mode.
Verify that a non-Boolean enrollment status is treated as invalid.
Verify that the enrollment has been deactivated, and that the mode is unchanged.
Verify that enrollment deactivation is idempotent.
Verify that omitting the mode returns 400 for course configurations  in which the default mode doesn't exist.
Create verified enrollment.
Deactivate enrollment.
Create a default and a verified mode for a course. This allows an update.
Create an enrollment
simulate the server-server api call under test
call should have succeeded
Load a CourseOverview. This initial load should result in a cache  miss; the modulestore is queried and course metadata is cached.
Expect an error response
Expect that the redirect URL is included in the response
Verify that we were not enrolled
Use the helper to setup the embargo and simulate a request from a blocked IP address.
Clear the cache to remove the effects of previous embargo tests
Update the user's profile, linking the user to the embargoed country.
Setup the embargo
Verify that users without black-listed country codes *can* be enrolled
Verify that we were enrolled
Expect that the request gets through successfully,  passing the CSRF checks (including the referer check).
get best association
not necesary, keys will timeout
not necesary, keys will timeout
Default to a `None` response, indicating that external auth  is not handling the request.
SSL login doesn't require a view, so redirect  branding and allow that to process the login if it  is enabled and the header is in the request.
If CAS is enabled, redirect auth handling to there
Redirect to branding to process their certificate if SSL is enabled  and registration is disabled.
save this for use by student.views.create_account
default conjoin name, no spaces, flattened to ascii b/c django can't handle unicode usernames, sadly  but this only affects username, not fullname
detect if full name is blank and ask for it from user
validate provided mail and if it's not valid ask the user
try the direct apache2 SSL key
Just to make sure we're calling this only at MIT:
no certificate information - go onward to main index
couldn't find the course, will just return vanilla signin page
now the dispatching conditionals.  Only shib for now
Default fallthrough to normal signin page
couldn't find the course, will just return vanilla registration page
now the dispatching conditionals.  Only shib for now  shib-login takes care of both registration and login flows
Default fallthrough to normal registration page
construct sreg response
not using OpenID attribute exchange extension
construct ax response
get and add extensions
create http response from OpenID response
add OpenID headers to response
not using trusted roots
don't allow empty trust roots
ensure trust root parses cleanly (one wildcard, of form *.foo.com, etc.)
don't allow empty return tos
ensure return to is within trust root
check that the root matches the ones we trust
make and validate endpoint
initialize store and server
don't allow invalid and non-trusted trust roots
checkid_immediate not supported, require user interaction
user failed login on previous attempt
OpenID response
don't allow invalid trust roots
authentication succeeded, so fetch user information  that was requested  remove error from session since login succeeded
redirect user to return_to location
Note too that this is hardcoded, and not really responding to  the extensions that were registered in the first place.
the request succeeded:
display login page
add custom XRDS header necessary for discovery process
custom XRDS header necessary for discovery process
custom XRDS header necessary for discovery process
-*- coding: utf-8 -*-
assert that we are logged in
Now that we are logged in, make sure we don't see the registration page
Test that they do signin if they don't have a cert
Call decorated mock function to make sure it passes  the call through without hitting the external_auth functions and  thereby creating an external auth map object.
Test logged in user gets called
Make sure that even though we logged out, we have logged back in
For the sake of python convention we'll make all of these variable names ALL_CAPS  These values would all returned from request.META, so they need to be str, not unicode
no audit logging calls
no audit logging calls
identity k/v pairs will show up in request.META
First we pop the registration form  Then we have the user answer the registration form  These are unicode because request.POST returns unicode
use RequestFactory instead of TestClient here because we want access to request.user
check that the created user has the right email, either taken from shib or user input
temporarily set the branch to draft-preferred so we can update the course
Tests the two case for courses, limited and not
method = 'POST'  undo the URL encoding of the POST arguments
method = 'GET'
the provider URL must be converted to an absolute URL in order to be  used as an openid provider.
now we can begin the login process by invoking a local openid client,  with a pointer to the (also-local) openid provider:
the provider URL must be converted to an absolute URL in order to be  used as an openid provider.
override the default args with any given arguments
try logging in 30 times, the default limit in the number of failed  log in attempts before the rate gets limited
verify that we are not returning the default 403  clear the ratelimit cache so that we don't fail other logins
call url again, this time with username and password
call url again, this time with username and password
login to the client so that we can persist session information
login once to get the right session information  We trigger situation where user is not active at final phase of  OpenId login.
call url again, this time with username and password
the provider URL must be converted to an absolute URL in order to be  used as an openid provider.
Wait until we get the result
Access the service status page, which starts a delayed  asynchronous task
HTTP response should be successful
Expect to get a JSON-serialized dict with  task and time information
Was it successful?
We should get a "pong" message back
We don't know the other dict values exactly,  but we can assert that they take the right form
Register signal handlers  pylint: disable=unused-import
By default use the statsd agent
Not all arguments are documented.  Look at the source code for details.
The settings SITE_NAME may contain a port number, so we need to  parse the full URL.
Construct the fake request.  This can be used to construct absolute  URIs to other paths.
The course to embargo
Whether or not to embargo
pylint: disable=no-member
The countries to embargo
checking is_restricted_course method also here to make sure course exists in the list otherwise in case of  no course found it will throw the key not found error on 'disable_access_check'
First check the cache to see if we already have  a URL for this (course_key, access_point) tuple
If there's a cache miss, we'll need to retrieve the message  configuration from the database
First check whether this is a restricted course.  The list of restricted courses is cached, so this does  not require a database query.
If the country code is not in the list of all countries,  we don't want to automatically exclude the user.  This can happen, for example, when GeoIP falls back  to using a continent code because it cannot determine  the specific country.
Retrieve all rules in one database query, performing the "join" with the Country table
If there are no whitelist countries, default to all countries
Consolidate the rules into a single list of countries  that have access to the course.
This restriction ensures that a country is on  either the whitelist or the blacklist, but  not both (for a particular course).
If a restricted course changed, we need to update the list  of which courses are restricted as well as any rules  associated with the course.
If the restricted course and its rules are being deleted,  the restricted course may not exist at this point.  However, the cache should have been invalidated  when the restricted course was deleted.
Invalidate the cache of countries for the course.
Hook up the cache invalidation receivers to the appropriate  post_save and post_delete signals.
Backwards compatibility with themes created for  earlier implementations of the embargo app.
The access point determines which set of messages to use.  This allows us to show different messages to students who  are enrolling in a course than we show to students  who are enrolled and accessing courseware.
Is this an valid ip address?
Clear the cache to ensure that previous tests don't interfere  with this test.
Remove all existing rules for the course
Create the country object  Ordinarily, we'd create models for every country,  but that would slow down the test suite.
Create a model for the restricted course
Ensure that there is a blacklist rule for the country
Simulate that the user is coming from the blacklisted country
Yield the redirect url so the tests don't need to know  the embargo messaging URL structure.
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
No-op if the country access feature is not enabled
Always give global and course staff access, regardless of embargo settings.
Retrieve the country code from the IP address  and check it against the allowed countries list for a course
Retrieve the country code from the user's profile  and check it against the allowed countries list for a course.
A user-facing description of the message
The mako template used to render the message
Backwards compatibility with themes  created for earlier implementations of the embargo app.
Clear the cache to prevent interference between tests
Configure the access rules
Configure the user's profile country
Appear to make a request from an IP in a particular country  Call the API.  Note that the IP address we pass in doesn't  matter, since we're injecting a mock for geo-location
Verify that the access rules were applied correctly
The user is set to None, because the user has not been authenticated.
The user is set to None, because the user has not been authenticated.
No restricted course model for this course key,  so all access checks should be skipped.
The second check should require no database queries
Test the scenario that will go through every check  (restricted course, but pass all the checks)
Verify that we can check the user's access without error
Test the scenario that will go through every check  (restricted course, but pass all the checks)  This is the worst case, so it will hit all of the  caching code.
Add a country to the blacklist
Appear to make a request from an IP in the blocked country
Expect that the user is blocked, because the user isn't staff
Add the user to the role
Now the user should have access
Retrieve the URL to the blocked message page
The first time we retrieve the message, we'll need  to hit the database.
The second time, we should be using cached values
No restrictions for the course
Use a default path
Retrieve the URL once, populating the cache with the list  of restricted courses.
Delete the restricted course entry
Clear the message URL cache
Try again.  Even though the cache results are stale,  we should still get a valid URL.
Explicitly import the cache from ConfigurationModel so we can reset it after each test
Invalid format for the course key
Validation shouldn't work
Explicitly clear ConfigurationModel's cache so tests have a clear cache  and don't interfere with each other
No custom override specified for the "default" message
Test that course is not authorized by default
Authorize
Now, course should be embargoed
Azerbaijan and France should not be blocked  Gah block USA and Antartica
Block
Change embargo - block Isle of Man too
Warm the cache
it should come from cache
it should come from cache
deleting an object will delete cache also.and hit db on  get the is_restricted course
it should come from cache
Warm the cache
Deleting an object will invalidate the cache
Delete the first rule
Delete the second rule
Create a rule
Delete the course (and, implicitly, all the rules)
Change the message key
Expect a history entry with the changed keys
Check that the record is for the correct course
Load the history entry and verify the message keys
For each rule, check that there is an entry  in the history record.
Check that there are no duplicate entries
Clear the cache to avoid interference between tests
Add the course to the list of restricted courses  but don't create any access rules
Expect that we can access courseware
Ensure that IP blocking works for anonymous users
Set up the IP rules
Check that access is enforced
Blacklist an IP address
Whitelist an IP address
Expect that we were still able to access the page,  even though we would have been blocked by country  access rules.
Make the user staff so that it has permissions to access the views.
Blacklist an IP address
Test with a fully-restricted course
Don't block the embargo message pages; otherwise we'd  end up in an infinite redirect loop.
Don't block the Django admin pages.  Otherwise, we might  accidentally lock ourselves out of Django admin  during testing.
Do not block access to course metadata. This information is needed for  sever-to-server calls.
If embargoing is turned off, make this middleware do nothing
Never block certain patterns by IP address
If the IP is blacklisted, reject.  This applies to any request, not just courseware URLs.
If the IP is whitelisted, then allow access,  skipping later checks.
Otherwise, perform the country access checks.  This applies only to courseware URLs.
Created is the time this action was initiated
Updated is the last time this entry was modified
Course that is being acted upon
Action that is being taken on the course
Current state of the action.
MANAGERS
WARNING - when you edit this value, you're also modifying the max_length  of the `message` column (see below)
Whether or not the status should be displayed to users
Message related to the status
FIELDS  Original course that is being rerun
Display name for destination course
MANAGERS  Override the abstract class' manager with a Rerun-specific manager that inherits from the base class' manager.
-*- coding: utf-8 -*-
initiate
set state to succeed
dismiss ui and verify
initiate
set state to fail
dismiss ui and verify
Sequence of Action models to be tested with ddt.
create course action states for all courses
some state changes may not be user-initiated so override the user field only when provided
update any additional fields in kwargs
Calculate the full URL, including any hashes added to the filename by the pipeline.  This will also include the base static URL (for example, "/static/") and the  ".js" extension.
To make the string comparision easy remove the whitespaces
Verify the default behavior
Verify that raw keyword causes raw URLs to be emitted
Verify that a single JS file is rendered with the pipeline enabled
Verify that multiple JS files are rendered with the pipeline disabled
invalid_client isn't really the right code, but this mirrors  https://github.com/edx/django-oauth2-provider/blob/edx/provider/oauth2/forms.pyL331
Ensure user does not re-enter the pipeline
pylint: disable=no-member
Initialize to minimal data
This is generally the same thing as the UID, expect when one backend is used for multiple providers
Details about the user sent back from the provider.
To be precise, it's set by AUTHENTICATION_BACKENDS - which aws.py sets from THIRD_PARTY_AUTH_BACKENDS
To allow instances to avoid storing secrets in the DB, the secret can also be set via Django:
Remove the prefix from the UID
To allow instances to avoid storing keys in the DB, the key pair can also be set via Django:
To allow instances to avoid storing keys in the DB, the private key can also be set via Django:
This provider is not visible to users
LTI login cannot be initiated by the tool provider
Remove the prefix from the UID
Whitelisted URL query parameters retrained in the pipeline session.  Params not in this whitelist will be silently dropped.
Inject exception middleware to make redirects fire.
Where to send the user if there's an error during social authentication  and we cannot send them to a more specific URL  (see middleware.ExceptionMiddleware).
Where to send the user once social authentication is successful.
Required so that we can use unmodified PSA OAuth2 backends:
We let the user specify their email address during signup.
Disable exceptions by default for prod so you get redirect behavior  instead of a Django error page. During development you may want to  enable this when you want to get stack traces rather than redirections.
Clean any partial pipeline data
Save validated LTI parameters (or None if invalid or not submitted)
Set a auth_entry here so we don't have to receive that as a custom parameter
We do this import internally to avoid initializing settings prematurely
'next' may be set to '/account/finish_auth/.../' if this user needs to be auto-enrolled  in a course. Otherwise, just redirect them to the dashboard, which displays a message  about activating their account.
At this point, we know 'name' is not set in a [OAuth2|LTI|SAML]ProviderConfig row.  It's probably a global Django setting like 'FIELDS_STORED_IN_SESSION':
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
The following are various possible values for the AUTH_ENTRY_KEY.
Entry modes into the authentication process by a remote API call (as opposed to a browser session).
User has authenticated with the third party provider but we don't know which edX  account corresponds to them yet, if any.
User has authenticated with the third party provider and now wants to finish  creating their edX account.
Pass the username, email, etc. via query params to the custom entry page:
Only return the user matched by email if their email has been activated.  Otherwise, an illegitimate user can create an account with another user's  email address and the legitimate user would now login to the illegitimate  account.
Users may want to view/edit the providers used for authentication before they've  activated their account, so we allow inactive users.
We are querying permissions for a user other than the current user.  Return a 403 (Unauthorized) without validating 'username', so that we  do not let users probe the existence of other user accounts.
provider existence checking
build our query filters  When using multi-IdP backend, we only retrieve the ones that are for current IdP.  test if the current provider has a slug  if yes, we add a filter for the slug on uid column
doesn't have access token or no provider_id specified
These users will be created and linked to third party accounts:
The "testshib:" prefix is stored in the UserSocialAuth.uid field but should  not be present in the 'remote_id', since that's an implementation detail:
Login as a super user
Get baseline provider count
Create a provider
Get the provider instance with active flag
Remove the icon_image from the POST data, to simulate unchanged icon_image
Change the name, to verify POST
Post the edit form: expecting redirect
Editing the existing provider creates a new provider instance
Ensure the icon_image was preserved on the new provider instance
This is ultimately probablistic since we could randomly select a good character 100000 consecutive times.
Also check the row ID. Note this 'id' changes whenever the configuration does:
Enable two providers - Google and LinkedIn:
Also check the row ID. Note this 'id' changes whenever the configuration does:
Define some XML namespaces:
Test two slightly different key pair export formats
To test an OAuth1 provider, we need to patch an additional method:
Check that the user was created correctly
Mock out HTTP requests that may be made to TestShib:
Configure the SAML library to use the same request ID for every request.  Doing this and freezing the time allows us to play back recorded request/response pairs
The SAML provider (TestShib) will authenticate the user, then get the browser to POST a response:
For the Dummy provider, the provider redirect URL is self.complete_url
Provider information:  Information about the user expected from the provider:
Now check that we can login again, whether or not we have yet verified the account:
Now check that we can login again:
Override setUp and set this:
Request malformed -- just one of email/password given.
Request well-formed and credentials good.
Request well-formed but credentials bad.
The combined login/registration page dynamically generates the login button,  but we can still check that the provider name is passed in the data attribute  for the container element.
pylint: disable=protected-access
The combined login/registration page dynamically generates the register button,  but we can still check that the provider name is passed in the data attribute  for the container element.
Instrument the pipeline to get to the dashboard with the full  expected state.
First we expect that we're in the unlinked state, and that there  really is no association in the backend.
We should be redirected back to the complete page, setting  the "logged in" cookie for the marketing site.
Set the cookie and try again
Fire off the auth pipeline to link.
Now we expect to be in the linked state, with a backend entry.
We're already logged in, so simulate that the cookie is set correctly
Instrument the pipeline to get to the dashboard with the full  expected state.
First we expect that we're in the linked state, with a backend entry.
Fire off the disconnect pipeline to unlink.
Now we expect to be in the unlinked state, with no backend entry.
pylint: disable=protected-access
Begin! Ensure that the login form contains expected controls before  the user starts the pipeline.
The pipeline starts by a user GETting /auth/login/<provider>.  Synthesize that request and check that it redirects to the correct  provider page.
Next, the provider makes a request against /auth/complete/<provider>  to resume the pipeline.  pylint: disable=protected-access
At this point we know the pipeline has resumed correctly. Next we  fire off the view that displays the login form and posts it via JS.
Next, we invoke the view that handles the POST, and expect it  redirects to /auth/complete. In the browser ajax handlers will  redirect the user to the dashboard; we invoke it manually here.
We should be redirected back to the complete page, setting  the "logged in" cookie for the marketing site.
Set the cookie and try again
First, create, the request and strategy that store pipeline state.  Mock out wire traffic.
Begin! Grab the registration page and check the login control on it.
The pipeline starts by a user GETting /auth/login/<provider>.  Synthesize that request and check that it redirects to the correct  provider page.
Next, the provider makes a request against /auth/complete/<provider>.  pylint: disable=protected-access
At this point we know the pipeline has resumed correctly. Next we  fire off the view that displays the registration form.
The user must not exist yet...
At this point the user object exists, but there is no associated  social auth.
We should be redirected back to the complete page, setting  the "logged in" cookie for the marketing site.
pylint: disable=protected-access
Create twice: once successfully, and once causing a collision.
Dict of string -> object. Information about the token granted to the  user. Override with test values in subclass; None to force a throw.
Dict of string -> object. Information about the user themself. Override  with test values in subclass; None to force a throw.
Now our custom login/registration page must resume the pipeline:
Explicitly set a server name that is compatible with all our providers:  (The SAML lib we use doesn't like the default 'testserver' as a domain)
Providers are only enabled via ConfigurationModels in the database
Guard against submitting a conf change that's convenient in dev but  bad in prod.
In facebook responses, the "id" field is used as the user's identifier
In google-oauth2 responses, the "email" field is used as the user's identifier
Fall back to django settings's SOCIAL_AUTH_LOGIN_ERROR_URL.
Safe because it's already been validated by  pipeline.parse_query_params. If that pipeline step ever moves later  in the pipeline stack, we'd need to validate this value because it  would be an injection point for attacker data.
Check if we have an auth entry key we can use instead
Just return the original path; don't kill everything.
Don't mess with things that end in '?raw'
if not, then assume it's courseware specific content and then look in the  Mongo-backed database
Otherwise, look the file up in staticfiles_storage, and append the data directory if needed
No namespace => no change to path
Namespace => content url
Create an unlocked image.
Create a locked image.
Create a thumbnail of the images.
Create an unlocked image in a subdirectory.
Create a locked image in a subdirectory.
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
To enable the Geoinfo feature on a per-view basis, use:
If no referer is specified, we can't check if it's a cross-domain  request or not.
-*- coding: utf-8 -*-
Set the META `CROSS_DOMAIN_CSRF_COOKIE_USED` flag so  that `CsrfCrossDomainCookieMiddleware` knows to set  the cross-domain version of the CSRF cookie.
Decorate the request with Django's  `ensure_csrf_cookie` to ensure that the usual  CSRF cookie gets set.
Check whether this is a secure request from a domain on our whitelist.
this is the UserPreference key for the user's preferred language
Named tuples can be referenced using object-like variable  deferencing, making the use of tuples more readable by  eliminating the need to see the context of the tuple packing.
Intersect the list of valid language tuples with the list  of release language codes
nothing set in the session or the prefs
language set in the user preferences and not the session
Dark lang middleware should run after this middleware, so it can  set a session language as an override of the user's preference.
Setting the session language to the browser language, if it is supported.
remove any port number from the hostname
on an update case, get the original and archive it
for archiving
for archiving
look up based on the HTTP request domain name  this will need to be a full domain name match,  not a 'startswith' match
if no match, then try to find a 'default' key in Microsites
if we have a match, then set up the microsite thread local  data
cdodge: This approach will not leverage any caching, although I think only Studio calls  this
This should be cacheable (via memcache to keep consistent across a cluster)  I believe this is called on the dashboard and catalog pages, so it'd be good to optimize
we take the list of ORGs associated with this microsite from the database mapping  tables. NOTE, for now, we assume one ORG per microsite
we must have at least one ORG defined
just take the first one for now, we'll have to change the upstream logic to allow  for more than one ORG binding
cache is empty so pull template from DB and fill cache.
if no match on subdomain then see if there is a 'default' microsite defined  if so, then use that
Filter at the setting file
Get the orgs in the db
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
invalid backend path
invalid class or class name is a method
module does not have a class
load a valid class
remove microsite root directory paths first
remove microsite root directory paths first
if microsite config does not exist
if no microsite exists
if no config is set
if microsite config does not exist default config should be used
See if we are running in a Microsite *AND* we have a custom SESSION_COOKIE_DOMAIN defined  in configuration
define wrapper function for the standard set_cookie()
only override if we are setting the cookie name to be the one the Django Session Middleware uses  as defined in settings.SESSION_COOKIE_NAME
then call down into the normal Django set_cookie method
then point the HttpResponse.set_cookie to point to the wrapper and keep  the original around
handle empty string for models being created w/o fields populated
strip key before comparing
raise validation error if the use of this field says it can't be blank but it is
pylint: disable=unused-import, missing-docstring
Ignore empty values to turn-off default tracker backends
Other mongo connection arguments
By default disable write acknowledgments, reducing the time  blocking during an insert
Make timezone aware by default
The event will be lost in case of a connection error or any error  that occurs when trying to insert the event into Mongo.  pymongo will re-connect/re-authenticate automatically  during the next event.
Check if time is stored in UTC
-*- coding: utf-8 -*-
These fields are present elsewhere in the event at this point  This field is only used for Segment web analytics and does not concern researchers
documentation of fields here: https://segment.com/docs/integrations/google-analytics/  this should *only* be used on events destined for segment.com and eventually google analytics
Some duplicated fields are passed into event-tracking via the context by track.middleware.  Remove them from the event here since they are captured elsewhere.
supplement event information with additional information  about the task in which it is running.
The middleware emits an event, reset the mock to ignore it since we aren't testing that feature.
The middleware emits an event, reset the mock to ignore it since we aren't testing that feature.
The middleware normally emits an event, make sure it doesn't in this case.
We use the same expected payload for all of these types of events, but the load video event is the only  one that is not actually expected to contain a "current time" field. So we remove it from the expected  event here.
We use the same expected payload for all of these types of events, but the load video event is the  only one that is not actually expected to contain a "current time" field. So we remove it from the  expected event here.
The POST body will contain the JSON encoded event
We mostly care about the properties
Start with the context provided by Segment in the "client" field if it exists  We should tightly control which fields actually get included in the event emitted.
Build up the event context by parsing fields out of the event received from Segment
Ignore event names that are unsupported
copy the entire segment's context dict as a sub-field of our custom context dict
remove duplicate and unnecessary fields from our copy
Overlay any context provided in the properties
pylint: disable=protected-access
Reset backends
The bytes in the string on the right are utf8 encoded in the source file, so we decode them to construct  a valid unicode string.
Localize to UTC naive datetime objects
Convert to UTC datetime objects from other timezones
Reverse-sort the keys to find the longest matching prefix.
Convert edx.video.seeked to edx.video.position.changed because edx.video.seeked was not intended to actually  ever be emitted.
Not a typo. See:  http://en.wikipedia.org/wiki/HTTP_refererOrigin_of_the_term_referer
Note we are explicitly relying on python's internal caching of  compiled regular expressions here.
HTTP headers may contain Latin1 characters. Decoding using Latin1 encoding here  avoids encountering UnicodeDecodeError exceptions when these header strings are  output to tracking logs.
requestcontext should not be None.
requestcontext should be None.
link_map maps URLs from the marketing site to the old equivalent on  the Django site
special case for when we only want the root marketing URL  only link to the old pages when the marketing site isn't on
don't try to reverse disabled marketing links
see if there is an override template defined in the microsite
In various testing contexts, there might not be a current request context.
"Fix" CSRF token by evaluating the lazy object
fetch and render template
Also clear the internal caches. Ick.
Make a copy of the list of directories for each namespace.
Get rid of all the lookups.
Re-create the lookups from our saved list.
base_loader is an instance of a BaseLoader subclass
This is a mako template
Just having this makes the template load as an instance, instead of a class.
collapse context_instance to a single dictionary for mako
This used to happen when a RequestContext object was initialized but was  moved to a different part of the logic when template engines were introduced.  Since we are not using template engines we do this here.  https://github.com/django/django/commit/37505b6397058bcc3460f23d48a7de9641cd6ef0
We've enrolled the student, so make sure they have the Student role
use existing table that was originally created from django_comment_client app
pylint: disable=no-member
use existing table that was originally created from django_comment_client app
self.assertIn(student_role, another_student.roles.all())
Check a staff account because those used to get the Moderator role
-*- coding: utf-8 -*-
For now, Community TA == Moderator, except for the styling.
Use an in-memory database since this settings file is only used for updating assets
Use RequireJS optimized storage
Redirect to the test_root folder within the repo
Store the static files under test root so that they don't overwrite existing static assets
Disable uglify when tests are running (used by build.js).  1. Uglify is by far the slowest part of the build process  2. Having full source code makes debugging tests easier for developers
SERVICE_VARIANT specifies name of the variant used, which decides what JSON  configuration files are read during startup.
CONFIG_ROOT specifies the directory where the JSON configuration  files are expected to be found. If not specified, use the project  directory.
CONFIG_PREFIX specifies the prefix of the JSON configuration files,  based on the service variant. If no variant is use, don't use a  prefix.
Don't use a connection pool, since connections are dropped by ELB.
For the Result Store, use the django cache named 'celery'
When the broker is behind an ELB, use a heartbeat to refresh the  connection and to detect if it has been dropped.
Each worker should only fetch one message at a time
Things like server locations, ports, etc.
DEFAULT_COURSE_ABOUT_IMAGE_URL specifies the default image to show for courses that don't provide one
GITHUB_REPO_ROOT is the base directory  for course data
social sharing settings
Set the names of cookies shared with the marketing site  These have the same cookie domain as the session, which in production  usually includes subdomains.
Determines whether the CSRF token can be transported on  unencrypted channels. It is set to False here for backward compatibility,  but it is highly recommended that this is True for environments accessed  by end users.
Theme overrides
Push to LMS overrides
Translation overrides
Additional installed apps
Event Tracking
Secret things: passwords, access keys, etc.
Note that this is the Studio key for Segment. There is a separate key for the LMS.
Disabling querystring auth instructs Boto to exclude the querystring parameters (e.g. signature, access key) it  normally appends to every returned URL.
Datadog for events!
Video Caching. Pairing country codes with CDN URLs.  Example: {'CN': 'http://api.xuetangx.com/edx/video?s3_url='}
Use ElasticSearch for the search engine
OpenID Connect issuer ID. Normally the URL of the authentication endpoint.
Partner support link for CMS footer
Affiliate cookie tracking
Django REST framework configuration
Dummy secret key for dev/test
for consistency in user-experience, keep the value of the following 3 settings  in sync with the ones in lms/envs/common.py
email address for studio staff (eg to request course creation)
Segment - must explicitly turn it on for production
Enable URL that shows information about the status of various services
Don't autoplay videos for course authors
If set to True, new Studio users won't be able to author courses unless  edX has explicitly added them to the course creator group.
whether to use password policy enforcement or not
Turn off account locking if failed login attempts exceeds a limit
Allow editing of short description in course settings in cms
Hide any Personally Identifiable Information from application logs
Toggles the embargo functionality, which blocks users  based on their location.
Turn on/off Microsites feature
Allow creating courses with non-ascii characters in the course id
Prevent concurrent logins per user
Turn off Advanced Security by default
Turn off Video Upload Pipeline through Studio, by default
let students save and manage their annotations  for consistency in user-experience, keep the value of this feature flag  in sync with the one in lms/envs/common.py
Enable support for content libraries. Note that content libraries are  only supported in courses using split mongo.
Milestones application flag
Prerequisite courses feature flag
Toggle course entrance exams feature
Toggle platform-wide course licensing
Enable the courseware search functionality
Enable content libraries search functionality
Enable course reruns, which will always use the split modulestore
Certificates Web/HTML Views
Teams feature
Show video bumper in Studio
How many seconds to show the bumper again, default is 7 days:
Enable credit eligibility feature
Can the visibility of the discussion tab be configured on a per-course basis?
Special Exams, aka Timed and Proctored Exams
Show Language selector
Note: Ensure 'CUSTOM_COURSE_URLS' has a matching value in lms/envs/common.py
For geolocation ip database
Change 'debug' in your environment settings files - not here.
use the ratelimit backend to prevent brute force attacks
These are standard regexes for pulling out info like course_ids, usage_ids, etc.  They are used so that URLs with deprecated-format strings still work.
Forwards-compatibility with Django 1.7  It is highly recommended that you override this in any environment accessed by  end users
Ignore deprecation warnings (so we don't clutter Jenkins builds/production)
Instead of SessionMiddleware, we use a more secure version  'django.contrib.sessions.middleware.SessionMiddleware',
Instead of AuthenticationMiddleware, we use a cache-backed version  Enable SessionAuthenticationMiddleware in order to invalidate  user sessions after a password change.
This is used to set or update the user language preferences.
Allows us to dark-launch particular languages
Detects user-requested locale from 'accept-language' header in http request
needs to run after locale middleware (or anything that modifies the request context)
catches any uncaught RateLimitExceptions and returns a 403 instead of a 500
for expiring inactive sessions
use Django built in clickjacking protection
Clickjacking protection can be enabled by setting this to 'DENY'
Platform for Privacy Preferences header
Import after sys.path fixup
These are the Mixins that should be added to every XBlock.  This should be moved into an XBlock Runtime/Application object  once the responsibility of XBlock creation is moved out of modulestore - cpennington
Paths to wrapper methods which should be applied to every XBlock's FieldData.
Modulestore-level field override providers. These field override providers don't  require student context.
Path to a sandboxed Python executable.  None means don't bother.  User to run as in the sandbox.
Configurable limits.  How many CPU seconds can jailed code use?
Change DEBUG in your environment settings files, not here
Site info
Get git revision of the current file
Not a git repository
Static content
This is how you would use the textbook images locally  ("book", ENV_ROOT / "book_images"),
Messages
Don't use compression by default
Ignore tests
Symlinks used by js-test-tool
The baseUrl to pass to the r.js optimizer, relative to STATIC_ROOT.
The name of the require.js script used by your project, relative to REQUIRE_BASE_URL.
A dictionary of standalone modules to build with almond.js.
Whether to run django-require in debug mode.
A tuple of files to exclude from the compilation result of r.js.
YouTube JavaScript API
URL to get YouTube metadata
Common views
History tables
Database-backed configuration
Monitor the status of services
Testing
For CMS
Tracking
Monitoring
For asset pipelining
Theming
Site configuration for theming and behavioral modification
comment common
for course creator table
for managing course modes
Dark-launching languages
Student identity reverification
User preferences
Monitoring signals
Course action state
Credit courses
edX Proctoring
Bookmarks
programs support
Self-paced course configuration
django-oauth2-provider (deprecated)
django-oauth-toolkit
These are apps that aren't strictly needed by Studio, but are imported by  other apps that are.  Django 1.8 wants to have imported models supported  by installed apps.
Microsite configuration application
edx-milestones service
Static i18n support
Tagging
We're already logging events, and we don't want to capture user  names/passwords.  Heartbeat events are likely not interesting.
edx-ora2
edxval
Organizations App (http://github.com/edx/edx-organizations)
First attempt to only find the module rather than actually importing it,  to avoid circular references - only try to import if it can't be found  by find_module, which doesn't work with import hooks
Empty by default
FAQ url to direct users to if they upload  a file that exceeds the above size
Specify XBlocks that should be treated as advanced problems. Each entry is a  dict:        'component': the entry-point name of the XBlock.        'boilerplate_name': an optional YAML template to be used.  Specify as                None to omit.
Default to no Search Engine
Adding components in this list will disable the creation of new problems for  those advanced components in Studio. Existing problems will work fine  and one can edit them in Studio.  DEPRECATED. Please use /admin/xblock_django/xblockdisableconfig instead.
Initial delay used for retrying tasks.  Additional retries use longer delays.  Value is in seconds.
Maximum number of retries per task for errors that are not related  to throttling.
Maximum age in seconds of timestamps we will accept  when a credit provider notifies us that a student has been approved  or denied for credit.
OpenID Connect issuer ID. Normally the URL of the authentication endpoint.
5 minute expiration time for JWT id tokens issued for external API requests.
Partner support link for CMS footer
Affiliate cookie tracking
https://stackoverflow.com/questions/2890146/how-to-force-pyyaml-to-load-strings-as-unicode-objects
SERVICE_VARIANT specifies name of the variant used, which decides what YAML  configuration files are read during startup.
CONFIG_ROOT specifies the directory where the YAML configuration  files are expected to be found. If not specified, use the project  directory.
CONFIG_PREFIX specifies the prefix of the YAML configuration files,  based on the service variant. If no variant is use, don't use a  prefix.
Don't use a connection pool, since connections are dropped by ELB.
For the Result Store, use the django cache named 'celery'
When the broker is behind an ELB, use a heartbeat to refresh the  connection and to detect if it has been dropped.
Each worker should only fetch one message at a time
Delete keys from ENV_TOKENS so that when it's imported  into settings it doesn't override what was set above
collectstatic will fail if STATIC_URL is a unicode string
Additional installed apps
Disable transaction management because we are using a worker. Views  that request a task and wait for the result will deadlock otherwise.
import settings from LMS for consistent behavior with CMS  pylint: disable=unused-import
mongo connection settings
Nose Test Runner
Want static files in the same dir for running on jenkins.
For testing "push to lms"
Avoid having to run collectstatic before the unit test suite  If we don't add these settings, then Django templates that can't  find pipelined assets will raise a ValueError.  http://stackoverflow.com/questions/12816941/unit-testing-with-django-pipeline
allow for additional options that can be keyed on a name, e.g. 'trashcan'
Create tables directly from apps' models. This can be removed once we upgrade  to Django 1.9, which allows setting MIGRATION_MODULES to None in order to skip migrations.
hide ratelimit warnings while running tests
Ignore deprecation warnings (so we don't clutter Jenkins builds/production)  https://docs.python.org/2/library/warnings.htmlthe-warnings-filter  Change to "default" to see the first instance of each hit  or "error" to convert all into errors
These ports are carefully chosen so that if the browser needs to  access them, they will be available through the SauceLabs SSH tunnel
http://slacy.com/blog/2012/04/make-your-tests-faster-in-django-1-4/
No segment key
Toggles embargo on for testing
For consistency in user-experience, keep the value of this setting in sync with  the one in lms/envs/test.py
Enable a parental consent age limit for testing
Enable content libraries code for the tests
MILESTONES
ENTRANCE EXAMS
Courseware Search Index
teams feature
Dummy secret key for dev/test
API access management -- needed for simple-history to run.
Set the default Oauth2 Provider Model so that migrations can run in  verbose mode
Enable debug so that static assets are served by Django
Set REQUIRE_DEBUG to false so that it behaves like production
Fetch static files out of the pipeline's static root
Needed for the reset database management command
Enable debug so that static assets are served by Django
Use the auto_auth workflow for creating users and logging them in
Enable milestones app
Enable pre-requisite course
Enable student notes
Enable teams feature
Enable custom content licensing
Enable partner support link in Studio footer
Disable some block types to test block deprecation logic
Path at which to store the mock index
this secret key should be the same as lms/envs/bok_choy.py's
Lastly, see if the developer has any local overrides.
To see stacktraces for MongoDB queries, set this to True.  Stacktraces slow down page loads drastically (for pages with lots of queries).
Don't use S3 in devstack, fall back to filesystem
Disable noisy loggers
Skip packaging and optimization in development
By default don't use a worker, execute tasks as if they were local functions
To see stacktraces for MongoDB queries, set this to True.  Stacktraces slow down page loads drastically (for pages with lots of queries).
Needed to enable licensing on video modules
Whether to run django-require in debug mode.
See if the developer has any local overrides.
Lastly, run any migrations, if needed.
Dummy secret key for dev
You need to start the server in debug mode,  otherwise the browser will not render the pages correctly
Output Django logs to a file
set root logger level
allow for additional options that can be keyed on a name, e.g. 'trashcan'
Use the auto_auth workflow for creating users and logging them in
HACK  Setting this flag to false causes imports to not load correctly in the lettuce python files  We do not yet understand why this occurs. Setting this to true is a stopgap measure
Where to run: local, saucelabs, or grid
Lastly, see if the developer has any local overrides.
Generate a random UUID so that different runs of acceptance tests don't break each other
import settings from LMS for consistent behavior with CMS
'origin': 'git@github.com:MITx/6002x-fall-2012.git',
Make the keyedcache startup warnings go away
Dummy secret key for dev
By default don't use a worker, execute tasks as if they were local functions
To see stacktraces for MongoDB queries, set this to True.  Stacktraces slow down page loads drastically (for pages with lots of queries).
Enable URL that shows information about the status of various services
If there's an environment variable set, grab it to turn on Segment  Note that this is the Studio key. There is a separate key for the LMS.
Lastly, see if the developer has any local overrides.
Import everything from .aws so that our settings are based on those.
You never migrate a read_replica
set the default Django settings module for the 'celery' program.
Using a string here means the worker will not have to  pickle the object when using Windows.
There is a course creators admin table.
temporary landing page for a course
User API endpoints
Update session view
User creation and updating views
restful api
We need to explicitly include external Django apps that are not in LOCALE_PATHS.
enable automatic login
These views use a configuration model to determine whether or not to  display the Programs authoring app. If disabled, a 404 is returned.  Drops into the Programs authoring app, which handles its own routing.
Custom error pages  pylint: disable=invalid-name
display error page templates, for testing purposes
This will make sure the app is always imported when  Django starts so that shared_task will use this app.
Comprehensive theming needs to be set up before django startup,  because modifying django template paths after startup has no effect.
Workaround for setting THEME_NAME to an empty  string which is the default due to this ansible  bug: https://github.com/ansible/ansible/issues/4812
Calculate the location of the theme's files
Namespace the theme's static files to 'themes/<theme_name>' to  avoid collisions with default edX static files
Make sure that we don't repeatedly nest CmsFieldData instances
-*- coding: utf-8 -*-
Call get_preview_fragment directly.
Now ensure the acid_aside is not in the result
Ensure about video don't have asides
-*- coding: utf-8 -*-
Within this class, allow access to protected members of client classes.  This comes up when accessing kvs data and caches during kvs saves and modulestore writes.
parse removes the id; so, grab it before parse
Before a graceperiod has ever been created, it will be None (once it has been  created, it cannot be set back to None).
'minimum_grade_credit' cannot be set to None
force propagation to definition
Copy the filtered list to avoid permanently changing the class attribute.
Do not show giturl if feature is not enabled.
Do not show edxnotes if the feature is disabled.
Do not show video_upload_pipeline if the feature is disabled.
Do not show teams configuration if feature is disabled.
Do not show enable_ccx if feature is not enabled.
Don't filter on the tab attribute if filter_tabs is False.
Validate the values before actually setting them.
If did validate, go ahead and update the metadata
A signal that will be sent when users should be added or removed from the creator group
A signal that will be sent when admin should be notified of a pending user request
A signal that will be sent when user should be notified of change in course creator privileges
If user has been denied access, granted access, or previously granted access has been  revoked, send a notification message to the user.
If the user has gone into the 'pending' state, send a notification to interested admin.
User is defined to be unique, can assume a single entry.
Store who is making the request.
changed to unrequested or pending
-*- coding: utf-8 -*-
User is initially unrequested.
try logging in 30 times, the default limit in the number of failed  login attempts in one 5 minute period before the rate gets limited
Since we are using the default rate limit behavior, we are  expecting this to return a 403 error to indicate that there have  been too many attempts
Calling add again will be a no-op (even if state is different).
Calling add_user_with_status_granted impacts is_user_in_course_group_role.
Calling add again will be a no-op (even if state is different).
Will not "downgrade" to pending because that would require removing the  user from the authz course creator group (and that can only be done by an admin).
Users marked as is_staff will not be added to the course creator table.
Users marked as is_staff will not be added to the course creator table.
if feature is not enabled then do a quick exit
likewise if course does not have these features turned on  then quickly exit
get all sequences, since they can be marked as timed/proctored exams
filter out any potential dangling sequences
only create/update exam policy for the proctored exams
remove any associated review policy
then see which exams we have in edx-proctoring that are not in  our current list. That means the the user has disabled it
This means it was turned off in Studio, we need to mark  the exam as inactive (we don't delete!)
Force the lazy i18n values to turn into actual unicode objects
then call into the credit subsystem (in /openedx/djangoapps/credit)  to perform any 'on_publish' workflow
import here, because signal is registered at startup, but items in tasks are not yet able to be loaded
import here, because signal is registered at startup, but items in tasks are not yet able to be loaded
If the script did not complete the last time it was run,  the admin user will already exist.
Some users will be both staff and instructors. Those folks have been  added with status granted above, and add_user_with_status_unrequested  will not try to add them again if they already exist in the course creator database.
Rethrow GitExportError as CommandError for SystemExit
N.B. This code breaks many abstraction barriers. That's ok, because  it's a one-time cleanup command.  pylint: disable=protected-access
purposely avoids auth.add_user b/c it doesn't have a caller to authorize
Remove all redundant Mac OS metadata files
try getting the ElasticSearch engine
if reindexing is done during devstack setup step, don't prompt the user  in case of --setup or --all, get the list of course keys from all courses  that are stored in the modulestore
in case course keys are provided as arguments
can this query modulestore for the list of write accessible stores or does that violate command pattern?
make sure this module wasn't deleted
call delete orphans, specifying the published branch  of the course
grab the published branch of the course
assert that this orphan is present in both branches
delete this orphan from the draft branch without  auto-publishing this change to the published branch
now there should be no orphans in the draft branch, but  there should be one in published
pylint: disable=protected-access
Create a course using split modulestore
verify that course has changes.
get draft and publish branch versions
verify that draft and publish point to different versions
force publish course
verify that course has no changes
get new draft and publish branch versions
verify that the draft branch didn't change while the published branch did
verify that draft and publish point to same versions now
Create good course xml
Create course XML where TRUNCATED_COURSE.org == BASE_COURSE_ID.org  and BASE_COURSE_ID.startswith(TRUNCATED_COURSE.course)
Load up base course and verify it is available
Now load up the course with a similar course_id and verify it loads
Clear out the modulestore mappings, else when the next import command goes to create a destination  course_key, it will find the existing course and return the mongo course_key. To reproduce TNL-1362,  the destination course_key needs to be the one for split modulestore.
With the bug, this fails because the chapter's course_key is the split mongo form,  while the course's course_key is the old mongo form.
Send bad url to get course not exported
Send bad course_id to get course not exported
Setup good repo with bad course to test xml export
Test bad git remote after successful clone
get course again in order to update its children list
create a dangling usage key that we'll add to the course's children list
the course block should now point to two children, one of which  doesn't actually exist
make sure the dangling pointer was removed from  the course block's children
lack of error implies success
Temp directories (temp_dir_1: relative path, temp_dir_2: absolute path)
Clean temp directories
Test `export` management command with invalid course_id
Test `export` management command with correct course_id
check that both courses exported successfully
pylint: disable=protected-access
Run it this way:    ./manage.py cms --settings dev edit_course_tabs --course Stanford/CS99/2013_spring
Cute: translate to CommandError so the CLI error prints nicely.
-*- coding: utf-8 -*-
This should be in a class which inherits from XmlDescriptor
update db record  remove status key
delete update item from given index  soft delete course update item
update db record
return 0 if no index found
update db record
Push to all Android devices
Used utf-8-sig encoding type instead of utf-8 to remove BOM(Byte Order Mark), e.g. U+FEFF
Allow upload only if any video link is presented  Generate and save for 1.0 speed, will create subs_sub_attr.srt.sjson subtitles file in storage.
We are creating transcripts for every video source, if in future some of video sources would be deleted.  Updates item.sub with `video_name` on success.
Check for youtube transcripts presence
new value of item.sub field, that should be set in module.
youtube transcripts are of high priority than html5 by design
find rejected html5_id and remove appropriate subs from store
updates item.sub with new_name if it is successful.
subtitles file `item.sub` is not presented in the system. Nothing to copy or rename.
If `new_sub` is empty, it means that user explicitly does not want to use  transcripts for current video ids and we remove all transcripts from storage.
This is placed before has_course_author_access() to validate the location,  because has_course_author_access() raises  r if location is invalid.
use the item's course_key, because the usage_key might not have the run
NOTE: This list is disjoint from ADVANCED_COMPONENT_TYPES
Fetch the XBlock info for use by the container page. Note that it includes information  about the block's ancestors and siblings for use by the Unit Outline.
need to figure out where this item is in the list of children as the  preview will need this
The component_templates array is in the order of "advanced" (if present), followed  by the components in the order listed in COMPONENT_TYPES.
Libraries do not support discussions
Libraries do not support advanced components at this time.
usage_key's course_key may have an empty run property
Let the module handle the AJAX
unintentional update to handle any side effects of handle call  could potentially be updating actual course data or simply caching its values
Deny access if the entrance exam feature is disabled
Deny access if the user is valid, but they lack the proper object access privileges
Retrieve the entrance exam module for the specified course (returns 404 if none found)
if request contains empty value or none then save the default one.
Remove the entrance exam module for the specified course (returns 204 regardless of existence)
No other HTTP verbs/methods are supported at this time
Provide a default value for the minimum score percent if nothing specified
Confirm the course exists
Create the entrance exam section item.
Clean up any pre-existing entrance exam graders
Regex to capture Content-Range header ranges.
Do everything in a try-except block to make sure everything is properly cleaned up.
Use sessions to keep info about import progress
If the course has an entrance exam then remove it and its corresponding milestone.  current course state before import.
Get upload chunks byte ranges
no Content-Range header, so make one that will work
try-finally block for proper clean up after receiving last chunk.  This was the last chunk.
set failed stage number with negative sign in case of unsuccessful import
if we have a nested exception, then we'll show the more generic error message
an _accept URL parameter will be preferred over HTTP_ACCEPT in the header.
Only HTML or x-tgz request formats are supported (no JSON).
static tab needs its locator information to render itself as an xmodule
Tabs are identified by tab_id or locators.  The locators are used to identify static tabs since they are xmodules.  Although all tabs have tab_ids, newly created static tabs do not know  their tab_ids since the xmodule editor uses only locators to identify new objects.
original tab list in original order
the old_tab_list may contain additional tabs that were not rendered in the UI because of  global or course settings.  so add those to the end of the list.
persist the new order of the tabs
Tabs are identified by tab_id or locator
set the is_hidden attribute on the requested tab
Note for future implementations: if you delete a static_tab, then Chris Dodge  points out that there's other stuff to delete beyond this element.  This code happens to not delete static_tab so it doesn't come up.
Convert the field name to the Mongo name
note, due to the schema change we may not have a 'thumbnail_location'  in the result set
Does the course actually exist?!? Get anything from it to prove its  existence  no return it as a Bad Request response
compute a 'filename' which is similar to the location formatting, we're  using the 'filename' nomenclature since we're using a FileSystem paradigm  here. We're just imposing the Location string formatting expectations to  keep things a bit more consistent
first let's see if a thumbnail can be created
delete cached thumbnail even if one couldn't be created this time (else  the old thumbnail will continue to show)  now store thumbnail location only if we could create it
then commit the content
Make sure the item to delete actually exists.
ok, save the content into the trashcan
delete the original  remove from cache
Needed for Backbone delete/update.
points to the temporary course landing page with log in and sign up
points to the temporary edge page
All other xblocks with children have their own page
We should use the 'fields' kwarg for newer module settings/values (vs. metadata or data)
Entrance Exams: Chapter module positioning
remove first slash in asset path  otherwise it generates InvalidKeyError in case of split modulestore  If the asset was not found, it doesn't have to be deleted...
Include the data contract version  Ensure a signatories list is always returned
Some keys are not required, such as the title override...
Return a new Certificate object instance
The top-level course field is 'certificates', which contains various properties,  including the actual 'certificates' list that we're working with in this context
Now drop the certificate record
for certificate activation/deactivation, we are assuming one certificate in certificates collection.
we are assuming only one certificate in certificates collection.
Only global staff (PMs) are able to edit active certificate configuration
Only global staff (PMs) are able to delete active certificate configuration
pylint: disable=unused-variable
afaik, this is only used in lti
Default expiration, in seconds, of one-time URLs used for uploading videos.
Translators: This is the header for a CSV file column  containing URLs for video encodings for the named profile  (e.g. desktop, mobile high quality, mobile low quality)
For now, assume all studio users that have access to the course can upload videos.  In the future, we plan to add a new org-level role for video uploaders.
convert VAL's status to studio's Video Upload feature status.
Useful constants for defining predicates
wrap the generated fragment in the xmodule_editor div so that the javascript  can bind to it correctly
Determine the items to be shown as reorderable. Note that the view  'reorderable_container_child_preview' is only rendered for xblocks that  are being shown in a reorderable container, so the xblock is automatically  added to the list.
Set up the context to be passed to each XBlock's render method.
Update after the callback so any changes made in the callback will get persisted.
Perform all xblock changes within a (single-versioned) transaction
Don't allow updating an xblock and discarding changes in a single operation (unsupported by UI).  Returning the same sort of result that we do for other save operations. In the future,  we may want to return the full XBlockInfo.
set the children on the xblock
update the xblock and call any xblock callbacks
Make public after updating the xblock, in case the caller asked for both an update and a publish.  Used by Bok Choy tests and by republishing of staff locks.
Note that children aren't being returned until we have a use case.
Only these categories are supported at this time.
Change the blockID to be unique.
Children are not automatically copied over (and not all xblocks have a 'children' attribute).  Because DAGs are not fully supported, we need to actually duplicate each child as well.
specify branches when deleting orphans
Create a new one for certain categories only. Used for course info handouts.
Pre-cache has changes for the entire course because we'll need it for the ancestor info  Except library blocks which don't [yet] use draft/publish
Note that children aren't being returned until we have a use case.
this should not be calculated for Sections and Subsections on Unit page or for library blocks
Filter the graders data as needed
We need to load the course in order to retrieve user partition information.  For this reason, we load the course once and re-use it when recursively loading children.
defining the default value 'True' for delete, drag and add new child actions in xblock_actions for each xblock.
Update with gating info
Entrance exam subsection should be hidden. in_entrance_exam is  inherited metadata, all children will have it.
Note that a unit that has never been published will fall into this category,  as well as previously published units with draft content.
If year of start date is less than 1900 then reset the start date to DEFAULT_START_DATE  For old mongo courses, accessing the start attribute calls `to_json()`,  which raises a `ValueError` for years < 1900.
Treat DEFAULT_START_DATE as a magic number that means the release date has not been set
check that logged in user has permissions to this item
the page only lists staff and assumes they're a superset of instructors. Do a union to ensure.
Ordered list of roles: can always move self to the right, but need STUDIO_EDIT_ROLES to move any user left
All of the following code is for editing/promoting/deleting users.  Check that the user has STUDIO_EDIT_ROLES permission or is editing themselves:
User has STUDIO_EDIT_ROLES permission or  is currently a member of a higher role, and is thus demoting themself
Remove the user from this old role:
The user may be newly added to this course.  auto-enroll the user in the course so that "View Live" will work.
Let the module handle the AJAX
xmodules can check for this attribute during rendering to determine if  they are being rendered for preview (i.e. in Studio)
This wrapper wraps the module in the template specified above
This wrapper replaces urls in the output that start with /static  with the correct course-specific url for the static content
stick the license wrapper in front
Set up functions to modify the fragment produced by student_view  Get the raw DescriptorSystem, not the CombinedSystem
POST requests were coming in w/ these header values causing an error; so, repro error here
refetch using provided id
now put in an evil update
try json w/o required fields
test an update with text in the tail of the header
update w/ malformed html
set to valid html which would break an xml parser
now try to delete a non-existent update
now confirm that the bad news and the iframe make up single update
create a course via the view handler
check that response status is 200 not 400
check that push notifications are not sent
check posting on handouts
check that response status is 200 not 500
Create some more libraries
extra_user has not been assigned to the library so should not show up in the list:
Now extra_user should apear in the list:
Verify course URL
Verify video URL
Verify library URL
Verify child vertical type display name
had a problem where index showed course but has_access failed to retrieve it for non-staff
Add a library:
now test that url
register a non-staff member and try to delete the course branch
test access
Finally, validate the entire response for consistency
try when no notification exists
verify that we get an empty dict out
create a test notification
add an instructor to this course
create a test notification
delete nofications that are dismissed
Change 'display_coursenumber' field to None and update the course.
Assert that 'display_coursenumber' field has been changed successfully.
Perform GET request on course outline url with the course id.
Assert that response code is 200.
Assert that 'display_course_number' is being set to "" (as display_coursenumber was None).
Finally, validate the entire response for consistency
Verify that None is returned for a non-existent locator
A course with the default release date should display as "Unscheduled"
info['blocks'] should be empty here because there is nothing  published or un-published present
Delete the un-published vertical or problem so that CourseStructure updates its data
info['blocks'] should only contain the info about vertical2 which is published.  There shouldn't be any info present about un-published vertical1
A course with the default release date should display as "Unscheduled"
register a non-staff member and try to delete the course branch
A course with the default release date should display as "Unscheduled"
set mocked exception response
Start manual reindex and check error in response
results are indexed because they are published from ItemFactory
Start manual reindex
Check results remain the same
results are indexed because they are published from ItemFactory
set mocked exception response
Start manual reindex and check error in response
results are indexed because they are published from ItemFactory
set mocked exception response
Start manual reindex and check error in response
results are indexed because they are published from ItemFactory
set mocked exception response
Start manual reindex and check error in response
set mocked exception response
Start manual reindex and check error in response
register a non-staff member and try to delete the course branch
results are indexed because they are published from ItemFactory
Start manual reindex
Check results are the same following reindex
results are indexed because they are published from ItemFactory
set mocked exception response
Start manual reindex and check error in response
results are indexed because they are published from ItemFactory
set mocked exception response
Start manual reindex and check error in response
results are indexed because they are published from ItemFactory
set mocked exception response
Start manual reindex and check error in response
set mocked exception response
Start manual reindex and check error in response
Test the draft version of the container
Now publish the unit and validate again
Check for invalid 'usage_key_strings'
Check 200 response if 'usage_key_string' is correct
Reload the test course now that the exam module has been added
What we have now is a course milestone requirement and no valid fulfillment  paths for the specified user.  The LMS is going to have to ignore this situation,  because we can't confidently prevent it from occuring at some point in the future.  milestone_key_1 =
No return, so we'll just ensure no exception is thrown
call super class to setup course, etc.
Set the URL for tests
add a static tab to the course, for code coverage
JSON GET request not supported
invalid JSON POST request
get the original tab ids
make sure we have enough tabs to play around with
reorder the last two tabs
remove the middle tab  (the code needs to handle the case where tabs requested for re-ordering is a subset of the tabs in the course)
post the request
reload the course and verify the new tab order
reorder the first two tabs
post the request
find the tab
visibility should be different from new setting
reload the course and verify the new visibility setting
Check that discussion has shifted up
Note: Actual contentType for textbook.pdf in asset.json is 'text/pdf'
simulation of html page where base_url is up-to asset's main directory  and relative_path is dom element with its src  browser append relative_path with base_url
Verify valid page requests
pylint: disable=protected-access
pylint: disable=protected-access
Load the toy course.
Lock the asset
Unlock the asset
First, upload something.
Check that `import_status` returns the appropriate stage (i.e., the  stage at which import failed).
Create a non_staff user and add it to course staff only
Check that course display name have changed after import
Now check that non_staff user has his same role
Now check that non_staff user has his same role
test trying to open a tar outside of the normal data directory
the extract_dir needs to be passed as a relative dir to  import_library_from_xml
the extract_dir needs to be passed as a relative dir to  import_library_from_xml
the extract_dir needs to be passed as a relative dir to  import_library_from_xml
Import the exported library into a different content library.
Compare the two content libraries for equality.
we don't have resp.context right now,  due to bugs in our testing harness :(
should be the same, except for added ID
Save the data that we've just changed to the underlying  MongoKeyValueStore before we update the mongo datastore.
Crude check for presence of data in returned HTML
Top level missing files key
Entry missing file_name
Entry missing content_type
If extra calls are made, return a dummy
Ensure response is correct
Call get_preview_fragment directly.
Call get_preview_fragment directly.
No property name.
Verify that user_partitions is properly updated in the course.
Verify that user_partitions is still the same.
Verify that user_partitions is properly updated in the course.
Verify that user_partitions is properly updated in the course.
Verify that user_partitions is still the same.
Verify that user_partitions is still the same.
Get the actual content group information
Assert that actual content group information is same as expected one.
This used to cause an exception since the code assumed that  only one partition would be available.
pylint: disable=no-value-for-parameter
When no data is provided, expect creation prompt.
When data is provided, expect a program listing.
Enable Programs authoring interface
this comparison is a little long-handed because we need to compare user instances directly
ext_user is not currently a member of the course team, and so should  not show up on the page.
reload user from DB
reload user from DB
reload user from DB
reload user from DB
reload user from DB
reload user from DB
Verify that ext_user is not enrolled in the new course before being added as a staff member.
Enable subsection gating for the test course
create a chapter
Remove all transcripts for current module.
incorrect xml produces incorrect item category error
Verify that ufeff character is in filedata.
Test for raising `InvalidLocationError` exception.
Add a vertical
Retrieve it
XBlock messages are added by the Studio wrapper.  Make sure that "wrapper-xblock" does not appear by itself (without -message at end).
Verify that the header and article tags are still added
Add a problem beneath a child vertical
Get the preview HTML
Verify that the Studio element wrapper has been added
Add a wrapper with child beneath a child vertical
Add static tab
Now delete it. There was a bug that the delete was failing (static tabs do not exist in draft modulestore).
create a chapter
get the course and ensure it now points to this one
use default display name
non-existent boilerplate: creates a default
Add a new static tab with no explicit name
Check that its name is not None
pylint: disable=no-member
pylint: disable=no-member
Set the location, display name, and parent to be the same so we can make sure the rest of the  duplicate is equal.
pylint: disable=no-member
Create a parent chapter (for testing children of children).
create a sequential containing a problem and an html component
create problem and an html component
Create a second sequential just (testing children of children)
2 because duplicate of problem should be located before.
Test duplicating something into a location that is not the parent of the original item.  Duplicated item should appear at the end.
Uses default display_name of 'Text' from HTML component.
The sequence does not have a display_name set, so category is shown.
Now send a custom display name for the duplicate.
Create a parent chapter
create a sequential containing a problem and an html component
create problem and an html component
create a chapter
create 2 sequentials
Remove one child from the course.
Verify that the child is removed.
The sequential already has a child defined in the setUp (a problem).  Children must be on the sequential to reproduce the original bug,  as it is important that the parent (sequential) NOT be in the draft store.
move unit 1 from sequential1 to sequential2
verify children
verify children
verify children
When the problem is first created, it is only in draft (because of its category).
Publish the item
Both published and draft content should be different
The unit and its children should be private initially
Even though user_partition_id is Scope.content, it will get saved by the Studio editor as  metadata. The code in item.py will update the field correctly, even though it is not the  expected scope.
Verify the partition_id was saved.
Initially, no user_partition_id is set, and the split_test has no children.
Set the user_partition_id to 0.
Set to first group configuration.
Set to first group configuration.
Set again to first group configuration.
Set to first group configuration.
Set to an group configuration that doesn't exist.
Set to first group configuration.
group_id_to_child and children have not changed yet.
Call add_missing_groups again -- it should be a no-op.
component_handler calls modulestore.get_item to get the descriptor of the requested xBlock.  Here, we mock the return value of modulestore.get_item so it can be used to mock the handler  of the xBlock descriptor.
Have to use the right method to create the request to get the HTTP method that we want
Initialize the deprecated modules settings with empty list
calls should be same after adding two new children for split only.
in case of entrance exam subsection, header should be hidden.
sequential xblock info should not contains the key of 'is_header_visible'.
Finally, validate the entire response for consistency
Finally, validate the entire response for consistency
Finally, validate the entire response for consistency
Finally, validate the entire response for consistency
Finally, validate the entire response for consistency
exam proctoring should be enabled and time limited.
exam proctoring should be enabled and time limited.
In case the staff_only state was set, return the updated xblock.
Finally verify the state of the chapter
Check that chapter has scheduled state
Change course pacing to self paced
Check that in self paced course content has live state now
Verify drag handles always appear.
Verify that there are no add buttons for public blocks
must have name of the certificate
an empty json
in html response
pylint: disable=unused-argument
ensure that we have a course and an action state
we assume any delete requests dismiss actions from the UI
Can't dismiss a notification that doesn't exist in the first place
We remove all permissions for this course key at this time, since  no further access is required to a course that failed to be created.
The CourseRerunState is no longer needed by the UI; delete
Custom Courses for edX (CCX) is an edX feature for re-using course content.  CCXs cannot be edited in Studio (aka cms) and should not be shown in this dashboard.
If the course_access does not have a course_id, it's an org-based role, so we fall back
ignore deleted, errored or ccx courses
No need to worry about ErrorDescriptors - split's get_libraries() never returns them.
user has global access so no need to get courses from django groups
user have some old groups or there was some error getting courses from django groups  so fallback to iterating through all courses
force the start date for reruns and allow us to override start via the client
Set default language from settings and enable web certs
Creating the course raises DuplicateCourseError if an existing course with this org/name is found
Make sure user has instructor and staff access to the new course
Initialize permissions for user in the new course
verify user has access to the original course
create destination course key
verify org course and run don't already exist
Make sure user has instructor and staff access to the destination course  so the user can see the updated status for that course
Mark the action as initiated
Clear the fields that must be reset for the rerun
Rerun the course as a new celery task
Return course listing page
check that logged in user has permissions to this item (GET shouldn't require this level?)
exclude current course from the list of available courses
get and all credit eligibility requirements  pair together requirements with same 'namespace' values
if 'minimum_grade_credit' of a course is not set or 0 then  show warning message to course author.
encoder serializes dates, old locations, and instances
If the entrance exam box on the settings screen has been unchecked,  and the course has an entrance exam attached...
Perform the normal update workflow for the CourseDetails model
encoder serializes dates, old locations, and instances
update credit course requirements if 'minimum_grade_credit'  field value is changed
Additionally update any tabs that are provided by non-dynamic course views
Save the tabs into the course if they have been changed
validate data formats and update the course module.  Note: don't update mongo yet, but wait until after any tabs are changed
update the course tabs if required by any setting changes
now update mongo
Handle all errors that validation doesn't catch
stick a random digit in front
add a random ASCII character to the end
create a new group configuration for the course
django is rewriting one to the other
User not grandfathered in as an existing user, has not previously visited the dashboard page.  Add the user to the course creator admin table with status 'unrequested'.
request method is get, since only GET and POST are allowed by @require_http_methods(('GET', 'POST'))
Give the user admin ("Instructor") role for this library:
Redirect to course to login to process their certificate if SSL is enabled  and registration is disabled.
SSL login doesn't require a login view, so redirect  to course now that the user is authenticated via  the decorator.
If CAS is enabled, redirect auth handling to there
Note: the following content group configuration strings are not  translated since they are not visible to users.
Check both that the user is created, and inactive
and now we try to activate
Now make sure that the user is now actually activated
clear the cache so ratelimiting won't affect these tests
we have a constraint on unique usernames, so this should fail
we can have two users with the same password, so this should succeed
Not activated yet.  Login should fail.
Now login should work
account should not be locked out after just one attempt
do one more login when there is no bad login counter row at all in the database to  test the "ObjectNotFound" case
we want to test the rendering of the activation page when the user isn't logged in
check the the HTML has links to the right login page. Note that this is merely a content  check and thus could be fragile should the wording change on this page
These are pages that should just load when the user is logged in  (no data needed)
need an activated user
Create a new session
Not logged in.  Should redirect to login.
Logged in should work.
not logged in.  Should return a redirect.
make sure we can access courseware immediately
then wait a bit and see if we get timed out
re-request, and we should get a redirect to login page
test if user gives empty blackout date it should return true for forum_posts_allowed
Make user staff to access course listing
Change 'display_coursenumber' field and update the course.
Check if response is escaped
get courses through iterating all courses
get courses by reversing group name formats
check both course lists have same courses
Create a course and assign access roles to user.
Create a ccx course key and add assign access roles to user.
Test that CCX courses are filtered out.
Get all courses which user has access.
Verify that CCX course exists in access but filtered by `_accessible_courses_list_from_groups`.
get courses through iterating all courses
get courses by reversing group name formats
Assign & verify staff role to the user
Fetch accessible courses list & verify their count
Verify fetched accessible courses list is a list of CourseSummery instances
Now count the db queries for staff
get courses through iterating all courses
get courses by reversing group name formats
get courses through iterating all courses
Verify fetched accessible courses list is a list of CourseSummery instances and only one course  is returned
get courses by reversing group name formats
check course lists have same courses
now delete this course and re-add user to instructor group of this course
Get courses through iterating all courses
Get course summaries by iterating all courses
Get courses by reversing group name formats
Test that course list returns no course
create list of random course numbers which will be accessible to the user
time the get courses by iterating through all courses
time again the get courses by iterating through all courses
time the get courses by reversing django groups
time again the get courses by reversing django groups
test that the time taken by getting courses through reversing django groups is lower then the time  taken by traversing through all courses (if accessible courses are relatively small)
Now count the db queries
Two types of org-wide roles have edit permissions: staff and instructor.  We test both
Verify fetched accessible courses list is a list of CourseSummery instances and test expacted  course count is returned
simulate initiation of course actions
Build out local bare repo, and set course git url to it
make sure that any children with one orphan parent and one non-orphan  parent are not deleted
Get a course with orphan modules
Verify `OrphanVert` is an orphan
Verify `multi_parent_html` is child of both `Vertical1` and `OrphanVert`
Verify `OrhanChapter` is an orphan
Verify chapter1 is parent of vertical1.
Make `Vertical1` the parent of `HTML0`. So `HTML0` will have to parents (`Vertical0` & `Vertical1`)
Get parent location & verify its either of the two verticals. As both parents are non-orphan,  alphabetically least is returned
test that course 'display_name' same as imported course 'display_name'
make sure course.static_asset_path is correct
make sure we have NO assets in our contentstore
we try to refresh the inheritance tree for each update_item in the import
_get_cached_metadata_inheritance_tree should be called only once
Import first time
Re-import
Check transcripts_utils.GetTranscriptsFromYouTubeException not thrown
Disabled 11/14/13  This test is flakey because it performs an HTTP request on an external service  Re-enable when `requests.get` is patched using `mock.patch`
Check transcripts_utils.GetTranscriptsFromYouTubeException not thrown
Check transcripts_utils.TranscriptsGenerationException not thrown.  Also checks that uppercase file extensions are supported.
unspecified start - should inherit from container
Only published modules should be in the index
Publish the vertical as is, and any unpublished children should now be available
Publish the vertical to start with
Now publish it and we should find it  Publish the vertical as is, and everything should be available
index the course in search_index
Publish the vertical to start with
just a delete should not change anything
but after publishing, we should no longer find the html_unit
Publish the vertical to start with
even after publishing, we should not find the non-indexable item
Publish the vertical
Add a new sequential
index based on time, will include an index of the origin sequential  because it is in a common subtree but not of the original vertical  because the original sequential's subtree is too old
full index again
index full course
reload course to allow us to delete one single unit
delete the first chapter
index and check correctness
Catch any exception here to see when we fail
unspecified start - should inherit from container
Note that this test will only succeed if celery is working in inline mode
Note that this test will only succeed if celery is working in inline mode
libraries work only with split, so do library indexer
updating a library item causes immediate reindexing
deleting a library item causes immediate reindexing
Activate french, so that if the fr files haven't been loaded, they will be loaded now.
wrap the ugettext functions so that 'XYZ ' will prefix each translation
Check that the old ugettext has been put back into place
Create the use so we can log them in.
1. import and populate test toy course
NOTE: When the code above is uncommented this can be removed.
Create a course using split modulestore
Check if re-run was successful
Now, we want to make sure that .children has the total  of potential  children, and that get_child_descriptors() returns the actual children  chosen for a given student.  In order to be able to call get_child_descriptors(), we must first  call bind_for_student:
Check which child a student will see:
Refresh the children:  Now re-load the block and try yet again, in case refreshing the children changed anything:
Next, create a course:
Next, create a course:
Add a LibraryContent block to the course:
Next, create a course:
Add a LibraryContent block to the course:
Create a course:
Add a LibraryContent block to the course:
Create a course:
Add a LibraryContent block to the course:
Create a course:
Add a LibraryContent block to the course:
Now log out and ensure we are forbidden from creating a library:
At this point, one library exists, created by the currently-logged-in staff user.  Create another library as staff:  Login as non_staff_user:
Now manually intervene to give non_staff_user access to library2_key:
Create some libraries as the staff user:
Login as a non-staff:
Now manually intervene to give non_staff_user access to all "PacificX" libraries:
As staff user, add a block to self.library:
Login as a non_staff_user:
Give non_staff_user read-only permission:
As staff user, add a block to self.library:  And create a course:
Assign roles:
As staff user, add a block to self.library:  And create a course:
Assign roles:
Create a problem block in the library:
Refresh library now that we've added something.
Also create a course:
Reset:
Save, reload, and verify:
Refresh our reference to the library
Refresh our reference to the block
The library has changed...
Create a course in an incompatible modulestore.
Add a LibraryContent block to the course:
default for ENABLE_MKTG_SITE is False.
test preview
now test with the course' location
Create an unreleased draft version of the xblock
any xblock with visible_to_staff_only set to True should not be visible to students.
Orphan the orphaned xblock
Test with group_access set to Falsey values.
This is a no-op.
Update group access and expect that now one group is marked as selected.
Select a group that is not defined in the partition
Expect that the inactive scheme is excluded from the results
Expect that the partition with no groups is excluded from the results
Verify the course has imported successfully
Get & verify that course actually has two assets
Verify both assets have similar `displayname` after saving.
Test course export does not fail
Verify that asset have been overwritten during export.
Remove exported course
this one should be in a non-override folder
make sure we have some assets in our contentstore
make sure we have some thumbnails in our contentstore
verify that course info update module has same data content as in data file from which it is imported  check 'data' field content
now export the course to a tempdir and test that it contains files 'updates.html' and 'updates.items.json'  with same content as in course 'info' directory
verify that exported course has same data content as in course_info_update module
then check a intra courseware link
export out to a tempdir
check for static tabs
check for about content
check for grading_policy.json
compare what's on disk compared to what we have in our course
check for policy.json
remove old course
reimport over old course
import to different course id
reimport
verify content of the course
create a new video module and add it as a child to a vertical  this re-creates a bug whereby since the video template doesn't have  anything in 'data' field, the export was blowing up
export out to a tempdir
export out to a tempdir
Create a module, and ensure that its `data` field is empty
Export the course
Reimport and get the video back
It should now contain empty data
Export the course
Reimport and get the video back
create OpenAssessmentBlock:  convert it to draft
note that it has no `xml_attributes` attribute
export should still complete successfully
just pick one vertical
Test that malicious code does not appear in html
This could be made better, but for now let's just assert that we see the advanced modules mentioned in the page  response HTML
Verify that the course has only one asset and it has been added with an invalid asset name.
Verify that only single asset has been exported with the expected asset name.
Remove tempdir
Fetch & verify course assets to be equal to 2.
Verify both assets have similar 'displayname' after saving.
Verify that asset have been overwritten during export.
Remove tempdir
just pick one vertical
refetch to check metadata
publish module
refetch to check metadata
put back in draft and change metadata and see if it's now marked as 'own_metadata'
Save the data that we've just changed to the underlying  MongoKeyValueStore before we update the mongo datastore.
read back to make sure it reads as 'own-metadata'
republish
and re-read and verify 'own-metadata'
make sure no draft items have been returned
put into draft
make sure we can query that item and verify that it is a draft
now requery with depth
make sure just one draft item have been returned
check that there's actually content in the 'question' field
also try a custom response which will trigger the 'is this course in whitelist' logic
make sure the parent points to the child object which is to be deleted  need to refetch chapter b/c at the time it was assigned it had no children
make sure the parent no longer points to the child object which was deleted
now try to find it in store, but they should not be there any longer
now try to find it and the thumbnail in trashcan - should be in there
let's restore the asset
now try to find it in courseware store, and they should be back after restore
make sure there's something in the trashcan
empty the trashcan
make sure trashcan is empty
this test presumes old mongo and split_draft not full split
Now test that 404 response is returned when user tries to access  asset of some invalid course from split ModuleStore
delete the course
assert that there's absolutely no non-draft modules in the course  this should also include all draft items
assert that all content in the asset library is also deleted
get module info (json)
make sure we pre-fetched a known sequential which should be at depth=2
make sure we don't have a specific vertical which should be at depth=3
Verify that the creator is now registered in the course.
should raise an exception for checking permissions on deleted course
unseed the forums for the first course  should raise an exception for checking permissions on deleted course
permissions should still be there for the other course
test that a user gets his enrollment and its 'student' role as default on creating a course
check that user's enrollment for this course is not deleted  check that user has form role "Student" for this course even after deleting it
Add user in possible groups and check that user in instructor groups of this course
Now delete course and check that user not in instructor groups of this course
Update our cached user since its roles have changed
b/c the intent of the test with bad chars isn't to test auth but to test the handler, ignore
One test case involves trying to create the same course twice. Hence for that course,  the user will be enrolled. In the other cases, initially_enrolled will be False.
Helper function for getting HTML for a page in Studio and  checking that it does not error.
delete a component
delete a unit
delete a unit
delete a chapter
we should have a number of modules in there  we can't specify an exact number since it'll always be changing
first check PDF textbooks, to make sure the url paths got updated
make sure we found the item (e.g. it didn't error while loading)
create a discussion item
now fetch it from the modulestore to instantiate its descriptor
refetch it to be safe
and make sure the same discussion items have the same discussion ids
and make sure that the id isn't the old "$$GUID$$"
let's assert on the metadata_inheritance on an existing vertical
crate a new module and add it as a child to a vertical
flush the cache
check for grace period definition which should be defined at the course level
now let's define an override at the leaf node level
flush the cache and refetch
Use conditional_and_poll, as it's got an image already
Make sure the course image is set to the right place
Ensure that the imported course image is present -- this shouldn't raise an exception
create data to post
post the request
Verify that the creator is now enrolled in the course.
Verify both courses are in the course listing section
Verify that the VAL copies videos to the rerun
Verify that the creator is not enrolled in the course.
Verify that the existing course continues to be in the course listings
Verify that the failed course is NOT in the course listings
Verify that the course rerun action doesn't exist
Verify that the existing course continues to be in the course listing
Verify created course's wiki_slug.
Verify rerun course's wiki_slug.
Logout redirects.
refetch parent which should now point to child
This test is in the CMS module because the test configuration to use a draft  modulestore is dependent on django.
get the review policy object
the hide after due value only applies to timed exams
update the sequence
simulate a publish
reverify
republish course
look through exam table, the dangling exam  should be disabled
there shouldn't be any exams because we haven't enabled that  advanced setting flag
create and log in a staff user.
create a course via the view handler to create course
check that user has enrollment for this course
check that user has his default "Student" forum role for this course
check that user's enrollment for this course is not deleted
check that user has forum role for this course even after deleting it
check that user has enrollment and his default "Student" forum role for this course
delete this course and recreate this course with same user
check that user has his enrollment for this course
check that user has his default "Student" forum role for this course
check that user has enrollment and his default "Student" forum role for this course  delete this course and recreate this course with same user
now create same course with different name case ('uppercase')
check that user has his default "Student" forum role again for this course (with changed name case)
create a Private (draft only) vertical
lock an asset
verify draft vertical has a published version with published children
verify that it has a draft too
make sure that we don't have a sequential that is in draft mode
verify that we have the private vertical
verify that we have the public vertical
verify that we have the draft html
verify that we have the draft video
verify verticals are children of sequential
verify draft html is the child of the public vertical
verify draft video is the child of the public vertical
verify textbook exists
verify asset attributes of locked asset key
verify non-portable links are rewritten
compare published state
compare meta-data
assert pre_requisite_courses is initialized
fetch updated course to assert pre_requisite_courses has new values
entrance_exam_minimum_score_pct is not present in the request so default value should be saved.
Unlike other tests, need to actually perform a db fetch for this test since update_cutoffs_from_json   simply returns the cutoffs you send into it, rather than returning the db contents.
update_grace_period_from_json doesn't return anything, so query the db for its contents.
Get the descriptor and the section_grader_type and assert they are the default values
see if test makes sense
Check valid results from validate_and_update_from_json
try fresh fetch to ensure no update happened
First ensure that none of the tabs are visible
verify that the course wasn't saved into the modulestore
the login error may be absent or invisible. Check absence first,  because css_visible will throw an exception if the element is not present
files_string should be comma separated with no spaces.
Since our only test for deletion right now deletes  the only file that was uploaded, our success criteria  will be that there are no files.  In the future we can refactor if necessary.
resetting the file back to its original state
resetting the file back to its original state
Note that world.visit would trigger a 403 error instead of displaying "Unauthorized"  Instead, we can drop back into the selenium driver get command.
try to change the grade range -- this should throw an exception
check to be sure that nothing has changed
Set the new grace period
The default value is 00:00  so we need to wait for it to change
This view presents the given problem component in uppercase. Assert that the text matches  the component selected
Wait for the saving notification to pop up then disappear
The display name for the unit uses the same structure, must differentiate by level-element.
Verify order of pages
For some reason, the drag_and_drop method did not work in this case.
To make this go to port 8001, put  LETTUCE_SERVER_PORT = 8001  in your settings.py file.
Navigate to the studio dashboard
Navigate to the studio dashboard
hit TAB or provided key to trigger save content
The file upload dialog is a faux modal, a div that takes over the display
Clicking the Upload button triggers an AJAX POST.
The modal stays up with a "File uploaded succeeded" confirmation message, then goes away.  It should take under 2 seconds, so wait up to 10.  Note that is_css_not_present will return as soon as the element is gone.
admins get staff privileges, as well
Verifying that the display name can be a string containing a floating point value  (to confirm that we don't throw an error because it is of the wrong type).
Go to course outline
We should wait 300 ms for event handler invocation + 200ms for safety.
Store the current URL so we can return here
Upload subtitles for the video using the upload interface
Return to the video
update .sub filed with proper subs name (which mimics real Studio/XML behavior)  this is needed only for that videos which are created in acceptance tests.
We should wait 300 ms for event handler invocation + 200ms for safety.
For some reason ChromeDriver doesn't trigger an 'input' event after filling  the field with an empty value. That's why we trigger it manually via jQuery.
A few deprecated settings for testing toggling functionality.
Test only a few of the existing properties (there are around 34 of them)
Sometimes get stale reference if I hold on to the array of elements
Verify course start date (required) and time still there
Time should have stayed from before attempt to clear date.
hit Enter to apply the changes
We need to wait for JavaScript to fill in the field, so we use  css_has_value(), which first checks that the field is not blank
Unset times get set to 12 AM once the corresponding date has been set.
Format dropdown  Font dropdown
This is our custom "code style" button. It uses an image instead of a class.
Verify that CodeMirror editor is not hidden  Verify that TinyMCE Editor is not present
Click on plugin button
Click on plugin button
Wait for the plugin window to open.
Trigger the action
Click OK
Count how many of that module is on the page. Later we will  assert that one more was added.  We need to use world.browser.find_by_css instead of world.css_find  because it's ok if there are currently zero of them.
Disable the jquery animation for the transition to the menus.
Wait for the advanced tab items to be displayed
The tab shows buttons for the given category
Find the button whose text matches what you're looking for
There should be one and only one
Sometimes this click does not work if you go too fast.
Retry this in case the list is empty because you tried too fast.
Wait for the link to be clickable. If you go too fast it is not.
Select the 'settings' tab if there is one (it isn't displayed if it is the only option)
We have a known issue that modifications are still shown within the edit window after cancel (though)  they are not persisted. Refresh the browser to make sure the changes WERE persisted after Save.
We have a known issue that modifications are still shown within the edit window after cancel (though)  they are not persisted. Refresh the browser to make sure the changes were not persisted.
can't use auth.add_users here b/c it requires user to already have Instructor perms in this course
seed the forums
auto-enroll the course creator in the course so that "View Live" will work.
set default forum roles (assign 'Student' role)
in the django layer, we need to remove all the user permissions groups associated with this course
Root will be "https://www.edx.org". The complete URL will still not be exactly correct,  but redirects exist from www.edx.org to get to the Drupal course about page URL.
Strip off https:// (or http://) to be consistent with the formatting of LMS_BASE.
If there's no published version then the xblock is clearly not visible
If visible_to_staff_only is True, this xblock is not visible to students regardless of start date.
Check start date
No start date, so it's always visible
Stop searching at the section level
Orphaned xblocks set their own release date
Stop searching if this xblock has explicitly set its own staff lock
Stop searching at the section level
Orphaned xblocks set their own staff lock
Exclude disabled partitions, partitions with no groups defined  Also filter by scheme name if there's a filter defined.
First, add groups defined by the partition
Put together the entire partition dictionary
Pre-process the partitions to make it easier to display the UI
import here, at top level this import prevents the celery workers from starting up correctly
deserialize the payload
use the split modulestore as the store for the rerun course,  as the Mongo modulestore doesn't support multiple runs of the same course.
set initial permissions for the user to access the course.
update state: Succeeded
call edxval to attach videos to the rerun
do NOT delete the original course, only update the status
update state: Failed
cleanup any remnants of the course
it's possible there was an error even before the course module was created
remove the +00:00 from the end of the formats generated within the system
Wrap counter in dictionary - otherwise we seem to lose scope inside the embedded function `prepare_item_index`
items_index is a list of all the items index dictionaries.  it is used to collect all indexes and index them using bulk API,  instead of per item index API call.
if it's not indexable and it does not have children, then ignore
First perform any additional indexing from the structure object
Now index the content
broad exception so that index operation does not prevent the rest of the application from working
Source location options - either from the course or the about info
load data for all of the 'about' modules for this course into a dictionary
Broad exception handler so that a single bad property does not scupper the collection of others
Broad exception handler to protect around and report problems with indexing
Open and parse the configuration file when the module is initialized
Patch the xml libs before anything else.
Disable PyContract contract checking when running as a webserver
This application object is used by the development server  as well as any WSGI server configured to use this file.
Delete all data added by data migrations. Unit tests should setup their own data using factories.
Start with empty caches
Make sure that cache contents don't leak out after the isolation is ended
N.B. As of 2016-04-20, Django won't return any caches  from django.core.cache.caches.all() that haven't been  accessed using caches[name] previously, so we loop  over our list of overridden caches, instead.
The sites framework caches in a module-level dictionary.  Clear that.
pylint: disable=method-hidden
force garbarge collection
pylint: disable=protected-access
If any mixins have been applied, then use the unmixed class
The block is acting as an XModule
The block is acting as an XModuleDescriptor
Replace / with \/ so that "</script>" in the data won't break things.
Replace / with \/ so that "</script>" in the data won't break things.
Passing module_id this way prevents sql-injection.
build edit link to unit in CMS. Can't use reverse here as lms doesn't load cms's urls.py
return edit link in rendered HTML for display
if original, unmangled filename exists then use it (github  doesn't like symlinks)
Need to define all the variables that are about to be used
could enforce that update[0].tag == 'h2'
return list in reversed order (old format: [4,3,2,1]) for compatibility
There's no need to get_parents
If filter_func isn't provided, make it a no-op.
Use deque for the stack, which is O(1) for pop and append.  Use the _Node class to keep track of iterated children.
Keep track of which nodes have been visited.
Peek at the current node at the top of the stack.
Verify the node wasn't already visited and the node  satisfies the filter_func.  Since already visited or filtered out, remove from the  stack and continue with the next node.
See if there are any additional children for this node.
Since there are no children left, visit the node and  remove it from the stack.
If so, add the child to the top of the stack.
If filter_func isn't provided, make it a no-op.
Use deque for the stack, which is O(1) for pop and append.
While there are more nodes on the stack...
Take a node off the top of the stack.
If we're doing a topological traversal, then make sure all  the node's parents have been visited. If they haven't,  then skip the node for now; we'll encounter it again later  through another one of its parents.
If all of the parents have not yet been visited, continue.
If none of the parents have yielded, continue, unless  specified otherwise (via yield_descendants_of_unyielded).
If the current node has already been visited, continue.
For a topological sort, add all the children since  they would not have been visited.
For a pre-order sort, filter out already visited  children.
Add the node's unvisited children to the stack in reverse  order so they are traversed in their original order.
Yield the result of the node if the node satisfies the  filter_func.
Keep track of whether or not the node was yielded so we  know whether or not to yield its children.
Service users may not have user profiles.
Service users may not have user profiles.
Revert to INFO if an invalid string is passed in
default to a blank string so that if SERVICE_VARIANT is not  set we will not log to a sub directory
if image_key is empty, use the default image url from settings
Not intented for programmatic use, so we print the keys out
See if there's a startup module in each app.
If the module has a run method, run it.
use lynx to get plaintext
Stevedore extension point namespaces
Register a prefix that collectstatic will add to each path
First, try to update the existing instance  If no instance exists yet, create it.  This is backwards-compatible with the behavior of DRF v2.
Backwards compatibility with DRF v2 behavior, which would catch model-level  validation errors and return a 400
For PUT-as-create operation, we need to ensure that we have  relevant permissions, as if this was a POST request.  This  will either raise a PermissionDenied exception, or simply  return None.
PATCH requests where the object does not exist should still  return a 404 response.
map over the search results and get a list of database objects in the same order
Unauthenticated, CSRF validation not required  This is where regular `SessionAuthentication` checks that the user is active.  We have removed that check in this implementation.  But we added a check to prevent anonymous users since we require a logged-in account.
CSRF passed with authenticated user
AuthenticationFailed is a subclass of drf_exceptions.AuthenticationFailed,  but we don't want to post-process the exception detail for our own class.
Note: we're creating the extension manager lazily to ensure that the Python path  has been correctly set up. Trying to create this statically will fail, unfortunately.
Demonstrate the base issue we are trying to solve.
This is the a change we've made from the django-rest-framework-oauth version  of these tests.
If no Authorization header is provided that contains a bearer token,  authorization passes to the next registered authorization class, or  (in this case) to standard DRF fallback code, so no error_code is  provided (yet).
This case is handled directly by DRF so no error_code is provided (yet).
Avoid double-binding the field, otherwise we'll get  an error about the source kwarg being redundant.
This is used to namespace gating-specific milestones
We should only ever have one gating milestone per UsageKey  Log a warning here and pick the first one
Get the unfulfilled gating milestones for this course, for this user
create chapter
Allow the "event" field to be a string, currently this is the case for all browser events.
Allow unexpected fields to exist in the top level event dictionary.
Allow unexpected fields to exist in the "context" dictionary. This is where new fields that appear in multiple  events are most commonly added, so we frequently want to tolerate variation here.
Allow unexpected fields to exist in the "event" dictionary. Typically in unit tests we don't want to allow this  type of variance since there are typically only a small number of tests for a particular event type.
NOTE: "payload_extra_fields" is deliberately excluded from this list since we want to detect erroneously added  fields in the payload by default.
Some events store their payload in a JSON string instead of a dict. Comparing these strings can be problematic  since the keys may be in different orders, so we parse the string here if we were expecting a dict.
Verify the API was actually hit (not the cache)
Warm up the cache.
Hit the cache.
Verify that only two requests were made, not four.
Test to see if the token is an uuid1 hex value
Links are interpreted relative to the directory containing the link
check that we're not trying to import outside of the data_dir
pylint: disable=protected-access
Set the timeout value for the cache to 1 day as a fail-safe  in case the signal to invalidate the cache doesn't come through.
Deserialize and construct the block structure.
Check if the xblock was already visited (can happen in  DAGs).
Add the xBlock.
Add relations with its children and recurse.
A dictionary key value for storing a transformer's version number.
List of usage keys of this block's parents.  list [UsageKey]
List of usage keys of this block's children.  list [UsageKey]
The usage key of the root block for this structure.  UsageKey
Map of a block's usage key to its block relations. The  existence of a block in the structure is determined by its  presence in this map.  defaultdict {UsageKey: _BlockRelations}
Add the root block.
Create a new block relations map to store only those blocks  that are still linked
Build the structure from the leaves up by doing a post-order  traversal of the old structure, thereby encountering only  reachable blocks.  If the block is in the old structure,  Add it to the new pruned structure
Add a relationship to only those old children that  were also added to the new pruned structure.
Replace this structure's relations with the newly pruned one.
Map of xblock field name to the field's value for this block.  dict {string: any picklable type}
Map of transformer name to the transformer's data for this  block.  defaultdict {string: dict}
Map of a block's usage key to its collected data, including  its xBlock fields and block-specific transformer data.  defaultdict {UsageKey: _BlockData}
Map of a transformer's name to its non-block-specific data.  defaultdict {string: dict}
Remove block from its children.
Remove block from its parents.
Remove block.
Recreate the graph connections if descendants are to be kept.
Map of a block's usage key to its instantiated xBlock.  dict {UsageKey: XBlock}
Set of xBlock field names that have been requested for  collection.  set(string)
pylint: disable=protected-access
get_children
get_parents
__contains__
create block structure
add each block
request fields
verify fields have not been collected yet
collect fields
verify values of collected fields
update the graph connecting the old parents to the old children
update all descendants  if the child has another parent, continue  add descendant to missing blocks and empty its  children
None case
1 registered
2 registered
1 unregistered
1 registered and 1 unregistered
An in-memory map of cache keys to cache values.
Use the class' name for Mock transformers.
0     / \    1  2   / \  3   4
0       /      1     /    2   /  3
0     / \    1  2    \ / \     3  4    / \   5  6
create empty block structure
_add_relation
Verify presence
Verify children
JSON mapping of discussion ids to usage keys for the corresponding discussion modules
Usage key strings might not include the course run, so we add it back in with map_into_course
find the dictionary entry for the current node
Reload the data to ensure the init signal is fired to decompress the data.
Method requires string input
Import tasks here to avoid a circular import.
Delete the existing discussion id map cache to avoid inconsistencies
Note: The countdown=0 kwarg is set to to ensure the method below does not attempt to access the course  before the signal emitter has finished all operations. This is also necessary to ensure all tests pass.
-*- coding: utf-8 -*-
Backwards compatibility with the behavior of DRF v2.  When the grader dictionary was missing keys, DRF v2 would default to None;  DRF v3 unhelpfully raises an exception.
Backwards compatibility with the behavior of DRF v2  Include a NULL value for "parent" in the representation  (instead of excluding the key entirely)
Backwards compatibility with the behavior of DRF v2  Leave the children list as a list instead of serializing  it to a string.
If we don't have data stored, generate it and return an error.
For some reason, `listen_for_course_publish` is not called when we run  all (paver test_system -s cms) tests, If we run only run this file then tests run fine.
If we don't disconnect then tests are getting failed in test_crud.py
Add this blocks children to the stack so that we can traverse them as well.
Import here to avoid circular import.
Ideally we'd like to accept a CourseLocator; however, CourseLocator is not JSON-serializable (by default) so  Celery's delayed tasks fail to start. For this reason, callers should pass the course key as a Unicode string.
IMPORTANT: Bump this whenever you modify this model and/or add a migration.
Cache entry versioning.
Start/end dates
URLs
Certification data
Grading
Access parameters
Enrollment details
Catalog information
Throw away old versions of CourseOverview, as they might contain stale data.
Regenerate the thumbnail images if they're missing (either because  they were never generated, or because they were flushed out after  a change to CourseOverviewImageConfig.
Note: If a newly created course is not returned in this QueryList,  make sure the "publish" signal was emitted when the course was  created. For tests using CourseFactory, use emit_signals=True.
In rare cases, courses belonging to the same org may be accidentally assigned  an org code with a different casing (e.g., Harvardx as opposed to HarvardX).  Case-insensitive exact matching allows us to deal with this kind of dirty data.
creates circular import; hence explicitly referenced is_discussion_enabled
This is either the raw image that the course team uploaded, or the  settings.DEFAULT_COURSE_ABOUT_IMAGE_URL if they didn't specify one.
Default all sizes to return the raw image if there is no  CourseOverviewImageSet associated with this CourseOverview. This can  happen because we're disabled via CourseOverviewImageConfig.
The URL can't be empty.
If this is an absolute URL, just return it as is.  It could be a domain  that isn't ours, and thus CDNing it would actually break it.
If image thumbnails are not enabled, do nothing.
If a course object was provided, use that. Otherwise, pull it from  CourseOverview's course_id. This happens because sometimes we are  generated as part of the CourseOverview creation (course is available  and passed in), and sometimes the CourseOverview already exists.
Small thumbnail, for things like the student dashboard
Large thumbnail, for things like the about page
The course about fields are accessed through the CourseDetail  class for the course module, and stored as attributes on the  CourseOverview objects.
test tabs for both cached miss and cached hit courses
Note: We specify a value for 'run' here because, for some reason,  .create raises an InvalidKeyError if we don't (even though my  other test functions don't specify a run but work fine).
Create a course where mobile_available is True.
Set mobile_available to False and update the course.  This fires a course_published signal, which should be caught in signals.py, which should in turn  delete the corresponding CourseOverview from the cache.
Make sure that when we load the CourseOverview again, mobile_available is updated.
Verify that when the course is deleted, the corresponding CourseOverview is deleted as well.
Creating a new course will trigger a publish event and the course will be cached
The cache will be hit and mongo will not be queried
This mock makes it so when the module store tries to load course data,  an exception is thrown, which causes get_course to return an ErrorDescriptor,  which causes get_from_id to raise an IOError.
Because the course overview now has an old version number, it should  be thrown out after being loaded from the cache, which results in  a call to get_course.
mock the CourseOverview ORM to raise a DoesNotExist exception to force re-creation of the object
Verify the CourseOverview is loaded successfully both times,  including after an IntegrityError exception the 2nd time.
This will create a version 10 CourseOverview
Now we're going to muck with the values and manually save it as v09
Now we're going to ask for it again. Because 9 < 10, we expect  that this entry will be deleted() and that we'll get back a new  entry with version = 10 again.
Now we're going to muck with this and set it a version higher in  the database.
Because CourseOverview is encountering a version *higher* than it  knows how to write, it's not going to overwrite what's there.
Test case-insensitivity.
Because we're sending None and '', we expect to get the generic  fallback URL for course images.
Even though there was no source image to generate, we should still  have a CourseOverviewImageSet object associated with this overview.
Disable model generation using config models...
Since we're disabled, we should just return the raw source image back  for every resolution in image_urls.
Because we are disabled, no image set should have been generated.
This initial seeding should create an entry for the image_set.
Now just throw in some fake data to this image set, something that  couldn't possibly work.
Now disable the thumbnail feature
Fetch a new CourseOverview
Assert that the data still exists for debugging purposes
But because we've disabled it, asking for image_urls should give us  the raw source image for all resolutions, and not our broken images.
Now enable the CDN...
Now enable the CDN...
Strictly speaking, this would fail anyway because there's no data  backing sample_image.png, but we're going to make the side-effect  more dramatic. ;-)
This will generate a CourseOverview and verify that we get the  source image back for all resolutions.
Make sure we were called (i.e. we tried to create the thumbnail)
Now an image set does exist, even though it only has blank values for  the small and large urls.
The next time we create a CourseOverview, the images are explicitly  *not* regenerated.
Save a real image here...
If create_after_overview is True, disable thumbnail generation so  that the CourseOverview object is created and saved without an  image_set at first (it will be lazily created later).
Now generate the CourseOverview...
If create_after_overview is True, no image_set exists yet. Verify  that, then switch config back over to True and it should lazily  create the image_set on the next get_from_id() call.
Save the image to the contentstore...
Now generate the CourseOverview...
Naming convention for thumbnail
Actual thumbnail data
Set config to False so that we don't create the image yet
First create our CourseOverview
Now create an ImageSet by hand...
Now do it the normal way -- this will cause an IntegrityError to be  thrown and suppressed in create_for_course()
All the URLs that come back should be for the expected_url
import CourseAboutSearchIndexer inline due to cyclic import  Delete course entry from Course About Search_index
ensure that the newly created courses aren't in course overviews
CourseOverview will be populated with all courses in the modulestore
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
Removed because we accidentally removed this column without first  removing the code that refers to this.  This can cause errors in production.
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
add a sequence to the course to which the problems can be added
Create a vertical to contain our split test
combine all values if there were multiple specified individually
parse them into a set
pylint: disable=abstract-method
Register signal handlers
Import here instead of top of file since this module gets imported before  the programs app is loaded, resulting in a Django deprecation warning.
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
Under cms the following setting is not defined, leading to errors during tests.
If either programs or credentials config models are disabled for this  feature, it may indicate a condition where processing of such tasks  has been temporarily disabled.  Since this is a recoverable situation,  mark this task for retry instead of failing it altogether.
Don't retry for this case - just conclude the task.
Determine which program certificates the user has already been  awarded, if any.
Retry because a misconfiguration could be fixed
keep trying to award other certs, but retry the whole task to fix any missing entries
N.B. This logic assumes that this task is idempotent
Disable certification to prevent the task from being triggered when  setting up test data (i.e., certificates with a passing status), thereby  skewing mock call counts.
The alternate course is used here to verify that the status and run_mode  queries are being ANDed together correctly.
Verify the API was actually hit (not the cache).
Warm up the cache.
Hit the cache.
Verify only one request was made.
Hit the Programs API twice.
Verify that three requests have been made (one for student, two for staff).
Enrollment for the shared course ID created last (most recently).
No enrollments, no program engaged.
Bypass caching for staff users, who may be creating Programs and want  to see them displayed immediately.
enrollment.course_id is really a course key _
This end-point is available to anonymous users,  so do not require authentication.
Translators: This label appears above a field on the login form  meant to hold the user's email address.
Translators: This example email address is used as a placeholder in  a field on the login form meant to hold the user's email address.
Translators: These instructions appear on the login form, immediately  below a field meant to hold the user's email address.
Translators: This label appears above a field on the login form  meant to hold the user's password.
For the initial implementation, shim the existing login view  from the student Django app.
This end-point is available to anonymous users,  so do not require authentication.
Map field names to the instance method used to add the field to the form
Default fields are always required
Custom form fields can be added via the form set in settings.REGISTRATION_EXTENSION_FORM
Extra fields configured in Django settings  may be required, optional, or hidden
Translators: This label appears above a field on the registration form  meant to hold the user's email address.
Translators: This example email address is used as a placeholder in  a field on the registration form meant to hold the user's email address.
Translators: This label appears above a field on the registration form  meant to hold the user's full name.
Translators: This example name is used as a placeholder in  a field on the registration form meant to hold the user's name.
Translators: These instructions appear on the registration form, immediately  below a field meant to hold the user's full name.
Translators: This label appears above a field on the registration form  meant to hold the user's public username.
Translators: These instructions appear on the registration form, immediately  below a field meant to hold the user's public username.
Translators: This example username is used as a placeholder in  a field on the registration form meant to hold the user's username.
Translators: This label appears above a field on the registration form  meant to hold the user's password.
Translators: This label appears above a dropdown menu on the registration  form used to select the user's highest completed level of education.
Translators: This label appears above a dropdown menu on the registration  form used to select the user's gender.
Translators: This label appears above a dropdown menu on the registration  form used to select the user's year of birth.
Translators: This label appears above a field on the registration form  meant to hold the user's mailing address.
Translators: This phrase appears above a field on the registration form  meant to hold the user's reasons for registering with edX.
Translators: This label appears above a field on the registration form  which allows the user to input the city in which they live.
Translators: This label appears above a field on the registration form  which allows the user to input the State/Province/Region in which they live.
Translators: This label appears above a field on the registration form  which allows the user to input the Company
Translators: This label appears above a field on the registration form  which allows the user to input the Title
Translators: This label appears above a field on the registration form  which allows the user to input the First Name
Translators: This label appears above a field on the registration form  which allows the user to input the First Name
Translators: This label appears above a dropdown menu on the registration  form used to select the country in which the user lives.
Separate terms of service and honor code checkboxes
Combine terms of service and honor code checkboxes  Translators: This is a legal document users must agree to  in order to register a new account.
Translators: "Terms of Service" is a legal document users must agree to  in order to register a new account.
Translators: "Terms of Service" is a legal document users must agree to  in order to register a new account.
Translators: This is a legal document users must agree to  in order to register a new account.
Translators: "Terms of service" is a legal document users must agree to  in order to register a new account.
Translators: "Terms of service" is a legal document users must agree to  in order to register a new account.
Override username / email / full name
Hide the password field
This end-point is available to anonymous users,  so do not require authentication.
Translators: This label appears above a field on the password reset  form meant to hold the user's email address.
Translators: This example email address is used as a placeholder in  a field on the password reset form meant to hold the user's email address.
Translators: These instructions appear on the password reset form,  immediately below a field meant to hold the user's email address.
Only check for true. All other values are False.
The minimum and maximum length for the name ("full name") account field
The minimum and maximum length for the username account field
The minimum and maximum length for the email account field
The minimum and maximum length for the password account field
Indicates the user's preference that all users can view the shareable fields in their account information.
Indicates the user's preference that all their account information be private.
Don't pass the 'configuration' arg up to the superclass
Don't pass the 'custom_fields' arg up to the superclass
Currently no read-only field, but keep this so view code doesn't need to know.
Calling UserPreference directly because the requesting user may be different from existing_user  (and does not have to be is_staff).
when user does not have profile it raises exception, when exception  occur we can simply get default image.
Public access point for this function.
If user has requested to change email, we must call the multi-step process to handle this.  It is not handled by the serializer (which considers email to be read-only).
If user has requested to change name, store old name because we must update associated metadata  after the save process is complete.
Check for fields that are not editable. Marking them read-only causes them to be ignored, but we wish to 400.
Build up all field errors, whether read-only, validation, or email errors.
If we have encountered any validation errors, return them to the user.
We have not found a way using signals to get the language proficiency changes (grouped by user).  As a workaround, store old and new values here and emit them after save is complete.
if any exception is raised for user preference (i.e. account_privacy), the entire transaction for user account  patch is rolled back and the data is not saved
Validate the username, password, and email  This will raise an exception if any of these are not in a valid format.
Create the user account, setting them to "inactive" until they activate their account.
Create a registration to track the activation process  This implicitly saves the registration.
Create an empty user profile with default values
Return the activation key, which the caller should send to the user
This implicitly saves the registration
Binding data to a form requires that the data be passed as a dictionary  to the Form class constructor.
Validate that a user exists with the given email address.  Generate a single-use link for performing a password reset  and email it to the user.  No user with the provided email address exists.
Ensure that parental controls don't apply to this user
With default configuration settings, email is not shared with other (non-staff) users.
Send a read-only error, serializer error, and email validation error.
Verify that the name change happened, even though the attempt to send the email failed.
Verify that no email change request was initiated.
Create a new account, which should have empty account settings by default.
Retrieve the account settings
Expect a date joined field but remove it to simplify the following comparison
Long email -- subtract the length of the @domain  except for one character (so we exceed the max length limit)
Create the account, which is initially inactive
Activate the account and verify that it is now active
Username and password cannot be the same
Create and activate an account
Request a password change
Verify that one email message has been sent
Verify that the body of the message contains something that looks  like an activation link
Verify that no email messages have been sent
Create an account, but do not activate it
Verify that the activation email was still sent
this is used in one test to check the behavior of profile image url  generation with a relative url in the config.
pylint: disable=no-member
Update user account visibility setting.
Verify how the view parameter changes the fields that are returned.
Badges aren't on by default, so should not be present.
Now make sure that the user can get the same information, even if not active
Ensure the user has birth year set, and is over 13, so  account_privacy behaves normally
If there are no values that would fail validation, then empty string should be supported;  except for account_privacy, which cannot be an empty string.
Make sure that gender did not change.
Although throwing a 400 might be reasonable, the default DRF behavior with ModelSerializer  is to convert to None, which also seems acceptable (and is difficult to override).
Verify that the behavior is the same for sending None.
Verify the new name was also stored.
Since request is multi-step, the email won't change on GET immediately (though goals will update).
Verify that the shared view is still private
Send a PATCH request with updates to both profile information and email.  Throw an error from the method that is used to process the email change request  (this is the last thing done in the api method). Verify that the profile did not change.
Fields output in the CSV
Number of records to read at a time when making  multiple queries over a potentially large dataset.
Default datetime if the user has not set a preference
Retrieve all the courses for the org.  If we were given a specific list of courses to include,  filter out anything not in that list.
Add in organizations from the course keys, to ensure  we're including orgs with different capitalizations
If no courses are found, abort
Let the user know what's about to happen
Open the output file and generate the report.
Remind the user where the output file is
Log the number of rows we processed
Use the read replica if one has been configured
The user isn't enrolled in the course, so the output should be empty
By default, if no preference is set by the user is enrolled, opt in
Enroll in a course that's not in the org
Opt out of the other course
The first course is included in the results,  but the second course is excluded,  so the user should be opted in by default.
Enroll in two courses, both in the org
Opt into the first course, then opt out of the second course
Enroll in the course and set a preference
Unenroll from the course
Enrollments should still appear in the outpu
Enroll in several courses in the org
Set a preference for the aliased course
Unenroll from the aliased course
No course available for this particular org
Create several courses in the same org
Execute the command, but exclude the second course from the list
Generate the report
Expect that every enrollment shows up in the report
Lowercase some of the org names in the course IDs
Set preferences for both courses
Create a temporary directory for the output  Delete it when we're finished
Sanitize the arguments
Override the query interval to speed up the tests
Execute the command
Return the output as a list of dictionaries
Include an empty "default" option at the beginning of the list
If there are overrides for this field, apply them now.  Any field property can be overwritten (for example, the default value or placeholder)
Transform kwarg "field_type" to "type" (a reserved Python keyword)
Transform kwarg "default" to "defaultValue", since "default"  is a reserved word in JavaScript
Ensure that the POST querydict is mutable
The login and registration handlers in student view try to change  the user's enrollment status if these parameters are present.  Since we want the JavaScript client to communicate directly with  the enrollment API, we want to prevent the student views from  updating enrollments.
Call the original view to generate a response.  We can safely modify the status code or content  of the response, but to be safe we won't mess  with the headers.
Otherwise, it's a general authentication failure.  Ensure that the status code is a 403 and pass  along the message from the view.
If an error condition occurs, send a status 400  The student views tend to send status 200 even when an error occurs  If the JSON-serialized content has a value "success" set to False,  then we know an error occurred.
If the response is successful, then return the content  of the response directly rather than including it  in a JSON-serialized dictionary.
Return the response, preserving the original headers.  This is really important, since the student views set cookies  that are used elsewhere in the system (such as the marketing site).
-*- coding: utf-8 -*-
persist the value as a course tag
There was no preference with that key, raise a 404.
Check that a 27 year old can opt-in
Check that a 32-year old can opt-out
Check that someone 14 years old can opt-in
Check that someone 13 years old cannot opt-in (must have turned 13 before this year)
Check that someone 12 years old cannot opt-in
Create the course and account.
Test that the API still works if no age is specified.  Create the course and account.
Check that a 27 year old can opt-in, then out.
Check that a 32-year old can opt-out, then in.
Check that someone 13 years old can opt-in, then out.
Check that someone 12 years old cannot opt-in, then explicitly out.
Create the course and account.
Create some test preferences values.
Verify that a preference can be deleted
Verify that deleting a non-existent preference throws a 404
Staff can always see profiles.  This should never return Multiple, as we don't allow case name collisions on registration.
Scopes  (currently only allows per-course tags.  Can be expanded to support  global tags (e.g. using the existing UserPreferences table))
get a tag that doesn't exist
Create a test user
get a group assigned to the user
make sure we get the same group back out every time
We should not get any group because assign is False which will  protect us from automatically creating a group for user
We should get a group automatically assigned to user
get a group assigned to the user
get a group assigned to the user - should be group 0 or 1
Now, get a new group using the same call - should be 3 or 4
We should get the same group over multiple calls
Changing the name of the group shouldn't affect anything  get a group assigned to the user - should be group 0 or 1
Now, get a new group using the same call
Verify that the raised exception has the error message
Verify that the error logger is called  This will include the stack trace for the original exception  because it's called with log level "ERROR"
Expect that the enrollment action and course ID  were stripped out before reaching the wrapped view.
Expect that the analytics course ID was passed to the view
Factories are self documenting  pylint: disable=missing-docstring
Retrieve the login form
Create a test user
Login
Verify that we logged in successfully by accessing  a page that requires authentication.
Create a test user
Login and remember me
Verify that the session expiration was set correctly
Create a test user
Invalid password
Invalid email address
Create a test user
Missing password
Missing email
Missing both email and password
Retrieve the password reset form
'min_length': account_api.PASSWORD_MIN_LENGTH,  'max_length': account_api.PASSWORD_MAX_LENGTH
Password field should be hidden
Verify that we've been logged in  by trying to access a page that requires authentication
Verify the user's account
Verify that we've been logged in  by trying to access a page that requires authentication
Initially, the field values are all valid
Override the valid fields, making the input invalid
Attempt to create the account, expecting an error response
Send a request missing a field
Retrieve the registration form description
Verify that the form description matches what we'd expect
Search the form for this field
Retrieve the registration form description
Modify the tag and save it. Check if the modified timestamp is updated.
does a round trip
get preference for key that doesn't exist for user
Middleware should pass request through
The middleware should clean up the context when the request is done
Even if the tracker blows up, the middleware should still return the response
-*- coding: utf-8 -*-
Nothing can be themed if we don't have a theme location.
This applies @with_comprehensive_theme to the func.
Because we want to match the original loader_tags.py file as closely as  possible, we should disable pylint so it doesn't complain about the violations  that are already in that file  pylint: skip-file
strip the prefix
-*- coding: utf-8 -*-
add SiteConfiguration to database
Verify an entry to SiteConfigurationHistory was added.
Make sure an entry (and only one entry) is saved for SiteConfiguration
add SiteConfiguration to database
Verify an entry to SiteConfigurationHistory was added.
Make sure two entries (one for save and one for update) are saved for SiteConfiguration
add SiteConfiguration to database
Verify an entry to SiteConfigurationHistory was added.
Make sure entry is saved if there is no error
try to add a duplicate entry
Make sure no entry is saved if there an error
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
Warm up the cache.
Hit the cache.
Verify only one request was made.
Hit the Credentials API twice.
Verify that three requests have been made (one for student, two for staff).
create credentials and program configuration
Mocking the API responses from programs and credentials
checking response from API is as expected
create credentials and program configuration
Mocking the API responses from programs and credentials
Checking result is as expected
create credentials and program configuration
Mocking the API responses from programs and credentials
Mocking the API responses from programs and credentials
Bypass caching for staff users, who may be generating credentials and  want to see them displayed immediately.
still need these for now b/c the client's screen shows these 3  fields
Default course license is "All Rights Reserved"
Ignore an attempt to delete an item that doesn't exist
NOTE: below auto writes to the db w/o verifying that any of  the fields actually changed to make faster, could compare  against db or could have client send over a list of which  fields changed.
Could just return jsondict w/o doing any db reads, but I put  the reads in as a means to confirm it persisted correctly
Signal that fires when a user is graded (in lms/courseware/grades.py)
update the course information on ccxcon using celery  import here, because signal is registered at startup, but items in tasks are not yet able to be loaded
-*- coding: utf-8 -*-
get the entire list of instructors  get anonymous ids for each of them  extract the course details
make the POST request
Trying to wrap the whole thing in a bulk operation fails because it  doesn't find the parents. But we can at least wrap this part...
no args used for the call
second call with different status code
no args used for the call
in case the maximum amount of retries has not been reached,  insert another task delayed exponentially up to 5 retries
Figure out what the XBlock class is from the block type, and  then open whatever resource has been requested.
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
order credit requirements according to their appearance in courseware
Maintain a history of requirement status updates for auditing purposes
Deadline for when credit eligibility will expire.  Once eligibility expires, users will no longer be able to purchase  or request credit.  We save the deadline as a database field just in case  we need to override the deadline for particular students.
Check all requirements for the course to determine if the user  is eligible.  We need to check all the *requirements*  (not just the *statuses*) in case the user doesn't yet have  a status for a particular requirement.
Enforce the constraint that each user can have exactly one outstanding  request to a given provider.  Multiple requests use the same UUID.
Retrieve all in-course reverification blocks in the course
Update the verification definitions in the course descriptor  This will also clean out old verification partitions if checkpoints  have been deleted.
Exclude all previously used IDs, even for partitions that have been disabled  (e.g. if the course author deleted an in-course reverifification block but  there are courseware components that reference the disabled partition).
Preserve existing, non-verified partitions from the course  Mark partitions for deleted in-course reverification as disabled.
Don't consume `.json` style suffixes
Filter by provider ID
Get the provider, or return HTTP 404 if it doesn't exist
Validate the course key
Validate the username
Ensure the user is actually eligible to receive credit
This endpoint should be open to all external credit providers.
Ensure the input data is valid
This CSRF exemption only applies when authenticating without SessionAuthentication.  SessionAuthentication will enforce CSRF protection.
Convert the serialized course key into a CourseKey instance  so we can look up the object.
Import here, because signal is registered at startup, but items in tasks  are not yet able to be loaded
This needs to be imported here to avoid a circular dependency  that can cause syncdb to fail.
Student received a passing grade
Grade was good, but submission arrived too late
Student failed to receive minimum grade
Ensure we converted the timestamp to a datetime
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
This seems to need to be here otherwise we get  circular references when starting up the app
This seems to need to be here otherwise we get  circular references when starting up the app
not enrolled
This seems to need to be here otherwise we get  circular references when starting up the app
quick exit, if course is not credit enabled
need to get user_name from the user object
This seems to need to be here otherwise we get  circular references when starting up the app
quick exit, if course is not credit enabled
always log any deleted activity to the credit requirements  table. This will be to help debug any issues that might  arise in production
need to get user_name from the user object
Retrieve all information we need to determine the user's group  as a multi-get from the cache.
Try a multi-get from the cache
Retrieve whether the user is enrolled in a verified mode.
Retrieve whether the user has skipped any checkpoints in this course
Retrieve the user's verification status for each checkpoint in the course.
Check whether the user has completed this checkpoint  "Completion" here means *any* submission, regardless of its status  since we want to show the user the content if they've submitted  photos.
create the root email message  add 'alternative' part to root email message to encapsulate the plain and  HTML versions, so message agents can decide which they want to display.  render the credit notification templates
add alternative plain text message
attach logo image
add email addresses of sender and receiver
send the root email message
insert style tag in the html and run pyliner.
Translators: The join of two university names (e.g., Harvard and MIT).
Translators: The join of three or more university names. The first of these formatting strings  represents a comma-separated list of names (e.g., MIT, Harvard, Dartmouth).
Initiate a new request if one has not already been created
Retrieve user account and profile info
Retrieve the final grade from the eligibility table
NOTE (CCB): Limiting the grade to seven characters is a hack for ASU.
Getting the students's enrollment date
Getting the student's course completion date
Sign the parameters using a secret key we share with the credit provider.
Retrieve all credit requirements for the course  We retrieve all of them to avoid making a second query later when  we need to check whether all requirements have been satisfied.
Find the requirement we're trying to set
Update the requirement status
If we're marking this requirement as "satisfied", there's a chance that the user has met all eligibility  requirements, and should be notified. However, if the user was already eligible, do not send another notification.
Find the requirement we're trying to remove
Remove the requirement status
check if an already added requirement is modified
Update the requirements, removing an existing requirement
Expect that now only the grade requirement is returned
Configure a credit eligibility that expired yesterday
The user should NOT be eligible for credit
The eligibility should NOT show up in the user's list of eligibilities
Configure a credit eligibility for a disabled course
The user should NOT be eligible for credit
The eligibility should NOT show up in the user's list of eligibilities
Initially, the status should be None
Set the requirement to "satisfied" and check that it's actually set
Set the requirement to "failed" and check that it's actually set
make sure the 'order' on the 2nd requirement is set correctly (aka 1)
Configure a credit course with no requirements
A user satisfies a requirement. This could potentially  happen if there's a lag when the requirements are removed  after the course is published.
Since the requirement hasn't been published yet, it won't show  up in the list of requirements.
Configure a course with two credit requirements
Satisfy one of the requirements, but not the other
The user should not be eligible (because only one requirement is satisfied)
Satisfy the other requirement
Now the user should be eligible
Credit eligibility email should be sent
Now check that html email content has same logo image 'Content-ID'  as the attached logo image 'Content-ID'
test text email contents
Credit eligibility email should be sent  Now check that on sending eligibility notification again cached  logo image is used
Configure a credit course with no requirements
A user satisfies a requirement.  This could potentially  happen if there's a lag when the requirements are updated  after the course is published.
Since the requirement hasn't been published yet, it won't show  up in the list of requirements.
Credit eligibility email should be sent
Verify the email subject
By default, configure the database so that there is a single  credit requirement that the user has satisfied (minimum grade)
Disable the provider; it should be hidden from the list
now test that user gets empty dict for non existent credit provider
Initiate a credit request
Validate the UUID
Validate the timestamp
Initiate a request with automatic integration disabled
Initial status should be "pending"
Update the status
- 2 queries: Retrieve and update the request  - 1 query: Update the history table for the request.
Create the first request
Request UUID should be the same
Request should use the updated information
Create the first request
Provider updates the status
Attempting a second request raises an exception
Create the first request
Create a request for a second course
Check that the requests have the correct course number
User did not specify a mailing address
Request should include an empty mailing address field
Simulate users who registered accounts before the country field was introduced.  We need to manipulate the database directly because the country Django field  coerces None values to empty strings.
Request should include an empty country field
Simulate an error condition that should never happen:  a user is eligible for credit, but doesn't have a final  grade recorded in the eligibility requirement.
The request UUID must exist
Warm up the cache.
Hit the cache.
Verify only one request was made.
pylint:disable=missing-docstring,no-member
creating course, checkpoint location and user partition mock object.
creating user and enroll them.
Check that a user is in verified allow group if that user has skipped  any ICRV block.
no db queries this time.
Check that a user is in verified allow group if that user has approved status at  any ICRV block.  this will warm the cache.
no db queries this time.
Check that a user is in verified allow group if that user has denied at  any ICRV block.
this will warm the cache.
no db queries this time.
Check that a user is in honor mode.  any ICRV block.  this will warm the cache.
no db queries this time.
this will warm the cache.
no db queries this time.
This value must be set here, as setting it outside of a method results in issues with CMS/Studio tests.
Create a user and login, so that we can use session auth for the  tests that aren't specifically testing authentication or authorization.
Non-staff users should not have access to the API
Staff users should have access to the API
Retrieve a CSRF token
Ensure POSTs made with the token succeed.
Non-staff users should not have access to the API
Staff users should have access to the API
Verify the API returns the serialized CreditCourse
Verify the CreditCourse was actually created
Verify the API returns the serialized CreditCourse
Verify the API returns a list of serialized CreditCourse objects
Verify the serialized CreditCourse is returned
Verify the data was persisted
Enable provider integration
Add a single credit requirement (final grade)
Mark the user as having satisfied the requirement and eligible for credit.
Check that the user's request status is pending
Check request parameters
Enable provider integration
Cannot initiate a request because we cannot sign it
Authentication should NOT be required for this endpoint.
Simulate a callback from the credit provider with an invalid signature  Since the signature is invalid, we respond with a 403 Not Authorized.
Initially, the status should be "pending"
First call sets the status to approved
Second call succeeds as well; status is still approved
Create an additional credit provider
Initiate a credit request with the first provider
Attempt to update the request status for a different provider
Response should be a 404 to avoid leaking request UUID values to other providers.
Request status should still be 'pending'
Callback from the provider is not authorized, because the shared secret isn't configured.
Test a key that has type `unicode` but consists of ASCII characters  (This can happen, for example, when loading the key from a JSON configuration file)  When retrieving the shared secret, the type should be converted to `str`
Test a key that contains non-ASCII unicode characters  This should return `None` and log an error; the caller  is then responsible for logging the appropriate errors  so we can fix the misconfiguration.
Run the tests in split modulestore  While verification access will work in old-Mongo, it's not something  we're committed to supporting, since this feature is meant for use  in new courses.
Disconnect the signal receiver -- we'll invoke the update code ourselves
Check that the groups for the partition were created correctly
Delete the reverification block, then update the partitions
Add an additional ICRV block in another section
Delete the first ICRV block and update partitions
Delete the ICRV block, so the number of ICRV blocks is zero
2 calls: get the course (definitions + structures)  2 calls: look up ICRV blocks in the course (definitions + structures)
One ICRV block created in the setup method  Additional call to load the ICRV block
Total of two ICRV blocks (one created in setup method)  Additional call to load each ICRV block
Reload each component so we can see the changes
Sanity check -- initially user partitions should be empty
pylint: disable=no-member
make sure we don't have a proctoring requirement
make sure we don't have a proctoring requirement
practice proctored exams aren't requirements
make sure we don't have a proctoring requirement
There should be one ICRV requirement
Delete the parent section containing the ICRV block
Check that the ICRV block is no longer visible in the requirements
Create multiple ICRV blocks
Add two additional ICRV blocks that have no start date  and the same name.
Since the last two requirements have the same display name,  we need to also check that their internal names (locations) are the same.
Create multiple ICRV blocks
Enable the course for credit
Configure a credit provider for the course
Add a single credit requirement (final grade)
mark the grade as satisfied
mark the grade as satisfied
now the status should be "satisfied" when looking at the credit_requirement_status list
remove the requirement status.
now the status should be None when looking at the credit_requirement_status list
mark the grade as satisfied
remove the requirement status with the invalid user id
this should be a no-op
make sure it is not returned by default
this should be a no-op
mark the grade as satisfied
mark the grade as satisfied
Note: we need to check if found components have been orphaned  due to a bug in split modulestore (PLAT-799).  Once that bug  is resolved, we can skip the `_is_in_course_tree()` check entirely.
XBlocks that can be added as credit requirements
pylint: disable=not-callable
sort credit requirements list based on start date and put all the  requirements with no start date at the end of requirement list.
Note: Need to import here as there appears to be  a circular reference happening when launching Studio  process
Note: groups associated with particular runs of a course.  E.g. Fall 2012 and Spring  2013 versions of 6.00x will have separate groups.
This block will transactionally commit updates to CohortMembership and underlying course_user_groups.  Note the use of outer_atomic, which guarantees that operations are committed to the database on block exit.  If called from a view method, that method must be marked with @transaction.non_atomic_requests.
If the membership was newly created, all the validation and course_user_group logic was settled  with a call to self.save(force_insert=True), which gets handled above.
Needs to exist outside class definition in order to use 'sender=CohortMembership'
pylint: disable=invalid-name
ironic, isn't it?
this is the easy case :)
First check whether the course is cohorted (users shouldn't be in a cohort  in non-cohorted courses, but settings can change after course starts)
Otherwise assign the user a cohort.
Add the new and update the existing cohorts  Update the manual cohorts already present in CourseUserGroup
Migrate cohort settings for this course
Note: error message not translated because it is not exposed to the user (UI prevents this state).
Note: error message not translated because it is not exposed to the user (UI prevents this state).
Note: error message not translated because it is not exposed to the user (UI prevents this state).  If cohort_id is specified, update the existing cohort. Otherwise, create a new cohort.
Note: error message not translated because it is not exposed to the user (UI prevents this state).
If group_id was specified as None, unlink the cohort if it previously was associated with a group.
this is a string when we get it here
this will error if called with a non-int cohort_id.  That's ok--it  shouldn't happen for valid clients.
These strings aren't user-facing so don't translate them
this is a string when we get it here
this is a string when we get it here
this is a string when we get it here  add staff check to make sure it's safe if it's accidentally deployed.
We extract the data for the course wide discussions from the category map.
First, we're going to simulate some problem states that can arise during this window
When migrations were first run, the users were assigned to CohortMemberships correctly
run the post-CohortMembership command, dry-run
run the post-CohortMembership command, and commit it
verify that both databases agree about the (corrected) state of the memberships
In this case, allow the pre-existing entry to be "correct"
-*- coding: utf-8 -*-
pylint: disable=attribute-defined-outside-init  pylint: disable=no-member
course-wide discussion
inline discussion
verify the default cohort is not created when the course is not cohorted
create a cohorted course without any auto_cohorts
verify the default cohort is not yet created until a user is assigned
create enrolled users
mimic users accessing the discussion forum  Default Cohort will be created here
set auto_cohort_groups  these cohort config will have not effect on lms side as we are already done with migrations
We should expect the DoesNotExist exception because above cohort config have  no effect on lms side so as a result there will be no AutoGroup cohort present
Create a new cohort with random assignment
Create a new cohort with random assignment
Check that the name didn't change.
create inline & course-wide discussion to verify the different map.
pylint: disable=invalid-name
Not implemented for XMLModulestore, which is used by test_cohorts.
Not implemented for XMLModulestore, which is used by test_cohorts.
pylint: disable=no-member
Modify existing cohort
Add non-cohort group
Add users to cohort
Remove users from cohort
Clear users from cohort
Clear users from non-cohort group
Add cohorts to user
Remove cohorts from user
Clear cohorts from user
Clear non-cohort groups from user
Make sure we get a Http404 if there's no course
Make the course cohorted...
Add an auto_cohort_group to the course...
get_cohort should return None as no group is assigned to user
get_cohort should return a group for user
Add an auto_cohort_group to the course...
Add an auto_cohort_group to the course...
Now set the auto_cohort_group to something different  This will have no effect on lms side as we are already done with migrations
Make the auto_cohort_group list empty
Add an auto_cohort_group to the course  This will have no effect on lms side as we are already done with migrations
add manual cohorts to course 1
Note that the following get() will fail with MultipleObjectsReturned if race condition is not handled.
place student 0 into first cohort
move student from first cohort to second cohort
move the student out of the cohort
assign user to cohort (but cohort isn't linked to a partition group yet)  scheme should not yet find any link
link cohort to group 0  now the scheme should find a link
link cohort to group 1 (first unlink it from group 0)  scheme should pick up the link
unlink cohort from anywhere  scheme should now return nothing
don't assign the student to any cohort initially
get the default cohort, which is automatically created  during the `get_course_cohorts` API call if it doesn't yet exist
map that cohort to a group in our partition
The student will be lazily assigned to the default cohort  when CohortPartitionScheme.get_group_for_user makes its internal  call to cohorts.get_cohort.
link cohort to group 0  place student into cohort  check link is correct
to simulate a non-destructive configuration change on the course, create  a new partition with the same id and scheme but with groups renamed and  a group added
the link should still work
to simulate a destructive change on the course, create a new partition  with the same id, but different group ids.
to simulate another destructive change on the course, create a new  partition with a different id, but using the same groups.
When the staff user is masquerading as being in a None group  (within an existent UserPartition), we should treat that as  an explicit None, not defaulting to the user's cohort's  partition group.
student doesn't have a cohort
cohort isn't mapped to any partition group.
Default error message for user
Add `current_page` value, it's needed for pagination footer.
Add `start` value, it's needed for the pagination header.
Note: The countdown=0 kwarg is set to ensure the method below does not attempt to access the course  before the signal emitter has finished all operations. This is also necessary to ensure all tests pass.
Don't pass the 'fields' arg up to the superclass  Instantiate the superclass normally
Drop any fields that are not specified in the `fields` argument.
-*- coding: utf-8 -*-
User can create up to max_bookmarks_per_course bookmarks
Without Serialized.
As bookmarks are sorted by -created so we will compare in that order.
Invalid course id.
self.other_vertical_1 has two parents
The bookmark object already created should have been returned without modifications.
Find a leaf block.
Block does not exist
Block is an orphan
Get bookmark that does not exist.
Assert False for item that does not exist.
Add this blocks children to the stack so that we can traverse them as well.
Ideally we'd like to accept a CourseLocator; however, CourseLocator is not JSON-serializable (by default) so  Celery's delayed tasks fail to start. For this reason, callers should pass the course key as a Unicode string.
Catalogs live in course discovery, so we do not create any  tables in LMS. Instead we override the save method to not  touch the database, and use our API client to communicate  with discovery.
We want to fill in a few fields ourselves, so remove them  from the form so that the user doesn't see them.
Delete any existing applications if the user has decided to regenerate their credentials
If no username is provided, bounce back to this page.
Get rid of the colons at the end of the field labels.
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
-*- coding: utf-8 -*-
Only add the 'value' attribute if a value is non-empty.
Assert that no POST was made to the catalog API
Assert that no PATCH was made to the Catalog API
pylint: disable=missing-docstring
Verify that initial save logs email errors properly  Verify object saved
Verify that updating request status logs email errors properly  Verify object saved
Service users may not have user profiles.
process the upload.
no matter what happens, delete the temporary file when we're done
image file validation.
generate profile pic and thumbnails and store them
update the user account to reflect that a profile image is available.
send client response.
update the user account to reflect that the images were removed.
remove physical files from storage.
send client response.
The if/else dance below is required, because PIL raises an exception if  you pass None as the value of the exif kwarg.
get the size of the image file and ensure it's square jpeg
subclasses should override this with the name of the view under test, as  per the urls.py configuration.
Reset the mock event tracker so that we're not considering the  initial profile creation events.
it's necessary to reload this model from the database since save()  would have been called on another instance.
Try another upload and make sure that a second event is emitted.
Ignore previous event
Ignore UserProfileFactory creation events.
Override Client.login method to update cookies with safe  cookies.
pre-verify steps 3, 4, 5
verify step 1: safe cookie data is parsed
verify step 2: cookie value is replaced with parsed session_id
verify step 3: session set in request
verify steps 4, 5: user_id stored for later verification
delete_cookies is called even if there are no cookies set
create and verify
serialize
parse and verify
compare
Should return the same digest twice.
The user ID is sometimes not set for  3rd party Auth and external Auth transactions  as some of the session requests are made as  Anonymous users.
For security reasons, we don't support requests with  older or invalid session cookie models.
The process_request pipeline has been short circuited so  return the response.
Mobile apps have custom handling of authentication failures. They  should *not* be redirected to the website's login page.
The user at response time is expected to be None when the user  is logging out. To prevent extra noise in the logs,  conditionally set the log level.
Create safe cookie data that binds the user with the session  in place of just storing the session_key in the cookie.
Update the cookie's value with the safe_cookie_data.
Nose runs setUpClass methods even if a class decorator says to skip  the class: https://github.com/nose-devs/nose/issues/946  So, skip the test class here if we are not in the LMS.
Check whether adding new resource is successful
Add resources, assume correct here, tested in test_add_resource
Test
Test
Test
Test
Test
Test
Test
Test
Test
Test
Test
Test
Test
Test
Upload file with wrong extension name or magic number
Upload file with correct extension name and magic number
... and log in as the appropriate user
Nose runs setUpClass methods even if a class decorator says to skip  the class: https://github.com/nose-devs/nose/issues/946  So, skip the test class here if we are not in the LMS.
We return a little bit of metadata helpful for debugging.  What is in this is not a defined part of the API contract.
This is a stop-gap until we can load OLX and/or OLX from  normal workbench scenarios
pylint: disable=no-member
We confirm we don't have errors rendering the student view
We confirm state sticks around
And confirm we render correctly
Nose runs setUpClass methods even if a class decorator says to skip  the class: https://github.com/nose-devs/nose/issues/946  So, skip the test class here if we are not in the LMS.
Generate a SECRET_KEY for this build
for use in openedx/core/djangoapps/profile_images/images.py
Django 1.7's setup is required before touching translated strings.
Add any paths that contain templates here, relative to this directory.
Add any paths that contain custom static files (such as style sheets) here,  relative to this directory. They are copied after the builtin static files,  so a file named "default.css" will overwrite the builtin "default.css".
django configuration  - careful here
Add any paths that contain templates here, relative to this directory.
Add any paths that contain custom static files (such as style sheets) here,  relative to this directory. They are copied after the builtin static files,  so a file named "default.css" will overwrite the builtin "default.css".
0,     os.path.abspath(         os.path.normpath(             os.path.dirname(__file__) + '/../../../..'         )    )
django configuration  - careful here
List of patterns, relative to source directory, that match files and  directories to ignore when looking for source files.
If your documentation needs a minimal Sphinx version, state it here.
Add any paths that contain templates here, relative to this directory.
The suffix of source filenames.
The encoding of source files.
The master toctree document.
General information about the project.
The version info for the project you're documenting, acts as replacement for  |version| and |release|, also used in various other places throughout the  built documents.  The short X.Y version.  The full version, including alpha/beta/rc tags.
There are two options for replacing |today|: either, you set today to some  non-false value, then it is used:  Else, today_fmt is used as the format for a strftime call.
List of patterns, relative to source directory, that match files and  directories to ignore when looking for source files.
The reST default role (used for this markup: `text`) to use for all documents.
If true, '()' will be appended to :func: etc. cross-reference text.
If true, the current module name will be prepended to all description  unit titles (such as .. function::).
If true, sectionauthor and moduleauthor directives will be shown in the  output. They are ignored by default.
The name of the Pygments (syntax highlighting) style to use.
A list of ignored prefixes for module index sorting.
If true, keep warnings as "system message" paragraphs in the built documents.
The theme to use for HTML and HTML Help pages.  See the documentation for  a list of builtin themes.
Theme options are theme-specific and customize the look and feel of a theme  further.  For a list of options available for each theme, see the  documentation.
Add any paths that contain custom themes here, relative to this directory.
The name for this set of Sphinx documents.  If None, it defaults to  "<Studio> v<release> documentation".
A shorter title for the navigation bar.  Default is the same as html_title.
The name of an image file (relative to this directory) to place at the top  of the sidebar.
The name of an image file (within the static path) to use as favicon of the  docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32  pixels large.
Add any paths that contain custom static files (such as style sheets) here,  relative to this directory. They are copied after the builtin static files,  so a file named "default.css" will overwrite the builtin "default.css".
If not '', a 'Last updated on:' timestamp is inserted at every page bottom,  using the given strftime format.
If true, SmartyPants will be used to convert quotes and dashes to  typographically correct entities.
Custom sidebar templates, maps document names to template names.
Additional templates that should be rendered to pages, maps page names to  template names.
If false, no module index is generated.
If false, no index is generated.
If true, the index is split into individual pages for each letter.
If true, links to the reST sources are added to the pages.
If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
If true, an OpenSearch description file will be output, and all pages will  contain a <link> tag referring to it.  The value of this option must be the  base URL from which the finished HTML is served.
This is the file name suffix for HTML files (e.g. ".xhtml").
Output file base name for HTML help builder.
The paper size ('letterpaper' or 'a4paper').
The font size ('10pt', '11pt' or '12pt').
Additional stuff for the LaTeX preamble.
Grouping the document tree into LaTeX files. List of tuples  (source start file, target name, title, author, documentclass [howto/manual]).
The name of an image file (relative to this directory) to place at the top of  the title page.
For "manual" documents, if this is true, then toplevel headings are parts,  not chapters.
If true, show page references after internal links.
If true, show URL addresses after external links.
Documents to append as an appendix to all manuals.
If false, no module index is generated.
One entry per manual page. List of tuples  (source start file, name, description, authors, manual section).
If true, show URL addresses after external links.
Documents to append as an appendix to all manuals.
If false, no module index is generated.
How to display URL addresses: 'footnote', 'no', or 'inline'.
If true, do not generate a @detailmenu in the "Top" node's menu.
Bibliographic Dublin Core info.
The language of the text. It defaults to the language option  or en if the language is not set.
The scheme of the identifier. Typical schemes are ISBN or URL.
The unique identifier of the text. This can be a ISBN number  or the project homepage.
A unique identification for the text.
A tuple containing the cover image and cover page html template filenames.
A sequence of (type, uri, title) tuples for the guide element of content.opf.
HTML files that should be inserted before the pages created by sphinx.  The format is a list of tuples containing the path and title.
HTML files shat should be inserted after the pages created by sphinx.  The format is a list of tuples containing the path and title.
A list of files that should not be packed into the epub file.
The depth of the table of contents in toc.ncx.
Allow duplicate toc entries.
Fix unsupported image types using the PIL.
Scale large images.
If 'no', URL addresses will not be shown.
If false, no index is generated.
Example configuration for intersphinx: refer to the Python standard library.
Maintain backwards compatibility with manage.py,  which calls "studio" "cms"
Ensure that we have a directory to put logs and reports
load data in db_fixtures
Create course in order to seed forum data underneath. This is  a workaround for a race condition. The first time a course is created;  role permissions are set up for forums.
this means it's already been done
Construct "multiprocess" nosetest substring
Clear any test data already in Mongo or MySQLand invalidate  the cache
load data in db_fixtures
load courses if self.imports_dir is set
Ensure the test servers are available
Default to running all tests if no specific test is specified
Skip any additional commands (such as nosetests) if running in  servers only mode
If imports_dir has been specified, assume the files are  already there -- no need to fetch them from github. This  allows someome to crawl a different course. They are responsible  for putting it, un-archived, in the directory.
Otherwise, obey `--skip-fetch` command and use the default  test course.  Note that the fetch will also be skipped when  using `--fast`.
Uses __enter__ and __exit__ for context  run the tests for this class, and for all subsuites
Since we are using SQLLite, we can reset the database by deleting it on disk.
Copy the cached database to the test root directory
Create the cache if it doesn't already exist
Handle "--failed" as a special case: we want to re-run only  the tests that failed within our Django apps  This sets the --failed flag for the nosetests command, so this  functionality is the same as described in the nose documentation
This makes it so we use nose's fail-fast feature in two cases.  Case 1: --fail_fast is passed as an arg in the paver command  Case 2: The environment variable TESTS_FAIL_FAST is set as True
Use one process per core for LMS tests, and no multiprocessing  otherwise.
We need to use $DIR/*, rather than just $DIR so that  django-nose will import them early in the test process,  thereby making sure that we load any django models that are  only defined in test files.
We delete the files but preserve the directory structure  so that coverage.py has a place to put the reports.
We delete the files but preserve the directory structure  so that coverage.py has a place to put the reports.
The mongo command will connect to the service,  failing with a non-zero exit code if it cannot connect.
Attempt to set a key in memcache. If we cannot do so because the  service is not available, then this will return False.
Root of the git repository (edx-platform)
Reports Directory
Python unittest dirs
For the time being, stubs are used by both the bok-choy and lettuce acceptance tests  For this reason, the stubs package is currently located in the Django app called "terrain"  where other lettuce configuration is stored.
Directory that videos are served from
Mongo databases that will be dropped before/after the tests run
Test Ids Directory
Directory for i18n test reports
Service variant (lms, cms, etc.) configured with an environment variable  We use this to determine which envs.json file to load.
Otherwise, load the file as JSON and return the resulting dict
pylint: disable=unexpected-keyword-arg
If the user is performing a dry run of a task, then just log  the command strings and return so that no destructive operations  are performed.
pylint: disable=broad-except
pylint: disable=unexpected-keyword-arg
Wait for process to actually finish
Subsuites to be added to the main suite
Main suite to be run
This may be that the coverage files were generated using -p,  try to combine them to the one file that we need.
Check if the .coverage data file is larger than the base file,  because coverage combine will always at least make the "empty" data  file even when there isn't any data to be combined.
Generate the coverage.py XML report  Generate the coverage.py HTML report
Find all coverage XML files (both Python and JavaScript)
Generate the diff coverage reports (HTML and console)
Developers can have private requirements, for local copies of github repos,  or favorite debugging tools, etc.
For files, hash the contents of the file
Compare the old hash to the new hash  If they do not match (either the cache hasn't been created, or the files have changed),  then execute the code within the block.
To add a package to the uninstall list, just add it to this list! No need  to touch any other part of this file.
Run pip to find the packages we need to get rid of.  Believe it or not,  edx-val is installed in a way that it is present twice, so we have a loop  to really really get rid of it.
Uninstall the pacakge
We tried three times and didn't manage to get rid of the pests.
Write our version.
Include all of the requirements files in the fingerprint.
Also fingerprint the directories where packages get installed:  ("/edx/app/edxapp/venvs/edxapp/lib/python2.7/site-packages")
In a virtualenv, "-e installs" get put in a src directory.
Also fingerprint this source file, so that if the logic for installations  changes, we will redo the installation.
Directory to put the pylint report in.  This makes the folder if it doesn't already exist.
Make sure the metrics subdirectory exists
Directory to put the pylint report in.  This makes the folder if it doesn't already exist.
Print number of violations to log
Also write the number of violations to a file
Fail number of violations is greater than the limit
An example string:  common/lib/xmodule/xmodule/tests/test_conditional.py:21: [C0111(missing-docstring), DummySystem] Missing docstring  More examples can be found in the unit tests for this method
If the string is parsed into four parts, then we've found a violation. Example of split parts:  test file, line number, violation name, violation details
Make sure the metrics subdirectory exists
Print number of violations to log
Also write the number of violations to a file
Fail if any violations are found
Ensure directory structure is in place: metrics dir, and an empty complexity report dir.
Record the metric
Fail if number of violations is greater than the limit
Record the metric  Print number of violations to log.
Print number of violations to log.
Record the metric  Output report to console.
Raise a build error if the file is not found
Example of the last line of a complexity report: "Average complexity: A (1.93953443446)"
Example of the last line of a jshint report (for example): "3482 errors"
An AttributeError will occur if the regex finds no matches.  A ValueError will occur if the returned regex cannot be cast as a float.
An AttributeError will occur if the regex finds no matches.  A ValueError will occur if the returned regex cannot be cast as a float.
Directory to put the diff reports in.  This makes the folder if it doesn't already exist.
Save the pass variable. It will be set to false later if failures are detected.
Run pep8 directly since we have 0 violations on master
Print number of violations to log
Also write the number of violations to a file
Set up for diff-quality pylint call   Set the string, if needed, to be used for the diff-quality --compare-branch switch.
Set the string, if needed, to be used for the diff-quality --fail-under switch.
run diff-quality for pylint.
run diff-quality for jshint.
If one of the quality runs fails, then paver exits with an error when it is finished
Directory to install static vendor files
To refresh the hash values of static xmodule content
Note: import sass only when it is needed and not at the top of the file.  This allows other paver commands to operate even without libsass being  installed. In particular, this allows the install_prereqs command to be  used to install the dependency.
Skip processing of the libraries if this is just a dry run
Ensure that the vendor directory exists
Copy each file to the vendor directory, overwriting any existing file.
Don't watch assets when performing a dry run
when running as a separate process, the main thread needs to loop  in order to allow for shutdown by contrl-c
Note: Bok Choy uses firefox if SELENIUM_BROWSER is not set. So we are using  firefox as the default here.
The default settings use DEBUG mode for running the server which means that  the optimized assets are ignored, so we skip collectstatic in that case  to save time.
First update assets for both LMS and Studio but don't collect static yet
Now collect static for each system separately with the appropriate settings.  Note that the default settings use DEBUG mode for running the server which  means that the optimized assets are ignored, so we skip collectstatic in that  case to save time.
Install an asset watcher to regenerate files that change
pylint: disable=line-too-long
Reset Environment back to original state
Check that we exited with a failure status code.
Check that we exited with a failure status code.
No System Exit is expected
No System Exit is expected
No exception should be raised
Mock the paver @needs decorator
Mock shell commands
Cleanup mocks
the cmd will dumbly compose whatever we pass in for the default_store
Mock shell commands
Cleanup mocks
Create a mock Paver environment
Don't run pre-reqs
Pep8 violations should be ignored.
Mock the paver @needs decorator
Temporary file infrastructure
Cleanup various mocks and tempfiles
Test that pep8, pylint, and jshint were called by counting the calls to  _get_pep8_violations (for pep8) and sh (for diff-quality pylint & jshint)
Test that pylint is NOT called by counting calls
Essentially mock diff-quality exiting with 1
Essentially mock diff-quality exiting with 1
Mock the paver @needs decorator
Cleanup mocks
Need to then compile the new dummy strings
Generate static i18n JS files.
Patch the xml libs before anything else.
can override with '--contracts' argument
This will trigger django-admin.py to print out its help
Creates a list, where each entry represents the index into the string where the next line break was found. Arguments: string: The string in which to find line breaks. Returns: A list of indices into the string at which each line begins.
Get the original string.
Given an index, determines the line of the index. Arguments: index: The index into the original string for which we want to know the line number Returns: The line number of the provided index.
Gets the index of the start of the line of the given index. Arguments: index: The index into the original string. Returns: The index of the start of the line of the given index.
Gets the index of the end of the line of the given index. Arguments: index: The index into the original string. Returns: The index of the end of the line of the given index.
Gets the starting index for the provided line number. Arguments: line_number: The line number of the line for which we want to find the start index. Returns: The starting index for the provided line number.
Gets the line of text designated by the provided line number. Arguments: line_number: The line number of the line we want to find. Returns: The line of text designated by the provided line number.
Gets the number of lines in the string.
Init method. Arguments: rule: The Rule which was violated.
Returns a key that can be sorted on
Since a file level rule has no first line, returns empty string.
Preps this instance for results reporting. Arguments: full_path: Path of the file in violation. string_lines: A StringLines containing the contents of the file in violation.
Prints the results represented by this rule violation. Arguments: _options: ignored out: output file
Returns a key that can be sorted on
Returns the initial line of code of the violation.
Init method.
Adds a violation to the summary details. Arguments: violation: The violation to add to the summary.
Init method. Arguments: full_path: The full path for this file.
Prepares the results for output for this file. Arguments: file_string: The string of content for this file. line_comment_delim: A string representing the start of a line comment. For example "" for Mako and "//" for JavaScript.
Remove any violations that were found in commented out code. Arguments: line_comment_delim: A string representing the start of a line comment. For example "" for Mako and "//" for JavaScript.
quote_regex = re.compile(r['"])
Loads a file into a string. Arguments: file_full_path: The full path of the file to be loaded. Returns: A string containing the files contents.
Init method.
Checks for violations in an Underscore.js template. Arguments: underscore_template: The contents of the Underscore.js template. results: A file results objects to which violations will be added.
Searches for Underscore.js expressions that contain violations. Arguments: underscore_template: The contents of the Underscore.js template. results: A list of results into which violations will be added.
Init method.
match = re.search(r\$\(\s*['"]<[a-zA-Z0-9]+\s*[/]?>['"]\s*[,)], argument)
Init method. Arguments: file_contents: The contents of the Python file. results: A file results objects to which violations will be added.
Skips processing of __repr__ functions, since these sometimes use '<' for non-HTML purposes. Arguments: node: An AST node.
Init function. Arguments: file_contents: The contents of the Python file. results: A file results objects to which violations will be added. skip_wrapped_html: True if visitor should skip strings wrapped with HTML() or Text(), and False otherwise.
Init function. Arguments: file_contents: The contents of the Python file. results: A file results objects to which violations will be added.
Init function. Arguments: file_contents: The contents of the Python file. results: A file results objects to which violations will be added.
Checks for uses of deprecated `display_name_with_default_escaped`. Arguments: node: An AST node.
Init method.
Init method.
Checks that a Mako expression using js_escaped_string is surrounded by quotes. Arguments: mako_template: The contents of the Mako template. expression: A Mako Expression. results: A list of results into which violations will be added.
Test line_number_to_line.
Creates a mock patch for _is_valid_directory on a Linter to always return true. This avoids nested patch calls. Arguments: linter_class: The linter class to be patched
Test _is_valid_directory correctly determines mako directories
'template': '${ triple }',
'template': r ${" \" \\"} ,
value: gettext("Copy Email To Editor"), id: 'copy_email_' + email_id))),
Test check_javascript_file_is_safe with concatenating strings and HTML
Test check_javascript_file_is_safe with JQuery append()
Test check_javascript_file_is_safe with JQuery prepend()
Test check_javascript_file_is_safe with JQuery insertion functions other than append(), prepend() and html() that take content as an argument (e.g. before(), after()).
Test check_javascript_file_is_safe with JQuery insert to target functions that take a target as an argument, like appendTo() and prependTo().
Test check_javascript_file_is_safe with JQuery html()
Test check_javascript_file_is_safe with interpolate()
Test check_javascript_file_is_safe with interpolate()
Test check_python_file_is_safe with concatenating strings and HTML
'python': rmsg = '{}</p>'.format(message),
'python': rr'regex with {} and named group(?P<id>\d+)?$'.format(test),
'python': rmsg = '<a href="%s"' % url,
),'rule': None }, { 'python': rmsg = '%s</p>' % message,
@alton cut ami for stage-edx-edxapp from prod-edx-edxapp with edx_platform_version={hotfix_hash} @alton cut ami for prod-edge-edxapp from prod-edge-edxapp with edx_platform_version={hotfix_hash} @alton cut ami for prod-edx-edxapp from prod-edx-edxapp with edx_platform_version={hotfix_hash} )
Returns a date object corresponding to the expected date of the next release: normally, this Tuesday.
Given a commit message, return a list of all JIRA ticket references in that message. If there are no ticket references, return an empty list.
Return a tuple of commits that exist between start_ref and end_ref, but were not merged to the end_ref. If everyone is following the pull request process correctly, this should return an empty tuple.
Override the default string handling function to always return unicode objects
Calls the enable_microsites function in the microsite backend. Here for backwards compatibility
Tests that we get empty list of courses in case the user is not provided
Test when no microsite is present - nothing to exclude
Return the specified user's course enrollments
fetch course key object from string representation - retain result for subsequent uses
fetch usage key for component from string representation - retain result for subsequent uses
module store accessor - retain result for subsequent uses
Sets the group_access dict on the block referenced by block_location.
Verify that the validation message has the expected validation message and type.
Test the validation messages produced for an xblock with full group access.
Test has_score is true for ora2 problems.
This class is only used to allow overriding __name__ on the tuples passed through ddt, in order to have the generated test names make sense.
Verify the expected value for the block's group_access.
Override default behavior because commentables don't actually exist in the comment service.
Return the context of the thread which this comment belongs to.
class for paginated results returned from comment services
Returns the corresponding CourseEmailTemplate for this CourseEmail.
Fetch the current template If one isn't stored, an exception is thrown.
Create plain text message. Convert plain text body (`plaintext`) into plaintext email message using the stored plain template and the provided `context` dict.
Returns whether or not email is enabled for the given course id.
Admin for course email.
Admin for optouts.
Enable the ability to add new templates, as we want to be able to define multiple templates.
Validate the HTML template.
Validate the plaintext template.
Load data from the fixture
Increments count of number of emails sent.
Creates one instructor and several course staff for self.course. Assigns them to self.instructor (single user) and self.staff (list of users), respectively.
Creates users and enrolls them in self.course. Assigns these users to self.students.
Log in self.client as user.
Test that email is still sent when the high priority queue is used
Test that no duplicate emails are sent to a course instructor that is also course staff
Test that no duplicate emails are sent to a course instructor that is also enrolled in the course
Test the CourseEmailTemplate model without loading the template data.
Provide sample context sufficient for rendering HTML template
Dummy exception used for unit tests.
Mock was not needed for some tests, testing to see if it's needed at all.
Passes a bad value for task_id to test update_subtask_status
Create students for testing
Mock exception for email testing.
Creates a subtask to send email to a given recipient list.
Partial function for formatting the from_addr. Since `course_title_no_quotes` may be truncated to make sure the returned string has fewer than 320 characters, we define this function to make it easy to determine quickly what the max length is for `course_title_no_quotes`.
escape HTML special characters in string
Create a valid random edX user ID. An ID is at most 30 characters long, and can contain upper and lowercase letters and numbers. :return:
Ensure that the client key supplied with the LTI launch is on that has been generated by our platform, and that it has an associated client secret. :return: True if the key is valid, False if it is not.
Fetch the client secret from the database. This method signature is required by the oauthlib library. :return: the client secret that corresponds to the supplied key if present, or None if the key does not exist in the database.
Unused abstract method from super class. See documentation in RequestValidator
Unused abstract method from super class. See documentation in RequestValidator
Unused abstract method from super class. See documentation in RequestValidator
Unused abstract method from super class. See documentation in RequestValidator
Unused abstract method from super class. See documentation in RequestValidator
Unused abstract method from super class. See documentation in RequestValidator
Unused abstract method from super class. See documentation in RequestValidator
Unused abstract method from super class. See documentation in RequestValidator
Unused abstract method from super class. See documentation in RequestValidator
Unused abstract method from super class. See documentation in RequestValidator
Unused abstract method from super class. See documentation in RequestValidator
Unused abstract method from super class. See documentation in RequestValidator
Unused abstract method from super class. See documentation in RequestValidator
Unused abstract method from super class. See documentation in RequestValidator
Unused abstract method from super class. See documentation in RequestValidator
Unused abstract method from super class. See documentation in RequestValidator
Unused abstract method from super class. See documentation in RequestValidator
Unused abstract method from super class. See documentation in RequestValidator
Unused abstract method from super class. See documentation in RequestValidator
Unused abstract method from super class. See documentation in RequestValidator
Helper method for all Signature Validator tests to get an LtiConsumer object.
Verify that check_client_key succeeds with a valid key
Verify that check_client_key fails with a disallowed key
Verify that check_nonce succeeds with a key of maximum length
Verify that check_nonce fails with badly formatted nonce
Verify that get_client_secret returns the right value for the correct key
Verifies that the LTI launch succeeds when passed a valid request.
Helper method to remove a parameter from the LTI launch and call the view
Override since LTI allows access to unenrolled students.
Returns an XML document containing a successful replace_result response.
Create and save a new GradedAssignment model in the test database.
Generate and save a User and an LTI user model
Patch a method with a given return value, and return the mock
Wraps the decorated function.
Convert the language from code to long name.
Update index with course_team object (if feature is enabled).
Remove course_team from the index (if feature is enabled).
Return course team search engine (if feature is enabled).
Return boolean of whether course team indexing is enabled.
Reindex object after save.
Update the user's last activity date upon endorsing a comment.
Handle user activity from django_comment_client and discussion_apiand update the user's last activity date. Checks if the user who performed the action is the original author, and that the discussion has the team context.
Adds the given user to the CourseTeam.
Reset team_size to reflect the current membership count.
Recompute the related team's team_size after deleting a membership
Paginate topics.
Paginate the user's teams.
Returns true if the user is enrolled or is staff.
Returns the queryset used to access the given team.
Return a list of team topics sorted alphabetically.Arguments: course_module (xmodule): the course which owns the team topics Returns: list: a list of sorted team topics
Returns the team with team_id, or throws Http404 if it does not exist.
Returns the membership for the given user and team, or throws Http404 if it does not exist.
Returns course_team object from team_id.
Test that raises CommandError for incorrect arguments.
Test that raises CommandError for disabled feature flag.
Test that command indexes a single passed team.
Test that command indexes multiple passed teams.
Represent the country as a 2-character unicode identifier.
Check that the code is a valid country code. We leave the data in its original format so that the Django model's CountryField can convert it to the internal representation used by the django-countries library.
The same as the `CourseTeamSerializer`, but elides the membership field.Intended to be used as a sub-serializer for serializing team memberships, since the membership field is redundant in that case.
Serializes a set of topics, adding the team_count field to each topic as a bulk operation. Requires that `context` is provided with a valid course_id in order to filter teams within the course.
Assembles a membership creation payload based on the raw values provided.
Assembles a membership creation payload based on the username and team model provided.
Posts data to the team creation endpoint. Verifies expected_status.
Gets detailed team information for team_id. Verifies expected_status.
Delete the given team. Verifies expected_status.
Patches the team with team_id using data. Verifies expected_status.
Gets the list of topics, passing data as query params. Verifies expected_status.
Gets a single topic, passing data as query params. Verifies expected_status.
Gets the membership list, passing data as query params. Verifies expected_status.
Posts data to the membership creation endpoint. Verifies expected_status.
Gets an individual membership record, passing data as query params. Verifies expected_status.
Deletes an individual membership record. Verifies expected_status.
Verifies that fields exist on the returned team json indicating that it is expanded.
Clear out the search index and reindex the teams.
Return the team id that we'd expect given this team data and this prefix.
Verifies that the team id starts with the specified prefix and ends with the discussion_topic_id
Test that team deletion is robust to Elasticsearch errors.
Convenience method to merge two dicts in a single expression
Verify that we return no results and make no SQL queries for a page with no topics.
Verify that we serialize topics with no team count, making only one SQL query.
Verify that we serialize topics with a positive team count, making only one SQL query.
Verify that we serialize a subset of the course's topics, making only one SQL query.
Convenience method to merge two dicts in a single expression
Create a mock comment service object with the given context.
Test that `last_activity_at` is correctly updated when team-relatedsignals are sent.
Get the list of profiles in priority order when requesting from VAL
Returns latest supported app version for a platform.
Verify the endpoint redirects to the user detail endpoint
Tests PDF certificates with CERTIFICATES_HTML_VIEW set to False.
Tests PDF certificates with CERTIFICATES_HTML_VIEW set to True.
Returns the course status
Get the ID of the module that the specified user last visited in the specified course.
Helper method to configure the partition and group mapping for the given xblock.
Returns whether the usage_key's block_type is one of self.block_types or a parent type.
defines fields to display in list view
Tests the case for an unfulfilled pre-requisite course
Tests the case where the user has not passed the entrance exam
Tests access when user has passed the entrance exam
Helper function to pass the entrance exam
Login test user.
Logout test user.
Enroll test user in test course.
Unenroll test user in test course.
Shortcut for both login and enrollment of the user.
Helper method for calling endpoint, verifying and returning response. If expected_response_code is None, doesn't verify the response' status_code.
Base implementation that returns response from the GET method of the URL.
Test Mixin for testing APIs decorated with mobile_view.
Base implementation of verifying a successful response.
Base implementation of verifying a failed response.
Base implementation of initializing the user for each test.
Method decorator for a mobile API endpoint that verifies the user has access to the course in a mobile context.
Function and class decorator that abstracts the authentication and permission checks for mobile api views.
Determines the platform type for mobile app making the request against user_agent. Returns: None if request app does not belong to one of the supported mobile platforms else returns an instance of corresponding mobile platform.
Get expiry date of app version for a platform.
Initialize base sysadmin dashboard class with modulestore, modulestore_type and return msg
Get an iterable list of courses.
Read and clear buffer for optimization
Generator for handling potentially large CSVs
Convenience function for testing command failures
Exception class for handling the typical errors in a git import.
GitImportError when the git url provided wasn't usable.
GitImportError when the cloned repository was malformed.
GitImportError when the clone of the repository failed.
GitImportError when the course import command failed.
GitImportError when the modulestore doesn't support imports.
Makes the test user staff and logs them in
Create a shell expansion of passed in parameter and iteratively remove them.  Must only expand to directories.
Create directory and add the cleanup for it.
Makes the test user staff and logs them in
Only override the sub (subject) claim.
Return boolean indicating user's administrator status. For our purposes an administrator is any user with is_staff set to True.
Add specialized claims.
User displayable full name.
Claim `instructor_courses` with list of course_ids for which the user has instructor privileges.
Claim `staff_courses` with list of course_ids for which the user has staff privileges.
Test the sitemap view
Test the about view
Make the user support staff.
Make the user support staff.
Verify that the endpoint requires authentication.
Verify that the endpoint supports session auth.
Verify that the endpoint returns a 400 when program certification is disabled.
Returns true if the `user` is an instructor for the course.
Test returns proper value when have proper access
Test returns proper value when have proper access
Test returns proper value when have proper access
Initializes connection to the mailchimp api
Given a course_id, returns a QuerySet of all the active students in the course.
Returns a set of email addresses subscribed to `list_id`
Returns a set of email addresses that have unsubscribed from `list_id`
Returns a set of email addresses that have been cleaned from `list_id` These email addresses may be invalid or have caused bounces, so you don't want to re-add them back to the list.
Batch unsubscribe the given email addresses from the list represented by `list_id`
Returns sanitized str `name`: no more than 10 characters, with spaces replaced with `_`
The CSS class of this summary. Indicates the type of information this summary block contains, and its urgency.
The title of this summary.
The detail text displayed by this summary.
This summary's date.
The format to display this date in. By default, displays like Jan 01, 2015.
The location to link to for more information.
The text of the link.
Return an HTML representation of this summary block.
Whether or not this summary block should be shown. By default, the summary is only shown if its date is in the future.
Displays the start date of the course.
Return the verification status for this user.
Return True if a verification deadline exists, and has already passed.
Returns an iterator over all ancestors of the given block, starting with its immediate parent and ending at the root of the block tree.
A thread local used to manage state of overrides being disabled or not.
A context manager which disables field overrides inside the context of a `with` statement, allowing code to get at the `original` value of a field.
Checks to see whether overrides are disabled in the current context. Returns a boolean value.  See `disable_overrides`.
Look for an override value for the field named `name` in `block`. Returns the overridden value or `default` if no override is found.
Return True if this provider should be enabled for a given course, and False otherwise. Concrete implementations are responsible for implementing this method. Arguments: course (CourseModule or None) Returns: bool
Checks for an override for the field identified by `name` in `block`. Returns the overridden value or `NOTSET` if no override is found.
Yields the values from items in chunks of size chunk_size
Return all model instances that correspond to problems that have been submitted for a given course. So module_type='problem' and a non-null grade. Use a read replica if one exists for this environment.
Finds the StudentModule object for this history record, even if our data is split across multiple data stores.  Django does not handle this correctly with the built-in student_module property.
Stores data set in the Scope.preferences scope by an xmodule field
An exception class for exceptions thrown by module_render that don't fit well elsewhere
Hash a :class:`xblock.fragment.FragmentResource
Function to split arbitrary score ranges into 3 buckets. Used with statsd tracking.
Convert a location to a remote cache key (add our prefixing).
Convert a remote cache key to a local cache key (i.e. location str).
How many items did we pull down from the remote cache?
How many local updates are we waiting to push to the remote cache?
Adds a max score to the max_score_cache
Retrieve a max score from the cache
Given a CourseDescriptor and User, create the FieldDataCache for grading. This will generate a FieldDataCache that only loads state for those things that might possibly affect the grading process, and will ignore things like Videos.
Returns progress summary for all chapters in the course.
Make a fake request because grading code expects to be able to look at the request. We have to attach the correct user to the request before grading that student.
Given a course id, return the corresponding course descriptor. If such a course does not exist, raises a 404. depth: The number of levels of children for the modulestore to cache. None means infinite depth
Looks for a filename in a list of dirs on a filesystem, in the specified order. filesystem: an OSFS filesystem dirs: a list of path objects filename: a string Returns d / filename if found in dir d, else raises ResourceNotFoundError.
Return the snippet of HTML to be included on the course info page in the 'Date Summary' section.
If the block's date is None, return the maximum datetime in order to force it to the end of the list of displayed blocks.
Returns the CourseOverview object for the course after checking for access.
Returns a list of courses sorted by their start date, latest first.
Get the Studio URL of the page that is passed in. Args: course (CourseDescriptor)
Checks to see if a course is properly configured for an entrance exam
Delegate to get_module_for_descriptor (imported here to avoid circular reference)
Set a single value in the KeyValueStore
Raise an InvalidScopeError if key.scope is not in self._allowed_scopes.
Return the django model object specified by `kvs_key` from the cache. Arguments: kvs_key (`DjangoKeyValueStore.Key`): The field value to delete Returns: A django orm object from the cache
Set the specified `kvs_key` to the field value `value`. Arguments: kvs_key (`DjangoKeyValueStore.Key`): The field value to delete value: The field value to store
Delete the value specified by `kvs_key`. Arguments: kvs_key (`DjangoKeyValueStore.Key`): The field value to delete Raises: KeyError if key isn't found in the cache
Return whether the specified `kvs_key` is set. Arguments: kvs_key (`DjangoKeyValueStore.Key`): The field value to delete Returns: bool
Return when the supplied field was changed. Arguments: kvs_key (`DjangoKeyValueStore.Key`): The field value to delete Returns: datetime if there was a modified date, or None otherwise
Return the key used in this DjangoOrmFieldCache to store the specified field_object. Arguments: field_object: A Django model instance that stores the data for fields in this cache
Return the key used in this DjangoOrmFieldCache for the specified KeyValueStore key. Arguments: key (:class:`~DjangoKeyValueStore.Key`): The key representing the cached field
Set the specified `kvs_key` to the field value `value`. Arguments: kvs_key (`DjangoKeyValueStore.Key`): The field value to delete value: The field value to store
Return when the supplied field was changed. Arguments: kvs_key (`DjangoKeyValueStore.Key`): The key representing the cached field Returns: datetime if there was a modified date, or None otherwise
Return the django model object specified by `kvs_key` from the cache. Arguments: kvs_key (`DjangoKeyValueStore.Key`): The field value to delete Returns: A django orm object from the cache
Return whether the specified `kvs_key` is set. Arguments: kvs_key (`DjangoKeyValueStore.Key`): The field value to delete Returns: bool
Return the key used in this DjangoOrmFieldCache for the specified KeyValueStore key. Arguments: key (:class:`~DjangoKeyValueStore.Key`): The key representing the cached field
Return the key used in this DjangoOrmFieldCache to store the specified field_object. Arguments: field_object: A Django model instance that stores the data for fields in this cache
Return the key used in this DjangoOrmFieldCache for the specified KeyValueStore key. Arguments: key (:class:`~DjangoKeyValueStore.Key`): The key representing the cached field
Return the key used in this DjangoOrmFieldCache to store the specified field_object. Arguments: field_object: A Django model instance that stores the data for fields in this cache
Return the key used in this DjangoOrmFieldCache for the specified KeyValueStore key. Arguments: key (:class:`~DjangoKeyValueStore.Key`): The key representing the cached field
Return the key used in this DjangoOrmFieldCache to store the specified field_object. Arguments: field_object: A Django model instance that stores the data for fields in this cache
Return the key used in this DjangoOrmFieldCache for the specified KeyValueStore key. Arguments: key (:class:`~DjangoKeyValueStore.Key`): The key representing the cached field
Returns a map of scopes to fields in that scope that should be cached
Basic constructor. from_field_data_cache() is more appopriate for most uses.
Return True if we have a score for this location.
The main courseware view.
A generator for iterating through all the SingleTextbookTab book objects associated with this collection of textbooks.
Returns the link_value as the link.
Validate that the tab_dict for this course tab has the necessary information to render.
Validate that the tab_dict for this course tab has the necessary information to render.
Constructs a link for textbooks from a view name, a course, and an index.
Load every descriptor in course.  Return bool success value.
Test case for management commands using the mixed mongo modulestore with old mongo as the default.
Test case for management commands using the mixed mongo modulestore with split as the default.
Load results from file
Exports a course into a tar.gz file
Checks if prerequisites are disabled in the settings.
Can this user load this course? NOTE: this is not checking whether user is actually enrolled in the course.
Returns whether the user can enroll in the course.
Can see if can enroll, but also if can load it: if user enrolled in a course and now it's past the enrollment period, they should still see it.
Implements the "can see course in catalog" logic if a course should be visible in the main course catalog In this case we use the catalog_visibility property on the course descriptor but also allow course staff to see this.
Implements the "can see course about page" logic if a course about page should be visible In this case we use the catalog_visibility property on the course descriptor but also allow course staff to see this.
Check if user has access to the course for this ccx_keyDelegates checking to _has_access_course_key Valid actions: same as for that function
Checks for staff access
Check that the user has access to the support UI.
Helper method that checks whether the user has staff access tothe course of the location. descriptor: something that has a location attribute
Helper method that checks whether the user has staff access tothe course of the location. descriptor: something that has a location attribute
Returns if the object is visible to nonstaff users. Arguments: descriptor: object to check
Returns whether the given user has fulfilled all milestones for the given course. Arguments: course_id: ID of the course to check user_id: ID of the user to check
Returns whether the given user has fulfilled all prerequisites for the given course. Arguments: user: user to check course_id: ID of the course to check
Returns whether the given course has the given visibility type
Returns if descriptor is available on mobile.
Returns whether the given course is mobile_available for the given user. Checks: mobile_available flag on the course Beta User and staff access overrides the mobile_available flag Arguments: descriptor (CourseDescriptor|CourseOverview): course or overview of course in question
Overrides bool(). Allows for truth value testing of AccessResponse objects, so callers who do not need the specific error information can check if access is granted. Returns: bool: whether or not access is granted
Creates a serializable JSON representation of an AccessResponse object. Returns: dict: JSON representation
Exception class that requires redirecting to a URL.
This simple override provider is always enabled
This error is raised if the service backing this client is currently unavailable.
This error is raised if the caller is not allowed to access the requested data.
This error is raised if the caller has requested data that does not exist.
Arguments: user (:class:`~User`): An already-loaded django user. If this user matches the username supplied to `set_many`, then that will reduce the number of queries made to store the user state.
DataDog increment method.
DataDog histogram method.
You get no ordering guarantees. Fetching will happen in batch_size increments. If you're using this method, you should be running in an async task.
Returns either the first or last child based on the value of the requested_child parameter.  If requested_child is None, returns the first child.
Return True if user is registered for course, else False
Display the progress page.
Render the initial financial assistance page.
Initialize metrics for New Relic so we can slice data in New Relic Insights
Verifies that the user can enter the course.
Check to see if there is a required survey that must be taken before the user can access the course.
Verify whether the section is gated and accessible to the user.
Returns the preferred language for the actual user making the request.
Returns whether the current request is masquerading as a student.
Finds the requested chapter.
Finds the requested section.
Save where we are in the course and chapter.
Unique identifier for the transformer's class; same identifier used in setup.py.
Collects any information that's necessary to execute this transformer's transform method.
Perform no transformations.
Collect the `max_score` for every block in the provided `block_structure`.
Collect the `max_score` from the given module, storing it as a `transformer_block_field` associated with the `GradesTransformer`.
Helper method to reset a password
Makes sure default behavior is correct when we don't have this turned on
Test login -- the setup function does all the work.
Test logout -- setup function does login.
Verify that the copyright page does not exist if we are not in a microsite
Set up course for tests
Ensure has_access handles a user being passed as null
Installs a masquerade for the specified user.
Ensure that user role is student for anonymous user.
Check that calling has_access with an unsupported action raises a ValueError.
Returns a video component with parent ``parent`` that is intended to be displayed to group ``group``.
Returns a problem component with parent ``parent`` that is intended to be displayed to group ``group``.
Set up the tests
Helper method to turn on ecommerce on the course
Verify that the homepage, when accessed at edx.org, has the edX footer
Verify that the homepage, when accessed at something other than edx.org, has the Open edX footer
Test courseware page access when ENTRANCE_EXAMS feature is disabled
Test can_skip_entrance_exam method with anonymous user
Test has_passed_entrance_exam method with anonymous user
Return root of the block.
Creates a mock user with the specified properties.
Returns true if the specified tab is enabled.
Tests the json from and to methods on the given tab
Test __getitem__ and __setitem__ for the given key
Searches the given lab_list for a given tab_type.
reverse lookup for discussion link
Test that setting discussion_link overrides everything else
Test that other cases return None with discussions disabled
Test a course with a discussion tab configured
Test a course with tabs configured but without a discussion tab
Generate a new ModuleSystem that is minimally set up for testing
Return item url with dispatch.
Release a set of languages using the dark lang interface. languages is a list of comma-separated lang codes, eg, 'ar, es-419'
Create srt file in filesystem.
Check that asset with asset_name exists in assets.
Clear all assets for location.
Attach `en` transcript.
Attach bumper transcript.
Return the rendered text for the page to be verified
Create a stock course with a specific due date. :param course_kwargs: All kwargs are passed to through to the :class:`CourseFactory`
Get the text of the /about page for the course.
A student view that displays the activate_block_id context variable.
Test rendering XBlocks for a self-paced course. Relies on the query count assertions in the tests defined by RenderXBlockMixin.
Test successful CDN request.
Test if no alternative video in CDN exists.
Ensure None args return None
Ensure emptyrstring args return None
Returns the result from calling the video's student_view_data method. Arguments: allow_cache_miss is passed in the context to the student_view_data method.
Tests retrieving a video that is stored in VAL but not associated with a course in VAL.
Create course, 2 chapters, 2 sections
Make sure that inconsistent speed keys are parsed correctly.
Re-fetch the course from the database so that the object being dealt with has everything added to it.
Returns the url of the problem given the problem's name
Create state for a problem, but don't answer it
Reset specified problem for current user.
Shows the answer to the current student.
Add a grading policy to the course.
Assert that percent grade is as expected.
Global scores, each Score is a Problem Set. Returns list of scores: [<points on hw_1>, <points on hw_2>, ..., <points on hw_n>]
Check grade is 0 to begin with.
Tests grading when the max score cache is disabled
Test that the exam section has the proper weight.
Reverse a list of course urls. `names` is a list of URL names that correspond to sections in a course. `course` is the instance of CourseDescriptor whose section URLs are to be returned. Returns a list URLs corresponding to section in the passed in course.
Verifies that going to the courseware which does not have a survey does not redirect to a survey
Verifies that going to the courseware with an unanswered survey, redirects to the survey
Verifies that going to the courseware with an answered survey, there is no redirect
Verifies that going to the courseware with a required, but non-existing survey, does not redirect
Used to stub out microsite.get_value().
Test image URL formatting.
Test that without course_image being set, but static_asset_path being set that we get the right course_image url.
Test that with course_image and static_asset_path both being set, that we get the right course_image url.
Test image URL formatting.
Returns the server response for course info page.
Returns a mock JSON request for the specified user
Verifies that the staff debug control visibility is as expected (for staff only).
Creates a normal student user.
Tests that staff debug control is not present for a student.
Tests that "Show Answer" is not visible for a student.
Creates a staff user.
Login as a staff user
Login as a student
Submit an answer to the single problem in our test course.
Return the reported progress detail for the problem in our test course. The return value is a string like u'1/2'.
Load the progress page for the course the user is enrolled in.
Test default favicon is served if no theme is applied
The overridden settings for this class get cached on class variables. Reset those to None before and after running the test to ensure clean behavior.
Course is created here and shared by all the class's tests.
Factory method.
Fetch the group to which this user is linked in this partition, or None.
Internal DRY / shorthand.
Set group_access on block specified by location.
Sets the user_partitions on block specified by location.
Clear out the stevedore extension points on UserPartition to avoid side-effects in other tests.
DRY helper.
Test for assert failure when a user who didn't create the kvs tries to get from it it
Test for assert failure when a user who didn't create the kvs tries to get from it it
Construct a kv_dict that can be passed to set_many
Patch a function with a given return value, and return the mock
Patch a function with a given mock
Ensure that the score_set handler properly calls the user_by_anonymous_id method to convert from an anonymized ID to a user object
Ensure that, on receipt of a score_set signal from the Submissions API that does not have the correct kwargs, the courseware model does not generate a signal.
Ensure that, on receipt of a score_set signal from the Submissions API that has an invalid user ID, the courseware model does not generate a signal.
Ensure that the score_reset handler properly calls the user_by_anonymous_id method to convert from an anonymized ID to a user object
Ensure that, on receipt of a score_reset signal from the Submissions API that does not have the correct kwargs, the courseware model does not generate a signal.
Empty XModule for testing with no dependencies.
Set the score for this testing XBlock.
Helper to return the dict TOC section associated with a Chapter of url_name
Helper to return the dict TOC section associated with a section of url_name
Helper to return the TOC section associated with url_name
Helper to return the sequential associated with sequential_url_name
for split courses if course_image is empty then course_image_url will be the default image url defined in settings
Get the module from the course from which to pattern match (or not) the 'View in Studio' buttons
Regular Studio courses should see 'View in Studio' links.
Courses that change 'course_edit_method' setting can hide 'View in Studio' links.
Mixed mongo courses that are mongo backed should see 'View in Studio' links.
Courses that change 'course_edit_method' setting can hide 'View in Studio' links.
A simple view that returns just enough to test.
This method return data that should be associated with the "check_problem" event
Creates a fake module, invokes the callback and extracts the 'module' metadata from the emitted problem_check event.
Publish the user's grade, takes grade_dict as input
Set up the course and user context
Empty XModule for testing with no dependencies.
Ensure the bound children are indeed children.
Ensure unbound children are indeed children.
Used to assert that sets of children are equivalent.
Simple helper method to iterate through student grades and give ustwo dictionaries -- one that has all students and their respective gradesets, and one that has only students that could not be graded and their respective error messages.
Create a new mock Score object with specified earned and possible values
Create a new BlockUsageLocation with the given type and ID.
Logs in the test user.
Options to configure the test course. Intended to be overridden by subclasses.
Ensure that all attributes are initialised when unpickling CourseMasquerade objects. Users might still have CourseMasquerade objects from older versions of the code in their session.  These old objects might not have all attributes set, possibly resulting in AttributeErrors.
Returns the masquerade for the current user for the specified course. If no masquerade has been installed, then a default no-op masquerade is returned.
Returns the role that the user is masquerading as, or None if no masquerade is in effect.
Returns whether the user is a staff member masquerading as a specific student.
Arguments: kvs: The KeyValueStore to wrap. session: The Django session used to store temporary data in.
Convert the key of Type KeyValueStore.Key to a string. Keys are not JSON-serializable, so we can't use them as keys for the Django session. The implementation is taken from cms/djangoapps/contentstore/views/session_kv_store.py.
Uppercasing the title here since CSS does it on the front-end
Make sure the alert has gone away. Note that the splinter documentation indicates that get_alert should return None if no alert is present, however that is not the case. Instead a NoAlertPresentException is raised.
Have the browser input an answer (either correct or incorrect)
Verify that a 404 is returned for a non-existent profile page.
Create courses in modulestore.
Assert courses don't exist in the course block cache.
Assert courses exist in course block cache.
A higher order function implemented on top of the block_structure.get_collected function that returns the block structure in the cache for the given course_key. Returns: BlockStructureBlockData - The collected block structure, starting at root_block_usage_key.
A higher order function implemented on top of the block_structure.updated_collected function that updates the block structure in the cache for the given course_key.
Returns the manager for managing Block Structures for the given course.
Unique identifier for the transformer's class; same identifier used in setup.py.
Returns whether the block with the given block_key in the given block_structure should be visible to staff only per computed value from ancestry chain.
Unique identifier for the transformer's class; same identifier used in setup.py.
Returns the merged value for the start date for the block with the given block_key in the given block_structure.
Unique identifier for the transformer's class; same identifier used in setup.py.
Get the student module for the given user for the given block. Arguments: user (User) course_key (CourseLocator) block_key (BlockUsageLocator) Returns: StudentModule if exists, or None.
Helper function to format block keys
Unique identifier for the transformer's class; same identifier used in setup.py.
Unique identifier for the transformer's class; same identifier used in setup.py.
Set state attribute on initialize.
Returns the block id (display name) that is used in the test course structures for the given block type and block reference string.
Gets the set of usage keys that correspond to the list of ref values as defined on blocks. Returns: set[UsageKey]
Helper method to retrieve the requested block (index) from the modulestore
Helper method to update the block in the modulestore
Helper method to publish the course (from draft to publish branch)
Returns the usage key for the given key parameters using the default modulestore
Returns a start date for the given enum value
Get the field value that is directly set on the xblock. Do not get the inherited value since field inheritance returns value from only a single parent chain (e.g., doesn't take a union in DAGs).
Validates that a string is lowercase.
Loads the badging backend.
Get the assertion for this badge class for this user, if it has been awarded.
Contacts the backend to have a badge assertion created for this badge class for this user.
Get all assertions for a user, optionally constrained to a course.
Parses the settings from the courses_completed field.
Parses the settings from the courses_completed field.
Base URL for all API requests.
URL for generating a new Badge specification
Get the URL for a course's badge in a given mode.
URL for generating a new assertion.
Headers to send along with the request-- used for authentication.
Dummy backend that creates assertions without contacting any real-world backend.
Lazily loads a BadgeHandler object for the current course. Can't do this on setUp because the settings overrides aren't in place.
Verify the a headers dict from a requests call matches the proper auth info.
Check to make sure the handler generates appropriate HTTP headers.
Make sure ensure_badge_created doesn't call create_badge if we know the badge is already there.
Awards badges based on the number of courses a user is enrolled in.
Generates a URL to the user's Certificate HTML view, along with a GET variable that will signal the evidence visit event.
Constructs the 'criteria' URL from the course about page.
Verify that a course with start/end dates contains a description with them.
Verify that a badge created for a course with no end date gets a different description.
Return the URL to look up the current user's assertions.
Used for tests which may need to test for a course_id or a wildcard.
Create a badge class, using a course id if it's relevant to the URL pattern.
Get a dictionary to be serialized into querystring params based on class settings.
Raised the course key given isn't valid.
Return most recent to least recent badge.
Get one of the test images from the test data directory.
Verify that the image validator is triggered when cleaning the model.
Dummy badge backend, used for testing.
Verify the BadgeClass fetches the backend properly.
Verify handing incomplete data for required fields when making a badge class raises an Integrity error.
Verify that the image validator is triggered when cleaning the model.
Verify that saving a valid badge image is no problem.
Verify that setting an image with an uneven width and height raises an error.
Get the prefix for the site URL-- protocol and server name.
Wrapped function which bails out early if bagdes aren't enabled.
returns a boolean indicating whether or not openbadges are enabled.
Adds the inline link
Is user allowed to change group of article to one of its own groups?
Ensure that the response has the course navigator.
Creates an article at /parent/slug and returns its URLPath
Test wiki tab when Enabled setting is True and the wiki is open to the public.
Test wiki tab when Enabled setting is False
Returns whether the slug can be interpreted as a number.
Authenticate users, but allow inactive users (with u.is_active == False) to authenticate.
Returns the appropriate adapter based on the OAuth client linked to the request.
Dispatch the request to the selected backend's view.
Return the client_id from the provided request
Returns a dictionary mapping scopes to methods that will add claims to the JWT payload.
Add the email claim details to the JWT payload.
Create an oauth client application that is confidential.
Create an oauth client application that is public.
Get the oauth client application with the specified filters. Wraps django's queryset.get() method.
Given an AccessToken object, return the associated client application.
Given a token string, return the matching AccessToken object.
Given a list of scopes, return a space-separated list of those scopes.
Create an oauth client application that is confidential.
Create an oauth client application that is public.
Get the oauth client application with the specified filters. Wraps django's queryset.get() method.
Given an AccessToken object, return the associated client application.
Given a token string, return the matching AccessToken object.
Given a list of scopes, return a space-separated list of those scopes.
Call the view with a POST request objectwith the appropriate format, returning the response object.
Return a dictionary to be used as the body of the POST request
Create a confidential client suitable for testing purposes.
Return a request with the specified client_id in the body
Evaluate a student attribute that is ready for JSON serialization
Build dict containing information about a single student.
accessor to see if they work too
Error thrown if validation fails.
Throw a ValidationError if false.
Get the orm filter parameters for a feature.
Helper class method to look up a Survey Form, throw FormItemNotFound if it does not exists in the database, unless throw_if_not_found=False then we return None
Returns all answers for all users for this Survey
Returns whether a given user has supplied answers to this survey
Removes all answers that a user has submitted
Returns a list of defined field names for all answers in a survey. This can be helpful for reporting like features, i.e. adding headers to the reports This is taken from the set of <input> fields inside the form.
Returns whether a user has any answers for a given SurveyForm for a course This can be used to determine if a user has taken a CourseSurvey.
View to render the survey to the end user
Asserts that an unauthenticated user cannot access a survey
Asserts that if we ask for a Survey that does not exist, then we get a 302 redirect
Asserts that an anonymous user cannot answer a survey
Asserts that any attempts to post back to a non existing survey returns a 404
Assert the a requried course survey is when both the flags is set and a survey name is set on the course descriptor
Assert that a new course which has a required survey and user has answers for it
Helper method to set up test form
Asserts that when looking up a form that does not exist
Asserts that when looking up a form that does not exist
See if the survey form returns the expected unicode string
Make sure that if a SurveyForm is saved with unparseable html an exception is thrown
Make sure we can't create two surveys of the same name
Create a new survey and assert that there are no answers to that survey
Create a new survey with no answers in it and check that a user is determined to not have answered it
Checkout/payment cancellation view.
Checkout/payment error view.
Helper to get the authenticated user from the current HTTP request (if applicable). If the requester of an unenrollment is not the same person as the student being unenrolled, we authenticate to the commerce service as the requester.
Add the service user.
Enroll the user in the course.
POST to the view being tested. Arguments course_id (str) --  ID of course for which a seat should be ordered. :return: Response
Asserts the detail field in the response's JSON body equals the expected message.
Asserts correctness of a JSON body containing payment information.
Asserts the response is a valid response sent when the E-Commerce API is unavailable.
Asserts that the user is NOT enrolled in the course, and that an enrollment event was NOT fired.
The view should return HTTP 403 status if the user is not logged in.
Verify that the view only responds to POST operations.
If the call to the E-Commerce API times out, the view should log an error and return an HTTP 503 status.
If the E-Commerce API raises an error, the view should return an HTTP 503 status.
Verifies that the view behaves appropriately when the course only has a professional mode.
Verifies that the view behaves appropriately when the course only has a professional mode and the E-Commerce Service is not configured.
If the order is not found, the view should return a 404.
List courses and modes.
Create course modes for a course.
Update course modes for an existing course.
Serializes datetime values using Django REST Framework's encoder.Use this to simplify equality assertions.
Verify only authenticated users can access the view.
Verify only authenticated users can access the view.
Verify create/edit operations require appropriate permissions.
Verify the view supports creating a course when authenticated with the API header key.
If the order is not found, the view should return a 404.
Verify a validator checking non-existent courses.
Verify the method properly maps mode slugs to display names.
Log into LMS.
The view should redirect to the login page if the user is not logged in.
DRY helper
Enable / Disable CommerceConfiguration model
Verify that is_enabled() returns True if used for a microsite.
Verify that the proper URL is returned.
DRY helper: emit the UNENROLL_DONE signal, as is done in common.djangoapps.student.models after a successful unenrollment.
Ensure that the receiver quietly bypasses attempts to initiate refunds when there is no external service configured.
Ensure that expected authorization issues are logged as warnings.
Ensure that unexpected Exceptions are logged as errors (but do not break program flow).
Ensure the notification function is triggered when refunds are initiated
Ensure the notification function is NOT triggered when no refunds are initiated
Ensure an error occuring during notification does not break program flow, but a warning is logged.
Ensure the notification function raises an Exception if used in the context of microsites.
Mock Zendesk's ticket creation API.
Call the create_zendesk_ticket function.
Verify the Zendesk API is not called if the settings are not all set.
Verify exceptions are handled appropriately if the request to the Zendesk API fails. We simply need to ensure the exception is not raised beyond the function.
JSON response that simply contains a detail field.
Determines the availability of the EcommerceService based on user activation and service configuration. Note: If the user is anonymous we bypass the user activation gate and only look at the service config. Returns: Boolean
Return the URL for the checkout page.Example: http://localhost:8002/basket/single_item/
Utility function; generates UUIDs
Returns the earliest allowed date given the settings
Return whether or not a user has satisfactorily proved their identity. Depending on the policy, this can expire after some period of time, so a user might have to renew periodically. This will check for the user's *initial* verification.
Check whether the user has an active or pending verification attempt Returns: bool: True or False according to existence of valid verifications
Datetime that the verification will expire.
Check whether the verification was active at a particular datetime.Arguments: deadline (datetime): The date at which the verification was active (created before and expired after). Returns: bool
Sometimes, the error message we've received needs to be parsed into something more human readable The default behavior is to return the current error message as is.
Returns the verification status for use in grade report.
Retrieve the verification deadline for a particular course. Arguments: course_key (CourseKey): The identifier for the course. Returns: datetime or None
Invalidate the cached verification deadline information.
Unicode representation of the checkpoint.
Get the status of the latest checkpoint attempt of the given user.Args: user_id(str): Id of user Returns: VerificationStatus object if found any else None
Create new verification status object.Arguments: checkpoint(VerificationCheckpoint): VerificationCheckpoint object user(User): user object status(str): Status from VERIFICATION_STATUS_CHOICES Returns: None
Create new verification status objects for a user against the givencheckpoints. Arguments: checkpoints(list): list of VerificationCheckpoint objects user(User): user object status(str): Status from VERIFICATION_STATUS_CHOICES Returns: None
Get the location ID of reverification XBlock.Args: photo_verification(object): SoftwareSecurePhotoVerification object Return: Location Id of XBlock if any else empty string
Return dict of all the checkpoints with their status.Args: user_id(int): Id of user. course_key(unicode): Unicode of course key Returns: dict: {checkpoint:status}
Return the name of the key to use to cache the current configurationArgs: user_id(int): Id of user. course_key(unicode): Unicode of course key Returns: Unicode cache key
Configure in-course re-verification.Enable or disable in-course re-verification feature. When this flag is disabled, the "in-course re-verification" feature will be disabled. When the flag is enabled, the "in-course re-verification" feature will be enabled.
Toggle in-course reverification (ICRV) status emailsDisabled by default. When disabled, ICRV status emails will not be sent. When enabled, ICRV status emails are sent.
Create skipped reverification object.Arguments: checkpoint(VerificationCheckpoint): VerificationCheckpoint object user_id(str): User Id of currently logged in user course_id(CourseKey): CourseKey Returns: None
Check existence of a user's skipped re-verification attempt for aspecific course. Arguments: user_id(str): user id course_id(CourseKey): CourseKey Returns: Boolean
Return the name of the key to use to cache the current configurationArguments: user(User): user object course_key(CourseKey): CourseKey Returns: string: cache key name
Encrypts and endcodes `data` using `key'
Decrypts and decodes `data` using `key'
Return a version of the `data` that has been encrypted to
Decrypt `encrypted_data` using `key`
Given an AES key, return a Cipher object that has `encrypt()` and `decrypt()` methods. It will create the cipher to use CBC mode, and create the initialization vector as Software Secure expects it.
Return the initialization vector Software Secure expects for a given AES key (they hash it a couple of times and take a substring).
Pad the given `data` such that it fits into the proper AES block size
remove all padding from `padded_data`
`rsa_pub_key` is a string with the public key
When given some `data` and an RSA private key, decrypt the data
Given a dictionary of headers and a dictionary of the JSON for the body, will return a str that represents the normalized version of this messsage that will be used to generate a signature.
Send email to given userArgs: user_id(str): User Id subject(str): Subject lines of emails message(str): Email message body Returns: None
When editing an existing record, all fields should be read-only.VerificationStatus records should be immutable; to change the user's status, create a new record with the updated status and a more recent timestamp.
The provided image data could not be decoded.
Test the case where the user has no pending `PhotoVerificationAttempts`, but is just starting their first.
Enroll the user in a course.
Unenroll the user from a course.
Set the contribution amount pre-filled in a session var.
Check whether a course mode is displayed.
Check whether steps in the flow are displayed to the user.
Check the messaging on the page.
Check the user detail information on the page.
Check the pre-filled contribution amount.
Check that the session flag for attempting an upgrade is set.
Check that the page redirects to the student dashboard.
Check that the page redirects to the start of the payment/verification flow.
Check that the page redirects to the "verify later" part of the flow.
Check that the page redirects to the "upgrade" part of the flow.
Checkout is handled by shoppingcart when the course mode's sku is empty.
Assuming patched_create_order was called, return a mapping containing the call arguments.
Checkout is handled by the ecommerce service when the course mode's sku is nonempty.
Assuming patched_create_order was called, return a mapping containing the call arguments.
Check the user's name.Arguments: full_name (unicode): The user's full name. Raises: AssertionError
Retrieve POST data from the last request.
Used as a side effect when mocking `verify_student.ssencrypt.has_valid_signature`.
Test that a User can use reverify link for initial verification.
Retrieve the reverification page and return the response.
Check that the reverification flow is rendered.
Check that the user is blocked from reverifying.
Verify that POST requests including an invalid checkpoint locationresults in a 400 response.
Helper method for creating a reverification checkpoint.
Helper method for initial verification.
Construct the reverification url. Arguments: course_key (unicode): The ID of the course checkpoint_location (str): Location of verification checkpoint Returns: url
Mocking a boto S3 Bucket object.
Mocking a boto S3 Connection
Simulates what happens if our post to Software Secure is rejected, for whatever reason.
Render a fake Software Secure page that will pick the most recent attempt for a given user and pass it to the html page.
Verify the signal sets deadline to course end when no deadline exists.
Test that the user gets 404 response if the feature flag 'ENABLE_SOFTWARE_SECURE_FAKE' is not enabled.
Test that the user gets 302 response if that user is not logged in.
Make a URL for a `url_name` using keyword args for url slots. Automatically provides the course id.
Writes InstructorTask immediately, ensuring the transaction is committed.
Creates standard message to store in output format for revoked tasks.
Given a list of `rows` containing unicode strings, return a new list of rows with those strings encoded as utf-8 for CSV compatibility.
Initialize with root_path where we're going to store our files. We will build a directory structure under this for each course.
Given a course_id, filename, and rows (each row is an iterable of strings), write this data out.
Exception indicating that a background task is already running
Exception indicating that a student id was not provided when generating a certificate for a specific student.
Submits a task to generate a CSV file containing all student answers to a given problem. Raises AlreadyRunningError if said file is already being updated.
AlreadyRunningError is raised if the course's grades are already being updated.
Submits a task to generate a CSV grade report containing problem values.
Submits a task to generate a CSV containing detailed enrollment info. Raises AlreadyRunningError if said CSV is already being updated.
Submits a task to generate a CSV file containing information about invited students who have not enrolled in a given course yet. Raises AlreadyRunningError if said file is already being updated.
Submits a task to generate a HTML File containing the executive summary report. Raises AlreadyRunningError if HTML File is already being updated.
Submits a task to generate a HTML File containing the executive summary report. Raises AlreadyRunningError if HTML File is already being updated.
Request to have students cohorted in bulk. Raises AlreadyRunningError if students are currently being cohorted.
Error signaling a fatal condition while updating problem modules. Used when the current module cannot be processed and no more modules should be attempted.
Gets task_id from `xmodule_instance_args` dict, or returns default value if missing.
Gets prefix to use when constructing xqueue_callback_url.
Submits the particular problem for rescoring
Submits the particular problem for rescoring for a particular student
returns number of attempts stored for `username` on problem `descriptor` for test course
Submits the current problem for resetting
Submits the current problem for deletion
Verify that all students were successfully graded by `upload_grades_csv`. Arguments: task_result (dict): Return value of `upload_grades_csv`.
Return the union of dicts Arguments: dicts: tuple of dicts
Create CourseEmail object for testing.
Tests the resubmission of an instructor task through the API. The call to the API is a lambda expression passed via `api_call`.  Expects that the API call returns the resulting InstructorTask object, and that its resubmission raises `AlreadyRunningError`.
Tests certificates generation task submission api
wrapper method for regenerate_certificates
Raises ValueError when student_set is 'specific_student' and 'specific_student_id' is None.
Create an internal location for a test problem.
Creates a InstructorTask entry representing a successful task.
Generate email address based on username
Login the user, given the `username`.
Creates an instructor for the test course.
Creates a student for the test course.
Use api method to fetch task status, using mock request.
Get StudentModule object for test course, given the `username` and the problem's `descriptor`.
Returns status corresponding to task_id via api method.
returns the result returned by instructor_task_status().
Create and enroll some students in the course.
Instead of initializing subtask info enroll some more students into course.
Expected method on a Key object.
Expected method on a Bucket object.
Expected method on an S3Connection object.
Subclasses should override this and return their report store.
Create and return a LocalFSReportStore.
Calculate dummy values for parameters needed for instantiating xmodule instances.
Check that a task_class fails when celery doesn't provide a current_task.
Run with celery, but with no course defined.
Run with celery, but no problem defined.
Run with no StudentModules defined for the current problem.
Test error is raised when certificate generation task run without current task
Test certificate generation task run without any errors
Helper method that format the user grade Args: header_row(list): header row of csv containing Student ID, Email, Username etc user(object): Django user object grade(list): Users' grade list
Mock out DefaultStorage.open with standard python open
Set a users emabargo state.
Create Students for course.
Exception indicating that a task already exists or has already completed.
Construct a SubtaskStatus object from a dict representation.
Construct a SubtaskStatus object.
Output a dict representation of a SubtaskStatus object. Use for creating a JSON-serializable representation for use by tasks.
Returns the number of retries of any kind.
Return print representation of a SubtaskStatus object.
Return unicode version of a SubtaskStatus object representation.
Filter that matches problems which are marked as being done
Helper method to verify that group_id is present.
sets up a mock response from the comments service for getting post counts for our other_user
given a course_id and thread_id, test for comment depth. if not too deep, call _create_comment to create the actual comment.
given a course_id and comment_id, create a response to a comment after checking the max depth allowed, if allowed
Given a course_id and comment_id, vote for this response.  AJAX only.
given a course id and comment id, remove vote ajax only
given a course id and thread id vote for this thread ajax only
given a course id and thread id, remove users vote for thread ajax only
given a course_id and commentable id, follow this commentable ajax only
given a course id and thread id, stop following this thread ajax only
given a course id and commentable id stop following commentable ajax only
Check whether the content is open.
Check if the given user is the author of the content.
:param extract_thread: a function which accepts a dictionary (complete json response payload) and returns another dictionary (first occurrence of a thread model within that payload).  if None is passed, the identity function is assumed.
Call the view for the implementing test class, constructing a request from the parameters.
Call the view for the implementing test class, constructing a request from the parameters.
Call `get_discussion_category_map`, and verify that it returns what is expected.
Asserts the expected map with the map returned by get_discussion_category_map method.
Basic test.
Returns true if the user has access to the discussion tab.
Make sure that course is reloaded every time--clear out the modulestore.
Returns a subset of keys from the provided dictionary
Returns a dictionary stripped of any keys having values of None
Determines if the provided value contains no information
Combines the keys from the two provided dictionaries
Boolean operation which tests a user's role-based permissions (not actually forums-specific)
Thrown when the discussion id map is not cached for this course, but an attempt was made to access it.
Returns the usage key of the discussion module associated with discussion_id if it is cached. If the discussion id map is cached but does not contain discussion_id, returns None. If the discussion id map is not cached for course, raises a DiscussionIdMapIsNotCached exception.
Transform the list of this course's discussion modules (visible to a given user) into a dictionary of metadata keyed by discussion_id.
Object constructor, converts data (if provided) to JSON
Object constructor, brokers provided HTML to caller
Injects the view name value into the request context
Determine whether a comment with the given parent violates MAX_COMMENT_DEPTH parent can be None to determine whether root comments are allowed
Checks the instance's module_type, and creates & saves a StudentModuleHistoryExtended entry if the module_type is one that we save.
Django can't cascade delete across databases, so we tell it at the model level to on_delete=DO_NOTHING and then listen for post_delete so we can clean up the CSMHE rows.
Given the status of a certificate, return a boolean indicating whether the student passed the course.
Enum for certificate social networks
Return a queryset for `GeneratedCertificate` models, filtering out ineligible certificates.
This returns the certificate for a student for a particular course or None if no such certificate exits.
Return True if certificate is valid else return False.
Deactivate certificate invalidation by setting active to False.
Mark a milestone entry if user has passed the course.
Iterate through example certificates in the set.Yields: ExampleCertificate
Return a 32-character UUID.
The course key associated with the example certificate.
Check whether self-generated certificates are enabled for a course.Arguments: course_key (CourseKey): The identifier for the course. Returns: boolean
Enable or disable self-generated certificates for a course.Arguments: course_key (CourseKey): The identifier for the course. is_enabled (boolean): Whether to enable or disable self-generated certificates.
Ensures configuration field contains valid JSON.
Retrieves the configuration field value from the database
Standard signal hook to create course badges when a certificate has been generated.
Standard signal hook to create 'x courses completed' badges when a certificate has been generated.
Helper function to create the url for certificates
Verify access with a valid Django Oauth Toolkit access token.
Verify the endpoint is inaccessible for authorization attempts made with an invalid OAuth access token.
Catches the signal that a course has been published in Studio andenable the self-generated certificates by default for self-paced courses.
Rolling back to zero-state, so remove all currently-defined configurations
Given the status of a certificate, return a boolean indicating whether the student passed the course.  This just proxies to the classmethod defined in models.py
Retrieve certificate information for a particular user for a specific course. Arguments: username (unicode): The identifier of the user. course_key (CourseKey): A Course Key. Returns: dict
Returns certificate template asset url for given asset_slug.
Return data to be used in Certificate Header, data returned should be customized according to the microsite settings
Mock the grading function to always return a passing grade.
Test the case when there is no certificate for a user for a specific course.
Test the case when there are no certificates for a user.
Test certificate url is empty if html view is not enabled and certificate is not yet generated
Check that self-generated certificates are enabled or disabled for the course.
Mock the XQueue method for adding a task to the queue.
Check that the certificate generation task was added to the queue.
Check the example certificate status.
Execute the function after setting up the microsite.
Create an example certificate.
Mock the XQueue method for sending a task to the queue.
Check the response from the callback end-point.
This will create a certificate html configuration
Run the management command to generate a fake cert.
Check the status of a certificate.
We just need one course here.
We just need one course here.
Execute a search and return the response.
Mocked version of microsite helper method to always return true
Build absolute URL pointing to test server.:param path: Path to append to the URL
Submit an HTTP GET request
Submit an HTTP GET request to the view for the given course
Verify that access is denied to non-authenticated users.
Verify that access is denied to non-authorized users.
The view should return a 404 if the course ID is invalid.
Determines if the user is staff or an instructor for the course. Always returns True if DEBUG mode is enabled.
Checks if the request user can access the course. Raises 404 if the user does not have course access.
Ensures that the user is authenticated (e.g. not an AnonymousUser), unless DEBUG mode is enabled.
Gets the course org
Gets the course run
Gets the course
Builds course detail uri
Allow external auth to intercept a login/registration request.Arguments: request (Request): The original request. mode (str): Either "login" or "register" Returns: Response or None
Request to change the user's password.
Construct the login URL to start third party authentication.
Make the next=... URL parameter that indicates where the user should go next. >>> _finish_auth_url_param([('next', '/dashboard')]) '/account/finish_auth?next=%2Fdashboard'
Verify that tabs header will be shown while program listing is enabled.
Verify that nav header will be shown while program listing is disabled.
Tear down initial setup
Test test_get_direct_parent
Test test_get_parent_none
Test test_orphaned_xblock
Test test_no_prerequisites
Returns the given cohort name for the specific course. Args: course_key (CourseKey): a course key representing the course we want the verified cohort name for Returns: The cohort name if the course key has one associated to it. None otherwise.
Verify that cohorting_settings is working for HTTP GET when verified track cohorting is disabled.
Upgrade the default enrollment to verified.
Return True if the CCX start date is in the past
Return True if the CCX due date is set and is in the past
Deserializes a course structure JSON object
A context manager for wrapping modulestore api methods.yields a stripped value and a function suitable for restoring it
wrap the provided modulestore
look up missing attributes on the wrapped modulestore
set attributes only on the wrapped modulestore
delete attributes only on the wrapped modulestore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See xmodule.modulestore.__init__.ModuleStoreWrite.delete_course
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
See the docs for xmodule.modulestore.mixed.MixedModuleStore
get json representation of ccx schedule
Override the default get_object to allow a custom getter for the CCX
Getter for the CCX Course ID
Helper function that checks that the response object has a body with the provided error
Test for different wrong inputs for the patch method
traverse the children of block in a breadth-first order
get a course given a key
After everything is done, clean up by un-doing the change to the OverrideFieldData object that is done during the wrap method.
Returns dummy request object for CCX coach tab test
Recursively unhide a unit and all of its children in the CCX schedule.
Helper function to set the node `visible_to_staff_only` property to True and save the change
Helper function for verifying the ccx tab.
Test ccx coach tab state (visible or hidden) depending on the value of enable_ccx flag, ccx feature flag.
call the function under test in this test case
Set up tests
Test the case where the course  has an unexpected structure.
Renders the progress page for the given course.
Assert that mongodb is queried ``calls`` times in the surrounded context.
Assert that exactly ``instantiations`` XBlocks are instantiated in the surrounded context.
Create a field override for the test CCX on <field> with <value>
verify that the course property of a ccx returns the right course
create staff user.
create instructor user.
create coach user
create ccx
get fake outbox
For [[1, 2], [3, 4]] returns [1, 2, 3, 4].  Does not recurse.
Finds a CCX of given coach on given master course. Arguments: course (CourseDescriptor): Master course coach (User): Coach to ccx ccx_id (long): Id of ccx Returns: ccx (CustomCourseForEdX): Instance of CCX.
Checks if an `identifier` string is a valid email
CCX field overrides are enabled per-courseprotect against missing attributes
Consume signals that indicate course published. If course already a CCX, do nothing.
Meta class for this Django model
Returns True if the user is the course staff else Returns False
Allow user access to course modification. `level` is one of ['instructor', 'staff', 'beta']
Revoke access from user to course modification. `level` is one of ['instructor', 'staff', 'beta']
example: { 'user': False, 'enrollment': False, 'allowed': True, 'auto_enroll': True, }
Render a mail subject and message templates using the parameters from param_dict and the given language. If language is None, the platform default language is used. Returns two strings that correspond to the rendered, translated email subject and message.
Return the rendered subject and message with the appropriate parameters.
Returns the User Enrollment information.
Returns the UserProfile information.
Returns the User Payment information.
Returns the User Enrollment information.
Returns email information marked as None, used in event email cannot be loaded
generate a unique password for each student.
convert user into dicts for json view
generate a random alphanumeric code of length defined in REGISTRATION_CODE_LENGTH settings
Convert user to dict for json rendering.
Gets invoice copy user's preferences.
Shows all of the students which have due date extensions for the given unit.
Shows all of the due date extensions granted to a particular student in a particular course.
Return the URL for a section in the instructor dashboard.Arguments: course_key (CourseKey) Keyword Arguments: section (str): The name of the section to load. Returns: unicode: The URL of a section in the instructor dashboard.
Start generating a set of example certificates.Example certificates are used to verify that certificates have been configured correctly for the course. Redirects back to the intructor dashboard once certificate generation has begun.
Returns true if the specified user has staff access.
Compares against MAX_ENROLLMENT_INSTR_BUTTONS to determine if course enrollment is considered small.
get_aside method for monkey-patching into applicable_aside_types while rendering an HtmlDescriptor for email text editing. This returns an empty list.
Generate an instance of HttpResponseBadRequest for this error.
Wrap the view.
Gets a student object using either an email address or username. Returns the student object associated with `unique_student_identifier` Raises User.DoesNotExist if no user object can be found.
Same as get_student_from_identifier() but will raise a DashboardError if the student does not exist.
Convert user input date string into an instance of `datetime.datetime` in UTC.
Find node in course tree for url.
Visit a node.  Checks to see if node has a due date and appends to `units` if it does.  Otherwise recurses into children to search for nodes with due dates.
Returns the `display_name` attribute of the passed in node of the course tree, if it has one.  Otherwise returns the node's url.
generate_unique_password should generate a unique password string that excludes certain characters.
generate_unique_password should generate a unique password string that hasn't been generated before.
create paid course mode.
mock request
Mock for get_task_completion_info
Convert fake task to dictionary representation.
Returns the matching mock emails for the given id
Test listing of bulk emails sent large amount of emails
Test the handling of email task that had failures
Test the handling of many emails with failures
Generate test certificate
Verify that we get a descriptive verification error when we haven't included a cohort field in the uploaded CSV.
Verify that we get a descriptive verification error when we haven't included a username or email field in the uploaded CSV.
Verify that we get a descriptive verification error when we haven't included any data in the uploaded CSV.
Verify that we get a descriptive verification error when we haven't uploaded a file with a '.csv' extension.
Verify that we can't access the view when we aren't a staff user.
Verify that we store the input CSV and call a background task when the CSV has username and cohort columns.
Verify that we store the input CSV and call the cohorting background task when the CSV has email and cohort columns.
Verify that we store the input CSV and call the cohorting background task when the CSV has username, email and cohort columns.
Verify that we store the input CSV and call the cohorting background task when lines in the CSV are delimited by carriage returns.
Test allow beta against list beta.
Raises DashboardError.
Returns "Oh yes!"
Fixtures
Test finding a nested unit.
Test attempt to find a unit that does not exist.
Check that the email outbox contains exactly one message for which both the message subject and body contain a certain French string.
Check that the email outbox contains exactly one message for which both the message subject and body contain a certain string.
Fake implementation of method which calls base class, which should throw NotImplementedError
Fake implementation of method which calls base class, which should throw NotImplementedError
Fake implementation of method which calls base class, which should throw NotImplementedError
Makes sure we get an instance of the registered enrollment provider
Reload and grab the module state from the database
Container for enrollment objects. `email` - student email `user` - student User object `cenr` - CourseEnrollment object `cea` - CourseEnrollmentAllowed object Any of the objects except email can be None.
Returns a dictionary of parameters used to render an email.
Returns the subject and message rendered in the specified language.
Returns the subject and message rendered in the specified language for CCX.
Returns expected dashboard enrollment message with link to Insights.
Test that the instructor dashboard correctly escapes course nameswith script tags.
adding course to user cart
Returns a dict representation of the object
Corrupt the task input field to test errors
Mocks out a django method
Mocks out a django method
Check that the certificates section is visible on the instructor dash.
Check that the "enable student-generated certificates" button is disabled.
Check whether the button says "enable" or "disable" cert generation.
Check that the response redirects to the certificates section.
Negative test of trying to reset attempts with bad content_id
Negative test of trying to reset attempts with bad user identifier
Negative test of trying to reset attempts with bad user identifier
Return a default host.
Always insecure.
Encode an object that the default encoder hasn't been able to.
Enable notes and add the tab to the course.
Returns true if the current course and user have a notes tab, false otherwise.
Create all test preferences in the database
Return `input_str` with PKCS#7 padding added to match AES block length
Return `input_str` with PKCS#7 padding trimmed to match AES block length
A view that disables notifications for the authenticated user This view should be invoked by an AJAX POST call. It returns status 204 (no content) or an error.
Return the tag if it is allowed or the empty string otherwise
Return source with all non-allowed tags removed, preserving the text content
Implements the GET method as described in the class docstring.
Implements the GET method for thread ID
Implements the POST method for the list endpoint as described in the class docstring.
Implements the PATCH method for the instance endpoint as described in the class docstring.
Implements the DELETE method for the instance endpoint as described in the class docstring
Implements the POST method for the list endpoint as described in the class docstring.
Implements the DELETE method for the instance endpoint as described in the class docstring
Return given valid page or default of 1
Return given valid page_size (capped at 100) or default of 10
Return a default choice
Return a default choice
Validate following
Create a new page containing the given objects, with the given page number and number of pages
Returns True if there is a page after this one, otherwise False
Returns True if there is a page before this one, otherwise False
Returns the number of the next page
Returns the number of the previous page
Overrides parent constructor to take information from discussion api essential for the parent method
Returns total number of results
Returns total number of pages the response is divided into
Returns absolute url of the next page if there's a next page available otherwise returns None
Validate that a value is not an empty string or whitespace. Raises: ValidationError
Ensure that a field is not edited in an update operation.
Returns a boolean indicating whether the given user_id identifies a privileged user.
Returns a boolean indicating whether the content should be anonymous to the requester.
Returns the author's username, or None if the content is anonymous.
Returns the role label (i.e. "Staff" or "Community TA") for the user with the given id.
Returns the role label for the content author.
Returns the rendered body content.
Returns a boolean indicating whether the requester has flagged the content as abusive.
Returns a boolean indicating whether the requester has voted for the content.
Returns the number of votes for the content.
Return the list of the fields the requester can edit
Compensate for the fact that some threads in the comments service do not have the pinned field set.
Returns the name of the group identified by the thread's group_id.
Returns a boolean indicating whether the requester is following the thread.
Returns the URL to retrieve the thread's endorsed comments.
Returns the URL to retrieve the thread's non-endorsed comments.
Returns the role label (i.e. "Staff" or "Community TA") for the endorsing user
Returns the timestamp for the endorsement, if available.
Check if the user is the author of a content object or a privileged user. Returns: Boolean
Get the sort key for the module (falling back to the discussion_target setting if absent)
Returns key sorted modules by category
Raise ValidationError if the given update data contains a field that is not editable by the requesting user
follow/unfollow thread for the user
mark or unmark thread/comment as abused
Retrieve a thread. Arguments: request: The django request object used for build_absolute_uri and determining the requesting user. thread_id: The id for the thread to retrieve
Delete a thread. Arguments: request: The django request object used for build_absolute_uri and determining the requesting user. thread_id: The id for the thread to delete Raises: PermissionDenied: if user does not have permission to delete thread
Return True if the requester authored the given content, False otherwise
Return True if the requester authored the given content or is a privileged user, False otherwise
Return the set of fields that the requester can initialize for a comment Any field that is editable by the author should also be initializable.
Remove the discussion tab for the course. user_id is passed to the modulestore as the editor of the module.
Create and return a course with discussions disabled. The user passed in will be enrolled in the course.
Build a discussion module in self.course
Get course topics for self.course, using the given user or self.user if not provided, and generating absolute URIs with a test scheme/host.
Register the appropriate comments service response, then call get_thread_list and return the result.
Create a thread with the given overrides, plus the course_id if not already in overrides.
Register the appropriate comments service response, then call get_comment_list and return the result.
Check that an empty update does not make any modifying requests.
Assert that the response has the given status code and parsed content
Create a thread with the given overrides, plus the course_id if not already in overrides.
Create a Role in self.course with the given name and users
Create a serializer with an appropriate context and use it to serialize the given thread, returning the result.
Create a serializer with an appropriate context and use it to serialize the given comment, returning the result.
Register a mock response for POST on the CS commentable endpoint
Register a mock response for PUT on the CS endpoint for the given thread_id.
Register a mock error response for GET on the CS thread endpoint.
Register a mock response for GET on the CS thread instance endpoint.
Register a mock error response for GET on the CS comment instance endpoint.
Register a mock response for PUT on the CS thread flag endpoints
Register a mock response for PUT on the CS comment flag endpoints
Assert that the last mock request had the expected query parameters
make a request to PATCH endpoint and return response
Return a context suitable for testing the permissions module
Return raw_body surrounded by p tags
Dry method for getting expected program credentials response data.
Verify that program data is present.
Verify that the page 404s if disabled.
This class specify purchase OrderTypes.
Returns a boolean whether a shopping cart (Order) exists for the specified user
Return the total cost of the cart.  If the order has been purchased, returns total of all purchased and not refunded items.
Reset the items price state in the user cart
Clear out all the items in the cart
Refund the given order. As of right now, this just marks the order as refunded.
Return the total cost of this OrderItem
This is basically a wrapper around purchased_callback that handles modifying the OrderItem itself
Start the purchase process.  This will set the order item status to "paying", at which point it should no longer be modified.
This is called on each inventory item in the shopping cart when the purchase goes through.
This is called on each item in a purchased order to generate receipt instructions. This should return a list of `ReceiptInstruction`s in HTML string Default implementation is to return an empty set
Returns a named tuple that annotates the pk of this instance with its class, to fully represent a pk of a subclass (inclusive) of OrderItem
Returns the unit_cost if no discount has been applied, or the list_price if it is defined.
The template that should be used when there's only one item in the order
Individual instructions for this order item. Currently, only used for emails.
if found Returns the Invoice Transaction object for the given invoice_id else returns None
Create a snapshot of the invoice item.The returned dictionary is JSON-serializable. Returns: dict
Create a snapshot of the invoice item.This is the same as a snapshot for other invoice items, with the addition of a `course_id` field. Returns: dict
Save a snapshot of the invoice's current state.Arguments: invoice (Invoice): The invoice to save.
Signal receiver that saves a snapshot of an invoice.Arguments: sender: Not used, but required by Django signals. instance (Invoice, InvoiceItem, or InvoiceTransaction)
Returns the registration codes that were generated via bulk purchase scenario.
Returns the registration codes that were generated via invoice.
Checks the existence of the registration code in the RegistrationCodeRedemption
Returns the registration code redemption object if found else returns None.
This function creates a RegistrationCodeRedemption entry in case the registration codes were invoice generated and thus the order_id is missing.
filter the is_active = True Coupons only
get all the coupon objects
return the coupon expiration date in the readable format
return discounted price against coupon
returns total seats purchases using coupon codes
returns the count of paid_course items filter by course_id and status.
Returns PaidCourseRegistration object if user has payed for the course enrollment else Returns None
Is the course defined by course_id contained in the order?
Tries to fetch an annotation associated with the course_id from the database.  If not found, returns u"". Otherwise returns the annotation
Is the course defined by course_id contained in the order?
Tries to fetch an annotation associated with the course_id from the database.  If not found, returns u"". Otherwise returns the annotation
When purchase goes through, activate and update the course enrollment for the correct mode
Configure whether donations are enabled on the site.
Donations do not need to be fulfilled, so this method does nothing.
Provide information about tax-deductible donations in the receipt.Returns: tuple of (Donation, unicode)
Provide information about tax-deductible donations in the confirmation email.Returns: unicode
Returns True if it's the first page of the pdf, False otherwise.
Inserts a new page and includes the border and the logos.
Creates the appropriate type of Report object based on the string report_type.
This method reset the code redemption from user cart items.
Tests if the user can download the payments report, based on membership in a group whose name is determined in settings.  If the group does not exist, denies all access
Gets date from the date input string.  Lets the ValueError raised by invalid strings be processed by the caller
override the default behavior of single instance of model delete method
Admin for course registration code invoice items.Displayed inline within the invoice admin UI.
Admin for invoice transactions.Displayed inline within the invoice admin UI.
Renders the HTML of the hidden POST form that must be used to initiate a purchase with CyberSource
Render an HTML form with POSTs to the hosted payment processor. Args: cart (Order): The order model representing items in the user's cart. Returns: unicode: the rendered HTML form
Return the URL of the current payment processor's endpoint. Returns: unicode
Return the URL of the payment end-point for CyberSource. Returns: unicode
Format an HTML error message
This is a test mocking function to return a microsite configuration
Tests the hash function.  Basically just hardcodes the answer.
Verify that this order does have a dump of information from the payment processor.
Returns the appropriate header based on the report type, in the form of a list of strings.
create a fake microsite site name
Fill in gap in test coverage.  __unicode__ method of PaidCourseRegistrationAnnotation
Tests when FEATURES['ENABLE_SHOPPING_CART'] is not set
Tests when FEATURES['ENABLE_PAID_COURSE_REGISTRATION'] is not set
Tests when request.user is anonymous
Tests when request.user doesn't have a cart with items
This method simple return the discounted amount
add dummy coupon into models
add dummy registration code into models
Adds a course mode to the test course.
adding course to user cart
Helper method to assert that a given url will return a 404 status code
add dummy coupon into models
Helper fn to login self.user
Helper fn to login self.user
Load the receipt page and verify that it contains the expected text.
Helper fn to login self.user
Group controlling perms is not present
User is not part of group controlling perms
User is part of group controlling perms
return the dictionary with the dummy data
This tests that calling purchased_callback on the base OrderItem class raises NotImplementedError
Test to check the total amount of the purchased items.
add dummy coupon into models
login the user to the platform.
Create a test user and order.
test to check the total amount of the invoices for the course.
Test to check the Invoice Transactions amount.
Check contact info in the latest history record.
Check line item info in the latest history record.
Check transactions (payments/refunds) in the latest history record.
Disable CSRF for these methods.
Helper function for `unquote_slashes`
Unquote slashes quoted by `quote_slashes`
local_resource_url for Studio
Returns the real, not anonymized, current user.
A test handler method.
A test handler method.
A test handler method.
Create a functional BlockUsageLocator for testing URL generation.
Return the parsed query string from a handler_url generated with the supplied query_string
Return the parsed path from a handler_url with the supplied handler_name and suffix
Just returns the test user
Just returns the test user
Test: module i18n service in LMS
Test: NoSuchServiceError should be raised block declaration returns none
Returns the user partition with the specified id.  Raises `NoSuchUserPartitionError` if the lookup fails.
Validates configuration text field.
Construct an absolute URL to a static asset.
Check whether the branding API is enabled.
Look up and return the value for given url name in microsite configuration. URLs are saved in "urls" dictionary inside Microsite Configuration. Return 'EMPTY_URL' if given url name is not defined in microsite configuration urls.
Return Base URL for site/microsite. Arguments: is_secure (bool): If true, use HTTPS as the protocol.
Lookup and return terms of services page url
Lookup and return privacy policies page url
Mock the render_to_response function
This is a regression test for a bug where the incoming user is anonymous and start dates are being checked.  It replaces a previous test as it solves the issue in a different way
Clear the configuration cache.
Enable or disable the feature flag for the branding API end-points.
Enable EdxNotes for the course.
Imitate get_html in module.
Tests that get_html is wrapped when feature flag is on, but edxnotes are disabled for the course.
Tests that get_html is not wrapped when feature flag is off.
Tests that get_html is not wrapped when problem is rendered in Studio.
Tests that is_feature_enabled shows correct behavior.
Tests the result if incorrect json is received.
Tests the result if an empty response is received.
Tests the result if incorrect json is received.
Tests the result if incorrect data structure is received.
Tests no results.
Returns `None` if no chapter found.
Returns `None` if no section found.
Tests that 404 status code is received if EdxNotes feature is disabled.
Tests that 404 status code is received if EdxNotes feature is disabled.
Test that generation of ID Token does not work for anonymous user.
Tests that 404 response is received if EdxNotes feature is disabled.
Verify EdxNotesTab visibility when user is unauthroized.
Verify EdxNotesTab visibility when ENABLE_EDXNOTES feature flag is enabled/disabled.
Get JWT ID-Token, in case you need new one.
Returns generated ID Token for edxnotes.
Returns token url for the course.
Returns an index of the child with `usage_key`.
Get the full path to a resource on the public notes API.
Get the full path to a resource on the private notes API.
Ensures the username is provided unless the request is made as an anonymous user.
Return valid 'return_type' or default value of 'dict'
Verifies whether the requesting user can access blocks in the course.
Returns whether the requesting_user can access all the blocks in the course.
Returns whether the requesting_user can access the blocks for other users in the given course.
Contain
Computes any information for each XBlock that's necessary to execute this transformer's transform method. Arguments: block_structure (BlockStructureCollectedData)
Return the precalculated depth of a block within the block_structure: Arguments: block_structure: a BlockStructure instance block_key: the key of the block whose depth we want to know Returns: int
Fail unless permission is denied to the form
Fail unless a 404 occurs
Check that the form returns the expected data
Verify that the response contains only the expected block ids.
Verify that the response contains the expected blocks
Assert that member is in container if and only if predicate is true. Arguments: member - any object container - any container predicate - an expression, tested for truthiness
Assert that the expression is true if and only if the predicate is true Arguments: expression predicate
Test fields accessed by a staff user
creates a BlockSerializer
creates a BlockDictSerializer
Ensure that the returned course is the course we just created
Call the `course_detail` api endpoint to get information on the course identified by `course_key`.
Call the list_courses api endpoint to get information about `specified_user` on behalf of `requesting_user`.
Verify that there is one course, and that it has the expected format.
log in the specified user and set its is_active field
Build a Request object for the specified user.
Return the CourseSerializer for the specified course.
Course ID is currently of the form "edx/999/2013_Spring" but this format could change.
URL for the registration page of a course.
Check element is visible
Return a success message displayed to the user
Check whether the combined login/registration page has loaded.
Current value of the email form field
Current value of the full_name form field
Current value of the username form field
Return a list of errors displayed to the user.
Return success status and any errors that occurred.
Return a success message displayed to the user.
Return success status and any errors that occurred.
Continue to peer grading after completing calibration.
Return a `RubricPage` for the calibration essay. If no rubric is available, raises a `BrokenPromise` exception.
Return the current problem name.
Return the text of the question of the problem.
Return the content of the problem
Return the "message" text of the question of the problem.
Return the "hint" text of the problem from html
Return the "hint" text of the problem from its div.
Returns True if MathJax css is present in the problem body
Returns True if MathJax css is present in the problem body
Fill in the answer to the problem. args: text: String to fill the input with. kwargs: input_num: If provided, fills only the input_numth field. Else, all input fields will be filled.
Click the Check button.
Click the Save button.
Click the Reset button.
wait for status icon
Waits for the expected status indicator. Args: status_selector(str): status selector string. message(str): description of promise, to be logged.
Click the Hint button.
Click the choice input(radio, checkbox or option) where value matches `choice_value` in choice group.
Is there a "correct" status showing?
Is there a "correct" status showing? Works with simple problem types.
Is there a "partially correct" status showing? Works with simple problem types.
Is there an "incorrect" status showing? Works with simple problem types.
Click on an inline icon that can be included in problem text using an HTML <clarification> element: Problem <clarification>clarification text hidden by an icon in rendering</clarification> Text
Return the current problem name.
Input a response to the prompt.
Click the run code button.
Return `selector`, but limited to this particular `NoteChild` context
Helper class that works with subsection grouping of notes in the Course Structure view on the Note page.
The tags associated with this note.
Clicks a tag associated with the note to change to the tags view (and scroll to the tag group).
Indicates if tab is closable or not.
Closes the tab.
Returns all notes on the page.
Helper class for Recent Activity view.
Helper class for Location in Course view.
Helper class for Tags view.
Helper class for Search Results view.
Switches to the appropriate tab `tab_name(str)`.
Closes the current view.
Indicates whether error message is visible or not.
Returns error message.
Returns all notes on the page.
Returns all chapter groups on the page.
Returns all subsection groups on the page.
Returns all tag groups on the page.
Returns the total number of notes in the list
Returns no content message.
Moves mouse to the element that matches `selector(str)`.
Clicks on the element that matches `selector(str)`.
Clicks on the "Show notes" checkbox.
Returns a list of annotatable components.
Returns a list of notes for the page.
Refreshes the page and returns a list of annotatable components.
Returns a list of notes for the component.
Removes the note by the selector.
Returns True if the note is visible.
Waiting for visibility of note adder button.
Waiting for visibility of note viewer.
Waiting for visibility of note editor.
Waiting for invisibility of all notes.
Clicks on the highlighted text.
Clicks on the note viewer.
Hover over highlighted text -> shows note.
Clicks cancel button.
Clicks save button.
Clicks delete button.
Clicks edit button.
Sets text for the note.
Sets tags for the note. Tags should be supplied as a list of strings, with each tag as an individual string.
Initialize the page.Arguments: browser (Browser): The browser instance.
This is the title label for the section of the student dashboard that shows all the courses that the student is enrolled in. The string displayed is defined in lms/templates/dashboard.html.
Return list of the names of available courses (e.g. "999 edX Demonstration Course")
Return the text of the banner on top of the page, or None if the banner is not present.
Verify if pre-requisite course messages are being displayed.
Retrieve the list of course DOM elements
Retrieves the specified social sharing widget by its classification
Get all courses shown in the dashboard
Get course date of the first course from dashboard
Click username dropdown.
Click username.
Return list username dropdown links.
Click on `Profile` link.
Click on `Account` link.
Check that MathJax has rendered in tab content
Return a boolean indicating whether the current tab is `tab_name`. Because this is a public method, it checks that we're on the right page before accessing the DOM.
Return the URL corresponding to the initial position in the flow.
Interact with the radio buttons appearing on the first page of the upgrade flow.
Interact with the payment button.
Interact with the immediate verification button.
Interact with the link allowing the user to defer their verification.
Interact with the 'Next' step button found in the verification flow.
Initialize the page.Arguments: browser (Browser): The browser instance. course_id (unicode): The course in which the user is enrolling.
Check if a step in the payment and verification flow has loaded.
Initialize the page.Arguments: browser (Browser): The browser instance. user_id: id of the user whom certificate is awarded course_id: course key of the course where certificate is awarded
Checks if certificate web view page is being viewed
Construct a URL to the page
returns accomplishment banner.
returns add to LinkedIn profile button
Verify if we are on correct page
Check if bookmarks button is visible
Click on Bookmarks button
Check if bookmarks results are present
Returns the bookmarks results header text
Returns the bookmarks empty header text
Returns the bookmarks empty list text
Returns the total number of bookmarks in the list
Return list of breadcrumbs for all bookmarks
Returns True if the browser is currently on the right page.
Returns True if the conditional's content has been revealed, False otherwise
Initialize the page.Arguments: browser (Browser): The browser instance.
Returns a browser query object representing the video modal element
Returns a browser query object representing the video modal element
Returns a browser query object representing the video modal element
Returns a browser query object representing the video modal element
Cancel the request. This redirects to an invalid URI, because we don't want actual network connections being made.
Confirm OAuth access This redirects to an invalid URI, because we don't want actual network connections being made.
Boolean for if the page has an error or not.
Returns count of chapters available on LHS navigation.
Return the number of sections in the sidebar on the page
Return the number of subsections in the sidebar on the page, including in collapsed sections
Return the xblock components within the unit on the page.
Return the number of rendered xblocks within the unit on the page
Extract rendered xblock component type. Returns: str: xblock module type index: which xblock to query, where the index is the vertical display within the page (default is 0)
Returns the course license text, if present. Else returns None.
Within a section/subsection navigate to the sequential position specified by `sequential_position`. Arguments: sequential_position (int): position in sequential bar
Returns the position of the active tab in the sequence.
Returns whether the active tab has changed. It is defensive against the case where the page is still being loaded.
Returns True if the timed/proctored exam timer bar is visible on the courseware.
clicks the start this timed exam link
Returns whether the "you have submitted your exam" message is present. This being true implies "the exam contents and results are hidden".
Return the entrance exam status message selector on the top of courseware page.
Returns boolean indicating presence entrance exam status message container div.
Returns boolean indicating presence of passed message.
Returns True if the timed/proctored exam timer bar is visible on the courseware.
Return the course tree breadcrumb shown above the sequential bar
Check if bookmark button is visible
Return `bookmarked` if button is in bookmarked state else ''
Check if bookmark icon is visible on active sequence nav item
Browser is on the wiki page if the wiki breadcrumb is present
Replace content of a wiki article with new content
Return the name of the article
Construct a URL to the page within the course.
The wiki page editor
Editor must be open already. This will replace any content in the editor with new content
search results list showing
did we find the search bar in the UI
enter the search term into the box
Fill input and do search
Check if loading indicator is visible.
Wait for loading indicator to become visible.
search results list showing
did we find the search bar in the UI
enter the search term into the box
execute the search
Selects the membership tab and returns the MembershipSection
Selects the data download tab and returns a DataDownloadPage.
Selects the student admin tab and returns the MembershipSection
Selects the certificates tab and returns the CertificatesSection
Selects the timed exam tab and returns the Special Exams Section
Selects the email tab and returns the bulk email section
Return `selector`, but limited to the bulk-email context.
Selects the specified recipient from the selector. Assumes that recipient is not None.
Returns the MembershipPageAutoEnrollSection page object.
Return `selector`, but limited to the cohort management context.
Promise Check Function
Returns the name of the cohort with the count information excluded.
Returns the count for the cohort (as specified in the label in the selector).
Click on Save button shown after click on Settings tab or when we add a new cohort.
Check if assignment settings are disabled.
Return assignment settings disabled message in case of default cohort.
Return cohort name as shown in cohort header.
Returns, as a list, the names of the available cohorts in the drop-down, filtering out "Select a cohort".
Returns the name of the selected cohort.
Returns the number of users in the selected cohort.
Set Cohort Name.
Set assignment type for selected cohort. Arguments: assignment_type (str): Should be 'random' or 'manual'
Returns the description of the current cohort
Click on Manage Students Tab under cohort management section.
Returns the contents of the input field where students can be added to a cohort.
When no content groups have been defined, a messages appears with a link to go to Studio group settings. This method assumes the link is visible and clicks it.
Returns all the content groups available for associating with the cohort currently being edited.
Selects the specified content group from the selector. Assumes that content_group is not None.
Clicks the radio button for "No Content Group" association. Returns whether or not the radio button is in the selected state after the click.
Returns array of messages related to a CSV upload of cohort assignments.
Returns an array of messages present in the confirmation area of the cohort management UI. The first entry in the array is the title. Any further entries are the details.
Returns an array of messages present in the error area of the cohort management UI. The first entry in the array is the title. Any further entries are the details.
Gets the error message shown next to the content group selector for the currently selected cohort. If no message, returns None.
Click on the link to the Data Download Page.
Returns the state of `Enable Cohorts` checkbox state.
Check/Uncheck the `Enable Cohorts` checkbox state.
Shows the discussion topics.
Selects discussion topic checkbox by clicking on it.
Selects the always_cohort_inline_discussions radio button.
Returns the checked always_cohort_inline_discussions radio button.
Returns the checked some_cohort_inline_discussions radio button.
Selects the cohort_some_inline_discussions radio button.
Returns the status of inline discussion topics, enabled or disabled.
Returns the status for category checkboxes.
Returns the count for cohorted topics.
Saves the discussion topics.
Return the visibility status of cohort management controls(cohort selector section etc).
Returns True if the Auto-Enroll Browse button is present.
Returns True if the Auto-Enroll Upload button is present.
Clicks the Auto-Enroll Upload Button.
Valid inputs for section_type: MembershipPageAutoEnrollSection.NOTIFICATION_SUCCESS / MembershipPageAutoEnrollSection.NOTIFICATION_WARNING / MembershipPageAutoEnrollSection.NOTIFICATION_ERROR Returns True if a {section_type} notification is displayed.
Selects the correct file and clicks the upload button.
Selects the file which will generate errors and warnings and clicks the upload button.
Selects an image file and clicks the upload button.
Helper method to upload a file with registration and enrollment information.
Returns True if the Add Allowance button is present.
Returns True if the Add Allowance button is present.
Returns True if the Add Allowance popup and it's all assets are present.
Click the add allowance button
Returns True if the search field is present
Returns True if a row with the Student's attempt is present
Returns the "Download profile information as a CSV" button.
Returns the "Generate Grade Report" button.
Returns the "Generate Problem Grade Report" button.
Returns the download links for the current page.
Returns the ORA2 response download button for the current page.
Waits for a downloadable report to be available.
Returns a list of all the available reports for download.
Confirms student admin section is present
Returns email address/username input box.
Returns reset student attempts button.
Returns rescore student submission button.
Return Let Student Skip Entrance Exam button.
Returns delete student state button.
Returns show background task history for student button.
Returns show background task history for student button.
Returns True if student email address/username input box is present.
Returns True if reset student attempts button is present.
Returns True if rescore student submission button is present.
Returns True if delete student state for entrance exam button is present.
Returns True if show background task history for student button is present.
Returns True if background task history table is present.
clicks reset student attempts button.
clicks rescore submissions button.
clicks let student skip entrance exam button.
clicks delete student state button.
clicks background task history button.
Sets given email address as value of student email address/username input box.
Wait for certificate invalidations section to be rendered on page
Refresh Certificates Page and wait for the page to load completely.
Makes query selector by pre-pending certificates section
Click 'Generate Exception Certificates' button in 'Certificates Exceptions' section
Fill username/email field with given text
Click 'Add Exception' button in 'Certificates Exceptions' section
Fill username/email field with given text
Click 'Invalidate Certificate' button in 'certificates invalidations' section
Returns the "Generate Certificates" button.
Returns the disabled state of button
Returns certificate generation status message container.
Returns the "Pending Instructor Tasks" section.
Returns the "Certificate Exceptions" section.
Returns the Last Certificate Exception in Certificate Exceptions list in "Certificate Exceptions" section.
Returns the Message (error/success) in "Certificate Exceptions" section.
Returns last certificate invalidation from "Certificate Invalidations" section.
Return the number of updates on the page.
Attempt to log in using `email` and `password`.
Loading indicator must be present, but not visible
Return search result items.
Clear all button.
Initialize the page.Arguments: browser (Browser): The browser instance. course_id (unicode): The course in which the user is enrolling.
Return the URL corresponding to the track selection page.
Check if the track selection page has loaded.
Return the currently chosen view mode, e.g. "Staff", "Student" or a content group.
Set the current view mode, e.g. "Staff", "Student" or a content group.
Open the staff debug window Return the page object for it.
Answers the problem to give state that we can clean
Load problem via ajax by clicking next.
This clicks on the reset attempts link with an optionally specified user.
This delete's a student's state for the problem
This clicks on the reset attempts link with an optionally specified user.
check if ccx dashboard is open.
check if enrollment page in ccx dashboard is open.
Course ID is currently of the form "edx/999/2013_Spring" but this format could change.
Construct a URL to the page within the course.
Bind the CSS to a particular tabpanel (e.g. My Teams or Browse).
Click the 'view' button of the first team card on the page.
Get all the team cards on the page.
Return the names of each team on the page.
Return the names of each team on the page.
Return the team memberships text for each card on the page.
Get the page breadcrumb text displayed by the page header
Click on the "All Topics" breadcrumb
Click on the breadcrumb for a specific topic
Checks if teams page is being viewed
Get the active tab.
View the Browse tab of the Teams page.
Verify the number of teams listed on the topic page (browse teams within topic).
Click on the "All Topics" breadcrumb
Click on the breadcrumb for a specific topic
Return the text of the team warning message.
Check if the "My Teams" tab is being viewed.
Check if the Browse tab is being viewed.
Return a list of the topic cards present on the page.
Return a list of the topic names present on the page.
Return a list of the topic descriptions present on the page.
Show the teams list for `topic_name`.
Sort the list of topics by the given `sort_order`.
Note that `topic` is a dict representation of a topic following the same convention as a course module's topic.
Check if we're on a teams list page for a particular topic.
Get the topic name displayed by the page header
Get the topic description displayed by the page header
Return the current sort order on the page.
Get all the team names on the page.
Click on create team link.
Click on create team link.
Click on browse team link.
Sort the list of teams by the given `sort_order`.
Returns true if showing search results.
Set up `self.url_path` on instantiation, since it dynamically reflects the current topic.  Note that `topic` is a dict representation of a topic following the same convention as a course module's topic.
Check if we're on the create team page for a particular topic.
Get the page name displayed by the page header
Get the page description displayed by the page header
Get the error message text
Click on create team button
Click on cancel team button
Returns the 'delete team' button.
Clicks the 'edit membership' button
Checks if the edit membership button is present
Returns the number of team members shown on the page.
Clicks the remove link on the first member listed.
Click 'delete' on the warning dialog.
Click 'delete' on the warning dialog.
Check if we're on the teams list page for a particular team.
Get the id of the discussion module on the page
Get the team's name as displayed in the page header
Get the team's description as displayed in the page header
Verifies that team members are present
Returns team capacity text
Returns team location/country.
Returns team location/country.
Returns the team membership text
Verifies that team leave link is present
Returns the number of team members in this team
Clicks on first team member's profile image
Returns the username of team member
Wait for the team capacity text to be correct.
Helper method to format the expected team capacity text.
Returns join team message
Returns True if Join Team button is present else False
Returns True if Join Team message is present else False
Returns True if New Post button is present else False
Returns True if Edit Team button is present else False
Check whether program cards are present.
Check whether sidebar is present.
Program details page.
Construct the mode creation URL.
Return the list of available problems to peer grade.
Choose the problem with `problem_name` to start grading or calibrating.
Return field with field_id.
Wait for a field to appear in DOM.
Return the title of a field.
Return the current message in a field.
Return the current message for textarea field.
Wait for a message to appear in a field.
Wait for an indicator to appear in a field.
Return the value in a readonly field.
Return value of field in `display` or `placeholder` mode.
Return the title of the link in a link field.
Wait until the title of the specified link field equals expected_title.
Click the link in a link field.
Checks if page is opened
Return `selector`, but limited to this particular block's context
Gets contents of all child XBlocks as list of strings
Wait until element with class name `video` appeared in DOM.
Check if video loading completed. Returns: bool: Tells Video Finished Loading.
Check whether a poster is show.
Click on the video poster.
Construct unique element selector. Arguments: class_name (str): css class name for an element. vertical (bool): do we need vertical css selector or not. vertical css selector is not present in Studio Returns: str: Element Selector.
Set current video display name. Arguments: video_display_name (str): Display name of a Video.
Check if a web element is present in DOM. Returns: tuple: (is_satisfied, result)`, where `is_satisfied` is a boolean indicating whether the promise was satisfied, and `result` is a value to return from the fulfilled `Promise`.
Extract autoplay value of `data-metadata` attribute to check video autoplay is enabled or disabled. Returns: bool: Tells if autoplay enabled/disabled.
Checks if video player error message shown. Returns: bool: Tells about error message visibility.
Checks if video spinner shown. Returns: bool: Tells about spinner visibility.
Extract video player error message text. Returns: str: Error message text.
Check if a video button specified by `button_id` is visible. Arguments: button_id (str): key in VIDEO_BUTTONS dictionary, its value will give us the css selector for button. Returns: bool: Tells about a buttons visibility.
Make Captions Visible.
Make Captions Invisible.
Make closed captions visible.
Make closed captions invisible.
Get current visibility sate of captions. Returns: bool: True means captions are visible, False means captions are not visible
Get current visibility sate of closed captions. Returns: bool: True means captions are visible, False means captions are not visible
Extract captions text. Returns: str: Captions Text.
Extract closed captioning text. Returns: str: closed captions Text.
Clicks a line in the transcript updating the current caption.
Get current video speed value. Return: str: speed value
Wait for the video to change its speed to the expected value. If it does not change, the wait call will fail the test.
Gets the width and height of element specified by `selector` Arguments: selector (str): css selector of a web element Returns: dict: Dimensions of a web element.
Searches for and returns `cookie_name`
Get current selected video transcript language.
Check if menu `menu_name` exists. Arguments: menu_name (str): Menu key from VIDEO_MENUS. Returns: bool: Menu existence result
Gets current video slider position. Returns: str: current seek position in format min:sec.
Extract seconds part from current video slider position. Returns: str
Wait until `state` occurs. Arguments: state (str): State we wait for.
Check if buffering completed
Reload/Refresh the current video page.
Wait until current will be equal to `position`. Arguments: position (str): position we wait for.
Get the visibility state of quality button Returns: bool: visibility status
Check if quality button is active or not. Returns: bool: active status
Checks if the skip-to containers in transcripts are present and visible. Returns: bool
Wait until captions rendered completely.
Wait until closed captions are rendered completely.
Waits for the closed captions to be turned off completely.
Returns a query corresponding to the given CSS selector within the scope of this thread page
Returns the text of the first element matching the given selector, or None if no such element exists
Returns the group visibility label shown for the thread.
Returns the response count text, or None if not present
Returns the number of responses actually rendered
Returns the shown response count text, or None if not present
Returns the load more responses button text, or None if not present
Clicks the load more responses button and waits for responses to load
Returns true if the add response button is visible, false otherwise
Returns true if the response editor is present, false otherwise
Checks that MathJax css class is present
Returns true if the response is viewable onscreen
Returns true if the edit response button is present, false otherwise
Extracts href attribute of the referenced link
Replace the contents of the response editor
Returns True if both errors are visible, False otherwise.
Returns true if the "show comments" link is visible for a response
Returns true if the "add comment" form is visible for a response
Returns true if the comment is viewable onscreen
Returns true if the delete comment button is present, false otherwise
Returns true if the edit comment button is present, false otherwise
Returns true if the comment editor is present, false otherwise
Replace the contents of the comment editor
Return true if the browser is on the right page else false.
Return the text of option that is selected for sorting.
Change the option of sorting by clicking on new option.
Reload the page.
Check if the focus is on element
Count the number of threads available on page.
Check focus is set
Returns a query corresponding to the given CSS selector within the scope of this discussion page
Click the link to expand the discussion
Returns true if this page is showing the thread with the specified id.
Clicks the link to expand the thread
Check if selector is focused
Clicks the 'New Post' button.
Returns the new post button.
Return a list of sequence items on the page. Sequence items are one level below subsections in the course nav. Example return value: ['Chemical Bonds Video', 'Practice Problems', 'Homework']
Return a list of all section titles on the page.
Return a `Promise` that is fulfilled when the user is on the correct section and subsection.
Clean HTML of sequence titles, stripping out span tags and returning the first line.
Return True if the badges model has focus, False otherwise.
Initialize the page. Arguments: browser (Browser): The browser instance. username (str): Profile username.
Construct a URL to the page.
Check if browser is showing correct page.
Get user profile privacy. Returns: 'all_users' or 'private'
Verify that the accomplishments tab is available.
Get all currently listed badges.
Check if a field with id set to `field_id` is shown. Arguments: field_id (str): field id Returns: True/False
Check if a field with id set to `field_id` is editable. Arguments: field_id (str): field id Returns: True/False
Check if profile visibility selector is shown or not. Returns: True/False
Check if an icon is present for a field. Only dropdown fields have icons. Arguments: field_id (str): field id Returns: True/False
Returns age limit message.
Check if age limit message is present.
Return bool if image field has default photo or not.
Mouse over on given element.
Check if image is present with remove/upload access.
Returns the text message for profile image.
Construct the URL.
A dictionary containing details about the user account.
Return the current problem name.
Mouse over on given element.
Return visibility of active problem's input selector.
Click on active problem's "Return to Annotation" link.
Return the text showing which items the user is currently viewing.
Return the the current page number.
Returns the total page value
Go to the given page_number in the paginated list results.
Press the next page button in the paginated list results.
Press the previous page button in the paginated list results.
Return whether the 'next page' button can be clicked.
Return whether the 'previous page' button can be clicked.
Return whether the given element is not disabled.
Whether or not the notification is currently showing.
Whether or not the notification is finished showing.
Logout page to logout current logged in user.
Args: browser (selenium.webdriver): The Selenium-controlled browser that this page is loaded in. context_selector (str): The selector that identifies where this :class:`.AcidBlock` view is on the page.
Return whether a particular :class:`.AcidBlock` test passed.
Return whether a particular :class:`.AcidParentBlock` test passed.
Whether the init-fn test passed in this view of the :class:`.AcidBlock`.
Whether the tests of children passed
Whether the resource-url test passed in this view of the :class:`.AcidBlock`.
Args: browser (selenium.webdriver): The Selenium-controlled browser that this page is loaded in.
Return the hint shown to the student
Check the student answer is set correctly
Click the rate_hint button
Types content into the html component and presses Save.Arguments: content (str): The content to be used. raw (bool): If true, edits in 'raw HTML' mode.
Types content into the html component and presses Cancel to abort.Arguments: content (str): The content to be used. raw (bool): If true, edits in 'raw HTML' mode.
Sets content in the html component, leaving the component open.Arguments: content (str): The content to be used.
Signup page for Studio.
Verify that the browser is on the page and it is not still loading.
Return list of the experiment group configurations for the course.
Return list of the content groups for the course.
Return list of the group-configurations-list-item's of specified type for the course.
Creates new group configuration.
Creates new content group when there are none initially defined.
Creates new content group when at least one already exists
Returns the message about "no content" for the specified type.
Returns whether or not anything related to content experiments is present.
Find elements as defined by css locator.
Expand/collapse group configuration.
Group configuration usage information is expanded.
Add new group.
Return text for the defined by css locator.
Click on the `Course Outline` link.
Click on the link to the unit.
Open editing view for the group configuration.
Returns whether or not the delete icon is present.
Delete the group configuration.
Save group configuration.
Cancel group configuration.
Return group configuration mode.
Return group configuration id.
Return validation message.
Return list of usages.
Return group configuration name.
Set group configuration name.
Return group configuration description.
Set group configuration description.
Return delete note for the group configuration.
Find elements as defined by css locator.
Return the name of the group .
Set the name for the group.
Return allocation for the group.
Remove the group.
Open new textbook form by clicking on new textbook button.
Return the text of the css selector.
Set the value of input field by selector.
Returns True iff the browser has loaded the course rerun page.
Returns the value of the course run field.
Sets the value of the course run field.
Home page for Studio when not logged in.
Refresh the page and wait for all resources to load.
Returns the pre-requisite course drop down field options.
Returns the enable entrance exam checkbox.
Returns the alert confirmation element, which contains text such as 'Your changes have been saved.'
CSS for the course pacing button which is currently checked.
Return the message indicating that course pacing cannot be toggled.
Ensure the pre_requisite_course_options dropdown selector is displayed
Clicks save button, waits for confirmation unless otherwise specified
Wait for jQuery to finish all AJAX calls, if it is present.
URL to this page - override in subclass
Returns True if the browser has loaded the page.
Return a list of users listed on this page.
Returns a list of user names for users listed on this page
Is the "New Team Member" button present?
Click on the "New Team Member" button
Is the new user form visible?
Set the value of the "New User Email Address" field.
Gets user wrapper by email
Adds user to a course/library
Deletes user from course/library
Checks if modal dialog of specified class is displayed
Gets modal dialog text
URL to the "User Access" page for the given library.
Course Team page in Studio.
Sanity check that our wrapper element is on the page.
Return `selector`, but limited to this particular user entry's context
Get this user's username, as displayed.
Get this user's role, as displayed.
Does the UI indicate that this is the current user?
Can this user be promoted to a more powerful role?
What does the promote user button say?
Click on the button to promote this user to the more powerful role
Can this user be demoted to a less powerful role?
What does the demote user button say?
Click on the button to demote this user to the less powerful role
Can this user be deleted?
Does this have a warning in place of the promote/demote buttons?
Refresh the certificate page
Return signatory title for the first signatory in certificate.
Return Course Number
Return Course Number Override
Return Course Number Override selector
Return list of the certificates for the course.
Returns whether or not no certificates created message is present.
Returns text of .no-content container.
Returns text of new-button link .
Ensure the button is available for use
Ensure the button is available for use
Clicks the 'Create your first certificate' button, which is only displayed at zero state
Clicks the 'Add new certificate' button, which is displayed when certificates already exist
Initialize CertificateSection Page :param container: Container Page Object of the certificate section :param prefix: css selector of the container element :param index: index of section in the certificate list on the page :return:
Verify that the browser is on the page and it is not still loading.
Return selector fo certificate container
Find elements as defined by css locator.
Return text for the defined by css locator.
Return validation message.
Return certificate mode.
Returns certificate id.
Return certificate name.
Set certificate name.
Return certificate description.
Set certificate description.
Return certificate course title override field.
Set certificate course title override field.
Returns whether or not the certificate delete icon is present.
Certificate details are expanded.
Create a new certificate.
Save certificate.
Add signatory to certificate
Open editing view for the certificate.
Cancel certificate editing.
Expand/collapse certificate configuration.
Remove the first (possibly the only) certificate from the set
Verify that the browser is on the page and it is not still loading.
Return selector fo signatory container
Find elements as defined by css locator.
Return signatory name.
Set signatory name.
Return signatory title.
Set signatory title.
Return signatory organization.
Set signatory organization.
Cancel signatory editing.
Returns whether or not the delete icon is present.
Promise to wait until signatory delete prompt is visible
Promise to wait until signatory edit view is loaded
Promise to wait until signatory details view is loaded
Promise to wait until signatory image upload prompt is visible
Promise to wait until signatory image upload button is visible
Promise for the signature image to be displayed
Verify this is the export page
Click the export button. Should only be used if expected to fail, as otherwise a browser dialog for saving the file will be presented.
Indicates whether or not the error modal is showing.
Click the button on the modal dialog that appears when there's a problem.
If an import or export has an error, an error modal will be shown.
Verify this is the export page
Wait for the upload button to appear.
Checks if the 'view updated' button is showing.
Outputs the CSS class and promise description for task states based on completion.
Wait for the upload to be confirmed.
An should be shown if the user tries to upload the wrong kind of file. Tell us whether it's currently being shown.
The task list shows a series of steps being performed during import. It is normally hidden until the upload begins. Tell us whether it's currently visible.
Checks if the UTC timestamp of the last successful import is visible
Wait for the timestamp of the last successful import to be visible.
Wait for the upload field to display an error.
Returns True if the 'Contains staff only content' message is visible
Enters new_name as the item's display name.
Sets the explicit staff lock of item on the container page to is_locked.
Returns the child at the specified index. :type self: object
Adds a child to this xblock, waiting for notifications.
Clicks the delete button, then cancels at the confirmation prompt if cancel is True.
Return `selector`, but limited to this particular `CourseOutlineChild` context
Open the container page linked to by this unit link, and return an initialized :class:`.ContainerPage` for that unit.
Return the :class:`.CourseOutlineUnit with the title `title`.
Returns the units in this subsection.
Returns the CourseOutlineUnit at the specified index.
Adds a unit to this subsection
Return the :class:`.CourseOutlineSubsection` with the title `title`.
Returns a list of the CourseOutlineSubsections of this section
Returns the CourseOutlineSubsection at the specified index.
Adds a subsection to this section
Represents the three states that the expand/collapse link can be in
Clicks the "View Live" link and switches to the new tab
Return the :class:`.CourseOutlineSection` with the title `title`.
Returns the :class:`.CourseOutlineSection` at the specified index.
Find and click on first section name in course outline
Get the list of names of all sections present
Check that section name edit form present
Returns the sections of this course outline page.
Clicks the button for adding a section which resides at the top of the screen.
Clicks the button for adding a section which resides at the bottom of the screen.
Toggles whether all sections are expanded or collapsed
Starts course reindex by clicking reindex button
clicks on the settings button of subsection.
Makes a Proctored exam.
Choose "none" exam but do not press enter
Choose a timed exam but do not press enter
Choose a proctored exam but do not press enter
Choose a practice exam but do not press enter
returns whether the time allotted field is visible
Returns whether the review rules field is visible
Returns whether the hide after due field is visible
Select the access settings tab.
Returns the query representing the bottom add section button.
Returns true if a message informing the user that the course has no content is visible
Returns true iff the rerun notification is present on the page.
Clicks the dismiss button in the rerun notification.
Returns reindex button.
Expands all the subsections in this course.
Return a list of xblocks loaded on the outline page.
Returns the course license text, if present. Else returns None.
Returns true if the deprecated warning is visible.
Returns deprecated warning heading text.
Returns deprecated warning component list heading text.
Returns True if deprecated warning advance modules remove text is visible.
Returns deprecated warning advance modules remove text.
Returns True if components list visible.
Returns deprecated warning components display name list.
Returns deprecated advance modules list.
Returns `selector`, but limited to this particular `CourseOutlineModal` context.
Return whether or not the modal defined by self.MODAL_SELECTOR is shown.
Find the given css selector on the page.
Perform a Click action on the given selector.
Click the save action button, and wait for the ajax call to return.
Click the publish action button, and wait for the ajax call to return.
Click the cancel action button.
Check if the input box for the release date exists in the subsection's settings window
Check if the input box for the release time exists in the subsection's settings window
Check if the input box for the due date exists in the subsection's settings window
Check if the input box for the due time exists in the subsection's settings window
Check if the input for the  grading policy is present.
Set `time` value to input pointed by `input_selector` Not using the time picker to make sure it's not being rounded up
Returns the unit's release date. Date is "mm/dd/yyyy" string.
Sets the unit's release date to `date`. Date is "mm/dd/yyyy" string.
Returns the current value of the release time. Default is u'00:00'
Time is "HH:MM" string.
Returns the due date from the page. Date is "mm/dd/yyyy" string.
Sets the due date for the unit. Date is "mm/dd/yyyy" string.
Returns the current value of the release time. Default is u''
Time is "HH:MM" string.
Select the grading format with `value` in the drop-down list.
Returns true if the explict staff lock checkbox is checked, false otherwise.
Returns true iff the staff lock warning is visible.
The list of course run metadata for all displayed courses Returns an empty string if there are none
(bool) is the "New Library" button present?
Click on the "New Library" button
Is the new library form visisble?
Submit the new library form.
Returns "New Course" button.
Is the new course form visible?
Click "New Course" button
Submit the new course form.
Returns error notification element.
Returns text of error message.
Returns course organization input.
Returns `True` if course for given org, number and run exists on the page otherwise `False`
Does the page's list of libraries include a library matching kwargs?
return language selector
Determine if the programs tab appears on the studio home page.
DRY helper.
Determine if the "new program" button is visible in the top "nav actions" section of the page.
Determine if the "create your first program" button is visible under the programs tab (when the program list result is empty).
Clicks one of the forward nav buttons. Position can be 'top' or 'bottom'.
Clicks one of the forward nav buttons. Position can be 'top' or 'bottom'.
Enter a number into the page number input field, and then try to navigate to it.
Returns the page number as the page represents it, in string form.
Pages page for a course.
Checks that type filter is in table header.
Checks type filter label is added and visible in the pagination header.
Clicks type filter menu.
Args: browser (selenium.webdriver): The Selenium-controlled browser that this page is loaded in. locator (str): The locator that identifies which xblock this :class:`.xblock-editor` relates to.
Return `selector`, but limited to this particular `ComponentEditorView` context
Returns None because this is not directly accessible via URL.
Clicks save button.
Clicks cancel button.
Sets the select with given label (display name) to the specified value, and presses Save.
Returns the text of the first selected option for the select with given label (display name).
Return all visibility options.
Return all selected visibility options.
Course Updates page.
Wait for validation response from the server, and make sure that the validation error modal pops up. This method should only be called when it is guaranteed that there're validation errors in the settings changes.
Refresh the page and wait for all resources to load.
Trigger clicking event of the undo changes button in the modal. Wait for the undoing process to load via ajax call. Before that Scroll so the button is clickable on all browsers
Trigger click event of the manual changes button in the modal. No need to wait for any ajax. Before that Scroll so the button is clickable on all browsers
Checks if the validation modal is present.
Returns a list of display names of all invalid settings.
Returns a list of error messages of all invalid settings.
Make multiple settings changes and save them.
Get a key-value dictionary of all keys in the given list.
Returns all settings displayed on the advanced settings page/screen/modal/whatever We call it 'name', but it's really whatever is embedded in the 'id' element for each field
URL to the container page for an xblock.
Waits until the menu bar of components is present on the page.
Return a list of xblocks loaded on the container page.
Return a list of inactive xblocks loaded on the container page.
Return a list of active xblocks loaded on the container page.
Returns the title as displayed on the publishing sidebar component.
Returns the title before the release date in the publishing sidebar component.
Returns the release date of the unit (with ancestor inherited from), as displayed in the publishing sidebar component.
Returns the last saved message as displayed in the publishing sidebar component.
Returns the last published message as displayed in the sidebar.
Returns True if the unit inherits staff lock from a section or subsection.
Returns the text within the sidebar visibility section.
Returns the link for publishing a unit.
Discards draft changes (which will then re-render the page).
Returns True if staff lock is currently enabled, False otherwise
Clicks "View Live Version", which will open the published version of the unit page in the LMS. Switches the browser to the newly opened LMS window.
Clicks "Preview", which will open the draft version of the unit page in the LMS. Switches the browser to the newly opened LMS window.
Duplicate the item with index source_index (based on vertical placement in page).
Clicks the "edit" button for the first component on the page.
Returns True if the "add missing groups" button is present.
Returns an information message for the container page.
Return whether this container's display name is in its editable form.
Returns list of tab name in a category. Arguments: category_type (str): category type Returns: list
Return list of component names in a tab in a category. Arguments: category_type (str): category type tab_index (int): tab index in a category Returns: list
Return `selector`, but limited to this particular `CourseOutlineChild` context
Returns the text content of the xblock as displayed on the container page.
Returns the text content of the xblock as displayed on the container page. (For blocks which implement a distinct author_view).
Is a validation warning/error/message shown?
Helper method to return the <p> element of a validation warning
Is a validation warning shown?
Is a validation error shown?
Is a validation "not configured" message shown?
Get the text of the validation warning.
Get the text of the validation error.
Get the text of the validation "not configured" message.
Returns true if this xblock has a 'duplicate' button
Returns true if this xblock has a 'delete' button
Returns true if this xblock has an 'edit visibility' button :return:
Open the container page linked to by this xblock, and return an initialized :class:`.ContainerPage` for that xblock.
Clicks the "edit" button for this xblock.
Clicks the edit visibility button for this xblock.
Click on Advanced Tab.
Click on Basic Tab.
If editing, click on the "Settings" tab
Set the text of a CodeMirror editor that is part of this xblock's settings.
Click on settings Save button.
Click on a button as specified by `button_name` Arguments: button_name (str): button name
Go to the Group Configuration used by the component.
Checks to see if the XBlock is rendered as a placeholder without a preview.
Get Group Configuration name from link.
Edit Subsection page in Studio
Initialize the page object for the course located at `{course_org}.{course_num}.{course_run}` These identifiers will likely change in the future.
Add a new instance of the discussion category. menu_index specifies which instance of the menus should be used (based on vertical placement within the page).
Sets the text field with given label (display name) to the specified value, and presses Save.
Course Grading Settings page.
URL to the library edit page for the given library.
Returns True iff the browser has loaded the library edit page.
The text of the main heading (H1) visible on the page.
When the page first loads, there is a loading indicator and most functionality is not yet available. This waits for that loading to finish. Always call this before using the page. It also disables animations for improved test reliability.
Return a list of xblocks loaded on the container page.
Determines whether or not previews are showing for XBlocks
Click on the duplicate button for the given XBlock
Given an XBlock's usage locator as a string, return the WebElement for that block's wrapper div.
Given an XBlock's usage locator as a string, return one of its action buttons. action is 'edit', 'duplicate', or 'delete'
Gets name of library
Select a library from the library select box
Gets value of children count input
Sets value of scored select
Gets value of CAPA type select
Sets value of CAPA type select
Sets the select with given label (display name) to the specified value
Returns true iff the library content area has been loaded
Returns true iff the Loading indicator is not visible
Factory method: creates :class:`.StudioLibraryContainerXBlockWrapper` from :class:`.container.XBlockWrapper`
Get current visibility sate of all video controls. Returns: bool: True means video controls are visible for all videos, False means video controls are not visible for one or more videos
Click .setting-replace button after first hovering to it.
Click on a button as specified by `button_name` Arguments: button_name (str): button name index (int): query index
Construct file path to be uploaded to assets. Arguments: filename (str): asset filename
Upload a handout file to assets Arguments: handout_filename (str): handout file name
Clear handout from settings
Check if handout download button is visible
Tells the total number of video xblocks present on current unit page. Returns: (int): total video xblocks
Focus a caption line as specified by `line_number` Arguments: line_number (int): caption line number
Check if a caption line focused Arguments: line_number (int): caption line number
Return True if slider range is visible.
Get settings value of `field_name` Arguments: field_name (str): Name of field field_value (str): Name of value Returns: bool: If `field_name` has `field_value`
Get count of translations.
Replace a translation. Arguments: old_lang_code (str): new_lang_code (str): transcript_name (str):
Extract translations Returns: list: list of translation language codes
Remove a translation having `language_code` Arguments: language_code (str): language code
Get asset upload status message
Get video url field status/error message. Arguments: message_type(str): type(status, error) of message Returns: str: status/error message
$('{selector}') .prop('disabled', false) .removeClass('is-disabled') .val('') .trigger('input'); .format(selector=CLASS_SELECTORS['url_inputs'])
Revert a field.
Construct the URL.
Authenticate as staff so we can view and edit courses.
Record visiting the Justice course outline page
Record visiting a Justice unit page
Record visiting the PUB101 course outline page
Produce a HAR for loading the Coursware page.
Produce a HAR for loading the Dashboard page.
Produce a HAR for loading the Course Info page.
Error occurred while installing a edxnote fixture.
Error occurred while configuring the stub XQueue.
Configure a ConfigurationModel exposed at `api_base` to have the configuration `configuration`.
Log in as a staff user, then return the cookies for the session (as a dict) Raises a `ConfigModelFixtureError` if the login fails.
Default HTTP headers dict.
Error occurred while installing certificate config fixture.
Error occurred while updating certificate config fixture.
Error occurred while logging in to the Studio API.
Log in as a staff user, then return the cookies for the session (as a dict) Raises a `StudioApiLoginError` if the login fails.
Default HTTP headers dict.
Error occurred while installing a course or library fixture.
Add children XBlock to the container. Each item in `args` is an `XBlockFixtureDesc` object. Returns the fixture to allow chaining.
Recursively create XBlock children.
Encode `post_dict` (a dictionary) as UTF-8 encoded JSON.
Return a list of nested XBlocks for the container that can be filtered by category.
Return a list of nested XBlocks for the container.
Configure the XBlock to be created by the fixture. These arguments have the same meaning as in the Studio REST API: * `category` * `display_name` * `data` * `metadata` * `grader_type` * `publish`
Add child XBlocks to this XBlock. Each item in `args` is an `XBlockFixtureDesc` object. Returns the `xblock_desc` instance to allow chaining.
String representation of the course fixture, useful for debugging.
Add an update to the course.  `update` should be a `CourseUpdateDesc`.
Add the handout named `asset_name` to the course info page. Note that this does not actually *create* the static asset; it only links to it.
Add the asset to the list of assets to be uploaded when the install method is called.
Add textbook to the list of textbooks to be added when the install method is called.
Adds advanced settings to be set on the course when the install method is called.
Configure Course Settings, take new course settings from self._course_details dict object
Return the url string for the assets
Return the locator string for the course handouts
Error occurred while configuring the stub XQueue.
String representation of the library fixture, useful for debugging.
Create the library and XBlocks within the library. This is NOT an idempotent method; if the library already exists, this will raise a `FixtureError`.  You should use unique library identifiers to avoid conflicts between tests.
Get the LibraryLocator for this library, as a string.
Return the locator string for the LibraryRoot XBlock that is the root of the library hierarchy.
Push the data to the stub comments service.
return a dictionary with the fixture's data serialized for PUTting to the stub server's config endpoint.
Selects the cohort with the given name and verifies the expected description is presented.
Produce unique username and e-mail.
Refresh the page.
Verifies the changed topics.
Links a cohort to a content group. Saves the changes and verifies the cohort updated properly. Then refreshes the page and selects the cohort.
No cohorts are desired for this mixin.
Sets up the course to use cohorting with a single defined cohort.
Scenario: I can create new posts from the Discussion home page. Given that I am on the Discussion home page When I click on the 'New Post' button Then I should be shown the new post form
Test to check the default sorting preference of user. (Default = date )
Remove index file
Logout and login with given credentials.
Publish content in first section on studio course page.
Make sure that the page exists.
Create `num_topics` test topics.
Helper to assert that a single team card has the expected name and description.
Filter out all non-team events.
Scenario: teams tab should not be present if no team configuration is set Given I am enrolled in a course without team configuration When I view the course info page Then I should not see the Teams tab
Scenario: teams tab should not be present if team configuration does not specify topics Given I am enrolled in a course with no topics in the team configuration When I view the course info page Then I should not see the Teams tab
Verify that the page header correctly reflects the current topic's name and description.
Verify that the page header correctly reflects the current topic's name and description.
Verify that the page header correctly reflects the create team header, description and breadcrumb.
Scenario: The student should not see the edit team button. Given I am student for a course with a team When I visit the Team profile page Then I should not see the Edit Team button
Logout and login with given credentials.
Gets texts of all xblocks in library
Logout and login with given credentials.
SetUp method
Expected XBLock headers according to populate_library_fixture
Sets library content XBlock parameters, saves, publishes unit, goes to LMS unit page and gets children XBlock headers to assert against them
Perform a general validation of the course listings section
Logout and login with given credentials.
Make sure that the page is accessible.
Subclasses should override this to complete the fixture
Logout and login with given credentials.
Verify that all expected acid block tests pass in the lms.
Authenticate the user.
Parse url's querystring into a dict.
Checks that the page correctly redirects to a url with a denied query param.
Checks that 'code' appears in the browser's current url.
Open staff page with assertion
Filter out any events that are not "settings changed" events.
Filter out any events that are not "settings change initiated" events.
The absolute URL of the account settings page given the test context.
Assert no setting changed event has been emitted thus far.
Initialize account and pages.
Test behavior of a readonly field.
Test behaviour of "Username" field.
Test behaviour of "Language" field.
Test behaviour of "Country or Region" field.
Initialize the page object
Create a unique user
Filter out all non-enrollment events.
Verify that tooltips are displayed when you hover over the sequence nav bar.
set pre-requisite course
Assert that the 'closed for enrollment' text is present on the dashboard.
Navigate to the course info page, then check that we're on the dashboard page with the appropriate message.
Visits the instructor dashboard.
Scenario: Uploading a CSV with correct data results in Success. Given that I am on the Membership tab on the Instructor Dashboard When I select a csv file with correct data and click the Upload Button Then I should be shown a Success Notification.
Logout and login with given credentials.
Verifies that the correct event is emitted when a report is requested.
Verifies that the correct event is emitted when a report is downloaded.
Scenario: Verify that an instructor can download an ORA2 grade report Given that I am an instructor And I visit the instructor dashboard's "Data Downloads" tab And I click on the "Download ORA2 Responses" button Then a report should be generated
Scenario: On the Certificates tab of the Instructor Dashboard, Pending Instructor Tasks section is visible. Given that I am on the Certificates tab on the Instructor Dashboard Then I see 'Pending Instructor Tasks' section
Scenario: On the Certificates tab of the Instructor Dashboard, Certificate Exceptions section is visible. Given that I am on the Certificates tab on the Instructor Dashboard Then I see 'CERTIFICATE EXCEPTIONS' section
Log in as a valid lms user.
Log in as a valid lms user.
Logout and login with given credentials.
Open staff page with assertion
Make sure that the page is accessible.
Authenticate, enrolling the user in the configured course if requested.
Verify that no cards appear when the user has no enrollments.
Verify that cards appear when the user has enrollments which are included in at least one active program.
Create breadcrumb
Logout and login with given credentials.
Logout and login with given credentials.
Go to sequential tab and assert that we are on problem whose name is given as a parameter. Args: position: Position of the sequential tab problem_name: Name of the problem
Create a unique user and return the account's username and id.
Fill in the public profile fields of a user.
Verify that the profile page is currently private.
Scenario: Verify that a new user's profile defaults to public. Given that I am a new user. When I go to my profile page. Then I see that the profile visibility is set to public.
Assert that profile image has public access.
data=<p><span class="{}">Annotate this!</span></p>.format(self.selector)
data=<p><span class="{}">Annotate this!</span></p>.format(self.selector)
data=<p><span class="{}">Annotate this!</span></p>.format(self.selector)
Verifies the expected title and subsection titles (subtitles) for the given chapter.
Verifies the expected title and child notes for the given group.
Logout and login with given credentials.
Edit chapter name on studio course page under specified section
Reindex course content on studio course page
Login and search for specific content Arguments: search_term - term to be searched for Returns: (bool) True if search term is found in resulting content; False if not found
Make sure that the page is accessible.
Visits courseware_page and defines self.problem_page.
Waits for the expected status indicator. Args: status: one of ("correct", "incorrect", "unanswered)
Args: `correct` (bool): Inputs correct answer if True, else inputs incorrect answer.
Answer checkbox problem.
Answer multiple choice problem.
Answer radio problem.
Answer drop down problem.
Answer string problem.
Answer numerical problem.
Answer formula problem.
Overridden for script test because the testing grader always responds with "correct"
Overridden for script test because the testing grader always responds with "correct"
Overridden for script test because the testing grader always responds with "correct"
Selects the nth (where n == input_num) choice of the problem.
Fills the nth (where n == input_num) text input field of the problem with value.
Answer radio text problem.
Subclasses should override this to complete the fixture
Logout and login with given credentials.
Make sure that the page is accessible.
Verify emitted event data. Arguments: event_type: expected event type event_data: expected event data
Bookmark first `num_units` units Arguments: num_units(int): Number of units to bookmarks
Navigates and verifies the bookmarks list page.
Open annotation component page with assertion.
Load a file from the "data" directory as a string. `rel_path` is the path relative to the data directory.
Remove a file if it exists
Disable jQuery and CSS3 animations.
Enable jQuery and CSS3 animations.
Disable jQuery animations.
Enable jQuery animations.
Get the first select element that matches the query and select the desired value.
Get the first select element that matches the query and return its value.
Returns all the options for the given select.
Makes a CourseLocator from org, number and run
return true if given value is selected in html select element, else return false.
Return true if the given text is present in the list.
Returns instance of modal alert box shown in browser after waiting for 6 seconds
% {'selector': selector}return page.browser.execute_script(js_script) def is_404_page(browser):  Check if page is 404
Drop any events that have been collected thus far and start collecting again from scratch.
Gather any events that have been emitted since `start_time`
Return True if enough events have been emitted that pass the `event_filter` since `start_time`.
Return an aboslute URI given a relative path taking into account the test context.
Create a unique course ID.
Error occurred while configuring YouTube Stub Server.
Allow callers to get current stub server configuration. Returns: dict
Helper method to create user partition JSON. If scheme is not supplied, "random" is used.
Creates search index backing file
Visit the page courseware page containing the hinter
Video control events should contain valid ID fields and a valid "currentTime" field. This function asserts that those fields are present and have correct values.
Filter out anything other than the video events of interest
Wait 5 seconds and press "skip" button.
Wait 5 seconds and press "do not show again" button.
Wait until video will be in given state. Finished state means that video is played to the end.
Add video bumper to the course.
Create a course with unit and also upload handout Arguments: handout_filename (str): handout file name to be uploaded save_settings (bool): save settings or not
Scenario: Handout downloading works correctly w/o preliminary saving Given I have created a Video component with handout file "textbook.pdf" And I can download handout file in editor with mime type "application/pdf"
Scenario: Handout clearing works correctly w/o preliminary saving Given I have created a Video component with handout file "asset.html" And I clear handout And I save changes Then I do not see video button "handout"
Create a video component and navigate to unit page Arguments: subtitles (bool): Upload subtitles or not
Scenario: User can view Video metadata Given I have created a Video component And I edit the component Then I see the correct video settings and default values
Prepare the course and get to the video and render it
Prepare the course and get to the video unit however do not wait for it to render, because the has been an error.
Register for the course and navigate to the video unit
Wait for the video player to render
Wait for the video Xmodule but not for rendering
Navigate to sequential specified by `video_display_name`
Scenario: Transcript button is hidden if no translations Given the course has a Video component in "Youtube" mode Then the "Transcript" button is hidden
Scenario: returns True if the captions are visible, False is else
Create a video component and navigate to unit page Arguments: subtitles (bool): Upload subtitles or not subtitle_id (str): subtitle file id
Create a Studio Video Course Unit and Navigate to it. Arguments: youtube_stub_config (dict) subtitles (bool)
Install the course with required components and navigate to course unit page
Open component Edit Dialog for first component on page. Arguments: xblock_index: number starting from 1 (0th entry is the unit page itself)
Scenario: YouTube stub server can block YouTube API Given youtube stub server blocks YouTube API And I have created a Video component Then I do not see video button "play"
Scenario: Autoplay is disabled in Studio Given I have created a Video component Then when I view the video it does not have autoplay enabled
Scenario: Captions are hidden correctly Given I have created a Video component with subtitles And I have hidden captions Then when I view the video it does not show the captions
Scenario: Captions are shown correctly Given I have created a Video component with subtitles Then when I view the video it does show the captions
Scenario: When enter key is pressed on a caption, an outline shows around it Given I have created a Video component with subtitles And Make sure captions are opened Then I focus on first caption line And I see first caption line has focused
Make sure that all the pages are accessible. Rather than fire up the browser just to check each url, do them all sequentially in this testcase.
Make sure that you can get to the dashboard page without a course.
Test the "edit" button on a container appearing on the unit page.
Test the "edit" button on a container appearing on the container page.
Edit the visibility of an xblock on the container page.
Verify that we see validation errors for the given component.
Update a component's metadata and refresh the page.
Goes to the published version, then waits for the browser to load the page.
Verifies that the browser is on the staff page and returns a StaffPage.
Verifies no component is visible when viewing as a student.
Verifies expected components are visible when viewing as a student.
Verifies how the release date is displayed in the publishing sidebar.
Verifies that last published and last saved messages respectively contain the given strings.
The programs tab and "new program" button should not appear at all unless enabled via the config model.
Tear down method: remove search index backing file
Populate the children of the test course fixture.
Wraps xblock into :class:`...pages.studio.library.StudioLibraryContainerXBlockWrapper`
Scenario: I am able to export a course or library Given that I have a course or library And I click the download button The download will succeed And the file will be of the right MIME type.
Scenario: I should see the correct text when exporting a course. Given that I have a course to export from When I visit the export page The correct header should be shown
Ensure a library exists and navigate to the library edit page.
Scenario: I should see the correct text when exporting a library. Given that I have a library to export from When I visit the export page The correct header should be shown
Create a library with a bad component.
Generates the args for initializing a page object.
Scenario: When uploading a library or course, a link appears for me to view the changes. Given that I upload a library or course A button will appear that contains the URL to the library or course's main page
Scenario: I should be reprimanded for trying to upload something that isn't a .tar.gz file. Given that I select a file that is an .mp4 for upload An error message will appear
Scenario: I should see the correct text when importing a course. Given that I have a course to import to When I visit the import page The correct header should be shown
Default values for representing the published state of a unit
Creates a new UnitState with the given properties
Tests that released never published locked units display staff only warnings
Tests that released never published unlocked units display 'Unpublished units will not be released'
Tests that released unpublished changes locked units display staff only warnings
Tests that released unpublished changes unlocked units display 'Unpublished changes to live content'
Tests that released published locked units display staff only warnings
Tests that released published unlocked units display no warnings
Tests that unreleased never published locked units display staff only warnings
Tests that unreleased never published unlocked units display 'Unpublished units will not be released'
Tests that unreleased unpublished changes locked units display staff only warnings
Tests that unreleased unpublished changes unlocked units display 'Unpublished changes to content that will release in the future'
Tests that unreleased published locked units display staff only warnings
Tests that unreleased published unlocked units display no warnings
Verifies that all the descendants of item are staff only
Scenario: Only some subsections in section are explicitly locked, section should NOT display staff only warning Given I have a course with one section and two subsections When I enable explicit staff lock on one subsection Then the section does not show a staff lock warning
Changes the display name of item from old_name to new_name, then verifies that its value is expected_name.
Start with a completely empty course to easily test adding things to it
Verifies that all sections are collapsed if collapsed is True, otherwise all expanded.
Toggles the expand collapse state of all sections.
Scenario: The default layout for the outline page is to show sections in expanded view Given I have a course with sections When I navigate to the course outline page Then I see the "Collapse All Sections" link And all sections are expanded
Start with an empty course
Scenario: Expand/collapse for a course with no sections Given I have a course with no sections When I navigate to the course outline page Then I do not see the "Collapse All Sections" link
Start with an empty course
Returns first section, subsection, and unit on the page.
Add `block_types` into `Advanced Module List` Arguments: block_types (list): list of block types
Scenario: Verify that deprecation warning message is not shown if no deprecated advance modules are not present and also no deprecated component exist in course outline. When I goto course outline Then I don't see any deprecation warning
Opens Course Team page
Reload the page.
Compares to course dictionaries using org, number and run as keys
Asserts dialog with specified message is shown
Scenario: if split_test module is not present in Advanced Settings, content experiment parts of the Group Configurations page are not shown. Given I have a course with split_test module not enabled Then when I go to the Group Configurations page there are no content experiment sections
Get list of options of dropdown that is specified by selector on a given page.
Scenario: A message is displayed on the textbooks page when there are no uploaded textbooks Given that I am viewing the Textbooks page in Studio And I have not yet uploaded a textbook Then I see a message stating that I have not uploaded any textbooks
Ensure a library exists and navigate to the library edit page.
Ensure a library exists and navigate to the library edit page.
Create four pages worth of XBlocks, and offset by one so each is named after the number they should be in line by the user's perception.
Reload the page.
Create a course with a section, subsection, and unit to which to add the component.
Install a course with no content using a fixture.
Populate the children of the test course fixture.
Go to the test unit page. If make_draft is true, the unit page will be put into draft mode.
Populate the children of the test course fixture.
Login as global staff because that's the only way to rerun a course.
Return the "bad" HTML content that has been problematic for Studio.
Tests that bad HTML data within an HTML component doesn't prevent Studio from displaying the components on the unit page.
Test to make sure page has 'enable entrance exam' field.
Test that the 'instructor paced' button is checked by default.
Test that the self-paced option is persisted correctly.
Write method - just does nothing
No-op signal handler.
Org display names are not implemented. This just provides API compatibility with CourseDescriptor. Always returns the raw 'org' field from the key.
Display numbers are not implemented. This just provides API compatibility with CourseDescriptor. Always returns the raw 'library' field from the key.
Given some exception info, convert it into a string usingthe traceback.format_exception() function.
Copies the `Validation` object to a `StudioValidation` object. This is a shallow copy. Args: validation (Validation): A `Validation` object to be converted to a `StudioValidation` instance. Returns: StudioValidation: A `StudioValidation` instance populated with the messages from supplied `Validation` object
Create a `StudioValidation` instance. Args: xblock_id (object): An identification object that must support conversion to unicode.
Sets a summary message on this instance. The summary is optional. Args: message (ValidationMessage): A validation message to set as this instance's summary.
Is this object empty (contains no messages and no summary)? Returns: bool: True iff this instance has no validation issues and therefore has no messages or summary.
takes the data in separate chunks
appends the reference to the body
joins together the seperate chunks into one cohesive string
Retrieve the definition that a usage is derived from.Args: usage_id: The id of the usage to query Returns: The `definition_id` the usage is derived from
Retrieve the block_type of a particular definitionArgs: def_id: The id of the definition to query Returns: The `block_type` of the definition
Retrieve the XBlock `usage_id` associated with this aside usage id. Args: aside_id: The usage id of the XBlockAside. Returns: The `usage_id` of the usage the aside is commenting on.
Retrieve the XBlock `definition_id` associated with this aside definition id. Args: aside_id: The usage id of the XBlockAside. Returns: The `definition_id` of the usage the aside is commenting on.
Retrieve the XBlockAside `aside_type` associated with this aside usage id. Args: aside_id: The usage id of the XBlockAside. Returns: The `aside_type` of the aside.
Retrieve the XBlockAside `aside_type` associated with this aside definition id. Args: aside_id: The definition id of the XBlockAside. Returns: The `aside_type` of the aside.
Make a new aside definition and usage ids, indicating an :class:`.XBlockAside` of type `aside_type` commenting on an :class:`.XBlock` usage `usage_id` Returns: (aside_definition_id, aside_usage_id)
Make a usage, storing its definition id.Returns the newly-created usage id.
Make a definition, storing its block type.If `slug` is provided, it is a suggestion that the definition id incorporate the slug somehow. Returns the newly-created definition id.
Return the html used to display this snippet
Set up the XBlock -> XModule shim on the supplied :class:`xblock.fragment.Fragment`
Return the XBlock runtime (backwards compatibility alias provided for XModules).
Return a display name for the module: use display_name if defined in metadata, otherwise convert the url name.
Return the title for the sequence item containing this xmodule as its top level item.
This property hold the value _field_data here before we wrap it in the LmsFieldData or OverrideFieldData classes.
save connected asides
get the list of connected asides
:param source: The name of the attribute to proxy to :param name: The name of the attribute to proxy
Return a fragment with the html from this XModule Doesn't yet add any of the javascript to the fragment, nor the css. Also doesn't expect any javascript binding, yet. Makes no use of the context parameter
Get the key for a location in a policy file.  (Since the policy file is specific to a course, it doesn't need the full location url).
Return a fragment with the html from this XModuleDescriptor's editing view Doesn't yet add any of the javascript to the fragment, nor the css. Also doesn't expect any javascript binding, yet. Makes no use of the context parameter
See :meth:`xblock.runtime.Runtime.local_resource_url`.
See documentation for `xblock.runtime:Runtime.get_block`
Returns a subclass of :class:`.XBlock` that corresponds to the specified `block_type`.
See :meth:`xblock.runtime.Runtime:resource_url` for documentation.
process_xml: Takes an xml string, and returns a XModuleDescriptor created from that xml
Makes value into a UsageKey inside the specified course. If value is already a UsageKey, returns that.
provide uniform access to attributes (like etree).
provide uniform access to attributes (like etree)
The url prefix to be used by XModules to call into handle_ajax
If the ModuleSystem is set, delete the attribute from it. Always delete the attribute from the DescriptorSystem.
A duck-compatible object to use in ModuleSystem when there's no cache.
Given a course's usage locator, returns the course's URL name. Arguments: location (BlockUsageLocator): The course's usage locator.
Given a course's end datetime, returns whether (a) it is not None, and (b) the current time is past it. Arguments: end_date (datetime): The end datetime of the course in question.
Returns whether a course's start date hasn't yet been set. Arguments: start (datetime): The start datetime of the course in question. advertised_start (str): The advertised start date of the course in question.
Contains specific template information (the raw data body)
Module that provides a raw editing view of its data as XML. It does not perform any validation of its definition
Module which only provides an editing interface for the metadata, it does not expose a UI for editing the module data
Module that provides a raw editing view of its data as XML. It does not perform any validation of its definition
Save module with updated metadata to database."
Args: youtube_id: The ID of the video to create a link for Returns: A full youtube url to the video whose ID is passed in
Returns the request_cache from the runtime.
Returns the VAL data for the requested video profiles for the given course.
Save named content to store by location. Returns location of saved content.
Save transcripts into `StaticContent`. Args: `subs_id`: str, subtitles id `item`: video module instance `language`: two chars str ('uk'), language of translation of transcripts Returns: location of saved subtitles.
Remove from store, if transcripts content exists.
Helper method to parse out an HTML5 source into the ideas NOTE: This assumes that '/' are not in the filename
Generate proper filename for storage.
Get asset from contentstore, asset location is built from subs_id and lang. `location` is module location.
Return asset by location and filename.
Return asset location. `location` is module location.
Returns true if this course tab is enabled in the course.Args: course (CourseDescriptor): the course using the feature user (User): an optional user interacting with the course (defaults to None)
Akin to the get method on Python dictionary objects, gracefully returns the value associated with the given key, or the default if key does not exist.
Overrides the not equal operator as a partner to the equal operator.
Validates the given dict-type tab object to ensure it contains the expected keys. This method should be overridden by subclasses that require certain keys to be persisted in the tab.
Constructs a tab of the given type_name. Args: type_name (str) - the type of tab that should be constructed **kwargs - any other keyword arguments needed for constructing this tab Returns: an instance of the CourseTab subclass that matches the type_name
Serializes the necessary members of the CourseTab object to a json-serializable representation. This method is overridden by subclasses that have more members to serialize. Returns: a dictionary with keys for the properties of the CourseTab object.
Returns a url for a given course and reverse function.
Static tabs are viewable to everyone, even anonymous users.
Ensures that the specified tab_dict is valid.
Return a dictionary representation of this tab.
Look for a tab with the specified 'url_slug'.  Returns the tab or None if not found.
Look for a tab with the specified type.  Returns the first matching tab.
Look for a tab with the specified tab_id.  Returns the first matching tab.
Returns a function that takes in a course and reverse_url_func, and calls the reverse_url_func with the given reverse_name and course's ID. This is used to generate the url for a CourseTab without having access to Django's reverse function.
Return a fragment that contains the html for the student view
Filter template that contains 'latex' from templates. Show them only if use_latex_compiler is set to True in course settings.
`use_latex_compiler` should not be editable in the Studio settings editor.
Overriding defaults but otherwise treated as HtmlModule.
These pieces of course content are treated as HtmlModules but we need to overload where the templates are located in order to be able to create new ones
Supports the field overrides
These pieces of course content are treated as HtmlModules but we need to overload where the templates are located in order to be able to create new ones
Return a fragment that contains the html for the student view
Return the set of partitions assigned to self._course_id
Look for a user partition with a matching id in the course's partitions. Returns: A UserPartition, or None if not found.
Base Exception for when an error was found regarding user partitions.
Exception to be raised when looking up a UserPartition by its ID fails.
Exception to be raised when looking up a UserPartition Group by its ID fails.
'Serialize' to a json-serializable representation. Returns: a dictionary with keys for the properties of the group.
Returns the current group if set, else the first group from the specified user partition.
Unset the UserPartition.scheme_extensions cache.
Mock PartitionService for testing.
Helper method for getting preview view name (student_view or author_view) for a given module.
Helper mixin for supporting Studio editing of xmodules. This class is only intended to be used with an XModule Descriptor. This class assumes that the associated XModule will have an "author_view" method for returning an editable preview view of the module.
Returns the group ID, or None if none is available.
Returns true if the split_test instance is associated with a UserPartition.
Grading needs to know that only one of the children is actually "real".  This makes it use module.get_child_descriptors().
Returns the partition that this split module is currently using, or None if the currently selected partition ID does not match any of the defined partitions.
Returns true if the split_test instance is associated with a UserPartition.
Parse an optional metadata key containing a time or a string: if present, assume it's a string if it doesn't parse.
Convert a time struct or string to a string.
Returns True if the current time is after the specified course end date. Returns False if there is no end date specified.
Return whether it is acceptable to show the student a certificate download link.
Return whether the course is cohorted. Note: No longer used. See openedx.core.djangoapps.course_groups.models.CourseCohortSettings.
Return whether the course is auto-cohorted. Note: No longer used. See openedx.core.djangoapps.course_groups.models.CourseCohortSettings.
Return the list of groups to put students into.  Returns [] if not specified. Returns specified list even if is_cohorted and/or auto_cohort are false. Note: No longer used. See openedx.core.djangoapps.course_groups.models.CourseCohortSettings.
Return list of topic ids defined in course policy.
Can this XBlock type can have a score or children?
Return the course_id for this course
Returns the desired text corresponding the course's start date and time in UTC.  Prefers .advertised_start, then falls back to .start
Checks if the start date set for the course is still default, i.e. .start has not been modified, and .advertised_start has not been set.
Returns the end date or date_time for the course formatted as a string.
Return a display course number if it has been specified, otherwise return the 'course' that is in the location
Return a display organization if it has been specified, otherwise return the 'org' that is in the location
Returns whether the video pipeline advanced setting is configured for this course.
Returns a unique deterministic base32-encoded ID for the course. The optional padding_char parameter allows you to override the "=" character used for padding.
Returns whether or not teams has been enabled for this course. Currently, teams are considered enabled when at least one topic has been configured for the course.
Returns the max size for teams if teams has been configured, else None.
Returns the topics that have been configured for teams for this course, else None.
Retrieve all user partitions defined in the course for a particular partition scheme. Arguments: scheme (object): The user partition scheme. Returns: list of `UserPartition`
Whether or not the course can be set to self-paced at this time. Returns: bool: False if the course has already started, True otherwise.
Return a display organization if it has been specified, otherwise return the 'org' that is in the location
Returns the highest priority icon class.
Gather all fields which can't be edited.
Get the human-friendly name for a problem type.
Convenience method to get the library ID as a LibraryLocator and not just a string
Generator returning XBlock instances of the children selected for the current user.
Validates the state of this Library Content Module Instance.
Return only the subset of our children relevant to the current student.
Grab the library tools service or raise an error.
Helper method to only set validation summary if it's empty
Inform the runtime that our children vary per-user. See get_child_descriptors() above
Returns list of friendly titles for our selected children only; without thi, all possible children's titles would be seen in the sequence bar in the LMS. This overwrites the get_content_titles method included in x_module by default.
Removes <instructions> from the xmltree and returns them as a string, otherwise None.
Copied from django_comment_client/permissions.py because I can't import that file from here. It causes the xmodule_assets command to fail.
Return CourseDescriptor by course id.
The user id of the last user to change this xblock content, children, or settings.
The datetime of the last change to this xblock content, children, or settings.
The user id of the last user to change content, children, or settings in this xblock's subtree
The datetime of the last change content, children, or settings in this xblock's subtree
The user id of the last user to publish this specific xblock (or a previous version of it).
The datetime of the last time this specific xblock was published.
The datetime of the last change to this xblock content, children, or settings.
The datetime of the last change to this xblock content, children, or settings.
The user id of the last user to change content, children, or settings in this xblock's subtree
The datetime of the last change content, children, or settings in this xblock's subtree
The user id of the last user to publish this specific xblock (or a previous version of it).
Special List class for listing UserPartitions
Return a JSON-friendly dictionary that contains only non-inherited field keys, mapped to their serialized values
`inheritable_names` is a list of names that can be inherited from parents.
Create an InheritanceFieldData that inherits the names in InheritanceMixin.
Check to see if the default should be from inheritance. If not inheriting, this will raise KeyError which will cause the caller to use the field's global default.
Return the index for course_key.
Delete the course index from cache and the db
Change the given course's index entry. Note, this operation can be dangerous and break running courses. Does not return anything useful.
If there's an active bulk_operation, see if it's cached this module and just return it Don't do any extra work to get the ones which are not cached. Make the caller do the work & cache them.
The counterpart to :method `get_cached_block` which caches a block. Returns nothing.
Write operations which don't write from blocks must remove the target blocks from the cache. Returns nothing.
Update a definition, respecting the current bulk operation status (no data will be written to the database if a bulk operation is active.)
Find all structures that specified in `ids`. Filter the course blocks to only return whose `block_type` is `course` Arguments: ids (list): A list of structure ids
Closes any open connections to the underlying databases
Returns the wire version for mongo. Only used to unit tests which instrument the connection.
Find the descriptor cache for this course if it exists :param course_version_guid:
Save this cache for subsequent access :param course_version_guid: :param system:
Internal generator for fetching lists of courses without loading them.
Internal generator for fetching lists of courses, libraries, etc.
Creates course locator using course_info dict and branch
Creates library locator using library_info dict and branch
Extract course information from the course block for split.
Return a valid :class:`~opaque_keys.edx.keys.CourseKey` for this modulestore that matches the supplied `org`, `course`, and `run`. This key may represent a course that doesn't exist in this modulestore.
Return a valid :class:`~opaque_keys.edx.keys.UsageKey` for this modulestore that matches the supplied course_key.
Gets Course or Library by locator
Returns an enumeration-like type reflecting the type of this modulestore, per ModuleStoreEnum.Type. Args: course_key: just for signature compatibility
Saves or updates a single asset. Simply makes it a list and calls the list save above.
Remove the item if it was found
Given a structure, find block_key's parent in that structure. Note returns the encoded format for parent
Encodes the block key before retrieving it from the structure to ensure it can be a json dict key.
Encodes the block key before accessing it in the structure to ensure it can be a json dict key.
Return the list of courses which use this wiki_slug :param wiki_slug: the course wiki root slug :return: list of course keys
Check that the db is reachable.
Ensure that all appropriate indexes are created that are needed by this modulestore, or raise an exception if unable to. This method is intended for use by tests and administrative commands, and not to be run during server startup.
Add value to the list ensuring the list is long enough to accommodate it at the given index
See :py:meth: xmodule.modulestore.split_mongo.split.SplitMongoModuleStore.clone_course
Returns True if location exists in this ModuleStore.
Returns the item identified by usage_key and revision.
Returns a list of XModuleDescriptor instances for the matching items within the course with the given course_locator.
If a block was inherited into another structure using copy_from_template, this will return the original block usage locator from which the copy was inherited.
Fix any children which point to non-existent blocks in the course's published and draft branches
See :py:meth `xmodule.modulestore.split_mongo.split.SplitMongoModuleStore.get_course_history_info`
See :py:meth `xmodule.modulestore.split_mongo.split.SplitMongoModuleStore.get_course_successors`
See :py:meth `xmodule.modulestore.split_mongo.split.SplitMongoModuleStore.get_block_generations`
Returns whether this xblock has a published version (whether it's up to date or not).
Return the version of the given database representation of a block.
Split specific lookup
Simple placeholder for yet-to-be-fetched data :param modulestore: the pymongo db connection with the definitions :param definition_locator: the id of the record in the above to fetch
Return cache for an `alias` Note: The primary purpose of this is to mock the cache in test_split_modulestore.py
Return value rounded up to the nearest power of 2.
Record a measurement of the timed data. This would be something to indicate the size of the value being timed. Arguments: name: The name of the measurement. size (float): The size of the measurement.
Add tags to the timer. Arguments: **kwargs: Each keyword is treated as a tag name, and the value of the argument is the tag value.
Arguments: metric_base: The prefix to be used for all queries captured with this :class:`QueryTimer`.
Check that the db is reachable.
Create the course_index in the db
Closes any open connections to the underlying databases
Returns the wire version for mongo. Only used to unit tests which instrument the connection.
See :meth: cms.lib.xblock.runtime.EditInfoRuntimeMixin.get_edited_by
See :class: cms.lib.xblock.runtime.EditInfoRuntimeMixin
See :class: cms.lib.xblock.runtime.EditInfoRuntimeMixin
See :class: cms.lib.xblock.runtime.EditInfoRuntimeMixin
Turn the published version into a draft, removing the published version. Raises: InvalidVersionError if called on a DIRECT_ONLY_CATEGORY
Get the courselike locator key
Get the library locator for the current library key.
Get the library from the modulestore.
Add extra attributes to the root XML file.
Thin wrapper for the Course Export Manager. See ExportManager for details.
Thin wrapper for the Library Export Manager. See ExportManager for details.
Add row to table.
Output table HTML as string.
Add a header to the document.
Output HTML document as string.
50/50 chance
Locked or unlocked.
Fake user id.
Version string.
Make a number of fake AssetMetadata objects.
The various types of modulestores provided
Branch constants to use for stores, such as Mongo, that have only 2 branches: DRAFT and PUBLISHED Note: These values are taken from server configuration settings, so should not be changed without alerting DevOps
Branch constants to use for stores, such as Split, that have named branches
Values for sorting asset metadata.
Return whether this bulk write is active.
Record another level of nesting of this bulk write operation
Record the completion of a level of nesting of the bulk write operation
Return whether the bulk write is at the root (first) level of nesting
Add the expected vars to the thread.
Yield all active (CourseLocator, BulkOpsRecord) tuples.
Clear the record for this course
The outermost nested bulk_operation call: do the actual begin of the bulk operation. Implementing classes must override this method; otherwise, the bulk operations are a noop
The outermost nested bulk_operation call: do the actual end of the bulk operation. Implementing classes must override this method; otherwise, the bulk operations are a noop
Return whether a bulk operation is active on `course_key`.
Send a signal just before items are published in the course.
Sends out the signal that library have been updated.
Two EditInfo instances are equal iff their storable representations are equal.
Two EditInfo instances are not equal if they're not equal.
Just define this as not self.__eq__(block_data)
Thrown when calling find() on a SortedAssetList not sorted by filename.
Verifies that a modulestore supports a particular method. Some modulestores may differ based on the course_key, such as mixed (since it has to find the underlying modulestore), so it's required as part of the method signature.
Base method to over-ride in modulestore.
Base method to over-ride in modulestore.
Returns True if usage_key exists in this ModuleStore.
Returns a list of XModuleDescriptor instances for the items that match location. Any element of location that is None is treated as a wildcard that matches any value location: Something that can be passed to Location
Is this key set in fields? (return tuple of boolean and value). A helper which can handle fields either being the json doc or xblock fields. Is inner function to restrict use and to access local vars.
Return a valid :class:`~opaque_keys.edx.keys.CourseKey` for this modulestore that matches the supplied `org`, `course`, and `run`. This key may represent a course that doesn't exist in this modulestore.
Return a valid :class:`~opaque_keys.edx.keys.UsageKey` for this modulestore that matches the supplied course_key.
Get all of the xblocks in the given course which have no parents and are not of types which are usually orphaned. NOTE: may include xblocks which still have references via xblocks which don't use children to point to their dependents.
Return a dictionary of course_dir -> [(msg, exception_str)], for each course_dir where course loading failed.
Returns a type which identifies which modulestore is servicing the given course_id. The return can be either "xml" (for XML based courses) or "mongo" for MongoDB backed courses
Return the list of courses which use this wiki_slug :param wiki_slug: the course wiki root slug :return: list of course keys
Returns true if this xblock exists in the published course regardless of whether it's up to date
Closes any open connections to the underlying databases
A context manager for notifying the store of bulk operations. This affects only the current thread.
Ensure that all appropriate indexes are created that are needed by this modulestore, or raise an exception if unable to. This method is intended for use by tests and administrative commands, and not to be run during server startup.
Returns an empty dict. It is up to subclasses to extend this method if the concept of errored courses makes sense for their implementation.
See ModuleStoreRead.get_course Default impl--linear search through course list
Returns True since this is a read-only store.
Closes any open connections to the underlying databases
Helper method used to emit the course_deleted signal.
Helper method used to emit the item_deleted signal.
Only use entry_points that are supplied by the xmodule package
Prefer entry_points from the xmodule package
Cleans the item's location and sets the `is_draft` attribute if needed. Sets `item.is_draft` to `True` if the item is DRAFT, and `False` otherwise. Sets the item's location to the non-draft location in either case.
Returns True if this xblock has an existing published version regardless of whether the published version is up to date.
Raises an exception if the current branch setting does not match the expected branch setting.
Key Revision constants to use for Location and Usage Keys in the Mongo modulestore Note: These values are persisted in the database, so should not be changed without migrations
Raised to indicate that writing to a particular key in the KeyValueStore is disabled
Convert a single serialized UsageKey string in a ReferenceField into a UsageKey.
Returns the JSON payload of the xblock at location.
See :class: cms.lib.xblock.runtime.EditInfoRuntimeMixin
See :class: cms.lib.xblock.runtime.EditInfoRuntimeMixin
See :class: cms.lib.xblock.runtime.EditInfoRuntimeMixin
See :class: cms.lib.xblock.runtime.EditInfoRuntimeMixin
See :class: cms.lib.xblock.runtime.EditInfoRuntimeMixin
See :class: cms.lib.xblock.runtime.EditInfoRuntimeMixin
Returns the Location that is the draft for `location` If the location is in the DIRECT_ONLY_CATEGORIES, returns itself
Returns the Location that is the published version for `location`
Tracks whether there've been any writes per course and disables inheritance generation
Returns whether a bulk operation is in progress for the given course.
Closes any open connections to the underlying database
Returns the wire version for mongo. Only used to unit tests which instrument the connection.
Provides a reference to one of the two branch-specific ParentLocationCaches associated with the current request (if any).
Renames the '_id' field in item to 'location'
Returns a boolean whether a particular query should trigger an application of inherited metadata onto the item
Extract course information from the course block for mongo.
Return a valid :class:`~opaque_keys.edx.keys.CourseKey` for this modulestore that matches the supplied `org`, `course`, and `run`. This key may represent a course that doesn't exist in this modulestore.
Return a valid :class:`~opaque_keys.edx.keys.UsageKey` for this modulestore that matches the supplied course_key.
Returns True if location exists in this ModuleStore.
Generate the partial key to look up items relative to a given course
Simple implementation of overwriting any existing xblock
Recursively applies update to all the ancestors of location
Returns an enumeration-like type reflecting the type of this modulestore per ModuleStoreEnum.Type Args: course_key: just for signature compatibility
To instantiate a new xmodule which will be saved later, set up the dbModel and kvs
Given a asset type, form a key needed to update the proper embedded field in the Mongo doc.
Updates any special static items, such as PDF coursebooks.
Given a courselike_key, get the version of the key that will actually be used in the modulestore for import.
Given a key, a runtime, and an intended destination key, get the descriptor for the courselike we'll be importing into.
To be overloaded with a method that installs the child items into self.store.
To be overloaded with a method that installs the draft items into self.store.
Libraries have no special static items to import.
Imports all children into the desired store.
Imports all drafts into the desired store.
Thin wrapper for the Course Import Manager. See ImportManager for details.
Thin wrapper for the Library Import Manager. See ImportManager for details.
Convert a reference to the new namespace, but only if the original namespace matched the original course. Otherwise, returns the input value.
Does this look like something that came from fallback_name()?
Return the XBlock for the specified location
Retrieve the definition that a usage is derived from.Args: usage_id: The id of the usage to query Returns: The `definition_id` the usage is derived from
Grab the course ID from the descriptor
Return the policy dictionary to be applied to the specified XBlock usage
Returns True if location exists in this ModuleStore.
Return a valid :class:`~opaque_keys.edx.locator.CourseLocator` for this modulestore that matches the supplied `org`, `course`, and `run`. This key may represent a course that doesn't exist in this modulestore.
Return a valid :class:`~opaque_keys.edx.keys.UsageKey` for this modulestore that matches the supplied course_key.
Returns a list of course descriptors.  If there were errors on loading, some of these may be ErrorDescriptors instead.
Returns `self.get_courses()`. Use to list courses to the global staff user.
Return a dictionary of course_dir -> [(msg, exception_str)], for each course_dir where course loading failed.
Return the list of courses which use this wiki_slug :param wiki_slug: the course wiki root slug :return: list of course locations
Ensure that every known course is loaded and ready to go. Really, just return b/c if this gets called the __init__ finished which means the courses are loaded. Returns the course count
A context manager for temporarily setting the branch value for the store to the given branch_setting.
For now this is not implemented, but others should feel free to implement using the asset.json which export produces.
For now this is not implemented, but others should feel free to implement using the asset.json which export produces.
For now this is not implemented, but others should feel free to implement using the asset.json which export produces.
A no-op. Added to simplify tests which use the XML-store directly.
Create a LibraryLocator given an org and library. url_name is ignored, but left in for compatibility with the parent signature.
Get a library from this modulestore or return None if it does not exist.
Get the Library Key from the Library descriptor.
Raise this exception when Iterating over the course blocks return multiple course blocks.
An incorrect pointer to an object exists. For example, 2 parents point to the same child, an xblock points to a nonexistent child (which probably raises ItemNotFoundError instead depending on context).
Print info about what's duplicated
The caller asked for either draft or published head and gave a version which conflicted with it.
existing_entry will have the who, when, and other properties of the existing entry
Test the has_course method
Test xblock aside class
Verify that every `course_summary` object has all the required fields
Return True if ``block_type`` is a detached block.
Tests whether the fields in the given store_settings are equal.
Get the course key for the given course string
initializes the mixed modulestore.
Add to the student view
Add to the student view
Verifies the results of calling get_parent_locations matches expected_results.
Test calling revert_to_published on vertical with no published version errors.
Asserts the number of problems with the given display name is the given expected number.
Check if the signal has been fired. The course_published signal fires before the _clear_bulk_ops_record.
Set up the database for testing
Export the course from a modulestore and then re-import the course.
Enable XModuleFactories. This should only be turned in a context where the modulestore will be reset at the end of the test (such as inside ModuleStoreTestCase).
Disable XModuleFactories. This should be called once the data from the factory has been cleaned up.
Return whether XModuleFactories are enabled.
Recursively creates a sub_tree on this parent_loc with this block.
Instruments the given method on the given object to verify the number of calls to the method is exactly equal to 'num_calls'.
Instruments the given method on the given object to verify the number of calls to the method is less than or equal to the expected maximum_calls and greater than or equal to the expected minimum_calls.
Return the total number of stacks recorded.
Return the number of calls to the supplied ``stack``.
Iterate over all unique captured stacks.
Return the set of captured calls with the supplied stack.
Add thumbnail to the asset_md
Check asset type/path values.
Add to the student view
Test get_library() with non-existent key
Result is a collection of descriptors. Find the one whose block id matches the _id.
Helper function to get a structure from a course.
children: list of descriptors Returns the `children` list with each member version-agnostic
Load the given engine
Add cleanups
Load the given engine
Gets fields that are explicitly set on block and checks if they are marked as explicitly set or not
Test xblock type to test the reference field types
No asset collection.
No asset collection - it's not used in the tests below.
Test that has_course() returns False when called with a LibraryLocator. This is required because MixedModuleStore will use has_course() to check where a given library are stored.
No asset collection.
Test that operations on with a closed transaction aren't affected by a previously executed transaction
This will return a new instance of a modulestore given an engine and options
Mocks out the CourseTab.from_json to just return the tab_dict itself so that we don't have to deal with plugin errors.
Get the UsageKey of this block.
Set the UsageKey of this block.
Get a key from the cache. Args: key: The key to update. default: The value to return if the key hasn't been set previously.
Set a key in the cache. Args: key: The key to update. value: The value change the key to.
Build both the contentstore and the modulestore.
A contextmanager that returns an isolated xml modulestore Args: contentstore: The contentstore that this modulestore should use to store all of its assets.
Args: store_builders: A list of modulestore builder objects. These will be instantiated, in order, as the backing stores for the MixedModuleStore. mappings: Any course mappings to pass to the MixedModuleStore on instantiation.
Given a block_type/num, return a block id.
Add a single entry for the course DB referenced by the tests below.
Method to ensure a course export - defined by subclass.
Return the path to the block type subdirectory, factoring in drafts.
Return the course export filename for a block.
Assert than an XML element has a specific tag. Arguments: element (ElementTree.Element): the element to check. tag (str): The tag to validate.
Check that all blocks in the list are only draft blocks in the OLX format when the course is exported.
Check that all blocks in the list are only published blocks in the OLX format when the course is exported.
Check that all blocks in the list are both draft and published in the OLX format when the course is exported.
Check that all blocks in the list are no longer in the OLX format when the course is exported.
Create a temporary export dir - and clean it up when done.
``True`` when modulestore under test is a SplitMongoModuleStore.
``True`` when modulestore under test is a MongoModuleStore.
Make a unique name for the new export dir.
Based on the expected result, verify that OLX for the listed blocks is correct.
Enumeration of store constructor types.
Start modulestore isolation, and then load modulestore specific test data.
Helper for accessing stores in a configuration setting for the Mixed modulestore.
For now saves the usage key in the deprecated location i4x/c4x form
Supported kwargs: asides - list with connected asides data for the passed block
In order for mapping to work, the locator must be minimal--no version, no branch-- as we never store one version or one branch in one ms and another in another ms. :param locator: the CourseKey
This method should only really be used by tests and migration scripts when necessary. Returns the module store as requested by type.  The type can be a value from ModuleStoreEnum.Type.
Some course_keys are used without runs. This function calls the corresponding fill_in_run function on the appropriate modulestore.
Does the course include the xblock who's id is reference?
see parent doc
Return a valid :class:`~opaque_keys.edx.keys.UsageKey` for the modulestore that matches the supplied course_key.
returns the course module associated with the course_id. If no such course exists, it returns None :param course_key: must be a CourseKey
See xmodule.modulestore.__init__.ModuleStoreWrite.delete_course
Find the metadata for a particular course asset. Args: asset_key (AssetKey): locator containing original asset filename Returns: asset metadata (AssetMetadata) -or- None if not found
Deletes a single asset's metadata. Arguments: asset_id (AssetKey): locator containing original asset filename user_id (int_long): user deleting the metadata Returns: Number of asset metadata entries deleted (0 or 1)
returns the parent locations for a given location
If a block was inherited into another structure using copy_from_template, this will return the original block usage locator from which the copy was inherited.
Returns a type which identifies which modulestore is servicing the given course_id. The return can be one of: "xml" (for XML based courses), "mongo" for old-style MongoDB backed courses, "split" for new-style split MongoDB backed courses.
Get all of the xblocks in the given course which have no parents and are not of types which are usually orphaned. NOTE: may include xblocks which still have references via xblocks which don't use children to point to their dependents.
Return a dictionary of course_dir -> [(msg, exception_str)], for each course_dir where course loading failed.
See :py:meth `ModuleStoreDraftAndPublished.import_xblock` Defer to the course's modulestore if it supports this method
See :py:meth `SplitMongoModuleStore.copy_from_template`
Update the xblock persisted to be the same as the given for all types of fields (content, children, and metadata) attribute the change to the given user.
Delete the given item from persistence. kwargs allow modulestore specific parameters.
Close all db connections
Return the list of courses which use this wiki_slug :param wiki_slug: the course wiki root slug :return: list of course keys
Save a current draft to the underlying modulestore Returns the newly published item.
Save a current draft to the underlying modulestore Returns the newly unpublished item.
Create a copy of the source and mark its revision as draft. Note: This method is to support the Mongo Modulestore and may be deprecated. :param location: the location of the source (its revision must be None)
Checks if the given block has unpublished changes :param xblock: the block to check :return: True if the draft and published versions differ
Verifies that the modulestore for a particular course supports a feature. Returns True/false based on this.
Finds and returns the store that contains the course for the given location, and verifying that the store supports the given method. Raises NotImplementedError if the found store does not support the given method.
A context manager for temporarily setting the branch value for the given course' store to the given branch_setting.  If course_id is None, the default store is used.
A context manager for notifying the store of bulk operations. If course_id is None, the default store is used.
Write all registered XModule css, sass, and scss files to output root.
Write all registered XModule js and coffee files to output root.
Write all registered XModuleDescriptor css, sass, and scss files to output root.
Write all registered XModuleDescriptor js and coffee files to output root.
Return a list of all registered XModuleDescriptor classes.
Return a list of all registered XModule classes.
Ensure that `directory` exists.
module_styles_lines.append({selector}.xmodule_{class_} {{.format(
Convert a location name for use in a path: replace ':' with '/'. This allows users of the xml format to organize content into directories
Return a string version of the value (where value is the JSON-formatted, internally stored value). If the value is a string, then we simply return what was passed in. Otherwise, we return json.dumps on the input value.
Extract the metadata from the XML.
Return the definition to be passed to the newly created descriptor during from_xml xml_object: An etree Element
Remove any attribute named for a field with scope Scope.settings from the supplied xml_object
Used when this module wants to parse a file object to xml that will be converted to the definition. Returns an lxml Element
If this returns True, write the definition of this descriptor to a separatefile. NOTE: Do not override this without a good reason.  It is here specifically for customtag...
Return a new etree Element object created from this modules definition.
Set the attributes on the metadata. Any which are not in ATTRS_ALLOWED_TO_UPDATE get put into fields. Arguments: attr_dict: Prop, val dictionary of all attributes to set.
Take a list of AssetMetadata objects. Add them all to the node. The node should already be created as a top-level "assets" element.
Params: course_id: Course ID for which the asset metadata is stored. doc_id: ObjectId of MongoDB document asset_md: Dict with asset types as keys and lists of storable asset metadata as values.
Returns the ID associated with the MongoDB document which stores these course assets.
Provides dict-equivalent setdefault functionality.
Provides dict-equivalent get functionality.
Base exception class for all exceptions related to assets.
Thrown when no asset metadata is present in the course modulestore for the particular asset requested.
TEMPORARY: Thrown if asset metadata is actually found in the course modulestore.
Ensure full asset sections with the wrong tag are detected.
Parse xml_element 'sources' attr and return a list of location strings.
Define a field to store how to randomize a problem.
Set the module's last submission time (when the problem was checked)
Access the problem's score
Access the problem's max score
Hint button handler, returns new html using hint_index from the client.
Is it now past this problem's due date, including grace period?
Is the student still allowed to submit answers?
Has the problem been attempted? used by conditional module
True iff full points
Return results of get_problem_html, as a simple dict for json-ing. { 'html': <the-html> } Used if we want to reconfirm we have the right thing e.g. after several AJAX calls.
Renders parameters to template.
This is called to get context with new oauth params to iframe.
Return course by course id.
Return context_id. context_id is an opaque identifier that uniquely identifies the context (e.g., a course) that contains the link being launched.
Tried to save an item with a location that a store cannot support (e.g., draft version for a non-leaf node)
Thrown when a module cannot be exported to XML
Tried to access an xmodule field which needs a different context (runtime) to have a value.
Return descriptor of selected choice
Return module instance of selected choice
For grading--return just the chosen child.
XBlock fields used by the ErrorModules
Normalizes library key for use with search indexing
Given a library key like "library-v1:ProblemX+PR0B", return the 'library' XBlock with meta-information about the library. A specific version may be specified. Returns None on error.
Filters children by CAPA problem type, if configured
Determines whether a modulestore holding a course_id supports libraries.
Accepts the same arguments as xmodule.x_module:XModule.__init__
Renders the Studio preview view.
Filter template that contains 'latex' from templates. Show them only if use_latex_compiler is set to True in course settings.
Mixin to use for XModule descriptors.
Since we are running outside of Django assert that get_current_request returns None
Fetches the body of a request specified by params
Mock function for returning fully-qualified handler urls
Test if OAuth signing was successful.
Test wrong XML Namespace. Tests that tool provider returned grade back with wrong XML Namespace.
Oauth signing verify fail.
Implements abstract method for getting the current user.
Returns the rendered student view for the given sequence and the requested_child parameter.
Verifies that the rendered view contains the expected position.
An exception type to use to verify raises in tests
Test that when an XModule throws an error during __init__, we get an ErrorModule back from XModuleDescriptor._xmodule
Test that a broken error descriptor doesn't cause an infinite loop
Test that `set_summary` errors if argument is not a ValidationMessage.
Helper function to create empty CAPA problem definition
Helper function to create a set of capa problems to test against. Creates four blocks total.
Test the settings that are marked as "non-editable".
Sets up search engine mock
XBlock for testing pure xblock xml import
Dummy implementation of gettext, so we don't need Django.
Custom hacky repr. XBlock.Runtime.render() replaces the _view_name attribute while rendering, which causes rendered comparisons of blocks to fail as unequal. So make the _view_name attribute None during the base repr - and set it back to original value afterward.
Pretty-print the args and kwargs. Allows us to not depend on any actual template rendering mechanism, while still returning a unicode object
Call Xmodule.handle_ajax.
Record ``formatted_exc`` in the set of exceptions captured by this assertion manager.
Raise a BulkAssertionError containing all of the captured AssertionErrors, if there were any.
A context manager that will capture all assertion failures made by self.assert* methods within its context, and raise a single combined assertion error at the end of the context.
Wrap all assert* methods of this class using self._wrap_assertion, to capture all assertion errors in bulk.
Mark field ``field_name`` of expected block usage ``usage_id`` as ignored Args: usage_id (:class:`opaque_keys.edx.UsageKey` or ``None``). If ``None``, skip, this field in all blocks field_name (string): The name of the field to skip
Add an asset key to the list of keys to be ignored when comparing assets. Args: key_name: The name of the key to ignore.
Compare block fields to check for equivalence.
Return the stringified version of the generated xml
An :class:`xml.etree.Element`
Return the policy data for the specified usage
Return the descriptor loaded for `location`
Run the supplied tuple of (assertion, *args) as a method on this class.
Factory for generating SplitTestModules for testing purposes
Test the settings that are marked as "non-editable".
Return the input key to use when passing GET parameters
Check that if the weight is 0 get_progress does not try to create a Progress object.
Check that get_html() calls get_progress() with no arguments.
Creates a CapaDescriptor to run test against
A factory for creating a Capa problem with arbitrary xml.
Return the next cls number
Return the input key to use when passing GET parameters
Call function under test.
Test no due date.
Test due date without extension.
Test due date with extension.
Test due date with extension, but due date is later than extension.
Test non-sensical extension without due date.
Mock ValVideoNotFoundError exception
Mock ValCannotCreateError exception
Make sure that inconsistent speed keys are parsed correctly.
Extract the list of tag names for children of elem
Assert that `video` has the correct attributes. `attrs` is a map of {metadata_field: value}.
Mock edxval.api.export_to_xml
Test XML export will raise TypeError by lxml library if contains illegal characters.
Add a team configuration to the course.
Initialize dummy testing course.
Test CourseDescriptor.clean_id.
Test CourseDescriptor.has_started.
Asserts that the html generated by the `student_view` view is correct for the supplied block :param block: The :class:`XBlock` that generated the html :param html: The generated html as parsed by lxml.html
Asserts that the html generated by the `studio_view` view is correct for the supplied block :param block: The :class:`XBlock` that generated the html :param html: The generated html as parsed by lxml.html
Asserts that the html generated by the `student_view` view is correct for the supplied block, given that html wasn't parsable :param block: The :class:`XBlock` that generated the html :param html: A string, not parseable as html
Asserts that the html generated by the `studio_view` view is correct for the supplied block :param block: The :class:`XBlock` that generated the html :param html: A string, not parseable as html
Helper function to assert that the `fragment` is valid output the specified `block`s `student_view`
Derives from the class under test for testing purposes. Since `ResourceTemplates` is intended to be used as a mixin, we need to derive a class from it in order to fill in some data it's expecting to find in its mro.
Like TestClass, but `get_template_dir` returns a directory that doesn't exist. See `TestClass`.
Just make sure descriptor loads without error
Test CourseDescriptor.has_started.
Class for testing pure XBlocks.
A timezone with non-None utcoffset
A timezone with None as its utcoffset
Flatten a dict from cls -> [fields, ...] and yields values of the form (cls, fields) for each entry in the dictionary value.
See documentation from :meth:`factory.Factory._build`
See documentation from :meth:`factory.Factory._build`
Update the position attribute of the generated ModuleRuntime.
Update the position attribute of the generated ModuleRuntime.
Set the xmodule_runtime to make this XModuleDescriptor usable as an XModule.
Factory to generate XModuleDescriptors that are containers.
Assert that both student_view and get_html render the same.
Assert that studio_view and get_html render the same.
Input with bad content type
Test the error cases for the "dispatch" argument to the LTI 2.0 handler.  Anything that doesn't fit the form user/<anon_id>
Test the good cases for the "dispatch" argument to the LTI 2.0 handler.  Anything that does fit the form user/<anon_id>
Test that bad json_str to parse_lti_2_0_result_json inputs raise appropriate LTI Error
Test that we get a 404 when there's no (or badly formatted) user specified in the url
An XBlock we can use in these tests.
Asserts the result of deserialize_field.
A class with location and content_type members
Set the cursor at "position"
Read "chunk_size" bytes of data at position cursor and move the cursor
Test-only implementation of load_item that simply returns static xblocks.
Dummy Xblock class
Test that given None throws value error
Test if settings service returns correct bucket
Alias the is_proctored_enabled field to the more legible is_proctored_exam
Alias the is_proctored_enabled field to the more legible is_proctored_exam
The usage keys for all descendants of an XBlock/XModule as a flat list. Includes the location of the node passed in.
`is_entrance_exam` should not be editable in the Studio settings editor.
Error class for LTIModule and LTI20ModuleMixin
Clears the module user state, including grades and comments, and also scoring in db's courseware_studentmodule Arguments: user (django.contrib.auth.models.User):  Actual user whose module state is to be cleared Returns: nothing
Ensure that when set explicitly the Field is set to a timedelta
Check value for possible `True` value.Using this function we can manage different type of Boolean value in xml files.
Convert raw word to suitable word.
Return top words from all words, filtered by number ofoccurences :param dict_obj: all words :type dict_obj: dict :param amount: number of words to be in top dict :type amount: int :rtype: dict
Returns a boolean if a path is believed to be a c4x link based on the leading element
Delete all of the assets which use this course_key as an identifier :param course_key:
Copy all the course assets from source_course_key to dest_course_key
Closes any open connections to the underlying databases
Get the value of attr set on location. If attr is unset, it returns default. Unlike set, this accessor does allow getting the value of reserved keywords. :param location: a c4x asset location
Load a function by name. path is a string of the form "path.to.module.function" returns the imported python object `function` from `path.to.module`
Removes <instructions> from the xmltree and returns them as a string, otherwise None.
Removes <instructions> from the xmltree and returns them as a string, otherwise None.
my dot product
Check if formula is in mathml presentation format.
Check if formula is in mathml format.
Indicate when a student inputs a variable which was not expected.
Like float, but with SI extensions. 1k goes to 1000.
Create a float out of its string parts. e.g. [ '7.13', 'e', '3' ] ->  7130 Calls super_float above.
When a variable is recognized, store it in `variables_used`.
When a function is recognized, store it in `functions_used`.
Secant
Cosecant
Inverse secant
Inverse cosecant
Hyperbolic secant
Hyperbolic cosecant
Inverse hyperbolic secant
Inverse hyperbolic cosecant
Properly handle parens, otherwise this is trivial.
Test that things like '4.' will be 4 and not throw an error
Test case insensitive evaluation Normal functions with some capitals should be fine
Test curvy parens.
Test brackets.
Test curly braces.
Test curvy parens with the tall parameter.
Test brackets, also tall.
Test tall curly braces.
Check that we get an error with invalid parens.
Simple numbers should pass through.
Suffixes should be escaped.
Simple valid variables should pass through.
Variable names that are greek should be formatted accordingly.
Things like 'epsilon_max' should display nicely
Valid function names should be escaped.
r Functions surrounding a tall element should have \left, \right
Sqrt function should be handled specially.
log10 function should be handled specially.
log2 function should be handled specially.
Powers should wrap the elements with braces correctly.
Powers should ignore the parenthesis of the last math.
r Parallel items should combine with '\|'.
r Simple products should combine with a '\cdot'.
Division should combine with '\frac'.
Division should ignore parens if they are extraneous.
Complex products/quotients should split into many '\frac's when needed.
A complicated expression should not hide the tallness.
Get a list of all the tags that have been registered.
Reset internal state to unfinished, with no answers
Return the maximum score for this problem.
Returns True if any part of the problem has been submitted to an external queue (e.g. for grading.)
Rescore student responses.  Called by capa_module.rescore_problem.
Return the IDs of all the responses -- these are the keys used for the dicts returned by grade_answers and get_question_answers. (Though get_question_answers may only return a subset of these.
Main method called externally to get the HTML to be rendered for this capa Problem.
Display the text for this problem
Error in specification of a problem
Error for failure in processing a response, including exceptions that occur when executing a custom script.
Error for an invalid student input. For example, submitting a string when the problem expects a number
Return the total maximum points of all answer fields under this Response
Called by capa_problem.LoncapaProblem to evaluate student answers, and to generate hints (if any). Returns the new CorrectMap, with (correctness,msg,hint,hintmode) for each answer_id.
Pull "extended hint" information out the xml based on the student answers, installing it in the new_map for display. Implemented by subclasses that have extended hints.
Return a CorrectMap for the answers expected vs given.  This includes (correctness, npoints, msg) for each answer_id. Arguments: - student_answers : dict of (answer_id, answer) where answer = student input (string)
Return a dict of (answer_id, answer_text) for each answer for this question.
True if the response has masking.
True if the response has a shuffle transformation.
True if the response has an answer-pool transformation.
Rearrangements run late in the __init__ process. Cannot do these at response init time, as not enough other stuff exists at that time.
Outside-facing function that lets us compare two numerical answers, with this problem's tolerance.
Returns whether this answer is in a valid form.
The course author can specify an initial display to be displayed the code response box.
An external interface for comparing whether a and b are equal.
Returns whether this answer is in a valid form.
Returns a dict of the max points for each input: input id -> maxpoints.
Returns the option with the given choice value, otherwise None.
Return the single option that was selected, otherwise None.
Returns a dictionary containing the names of binary choices as keys and a string of answers to any numtolerance_inputs which they may have e.g {choice_1bc : "answer1, answer2", choice_2bc : ""}
Compares student submitted checkbox/radiobutton answers against the correct answers. Returns True or False. True if all of the correct choices are selected and no incorrect choices are selected.
Generate a string key by hashing
Duck typing to check if 'file_to_test' is a File object
return dict version of self
Takes an answer_id Returns true if the problem is correct OR partially correct.
Takes an answer_id Returns true if the problem is partially correct.
Error occurred while rendering a Mako template.
Asserts that the xml tree does NOT have an element satisfying `xpath`. `xml_root` is an etree XML element `xpath` is an XPath string, such as `'/foo/bar'` `context` is used to print a debugging message
A test version of render to template.  Renders to the repr of the context, completely ignoring the template name.  To make the output valid xml, quotes the content, and wraps it in a <div>
Construct a `LoncapaProblem` suitable for unit tests.
Take list of options, confirm that output is in the silly doubled format
<matlabinput id="prob_1_2"rows="{r}" cols="{c}" tabsize="{tabsize}" mode="{m}" linenumbers="{ln}"> <plot_payload> {payload} </plot_payload> </matlabinput>.format(r=self.rows,
xml_str = <chemicalequationinput id="prob_1_2" size="{size}"/>.format(size=self.size)
With a bad dispatch, we shouldn't receive anything
xml_str = <formulaequationinput id="prob_1_2" size="{size}"/>.format(size=self.size)
With a bad dispatch, we shouldn't receive anything
Test that a properly formatted radiotextgroup problem generates expected ouputs
Test that a properly formatted checkboxtextgroup problem generates expected ouput
Test to ensure that an unrecognized inputtype tag causes an error
Test to ensure having a tag other than <choice> inside of a checkbox or radiotextgroup problem raises an error.
Test stringifing Status objects
Returns code to be used to generate a random result.
Create queuestate dict
Test that staff may enter in an expression as the answer.
Test that staff may enter in a complex number as the answer.
Return the 'translation' of `text`.
Look up the given response for `math_string`.
Raise an error only for the student input.
Convenience method to fill in default values for script and type if needed, then call self.build_problem
Test that build problem raises errors for invalid options
Given an xml element corresponding to the output of test_capa_system.render_template, get back the original context
xml_str = <math>{tex}</math>.format(tex=latex_in)
Subclasses override to return an etree elementrepresenting the capa response XML (e.g. <numericalresponse>). The tree should NOT contain any input elements (such as <textline />) as these will be added later.
Create the <schematic> XML element.Although <schematic> can have several attributes, (*height*, *width*, *parts*, *analyses*, *submit_analysis*, and *initial_value*), none of them are used in the capa module. For testing, we create a bare-bones version of <schematic>.
Create a <choiceresponse> element
Create a <checkboxgroup> element.
Create the <imageresponse> element.
Create the <javascriptinput> element
Create the <multiplechoiceresponse> element
Create the <choicegroup> element
Create the <truefalseresponse> element
Create the <choicegroup> element
Create the <optionresponse> element
Create a <annotationresponse> element
Create a <choicetextresponse> element
Return the md5 hash that `update_hash` makes us.
Should return a list of Attribute objects (see docstring there for details). Subclasses should override.  e.g. return [Attribute('unicorn', True), Attribute('num_dragons', 12, transform=int), ...]
Subclasses can override this to return extra context that should be passed to their templates for rendering. This is useful when the input type requires computing new template variables from the parsed attributes.
Convert options to a convenient format.
Register the attributes.
Given a string like 'a.py b.py c.out', split on whitespace and return as a json list.
Defined queue_len, add it
Return whether or not we want the 'Test Code' button visibleRight now, we only want this button to show up when a problem has not been checked.
Note: src, height, and width are all required.
Note: height, width, molecules and geometries are required.
Can set size of text field.
Since we only have chemcalc preview this input, check to see if it matches the corresponding dispatch and send it through if it does
Since we only have formcalc preview this input, check to see if it matches the corresponding dispatch and send it through if it does
Can set size of text field.
Note: width, hight, and target_shape are required.
Note: width, height, and dna_sequencee are required.
Returns a dictionary of extra content necessary for rendering this InputType. `input_type` is either 'radio' or 'checkbox' indicating whether the choices for this problem will have radiobuttons or checkboxes.
Logging function for tests
Returns least common multiple of a, b Args: a, b: floats Returns: float
Render a chemical expression--no arrows.
Wrapper around dog_stats_api.increment that cleans any tags used.
Wrapper around dog_stats_api.histogram that cleans any tags used.
Setup.py for safe_lxml.
Monkey patch and defuse all stdlib xml packages and lxml.
A safer version of XMLParser which by default disables entity resolution.
Return user by anonymous_user_id using AnonymousUserId lookup table. Do not raise `django.ObjectDoesNotExist` exception, if there is no user for anonymous_student_id, because this function will be used inside xmodule w/o django access.
Convenience method that returns a boolean indicating whether or not this user has uploaded a profile image.
Convenience method that returns the age given a year_of_birth.
Convenience method that returns the human readable level of education.
Get the human readable value from an enumerable list of key-value pairs.
Return cache key name to be used to cache current country.Args: user_id(int): Id of user. Returns: Unicode cache key
Capture old fields on the user instance before save and cache them as a private field on the current model for use in the post_save callback.
This table contains information about users registering via Micro-Sites
Request a change to a user's email.Implicitly saves the pending email change record. Arguments: email (unicode): The proposed new email for the user. Returns: unicode: The activation code to confirm the change.
Returns whether the configuration which limits password reuse has been turned on
Returns whether the configuration which limits password reuse has been turned on
Returns whether the configuration which limits the password reset frequency has been turned on
Returns whether the configuration which forces password resets to occur has been turned on
Returns whether the configuration which forces password resets to occur has been turned on
Gets a user's record, and fixes any duplicates that may have arisen due to get_or_create race conditions. See https://code.djangoproject.com/ticket/13906 for details. Use this method in place of `LoginFailures.objects.get(user=user)`
Returns whether the feature flag around this functionality has been set
Removes the lockout counters (normally called after a successful login)
Returns the count of active enrollments in a course. 'course_id' is the course_id to return enrollments
Returns a boolean value regarding whether a course has already reached it's max enrollment capacity
Return a queryset of User for every user enrolled in the course.
Return a queryset of Users in the course.
Returns a CoursewareEnrollment object.Args: user (User): The user associated with the enrollment. course_id (CourseKey): The key of the course associated with the enrollment. Returns: Course enrollment object or None
Returns True, if course is paid
Makes this `CourseEnrollment` record active. Saves immediately.
Makes this `CourseEnrollment` record inactive. Saves immediately. Aninactive record means that the student is not enrolled in this course.
Changes this `CourseEnrollment` record's mode to `mode`.  Saves immediately.
Invalidate the cache of CourseEnrollment model.
saves the student manual enrollment information
if matches returns the most recent entry in the table filtered by email else returns None.
if matches returns the most recent entry in the table filtered by enrollment else returns None,
Return QuerySet of students who are allowed to enroll in a course. Result excludes students who have already enrolled in the course. `course_id` identifies the course for which to compute the QuerySet.
convenience function to make eq overrides easier and clearer. arbitrary decision that role is primary, followed by org, course, and then user
Return a User object, looking up by email if username_or_email contains a '@', otherwise by username. Raises: User.DoesNotExist is lookup fails.
Name of the certification, for display on LinkedIn.
Return True if given user can skip entrance exam for given course otherwise False.
Unicode representation of the attribute.
Return the configured refund window as a `datetime.timedelta`.
Set the current refund window to the given timedelta.
Unicode representation of this attribute.
Add an name/value pair as an attribute for the given user. Overwrites any previous value for that name, if it exists.
Old name for has_studio_write_access
Return True iff user is allowed to view this course/library in studio. Will also return True if user has write access in studio (has_course_author_access) There is currently no such thing as read-only course access in studio, but there is read-only access to content libraries.
The caller requests adding the given users to the role. Checks that the caller has sufficient authority. :param caller: a user :param role: an AccessRole
If {UNIQUE_ID} appears in the link, replace it with a unique id for the user. Currently, this is sha1(user.username).  Otherwise, return survey_link.
Helper function used to hit the profile API if email opt-in is enabled.
Attribute this user's registration to the referring affiliate, if applicable.
Decorator that allows access roles to be registered within the roles module and referenced by their string values. Assumes that the decorated class has a "ROLE" attribute, defining its type.
Return whether this RoleCache contains a role with the specified role, course_id, and org
Return whether the supplied django user has access to this role.
Add the role to the supplied django users.
Remove the role from the supplied django users.
Return a django QuerySet for all of the users with this role
Args: course_key (CourseKey)
A named role in a particular org independent of course
A Staff member of a course
A course Instructor
A course staff member with privileges to review financial data.
A course staff member with privileges to perform sales operations.
A course Beta Tester
A user who can view a library and import content from it, but not edit it. Used in Studio only.
A CCX Coach
An organization staff member
An organization instructor
A user who can view any libraries in an org and import content from them, but not edit them. Used in Studio only.
This is the group of people who have permission to create new courses (we may want to eventually make this an org based role).
Student support team members.
Create a UserBasedRole accessor: for a given user and role (e.g., "instructor")
A checkbox widget that only accepts "true" (case-insensitive) as true.
A boolean field that only accepts "true" (case-insensitive) as true
Parse year_of_birth to an integer, but just use None instead of raising an error if it is malformed
Return a dictionary containing the extended_profile_fields and values
Create num users, enrolling them in course_key if it's not None
Generic Error when handling student transfers.
Exception raised explicitly to cause a database transaction rollback.
Checks that the current state of the database matches the specified groups and permissions.
Signal Receiver stub for testing that the unenroll signal was fired.
Creates a course
Helper method to change password on user and record in the PasswordHistory
Verify properly default behavior when feature is disabled
It will be true only if enrollment mode is honor and course has verified mode.
If user enrollment mode is either verified or credit then show_upsellwill be always false.
Helper method to assert that we emit the expected user settings events. Expected settings are passed in via `kwargs`.
Enroll a student in a course.
test users_for_role
Reverse the setup
Converts uidb36 into uidb64
Tests that CourseCreatorRole().has_user always returns True if ENABLE_CREATOR_GROUP and DISABLE_COURSE_CREATION are both not turned on.
Assert base case is refundable
create a fake microsite site name
create a fake microsite site name
test to create a user form the microsite but don't provide any of the microsite specific profile information
Helper method that sets a birth year for the specified user.
Helper method that sets a level of education for the specified user.
Helper method that sets a gender for the specified user.
Verify nothing is returned.
Verify the level of education is displayed correctly.
Verify nothing is returned.
Verify the gender displayed correctly.
Verify nothing is returned.
Return a preset certificate status.
Assert that the dashboard loads when cert_status is None.
Creates a course and associated enrollment.
Configure the amount of time the enrollment message will be displayed.
Exception used for testing that nothing will catch explicitly
Return a string that encodes template_name and context
Append hostname to settings.ALLOWED_HOSTS
Send the reactivation email to the specified user, and return the response as json data.
Test that trying to send a reactivation email to an unregistered user fails without throwing a 500 error.
Executes validate_new_email, returning any resulting error message.
Executes do_email_change_request, returning any resulting error message.
Assert that `response_data` indicates a failed request that returns `expected_error`
Assert the expected error message from the email validation method for an invalid (improperly formatted) email address.
Test the error message if user attempts to change email to the existing value.
Assert the expected error message from the email validation method for an email address that is already in use by another account.
Assert that the function failed before emailing a user
Call `confirm_email_change` and assert that the content was generated as expected`expected_template`: The name of the template that should have been used to generate the content `expected_context`: The context dictionary that should have been used to generate the content
Helper method that creates a mock profile for the specified user.
Verify the behavior for users with no specified year of birth.
Verify that we don't emit events for ignored fields.
Verify no event is triggered if the save does not complete. Note that the pre_save signal is not called in this case either, but the intent is to make it clear that this model should never emit an event if save fails.
Verify that password values are not included in the event payload.
Verify that we don't emit events for related fields.
Verify no event is triggered if the save does not complete. Note that the pre_save signal is not called in this case either, but the intent is to make it clear that this model should never emit an event if save fails.
Test to make sure multiple users are created.
Load the student dashboard and return the HttpResponse.
Set the status of a request for credit, simulating the notification from the provider.
Tests user creation without sending activation email when settings.FEATURES['BYPASS_ACTIVATION_EMAIL_FOR_EXTAUTH']=True and doing external auth
Tests user creation without sending activation email when settings.FEATURES['BYPASS_ACTIVATION_EMAIL_FOR_EXTAUTH']=False and doing external auth
Tests user creation without sending activation email when settings.FEATURES['BYPASS_ACTIVATION_EMAIL_FOR_EXTAUTH']=False and doing external auth
Verify that a referral attribution is recorded if an affiliate cookie is present upon a new user's registration.
Assert that requesting account creation results in the expected error
Assert that requesting account creation results in the expected error
Construct the URL that follows login/registration if we are doing auto-enrollment
Mocked version of microsite helper method to always return true
Confirm that if we get a certificate with a no-id-professional mode we still can download our certificate
Delete cookies indicating that the user is logged in. Arguments: response (HttpResponse): The response sent to the client. Returns: HttpResponse
Test session verification with LMS-specific URLs.
Purges the cache keys for the instances of this model.
Configuration flag to enable/disable rate limiting.Applies to Django Rest Framework views. This is useful for disabling rate limiting for performance tests. When enabled, it will disable rate limiting on any view decorated with the `can_disable_rate_limit` class decorator.
Reloads Django's URL config. This is useful, for example, when a test enables new URLs with a django setting and the URL config needs to be refreshed.
Converts "true" (case-insensitive) to the boolean True. Everything else will return False (including None). An error will be thrown for non-string input (besides None).
Reset the mock tracker in order to forget about old events.
Generic mixin for verifying unsupported media type in PATCH
Method that performs atomic-entering accounting.
Method that performs atomic-rollback accounting.
Hashes `string` into a string representation of a 128-bit digest.
Converts `val` to unicode and URL-encodes special characters (including quotes and spaces)
Returns if the client has been rated limited
Returns true if these are w/in a minute of each other. (in case secs saved to db or timezone aren't same) :param dt1: :param dt2:
Convert a datetime into a timestamp, represented as the number of seconds since January 1, 1970 UTC.
Convert a timestamp (number of seconds since Jan 1, 1970 UTC) into a timezone-aware datetime. If the timestamp cannot be converted, returns None instead.
Return the enum to the caller
Checks to see if the Entrance Exams feature is enabled Use this operation instead of checking the feature flag all over the place
Returns boolean indicating prerequisite courses enabled system wide or not.
It would remove pre-requisite course milestone for course referred by `course_key`.
Returns a string to display for a course or course overview. Arguments: descriptor (CourseDescriptor|CourseOverview): a course or course overview.
It would fetch list of milestones completed by user
validates course key. returns True if valid else False.
Returns a specifically-formatted namespace string for the specified type
Returns a milestones-friendly representation of a user object
Client API operation adapter/wrapper
Client API operation adapter/wrapper
Client API operation adapter/wrapper
Client API operation adapter/wrapper
Client API operation adapter/wrapper
Client API operation adapter/wrapper
Client API operation adapter/wrapper
Client API operation adapter/wrapper
Returns a boolean if user has any unfulfilled milestones
Client API operation adapter/wrapper
Create the given `ticket` in Zendesk. The ticket should have the format specified by the zendesk package.
Update the Zendesk ticket with id `ticket_id` using the given `update`. The update should have the format specified by the zendesk package.
Return whether this request has an Accept header that matches type
Client API operation adapter/wrapper
Client API operation adapter/wrapper
Client API operation adapter/wrapper
Client API operation adapter/wrapper
Client API operation adapter/wrapper
Client API operation adapter/wrapper
Gets a user's anonymous id from their user id
Ensure that rate limiting is enabled by default.
Return a unique integer in the range [minimum, maximum], inclusive.
Return invalid migrations modules for apps. Used for disabling migrations during tests. See https://groups.google.com/d/msg/django-developers/PWPj3etj3-U/kCl6pMsQYYoJ.
An exception thrown during file validation.
Replace CR and CRLF with LF within `string`.
This returns all of the descendants of a descriptor. If the descriptor has dynamic children, the module will be created using module_creator and the children (as descriptors) of that module will be returned.
Just return.
Just return.
Verify that we get a random integer within the specified range when there are no used ids.
Test that sub-ing doesn't ocurr with illegal tags
Test that sub-ing doesn't work without subtags
Check that caches are empty, and add values.
Check to make sure cache is empty, and add values to it.
Check to make sure cache is empty, and add values to it.
Helper method to verify exception text.
Verify whether or not the stored file, passed to the validator, exists.
Stores file validator data for testing after validation is complete.
Validation test function that is a no-op
Helper method that checks that the stored version of the uploaded file has the correct content
Static timezone for testing
Tests get_organization_by_short_name api when app is disabled.
Generate a request, invoke the view, and assert success. The request will be a POST request from the given `user`, with the given `fields` in the POST body. The response should have a 200 (success) status code.
Test for Zendesk submission not enabled in `settings`. We should raise Http404.
Gets the cache TTL for course assets, if present
Gets the list of CDN user agents, if present
Create user and login.
Test that unlocked assets are being served.
Test that locked assets behave appropriately in case the user is not logged in.
Test that locked assets behave appropriately in case user is logged in in but not registered for the course.
Test that locked assets behave appropriately in case user is staff.
Test that syntactically invalid Range values result in a 200 OK full content response.
Tests that we're properly setting the Vary header to ensure browser requests don't get cached in a way that breaks XHR requests to the same asset.
Restore default list_display behavior. ConfigurationModelAdmin overrides this, but in a way that doesn't respect the ordering. This lets us customize it the usual Django admin way.
Restore default list_display behavior. ConfigurationModelAdmin overrides this, but in a way that doesn't respect the ordering. This lets us customize it the usual Django admin way.
Determines whether the given request is an asset request
Generates an RFC1123 datetime string based on a future offset.
Determines whether or not the given content is locked.
Return True if block_type is disabled.
Return list of disabled xblock types.
Returns the currently-logged in user, as an instance of XBlockUser
A set of assertions for an anonymous XBlockUser.
Tests for convert_django_user_to_xblock_user behavior when django user is AnonymousUser.
Tests for convert_django_user_to_xblock_user behavior when django user is User.
Tests for anonymous_user_id method to return None if user is Non-Staff.
Tests for anonymous_user_id method to return None username does not exist in system.
Tests that it correctly splits the xblocks defined in field.
Tests that deprecated modules contain entries from settings file DEPRECATED_ADVANCED_COMPONENT_TYPES
Tests that deprecated types defined in both settings and config model are read.
Check if an attribute has been monkey-patched
Monkey-patch an attribute A backup of the original attribute is preserved in the patched attribute (see: __BACKUP_ATTRIBUTE_NAME).
Helper method to get header values from a request's META dict, if present.
Please note: This method must be called RIGHT BEFORE an expected alert Window variables are page local and thus all changes are removed upon navigating to a new page In addition, this method changes the functionality of ONLY future alerts
Please note: This method must be called RIGHT BEFORE an expected alert Window variables are page local and thus all changes are removed upon navigating to a new page In addition, this method changes the functionality of ONLY future alerts
Please note: This method must be called RIGHT BEFORE an expected alert Window variables are page local and thus all changes are removed upon navigating to a new page In addition, this method changes the functionality of ONLY future alerts
Run ipdb as step for easy debugging
Returns the Sauce Labs username and access ID as set by environment variables
Clean out the django test database defined in the envs/acceptance.py file: edx-platform/db/test_edx.db
Before each scenario, turn off automatic screenshots. Args: str, scenario. Name of current scenario.
Start the required stub service running on a local port. Since these services can be reconfigured on the fly, we start them on a scenario basis when needed and stop them at the end of the scenario.
Handle GET methods to the EdxNotes API stub.
Handle POST methods to the EdxNotes API stub.
Handle PUT methods to the EdxNotes API stub.
Handle DELETE methods to the EdxNotes API stub.
Delete the note by note id.
makes url with the query params including pagination params for pagination next and previous urls
Helper method that removes all notes to the stub EdxNotes service.
Returns a list of all notes without pagination
Adds `notes(list)` to the stub EdxNotes service.
Updates the note with `note_id(str)` by the `note_info(dict)` to the stub EdxNotes service.
Removes the note with `note_id(str)` to the stub EdxNotes service.
Removes all notes to the stub EdxNotes service.
Filters provided `data(list)` by the `note_id(str)`.
Filters provided `data(list)` by the `user(str)`.
Filters provided `data(list)` by the `usage_id(str)`.
Filters provided `data(list)` by the `course_id(str)`.
Filters provided `data(list)` by the `field_name(str)` with `value`.
Handle a GET request from the client and sends response back. Used for checking LTI Provider started correctly.
{{ "@context" : "http://purl.imsglobal.org/ctx/lis/v2/Result", "@type" : "Result", "resultScore" : {score}, "comment" : "This is awesome." }} )
{ "@context" : "http://purl.imsglobal.org/ctx/lis/v2/Result", "@type" : "Result" } )
Return a boolean indicating whether the URL path is a valid LTI end-point.
Remove any extra parameters from the path. For example /gizmo.mp4?1397160769634 becomes /gizmo.mp4
Return a list of notes from the stub EdxNotes service.
Fake timer implementation that executes immediately.
Tests that LTI server processes request with right program path but with wrong header.
Tests that LTI server processes request with right program path and responses with incorrect signature.
Success lti launch.
Redirect messages to keep the test console clean.
Helper to log a server error.
Retrieve the content of the request.
Return the URL path without GET parameters. Removes the trailing slash if there is one.
Send a response with status code 200, the given content serialized as JSON, and the Content-Type header set appropriately
Format message for logging. `format_str` is a string with old-style Python format escaping; `args` is an array of values to fill into the string.
Respond to an HTTP HEAD request
Return a boolean indicating whether the requested URL indicates a submission.
An error related to waiting for require.js. If require.js is unable to load a dependency in the `wait_for_requirejs` function, Python will throw this exception to make sure that the failure doesn't pass silently.
Wait for the element to be present in the DOM.
Wait for the element to be visible in the DOM.
Wait for the element to be either invisible or not present on the DOM.
Wait for the element to be present and clickable.
Wait for the element(s) as defined by css locator to be present. This method will return a WebDriverElement.
Perform a click on an element as specified by its id
Set the value of the element to the specified text. Note that this will replace the current value completely. Then for synchronization purposes, wait for the value on the page.
Returns the HTML of a css_selector
View function that returns XModule URLs as a JSON list; meant to be used as an API
Sets ``key`` in ``dct`` to ``value`` unless ``value`` is ``UNSET``
Assert that the HTML_ACCEPT_LANGUAGE header in request is equal to value
Assert that the LANGUAGE_SESSION_KEY set in request.session is equal to value
Enable DarkLang by default when it is installed, to prevent accidental release of testing languages.
Current list of released languages
Prevent user from requesting un-released languages except by using the preview-lang query string.
Formats lang and priority into a valid accept header fragment.
Returns mode_slug NOTE (CCB): This is a silly hack needed because all of the class methods use tuples with a property named slug instead of mode_slug.
Return _expiration_datetime.
Check whether the modes for a course allow a student to pursue a verified certificate.Args: course_mode_dict (dictionary mapping course mode slugs to Modes) Returns: bool: True iff the course modes contain a verified track.
check the course mode is profession or no-id-professional Args: modes_dict (dict): course modes. Returns: bool
checking that tuple is professional mode. Args: course_mode_tuple (tuple) : course mode tuple Returns: bool
checking slug is professionalArgs: slug (str) : course mode string Return: bool
Check whether the given modes is_verified or not.Args: course_mode_tuple(Mode): Mode tuple Returns: bool: True iff the course modes is verified else False.
Check whether the given mode_slug is_verified or not.Args: mode_slug(str): Mode Slug Returns: bool: True iff the course mode slug is verified else False.
Check whether this is a credit mode.Students enrolled in a credit mode are eligible to receive university credit upon completion of a course.
return the auto-enrollable mode from given dict Args: modes_dict (dict): course modes. Returns: String: Mode name
Returns the minimum price of the course in the appropriate currency over all the course's non-expired modes. If there is no mode found, will return the price of DEFAULT_MODE, which is 0
Takes a mode model and turns it into a model named tuple. Returns: A 'Model' namedtuple with all the same attributes as the model.
Disable atomicity for the view.Otherwise, we'd be unable to commit to the database until the request had concluded; Django will refuse to commit when an atomic() block is active, since that would break atomicity.
Ensure that the verification deadline we save uses the UTC timezone.
Create a test course.
Create a new course mode
Verify that non-audit modes are eligible for a cert.
Create a new course mode
Returns True if this feature is configured as enabled, else False.
Key for fetching unique key values from the cache
Test model for testing ``ConfigurationModels``.
Only allow access by users with `add` permissions on the model.
Overrides as_view to add atomic transaction.
Meta information for AutoConfigModelSerializer.
Should this filter be shown?
Filter the queryset. No-op since it's done by KeyedConfigurationModelAdmin
List the query string params used by this filter
Add a link to each row for creating a new row using the chosen row as a template
Session authentication that allows inactive users and cross-domain requests.
Checks to see if the request was made by a server with an API key. Args: request (Request): the request being made into the view Return: True if the request has been made with a valid API key False otherwise
Limit the number of requests users can make to the enrollment API.
Retrieve course modes associated with the course.
Create the course modes required for a test.
Check the tag doesn't exit
Attempts to change an enrollment for a non-existent user should result in an HTTP 404 for non-server users, and HTTP 406 for server users.
Retrieve the enrollment list for the current user.
Stubbed out Enrollment data request.
Stubbed out Enrollment data request.
Stubbed out Enrollment creation request.
Stubbed out Enrollment data request.
Stubbed out Enrollment data request.
Get an enrollment from the enrollments array.
Get a course from the courses array.
Retrieve enrollment attribute array
Helper function to determine if input_str (typically the queryparam 'next') contains a course_id. @param input_str: @return: the course_id if found, None if not
Helper function to get the enrollment domain set for a course with id course_id @param course_id: @return:
Generate internal password for externally authenticated user
Wrap function again for call by _external_login_or_signup
Setup test case by adding primary user.
Wrapper to run base_test_extauth_auto_activate_user_with_flag with {'SQUELCH_PII_IN_LOGS': False}
Wrapper to run base_test_extauth_auto_activate_user_with_flag with {'SQUELCH_PII_IN_LOGS': True}
@param client: A test client object
Attempt a standard successful login
Test for 403 error code when the namespace of the request is invalid
Test for 403 error code when the url
Test to see that we can handle login redirection properly
An empty view
A view that returns Celery stats
Create a django test client
Outside the context of the request, we should still get a request that allows us to build an absolute URI.
Create a task that adds stuff to the request cache.
Once a celery task completes, clear the request cache to prevent memory leaks.
Return the request cache named ``name``. Arguments: name (str): The name of the request cache to load Returns: dict
Return the current request.
A thread-local for storing the per-request cache.
This method is deprecated. Please use :func:`request_cache.get_cache`.
This method is deprecated. Please use :func:`request_cache.get_request`.
Empty the request cache.
Removes the given headers from the response using the header_control middleware.
Alters the response.
Fake view that returns an empty response.
Returns whether or not the given course id is embargoed. If course has not been explicitly embargoed, returns False.
Return a list of upper case country codes
Check if the course is in restricted list Args: course_id (str): course_id to look for Returns: Boolean True if course is in restricted course list.
Default ordering is ascending by country code
Invalidate the cache.
Create a snapshot of course access rules when the rules are updated.
Return a list of valid IP addresses to whitelist
Inline editor for country access rules.
Validates the whitelist
Populate the available countries with all 2-character ISO country codes.
Test Country model.
Gets the rerun state object for self.course_key and verifies that the values of its fields equal self.expected_rerun_state.
Base class for testing Course Action State Managers.
Asserts that the set of course keys in the expected state equal those that are found
Abstract manager class, with subclasses defining the ACTION (string) field.
Deletes the entry with given id.
Updates the should_display field with the given value for the entry for the given id.
An Enum class for maintaining the list of possible states for Reruns.
To be called when a new rerun is initiated for the given course by the given user.
To be called when an existing rerun for the given course has successfully completed.
Create static assets once for all pipeline render tests.
View for token exchange from 3rd party OAuth access token to 1st party OAuth access token.  Uses django-oauth2-provider (DOP) to manage access tokens.
Wrap an access token in an appropriate response
django-oauth-toolkit expects certain non-standard attributes to be present on the request object.  This function modifies the request object to match these expectations
Return an error response consisting of the errors in the form
Return the path to the first found authentication backend that recognizes the given user.
Validates and returns the "access_token" field.
Validates and returns the "client_id" field.
Create an oauth client application that is public.
Create an oauth client application that is confidential.
Return the set of keys provided when requesting an access token
Create an oauth client application that is public.
Create an oauth client application that is confidential.
Return the set of keys provided when requesting an access token
Returns the access token from the response payload.
Tests for AccessTokenExchangeView used with Facebook
Tests for AccessTokenExchangeView used with Google using django-oauth-toolkit backend.
Given request data, execute a test and check that the expected error was returned (along with any other appropriate assertions).
Given request data, execute a test and check that the expected scopes were returned (along with any other appropriate assertions).
Create an oauth2 client application using class defaults.
Load the list of python-social-auth backend classes from Django settings
Unique string key identifying this provider. Must be URL and css class friendly.
Get the python-social-auth backend class used for this provider
Get a dict of GET parameters to append to login links for this provider
Is this provider being used for the specified pipeline?
Is this provider being used for this UserSocialAuth entry?
Return the uid in social auth. This is default implementation. Subclass may override with a different one.
Gets associated Django settings.AUTHENTICATION_BACKEND string.
Standardize and validate fields
Standardize and validate fields
Get a dict of GET parameters to append to login links for this provider
Is this provider being used for the specified pipeline?
Is this provider being used for this UserSocialAuth entry?
Get social auth uid from remote id by prepending idp_slug to the remote id
Is this data valid?
Return the name of the key to use to cache the current data
Is this provider being used for this UserSocialAuth entry?
Is this provider being used for the specified pipeline?
Not used
Not used
Computes social auth username from LTI parameters
Adds LTI parameter to user details dict if it exists
Interprets parameter as an int or returns 0 if not possible
Returns list of enabled providers.
Returns list of providers that can be used to initiate logins currently
Gets the provider that is being used for the specified pipeline (or None).Args: running_pipeline: The python-social-auth pipeline being used to authenticate a user. Returns: An instance of ProviderConfig or None.
This is a combination login/complete due to LTI being a one step login
Django Admin form class for OAuth2ProviderConfig
Don't show every single field in the admin change list
Django Admin form class for SAMLProviderConfig
Shorten the public/private keys in the change view
Don't show every single field in the admin change list
Get the URL to which we must redirect in order to authenticate the user
Get the permanent ID for this user from the third party.
Given the name of an IdP, get a SAMLIdentityProvider instance
Get a setting, from SAMLConfiguration
Gets the name used in HTML forms that unlink a provider account.
Gets the running pipeline from the passed request.
Gets an enabled provider by its provider_id member or throws.
Redirects to the login page.
Redirects to the registration page.
For some third party providers, we auto-create user accounts
Gets the edx username from a social user
Initialize the class with a provider_id
Generate mapping data used in response
Create users and oauth client for use in the tests
Add the given referer to a request and then return it.
Base test case.
Gets a User by username.
When SAML is not enabled, the metadata view should return 404
Accessing the login endpoint without an idp query param should return 302
Return a cached copy of TestShib's metadata by reading it from disk
Configure TestShib before running the login test
Configure TestShib before running the register test
Mock the current time for SAML, so we can replay canned requests/responses
mock logging in to the provider Should end with loading self.complete_url, which should be returned
Load the login form and check that it contains a button for the provider. Return the URL for logging into that provider.
Load the registration form and check that it contains a button for the provider. Return the URL for registering with that provider.
Get the auth completion URL for this provider
Asserts a GET of /login in the pipeline looks correct.
Verifies that the given password is not correct.The pipeline overrides POST['password'], if any, with random data.
Makes sure the given request is running an auth pipeline.
Asserts a response would redirect to /login.
Asserts a response would redirect to /register.
Asserts a user does not have an auth with the expected provider.
Gets a user by email, using the given strategy.
Render the template and send the context info to any listeners that want it
Initializes the fake from mappings dict.
Enable SAML support (via SAMLConfiguration, not for any particular provider)
Update the settings for an OAuth2-based third party auth provider
Update the settings for a SAML-based third party auth provider
Update the settings for a LTI Tool Consumer third party auth provider
Update the settings for the Dummy third party auth provider/backend
Mark the user with the given email as verified
Configure a oauth client for testing
Configure the client and provider_id pair. This will give the access to a client for that provider.
Read the contents of a file in the data folder
Get a public key for use in the test.
Get a private key for use in the test.
Create an OAuth2 client application
An error occurred while parsing the SAML metadata from an IdP
Gets the base URL to use for serving static assets, if present
Gets the excluded file extensions when canonicalizing static asset paths
Function to actually do a single relative -> absolute url replacement
Restore default list_display behavior. ConfigurationModelAdmin overrides this, but in a way that doesn't respect the ordering. This lets us customize it the usual Django admin way.
Restore default list_display behavior. ConfigurationModelAdmin overrides this, but in a way that doesn't respect the ordering. This lets us customize it the usual Django admin way.
Skip the cross-domain CSRF referer check.Django's CSRF middleware performs the referer check only when the request is made over a secure connection. To skip the check, we patch `request.is_secure()` to False.
Fake view that returns the request META as a JSON-encoded string.
Enable or disable the end-point and configure the whitelist.
Load the end-point.
Build a test request
Check that the request doesn't pass (yet) the `is_secure()` test
Disable the middleware if the feature flag is disabled.
Meta class for this Django model
Helper method to make a copy of a Microsite into the history table
Archive the exam attempt when the item is about to be deleted Make a clone and populate in the History table
String conversion
Returns a list of organizations associated with the microsite key, returned as a set
Returns the microsite object for a given organization based on the table mapping, None if no mapping exists
String conversion
Meta class for this Django model
Returns whether the feature flag to enable microsite has been set
This will return if current request is a request within a microsite
Returns a value associated with the request's microsite, if present
Returns a dictionary product of merging the request's microsite and the default value. This can be used, for example, to return a merged dictonary from the settings.FEATURES dict, including values defined at the microsite
Returns True/False whether a Microsite has a definition for the specified named value
This returns a configuration value for a microsite which has an org_filter that matches what is passed in
This returns a dict have all microsite configs. Each key in the dict represent a microsite config.
Clears out any microsite configuration from the current request/thread
For a given request domain, find a match in our microsite configuration and make it available to the complete django request process
Prepare the feature settings that must be enabled before django.setup() or autostartup() during the startup script
Enable the use of microsites during the startup script
Returns a template for the specified URI, None if none exists or if caller should use default templates/search paths
Returns a path (string) to a template
Don't allow adds
Don't allow deletes
Microsite backend that reads the microsites definitions from a dictionary called MICROSITE_CONFIGURATION in the settings file.
Returns whether there is any Microsite configuration settings
This returns all configuration for all microsites
For a given request domain, find a match in our microsite configuration and make it available to the complete django request process
Returns a value associated with the request's microsite, if present
Returns a dictionary product of merging the request's microsite and the default value. This can be used, for example, to return a merged dictonary from the settings.FEATURES dict, including values defined at the microsite
This will return True/False if the current request is a request within a microsite
Returns True/False whether a Microsite has a definition for the specified named value
This returns a configuration value for a microsite which has an org_filter that matches what is passed in
Clears out any microsite configuration from the current request/thread
Returns whether there is any Microsite configuration settings
Returns the current request's microsite configuration. if request's microsite configuration is not present returns empty dict.
Retrieves a key from a cache scoped to the thread
Stores a key value pair in a cache scoped to the thread
Returns a value associated with the request's microsite, if present
This will return if current request is a request within a microsite
Will return True/False whether a Microsite has a definition for the specified val_name
This returns all configuration for all microsites
Clears out any microsite configuration from the current request/thread
The TEMPLATE_ENGINE directory to search for microsite templates in non-mako templates must be loaded before the django startup
Returns the actual template for the microsite with the specified URI, default implementation returns None, which means that the caller framework should use default behavior
Django template that creates breadcrumbs for page titles: {% page_title_breadcrumbs "Specific" "Less Specific" General %}
Django template tag that outputs the current platform name: {% platform_name %}
Django template tag that outputs the configured favicon: {% favicon_path %}
Base class for microsite related tests.
When an unexistent path is passed to the filter, it should return the same path
For a given request domain, find a match in our microsite configuration and make it available to the complete django request process
Returns a path (string) to a Mako template, which can either be in an override or will just return what is passed in which is expected to be a string
Returns a value associated with the request's microsite, if present
Returns a dictionary product of merging the request's microsite and the default value. This can be used, for example, to return a merged dictonary from the settings.FEATURES dict, including values defined at the microsite
This will return True/False if the current request is a request within a microsite
Returns True/False whether a Microsite has a definition for the specified named value
This returns a configuration value for a microsite which has an org_filter that matches what is passed in
Clears out any microsite configuration from the current request/thread
Tests microsite.get_value works as expected.
Tests microsite.is_request_in_microsite works as expected.
Tests microsite.get_dict works as expected.
Tests microsite.has_override_value works as expected.
Tests microsite.get_all_orgs works as expected.
Tests microsite.has_configuration_set works as expected on this backend.
Tests microsite.get_value works as expected.
Tests microsite.is_request_in_microsite works as expected.
Tests microsite.has_override_value works as expected.
Tests microsite.get_all_config works as expected.
Middleware entry point on every request processing. This will associate a request's domain name with a 'University' and any corresponding microsite configuration information
Middleware entry point for request completion.
Args: field_names: The list of field names to initialize the :class:`NoneToEmptyQuerySet` with.
Returns the result of NoneToEmptyQuerySet instead of a regular QuerySet.
Strips branch and version info if the given key supports those attributes.
Helper function to remove the branch and version information from the given value, which could be a single object or a list.
Validate Empty values, otherwise defer to the parent
A django Field that stores a CourseKey object as a string.
A django Field that stores a UsageKey object as a string.
Wraps create_parser to snag command line info.
A locally-defined command, for testing, that returns the current context as a JSON string.
Runs the test command's execute method directly, and outputs a dict of the current context.
Event tracker backend that uses a python logger.:Parameters: - `name`: identifier of the logger, which should have been configured using the default python mechanisms.
Configure database used by the backend. :Parameters: - `name` is the name of the database as specified in the project settings.
Move a field from the context to the top level of the event.
Capture a event by sending it to the register trackers
Helper method to get header values from a request's META dict, if present.
Helper method to get IP from a request's META dict, if present.
Post a fake Segment event to the view that processes it
Return a json string containing a fake Segment event
Create a fake event and remove some fields from it
Store the event in a list
Re-initialize the tracking system using updated django settings. Use this if you make use of the @override_settings decorator to customize the tracker configuration.
A reference to the in-memory backend that stores the events.
Retrieve an event emitted up to this point in the test.
Ensure no events were emitted at this point in the test.
Test configuration of a simple backend
Test if a backend can be remove by setting it to None.
Extract the generated event tracking context for a given request for the given path.
Assert that the superset dict contains all of the key-value pairs found in the subset dict.
Return `self[key]` if it exists, otherwise, return `None` or `default` if it is specified.
Update the mapping with the values in the supplied `dict`.
Return the keys of the mapping, including both exact matches and prefix matches.
Decorator to register an EventTransformer.  It must have a `match_key` class attribute defined.
Create an EventTransformer of the given event. If no transformer is registered to handle the event, this raises a KeyError.
Returns the event's name.
Transform the event with legacy fields and other necessary modifications.
Update the event's `event_type` to the value specified by `self.legacy_event_type`.
Override this method to specify how to update event fields to maintain compatibility with legacy events.
Override this method to make unconditional modifications to event fields.
Linear sequence events are legacy events if the origin and target lie within the same sequence.
Set legacy payload fields: old: equal to the new current_tab field new: the tab to which the user is navigating
Returns true if the navigation takes the focus out of the current sequence.
Returns true if the navigation moves the focus to the next sequence.
Returns true if the navigation moves the focus to the previous sequence.
Return the legacy event_type of the current event
Transform the event with necessary modifications if it is one of the expected types of events.
Convert the current_time field to currentTime.
If `open_in_browser_url` is specified, set the page to the base of the specified url.
Handle seek bug in iOS. iOS build 1.0.02 has a bug where it returns a +30 second skip when it should be returning -30.
Gets and encrypts the Django session key from the request or an empty string if it isn't found.
Gets the primary key of the logged in Django user
Gets the username of the logged in Django user
Gets the IP address of the request
Test render_to_string() when makomiddleware has not initialized the threadlocal REQUEST_CONTEXT.context. This is meant to run in LMS.
Test render_to_string() when makomiddleware has not initialized the threadlocal REQUEST_CONTEXT.context. This is meant to run in CMS.
Returns a boolean if any given named marketing links are configured.
Returns a boolean if a given named marketing link is configured.
Checks the site name to determine whether to use the edX.org footer or the Open Source Footer.
Overridden method which will hand-off the template lookup to the microsite subsystem
Remove mako template lookups for the given namespace.
Look up a Mako template by namespace and name.
Overrides base __init__ to provide django variable overrides
This can be used within a mako template to include a django template in the way that a django-style {% include %} does. Pass it context which can be the mako context ('context') or a dictionary.
Process the middleware request.
Process the middleware response.
Returns the context processors defined in settings.TEMPLATES.
Assign forum default role 'Student' to user
An enumeration that represents the context of a thread. Used primarily by the comments service.
Save and Update 'course_key' for all roles which are already created to keep course_id same as actual passed course key
Override the default string handling function to always return unicode objects
Make an item visible to staff only.
Set group_access for the specified item to the specified group ids within the content partition.
Verify that an item's visibility view returns an html string containing all the expected substrings.
Return the parsed query string from a handler_url generated with the supplied query_string
Return the parsed path from a handler_url with the supplied handler_name and suffix
Returns the Studio URL to a static resource.
Return the list of available values for the particular category
Return available tags
Returns the Studio URL to a static resource.
Fetch the course grading policy for the given course from persistence and return a CourseGradingModel.
Create or update the grade cutoffs for the given course. Returns sent in cutoffs (ie., no extra db fetch).
Delete the course's grace period.
Fetch the key:value editable course details for the given course from persistence and return a CourseMetadata model.
Extend to store previous state.
Method for adding and removing users from the creator group. Caller must have staff permissions.
User has requested course creator access. This changes the user state to CourseCreator.PENDING, unless the user state is already CourseCreator.GRANTED, in which case this method is a no-op.
Returns the email address for a user
Returns the username for a given user. Implemented to make sorting by username instead of by user object.
Callback for when the model's creator status has changed.
Return a string that encodes template_name and context
Helper method for changing state
Tests that staff cannot add entries
Tests that staff cannot delete entries
Tests that only staff can change entries
Tests that any method changing the course creator authz group must be called with staff permissions.
Convert the command line arg into a course key
Load results from file
Exports a course into a tar.gz file
Test delete_orphans command with no arguments
Test for when a course key is malformed
Test for when a non-existing course key is entered
Test 'force_publish' command with no arguments
Test 'force_publish' command with invalid course key
Test 'force_publish' command with non-existing course key
Tests that forum roles were created with import.
Test export command with no arguments
Test export command with an invalid course key.
Test export command with a valid course key that doesn't exist.
Get's library key as it is passed to indexer
Builds a list of mock.call instances representing calls to reindexing method
Test that raises CommandError for incorrect arguments
Test that raises InvalidKeyError for invalid keys
Get's library key as it is passed to indexer
BUilds a list of mock.call instances representing calls to reindexing method
Test that raises CommandError for incorrect arguments
Test that raises InvalidKeyError for invalid keys
Test fix_not_found command with no arguments
Test the arg length error
Test passing an unparsable course id
Test error for using an unknown user primary key
Test export command with no arguments
Return a user identified by the given string. The string could be an email address, or a stringified integer corresponding to the ID of the user in the database. If no user could be found, a User.DoesNotExist exception will be raised.
Return course update item as a dictionary with required keys ('id', "date" and "content").
Returns whether the push notification feature is enabled.
Simplify similar actions: log message and return JsonResponse with message included in response. By default return 400 (Bad Request) Response.
Return advanced component types which can be created.
Load an XBlock by category name, and apply all defined mixins
api method to create an entrance exam. First clean out any old entrance exams.
api method to delete an entrance exam
For each file in the directory, yield a 2-tuple of (file-name, directory-path)
Returns the dirpath for the first file found in the directory with the given name.  If there is no file in the directory with the specified name, return None.
Helper method for getting file size of an upload file. Can be used for mocking test file sizes.
Render a template using the LMS MAKO_TEMPLATES
Returns the xblock that is the parent of the specified xblock, or None if it has no parent.
Returns true if the specified xblock is a vertical that is treated as a unit. A unit is a vertical that is a direct child of a sequential (aka a subsection).
Returns the primary child category for the specified xblock, or None if there is not a primary category.
Converts usage_key_string to a UsageKey, adding a course run if necessary
Internal method used to calculate and return the locator and course module for the view functions in this file.
Base exception for Certificates workflows
An exception raised when certificate information is invalid.
Return a list of certificate identifiers that are already in use for this course
Track certificate configuration event.Arguments: event_name (str):  Name of the event to be logged. event_data (dict): A Dictionary containing event data Returns: None
Retrieve the locally-stored certificate data from the Certificate object via a helper method
Returns the information about each video upload required for the video list
Returns an S3 bucket for video uploads.
Hash a :class:`xblock.fragment.FragmentResource`.
If the entrance exams feature is enabled we need to hide away the grader from views/controls like the 'Grade as' dropdown that allows a course author to select the grader type for a given section of a course
Does the user have read access to the given course/library?
Does the user have read access to the given course/library?
Exposes internal helper method without breaking existing bindings/dependencies
Exposes internal helper method without breaking existing bindings/dependencies
Collect xblock info regarding the specified xblock and its ancestors.
Returns a string representation of the section or subsection that sets the xblock's release date
Returns a string representation of the section or subsection that sets the xblock's release date
Returns a string representation of the xblock's type and display name
User has requested course creation access.
Build user representation with attached role
Renders a placeholder XBlock.
Get the RESTful/studio URL for testing the given library
The library URLs should return 404 if libraries are disabled.
We should get an error if we do weird requests to /library/
Make sure we are prevented from creating libraries with invalid keys/data
Check that various Nonexistent/invalid keys give 404 errors
Test that people with is_staff see the courses and can navigate into them
Return the release date from the course page
Verify that a public xblock's preview returns the expected HTML.
Verify that a draft xblock's preview returns the expected HTML.
Get the HTML for a container page and verify the section tag is correct and the breadcrumbs trail is correct.
Verify that a draft xblock's container preview returns the expected HTML.
creates an item in the module store, without publishing it.
Verify that a draft container rendered as a child of the container page returns the expected HTML.
Unit Test: test_contentstore_views_entrance_exam_delete_bogus_course
Unit Test: test_contentstore_views_entrance_exam_get_bogus_course
Unit Test: test_contentstore_views_entrance_exam_post_bogus_course
Unit Test: test_contentstore_views_entrance_exam_post_invalid_http_accept
Unit Test: test_contentstore_views_entrance_exam_unsupported_method
Basic check that the Pages page responds correctly
Test toggling of tab visibility
Post to the asset upload url
Helper method to verify lock state in the contentstore
Sets up the test course.
Get the HTML for the page.
JSON is unsupported.
Get tar.gz file, using HTTP_ACCEPT.
Get tar.gz file, using URL parameter.
Export success helper method.
Export failure if course is not exist
Returns the URL for textbook detail handler.
Return video handler URL for the given course
Returns the previous upload with the given video id.
Pure XBlock to use in tests.
Remove ids from the response. We cannot predict IDs, because they're generated randomly. We use this method to clean up response when creating new group configurations. Returns a tuple that contains removed group configuration ID and group IDs.
Set up GroupConfigurationsListHandlerTestCase.
Return url for the handler.
Test if not allowed header present in request.
Return url for the handler.
Test that right data structure will be created if content group is not used.
Set up the for the course header menu tests.
Verify the status code returned by the Program authoring view.
Verify that accessing the view requires the user to be authenticated.
Ensure the endpoint returns 404 when Programs authoring is disabled.
Asserts that self.ext_user is not enrolled in self.course.
Test adding a subsection as a prerequisite
Test removing a subsection as a prerequisite
Returns the usage key from the response returned by a create operation.
Add to the student view
Get the item referenced by the UsageKey from the modulestore
Creates a vertical, returning its UsageKey.
Make request and asserts on response code and response contents
Returns whether or not the item with given location has a published version.
Verifies the item with given location has a published version and no draft (unpublished changes).
Verifies the item with given location has a published version and also a draft version (unpublished changes).
Test creating a draft version of a public problem.
Verifies the number of children of the split_test instance.
Returns the template which has the specified display name.
Returns the child xblock info at the specified index.
Returns the xblock info for the specified location.
Returns the xblock info for the specified location as neeeded for the course outline page.
Sets the release date for the specified xblock.
Enables staff only for the specified xblock.
Sets the display name for the specified xblock.
Verify the staff_only_message field of xblock_info.
Verify the publish state of an item in the xblock_info.
Verify the explicit staff lock state of an item in the xblock_info.
Returns the HTML for the page representing the xblock.
Remove ids from the response. We cannot predict IDs, because they're generated randomly. We use this method to clean up response when creating new certificate.
Set up CertificatesListHandlerTestCase.
Return url for the handler.
Test if not allowed header present in request.
Unit Test: test_certificate_unsupported_method
Set up CertificatesDetailHandlerTestCase.
Return url for the handler.
An exception that is raised whenever we need to `fall back` to fetching *all* courses available to a user, rather than using a shorter method (i.e. fetching by group)
Internal method used to calculate and return the locator and course module for the view functions in this file.
Internal method used to restart indexing on a course.
Returns a JSON representation of the course module and recursively all of its children.
CCXs cannot be edited in Studio and should not be shown in this dashboard
Returns the rerun link for the given course key.
Returns True if content experiments have been enabled for the course.
An error thrown when a group configurations input is invalid.
Receive group configuration as a json (`json_string`), deserialize it and validate.
Deserialize given json that represents group configuration.
Return a list of IDs that already in use.
Get user partition for saving in course.
Get usage information for all Group Configurations currently referenced by a split_test instance.
Get usage information for content groups.
Get usage information on items for content groups.
Login, check that it worked.
Creates the test course.
Create test course.
Create dummy course with 'CourseFactory' and role (instructor/staff) groups
Assign access roles to user in the course.
Reverse the setup
Asserts that we have the expected count of orphans for a given course_key
Test rewriting references in ReferenceValueDict, specifically with published content.
Test rewriting references in ReferenceValueDict, specifically with draft content.
Remove, if subtitles content exists.
Remove, if subtitles content exists. youtube_subs: dict of '{speed: youtube_id}' format for different speeds.
<transcript_list> <track id="1" name="Custom" lang_code="en" /> <track id="0" name="Custom1" lang_code="en-GB"/> </transcript_list>
<transcript_list> <track id="1" name="Custom" lang_code="en" /> <track id="0" name="Custom1" lang_code="en-GB"/> </transcript_list>
base version of setup_course_base is a no-op
Centralized call to getting the search engine for the test
Returns field_dictionary for default search
Performs index search according to passed parameters
publish the item at the given location
delete the item at the given location
update the item at the given location
kick off complete reindex of the course
index course using recent changes
if search setting has it as off, confirm that nothing is indexed
Test that exception within indexing yields a SearchIndexingError
Test for removing course from CourseAboutSearchIndexer
Check that the search within this course will yield the expected number of results
private function to get ids from object down the tree
Returns field_dictionary for default search
kick off complete reindex of the course
Extracts contents from search response
if search setting has it as off, confirm that nothing is indexed
Test that exception within indexing yields a SearchIndexingError
Return url for the handler.
kick off complete reindex of the course
Mock override for ugettext translation operation
return gettext.translation for given language
return the module i18n service.
custom function
Test: Django default translator should in use if we have an empty block
Login as a staff user
Helper method to add a LibraryContent block to a course. The block will be configured to select content from the library specified by library_key. other_settings can be a dict of Scope.settings fields to set on the block.
Adds simple HTML block to library
Helper to use the CMS's module system so we can access student-specific fields.
Helper method: Uses the REST API to update the fields of an XBlock. This will result in the XBlock's editor_saved() method being called.
Use the REST API to get a list of libraries visible to the current user.
Create a library, staff user, and non-staff user
Log out when done each test
Error case. ENABLE_MKTG_SITE is True, but there is either no MKTG_URLS, or no MKTG_URLS Root property.
No LMS_BASE, nor is ENABLE_MKTG_SITE True
create mock course and return the about page link
Returns an array of tab dictionaries.
Verifies that a private unreleased xblock is not visible
Verifies that a private released xblock is not visible
Verifies that a public (published) unreleased xblock is not visible
Verifies that public (published) released xblock is visible if staff lock is not enabled.
Verifies that a private xblock with no start date is not visible
Verifies that a public (published) xblock with no start date is visible unless staff lock is enabled
Helper to verify that the release date source of a given item matches the expected source
Tests a vertical's release date being set by its chapter
Tests a vertical's release date being set by its sequential
Tests a sequential's release date being set by its chapter
Tests a sequential's release date being set by itself
Helper to verify that the staff lock source of a given item matches the expected source
Tests a vertical's staff lock being set by its chapter
Tests that a orphaned xblock has no staff lock source
Tests a vertical with no staff lock set anywhere
Tests that an orphaned xblock does not inherit staff lock
Sets group_access to specified value and calls update_item to persist the change.
Set the user partitions of the course descriptor.
Set group access of the block.
Reverse the setup
Verifies all temporary attributes added during export are removed
Verifies rendering the editor in all the verticals in the given test course
Test new course creation - happy path
Test new course creation and verify default language
Test new course creation and verify forum seeding
Test that course creation works after deleting a course with the same URL
Test new course creation - error path for bad organization name
Test new course creation -- course creation disabled, but staff access.
Test new course creation -- course creation group enabled, staff, group is empty.
Checks that the course did not get created due to a PermissionError.
Test viewing the index page with no courses
Test that the course factory works correctly.
Test that the item factory works correctly.
Show the course overview page.
Test viewing the course overview page with invalid course id
Returns the elements in the course listing section of html that have the given course_key
Returns the elements in the unsucceeded course action section that have the given course_key
Initial data setup
Reverse the setup
Parse response, which is assumed to be json
look up a user by email
look up registration object by email
Convenience method for client.get which sets the accept type to html
Convenience method for client.get which sets the accept type to json
Create a non-staff user, log them in (if authenticate=True), and return the client, user to use for testing.
Reloads the course object from the database
Updates the course object in the database
Verifies the publish state of the item is as expected.
Use the xblock serializer to convert the datetime
If feature flag ENABLE_EXPORT_GIT is on, show the setting as a non-deprecated Advanced Setting.
If feature flag ENABLE_EXPORT_GIT is off, don't show the setting at all on the Advanced Settings page.
If feature flag ENABLE_EDXNOTES is on, show the setting as a non-deprecated Advanced Setting.
If feature flag ENABLE_EDXNOTES is off, don't show the setting at all on the Advanced Settings page.
Compute the url to use in tests
Test that user enrollment end date is editable in response.Feature flag 'ENABLE_MKTG_SITE' is not enabled. User is global staff.
Test that user enrollment end date is editable in response.Feature flag 'ENABLE_MKTG_SITE' is not enabled. User is non-global staff.
Test that user enrollment end date is editable in response.Feature flag 'ENABLE_MKTG_SITE' is enabled. User is global staff.
Mock cached content
Reverse the setup
Add the user to the instructor group of the course so they will have the permissions to see it in studio
Waits for the loading indicator to be hidden.
name is uppercased because the heading styles are uppercase in css
If alert appear on save then UnexpectedAlertPresentException will occur and test will fail.
var editor = tinyMCE.activeEditor; editor.setContent(arguments[0]); editor.selection.select(editor.dom.select('p')[0]);
Edits an advanced problem (assumes only on page), types the provided XML, and saves the component.
Removes all instructor and staff users from the given course.
Returns True if this xblock has children that are limited to specific content groups. Note that this method is not recursive (it does not check grandchildren).
Returns True if this xblock has visibility limited to specific content groups.
Creates the URL for the given handler. The optional key_name and key_value are passed in as kwargs to the handler.
Creates the URL for handlers that use course_keys as URL parameters.
Creates the URL for handlers that use library_keys as URL parameters.
Creates the URL for handlers that use usage_keys as URL parameters.
Checks to see if the indexing feature is enabled
Indicates some error(s) occured during indexing
Checks to see if the indexing feature is enabled
Modifies usage_id to submit to index
Gets the version agnostic item location
(Re)index all content within the given structure (course or library), tracking the fact that a full reindex has taken place
Track content index requests.Arguments: event_name (str):  Name of the event to be logged. category (str): category of indexed items indexed_count (int): number of indexed items Returns: None
Base implementation of fetch group usage on course/library.
Perform any supplemental indexing given that the structure object has already been loaded. Base implementation performs no operation. Arguments: modulestore - modulestore object used during the indexing operation structure - structure object loaded during the indexing job Returns: None
Any supplemental fields that get added to the index for the specified item. Base implementation returns an empty dictionary
Normalizes structure key for use in indexing
Fetch the item from the modulestore location
Builds location info dictionary
(Re)index all content within the given course, tracking the fact that a full reindex has taken place
Perform additional indexing from loaded structure object
Normalizes structure key for use in indexing
Fetch the item from the modulestore location
Builds location info dictionary
Modifies usage_id to submit to index
(Re)index all content within the given library, tracking the fact that a full reindex has taken place
get the value for this piece of information, using the correct source
Builds location info dictionary
Helper class that has no default JSON encoding
Test js_escaped_string returns empty string for None
Returns a new Fragment that has `new_content` and all as its content, and all of the resources from fragment
Updates the supplied module with a new get_html function that wraps the old get_html function and substitutes urls of the form /static/... with urls that are /static/<prefix>/...
Template uses element_id in js function names, so can't allow dashes and colons.
Just like mkdtemp, but the directory will be deleted when the process ends.
If arg is an xblock, use its location. otherwise just turn it into a string
Given any data structure, returns a zlib compressed pickled serialization.
Returns the results of running `glob` rooted in the directory `root`. All returned paths are relative to `root`. Uses glob2 globbing
Returns a file system filename for the specified file name.
Returns True if the specified path exists.
Retrieves the specified file from storage.
Returns the size of the package resource.
Returns a URL to the package resource.
Returns the created time of the package resource.
Returns the modified time of the resource.
Note: package resources do not support URLs
Note: deleting files from a package is not supported.
Build an error response with the given status code and developer_message
Requires either OAuth2 or Session-based authentication. If is_user is True, also requires username in URL matches the request user.
Retrieves the specified resource using the RetrieveModelMixin.
Checks for validation errors, then updates the model using the UpdateModelMixin.
Returns a dictionary containing the http auth header with encoded username+password
Issue a get request to the given URI with the API key header
Assert that accessing the "url" entry in the given object returns the same object
Assert that the given response has the status code 200
Assert that the given response has the status code 403
Assert that the given response has the status code 400
Assert that the given response has the status code 405
Convert a course key to unicode.
Convert unicode to a course key.
Convert a usage key to unicode.
Returns total number of results
Returns total number of pages the results are divided into
Return a valid access token that exists in one of our OAuth2 libraries, or None if no matching token is found.
Return a valid access token stored by django-oauth2-provider (DOP), or None if no matching token is found.
Intermediate class to allow exceptions to pass dict detail values.  Use by subclassing this along with another subclass of `exceptions.APIException`.
Override of DRF's AuthenticationFailed exception to allow dictionary responses.
Override of DRF's MethodNotAllowed exception to allow dictionary responses.
Permission that checks to see if the request user matches the user in the URL or has is_staff access.
Base Exception for when an error was found regarding features.
Generate a JWT token with the provided payload.
Generate a JWT id_token that looks like the ones currentlyreturned by the edx oidc provider.
Simple serializer to paginate results from
Build a mock object with the passed id
Mocks `Request.build_absolute_uri`.
Verify the method returns the passed value, if the value is an absolute URL.
Make a GET request to the specified URL with an OAuth2 bearer token.  If no token is provided, a valid token will be used.  Query parameters can also be passed in if desired.
Make a POST request to the specified URL with an OAuth2 bearer token.  If no token is provided, a valid token will be used.
Ensure GETing form over OAuth with correct client credentials succeed
Ensure GETing form over OAuth with correct client credentials in form data succeed
Ensure POSTing form over OAuth with correct credentials passes and does not require CSRF
Ensure POSTing when there is no OAuth access token in db fails
Ensure POSTing with refresh token instead of access token fails
Fake class for object permission tests.
Fake class for object permission for CCX Courses
Asserts whether or not the user has permission to access an object. Arguments user (User) permitted (boolean)
Staff users should be permitted.
Owners should be permitted.
Non-staff and non-owner users should not be permitted.
Staff users always have permission.
Removes the Milestone and CourseContentMilestones related to the gating prerequisite which the given course content fulfills Arguments: prereq_content_key (str|UsageKey): The prerequisite content usage key Returns: None
Create a mock plugin with the specified name and priority.
Allow all known variations.
Allow no variation at all.
Use the provided tolerance or provide a default one if None was specified.
Strict comparison of two events. This asserts that every field in the real event exactly matches the expected event.
Given a multi-line string, indent every line of it by the given number of spaces. If `text` is not a string it is formatted using pprint.pformat.
Return True iff the `actual_event` matches the `expected_event` given the tolerances.
DRY helper for verifying request counts.
Verify that no data is retrieved if the provided config model is disabled.
Create a fragment.
Helper method for verifying the URL is as expected.
Test image URL formatting.
Verify that if a course has empty `course_image`, `course_image_url` returns `DEFAULT_COURSE_ABOUT_IMAGE_URL` defined in the settings.
A test cache that provides a data dict for caching values, analogous to the request_cache.
A test function whose results are to be memoized in the request_cache.
A test function with multiple parameters whose results are to be memoized in the request_cache.
Returns the canonical absolute path of `rpath`.
Is (the canonical absolute path of) `path` outside `base`?
Arguments: cache (django.core.cache.backends.base.BaseCache) - The cache into which cacheable data of the block structure is to be serialized.
Deletes the block structure for the given root_block_usage_key from the given cache. Arguments: root_block_usage_key (UsageKey) - The usage_key for the root of the block structure that is to be removed from the cache.
Returns a set of all registered transformers. Returns: {BlockStructureTransformer} - All transformers that are registered with the platform's PluginManager.
The default iterator for a block structure is get_block_keys() since we need to filter blocks as a list. A topological traversal can be used to support DAGs.
Returns the parents of the block identified by the given usage_key. Arguments: usage_key - The usage key of the block whose parents are to be returned. Returns: [UsageKey] - A list of usage keys of the block's parents.
Returns the children of the block identified by the given usage_key. Arguments: usage_key - The usage key of the block whose children are to be returned. Returns: [UsageKey] - A list of usage keys of the block's children.
Returns the block keys in the block structure. Returns: iterator(UsageKey) - An iterator of the usage keys of all the blocks in the block structure.
Performs a topological sort of the block structure and yields the usage_key of each block as it is encountered. Arguments: See the description in openedx.core.lib.graph_traversals.traverse_topologically. Returns: generator - A generator object created from the traverse_topologically method.
Performs a post-order sort of the block structure and yields the usage_key of each block as it is encountered. Arguments: See the description in openedx.core.lib.graph_traversals.traverse_post_order. Returns: generator - A generator object created from the traverse_post_order method.
Adds a parent to child relationship in this block structure. Arguments: parent_key (UsageKey) - Usage key of the parent block. child_key (UsageKey) - Usage key of the child block.
Returns the version number stored for the given transformer. Arguments: transformer (BlockStructureTransformer) - The transformer whose stored version is requested.
Returns the instantiated xBlock for the given usage key. Arguments: usage_key (UsageKey) - Usage key of the block whose xBlock object is to be returned.
Iterates through all instantiated xBlocks that were added and collects all xBlock fields that were requested.
Test transformer with default version number (0).
1st test instance of the MockTransformer that is registered.
2nd test instance of the MockTransformer that is registered.
3rd test instance of the MockTransformer that is not registered.
Returns the children of the mock XBlock.
Returns the mock XBlock (MockXBlock) associated with the given block_key. Raises ItemNotFoundError if the item is not found.
Associates the given key with the given value in the cache.
Returns the value associated with the given key in the cache; returns default if not found.
Deletes the given key from the cache.
Creates and returns a MockModulestore from the given children_map. Arguments: children_map ({block_key: [block_key]}) - A dictionary mapping a block key to a list of block keys of the block's corresponding children.
Context manager for mocking the transformer registry to return the given transformers.
Converts and returns the given children_map to a parents_map.
Collects block data for the block structure.
Transforms the block structure.
Asserts data was collected for the block structure.
Asserts the block structure was transformed.
Sets a value for each block in the given structure, using the given data key.
Verifies the value for each block in the given structure, for the given data key.
Returns a unique deterministic value for the given block key and data key.
Mock transformer that is not registered.
Adds the registered transformers to the self.transformers collection.
Updates the collected Block Structure for the root_block_usage_key. Details: The cache is cleared and updated by collecting transformers data from the modulestore.
Deserializes a course structure JSON object
Return the blocks in the order with which they're seen in the courseware. Parents are ordered before children.
Mixin for tests to disable calls to signals.listen_for_course_publish when the course_published signal is fired.
Retrieves the course for the given course key.Args: course_key: The CourseKey for the course we'd like to retrieve. Returns: the course that matches the CourseKey Raises: CourseNotFoundError
Returns a unique deterministic base32-encoded ID for the course. Arguments: padding_char (str): Character used for padding at end of base-32 -encoded string, defaulting to '='
Returns this course's URL name.
Return reasonable display name for the course.
Returns whether the the course has started.
Returns whether the course has ended.
Returns True if the course starts with-in given number of days otherwise returns False.
Returns the desired text corresponding the course's start date and time in UTC.  Prefers .advertised_start, then falls back to .start.
Checks if the start date set for the course is still default, i.e. .start has not been modified, and .advertised_start has not been set.
Returns the end date or datetime for the course formatted as a string.
Returns the type of the course's 'start' field.
Returns the display value for the course's start date.
Returns whether it is acceptable to show the student a certificate download link.
Returns a list of ID strings for this course's prerequisite courses.
Returns all course keys from course overviews.
Returns the pacing for the course.Potential values: self: Self-paced courses instructor: Instructor-led courses
Represent ourselves with the course key.
Model for storing and caching tabs information of a course.
Tuple for small image dimensions in pixels -- (width, height)
Tuple for large image dimensions in pixels -- (width, height)
Create an active CourseOverviewImageConfig with non-default values.
Enable or disable thumbnail generation config. Config models pick the most recent by date created, descending. I delete entries here because that can sometimes screw up on MySQL, which only has second-level granularity in this timestamp. This uses non-default values for the dimensions.
Restore default list_display behavior. ConfigurationModelAdmin overrides this, but in a way that doesn't respect the ordering. This lets us customize it the usual Django admin way.
Catches the signal that a course has been published in Studio and updates the corresponding CourseOverview cache entry.
Add arguments to the command parser.
Create courses in modulestore.
Assert that courses doesn't exist in the course overviews.
Assert courses exists in course overviews.
Test that CommandError is raised for invalid key.
Test keys not found are logged.
Return a form bound to self.form_data, asserting its validity (or lack thereof) according to expected_valid
Create a form bound to self.form_data, assert its invalidity, and assert that its error dictionary contains one entry with the expected field and message
Check that the form returns the expected data
Ensure no empty values were passed
Generate a URL based on internal service URL and API version number.
Generate a URL based on public service URL and API version number.
Returns a named tuple containing information required for working with the Programs authoring app, a Backbone app hosted by the Programs service.
Whether responses from the Programs API will be cached.
Indicates whether LMS dashboard functionality related to Programs should be enabled or not.
Indicates whether Studio functionality related to Programs should be enabled or not.
Indicates whether background tasks should be initiated to grant certificates for Program completion.
Indicates whether we should show xseries add
Indicates whether we want to show program listing page
Find all run modes which are part of a program.
Create and configure an API client for authenticated HTTP requests. Args: api_config: ProgramsApiConfig or CredentialsApiConfig object student: User object as whom to authenticate to the API Returns: EdxRestApiClient
Given a set of completed courses, determine which programs are completed. Args: client: programs API client (EdxRestApiClient) course_certificates: iterable of dicts with structure {'course_id': course_key, 'mode': cert_type} Returns: list of program ids
Find the ids of all the programs for which the student has already been awarded a certificate. Args: student: User object representing the student Returns: ids of the programs for which the student has been awarded a certificate
Issue a new certificate of completion to the given student for the given program. Args: client: credentials API client (EdxRestApiClient) username: The username of the student program_id: id of the completed program Returns: None
Creates a new ProgramsApiConfig with DEFAULTS, updated with any provided overrides.
Dry method for getting expected program credentials response data.
Verify behavior when programs is disabled.
Verify behavior when API client fails to initialize.
Verify behavior when data can't be retrieved from Programs.
Verify behavior when student dashboard display is disabled.
Verify behavior when no programs data is found for the user.
Variadic helper used to create course enrollments.
Variadic helper used to verify progress calculations.
Construct a list containing the display names of the indicated course codes.
Verify the behavior of the property controlling whether API responses are cached.
Ensures the receiver function is invoked when COURSE_CERT_AWARDED is sent. Suboptimal: because we cannot mock the receiver function itself (due to the way django signals work), we mock a configuration call that is known to take place inside the function.
Ensures that the receiver function does nothing when the programs API configuration is not enabled.
Event changes to user preferences.
Event changes to user preferences.
Check whether a field is visible based on Django settings.
Check whether a field is required based on Django settings.
DRF class for interacting with the User ORM object
This is used in bulk updates to determine the identity of an object. The default is to use the id of an object, but we want to override that and consider the language code to be the canonical identity of a LanguageProficiency model.
Filter serialized account Dict to only include whitelisted keys
Enforce minimum length for name.
Converts empty string to None, to indicate not set. Replaced by to_representation in version 3.
Helper method to convert empty string to None (other values pass through).
Returns a boolean representing whether the user requires parental controls.
Returns metadata about a user's profile image This protected method delegates to the static 'get_profile_image' method because 'serializers.SerializerMethodField("_get_profile_image")' will call the method with a single argument, the user_profile object.
Configures and returns a django Storage instance that can be used to physically locate, read and write profile images.
Returns the user-specific part of the image filename, based on a hash of the username.
Returns the full filename for a profile image, given the name and size.
Returns a dict containing the filenames for a complete set of profile images, keyed by pixel size.
Helper method to return the legacy user and profile objects based on username.
Verify correct url structure.
Verify correct url structure for a default profile image.
Return a string that encodes template_name and context
Helper method for getting the client and user and logging in. Returns client.
Helper method for sending a PUT to the server. Verifies the expected status and returns the response.
Helper method for sending a DELETE to the server. Verifies the expected status and returns the response.
Test that an anonymous client (not logged in) cannot call GET or PATCH.
Confirms that private fields are private, and public/shareable fields are public/shareable
Test that a client cannot call PATCH on a different client's user account (even with is_staff access).
Internal method to encapsulate the retrieval of old names used
Retrieve all course keys for a particular org.Arguments: org_aliases (list): List of aliases for the org. Returns: List of `CourseKey`s
Context manager for measuring execution time.
Iterate through the results of a database query, fetching in chunks.Arguments: cursor: The database cursor Yields: tuple of row values from the query
Serialize a list of values for including in a SQL "IN" statement.
Set the email opt-in preference.Arguments: user (User): The user model. org (unicode): The org in the course key. is_opted_in (bool): Whether the user is opted in or out of emails. Returns: None
Retrieve the latest opt-in preference for the user,across all orgs and preference keys. Arguments: user (User): The user whos preference was set. Returns: ISO-formatted datetime string or empty string
Return the name attribute from the user profile object
Returns the set of preferences as a dict for the specified user
Serializer that generates a represenation of a UserPreference entity
Serializer that generates a raw representation of a user preference.
Return all fields on this Serializer class which are read-only. Expects sub-classes implement Meta.explicit_read_only_fields, which is a tuple declaring read-only fields which were declared explicitly and thus could not be added to the usual cls.Meta.read_only_fields tuple.
Configure how the form should be submitted.Args: method (unicode): The HTTP method used to submit the form. submit_url (unicode): The URL where the form should be submitted.
Forces evaluation of ugettext_lazy promises.
There was a problem with the request to the User API.
An internal error occurred in the User API.
The requested user does not exist.
The user is not authorized to perform the requested action.
There was a problem with the request to the account API.
User with the same username and/or email already exists.
The requested username is not in a valid format.
The requested email is not in a valid format.
The requested password is not in a valid format.
An update to the account failed. More detailed information is present in developer_message, and depending on the type of error encountered, there may also be a non-null user_message field.
There was a problem with a preference request.
An update to a user preference failed. More detailed information is present in developer_message, and depending on the type of error encountered, there may also be a non-null user_message field.
GET /api/user/v1/preferences/{username}/
Helper method to return the authorized user for a given username. If username is not provided, requesting_user.username is assumed.
Helper method that raises UserNotAuthorized if requesting user is not owner user or is not staff if access to staff is given (i.e. 'allow_staff' = true)
Internal helper to assert the type of the provided timestamp value
Returns the expected user message for an invalid key.
Test that an anonymous client (not logged in) cannot call GET or PATCH.
Test that a client (logged in) cannot get the preferences information for a different client.
Test that a client (logged in) can get her own preferences information (verifying the default state before any preferences are stored).
Test that a client (logged in) can create her own preferences information.
Test that a client (logged in but not active) can create her own preferences information.
Sets the url attribute including the username and provided preference key
Test that an anonymous client (logged in) cannot manipulate preferences.
Test that a client (logged in) can create a preference.
Test that a client (logged in but not active) can create a preference.
Test that a client (logged in) cannot update a preference for another user.
Sets the value of ``key`` to ``value``
Gets the value of ``key``
Fake exception that should be intercepted.
Fake exception that should be raised.
Function used to test the intercept error decorator.Keyword Arguments: raise_error (Exception): If provided, raise this exception.
Dummy save method for dummy model.
Set options for fields which can't be conveyed in their definition.
Given a user object, get the URI for the corresponding resource
Tests the User API registration endpoint with Google authentication.
Verify that we emit an event when a user preference is updated.
Verify that we emit an event when a user preference is deleted.
Configuration for self-paced courses.
Get the path to the real asset on disk
This is a proxy function to hide microsite_configuration behind comprehensive theming.
This is a proxy function to hide microsite_configuration behind comprehensive theming.
This is a proxy function to hide microsite_configuration behind comprehensive theming.
This is a proxy function to hide microsite_configuration behind comprehensive theming.
Generate a URL based on internal service URL and API version number.
Generate a URL based on public service URL and API version number.
Indicates whether the learner credential should be enabled or not.
Indicates whether Studio functionality related to Credential should be enabled or not.
Creates a new CredentialsApiConfig with DEFAULTS, updated with anyprovided overrides.
Dry method for getting expected program credentials response data.
Verify user credentials data can be retrieve.
Verify that user program credentials cannot be retrieved if issuance is disabled.
Verify behavior if no credential exist.
Fetch the course details for the given course from persistence and return a CourseDetails model.
Returns the course about video ID.
Returns the course about video URL.
Updates the Course's about video to the given video ID.
Helper function used to check if a string is a valid url. Args: url (str): the url string to be validated Returns: bool: whether the url is valid or not
Mock function used to bypass the oauth fetch token
Test for an invalid course key
Test for 500 error: a CCXConnServerError exception is raised
Test task with no problems
Return platform_key for current active configuration. If current configuration is not enabled - return empty string :return: Platform key :rtype: unicode
Return course key for coursetalk widget CourseTalk unique key for a course contains only organization and course code. :param course_key: SlashSeparatedCourseKey instance :type course_key: SlashSeparatedCourseKey :return: CourseTalk course key :rtype: str
Setup database for this test: Create CourseTalkWidgetConfiguration
Retrieve a credit provider with provided 'provider_id'.
Unicode representation of the credit provider.
Invalidate the cache of credit providers.
Get the credit course if exists for the given 'course_key'. Args: course_key(CourseKey): The course identifier Raises: DoesNotExist if no CreditCourse exists for the given course key. Returns: CreditCourse if one exists for the given course key.
Unicode representation of the credit course.
Invalidate the cache of credit courses.
Mark the given requirements inactive. Args: requirement_ids(list): List of ids Returns: None
Get credit requirement of a given course. Args: course_key(CourseKey): The identifier for a course namespace(str): Namespace of credit course requirements name(str): Name of credit course requirement Returns: CreditRequirement object if exists
Get credit requirement statuses of given requirement and username Args: requirement(CreditRequirement): The identifier for a requirement username(str): username of the user Returns: Queryset 'CreditRequirementStatus' objects
The default deadline to use when creating a new CreditEligibility model.
Returns the eligibilities of given user. Args: username(str): Username of the user Returns: CreditEligibility queryset for the user
Check if the given user is eligible for the provided credit course Args: course_key(CourseKey): The course identifier username(str): The username of the user Returns: Bool True if the user eligible for credit course else False
Unicode representation of the credit eligibility.
try: return cls.objects.filter( username=username, course__course_key=course_key ).select_related('course', 'provider').latest() except cls.DoesNotExist: return None def __unicode__(self): Unicode representation of a credit request.
Whether responses from the commerce API will be cached.
CreditCourse Serializer
Returns the course key associated with the course.
Helper method to get a course key eith from a string or a CourseKey, where the CourseKey will simply be returned
Return physical path of file if found.
Check whether the course has been configured for credit. Args: course_key (CourseKey): Identifier of the course. Returns: bool: True iff this is a credit course.
Returns a boolean indicating if the user is eligible for credit for the given course Args: username(str): The identifier for user course_key (CourseKey): The identifier for course Returns: True if user is eligible for the course else False
Could not complete a request to the credit API because there was a problem with the request (as opposed to an internal error).
The requirement dictionary provided has invalid format.
The course is not configured for credit.
The user has not satisfied eligibility requirements for credit.
The requested credit provider is not configured correctly for the course.
The user has already submitted a request and received a response from the credit provider.
The request does not exist.
The status is not either "approved" or "rejected".
API request is invalid.
Course key is invalid.
Verify the mailing address is always empty.
Check the user's credit status.
Verify that parsed providers list is returns after getting course production information.
Verify that in case of any exception it logs the error and return.
Verify that if all providers are in-active than method return empty list.
Create and enroll users with provided enrollment type.
Adding the verification status for a user.
Validate the response's status and detail message.
Verify the endpoint requires authentication.
Verify the viewset does not allow CreditProvider objects to be created or modified.
Serializes a CreditCourse to a Python dict.
Create a credit request for the given user and course.
Verify the endpoint returns HTTP 400 if no username is supplied.
Check the status of a credit request.
Verify HTTP 400 is returned for requests with an invalid timestamp.
Verify requests with an invalid status value return HTTP 400.
Returns a URL that can be used to view eligibility data.
Verify the endpoint returns eligibility information for the give user and course.
Verify that staff users can view eligibility data for all users.
Safely reload an item from the moduelstore.
Used as a side effect when mocking method credit api method'set_credit_requirements'.
Test with valid grades submitted before deadline
Verify the status is set to failure if a passing grade is received past the submission deadline.
Test with failed grades and deadline is still open or not defined.
Enroll the test user in the given course's honor mode, or the test course if not provided.
Makes sure that get_credit_state returns None if user_id cannot be found
Makes sure that get_credit_state returns None if user_id is not enrolled in the test course
Makes sure that get_credit_state returns None if the user's enrollment is inactive
Retrieve all XBlocks in the course for a particular category. Returns only XBlocks that are published and haven't been deleted.
Create a new course user group. Args: name: Name of group course_id: course id group_type: group type
Ensures that when a CohortMemebrship is deleted, the underlying CourseUserGroup has its users list updated to reflect the change as well.
Jsonify the cohorted_discussions
Un-Jsonify the cohorted_discussions
Create a complete(CourseUserGroup + CourseCohort) object. Args: cohort_name: Name of the cohort to be created course_id: Course Id course_user_group: CourseUserGroup assignment_type: 'random' or 'manual'
Returns a dictionary containing a mashup of cohort and user information for the given lists
Given a course key, return a boolean for whether or not the course is cohorted. Raises: Http404 if the course doesn't exist.
Given a course key and a user, return the id of the cohort that user is assigned to in that course.  If they don't have a cohort, return None.
Return the CourseUserGroup object for the given cohort.  Raises DoesNotExist it isn't present.
Return the CourseUserGroup object for the given cohort.  Raises DoesNotExist it isn't present.  Uses the course_key for extra validation.
Check if a cohort already exists.
Get assignment type for cohort.
Check if this cohort is the only random cohort in the course.
Return an HttpResponse with the data json-serialized and the right content type header.
Split a string both by commas and whitespace.  Returns a list.
Create cohort to partition_id/group_id link.
Add arguments to the command parser.
Enroll each user in the specified course
Return true iff a user with `username` exists in `cohort`.
Returns the static response dict.
Create a tuple storing the expected cohort information.
Verify that no cohorts are in response for a course with no cohorts.
Verify that we cannot create a cohort without specifying a name.
Verify that non-staff users cannot access `check_users_in_cohort`.
Verify that non-staff users cannot access `check_users_in_cohort`.
Verify that adding an empty list of users to a cohort has no result.
Verify that non-staff users cannot access `check_users_in_cohort`.
Verify that we get an error message when omitting a username.
Verify that we cannot access cohort_discussion_topics if we're a non-staff user.
Returns the users associated with the cohort.
Factory for constructing mock course cohort.
Given a discussion topic name, return an id for that name (includes course and url_name).
Helper method to convert a discussion topic name to a database identifier
Make sure that course is reloaded every time--clear out the modulestore.
Create a cohort for testing.
Tests get_course_cohorts returns an empty list when no cohorts exist.
Utility to create cohort -> partition group assignments in the database.
Utility for checking that our test student comes up as assigned to the specified partition (or, if None, no partition at all)
Test get_cohorted_user_partition returns None when there are no cohorted user partitions.
Verify that the staff user can masquerade as being in all groups as well as no group.
Tests that a staff member can masquerade as being in a particular group.
Return the data from a list of PathItems ready for serialization to json.
Bookmark metadata.
Return paths. Returns: list of list of PathItems.
Set paths. Arguments: value (list of list of PathItems): The list of paths to cache.
Returns names of fields which should be included in the response. Arguments: params (dict): The request parameters.
Serializer metadata.
Return the REST resource id: {username,usage_id}.
if try to create new bookmark when max limit of bookmarks already reached
Delete a bookmark. Arguments: user (User): The user of the bookmark. usage_key (UsageKey): The usage_key of the bookmark. Returns: Dict. Raises: ObjectDoesNotExist: If a bookmark with the parameters does not exist.
Return a list of bookmarks for the course for the current user. Arguments: course_key: CourseKey of the course for which to retrieve the user's bookmarks for. Returns: list of dict:
Return whether the block has been bookmarked by the user. Arguments: usage_key: UsageKey of the block. Returns: Bool
Assert that an event has been emitted.
Verifies that get_bookmark raises error as expected.
Helper method for getting the client and user and logging in. Returns client.
Helper method for sending a GET to the server. Verifies the expected status and returns the response.
Helper method for sending a POST to the server. Verifies the expected status and returns the response.
Helper method for sending a DELETE to the server. Verifies the expected status and returns the response.
Returns bookmark data for testing.
Tests creation of bookmark with display_name None.
Test XBlockCache.create() constructs and updates objects correctly.
Do a DFS and add paths info to each block_info.
Returns whether or not this user has been granted API access.Arguments: user (User): The user to check access for. Returns: bool
Returns the user's API access status, or None if they have not requested access. Arguments: user (User): The user to check access for. Returns: str or None
Approve this request.
Deny this request.
Configuration for API management.
Send request email after new record created.
Send decision email after status changed.
Return a dictionary representation of this catalog.
If the requesting user has already requested API access, redirect them to the client creation page.
View to show the API Terms of Service.
Display a form to search for catalogs belonging to a user.
Form widget to display a comma-separated list of usernames.
Parse out a comma-separated list of usernames.
Wrapper for the view function.
Verify that a logged-in can see the API request form.
Verify that users must be logged in to see the page.
Verify that users who have already requested access are redirected to the client creation page to see their status.
Verify that a logged-in user can create an API request.
Verify that the view can be disabled via ApiAccessConfig.
Verify that the view can be disabled via ApiAccessConfig.
Verify that users who have not yet requested API access are redirected to the API request form.
Verify that users must be logged in to see the page.
Verify that the view can be disabled via ApiAccessConfig.
Test that users who have not requested API access do not get it.
Generate a server-side timestamp for the upload. This is in a separate function so its behavior can be overridden in tests.
POST /api/profile_images/v1/{username}/upload
Physically remove the image files specified in `profile_image_names`
Given a PIL.Image object, return a copy with the color mode set to RGB.
Given a PIL.Image object, get a resized copy with each side being `side_length` pixels long.  The scaled image will always be square.
Given an exif value and an integer value 1-8, reflecting a valid value for the exif orientation, return a new exif with the orientation set.
Return the orientation value for the given Image object, or None if the value is not set.
Return comma separated string of valid file types.
Ensure that files outside the accepted size range fail validation.
Ensure that files whose extension is not supported fail validation.
Make sure that the specified method rejects access by unauthorized users.
Make sure we emit a UserProfile event corresponding to the profile_image_uploaded_at field changing.
Test that an anonymous client (not logged in) cannot call POST.
Make sure we emit a UserProfile event corresponding to the profile_image_uploaded_at field changing.
Test that an anonymous client (not logged in) cannot call DELETE.
Tests for the deprecated profile_image upload endpoint. Actual tests defined on DeprecatedProfileImageTestMixin
Tests for the deprecated profile_image remove endpoint. Actual tests defined on DeprecatedProfileImageTestMixin
Asserts that the logger with the given log_level was called with a string.
Asserts that the logger was not called with either a warning or an error.
Asserts that the logger was not called with a warning.
Asserts that the logger was not called with an error.
Asserts that the logger was called when signature verification failed on a SafeCookieData object, either because of a parse error or a cryptographic failure. The sig_error_string is the expected additional context logged with the error.
Asserts that the logger was called when signature verification failed on a SafeCookieData object due to a cryptographic failure.
Asserts that the logger was called upon finding that the SafeCookieData object is not bound to the expected user.
Asserts that the logger was called when the SafeCookieData object could not be parsed successfully.
Asserts that the logger was called when a SafeCookieData was created with a Falsey value for the session_id.
Asserts that warning was logged when request.user was not equal to user at response
Creates and returns a mock request object for testing.
Asserts that a session object is *not* set on the request.
Asserts that a user object is *not* set on the request's session.
Asserts that a user object *is* set on the request's session.
Calls SafeSessionMiddleware.process_response and verifies the response, while expecting the cookie to be deleted if expect_delete_called is True. See assert_response for information on the other parameters.
Transfers the cookies from the request object to the response object.
Asserts equivalency of the given cookie datas by comparing their member variables.
Replaces characters in the given signature starting at the start offset until the end offset.
An exception class for safe cookie related errors.
Factory method for creating the cryptographically bound safe cookie data for the session and the user. Raises SafeCookieError if session_id is None.
Returns a string serialization of the safe cookie data.
Computes the signature of this safe cookie data. A signed value of hash(version | session_id | user_id):timestamp with a usage-specific key derived from key_salt.
Updates the given request object to designate that the session cookie should be deleted.
Returns whether the session cookie has been designated for deletion in the given request object.
Returns whether the request has come from logout action to see if 'is_from_logout' attribute is present.
Control the logging by changing logger's level if the request is from logout.
Student login and enroll for the course
Staff login and enroll for the course
Call a ajax event (add, edit, flag, etc.) by specifying the resource it takes
Based on the given resource (specified by resource_id), this function generate a new one for testing 'edit_resource' event
Edit a non-existing resource
Check whether changing the content of resource is successful
Check whether changing the content of resource is successful in two different xblocks
Vote a non-existing resource
Vote a resource
Remove/endorse a non-existing resource
Test the function for importing all resources into the Recommender by a student.
Test the function for importing all resources into the Recommender.
Log the event, and call the original publish
Reset the mock tracker in order to forget about old events.
sequence cleanups.
Call setups of all parents
Student login and enroll for the course
Staff login and enroll for the course
Call a ajax event (add, edit, flag, etc.) by specifying the resource it takes
Call the event specified by the handler with the resource, and check whether the element (resp_key) in response is as expected (resp_val)
Concatenate the arguments into a space-separated shell command.
Runs pa11ycrawler json-to-html
The command to run tests (as a string). For this base class there is none.
Collect static assets using test_static_optimized.py which generates optimized files to a dedicated test static root.
Internal helper method to manage asset compilation
Cleans mongo afer the tests run.
Returns all JS test suites
Clean mongo test databases
Starts a single server.
Clears mongo database.
Check that mongo is running
Check that memcache is running
Check that mysql is running
Run the shell command `cmd` in a separate process, piping stdout to `out_log` (a path) and stderr to `err_log` (also a path). Terminates the process on CTRL-C or if an error occurs.
Create the directory for storing the hashes, if it doesn't exist already.
Installs Python prerequisites
Run the JavaScript tests and print results to the console
Run the JavaScript tests in your default browsers
Returns a tuple of (num_violations, violations_list) for all pep8 violations in the given report_file.
with property names in double-quotes..format(
Write a given metric to a given file Used for things like reports/metrics/jshint, which will simply tell you the number of jshint violations found
Sets a given directory to a created, but empty state
When diff-quality is run with a threshold percentage, it ends with an exit code of 1. This bubbles up to paver with a subprocess return code error. If the subprocess exits with anything other than 1, raise a paver exception.
Register files with observer
Compile CoffeeScript to JavaScript.
Process XModule static assets.
Restart the django server. `$ touch` makes the Django file watcher thinks that something has changed, therefore it restarts the server.
Collect static assets, including Django pipeline processing. `systems` is a list of systems (e.g. 'lms' or 'studio' or both) `settings` is the Django settings module to use.
Generates a har file for with page performance info.
Generate coverage reports for bok-choy tests
Ensure that 'true' will be True.
Ensure that 'false' will be False.
Ensure that 'True' will be True.
Ensure that 'False' will be False.
Ensure that '0' will be False.
Helper decorator to mock open() in pavelib.i18n. Arguments: content (str): any number of strings, which are dedented, then concatenated, and then returned as f.read() when pavelib.i18n opens a file.
Don't do anything, for replacing prerequisite tasks we want to skip.
Test the "devstack" task.
Test the "devstack" task.
Test the "run_all_servers" task.
run_safecommit_report encounters an error parsing the safecommit output log.
run_safelint encounters an error parsing the safelint output log
run_safelint finds violations, but a limit was not set
run_safelint fails when thresholds option is poorly formatted
run_jshint encounters an error parsing the jshint output log
If an invalid combination of verbosity and number of processors is passed in, a BuildFailure should be raised
Returns the messages output by the Paver task.
Returns the current platform's root directory.
Clear the recorded message
Test the "test_js_run" task.
Test the "test_js_run" task.
Return a comma-separated string of valid doc types.
Extract localizable strings from sources
Compile localizable strings from sources without re-extracting strings first.
Compile localizable strings from sources, extracting strings first.
Compile localizable strings from sources, extracting strings first. Complains if files are missing.
Push source strings to Transifex for translation
Pull translated strings from Transifex
Clean the i18n directory of artifacts
Extract new strings, and push to transifex
Push release-specific resources to Transifex.
Pull release-specific translations from Transifex.
Does this return subsets that need fancy indexing? (i.e. lists  of indices)
Does this class make use of random number generators?
Does it ensure that every batch has the same size?
Does it ensure that every batch has the same size?
Does this return subsets that need fancy indexing? (i.e. lists  of indices)  Needs to be set before initialization. See Examples section in class docs
Does this class make use of random number generators?  Needs to be set before initialization. See Examples section in class docs
base iterator that ForcedEvenIterator class wraps  Needs to be set before initialization. See Examples section in class docs
check if the batch has wrong length, throw it away
find unique lengths in sequences
stop when there are no more sequences left
pick a length from the permuted array of lengths
find the position and the size of the minibatch of sequences  to be returned
get the actual indices for the sequences
update the pointer and counts of sequences in the chosen length
Keep only the needed sources in self._raw_data.  Remember what source they correspond to in self._source
If the dataset is incompatible with the new interface, fall back to  the old one
Python 2.6 don't have usesTime() fct.  So we skip that information for them.
Cache the traceback text to avoid converting it multiple times  (it's constant anyway)
Sometimes filenames have non-ASCII chars, which can lead  to errors when s is Unicode and record.exc_text is str  See issue 8924
Do not propagate messages to the root logger.
Set the log level of our logger, either to DEBUG or INFO.
Get rid of any extant logging handlers that are installed.  This means we can call configure_custom() more than once  and have it be idempotent.
Install our custom-configured handler and formatter.
Propagate log messages upwards.
Restore the log level to its default value, i.e. logging.NOTSET.
Delete any handlers that might be installed on our logger.
key for sorting strings alphabetically with numbers
We add all the arguments to the message, to make sure that this  information isn't lost if this exception is reraised again
Delay import of pylearn2.config.yaml_parse and pylearn2.datasets.control  to avoid circular imports
Groups of Python types that are often used together in `isinstance`
If we don't do that, tests function won't be run.
Return the wrapper so this can be used as a decorator via partial()
Put together all modules with unknown versions.
The first line looks like:    changeset:   1517:a6e634b83d88
If not defined, we default to 0 because this is the default  protocol used by cPickle.dump (and because it results in  maximum portability)
dictionary to convert lush binary matrix magic numbers  to dtypes
Publish environment variables related to file name
this code should never be reached
for loading PY2 pickle in PY3
assert False
Don't attempt to guess the right name if the directory is  huge
end if  end for
don't use *=, we don't want to modify the input array
PIL is too stupid to handle single-channel arrays
Create a temporary file with the suffix '.png'.
The expression below can be re-written in a more C style as  follows :  out_shape    = [0,0]  out_shape[0] = (img_shape[0]+tile_spacing[0])*tile_shape[0] -                 tile_spacing[0]  out_shape[1] = (img_shape[1]+tile_spacing[1])*tile_shape[1] -                 tile_spacing[1]
colors default to 0, alpha defaults to 1 (opaque)
if channel is None, fill it with zeros of the correct  dtype
use a recurrent call to compute the channel and store it  in the output
if we are dealing with only one channel
generate a matrix to store the output
if we should scale values to be between 0 and 1  do this by calling the `scale_to_unit_interval`  function
Standard library imports
Third-party imports
Load as the usual ndarray
Special case for on-the-fly normalization
If there are too much features, outputs kernel matrices
Quantitize data
Store the representations in two temporary files
Reread those files and put them together in a .zip
Sparse datasets are not stored as Theano shared vars.
Prefilter features, if needed.
Valid and test representations
Convert into text info
Concatenate the sets, and give different one hot labels for valid and test
Standard library imports
Local imports
Take the first 3 columns
Examples for which any label is set
Special case for sparse matrices
Compress train and label arrays according to condition
Assumes all values are >0, which is the case for all sparse datasets.
Local shortcuts for array operations
Record external parameters
Upper bounds for each minibatch indexes
Number of rows in the resulting union
Random number generation using a permutation
Use a deterministic seed
Retrieve minibatch from chosen set  Increment the related counter  Return the computed minibatch
message has been "improved"
Right now this file just tests that the utlc module can be imported
Save current properties
Ensure that the logger didn't change
This should be fine, we have enough examples for 4 batches  (with one under-sized batch).
This should be fine, we have enough examples for 4 batches  (with one to spare).
This should fail, since you can't make 5 batches of 3 from 10.
Size of the flattened space
This Space does not contain any data, and should not  be mapped to anything
Space is a simple Space, source should be a simple source
Recursively fill the mapping, and return it
Initialize the flatten returned value with Nones
Fill rval with the auxiliary function
The corresponding space was a NullSpace,  and there is no corresponding value in flat,  we use None as a placeholder
We are at a leaf of the tree
We are at a leaf of the tree
flat is not iterable, this is valid only if spec_mapping  contains only 0's, that is, when self.n_unique_specs == 1
final result shape
unraveling
final result shape
unraveling
Avoid upcast to float64 when floatX==float32 and n_classes is int64
Initialize with threshold set to label all inputs as negative
transfer during test
put the inputs + outputs in shared variables so we don't pay GPU  transfer during test
transfer during test
transfer during test
put the inputs + outputs in shared variables so we don't pay GPU  transfer during test
make sure the test gets good coverage, ie, that it includes many  different activation probs for both detector and pooling layer
plot maps of the estimation error, this is to see if it has  some spatial pattern this is useful for detecting bugs like  not handling the border correctly, etc.
don't really know how tight this should be  but you can try to pose an equivalent problem  and implement it in another way  using a numpy implementation in softmax_acc.py  I got a max error of .17
Do exhaustive checks on just the last sample
make sure the test gets good coverage, ie, that it includes  many different activation probs for both detector and pooling layer
don't really know how tight this should be  but you can try to pose an equivalent problem  and implement it in another way  using a numpy implementation in softmax_acc.py  I got a max error of .17
Do exhaustive checks on just the last sample
make sure the test gets good coverage, ie, that it includes many  different activation probs for both detector and pooling layer
plot maps of the estimation error, this is to see if it has some  spatial pattern this is useful for detecting bugs like not handling  the border correctly, etc.
don't really know how tight this should be  but you can try to pose an equivalent problem  and implement it in another way  using a numpy implementation in softmax_acc.py  I got a max error of .17
Do exhaustive checks on just the last sample
don't really know how tight this should be  but you can try to pose an equivalent problem  and implement it in another way  using a numpy implementation in softmax_acc.py  I got a max error of .17
Do exhaustive checks on just the last sample
use a big value of alpha so mistakes involving alpha show up strong
This call should not raise any error:
This call should not raise any error:
The actual function should do exactly the same arithmetic on  integers so we should get exactly the same floating point values
Note: this is per-example mean across pixels, not the  per-pixel mean across examples. So it is perfectly fine  to subtract this without worrying about whether the current  object is the train, valid, or test set.
ddof=1 simulates MATLAB's var() behaviour, which is what Adam  Coates' code does.
If we don't do this, X.var will return nan.
Don't normalize by anything too small.
Messages that matches the flag value returned by the method
Initialise
Note that Anorm has been initialized by IsOpSym6.
[dlta_k epln_{k+1}] = [cs  sn][dbar_k    0      ]    [gbar_k  dbar_{k+1} ]   [sn -cs][alpha_k beta_{k+1}].
Update x except if it will become too big
Failed to find a suitable step length
print 'armijo'
Make sure variables are tensors otherwise strange things happen
Note: `lazy if` would make more sense, but it is not        implemented in C right now
f(x) = B*(x-a)^2 + C*(x-a) + D
Check new value of a_j
Check new value of a_j
Use <= rather than = so if there are ties  the bigger step size wins  end if obj  end for ind, alpha
end check on alpha_ind
used for statistics gathering
it is initialized to 1 to get all the means started at  data points, but then we turn it into a running average
This works if there is no output,  because the output is an empty list
x is a numpy array  x = pickle.load(open(test_path, 'rb'))
obj is a Dataset
define some common parameters
average MBCE over example rather than sum it
random point to start at
code to get log likelihood from kernel density estimator  this crashed on GPU (out of memory), but works on CPU
average over costs rather than summing
combine costs into GSNCost object  reconstruction on layer 0 with weight 1.0
classification on layer 2 with weight 2.0
turn off corruption
error indices
white block to indicate end of chain
map ids of objects we've fixed before to the fixed version, so we don't clone objects when fixing  can't use object itself as key because not all objects are hashable
ids of objects being fixed right now (we don't support cycles)
Base case: we found a shared variable, must convert it  Sabotage its getstate so if something tries to pickle it, we'll find out
pass args=[] so we can pass options to nosetests on the command line
!/usr/bin/env python
configs on sgd
supervised training
Make the termination criterion really lax so that it is quick
We'll need the serial module to save the dataset
Our raw dataset will be the CIFAR10 image dataset
We'll need the preprocessing module to preprocess the dataset
Our raw training set is 32x32 color images
First we want to pull out small patches of the images, since it's easier  to train an RBM on these
Next we contrast normalize the patches. The default arguments use the  same "regularization" parameters as those used in Adam Coates, Honglak  Lee, and Andrew Ng's paper "An Analysis of Single-Layer Networks in  Unsupervised Feature Learning"
Finally we whiten the data using ZCA. Again, the default parameters to  ZCA are set to the same values as those used in the previously mentioned  paper.
Escape potential backslashes in Windows filenames, since  they will be processed when the YAML parser will read it  as a string
copy data if don't exist
Load train data
prepare preprocessing  without batch_size there is a high chance that you might encounter memory error  or pytables crashes
apply the preprocessings to train
load and preprocess valid
load and preprocess test
The averaging math assumes batches are all same size
Train shortly and prevent saving
Train shortly and prevent saving
Run some checks on the samples, this should help catch any bugs
Now compile the full sampling update
Make shared variables representing the sampling state of the model  Seed the sampling with the data batch
There's as much layers in the DBM as there are bias vectors
Contribution from model B, at temperature beta_k
Contribution from model A, at temperature (1 - beta_k)
There's as much layers in the DBM as there are bias vectors
Contribution of biases
Initialize log-ais weights
Estimate the log-mean of the AIS weights
Perform inference
Copy into negative phase buffers to measure energy
Compute sum of likelihood for current buffer
Perform moving average of negative likelihood  Divide by len(x) and not bufsize, since last buffer might be smaller
There's as much layers in the DBM as there are bias vectors
Top-down input
Bottom-up input
Add a dummy placeholder for visible layer's weights in W_list
Depth of the DBM
For an even number of layers, we marginalize the odd layers  (and vice-versa)
Build function to compute free-energy of p_k(h1).
Possible metrics
replicate the preprocessing described in  Kai Yu's paper Improving LCC with Local Tangents
Maps a label vector to the corresponding index in <values>
shift subplots down to make more room for the text
Returns None if there is no 'blank' category (e.g. if we're using  the small NORB dataset.
Indexes into the first 5 labels, which live on a 5-D grid.
Maps 5-D label vector to a list of row indices for dataset.X, dataset.y  that have those labels.
Indexes into the row index lists returned by label_to_row_indices.
Index into grid_indices currently being edited
Hides axes' tick marks
prepends the current index's line with an arrow.
Shaves off the singleton dimensions  (batch  and channel ), leaving just 's', 0, and 1.
If dataset is big NORB, add one for the image index
increment the image index
increment one of the grid indices
some grid indices have 2 images instead of 3.
Disables left/right key if we're currently showing a blank,  and the current index type is neither 'category' (0) nor  'image number' (5)
defining azimuth, elevation, and depth
find the gradient  (it is two arrays: grad_x and grad_y)  getting the unit incident ray
get MNIST image
extract patch from texture database. Note that texture 14  does not exist.
store output details
generate binary mask for digit outline
copy contents of masked-MNIST image into background texture
this now because the image to emboss
Check if MAT files have been downloaded
equal -> compare val record entries with np.all(x == y)  allclose -> compare val record entries with np.allclose(x, y)
Load the records
Print numerical differences between the channels
Quit scanning channels that we've read all of
Obtain versions of the various Python packages.
Local imports
This will call str() on keys and values, not repr(), so unicode  objects will have the form 'blah', not "u'blah'".
Convert nested DD into nested ydict.
This will be the complete yaml string that should be executed
Instantiate an object from YAML string
print "Executing the model."  This line will call a function defined by the user and pass train_obj  to it.
Standard library imports
Third-party imports
Disable the display for the plot extension to work  An alternative is to create another training script
Local imports
Publish a variable indicating the training phase.
Execute this training phase.
Clean up, in case there's a lot of memory used that's  necessary for the next phase.
run print_monitor_cv.py main
run print_monitor_cv.py main with all=True
cleanup
no unique substring
If there is more than one channel in the monitor ask which ones to  plot
Display the codebook
end for code in codes
plot the requested channels
older saved monitors won't have epoch_record
pdb.set_trace()
'* 1.8' comse from the fact that rows take up about 1.8 times as much  space as columns, due to the title text.
Hides tickmarks
For each pixel, remove mean of 9x9 neighborhood
Scale down norm of 9x9 patch if norm is bigger than 1
Convert the .csv file to numpy
Discard header
discard any zero-padding that was used to give the batches uniform size
Convert the .csv file to numpy
Discard header
discard any zero-padding that was used to give the batches uniform size
Pick whether to iterate over visible or hidden states.
Determine in how many steps to compute Z.
configure base-rate biases to those supplied by user
check that both models have the same number of hidden units  check that both models have the same number of visible units
make sure parameters are in floatX format for GPU support
declare symbolic vars for current sample `v_sample` and temp `beta`
initialize log importance weights
insert key temperatures within
initial sample
whenever we reach a "key" beta value, log log_ais_w and  var(log_ais_w) so we can estimate log_Z_{beta=key_betas[i]} after  the fact.
generate a new sample at temperature beta_{i+1}
estimate the log-mean of the AIS weights
Initialize self._nested_data_specs, self._data_specs_mapping,  and self._flat_data_specs
If the channels have changed at all, we need to recompile the theano  functions used to compute them
need to put d back into self._datasets
If self._flat_data_specs is empty, no channel needs data,  so we do not need to call the iterator in order to average  the monitored values across different batches, we only  have to call them once.
X is a flat (not nested) tuple  end for X
Recompute the data specs, since the channels may have changed.
Get the appropriate kind of theano variable to represent the data  the model acts on
Flatten channel.graph_input and the appropriate part of  nested_theano_args, to iterate jointly over them.
Some channels may not depend on the data, ie, they might just  monitor the model parameters, or some shared variable updated  by the training algorithm, so we need to ignore the unused  input error
Patch old pickled monitors
patch old pkl files
Ask the model for the data_specs needed
Build a nested tuple from ipt, to dispatch the appropriate parts  of the ipt batch to each cost
We need three things: the value itself (raw_channels[name]),  the input variables (cost_ipt), and the data_specs for  these input variables ((spaces[i], sources[i]))
Use the last inputs from nested_ipt for the model  Note: some code used to consider that model_channels[name]  could be a a (channel, prereqs) pair, this is not supported.
Hack to deal with Theano expressions not being serializable.  If this is channel that has been serialized and then  deserialized, the expression is gone, but we should have  stored the doc  Support pickle files that are older than the doc system
Standard library imports
Third-party imports
Do not duplicate the parameters if some are shared  between layers
Build the hidden representation at each layer
Remove this from the top-level namespace.
use the milk implementation of k-means if it's available
print 'iter:',iter,' conv crit:',abs(mmd-prev_mmd)  if numpy.sum(numpy.isnan(mu)) > 0:
computing distances
mean minimum distance:
converged
finding minimum distances
One call to train_all currently trains the model fully,  so return False immediately.
Use version defined in Model, rather than Block (which raises  NotImplementedError).
Third-party imports
Parameters
only for convenience
easy way to turn off corruption (True => corrupt, False => don't)
easy way to turn off sampling
easy way to not use bias (True => use bias, False => don't)
check that autoencoders are the correct sizes by looking at previous  layer. We can't do this for the first ae, so we skip it.
activation for visible layer is aes[0].act_dec
the indices which are being set
intialize steps
main loop
handle splitting of concatenated data
things that require re-compiling everything
everything is cached, return all but state and indices
indices have changed, need to recompile f_init
have no cached function (or incorrect state)
leave out the first time step
set minibatch
Update and corrupt all of the odd layers (which we aren't skipping)
precor is before sampling + postactivation corruption (after preactivation  corruption and activation)
take values from initial
zero out values in activations
using _apply_corruption to apply samplers
Using the activation function from lower autoencoder
ACTIVATION  None implies linear
3d tensor: axis 0 is time step, axis 1 is minibatch item,  axis 2 is softmax output for label (after slicing)
convert argmax's to one-hot format
Standard library imports
taking the mean over each term independently allows for different  mini-batch sizes in the positive and negative phase.
zero mean, std sigma noise
Derived closed to Xavier Glorot's magic formula
THE BETA IS IGNORED DURING TRAINING - FIXED AT MARGINAL DISTRIBUTION
Sometimes, the number of examples in the data set is not a  multiple of self.batch_size.
sample h given v
sample v given (s,h)
Create the stack
Take care of learning rate scales for individual parameters  Base learning rate per example.
A shared variable for storing the iteration number.
A shared variable for storing the annealed base learning rate, used  to lower the learning rate gradually after a certain amount of time.
Update the shared variable for the annealed learning rate.
Calculate the learning rates for each parameter, in the order  they appear in self.params
Add the learning rate/iteration updates
Get the updates from sgd_updates, a PyLearn library function.
Add the things in p_up to ups
Return the updates dictionary.
Space initialization
Look for the right KLIntegrator if it's not specified
Sample from p(z)  Decode theta  Sample from p(x | z)
We express mu in terms of the pre-sigmoid activations. See  `log_conditional` for more details.
`conditional_params` is composed of pre-sigmoid activations; see  `log_conditional` for more details.
Standard library imports
Local imports
This module really has no adjustable parameters -- once train()  is called once, they are frozen, and are not modified via gradient  descent.
Center each feature.
Compute eigen{values,vectors} of the covariance matrix.
Build Theano shared variables  For the moment, I do not use borrow=True because W and v are  subtensors, and I want the original memory to be freed
they were doing  component_cutoff is a shared variable, so updating its value here has  NO EFFECT on the symbolic expression returned by this call (and what  this expression evalutes to can be modified by subsequent calls to  _update_cutoff)
this proprocessing is already done
The resulting components are in *ascending* order of eigenvalue, and  W contains eigenvectors in its *columns*, so we simply reverse both.
Compute feature means.
The resulting components are in *ascending* order of eigenvalue,  and W contains eigenvectors in its *rows*, so we reverse both and  transpose W.
The resulting components are in *ascending* order of eigenvalue, and  W contains eigenvectors in its *columns*, so we simply reverse both.
Can't subtract a sparse vector from a sparse matrix, apparently,  so here I repeat the vector to construct a matrix.
The resulting components are in *ascending* order of eigenvalue, and  W contains eigenvectors in its *columns*, so we simply reverse both.
Update component cutoff, in case min_variance or num_components has  changed (or both).
Total number of observations: to compute the normalizer for the mean  and the covariance.  Index in the current minibatch
Matrix containing on its *rows*:  - the current unnormalized eigen vector estimates  - the observations since the last reevaluation
The discounted sum of the observations.
Holds the unnormalized eigenvectors of the covariance matrix before  they're copied back to Xt.
Add the *non-centered* observation to Xt.
Update the discounted sum of the observations.
To get the mean, we must normalize the sum by:  \gamma^(n_observations-1) + /gamma^(n_observations-2) + ... + 1
Now center the observation.  We will lose the first observation as it is the only one in the mean.
Regularize - not necessary but in case
Convert the n_eigen LAST eigenvectors of the Gram matrix contained in  V into *unnormalized* eigenvectors U of the covariance (unnormalized  wrt the eigen values, not the moving average).
Update Xt, G and minibatch_index
We subtract self.minibatch_index in case this call is not right  after a reevaluate call.
Patch old pickle files
This is not really an unimplemented case.  We actually don't know how to format the weights  in design space. We got the data in topo space  and we don't have access to the dataset
Let the PatchViewer decide how to arrange the units  when they're not pooled  When they are pooled, make each pooling unit have one row
Let the PatchViewer decide how to arrange the units  when they're not pooled  When they are pooled, make each pooling unit have one row
note: I think the desired space thing is actually redundant,  since LinearTransform will also dimshuffle the axes if needed  It's not hurting anything to have it here but we could reduce  code complexity by removing it
Let the PatchViewer decide how to arrange the units  when they're not pooled  When they are pooled, make each pooling unit have one row
Only to be used by the deprecation warning wrapper functions
When applying dropout to a layer's input, use this for masked values.  Usually this will be 0, but certain kinds of layers may want to override  this behaviour.
check if the layer_name is None (the MLP is the outer MLP)
check the case where coeffs is a scalar
check the case where coeffs is a scalar
Patch old pickle files
because of an error in optimization (local_useless_tile)  when tiling with (1, 1)
This is not really an unimplemented case.  We actually don't know how to format the weights  in design space. We got the data in topo space  and we don't have access to the dataset
Let the PatchViewer decide how to arrange the units  when they're not pooled  When they are pooled, make each pooling unit have one row
This is not really an unimplemented case.  We actually don't know how to format the weights  in design space. We got the data in topo space  and we don't have access to the dataset
Original: p = p * (p > 0.) + self.left_slope * p * (p < 0.)  T.switch is faster.  For details, see benchmarks in  pylearn2/scripts/benchmark/time_relu.py
Format the input to be supported by max pooling
Alias the variables for pep8
Check 'not value' to support case of empty list
This is to mimic the behavior of CompositeSpace's restrict  method, which only returns a CompositeSpace when the number  of components is greater than 1
No two layers can contend to scale a parameter  Don't try to scale anything that's not a parameter
update, scaled back onto unit sphere
dot product between scaled update and current W
Standard library imports
Third-party imports
Local imports
why a theano rng? should we remove it?
Compute the input flowing into the hidden units, i.e. the  value before applying the nonlinearity/activation function  Apply the activating nonlinearity.
As long as act_enc is an elementwise operator, the Jacobian  of a act_enc(Wx + b) hidden layer has a Jacobian of the  following form.
Create the stack
Patch old pickle files
Catch classes that try to override the old method.  This check may be removed after 2015-05-13.
Quick check in case __init__ was never called, e.g. by a derived  class.
Validate num_steps
Implement the num_steps > 1 case by repeatedly calling the  num_steps == 1 case
The rest of the function is the num_steps = 1 case  Current code assumes this, though we could certainly relax this  constraint
Validate layer_to_clamp / make sure layer_to_clamp is a fully  populated dictionary
Assemble the return value
Get the sampled state of the layer below so we can condition  on it in our Gibbs update
Compute the Gibbs sampling update  Sample the state of this layer conditioned  on its Markov blanket (the layer above and  layer below)
Sample the odd-numbered layers
Get the sampled state of the layer below so we can condition  on it in our Gibbs update
Compute the Gibbs sampling update  Sample the state of this layer conditioned  on its Markov blanket (the layer above and  layer below)
Check that all layers were updated  Check that we didn't accidentally treat any other object as a layer  Check that clamping worked
Make corrections for if we're also running inference on Y
Last layer before Y does not need its weights doubled  because it already has top down input
Last layer is clamped to Y
end for mf iter  end if recurrent  Run some checks on the output
layer_above = None,
debugging, make sure V didn't get changed in this function
Originally WeightDoubling did not support multi-prediction training,  while a separate class called SuperWeightDoubling did. Now they are  the same class, but we maintain the SuperWeightDoubling class for  backwards compatibility. May be removed on or after 2015-04-20.
Y is observed, specify that it's fully observed
layer_above = None,
debugging, make sure V didn't get changed in this function
Make corrections for if we're also running inference on Y  Last layer is clamped to Y
we only need recurrent inference if there are multiple layers
Run some checks on the output
debugging, make sure V didn't get changed in this function
Make corrections for if we're also running inference on Y  Last layer is clamped to Y
we only need recurrent inference if there are multiple layers
debugging, make sure V didn't get changed in this function
The examples are used to initialize the visible layer's chains
Make sure all DBM have only one hidden layer, except for the last  one, which can have an optional target layer
This condition could be relaxed, but current code assumes it
This condition could be relaxed, but current code assumes it
Patch old pickle files
patch old pickle files
Patch pickle files that predate the freeze_set feature
No two layers can contend to scale a parameter  Don't try to scale anything that's not a parameter
Make a list of all layers
Make a list of all layers
Validate layer_to_clamp / make sure layer_to_clamp is a fully  populated dictionary
Translate update expressions into theano updates
Don't serialize the dataset
Energy function is linear so it doesn't matter if we're averaging  or not
This is not really an unimplemented case.  We actually don't know how to format the weights  in design space. We got the data in topo space  and we don't have access to the dataset
Should probably implement sum pooling for the non-pooled version,  but in reality it's not totally clear what the right answer is
Don't serialize the dataset
data is in [-1, 1], but want biases for a sigmoid  init_bias =
Energy function is linear so it doesn't matter if we're averaging  or not
Don't serialize the dataset
Energy function is linear so it doesn't matter if we're averaging or not
Patch old pickle files
This is not really an unimplemented case.  We actually don't know how to format the weights  in design space. We got the data in topo space  and we don't have access to the dataset
Let the PatchViewer decidew how to arrange the units  when they're not pooled  When they are pooled, make each pooling unit have one row
If the pool size is 1 then pools = detectors  and we should not penalize pools and detectors separately
If the pool size is 1 then pools = detectors  and we should not penalize pools and detectors separately
Should probably implement sum pooling for the non-pooled version,  but in reality it's not totally clear what the right answer is
Patch old pickle files
If you implement this case, also add a unit test for it.  Or at least add a warning that it is not tested.
patch old pickle files
patch old pickle files
we use sum and not mean because this is really one variable per row
To make GaussianVisLayer compatible with any axis ordering
If the pool size is 1 then pools = detectors  and we should not penalize pools and detectors separately
note that, within each group, E[p] is the sum of E[h]
work around theano bug with broadcasted stuff
If the pool size is 1 then pools = detectors  and we should not penalize pools and detectors separately
note that, within each group, E[p] is the sum of E[h]
scale each learning rate by 1 /  times param is reused
work around theano bug with broadcasted stuff
This is not really an unimplemented case.  We actually don't know how to format the weights  in design space. We got the data in topo space  and we don't have access to the dataset
Should probably implement sum pooling for the non-pooled version,  but in reality it's not totally clear what the right answer is
called should cache the compilation results, including those  inside cg
Temporarily change config.floatX to float64, as s3c these  tests currently fail with float32.
Restore previous value of floatX
We also have to change the value of config.floatX in __init__.
begin block
begin block
Create fake data
Construct an equivalent MLP which gives the same output  after flattening both.
Check that the two models give the same output
Check that both costs are not implemented
Skip test if cuda_ndarray is not available.
Compile in debug mode so we don't optimize out the size of the buffer  of zeros
axes for batch, rows, cols, channels, can be given in any order
rng = np.random.RandomState([2012,11,1])
axes for batch, rows, cols, channels, can be given in any order
pool_size=1 is an important corner case
This is just to placate mf_update below
To find the mean of the samples, we use mean field with an input of 0
Make DBM and read out its pieces
Choose which unit we will test
Randomly pick a v, h1[-p_idx], and h2 to condition on  (Random numbers are generated via dbm.rng)
Infer P(h1[i] | h2, v) using mean field
np.asarray(on_probs) doesn't make a numpy vector, so I do it manually
1 is an important corner case  We must also run with a larger number to test the general case
Make DBM and read out its pieces
Choose which unit we will test
Randomly pick a v, h1[-p_idx], and h2 to condition on  (Random numbers are generated via dbm.rng)
Infer P(h1[i] | h2, v) using mean field
np.asarray(on_probs) doesn't make a numpy vector, so I do it manually
1 is the only pool size for which centering is implemented
Make DBM and read out its pieces
Choose which unit we will test
Randomly pick a v, h1[-p_idx], and h2 to condition on  (Random numbers are generated via dbm.rng)
Infer P(h1[i] | h2, v) using mean field
1 is an important corner case  We must also run with a larger number to test the general case
Make DBM
Randomly pick a v to condition on  (Random numbers are generated via dbm.rng)
Infer P(y | v) using mean field
Infer P(y | v) using the energy function
np.asarray(probs) doesn't make a numpy vector, so I do it manually
Make DBM
Randomly pick a v to condition on  (Random numbers are generated via dbm.rng)
Infer P(y | v) using mean field
Infer P(y | v) using the energy function
np.asarray(probs) doesn't make a numpy vector, so I do it manually
Make DBM
Randomly pick a v to condition on  (Random numbers are generated via dbm.rng)
Infer P(y | v) using mean field
copy all the states out into a batch size of num_samples
Tests whether the returned p_sample and h_sample have the right  dimensions
Verifies that VariationalCD works well with make_layer_to_symbolic_state
Verify that get_total_input_dimension works.
Accumulate the sum of output of all masked networks.
Create network with single softmax layer, corresponding to first  layer in the composite network.
Create network with single softmax layer, corresponding to second  layer in the composite network.
Create dataset which we will test our networks against.
Train all models with their respective datasets.
Check that we get same output given the same input on a randomly  generated dataset.
Finally check that calling the internal FlattenerLayer behaves  as we would expect. First, retrieve the FlattenerLayer.
Check that it agrees on the input space.
Check that it agrees on the parameters.
Test linear layer, see the function  compare_flattener_composite_mlp_with_separate_mlps for more details
Create network with single softmax layer, corresponding to first  layer in the composite network.
Now train the three networks on the same dataset
Finally, check that we get same output given the same input on a randomly  generated dataset.
Temporarily change config.floatX to float64, as s3c inference  tests currently fail due to numerical issues for float32.
Restore previous value of floatX
We also have to change the value of config.floatX in __init__.
Second part of the check handles cases where kl is None, etc.
Recurse on the keys too, for backward compatibility.  Is the key instantiation feature ever actually used, by anyone?
In the future it might be good to consider a dict argument that provides  a type->callable mapping for arbitrary transformations like this.
This is apparently here to avoid the odd instance where a file gets  loaded as Unicode instead (see 03f238c6d). It's rare instance where  basestring is not the right call.
We know it's an ImportError, but is it an ImportError related to  this path,  or did the module we're importing have an unrelated ImportError?  and yes, this test can still have false positives, feel free to  improve it
The yaml file is probably to blame.  Report the problem with the full module path from the YAML  file
Add the custom multi-constructor
we could have also just put the corruptor definition here
yaml.load can take a string or a file object  These two things should be the same object
Assert the unsubstituted TEST_VAR is in yaml_src
Try to call theano_expr with a bad label dtype.
Try to call format with a bad label dtype.
Make sure an invalid max_labels raises an error.
Make sure an invalid dtype identifier raises an error.
Make sure an invalid ndim raises an error for theano_expr().
Print all .py files in the library
Work around Python < 2.6 behaviour, which does not generate NL after  a comment which is on a line by itself.
The line could contain multi-byte characters
assert char in '([{'
indent_next tells us whether the next block is indented; assuming  that it is indented by 4 spaces, then we should not allow 4-space  indents on the final continuation line; in turn, some other  indents are allowed to have an extra 4 spaces.
this is the beginning of a continuation line.
record the initial indent.
identify closing bracket
closing bracket for visual indent
closing bracket matches indentation of opening bracket's line
visual indent is broken
hanging indent is verified
visual indent is verified
ignore token lined up with matching one from a previous line
Syntax "class A (B):" is allowed, but avoid it  Allow "return (a.foo for a in range(5))"
ERRORTOKEN is triggered by backticks in Python 3
Found a (probably) needed space
Tolerate the "<>" operator, even if running Python 3  Deal with Python 3's annotated return value "->"
A needed trailing space was not found
Allow keyword args or defaults: foo(bar=None).
Surrounding space is optional, but ensure that  trailing space matches opening space
A needed opening space was not found
The physical line contains only this token.
The comment also ends a physical line
Results
Don't care about expected errors or warnings
The default choice: ignore controversial checks
Ignore all checks which are not explicitly selected
contain a pattern that matches?
First, read the default values
Third, overwrite with the command-line options
Don't read the command line if the module is used as a library.  If parse_argv is True and arglist is None, arguments are  parsed from the command line (sys.argv)
De-indent paragraph
string conversion routines
out += self._str_index()
Skip out-of-library inherited methods
We know scipy.sparse is available
Catches any CompositeSpace batches that were mistakenly hand-constructed  using nested lists rather than nested tuples.
Data-less batches such as None or () are valid numeric and symbolic  batches.  Justification: we'd like  is_symbolic_batch(space.make_theano_batch()) to always be True, even if  space is an empty CompositeSpace.
The subbatch_results must be all true, or all false, not a mix.
Uses the 'CudaNdarray' string to avoid importing  theano.sandbox.cuda when it is not available
theano._asarray is a safer drop-in replacement to numpy.asarray.
Checks if batch belongs to this space
checks if self and space have compatible sizes for formatting.
Checks if batch belongs to this space
When unpickling a Space that was pickled before Spaces had dtypes,  we need to set the _dtype to the default value.
checks that batch isn't a tuple, checks batch.type against self.dtype
Undo subtensor slice
checks that batch isn't a tuple, checks batch.type against self.dtype
Only batch size of 1 is supported
checks that batch isn't a tuple, checks batch.type against self.dtype
Only batch size of 1 is supported
checks that batch isn't a tuple, checks batch.type against self.dtype
Assume pylearn2's get_topological_view format, since this is how  data is currently served up. If we make better iterators change  default to ('b', 'c', 0, 1) for theano conv2d
Converts shape to a tuple, so it can be hashable, and self can be too
Patch old pickle files
checks batch.type against self.dtype
Check for cast
Check to see if axis ordering was changed
NullSpaces don't support validation callbacks, since they only take None  as data batches.
There is no way to know how many examples would actually  have been in the batch, since it is empty. We return 0.
Can't use nose.tools.assert_raises, only introduced in python 2.7. Use  numpy.testing.assert_raises instead
Sparse VectorSpaces throw an exception if batch_size is specified.
Use this when space doesn't specify a dtype
Sparse VectorSpaces throw an exception if batch_size is  specified
simple -> simple
composite -> simple
simple -> composite
no need to make CompositeSpaces with components spanning all possible  dtypes. Just try 2 dtype combos. No need to try different sparsities  either. That will be tested by the non-composite space conversions.
A few composite dtypes to try throwing at CompositeSpace's batch-making  methods.
Tests CompositeSpace's batch-making methods and dtype setter  with composite dtypes
VectorSpace and Conv2DSpace
VectorSpace to Sparse VectorSpace
Start in VectorSpace
VectorSpace and Conv2DSpace
Third-party imports
Shortcuts
for stability
generate random one-hot matrix
pass up a 0 because corruption_level is not relevant here
corruption_level isn't relevant here
pass up the 0 for corruption_level (not relevant here)
This sets to zero all elements where Y == -1
normalize for number of steps
don't include label layer
don't include features
normalize for coefficients on each cost
if there's only 1 cost, then no need to split up the costs
get space for layer i of model
get the spaces for layers that we have costs at
layer_to_chains = model.rao_blackwellize(layer_to_chains)
note: if the Y layer changes to something without linear energy,  we'll need to make the expected energy clamp Y in the positive  phase
note: if the Y layer changes to something without linear energy,        we'll need to make the expected energy clamp Y in the        positive phase
Note that we replace layer_to_chains with a dict mapping to the new  state of the chains
Note that we replace layer_to_chains with a dict mapping to the new  state of the chains
note: if the Y layer changes to something without linear energy,  we'll need to make the expected energy clamp Y in the positive  phase
Note that we replace layer_to_chains with a dict mapping to the new  state of the chains
Note that we replace layer_to_chains with a dict mapping to the new  state of the chains  We first initialize the chain by clamping the visible layer and the  target layer (if it exists)
We then do the required mcmc steps
have been a bug, where costs from lower layers got  applied to higher layers that don't implement the cost
rval['empirical_beta_min'] = empirical_beta.min()  rval['empirical_beta_mean'] = empirical_beta.mean()  rval['empirical_beta_max'] = empirical_beta.max()
ignore Y if some other cost is supervised and has made it get  passed in (can this still happen after the (space, source)  interface change?)
end if include_Y  end if both directions
end for substates  end for layers  end if act penalty
size needs to have a fixed length at compile time or the  theano random number generator will be angry
based on equation 3 of the paper  ours is the negative of theirs because  they maximize it and we minimize it
compute negative phase updates
Compute SML cost
Compute CD cost
X is theano sparse
a random pattern that indicates to reconstruct all the 1s and some of  the 0s in X
L1 penalty on activations
there is a numerical problem when using  tensor.log(1 - model.reconstruct(X, P))  Pascal fixed it.
X is theano sparse
a random pattern that indicates to reconstruct all the 1s and some of  the 0s in X
L1 penalty on activations
Handle explicitly undefined costs
If anybody knows how to add type(self) to the exception message  but still preserve the stack trace, please do so  The current code does neither
Build composite space representing all inputs
This Cost does not depend on any data, and get_data_specs does not  ask for any data, so we should not be provided with some.
Absolute value handles odd-valued p cases
To be compatible with earlier scripts,  try (self.method)_data_specs
We assume aliasing is a bug
In the case the monitor has only one channel, the channel_name can  be omitted and the criterion will examine the only channel  available. However, if the monitor has multiple channels, leaving  the channel_name unspecified will raise an error.
The countdown decreases every time the termination criterion is  called unless the channel value is lower than the best value times  the prop_decrease factor, in which case the countdown is reset to N  and the best value is updated
The optimization continues until the countdown has reached 0,  meaning that N epochs have passed without the model improving  enough.
Defined in setup(). A dict that maps Datasets in self._randomize and  self._randomize_once to zero-padded versions of their topological  views.
Central windowing of auxiliary datasets (e.g. validation sets)
maps each dataset in randomize_now to a zero-padded topological view  of its data.
For each dataset, for each image, extract a randomly positioned and  potentially horizontal-flipped window
If no tag key is provided, use the class name by default.
placeholders
More stuff to be added later. For now, we care about the best cost.
one vs. the rest
Start training an MLP with the LiveMonitoring train extension
Query for first two elements of train_objective data
Query for second element of train_objective data
Close the training process
Test not a list
Test empty list
Test bad start/end combination
4 5x5x2 images (stored in a 2x5x5x4 tensor)
no zero-padding.
Tracks the number of times on_monitor has been called
Determine what type of message was received
Create the desired permission
Set the permission
Initialize the layout
Limit the range of possible layouts
Create the list of color hue
Set the color in HSV format
Put in a matplotlib-friendly format  Convert to RGB
Keep the relevant part
Get the x axis
Put in seconds if needed
Plot the quantities
Set a default freq
fatal
benign
whatever
repeatedly remove the right-most  extension, until none is found
This file is intentionally monolithic.  It also intentionally restricts itself  to standard library modules, with no  extra dependencies.
Global variables for the whole module.
both dictionaries for fast search  (but are semantically lists)
repeatedly remove the right-most  extension, until none is found
deals with non-atomic move
an atomic move is performed  (both files are on the same device,  or the destination doesn't exist)
check if directories exist, and if not,  create them, and then fetch source.lst
not a problem if not found in a given location
file opened
not a problem if not found in a location
read from file and  create a dictionary
then read only root
replace the installed.lst in  a safe way
download to temporary was successful,  let's (try to) perform the atomic replace
file does not exist, just download!
yay! download successful!
open the tarball as read, bz2
ok, it's openable, let's expand it  yay! success!
throws CalledProcessError if return  return code is not zero.
ok, success (or not), let's unstack
readable when invoked with super-powers
remove the package from the list
install location is determined by super-powers  (so a root package can be upgraded locally!)
assign filename to cached package
runs through the .../package_name/scripts/  directory and executes the scripts in a  specific order (which shouldn't display  much unless they fail)
get names only
check what packages are in the list,  and really to be upgraded.
check if there's a date
ok, there's a newer version
no newer version, nothing to update
not installed?
ok, nothing to upgrade,  move along.
ok, nothing to upgrade,  move along.
check if in the installed.lst  then if directory actually exists  then if you have rights to remove it
ok, you may have rights to delete it
ok, nothing to remove, filenames where bad.
does nothing, no cache implemented  yet.
to remove RuntimeWarnings about how  tempfilename is unsafe.
OK, let's construct the environment  needed by dataset-get
maybe not a problem, but  FIXME: print a warning if exists,  but cannot be read (permissions)
read from file and  create a dictionary
PYLEARN2_DATA_PATH may or mayn't be defined
simplest tests
If it's iterable, we're fine. If not, it's a single callback,  so wrap it in a list.
saturate=start, so just jump straight to final momentum
mean_squared_grad := E[g^2]_{t-1}  mean_square_dx := E[(\Delta x)^2]_{t-1}
Accumulate gradient
Accumulate updates
Apply update
sum_square_grad := \sum g^2
Accumulate gradient
Compute update
Apply update
mean_squared_grad := E[g^2]_{t-1}
Store variable in self.mean_square_grads for monitoring.
Accumulate gradient
Apply update
test if force batch size and batch size
Methods of `self.cost` need args to be passed in a format compatible  with data_specs
Concatenate the name of all tensors in theano_args !?
Use standard SGD updates with fixed learning rate.
Make sure none of the parameters have bad values
Make sure none of the parameters have bad values
only the initial monitoring has happened  no learning has happened, so we can't adjust learning rate yet  just do nothing
If we keep on executing the exponentiation on each mini-batch,  we will eventually get an OverflowError. So make sure we  only do the computation until min_lr is reached.
HACK
Get the data specifications needed by the model
model.train_batch and self.train both return False when training  should terminate.
We include a cost other than SumOfParams so that data is actually  queried from the training set, and the expected number of updates  are applied.
We include a cost other than SumOfParams so that data is actually  queried from the training set, and the expected number of updates  are applied.
We include a cost other than SumOfParams so that data is actually  queried from the training set, and the expected number of updates  are applied.
begin adadelta
the value must be positive
We include a cost other than SumOfParams so that data is actually  queried from the training set, and the expected number of updates  are applied.
Implemented only so that DummyCost would work
Make the test fail if algorithm does not  respect get_input_space  Multiplying by P ensures the shape as well  as ndim is correct
Make the test fail if algorithm does not  respect get_input_space  Multiplying by P ensures the shape as well  as ndim is correct
Including a monitoring dataset lets us test that  the monitor works with supervised data
We need to include this so the test actually stops running at some point
Including a monitoring dataset lets us test that  the monitor works with unsupervised data
We need to include this so the test actually stops running at some point
including a monitoring datasets lets us test that  the monitor works with supervised data
We need to include this so the test actually stops running at some point
including this extension for saving learning rate value after each batch
including a monitoring datasets lets us test that  the monitor works with supervised data
We need to include this so the test actually stops running at some point
including this extension for saving learning rate value after each batch
including a monitoring datasets lets us test that  the monitor works with supervised data
We need to include this so the test actually stops running at some point
including a monitoring datasets lets us test that  the monitor works with supervised data
We need to include this so the test actually stops running at some point
including a monitoring datasets lets us test that  the monitor works with supervised data
We need to include this so the test actually stops running at some point
including a monitoring datasets lets us test that  the monitor works with supervised data
We need to include this so the test actually stops running at some point
including a monitoring datasets lets us test that  the monitor works with supervised data
We need to include this so the test actually stops running at some point
We need to include this so the test actually stops running at some point
including a monitoring datasets lets us test that  the monitor works with supervised data
We need to include this so the test actually stops running at some point
including a monitoring datasets lets us test that  the monitor works with supervised data
testing for bad dataset_name input
testing for bad channel_name input
We need to include this so the test actually stops running at some point
including a monitoring datasets lets us test that  the monitor works with supervised data
We need to include this so the test actually stops running at some point
including a monitoring datasets lets us test that  the monitor works with supervised data
including a monitoring datasets lets us test that  the monitor works with supervised data
We need to include this so the test actually stops running at some point
We need to include this so the test actually stops running at some point
We need to include this so the test actually stops running at some point
We need to include this so the test actually stops running at some  point
Must be seeded the same both times run_sgd is called
Synthesize dataset with a linear decision boundary
We include a cost other than SumOfParams so that data is actually  queried from the training set, and the expected number of updates  are applied.
Implemented only so that DummyCost would work
We include a cost other than SumOfParams so that data is actually  queried from the training set, and the expected number of updates  are applied.
without monitoring datasets
with uneven training datasets
with even monitoring datasets
with uneven monitoring datasets
Make the test fail if algorithm does not  respect get_input_space  Multiplying by P ensures the shape as well  as ndim is correct
including a monitoring datasets lets us test that  the monitor works with supervised data
We need to include this so the test actually stops running at some point
Must be seeded the same both times run_bgd is called
Synthesize dataset with a linear decision boundary
Synthesize dataset with a linear decision boundary
Make sure all the right methods were used to compute the updates
Make sure the load_batch callbacks were called the right amount of times
Make sure the gradient updates were run the right amount of times
Methods of `self.cost` need args to be passed in a format compatible  with their data_specs
obj_prereqs has to be a list of function f called with f(*data),  where data is a data tuple coming from the iterator.  this function enables capturing "mapping" and "f", while  enabling the "*data" syntax
msg='Conv2d{%s}'%self._message)
dot(x, A)
fixed parameters
re-arrange these random-images so that the channel data is the minor  dimension: (batch rows cols channels)
symbolic stuff
dot(x, A)  = dot(A.T, x.T).T
dot(x, A.T)  = dot(A, x.T).T
dot(A, x)  = dot(x.T, A.T).T
dot (A.T, x)  = dot(x.T, A).T
OVER-RIDE THIS
split the output rows into pieces  multiply each piece by one transform  sum the results
multiply the input by each transform  join the resuls
t.print_status()
start by computing output dimensions, size, etc
construct indices and index pointers for sparse matrix, which, when multiplied  with input images will generate a stack of image patches
compute output of linear classifier
kern is of shape: nkern x ksize*number_of_input_features  output is thus of shape: bsize*outshp x nkern
start by computing output dimensions, size, etc
construct indices and index pointers for sparse matrix, which, when multiplied  with input images will generate a stack of image patches
compute output of linear classifier
kern is of shape: nkern x ksize*number_of_input_features  output is thus of shape: bsize*outshp x nkern
imgshp contains either 2 entries (height,width) or 3 (nfeatures,h,w)  in the first case, default nfeatures to 1
construct indices and index pointers for sparse matrix, which, when multiplied  with input images will generate a stack of image patches
STALE
inshp contains either 2 entries (height,width) or 3 (nfeatures,h,w)  in the first case, default nfeatures to 1
range of output units over which to iterate
coordinates of image in "fulloutshp" coordinates
sparse matrix specifics...
loop over output image pixels
incremented every time we write something to the sparse matrix  this is used to track the ordering of filter tap coefficient in sparse  column ordering
... ITERATE OVER INPUT UNITS IN RECEPTIVE FIELD
verify if we are still within image boundaries. Equivalent to  zero-padding of the input image
convert to "valid" input space coords  used to determine column index to write to in sparse mat  determine raster-index of input pixel...
convert oy,ox values to output space coordinates
convert to row index of sparse matrix
total number of active taps (used for kmap)
BUG ALERT: scipy0.6 has bug where data and indices are written in reverse column  ordering. Explicit call to ensure_sorted_indices removes this problem
inshp contains either 2 entries (height,width) or 3 (nfeatures,h,w)  in the first case, default nfeatures to 1
construct indices and index pointers for sparse matrix
this corresponds to grad when doing convolution
Skip test if cuda_ndarray is not available.
this needs to work for older versions of theano too
not really a test, but important code to support  Currently exposes error, by e.g.:   CUDA_LAUNCH_BLOCKING=1   THEANO_FLAGS=device=gpu,mode=DEBUG_MODE   nosetests -sd test_localdot.py:TestLocalDotLargeGray.run_autoencoder
import here to fail right away
Use grad_not_implemented for versions of theano that support it
this could be implemented, but GPU case doesn't do it
frows already assigned  fcols already assigned
test only the left so that the right can be a shared variable,  and then TestGpuFilterActs can use a gpu-allocated shared var  instead.
assume default
these are the colors of the activation shells
x coordinate of center of leftmost pixel  x coordinate of center of rightmost pixel
This would be a pretty weird feature to want but I put  the interface here for compatibility with the L2 norm  constraint class.
Column 0 tests the case where a column has zero norm  Column 1 tests the case where a column is smaller than the limit  Column 2 tests the case where a column is on the limit  Column 3 tests the case where a column is too big
Column 0 tests the case where an element has zero norm  Column 1 tests the case where an element is smaller than the limit  Column 2 tests the case where an element is on the limit  Column 3 tests the case where an element is too big
and go
we define here:
load test data
process this data
This needs to come after the prepro so that it doesn't  change the pixel means computed above for toronto_prepro
assumes no preprocessing. need to make preprocessors mark the  new ranges
if the scale is set based on the data, display X oring the  scale determined by orig  assumes no preprocessing. need to make preprocessors mark  the new ranges
Actual image shape may change, e.g. after being preprocessed by  datasets.preprocessing.Downsample
Maps azimuth labels (ints) to their actual values, in degrees.
Maps a label type to its index within a label vector.
Number of labels, for each label type.
Formats data as rows in a matrix, for DenseDesignMatrix
's' is the stereo channel: 0 (left) or 1 (right)
inserts a singleton dimension where the 's' dimesion will be
Local cache seems to be deactivated
Check if a local directory for data has been defined. Otherwise,  do not locally copy the data
Make sure the file to cache exists and really is a file
Determine local path to which the file is to be cached
If the file does not exist locally, consider creating it
Check that there is enough space to cache the file
There is enough space; make a local copy of the file
Obtain a readlock on the downloaded file before releasing the  writelock. This is to prevent having a moment where there is no  lock on this file which could give the impression that it is  unused and therefore safe to delete.
Instead of only looking if there's enough space, we ensure we do not  go over max disk usage level to avoid filling the disk/partition
Register function to release the readlock at the end of the script
Make sure the lock still exists before deleting it
Locally cache the files before reading them
hdf5 handle has no ndim
extract image center, which remains dense
flatten and write to dense output matrix
start by downsampling the periphery of the images  downsample the ring with top-left corner (idx,idx) of width rd  results are written in output[start_idx:]
now restore image center in uncompressed image
now undo downsampling along the periphery  downsample the ring with top-left corner (idx,idx) of width rd  results are written in img[idx:idx+rd, idx:idx+rd]
broadcast along the width and height of the block
determine output shape
perform retina encoding on each channel separately
perform retina encoding on each channel separately
Region 2 -- right inner and left outer, excluding center nut
This will check that dtype is a legitimate dtype string.
Maps column indices of self.y to the label type it contains.  Names taken from http://www.cs.nyu.edu/~ylclab/data/norb-v1.0/
Big NORB has additional label types
Maps label type names to the corresponding column indices of self.y
The size of one side of the image
Needed for pickling / unpickling.  These are set during pickling, by __getstate__()
Get topo view from view converter.
inserts a singleton dimension where the 's' dimesion will be
We don't want to pickle the memmaps; they're already on disk.
Replace memmaps with their constructor arguments
We never want to set mode to w+, even if memmap.mode  is w+. Otherwise we'll overwrite the memmap's contents  when we open it.
This prevents self.X and self.y from being accidentally written to  after the save, thus unexpectedly changing the saved file. If the  user really wants to, they can make the memmaps writeable again  by calling setflags(write=True) on the memmaps.
Converts filename from relative to absolute path.
Reorders the shape vector to match the new axis ordering.
Reads the first two components of the version number as a floating point  number.
Locally cache the files before reading them
Copy ensures that memory is not aliased.
Defaults for iterators
data is organized as data_specs  keep self.data_specs, and convert data
Load data from .npy file
some sanity checkes
self.X_topo_space stores a "default" topological space that  will be used only when self.iterator is called without a  data_specs, and with "topo=True", which is deprecated.
convert to boolean selection
if hdf5 file does not exist make them
The table size for y is being set to [sizes[which_set], 1] since y  contains the labels. If you are using the old one-hot scheme then  this needs to be set to 10.
For consistency between experiments better to make new random stream
The original splits
.mat labels for SVHN are in range [1,10]  So subtract 1 to map labels to range [0,9]  This is consistent with range for MNIST dataset labels
load data
rescale or center if permitted
For consistency between experiments better to make new random stream
The original splits
'packed matrix': 0x1E3D4C52,
what is the rank of the tensor?
Apply transformation on raw_batch, and format it  in the requested Space
If the space is preserved, then raw_batch is already provided  in the requested space
Only one source, return_tuple is False
Apply the transformer only on the first element
0 :  aquatic_mammals  1 :  fish  2 :  flowers  5 :  household_electrical_devices  8 :  large_carnivores  9 :  large_man-made_outdoor_things  10 :  large_natural_outdoor_scenes  13 :  non-insect_invertebrates  14 :  people  15 :  reptiles  16 :  small_mammals  17 :  trees  18 :  vehicles_1  19 :  vehicles_2
limit examples returned to `example_range`
get images and cast to float32  create dense design matrix from topological view
get labels
create view converting for retrieving topological view
init the super class
perform mean and std in float64 to avoid losing  too much numerical precision
Don't import tables initially, since it might not be available  everywhere.
Get the topo_space (usually Conv2DSpace) from the  view_converter
self.X_topo_space stores a "default" topological space that  will be used only when self.iterator is called without a  data_specs, and with "topo=True", which is deprecated.
Defaults for iterators
If there is a view_converter, we have to use it to convert  the stored data for "features" into one that the iterator  can return.
Get the topo_space from the view_converter
self.X_topo_space stores a "default" topological space that  will be used only when self.iterator is called without a  data_specs, and with "topo=True", which is deprecated.
self.X_topo_space stores a "default" topological space that  will be used only when self.iterator is called without a  data_specs, and with "topo=True", which is deprecated.
Update self.data_specs with the updated dimension of self.y
Update self.X_topo_space, which stores the "default"  topological space, which is the topological output space  of the view_converter
For 1D ndarray of int labels, override the atom to integer
Maps the (0, 1, 'c') of self.shape to ('c', 0, 1)
weights view is always for display
Patch old pickle files that don't have the axes attribute.
Same for topo_space
Build a column array for y
get images and cast to floatX
get labels
convert to float for performing regression
retrieve only subset of data
strip off stupid header line they added to only the test set  strip off empty final line
verify  of examples
strip off endlines, separate entries
split data into features and targets
If there is a view_converter, we have to use it to convert  the stored data for "features" into one that the iterator  can return.
the ind of minibatch goes beyond the boundary
This needs to come after the prepro so that it doesn't change  the pixel means computed above
assumes no preprocessing. need to make preprocessors mark the new  ranges
patch old pkl files
if the scale is set based on the data, display X oring the scale  determined  by orig  assumes no preprocessing. need to make preprocessors mark the new  ranges
patch old pkl files
Subclasses that support topological view must implement this to  specify how their data is formatted.
Path substitution done here in order to make the lower-level  mnist_ubyte.py as stand-alone as possible (for reuse in, e.g.,  the Deep Learning Tutorials, or in another package).
Locally cache the files before reading them
test that train/valid/test sets load (when standardize=True).
Force double precision to compute mean and std, otherwise the test  fails because of precision.
instantiate Train object
cleanup
instantiate Train object
cleanup
instantiate Train object
cleanup
instantiate Train object
cleanup
Test loading of transfer data
Test loading of transfer data
Test that the FoveatedNORB class can be instantiated
Get a topological view as two "(b, 0, 1, c)" tensors
Use stop parameter for SmallNORB; otherwise the buildbot uses close  to 10G of RAM.
category
instance
elevation
azimuth
lighting
horizontal shift
vertical shift
lumination change
contrast change
Use of zip rather than safe_zip intentional;  norb.label_to_value_funcs will be shorter than  label_to_value_maps if norb is small NORB.
Load and create ddm from cifar100
without y:
Preparation
Testing mapback()
Testing mapback_for_viewer()
Testing adjust_for_viewer()
Testing has_targets()
Currently this test file does nothing but make sure the module can be  imported.
Test features
the settings of subtract_mean and use_norm are not relevant to  the test  std_bias = 0.0 is the only value for which there should be a risk  of failure occurring
the setting of subtract_mean is not relevant to the test  the test only applies when std_bias = 0.0 and use_std = False
Check some basics of transformation matrix
Check if preprocessed data matrix is white
Keep 3 components
Drop 2 components: result should be similar
sut is an abbreviation for System Under Test
testing whether the eigenvalues are in decreasing order
testing whether the eigenvalues are all ones
Learn PCA preprocessing and apply it to the training set  Now apply the same transformation to the test set
fix lables
fix labels
Return the batch in the original storage space
Uncompress and go through the original view converter
assert below fails when 'whiten' is True or sometimes on test  or validation set when the preprocessor was fit on train set
Analogous to DenseDesignMatrix.design_loc. If not None, the  matrices P_ and inv_P_ will be saved together in <save_path>  (or <save_path>.npz, if the suffix is omitted).
Removes the matrices from the dictionary to be pickled.
Patch old pickle files
puts matrices' items into state, overriding any colliding keys in  state.
Center data
For each pixel, remove mean of 9x9 neighborhood
Scale down norm of 9x9 patch if norm is bigger than 1
put things in pylearn2's DenseDesignMatrix format
this is uint8
Load the class names
The data is stored as uint8  If we leave it as uint8, it will cause the CAE to silently fail  since theano will treat derivatives wrt X as 0
this is uint8 but labels range should be corrected
Load the class names
this is uint8 but labels range should be corrected
this file is stored in HDF format, which transposes everything
x must be formatted as batch index, channel, topo dim 0, topo dim 1  for use with conv2d, so check what the current input space format is
Format the output based on the output space
dot(x, A.T)
Format the output based on the input space
Format the output based on the input space
local_rf_stride specified, make local_rfs on a grid
x must be formatted as channel, topo dim 0, topo dim 1, batch_index  for use with FilterActs
Format the output based on the output space
Format the output based on the input space
dot(x, sq(A).T)
image_shape=self._img_shape,  filter_shape=self._filters_shape,  kernel_stride=self._kernel_stride,  pad = self.pad  )
Format the output based on the input space
Use "self" to refer to layer from now on, so we can pretend we're  just running in the set_input_space method of the layer
Make sure cuda is available
Store the input space
conv_op has to be changed
x must be formatted as batch index, channel, topo dim 0, topo dim 1  for use with conv2d, so check what the current input space format is
Format the output based on the output space
Apply f on the `another_axes`-shaped image  Apply f_def on self.image (b,c,0,1)  transpose output to def
We set up each dataset with a different batch size  check here that we're getting the right one  Each dataset has different content, make sure we  get the right one
Use functools.wraps so that wrapped.func_name matches  fn.func_name. Otherwise nosetests won't recognize the  returned function as a test.
pyflakes gets mad if you set scipy to None here
make sure the decorator gets rid of DEBUG_MODE
make sure the decorator restores DEBUG_MODE when it's done
sum() will call theano.add on the symbolic variables
This cost does not need any data
This cost does not need any data
Model.modify_updates is used by the training algorithm to  enforce constraints after each step of learning. Here we  make sure the constraints are enforced from the start.
First check if the model is already beyond the stop criteria of  training, if so, just return directly.
We catch an exception here instead of relying on return  values for backward compatibility. Lots of extensions  exist that don't return anything, currently.
just keeping these for debugging/examination, not needed
accept less than 1% error
load data to set visible biases to ML solution
Estimate can be off when using the wrong base-rate model.
even_sequences iterator does not support specifying a fixed number  of minibatches.
Note: if the monitor starts supporting variable batch sizes,  take this out. Maybe move it to a new test that the iterator's  uneven property is set accurately  assert X.shape[0] == mon_batch_size
end if  end __call__
check that handling all these datasets did not  result in them getting serialized
mock save
make the dataset part of the model, so it will get  serialized
Unpack the data specs into two tuples
Add mask source for targets  ('targets') -> ('targets', 'targets_mask')
Initialize the parameters
W is the input-to-hidden matrix
U is the hidden-to-hidden transition matrix
b is the bias
Later we will add a noise function
Only update the state for non-masked data, otherwise  just carry on the previous state until the end
Initialize the parameters
W is the input-to-hidden matrix
b is the bias
Only update the state for non-masked data, otherwise  just carry on the previous state until the end
Initialize the parameters
W is the input-to-hidden matrix
b is the bias
These can't be wrapped
Newly added part  end of newly added part
Set a number which is not equal to batch_size for comfort debugging
Data here is [time, batch, data]
Set a number which is not equal to batch_size for comfort debugging  creating masks that have different zero values.  Non-zeros is 15 out of 20
This effectively makes this class a subclass  of the class instance that was passed in the constructor
The MLP defines f(x) = (x W)^2, with df/dW = 2 W x^2
df/dW = df/db = 20 for W = 10, x = 1, so the norm is 20 * sqrt(2)  and the gradients should be clipped to 20 / sqrt(2)
check that all of them are equal
Load data into self._data (defined in PennTreebank)
This should be fixed to allow iteration with default data_specs  i.e. add a mask automatically maybe?
The amount of braces that must be closed at the end
The amount of braces that must be closed at the end
bench.py should always be run in gpu mode so we should not need a gpu_from_host here
bench.py should always be run in gpu mode so we should not need a gpu_from_host here
The amount of braces that must be closed at the end
The amount of braces that must be closed at the end
Note : `get_scalar_constant_value` returns a ndarray not a  int
The amount of braces that must be closed at the end
Not strictly necessary I don't think
The amount of braces that must be closed at the end
The amount of braces that must be closed at the end
Computing whether the rows and columns are broadcastable requires doing  arithmetic on quantities that are known only at runtime, like the specific  shape of the image and kernel
nb mul and add by output pixed  for all outputs imagesn_stack==self.imshp[0]
The amount of braces that must be closed at the end
Must delay import to avoid circular import problem
Computing whether the rows and columns are broadcastable requires doing  arithmetic on quantities that are known only at runtime, like the specific  shape of the image and kernel
The amount of braces that must be closed at the end
We don't know anything about filter_rows or filter_cols at compile  time, so we assume they're not broadcastable.
The partial sum is just a way to specify how to compute  stuff inside the op.  It don't change the number of flops.  nb mul and add by output pixed  for all outputs imagesn_stack==self.imshp[0]
For some reason, the function called in the C code (_weightActs)  is not defined in cudaconv2.cuh, so I defined it in weight_acts.cuh
The amount of braces that must be closed at the end
gpu op
theano graph
gpu op
theano graph
Tests that running FilterActs with a non-square  kernel is an error
Tests that running FilterActs with a  of filters per  group that is not 16 is an error
Don't call verify_grad. There was problem with  the test and we already assert that 2 version  are equals.  Also, it will be slower to verify  like that then the comparison.
Proper random projection, like verify_grad does.
Proper random projection, like verify_grad does.
XXX: use verify_grad
put the inputs + outputs in shared variables so we don't pay GPU  transfer during test
put the inputs + outputs in shared variables so we don't pay GPU  transfer during test
Make sure the cuda_convnet library is compiled and up-to-date
This is needed as otherwise DebugMode will consider that  BaseActs.make_thunk do something else then the default code, and  would duplicate verification.
If already compiled, OK
If there was an error, do not try again
Else, we need CUDA
Try to actually compile
Initialize variables in convnet_available
Check if the compilation has already been done by another process  while we were waiting for the lock
Raise an error if libcuda_convnet_so is still not available
Add cuda_convnet to the list of places that are hard-coded into  compiled modules' runtime library search list.
Cast is for compatibility with default bit depth of T.iscalar  (wtf, theano?)
stack the k-th block from each layer
_folds contains a StackedBlocks instance for each CV fold
setup monitoring datasets
extensions
Train extensions
TrainCV extensions
correct proportion to correspond to a subset of the training set
correct proportion to correspond to a subset of the training set
data_subsets is an OrderedDict to maintain label order
clean up
one label
multiple labels
improper label (iterator only returns 'train' and 'test' subsets)
bogus label (not in approved list)
train the first hidden layer (unsupervised)  (test for TrainCV)
train the second hidden layer (unsupervised)  (test for TransformerDatasetCV)
train the third hidden layer (unsupervised)  (test for StackedBlocksCV)
train the full model (supervised)  (test for PretrainedLayerCV)
clean up
--test: build the docs with warnings=errors to test them (exclusive)
Make sure the appropriate 'theano' directory is in the PYTHONPATH
If your extensions are in another directory, add it here. If the directory  is relative to the documentation root, use os.path.abspath to make it  absolute, like shown here.
Add any Sphinx extension module names here, as strings. They can be extensions  coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
Add any paths that contain templates here, relative to this directory.
The suffix of source filenames.
The master toctree document.
General substitutions.
The default replacements for |version| and |release|, also used in various  other places throughout the built documents.  The short X.Y version.  The full version, including alpha/beta/rc tags.
There are two options for replacing |today|: either, you set today to some  non-false value, then it is used:  Else, today_fmt is used as the format for a strftime call.
List of documents that shouldn't be included in the build.
List of directories, relative to source directories, that shouldn't be searched  for source files.
The reST default role (used for this markup: `text`) to use for all documents.
If true, '()' will be appended to :func: etc. cross-reference text.
If true, the current module name will be prepended to all description  unit titles (such as .. function::).
If true, sectionauthor and moduleauthor directives will be shown in the  output. They are ignored by default.
The name of the Pygments (syntax highlighting) style to use.
The style sheet to use for HTML and HTML Help pages. A file of that name  must exist either in Sphinx' static/ path, or in one of the custom paths  given in html_static_path.
The name for this set of Sphinx documents.  If None, it defaults to  "<project> v<release> documentation".
A shorter title for the navigation bar.  Default is the same as html_title.
The name of an image file (within the static path) to place at the top of  the sidebar.
The name of an image file (within the static path) to use as favicon of the  docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32  pixels large.
If not '', a 'Last updated on:' timestamp is inserted at every page bottom,  using the given strftime format.
If true, SmartyPants will be used to convert quotes and dashes to  typographically correct entities.
Custom sidebar templates, maps document names to template names.
Additional templates that should be rendered to pages, maps page names to  template names.
If false, no module index is generated.
If false, no index is generated.
If true, the index is split into individual pages for each letter.
If true, the reST sources are included in the HTML build as _sources/<name>.
If true, an OpenSearch description file will be output, and all pages will  contain a <link> tag referring to it.  The value of this option must be the  base URL from which the finished HTML is served.
If nonempty, this is the file name suffix for HTML files (e.g. ".xhtml").
Output file base name for HTML help builder.
The paper size ('letter' or 'a4').
The font size ('10pt', '11pt' or '12pt').
Grouping the document tree into LaTeX files. List of tuples  (source start file, target name, title, author, document class [howto/manual]).
The name of an image file (relative to this directory) to place at the top of  the title page.
For "manual" documents, if this is true, then toplevel headings are parts,  not chapters.
Additional stuff for the LaTeX preamble.
Documents to append as an appendix to all manuals.
If false, no module index is generated.
The (maximum) number of examples in each batch. Returns  batch_size : int The (maximum) number of examples in each batch. This is either as specified via the constructor, or inferred from the dataset size and the number of batches requested.
The total number of batches that the iterator will ever return. Returns  num_batches : int The total number of batches the iterator will ever return. This is either as specified via the constructor, or inferred from the dataset size and the batch size.
The total number of examples over which the iterator operates. Returns  num_examples : int The total number of examples over which the iterator operates. May be less than the dataset size.
Whether every batch will be the same size. Returns  uneven : bool `True` if returned batches may be of differing sizes, `False` otherwise.
Number of examples that will be visited by the iterator. (May be lower than dataset_size)
Returns True if the iteration scheme has uniform batch size, False if not Parameters  mode: string A string defining an iteration scheme in _iteration_schemes Returns  boolean True if the iteration scheme has uniform batch size, False otherwise
Flushes the stream.
Equality assertion with a more informative error message. Parameters  expected : WRITEME actual : WRITEME
Asserting object identity. Parameters  expected : WRITEME actual : WRITEME
If variable has a name, returns that name. Otherwise, returns anon. Parameters  variable : tensor_like WRITEME anon : str, optional WRITEME Returns  WRITEME
Transform value into a shared variable of type floatX Parameters  value : WRITEME name : WRITEME borrow : WRITEME dtype : str, optional data type. Default value is theano.config.floatX Returns  WRITEME
Returns a constant of value `value` with floatX dtype Parameters  variable : WRITEME Returns  WRITEME
Create a subdictionary of d with the keys in keys Parameters  d : WRITEME keys : WRITEME Returns  WRITEME
Like dict_to.update(dict_from), except don't overwrite any keys. Parameters  dict_to : WRITEME dict_from : WRITEME Returns  WRITEME
Like izip, but ensures arguments are of same length
Memory free on the GPU Returns  megs_free : float Number of megabytes of memory free on the GPU used by Theano
Report being disconnected to all inputs in order to have no gradient at all. Parameters  node : WRITEME
Parameters  op : object Returns  is_block_gradient : bool True if op is a gradient-blocking op, False otherwise
A wrapper around theano.function that disables the on_unused_input error. Almost no part of pylearn2 can assume that an unused input is an error, so the default from theano is inappropriate for this project.
Constructor that will be called everytime another's class constructor is called (if the "__metaclass__ = MetaLibVersion" line is present in the other class definition). Parameters  cls : WRITEME name : WRITEME bases : WRITEME dict : WRITEME
Return version of the Python packages as a string. e.g. numpy:1.6.1 | pylearn:a6e634b83d | pylearn2:57a156beb0
Return path to a given module.
Return path to the parent directory of a given module.
Print version of the Python packages as a string. e.g. numpy:1.6.1 | pylearn:a6e634b83d | pylearn2:57a156beb0
Makes a "deep copy" of an object by serializing it and then deserializing it. Parameters  obj : object The object to clone. Returns  obj2 : object A copy of the object.
Serializes an object to a string. Parameters  obj : object The object to serialize. Returns  string : str The object serialized as a string.
Deserializes an object from a string. Parameters  s : str The object serialized as a string. Returns  obj : object The object.
Makes sure Image has been imported from PIL
Scales image down to shape. Preserves proportions of image, introduces black letterboxing if necessary. Parameters  image : WRITEME shape : WRITEME Returns  WRITEME
Saves an image to a file. Parameters  filepath : str The path to write the file to. ndarray : ndarray An array containing the image to be saved.
Scales all values in the ndarray ndar to be between 0 and 1 Parameters  ndar : WRITEME eps : WRITEME Returns  WRITEME
Raises a TypicalMemoryError if the MemoryError has no messages Parameters  error: MemoryError An instance of MemoryError msg: string A message explaining what possibly happened
Try to retrieve key from dict1 if exists, otherwise try with dict2. If the key is not found in any of them, raise an exception. Parameters  dict1 : dict WRITEME dict2 : dict WRITEME key : WRITEME default : WRITEME Returns  WRITEME
Function that loads the dataset into shared variables
Return length of the weighted union
Same generator as __iter__, but yield only the chosen indexes
A dummy test that instantiates a TypicalMemoryError to see if there is no bugs.
Tests that pylearn2.utils.contains_nan correctly identifies `np.nan` values in an array.
Return the first keyParameters  obj: dict-like object
NumpPy implementation of the softmax function. Parameters  x : ndarray Should have two dimensions Returns  rval : ndarray rval[i,:] is the softmax of x[i,:]
NumPy implementation of a pseudo-inverse of the softmax function. Parameters  x : vector Returns  y : vector softmax(y) = x Notes  This problem is underdetermined, so we also impose y.mean() = 0
NumPy implementation of the logistic sigmoid function. Parameters  x : ndarray Arguments to the logistic sigmoid function Returns  y : ndarray The output of the logistic sigmoid function applied element-wise to x
NumPy implementation of the inverse of the logistic sigmoid function. Parameters  x : ndarray An array of values in the interval (0, 1) Returns  y: ndarray An array of values such that sigmoid_numpy(y) ~=~ x
Computes the precision for the binary decisions. Computed as tp/(tp + fp). Parameters  tp : Variable True positives. fp : Variable False positives. Returns  precision : Variable Precision of the binary classifications.
Computes the recall for the binary classification. Parameters  y : Variable Targets for the binary classifications. tp : Variable True positives. Returns  recall : Variable Recall for the binary classification.
Tests that arg_of_sigmoid works when given a good input.
The toy dataset is only meant to used for testing pipelines. Do not try to visualize weights on it. It is not picture and has no color channel info to support visualization
Executes the the main_loop() Parameters  yaml_file: string Configuration yaml
Show or save weights to an image for a pickled model Parameters  model_path : str Path of the model to show weights for rescale : str WRITEME border : bool, optional WRITEME out : str, optional Output file to save weights to
Get mapped batch if 'mapback_for_viewer' is available with the dataset. Parameters  dataset: pylearn2 dataset design_batch: numpy array
Load given model. Parameters  model_path: str Path of the model to load. m: int Size of the batch.
Adjust the shape of the grid to show. Parameters  m: int Number of visible chains.
Add the patches to show. Parameters  grid_shape: tuple The shape of the grid to show. vis_chains: numpy array Visibles chains. m: int Number of visible chains.
Show the matrix product of 2 layers. Parameters  W1: list First hidden layer. W2: list Second hidden layer. out_prefix: str Path where to save image.
Load given model. Parameters  model_path: str Path of the model to load. m: int Size of the batch.
Convert PIL.Image to numpy.ndarray. :param img: numpy.ndarray
Convert numpy.ndarray to PIL.Image :param arr: numpy.ndarray :param os: integer, size of output image.
Delete the pickle file created for the tests
Test the show_negative_chains script main function
Train a higher order contractive autoencoder for a single epoch
relu implementation with T.maximum Parameters  x: tensor variable
Alternative relu implementation Parameters  x: tensor variable
Alternative relu implementation. The most efficient one. Parameters  x: tensor variable
Returns the number of batches the model has learned on (assuming that the learning code has been calling Monitor.report_batch correctly).
Call this whenever the model has learned on another batch of examples. Report how many examples were learned on. Parameters  num_examples : int The number of examples learned on in this minibatch.
Call this whenever the model has completed another "epoch" of learning. We regard one pass through Dataset.iterator as one epoch.
Register names of fields that should be deleted before pickling. Parameters  names : list A list of attribute names as strings.
Add a new layer on top of the last one Parameters  layer : WRITEME
Returns the log probability of a batch of examples. Parameters  X : WRITEME The examples whose log probability should be computed. Returns  log_prob : WRITEME The log probability of the examples.
Returns the free energy of a batch of examples. Parameters  X : WRITEME The examples whose free energy should be computed. Returns  free_energy : WRITEME The free energy of the examples.
Initialize the biases of the mapping units.
Initialize the biases of the first set of visible units.
Initialize the biases of the second set of visible units.
Applies the filters wxf to the first input and returns the corresponding factors
Applies the filters wyf to the second input and returns the corresponding factors
Returns the mapping units.
Single minibatch activation function. Parameters  inputs : tensor_like Theano symbolic representing the input minibatch that consists of a tuple of spaces with sizes (nviX, nvisY). Returns  y : tensor_like (Symbolic) hidden unit activations given the input.
Returns the factors corresponding to the mapping units.
This just aliases the `_hidden_activation()` function for syntactic sugar/convenience.
Returns how many layers the GSN has.
Utility method that calculates how much walkback is needed to get at at least 'trials' samples. Parameters  trials : WRITEME
Get the data_specs describing the data for get_monitoring_channel. This implementation returns specification corresponding to unlabeled inputs. Returns  WRITEME
Wrapper around mean_h_given_v method.  Called when RBM is accessed by mlp.HiddenLayer.
Forward propagate (symbolic) input through this module, obtaining a representation to pass on to layers above. This just aliases the `mean_h_given_v()` function for syntactic sugar/convenience.
Return symbolic updates to apply.
Returns the weights of the first layer of the decoding network
Returns the model's prior distribution parameters
Returns the model's conditional distribution parameters
Returns the model's posterior distribution parameters
Maps input `X` to a tuple of parameters of the :math:`q_\\phi(\\mathbf{z} \\mid \\mathbf{x})` posterior distribution Parameters  X : tensor_like Input Returns  phi : tuple of tensor_like Tuple of parameters for the posterior distribution
Maps latent variable `z` to a tuple of parameters of the :math:`p_\\theta(\\mathbf{x} \\mid \\mathbf{z})` distribution Parameters  z : tensor_like Latent sample Returns  theta : tuple of tensor_like Tuple of parameters for the conditional distribution
Returns parameters of the prior distribution :math:`p_\\theta(\\mathbf{z})`
Given a tuple of parameters of the :math:`p_\\theta(\\mathbf{x} \\mid \\mathbf{z})` distribution, returns the expected value of `x`. Parameters  theta : tuple of tensor_like Tuple of parameters for the conditional distribution Returns  means : tensor_like Expected value of `x`
Computes an approximation of :math:`\\mathrm{E}_{q_\\phi(\\mathbf{z} \\mid \\mathbf{x})} [\\log p_\\theta(\\mathbf{x} \\mid \\mathbf{z})]` Parameters  X : tensor_like Input theta : tuple of tensor_like Tuple of parameters for the conditional distribution Returns  expectation_term : tensor_like Expectation term
Given a tuple of parameters, samples from the :math:`p_\\theta(\\mathbf{x} \\mid \\mathbf{z})` conditional distribution Parameters  num_samples : int Number of samples theta : tuple of tensor_like Tuple of parameters for the conditional distribution Returns  x : tensor_like Samples
Samples from the prior distribution :math:`p_\\theta(\\mathbf{z})` Parameters  num_samples : int Number of samples Returns  z : tensor_like Sample from the prior distribution
Samples from a canonical noise distribution from which posterior samples will be drawn using the reparametrization trick (see `_sample_from_q_z_given_x`) Parameters  shape : tuple of int Shape of the requested samples Returns  epsilon : tensor_like Noise samples
Computes the log-prior probabilities of `z` Parameters  z : tensor_like Posterior samples Returns  log_p_z : tensor_like Log-prior probabilities
Computes the log-conditional probabilities of `X` Parameters  X : tensor_like Input theta : tuple of tensor_like Tuple of parameters for the contitional distribution Returns  log_p_x_z : tensor_like Log-prior probabilities
Returns the VAE that this `Prior` instance belongs to, or None if it has not been assigned to a VAE yet.
Initialize model parameters. Parameters  nhid : int Number of latent units for z
Get monitoring channels from the parameters of the prior distribution. By default, no monitoring channel is computed.
Samples from the prior distribution :math:`p_\\theta(\\mathbf{z})` Parameters  num_samples : int Number of samples Returns  z : tensor_like Sample from the prior distribution
Computes the log-prior probabilities of `z` Parameters  z : tensor_like Posterior samples Returns  log_p_z : tensor_like Log-prior probabilities
Returns its MLP's weights
Returns the encoding model's learning rate scalers
Returns a default `Layer` mapping the MLP's last hidden representation to parameters of the conditional distribution
Returns the expected output space of the MLP, i.e. a description of how the parameters output by the MLP should look like.
Get monitoring channels from the parameters of the conditional distribution. By default, no monitoring channel is computed. Parameters  conditional_params : tuple of tensor_like Parameters of the conditional distribution
Modifies the parameters before a learning update is applied. By default, only calls the MLP's `modify_updates` method.
Returns the VAE that this `Conditional` instance belongs to, or None if it has not been assigned to a VAE yet.
Maps input `X` to a tuple of parameters of the conditional distribution Parameters  X : tensor_like Input Returns  conditional_params : tuple of tensor_like Tuple of parameters for the conditional distribution
Given parameters of the conditional distribution, returns the expected value of a in p(a | b). Parameters  conditional_params : tuple of tensor_like Tuple of parameters for the conditional distribution
Given the conditional parameters, computes the log-conditional probabilities of samples of this distribution. Parameters  samples : tensor_like Conditional samples conditional_params : tuple of tensor_like Tuple of parameters for the conditional distribution Returns  log_conditonal : tensor_like Log-conditional probabilities
Computes the KL-divergence term of the VAE criterion. Parameters  phi : tuple of tensor_like Parameters of the distribution :math:`q_\\phi(\\mathbf{z} \\mid \\mathbf{x})` theta : tuple of tensor_like Parameters of the distribution :math:`p_\\theta(\\mathbf{z})`
Compute and return eigen{values,vectors} of X's covariance matrix. Parameters  X : WRITEME Returns  All eigenvalues in decreasing order matrix containing corresponding eigenvectors in its columns
Returns a compiled theano function to compute a representation Parameters  name : str WRITEME
Returns a compiled theano function to compute a representation Parameters  name : str WRITEME Returns  WRITEME
Returns  rval : str A string representation of the object. In this case, just the class name.
Returns the MLP that this layer belongs to. Returns  mlp : MLP The MLP that this layer belongs to, or None if it has not been assigned to an MLP yet.
Assigns this layer to an MLP. This layer will then use the MLP's random number generator, batch size, etc. This layer's name must be unique within the MLP. Parameters  mlp : MLP
Does the forward prop transformation for this layer. Parameters  state_below : member of self.input_space A minibatch of states of the layer below. Returns  state : member of self.output_space A minibatch of states of this layer.
Freezes some of the parameters (new theano functions that implement learning will not use them; existing theano functions will continue to modify them). Parameters  parameter_set : set Set of parameters to freeze.
Get the total number of inputs to the layers whose names are listed in `layers`. Used for computing the total number of dropout masks. Parameters  layers : WRITEME Returns  WRITEME
Computes self.cost, but takes data=(X, Y) rather than Y_hat as an argument. This is just a wrapper around self.cost that computes Y_hat by calling Y_hat = self.fprop(X) Parameters  data : WRITEME
Returns the data specs needed by cost_from_X. This is useful if cost_from_X is used in a MethodCost.
Applies the nonlinearity over the convolutional layer. Parameters  linear_response: Variable linear response of the layer. Returns  p: Variable the response of the layer after the activation function is applied over.
Notes  Mean squared error across examples in a batch
Parameters  left_slope : float, optional left slope for the linear response of the rectifier function. default is 0.0.
Applies the rectifier nonlinearity over the convolutional layer.
Applies the sigmoid nonlinearity over the convolutional layer.
Applies the tanh nonlinearity over the convolutional layer.
Notes  The cost method calls `self.nonlin.cost`
Returns the marginal precision of the targets in a dataset. Parameters  dataset : DenseDesignMatrix A DenseDesignMatrix with a targets field `y` kwargs : dict Extra arguments to `beta_from_design` Returns  beta : ndarray A 1-D vector containing the marginal precision of the *targets* in `dataset`.
Returns the marginal precision of the features in a dataset. Parameters  dataset : DenseDesignMatrix The dataset to compute the precision on. kwargs : dict Passed through to `beta_from_design` Returns  beta : ndarray Vector of precision values for each feature in `dataset`
Returns the mean of the targets in a dataset. Parameters  dataset : DenseDesignMatrix Returns  mn : ndarray A 1-D vector with entry i giving the mean of target i
Dummy replacement for `sklearn.multiclass.OneVsRestClassifier`. Parameters  estimator : see `sklearn` doc. See `sklearn` doc. Notes  This class is a dummy class included so that sphinx can import DenseMulticlassSVM and document it even when sklearn is not installed.
Fit underlying estimators. Parameters  X : array-like, shape = [n_samples, n_features] Data. y : array-like, shape = [n_samples] or [n_samples, n_classes] Multi-class targets. An indicator matrix turns on multilabel classification. Returns  self
Get the data_specs describing the data for get_monitoring_channel. This implementation returns specification corresponding to unlabeled inputs. WRITEME: Returns section
Returns the variational parameter for the variance of s given h=1. This is data-independent so its just a vector of size (nhid,) and doesn't take any arguments Returns  WRITEME
Forward propagate (symbolic) input through this module, obtaining a representation to pass on to layers above. This just aliases the `encode()` function for syntactic sugar/convenience.
Single minibatch activation function. Parameters  x : tensor_like Theano symbolic representing the input minibatch. Returns  y : tensor_like (Symbolic) hidden unit activations given the input.
Given a single minibatch, computes the input to the activation nonlinearity without applying it. Parameters  x : tensor_like Theano symbolic representing the input minibatch. Returns  y : tensor_like (Symbolic) input flowing into the hidden layer nonlinearity.
Wrapper to Autoencoder encode function. Called when autoencoder is accessed by mlp.PretrainedLayer Parameters  inputs : WRITEME Returns  WRITEME
Returns the default cost to use with this model. Returns  default_cost : Cost The default cost to use with this model.
If train_all is used to train the model, this method is used to determine when the training process has converged. This method is called after the monitor has been run on the latest parameters. Returns  rval : bool True if training should continue
Sets the batch size used by the model. Parameters  batch_size : int If None, allows the model to use any batch size.
Returns true if the model overrides censor_updates. (It shouldn't do so because it's deprecated, and we have to take special action to handle this case)
Deprecated method. Callers should call modify_updates instead. Subclasses should override _modify_updates instead. This method may be removed on or after 2015-05-25. Parameters  updates : dict A dictionary mapping shared variables to symbolic values they will be updated to.
Returns an instance of pylearn2.space.Space describing the format of the vector space that the model operates on (this is a generalization of get_input_dim)
Returns an instance of pylearn2.space.Space describing the format of the vector space that the model outputs (this is a generalization of get_output_dim)
Returns an instance of pylearn2.space.Space describing the format of that the targets should be in, which may be different from the output space. Calls get_output_space() unless _target_space exists.
Returns a string, stating the source for the input. By default the model expects only one input source, which is called 'features'.
Returns a string, stating the source for the output. By default the model expects only one output source, which is called 'targets'.
Sets the values of the parameters that define the model Parameters  values : list list of ndarrays borrow : bool The `borrow` flag to use with `set_value`.
Returns all parameters flattened into a single vector. Returns  params : ndarray 1-D array of all parameter values.
Returns the number of visible units of the model. Deprecated; this assumes the model operates on a vector. Use get_input_space instead. This method may be removed on or after 2015-05-25.
Returns the number of visible units of the model. Deprecated; this assumes the model operates on a vector. Use get_input_space instead. This method may be removed on or after 2015-05-25.
Enforces all constraints encoded by self.modify_updates.
Associates the SamplingProcedure with a specific DBM. Parameters  dbm : pylearn2.models.dbm.DBM instance The model to perform sampling from.
Associates the InferenceProcedure with a specific DBM. Parameters  dbm : pylearn2.models.dbm.DBM instance The model to perform inference in.
Get all layers in this model. Returns  layers : list
Perform mean field inference, using the model's inference procedure.
Set the random number generator for the model.
Set the inference procedure for the model. Default using `WeightDoubling`
Set the sampling procedure for the model. Default using `GibbsEvenOdd`
Get the data_specs describing the data for get_monitoring_channel. This implementation returns specification corresponding to unlabeled inputs.
Reconstruct the visible variables. Returns  recons : tensor_like Unmasked reconstructed visible variables.
Returns the DBM that this layer belongs to, or None if it has not been assigned to a DBM yet.
Assigns this layer to a DBM. Parameters  dbm : WRITEME
Returns the Space that the layer's total state lives in.
Returns a shared variable containing an actual state (not a mean field state) for this variable. Parameters  num_examples : WRITEME numpy_rng : WRITEME Returns  WRITEME
Returns a theano symbolic variable containing an actual state (not a mean field state) for this variable. Parameters  num_examples : WRITEME numpy_rng : WRITEME Returns  WRITEME
Some layers' initialization depends on layer above being initialized, which is why this method is called after `set_input_space` has been called.
Returns the total state of the layer. Returns  total_state : member of the input space The total state of the layer.
Returns  biases : ndarray The numpy value of the biases
Set mean parameter Parameters  bias: WRITEME Vector of size nvis
Returns beta, broadcasted to have the same shape as a batch of data
A layer that we build for the test that just uses a state as its downward message.
A dummy DBM for some of the tests below.
A layer that we build for the test that just uses a state as its downward message.
A layer that we build for the test that just uses a state as its downward message.
Set up test for DenseMulticlassSVM. Imports DenseMulticlassSVM if available, skips the test otherwise.
Tests that UntiedAutoencoder calls the Model superclass constructor
A Model that exercises this test by having a few different parameters with different shapes and dimensionalities. Don't instantiate more than one of these because the parameters are class-level attributes.
Prior.set_vae raises an exception if it has already been called
DiagonalGaussianPrior.initialize_parameters works without crashing
DiagonalGaussianPrior.sample_from_p_z works without crashing
DiagonalGaussianPrior.log_p_z works without crashing
Conditional rejects non-nested MLPs
VAE trains properly with the VAE cost
Return a hash based on the object ID (to avoid hashing unhashable namedtuple elements).
Callback used by PyYAML when a "!import:" tag is encountered.
Callback used by PyYAML when a "!import <str>" tag is encountered. This tag exects a (quoted) string as argument.
Callback used by PyYAML when a "!float <str>" tag is encountered. This tag exects a (quoted) string as argument.
given a file path to a json file, returns the dictionary definde by the json file
given a dictionary d, returns the object described by the dictionary
Returns a list of all files in pylearn2 with the given suffix. Parameters  suffix : str Returns  file_list : list A list of all files in pylearn2 whose filepath ends with `suffix`
JCR: Trailing blank lines are superfluous. Okay: spam(1) W391: spam(1)\n
JCR: The last line should have a newline. Reports warning W292.
The {}.has_key() method is removed in the Python 3. Use the 'in' operation instead. Okay: if "alph" in d:\n    print d["alph"] W601: assert d.has_key('alph')
Backticks are removed in Python 3. Use repr() instead. Okay: val = repr(1 + 2) W604: val = `1 + 2`
Check if patterns contains a pattern that matches filename. If patterns is unspecified, this always returns True.
Register all globally visible functions where the first argument name is 'physical_line' or 'logical_line'.
Run a check plugin.
Start the timer.
Stop the timer.
Signal a new logical line.
Return the count of errors and warnings for this file.
Return the total count of errors and warnings.
Print overall statistics (number of errors and warnings).
Collect the results of the checks and print only the filenames.
Signal a new file.
Initialize the report instance.
Run all checks on a Python source file.
Test if docstrings are well formatted.
Returns True if batch is a symbolic variable. Note that a batch may be both a symbolic and numeric variable (e.g. () for empty CompositeSpaces, None for NullSpaces).
Returns true iff space.format_as(batch, self) and space.format_as(batch, other) return the same formatted batch.
Returns the batch axis of the output space. Returns  batch_axis : int the axis of the batch in the output space.
Returns the origin in this space. Returns  origin : ndarray An NumPy array, the shape of a single points in this space, representing the origin.
An alias to make_theano_batch
Runs all validate_callbacks, then checks that batch lies in this space. Raises an exception if the batch isn't symbolic, or if any of these checks fails. Parameters  batch : a symbolic (Theano) variable that lies in this space.
Returns the batch size of a symbolic batch. Parameters  batch : WRITEME
Returns the batch size of a numeric (numpy/scipy.sparse) batch. Parameters  batch : WRITEME
Returns the batch size of a batch. Parameters  batch : WRITEME
Returns a batch of data starting from index `start` to index `stop` Parameters  data : WRITEME start : WRITEME end : WRITEME
Return a string representation
Returns True if space can contain no data.
Creates a nested tuple tree that mirrors the tree structure of <space>, populating the leaves with <dtype>.
Returns a compsite space with a particular tree structure.
Returns the (nested) shape(s) of a (nested) batch.
Returns True iff space has a completely specified dtype.
Returns dtype, with any Nones replaced by fallback_dtype.
Returns whether a space or a batch has a complex dtype.
The partition function makes this intractable. Parameters  model : DBM data : Batch in get_data_specs format
Computes the positive phase using Gibbs sampling. Returns  gradients : OrderedDict A dictionary mapping parameters to positive phase gradients. updates : OrderedDict An empty dictionary
The partition function makes this intractable. Parameters  model : Model data : Minibatch in get_data_specs format Returns  None : (Always returns None)
Computes `h` from the NCE paper. Parameters  X : Theano matrix Batch of input data model : Model Any model with a `log_prob` method. Returns  h : A theano symbol for the `h` function from the paper.
Computes `G` from the NCE paper. Parameters  X : Theano matrix Batch of input data model : Model Any model with a `log_prob` method. Returns  G : A theano symbol for the `G` function from the paper.
The cost of returning `output` when the truth was `target` Parameters  target : Theano tensor The ground truth output : Theano tensor The model's output
The cost of reconstructing `data` using `model`. Parameters  model : a GSN data : a batch of inputs to reconstruct. args : evidently ignored? kwargs : optional keyword arguments For use with third party TrainingAlgorithms or FixedVarDescr
Provides an implementation of `Cost.expr`. Returns data specifications corresponding to not using any data at all. Parameters  model : pylearn2.models.Model
Parameters  variables : list list of tensor variables to be regularized p : int p in "L-p penalty"
Returns True if training should continue for this model, False otherwise Parameters  model : a Model instance Returns  bool True or False as described above
Returns the best parameters up to now for the model.
Verifies that the zmq module is present. If not, raises SkipTest.
Function that trains an MLP for testing the Live Monitoring extension.
Test RocAucChannel.
Test one vs. rest RocAucChannel.
An empty model.
A mock object for MonitorChannel.
Method that instantiates a response message for a given request message. It is not necessary to implement this function on response messages.
A message containing the list of channels being monitored.
A message indicating a request for a list of channels being monitored.
Setup the plotters. Parameters  model : pylearn2.models.Model The model trained dataset : pylearn2.datasets.Dataset The dataset on which the model is trained algorithm : pylearn2.training_algorithms.TrainingAlgorithm The algorithm the model is trained with
The method that draw and save the desired figure, which depend on the object and its attribute. This method is called by the PlotManager object as frequently as the `freq` attribute defines it.
Make the produced files readable by everyone. Parameters  public : bool If public is True, then the associated files are readable by everyone.
Takes a local, OS-specific path or filename and transforms it into an url starting with file:// (it simplifies a lot of things). :param filename: a relative or absolute pathname :returns: the urlified absolute path
Determines whether or not the program is run as root. :returns: true if run as root, false otherwise
Checks if both files reside on the same FS device
Simple hook to show download progress. caveat: not that great-looking, fix later to a cooler progress bar or something.
Performs some amount of training, generally one "epoch" of online learning Parameters  dataset : object Object implementing the dataset interface defined in `pylearn2.datasets.dataset.Dataset`. Returns  None
Return True to continue learning. Called after the Monitor has been run on the latest parameters so the monitor may be used to determine convergence. Parameters  model : WRITEME
An exception raised when the user does not specify a batch size anywhere.
Activates monitoring of the momentum. Parameters  monitor : pylearn2.monitor.Monitor Monitor object, to which the rule should register additional monitoring channels. monitoring_dataset : pylearn2.datasets.dataset.Dataset or dict Dataset instance or dictionary whose values are Dataset objects.
Returns True if the algorithm should continue running, or False if it has reached convergence / started overfitting and should stop. Parameters  model : a Model instance
Returns the current desired learning rate according to the annealing schedule.
Updates the learning rate based on the linear decay schedule. Parameters  model : a Model instance dataset : Dataset algorithm : WRITEME
To be called after each SGD step. Updates the Polyak averaged-parameters for this model Parameters  algorithm : WRITEME
Return a rectangle (height, width) with area N that is closest to square. Parameters  N : int WRITEME Returns  WRITEME
Return True iff any a in `args` is a theano Variable
This function returns (zlike) transpose(W(y)) Parameters  zlike : WRITEME *inputs_1_to_n : WRITEME Returns  WRITEME
Sets the shape of the display (in pixels) Parameters  shape : tuple The (rows, columns) of the display.
A dummy model that has some weights. Parameters  W : 2-D theano shared The model's weights.
Returns the category string corresponding to an integer category label.
Returns the elevation, in degrees, corresponding to an integer elevation label.
Reads 4 bytes from file, returns it as a 32-bit integer.
Return free usage about the given path, in bytes Parameters  path : string Folder for which to return disk usage Returns  output : tuple Tuple containing total space in the folder and currently used space in the folder
Returns the aliases (if defined, sources otherwise) provided when the HDF5 object was created Returns  A string or a list of strings.
Returns the Space(s) associated with the aliases (or sources) specified when the HDF5 object has been created. Returns  A Space or a list of Spaces.
Returns the item corresponding to a key or an alias. Parameter  key_or_alias: any valid key for a dictionary A key or an alias.
Returns a batch formatted to a space. Parameters  batch : ndarray The batch to format space : a pylearn2.space.Space The target space to format to.
Called by DenseDesignMatrix.get_formatted_view(), get_batch_topo() Parameters  design_mat : ndarray
Called by DenseDesignMatrix.get_weights_view() Parameters  design_mat : ndarray
Used by DenseDesignMatrix.set_topological_view(), .get_design_mat() Parameters  topo_batch : ndarray
Returns the category name represented by a category label int. Parameters  label: int Category label.
Returns the instance value corresponding to a lighting label int. The value is the int itself. This just sanity-checks the label for range errors. Parameters  label: int Instance label.
Returns the angle in degrees represented by a elevation label int. Parameters  label: int Elevation label.
Returns the value corresponding to a lighting label int. The value is the int itself. This just sanity-checks the label for range errors. Parameters  label: int Lighting label.
Returns the value corresponding to a horizontal shift label int. The value is the int itself. This just sanity-checks the label for range errors. Parameters  label: int Horizontal shift label.
Returns the value corresponding to a vertical shift label int. The value is the int itself. This just sanity-checks the label for range errors. Parameters  label: int Vertical shift label.
Returns the value corresponding to a lumination change label int. The value is the int itself. This just sanity-checks the label for range errors. Parameters  label: int Lumination change label.
Returns the float value represented by a contrast change label int. Parameters  label: int Contrast change label.
Returns the float value represented by a scale change label int. Parameters  label: int Scale change label.
Returns the value corresponding to a rotation change label int. The value is the int itself. This just sanity-checks the label for range errors. Parameters  label: int Rotation change label.
Adjusts the data to be compatible with a viewer that expects values to be in [-1, 1]. Parameters  X : numpy.ndarray Data
Adjusts the data to be compatible with a viewer that expects values to be in [-1, 1]. Parameters  X : numpy.ndarray Data other : WRITEME per_example : WRITEME
Returns the data_specs specifying how the data is internally stored. This is the format the data returned by `self.get_data()` will be.
Get an iterator for this dataset. The FiniteDatasetIterator uses indexing that is not supported by HDF5 datasets, so we change the class to HDF5DatasetIterator to override the iterator.next method used in dataset iteration. Parameters  WRITEME
unpack a 4-byte integer from the current position in file f
Makes sure tables module has been imported
Returns all the data, as it is internally stored. The definition and format of these data are described in `self.get_data_specs()`. Returns  data : numpy matrix or 2-tuple of matrices The data
The index of the axis of the batches Returns  axis : int The axis of a topological view of this dataset that corresponds to indexing over different examples.
This function splits the dataset into to the number of n folds given by the user. Returns an array of folds. Parameters  nfolds : int, optional The number of folds for the  the validation set. Returns  WRITEME
This function splits the dataset using the random_slice and into the n folds. Returns the folds. Parameters  nfolds : int The number of folds for the  dataset. rng : WRITEME Random number generation class to be used.
If we view the dataset as providing a stream of random examples to read, the object returned uniquely identifies our current position in that stream.
Return to the default initial state of the random example stream.
Returns the data_specs specifying how the data is internally stored. This is the format the data returned by `self.get_data()` will be.
Update self.topo_space from self.shape and self.axes
Formats examples for use with PatchViewer Parameters  X : 2d numpy array One example per row Returns  output : 2d numpy array One example per row, rescaled so the maximum absolute value within each row is (almost) 1.
Method inherited from Dataset
Method inherited from Dataset
Returns the data_specs specifying how the data is internally stored. This is the format the data returned by `self.get_data()` will be.
Returns  data : numpy matrix or 2-tuple of matrices Returns all the data, as it is internally stored. The definition and format of these data are described in `self.get_data_specs()`.
Return an iterator for this dataset
Returns true if the dataset includes targets
Tests that a topological batch has 4 dimensions
This loads train and test sets.
Load train, test, valid sets
Tests that a topological batch has 4 dimensions
Tests that a topological batch has 4 dimensions
Test method
Test method on train set
Tests that a topological batch has 4 dimensions
Tests that the data spans [0,1]
Tests that a topological batch has 4 dimensions
Tests that requesting the targets to be in IndexSpace and iterating over them works
Compute and return the softmax transformation of sparse data.
Return a list of parameters that govern the linear transformation
Sets the initial values of the matrix
Return self._filters.
Check whether the local receptive field has stored the correct filters
Check whether the conv2d has stored the correct filters
Check whether the conv2d has stored the correct filters
After test clean up.
Check correct errors are raised when bad input is given.
Check whether the cudnn has stored the correct filters.
Calls setup on all extensions.
Store state of parameters
A function that adds additive Gaussian noise Parameters  param : sharedX model parameter to be regularized Returns  param : sharedX model parameter with additive noise
Recursive helper function that searches the (possibly nested) input space to see if it contains SequenceSpace
Skip all tests.
convResponseNormCrossMap(nv_images, nv_denoms, nv_targets, numFilters, sizeF, addScale, powScale, blocked);
convFilterActs(nv_images, nv_filters, nv_targets, imgSizeY, numModulesY, numModulesX, paddingStart, moduleStride, img_channels, numGroups, scaleTargets, scaleOutput);
Useful with the hack in profilemode to print the MFlops
convImgActs(nv_hid_acts, nv_filters, nv_targets, imgSizeY, imgSizeX, numModulesY, paddingStart, moduleStride, filter_channels, numGroups);
Check if an existing library exists and can be read.
Returns a callable that takes no arguments and returns a minibatch of contexts. Minibatch should be in VectorSpace(n).
Returns a callable that takes no arguments and returns a minibatch of rewards. Assumes that this function has been called after a call to context_func that gave the contexts used to choose the actions.
Choose a single cross-validation fold to represent. Parameters  k : int Index of selected fold.
Get input space.
Get output space.
Set up the main loop.
Set up extensions.
Run main_loop of this trainer. Parameters  trainer : Train object Train object. time_budget : int, optional The maximum number of seconds before interrupting training. Default is `None`, no time limit.
Yield train/valid/test splits.
Yield train/valid/test splits.
Choose a single cross-validation fold to represent. Parameters  k : int Index of selected fold.
Set input space. Parameters  space : Space The input space for this layer.
Get parameters.
Get input space.
Get output space.
Test DatasetKFold.
Test StratifiedDatasetKFold.
Test DatasetShuffleSplit.
Test StratifiedDatasetShuffleSplit.
Test DatasetValidKFold.
Test StratifiedDatasetValidKFold.
Test DatasetValidShuffleSplit.
Test StratifiedDatasetValidShuffleSplit.
Re-force dtype to ints in case of empty list  Make sure the array is 2D with 2 columns.  This is needed when dealing with an empty list
No need to bother with assignments if one of the dimensions  of the cost matrix is zero-length.
Look for the starred columns
We need to swap the columns because we originally  did a transpose on the input cost matrix.
Erase all prime markings
Silenced by default to reduce verbosity. Turn on at runtime for  performance profiling.
Don't get num_samples from an ensembles length!
special notation for singleton tuples
create new with correct sparse
convert dtype
force copy
store whether originally we wanted numeric dtype
not a data type (e.g. a column named dtype in a pandas DataFrame)
if input is object, convert to float.
no dtype conversion required
dtype conversion required. Let's select the first element of the  list of accepted types.
To ensure that array flags are maintained
FIXME NotFittedError_ --> NotFittedError in 0.19
update the docstring of the descriptor
Import error caused by circular imports.
uniform class weights
Get class weights for the subsample, covering all classes in  case some labels that were present in the original data are  missing from the sample.
Make missing classes' weight zero
x may be of the form dev-1ea1592
1 / (1 + exp(-x)) = (1 + tanh(x / 2)) / 2  This way of computing the logistic is both fast and stable.
little danse to see if np.copy has an 'order' keyword argument  Copy, but keep the order  Before an 'order' argument was introduced, numpy wouldn't muck with  the ordering
Compat where astype accepted no copy argument
Don't raise the numpy deprecation warnings that appear in  1.9, but avoid Python bug due to simplefilter('ignore')
Numpy < 1.8.0 don't handle empty arrays in reduceat
numpy.argpartition was introduced in v 1.8.0
Prior to 1.7.0, np.frombuffer wouldn't work for empty first arg.
Backport of numpy function in1d 1.8.1 to support numpy 1.6.2  Ravel both arrays, behavior for the first array could be different
Otherwise use sorting
Backport fix for scikit-learn/scikit-learn2986 / scipy/scipy4142
Find index of median prediction for each sample
Copyright (c) 2011, 2012  Authors: Pietro Berkes,           Andreas Muller           Mathieu Blondel           Olivier Grisel           Arnaud Joly           Denis Engemann           Giorgio Patrini           Thierry Guillemot  License: BSD 3 clause
Python 2
Python 3+
WindowsError only exist on Windows
Conveniently import all assertions in one place.
assert_raises_regexp is deprecated in Python 3.4 in favor of  assert_raises_regex but lets keep the backward compat in scikit-learn with  the old name for now
Verify some things
Checks the message of all warnings belong to warning_class  substring will match, the entire message with typo won't
To remove when we support numpy 1.7  XXX: once we may depend on python >= 2.6, this can be replaced by the
warnings module context manager.  very important to avoid uncontrolled state propagation
Filter out numpy-specific warnings in numpy >= 1.9
very important to avoid uncontrolled state propagation
concatenate exception names
transpose all variables
Lazy import to avoid mutually recursive imports
Lazy import to avoid mutually recursive imports
get rid of abstract base classes
possibly get rid of meta estimators
drop duplicates, sort for reproducibility  itemgetter is used to ensure the sort does not extend to the 2nd item of  the tuple
this fails if no $DISPLAY specified
This can fail under windows,   but will succeed when called by atexit
Pandas Dataframes and Series  Cython typed memoryviews internally used in pandas do not support  readonly buffers.
This is often substantially faster than X[indices]
Reverse the order here from the original matlab code because  there was an error on return when arnorm==0
Use a plane rotation to eliminate the damping parameter.  This alters the diagonal (rhobar) of the lower-bidiagonal matrix.
Use a plane rotation to eliminate the subdiagonal element (beta)  of the lower-bidiagonal matrix, giving an upper-bidiagonal matrix.
Update x and w.
Test for convergence.  First, estimate the condition of the matrix  Abar,  and the norms of  rbar  and  Abar'rbar.
Distinguish between     r1norm = ||b - Ax|| and     r2norm = rnorm in current code            = sqrt(r1norm^2 + damp^2*||x||^2).     Estimate r1norm from     r1norm = sqrt(r2norm^2 - damp^2*||x||^2).  Although there is cancellation, it might be accurate enough.
Allow for tolerances set by the user.
Check that all estimator yield informative messages when  trained on empty datasets
SpectralEmbedding is non-deterministic,  see issue 4236  cross-decomposition's "transform" returns X and Y
Test that all estimators check their input for NaN's and infs
FIXME!  in particular GaussianProcess!
Test that estimators can be pickled, and once pickled  give the same answer as before.
test if NotFittedError is raised
this is clustering on the features  let's not test that here.
be tolerant of noisy datasets (not actually speed)
Due to the jl lemma and often very few samples, the number  of components of the random matrix projection will be probably  greater than the number of features.  So we impose a smaller number (avoid "auto" mode)
SelectKBest has a default of k=10  which is more feature than we have in most case.
We need to make sure that we have non negative data, for things  like NMF
catch deprecation warnings
fit_transform method should work on non fitted estimator
check for consistent n_samples
raises error on malformed input for transform  If it's not an array, it does not have a 'T' property
Those transformers yield non-deterministic output when executed on  a 32bit Python. The same transformers are stable on 64bit Python.  FIXME: try to isolate a minimalistic reproduction case only depending  scipy and/or maybe generate a test dataset that does not  cause such unstable behaviors.
The precise message can change depending on whether X or y is  validated first. Let us test the type of exception only:
some estimators can't do features less than 0
some estimators only take multioutputs
catch deprecation warnings
pickle and unpickle!
fit  with lists
fit another time with ``fit_predict`` and compare results  there is no way to make Spectral clustering deterministic :(
MiniBatchKMeans
raises error on malformed input  raises error on malformed input for decision_function
some want non-negative input
Common test for Regressors as well as Classifiers
These only work on 2d, so this test makes no sense
catch deprecation warnings  fit
We need to make sure that we have non negative data, for things  like NMF
catch deprecation warnings  separate estimators to control random seeds
checks whether regressors have decision_function or predict_proba
FIXME CCA, PLS is not robust to rank 1 effects
doesn't have function  has function. Should raise deprecation warning
the sparse version has a parameter that doesn't do anything
NaiveBayes classifiers have a somewhat different interface.  FIXME SOON!
This is a very small dataset, default n_iter are likely to prevent  convergence
Let the model compute the class frequencies
Count each label occurrence to reweight manually
some want non-negative input  catch deprecation warnings
Make a physical copy of the original estimator parameters before fitting.
Fit the model
Compare the state of the model parameters with the original parameters
test sparsify with dense inputs
pickle and unpickle with sparse coef_
catch deprecation warnings  separate estimators to control random seeds
this comes from getattr. Gets rid of deprecation decorator.
init is not a python function.  true for mixins
they can need a non-default argument
deprecated parameter, not in get_params
Estimators in mono_output_task_error raise ValueError if y is of 1-D  Convert into a 2-D y for those estimators.
HuberRegressor depends on scipy.optimize.fmin_l_bfgs_b  which doesn't return a n_iter for old versions of SciPy.
These return a n_iter per component.
Get the unique set of labels
Check that we don't mix string type with number type
Known to fail in numpy 1.3 for array of arrays
Invalid inputs
check float and contains non-integer float values  [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]
This is the first call to partial_fit
An explicit zero was found, combine its weight with the weight  of the implicit zeros
If an there is an implicit zero and it is not in classes and  class_prior, make an entry for it
have shape an length but don't support indexing.  ugly hack to make iloc work.
Pandas data frames also are array-like: we want to make sure that  input validation in cross-validation does not try to call that  method.
Newer NumPy has a ravel that needs less copying.
important to access flags instead of calling np.isfortran,  this catches corner cases.
Maltyped or malformed data.
Generating normal random vectors with shape: (A.shape[1], size)
Deal with "auto" mode
Sample the range of A using by linear projection of Q  Extract an orthonormal basis
Checks if the number of iterations is explicitely specified
this implementation is a bit faster with smaller shape[1]
project M to the (k + p) dimensional space using the basis vectors
compute the SVD on the thin matrix: (k + p) wide
In case of transpose u_based_decision=false  to actually flip based on u and not v.
transpose back the results according to the input convention
Use the max to normalize, as with the log this is what accumulates  the less errors
unlike svd case, eigh can lead to negative eigenvalues
old = stats until now  new = the current increment  updated = the aggregated stats
line search failed: try different one.
Outer loop: our Newton iteration  Compute a search direction pk by applying the CG method to   del2 f(xk) p = - fgrad f(xk) starting from 0.
Inner loop: solve the Newton update by conjugate gradient, to  avoid inverting the Hessian
if undirected and csc storage, then transposing in-place  is quicker than later converting to csr.
Oldish versions of scipy don't have that
Author: Hamzeh Alsalhi <ha258@cornell.edu>  License: BSD 3 clause
In most cases a scalar will have been made an array
Use samples as indices for a if a is array-like
use uniform distribution if no class_probability is given
If 0 is not present in the classes insert it with a probability 0.0
XXX we should be testing the public API here
Square
Rectangular variant
Square
Rectangular variant
n == 2, m == 0 matrix
Check that dtype conversion works
Changing dtype forces a copy even if copy=False
Check that copy can be skipped if requested dtype match
Check that copy can be forced, and is the case by default:
test custom sampling without replacement algorithm
n_population < n_sample
n_population == n_samples
n_population >= n_samples
n_population < 0 or n_samples < 0
This test is heavily inspired from test_random.py of python-core.  For the entire allowable range of 0 <= k <= N, validate that  the sample is of the correct length and contains only unique items
test edge case n_population == n_samples == 0
This test is heavily inspired from test_random.py of python-core.  For the entire allowable range of 0 <= k <= N, validate that  sample generates all possible permutations
a large number of trials prevents false negatives without slowing normal  case
Counting the number of combinations is not as good as counting the  the number of permutations. However, it works with sampling algorithm  that does not provide a random permutation of the subset of integer.
doesn't error on actual estimator
check that a ValueError/AttributeError is raised when calling predict  on an unfitted estimator
check that CorrectNotFittedError inherit from either ValueError  or AttributeError
Confirm that input validation code does not return np.matrix
force_all_finite
nan check
no change if allowed
got converted
doesn't copy if it was already good
other input formats  convert lists to arrays  raise on too deep lists
convert weird stuff to arrays
empty list is considered 2D by default:
If considered a 1D collection when ensure_2d=False, then the minimum  number of samples will break:
Invalid edge case when checking the default minimum sample of a scalar
But this works if the input data is forced to look like a 2 array with  one sample and one feature:
The same message is raised if the data has 2 dimensions even if this is  not mandatory
Only the feature check is enabled whenever the number of dimensions is 2  even if allow_nd is enabled:
check error for bad inputs
check that asymmetric arrays are properly symmetrized  Check for warnings and errors
Check is ValueError raised when non estimator instance passed
Despite ensembles having __len__ they must raise TypeError  XXX: We should have a test with a string, but what is correct behaviour?
We compare path length and not costs (-> set distances to 0 or 1)
Non-reachable nodes have distance 0 in graph_py
Check the check_random_state utility function behavior
First a function...
... then a class.
Border case not worth mentioning in doctests
Non-regression test that shows null-space computation is better with  initialization of eigsh from [-1,1] instead of [0,1]
Test if eigsh is working correctly  New initialization [-1,1] (as in original ARPACK)  Was [0,1] before, with which this test could fail
Eigenvalues of s.p.d. matrix should be nonnegative, w[0] is smallest
fun with read-only data in dataframes  this happens in joblib memmapping
check that gen_even_slices contains all samples
check that passing negative n_chunks raises an error
Sparsify the array a little bit
Sparsify the array a little bit
default params for incr_mean_variance
Test _incremental_mean_and_var with whole data
Test that it raises an Error for non-csc matrices.
total effect of samples is preserved
When the user specifies class weights, compute_class_weights should just  return them.
Test with user-defined weights
Test with `None` weights
Not "auto" for subsample
Not a list or preset for multi-output
Incorrect length list for multi-output
next sample
random sample
and also confusable as sequences of sequences
empty second dimension
3d
Empty iterable
Multilabel indicator
Smoke test for all supported format
We don't support those format at the moment
Mix with binary or multiclass and multilabel
Only mark explicitly defined sparse examples as valid sparse  multilabel-indicators
Densify sparse examples before testing
with uniform weights, results should be identical to stats.mode
set this up so that each row should have a weighted mode of 6,  with a score that is easily reproduced
Try to add some smallish numbers in logspace
Check that extmath.randomized_svd is consistent with linalg.svd
generate a matrix X of approximate effective rank `rank` and no noise  component (very structured signal):
compute the singular values of X using the slow exact method
ensure that the singular values of both methods are equal up to the  real rank of the matrix
check the singular vectors too (while not checking the sign)
check the sparse matrix representation
compute the singular values of X using the fast approximate method
Check that extmath.randomized_svd can handle noisy matrices
generate a matrix X wity structure approximate rank `rank` and an  important noisy component
compute the singular values of X using the slow exact method
compute the singular values of X using the fast approximate  method without the iterated power method
the approximation does not tolerate the noise:
compute the singular values of X using the fast approximate  method with iterated power method
the iterated power method is helping getting rid of the noise:
Check that extmath.randomized_svd can handle noisy matrices
let us try again without 'low_rank component': just regularly but slowly  decreasing singular values: the rank of the data matrix is infinite
the approximation does not tolerate the noise:
compute the singular values of X using the fast approximate method  with iterated power method
the iterated power method is still managing to get most of the  structure at the requested rank
Check that transposing the design matrix has limited impact
in this case 'auto' is equivalent to transpose
Check that svd_flip works in both situations, and reconstructs input.
Without transpose
With transpose
check single axis
Check correctness and robustness of logistic sigmoid implementation
Check fast dot blas wrapper function
ndim == 0
ndim == 1
ndim > 2
min(shape) == 1
test for matrix mismatch error
Test cov-like use case + dtypes.
col < row
Test square matrix * rectangular use case.
Two-pass algorithm, stable.  We use it as a benchmark. It is not an online algorithm  https://en.wikipedia.org/wiki/Algorithms_for_calculating_varianceTwo-pass_algorithm
Older versions of numpy have different precision  In some old version, np.var is not stable
Naive one pass var: >tol (=1063)
Assign this twice so that the test logic is consistent
Check that the nose implementation of assert_less gives the  same thing as the scikit's
Check that the nose implementation of assert_less gives the  same thing as the scikit's
Linear Discriminant Analysis doesn't have random state: smoke test
multiple exceptions in a tuple
This check that ignore_warning decorateur and context manager are working  as expected
Check the decorator
Check the context manager
This class is inspired from numpy 1.7 with an alteration to check  the reset warning filters after calls to assert_warns.  This assert_warns behavior is specific to scikit-learn because  and clears all previous filters.
Test that assert_warns is not impacted by externally set  filters and is reset internally.  This is because `clean_warning_registry()` is called internally by  assert_warns and clears all previous filters.
Test that the warning registry is empty after assert_warns
Should raise an AssertionError
FIXME: we should probably reset __new__ for full generality
accepted values of parameter WHICH in _SEUPD
accepted values of parameter WHICH in _NAUPD
Note: slices producing 0-size arrays do not necessarily change  data pointer  so we use and allocate size+1
ARPACK overwrites its initial resid,  make a copy
ARPACK will use a random initial vector.
sigma not used
set solver mode and parameters
Use _aligned_zeros to work around a f2py bug in Numpy 1.9.1
initialization
Use _aligned_zeros to work around a f2py bug in Numpy 1.9.1
Use _aligned_zeros to work around a f2py bug in Numpy 1.9.1
initialization
Build complex eigenvalues from real and imaginary parts
Arrange the eigenvectors: complex eigenvectors are stored as  real,imaginary in consecutive columns
we got less or equal as many eigenvalues we wanted
when tol=0, ARPACK uses machine tolerance as calculated  by LAPACK's _LAMCH function.  We should match this
when tol=0, ARPACK uses machine tolerance as calculated  by LAPACK's _LAMCH function.  We should match this
standard eigenvalue problem
general eigenvalue problem
standard eigenvalue problem
general eigenvalue problem
sigma is not None: shift-invert mode
unrecognized mode
Get a low rank approximation of the implicitly defined gramian matrix.  This is not a stable way to approach the problem.
In 'LM' mode try to be clever about small eigenvalues.  Otherwise in 'SM' mode do not try to be clever.
Gramian matrices have real non-negative eigenvalues.
Authors: Manoj Kumar           Thomas Unterthiner           Giorgio Patrini  License: BSD 3 clause
The following swapping makes life easier since m is assumed to be the  smaller integer below.
Modify indptr first
Prevent modifying X in place
normalize by P(x) = P(f_1, ..., f_n)
Combine mean of old and new data, taking into consideration  (weighted) number of observations
If the ratio of data variance between dimensions is too small, it  will cause numerical errors. To address this, we artificially  boost the variance by epsilon, a small fraction of the standard  deviation of the largest dimension.
Put epsilon back in each time
Update if only no priors is provided  Empirical prior, with sample_weight taken into account
empirical prior, with sample_weight taken into account
label_binarize() returns arrays with dtype=np.int64.  We convert it to np.float64 to support sample_weight consistently
Count raw events from data before updating the class log prior  and feature log probas
XXX: OPTIM: we could introduce a public finalization method to  be called by the user explicitly just once after several consecutive  calls to partial_fit and prior any call to predict[_[log_]proba]  to avoid computing the smooth log probas at each call to partial fit
LabelBinarizer().fit_transform() returns arrays with dtype=np.int64.  We convert it to np.float64 to support sample_weight consistently;  this means we also don't have to cast X to floating point
XXX The following is a stopgap measure; we need to set the dimensions  of class_log_prior_ and feature_log_prob_ correctly.
Compute  neg_prob  (1 - X).T  as  neg_prob - X  neg_prob
skip index generation if totally dense
Among non zero components the probability of the sign is 50%/50%
build the CSR structure by concatenating the rows
Generate a projection matrix of size [n_components, n_features]
Check contract
Convert data
submodules with build utilities
add cython extension module for isotonic regression
the following packages depend on cblas, so they have to be build  after the above.
add the test directory
Make sure that DeprecationWarning within this package always gets printed
This variable is injected in the __builtins__ by the build  process. It used to enable importing subpackages of sklearn when  the binaries are not built
We are not importing the rest of the scikit during the build  process, as it may not be compiled yet
Non-modules:
Ensure that this module is still importable under Python3 to avoid  crashing code-inspecting tools like nose.
Setting a new item creates a new link which goes at the end of the linked  list, and the inherited dictionary is updated with the new key/value pair.
Deleting an existing item uses self.__map to find the link which is  then removed by updating the links in the predecessor and successor nodes.
Useful for very coarse version differentiation.
Jython always uses 32 bits.
This is a bit ugly, but it avoids running this again.
This is about 2x faster than the implementation above on 3.2+
XXX: This conflicts with the debug flag used in children class
FIXME: Too much logic duplicated
XXX: We actually need a debug flag to disable this  silent failure.
By default we want a pickle protocol that only changes with  the major python version and not the minor one  Initialise the hash obj
builtin  type  classobj  function
forces order of items in Set to ensure consistent hash
delayed import of numpy, to avoid tight coupling
The object will be pickled by the pickler hashed at the end.
Python 2 compat
Customizable pure Python pickler in Python 2  customizable C-optimized pickler under Python 3.3+
We need the class definition to derive from it not the multiprocessing.Pool  factory function
Some system have a ramdisk mounted by default, we can use it instead of /tmp  as the default folder to dump big arrays to share with subprocesses
Folder and file permissions to chmod temporary files generated by the  memmaping pool. Only the owner of the Python process can access the  temporary files and folder.
a is already a real memmap instance.
Recursive exploration of the base ancestry
Do not zero the original data when unpickling
Simple, contiguous memmap
For non-contiguous data, memmap the total enclosing buffer and then  extract the non-contiguous view with the stride-tricks API
offset that comes from the striding differences between a and m
offset from the backing memmap
The backing memmap buffer is necessarily contiguous hence C if not  Fortran
If the array is a contiguous view, no need to pass the strides
Compute the total number of items to map from which the strided  view will be extracted.
m is a real mmap backed memmap instance, reduce a preserving striding  information
This memmap instance is actually backed by a regular in-memory  buffer: this can happen when using binary operators on numpy.memmap  instances
a is already backed by a memmap file, let's reuse it directly
check that the folder exists (lazily create the pool temp folder  if required)
Warm up the data to avoid concurrent disk access in  multiple children processes
The worker process will use joblib.load to memmap the data
Make the dispatch registry an instance level attribute instead of  a reference to the class dictionary under Python 2
Under Python 3 initialize the dispatch table with a copy of the  default registry
Python 2 pickler dispatching is not explicitly customizable.  Let us use a closure to workaround this limitation.
writes to a message oriented win32 pipe are atomic
Register smart numpy.ndarray reducers that detects memmap backed  arrays and that is alse able to dump to memmap large in-memory  arrays over the max_nbytes threshold
Communication from child process to the parent process always  pickles in-memory numpy.ndarray without dumping them as memmap  to avoid confusing the caller and make it tricky to collect the  temporary folder
An in-memory store to avoid looking at the disk-based function  source code to check if a function definition has changed
__getstate__ and __setstate__ are required because of __slots__
Should be a light as possible (for speed)
Argument "warn" is for compatibility with MemorizedFunc.clear
Public interface
Pydoc does a poor job on other objects
Private interface
Here, we go through some effort to be robust to dynamically  changing code and collision. We cannot inspect.getsource  because it is not reliable when using IPython's magic "%run".
No metadata available here.
Private `object` interface
Public interface
Partial application, to be able to specify extra keyword  arguments in decorators
Private `object` interface
We need to remove 'joblib' from the end of cachedir
Compressed pickle header format: _ZFILE_PREFIX followed by _MAX_LEN  bytes which contains the length of the zlib compressed data as an  hexadecimal string. For example: 'ZF0x139              '
Pickling needs file-handles at the beginning of the file
Store the length of the data
Load the array from the disk
Count the number of npy files that we have created:  By default we want a pickle protocol that only changes with  the major python version and not the minor one
delayed import of numpy, to avoid tight coupling
When compressing, as we are not writing directly to the  disk, it is more efficient to use standard pickling  Pickling doesn't work with memmaped arrays
This converts the array in a container
XXX: We should have a logging mechanism
Be careful to register our new method.
By default, if compress is enabled, we want to be using 3 by  default
People keep inverting arguments, and the resulting error is  incomprehensible
Environment variables to protect against bad situations when nesting
In seconds, should be big enough to hide multiprocessing dispatching  overhead.  This settings was found by running benchmarks/bench_auto_batching.py  with various parameters on various platforms.
Should not be too high to avoid stragglers: long jobs running alone  on a single worker while other workers have no work to process any more.
We capture the KeyboardInterrupt and reraise it as  something different, as multiprocessing does not  interrupt processing for a KeyboardInterrupt
Try to pickle the input function, to catch the problems early when  using with multiprocessing:
Don't delay the application, to avoid keeping the input  arguments in memory
Update the smoothed streaming estimate of the duration of a batch  from dispatch to completion  First record of duration for this batch size after the last  reset.  Update the exponentially weighted average of the duration of  batch for the current effective size.
`backend=None` was supported in 0.8.2 with this effect
Make it possible to pass a custom multiprocessing context as  backend to change the start method to forkserver or spawn or  preload modules on the forkserver helper process.
Not starting the pool in the __init__ is a design decision, to be  able to close it ASAP, and not burden the user with closing it  unless they choose to use the context manager API with a with block.
This lock is used coordinate the main thread of this process with  the async callback thread of our the pool.
multiprocessing is not available or disabled, fallback  to sequential mode
The list of exceptions that we will capture
Sequential mode: do not use a pool instance to avoid any  useless dispatching overhead
Daemonic processes cannot have children
Prevent posix fork inside in non-main posix threads
Set an environment variable to avoid infinite loops
We are using multiprocessing, we also want to capture  KeyboardInterrupts
If job.get() catches an exception, it closes the queue:
Batching is never beneficial with the threading backend
No batch size adjustment
Reset estimation of the smoothed mean batch duration: this  estimate is updated in the multiprocessing apply_async  CallBack as long as the batch_size is constant. Therefore  we need to reset the estimate whenever we re-tune the batch  size.
Fixed batch size strategy
No more tasks available in the iterator: tell caller to stop.
Wait for an async callback to dispatch new jobs  We need to be careful: the job list can be filling up as  we empty it and Python list are not thread-safe by default hence  the use of the lock
Stop dispatching any new job in the async callback thread
Convert this to a JoblibException
A flag used to abort the dispatching of jobs in case an  exception is found
prevent further dispatch via multiprocessing callback thread
The main thread will consume the first pre_dispatch items and  the remaining items will later be lazily dispatched by async  callbacks upon task completions.
Only set self._iterating to True if at least a batch  was dispatched. In particular this covers the edge  case of Parallel used with an exhausted iterator.
The iterable was consumed all at once by the above for loop.  No need to wait for async callbacks to trigger to  consumption.
on some platform st_blocks is not available (e.g., Windows)  approximate by rounding to next multiple of 512  We need to convert to int to avoid having longs on some systems (we  don't want longs to avoid problems we SQLite)
if a rmtree operation fails in rm_subdirs, wait for this much time (in secs),  then retry once. if it still fails, raise the exception
allow the rmtree to fail once, wait and re-try.  if the error is raised again, fail
Available in Python 3
Copied from python3 tokenize
This behaviour mimics the Python interpreter
This behaviour mimics the Python interpreter
If the error is at the console, don't build any context, since it would  otherwise produce 5 blank lines printed out (there is no file at the  console)
Initialize a list of names on the current line, which the  tokenizer below will populate.
prune names list of duplicates, but keep the right order
some locals
Drop topmost frames if requested
Obtain possible configuration from the environment, assuming 1 (on)  by default, upon 0 set to None. Should instructively fail if some non  0/1 value is set.
2nd stage: validate that locking is available on the system and             issue a warning if not
3rd stage: backward compat for the assert_spawning helper  Python 3.4+
The next line set the .args correctly. This is needed to  make the exception loadable with pickle
Updating module locals so that the exceptions pickle right. AFAIK this  works only at module-creation time
All the lines after the function definition:
In Python 3, quote is elsewhere
Happens in doctests, eg
inspect.formatargspec can not deal with the same  number of arguments in python 2 and 3
Catch a common mistake  Special case for functools.partial objects
First argument is 'self', it has been removed by Python  we need to add it back:  XXX: Maybe I need an inspect.isbuiltin to detect C-level methods, such  as on ndarrays.
Missing argument
XXX: Not using logging framework
Once '__signature__' will be added to 'C'-level  callables, this check won't be necessary
In this case we skip the first parameter of the underlying  function (usually `self` or `cls`).
Was this function wrapped by a decorator?
An object with __call__  We also check that the 'obj' is not an instance of  _WrapperDescriptor or _MethodWrapper to avoid  infinite recursion (and even potential segfault)
For classes and objects we skip the first parameter of their  __call__, __new__, or __init__ methods
Raise a nicer error message for builtins
Add annotation and default value
Keyword arguments mapped by 'functools.partial'  (Parameter._partial_kwarg is True) are mapped  in 'BoundArguments.kwargs', along with VAR_KEYWORD &  KEYWORD_ONLY
We're done here. Other arguments  will be mapped in 'BoundArguments.kwargs'
*args
plain argument
**kwargs
plain keyword argument
Non-keyword-only parameters w/o defaults.
... w/ defaults.
*args
Keyword-only parameters.
**kwargs
Support for binding arguments to 'functools.partial' objects.  See 'functools.partial' case in 'signature()' implementation  for details.  Simulating 'functools.partial' behavior
We have an '*args'-like argument, let's fill it with  all positional arguments we have left and move on to  the next phase
Memorize that we have a '**kwargs'-like parameter
We have no value for this parameter.  It's fine though,  if it has a default value, or it is an '*args'-like  parameter, left alone by the processing of positional  arguments.
Process our '**kwargs'-like parameter
OK, we have an '*args'-like parameter, so we won't need  a '*' to separate keyword-only arguments
x_old equals one of our samples
gelss need to pad y_subpopulation to be of the max dim of X_subpopulation
Initialization of the values of the parameters
Convergence loop of the bayesian ridge regression
Launch the convergence loop
Initialization of the values of the parameters
Prune the weights with a precision over a threshold
add other directories
inverse Lipschitz constant for log loss
inverse Lipschitz constant for squared loss
Ridge default max_iter is None
As in SGD, the alpha is scaled by n_samples.
if loss == 'multinomial', y should be label encoded.
initialization
assume fit_intercept is False
check_finite=False is an optimization available only in scipy >=0.12
new scipy, don't need to initialize because check_finite=False
old scipy, we need the garbage upper triangle to be non-Inf
atom already selected or inner product too small
new scipy, don't need to initialize because check_finite=False
old scipy, we need the garbage upper triangle to be non-Inf
selected same atom twice, or inner product too small
default for n_nonzero_coefs is 0.1 * n_features  but at least one.
or subsequent target will be affected
default for n_nonzero_coefs is 0.1 * n_features  but at least one.
Author: Gael Varoquaux, Alexandre Gramfort  License: BSD 3 clause
We are generating 1 - weights, and not weights
Center X and y to avoid fit the intercept
Scale alpha by alpha_max  Sort alphas in assending order  Get rid of the alphas that are too small  We also want to keep the first one: it should be close to the OLS  solution
Calculate the values where |y - X'w -c / sigma| > epsilon  The values above this threshold are outliers.
Calculate the linear loss due to the outliers.  This is equal to (2 * M * |y - X'w -c / sigma| - M**2) * sigma
n_sq_outliers includes the weight give to the outliers while  num_outliers is just the number of outliers.
Calculate the quadratic loss due to the non-outliers.-  This is equal to |(y - X'w - c)**2 / sigma**2| * sigma
Gradient due to the squared loss.
Gradient due to the penalty.
Gradient due to sigma.
Gradient due to the intercept.
Sigma or the scale factor should be non-negative.  Setting it to be zero might cause undefined bounds hence we set it  to a value close to zero.
Logistic loss is the negative of the log of the logistic function.
Case where we fit the intercept.
Logistic loss is the negative of the log of the logistic function.
Case where we fit the intercept.
Calculate the double derivative with respect to intercept  In the case of sparse matrices this returns a matrix object.
For the fit intercept case.
`loss` is unused. Refactoring to avoid computing it does not  significantly speed up the computation and decreases readability
np.unique(y) gives labels in sorted order.
If class_weights is a dict (provided by the user), the weights  are assigned to the original labels. If it is "balanced", then  the class_weights are assigned after masking the labels with a OvR.
'auto' is deprecated and will be removed in 0.19
SAG multinomial solver needs LabelEncoder, not LabelBinarizer
To deal with object dtypes, we need to convert into an array of floats.
Hack so that we iterate only once for the multinomial case.
init cross-validation generator
OvR in case of binary problems is as good as fitting  the higher label
We need this hack to iterate only once over labels, in the case of  multi_class = multinomial, without changing the value of the labels.
'auto' is deprecated and will be removed in 0.19
hack to iterate only once for multinomial case.
X can be touched inplace thanks to the above line
Workaround to find alpha_max for sparse matrices.  since we should not destroy the sparsity of such matrices.
return self for chaining fit and predict calls
No Gram variant of multi-task exists right now.  Fall back to default enet_multitask
Do the ordering and type casting here, as if it is done in the path,  X is copied and a reference is kept here
Doing this so that it becomes coherent with multioutput.
This makes sure that there is no duplication in memory.  Dealing right with copy_X is important in the following:  Multiple functions touch X and subsamples of X and can induce a  lot of duplication of memory
Making sure alphas is properly ordered.  We want n_alphas to be the number of alphas used for each l1_ratio.
We are not computing in parallel, we can modify X  inplace in the folds
init cross-validation generator
Compute path for all folds and compute MSE to get the best alpha
Remove duplicate alphas in case alphas is provided.
X and y must be of type float64
return self for chaining fit and predict calls
iteration count for learning rate schedule  must not be int (e.g. if ``learning_rate=='optimal'``)
raises ValueError if not registered
uniform sample weights
user-provided array
XXX should have random_state_!  numpy mtrand expects a C long which is a signed 32 bit integer under  Windows
Allocate datastructures from input arguments
labels can be encoded as float, int, or string literals  np.unique sorts in asc order; largest class id is positive class
Clear iteration count for multiple call to fit.
the above might assign zero to all classes, which doesn't  normalize neatly; work around this to produce uniform  probabilities
normalize
Allocate datastructures from input arguments
Clear iteration count for multiple call to fit.
numpy mtrand expects a C long which is a signed 32 bit integer under  Windows
According to the lsqr documentation, alpha = damp^2.
w = inv(X^t X + alpha*Id) * X.T y
dual_coef = inv(X X^t + alpha*Id) y
Unlike other solvers, we need to support sample_weight directly  because K might be a pre-computed kernel.
Only one penalty, we can solve multi-target problems in one time.
Note: we must use overwrite_a=False in order to be able to        use the fall-back solution below in case a LinAlgError        is raised
K is expensive to compute and store in memory so change it back in  case it was user-given.
One penalty per target. We need to solve each target separately.
cholesky if it's a dense array and cg in any other case
SAG supports sample_weight directly. For other solvers,  we implement sample_weight via a simple rescaling.
use SVD solver if matrix is singular
use SVD solver if matrix is singular
precompute max_squared_sum for all targets
When y was passed as a 1d-array, we flatten the coefficients.
we don't (yet) support multi-label classification in Ridge
modify the sample weights with the corresponding class weight
compute diagonal of the matrix: dot(Q, dot(diag(v_prime), Q^T))
handle case where y is 2-d
handle case where y is 2-d
FIXME non-uniform sample weights not yet supported
assert n_samples >= n_features
The scorer want an object that will make the predictions but  they are already computed efficiently by _RidgeGCV. This  identity_estimator will just return them
modify the sample weights with the corresponding class weight
assume linear model by default
MAD (median absolute deviation)
number of data samples
choose random sample set
check if random sample set is valid
fit model for current random sample set
check if estimated model is valid
residuals of all data for current random sample model
classify data into inliers and outliers
extract inlier data set
score of inlier data set
same number of inliers but worse score -> skip current random  sample
save current random sample as best sample
break if sufficient number of inliers or score is reached
estimate final model using all inliers
seed should never be 0 in SequentialDataset
transform variance to std in-place
transform variance to norm in-place
OvR normalization, like LibLinear's predict_probability
Sample weight can be implemented via a simple rescaling.
copy was done in fit if necessary
recompute Gram
precompute if n_samples > n_features
make sure that the 'precompute' array is contiguous.
Xy is 1d, make sure it is contiguous.
Make sure that Xy is always F contiguous even if X or y are not  contiguous: the goal is to make it fast to extract the data for a  specific target.
also test verbose output
no more than max_pred variables can go into the active set
no more than max_pred variables can go into the active set
Test that the ``return_path=False`` option with Gram and Xy remains  correct
consistency test that checks that LARS Lasso is handling rank  deficient input data (with n_features < rank) in the same way  as coordinate descent Lasso
Test that LassoLars and Lasso using coordinate descent give the  same results.
The path should be of length 6 + 1 in a Lars going down to 6  non-zero coefs
Assure that estimators receiving multidimensional y do the right thing
test error on unknown IC
When using automated memory mapping on large input, the  fold data is in read-only mode  This is a non-regression test for:  https://github.com/scikit-learn/scikit-learn/issues/4597  The following should not fail despite copy=False
not normalized data
Test LinearRegression on a simple dataset.  a simple dataset
test it also for degenerate input
It would not work with under-determined systems
LinearRegression with explicit sample_weight
make sure the "OK" sample weights actually work
Test multiple-outcome linear regressions
XXX: if normalize=True, should we expect a weighted standard deviation?       Currently not weighted, but calculated with respect to weighted mean
Sparse cases
test set
Ensure the unconstrained fit has a negative coefficient
On same data, constrained fit has non-negative coefficients
We use a large number of samples and of informative features so that  the l1_ratio selected is more toward ridge than lasso
Well-conditioned settings, we should have selected our  smallest penalty  Non-sparse ground truth: we should have selected an elastic-net  that is closer to ridge than to lasso
We are in well-conditioned settings with low noise: we should  have a good test-set performance
Ensure the unconstrained fit has a negative coefficient
On same data, constrained fit has non-negative coefficients
Y_test = np.c_[y_test, y_test]
This dataset is not trivial enough for the model to converge in one pass.
Check that n_iter_ is invariant to multiple calls to fit  when warm_start=False, all else being equal.
Fit the same model again, using a warm start: the optimizer just performs  a single pass before checking that it has already converged
Train a model to converge on a lightly regularized problem
Fitting a new model on a more regularized version of the same problem.  Fitting with high regularization is easier it should converge faster  in general.
Fit the solution to the original, less regularized version of the  problem but from the solution of the highly regularized variant of  the problem as a better starting point. This should also converge  faster than the original model that starts from zero.
Raise error when selection is not in cyclic or random.
With no input checking, providing X in C order should result in false  computation
test that the feature score of the best features
Check lasso stability path  Load diabetes data and add noisy features
Check randomized lasso
Check randomized sparse logistic regression
Check randomized sparse logistic regression on sparse data
center here because sparse matrices are usually not centered  labels should not be centered
sparse data has a fixed decay of .01
Test that explicit warm restart...
... and implicit warm restart are equivalent.
Input format tests.
Check whether expected ValueError on bad alpha, i.e. 0  since alpha is used to compute the optimal learning rate
assert_almost_equal(clf.coef_[0], clf.coef_[1], decimal=7)
Check whether expected ValueError on bad l1_ratio
Check whether expected ValueError on bad learning_rate
Check whether expected ValueError on bad eta0
Check whether expected ValueError on bad alpha
Check whether expected ValueError on bad penalty
Check whether expected ValueError on bad loss
Test parameter validity check
Test parameter validity check
Checks coef_init not allowed as model argument (only fit)  Provided coef_ does not match dataset.
Checks coef_init shape for the warm starts  Provided coef_ does not match dataset.
Checks intercept_ shape for the warm starts  Provided intercept_ does not match dataset.
Checks intercept_ shape for the warm starts in binary case
simple linear function without noise
Target must have at least two labels
Multi-class average test case
Checks coef_init and intercept_init shape for multi-class  problems  Provided coef_ does not match dataset
Provided coef_ does match dataset
Provided intercept_ does not match dataset
Provided intercept_ does match dataset.
log loss multiclass probability estimates
the following sample produces decision_function values < -1,  which would cause naive normalization to fail (see comment  in SGDClassifier.predict_proba)
Test L1 regularization
test sparsify with dense inputs
pickle and unpickle with sparse coef_
we give a small weights to class 1
now the hyperplane should rotate clock-wise and  the prediction on this point should shift
should be similar up to some epsilon due to learning rate schedule
ValueError due to not existing class label.
ValueError due to wrong class_weight argument type.
Make sure that in the balanced case it does not change anything  to use "balanced"
build an very very imbalanced dataset out of iris data
we give a small weights to class 1
now the hyperplane should rotate clock-wise and  the prediction on this point should shift
Test if ValueError is raised if sample_weight has wrong shape  provided sample_weight too long
classes was not specified
check that coef_ haven't been re-allocated
check that coef_ haven't been re-allocated
Partial_fit should work after initial fit in the multiclass case.  Non-regression test for 2496; fit would previously produce a  Fortran-ordered coef_ that subsequent partial_fit couldn't handle.
Test multiple calls of fit w/ different shaped inputs.
Non-regression test: try fitting with a different label set.
Check whether expected ValueError on bad penalty
Check whether expected ValueError on bad loss
simple linear function without noise
simple linear function without noise
simple linear function without noise
simple linear function with noise
simple linear function without noise
simple linear function with noise
simple linear function without noise
simple linear function with noise
ground_truth linear model that generate y from X and to which the  models should converge if the regularizer would be set to 0.0
check that coef_ haven't been re-allocated
Test if l1 ratio extremes match L1 and L2 penalty settings.
Generate some weird data with hugely unscaled features
Use MinMaxScaler to scale the data without introducing a numerical  instability (computing the standard deviation naively is not possible  on this data)
smoke test: model is stable on scaled data
Test gradient of different loss functions  cases is a list of (p, y, expected)
Test BayesianRidge on diabetes
Test with more samples than features  Test that scores are increasing at each iteration
Test with more features than samples  Test that scores are increasing at each iteration
Check that the model could approximately learn the identity function
Test BayesianRegression ARD classifier
Check that the model could approximately learn the identity function
Generate data with outliers by replacing 10% of the samples with noise.
SciPy performs the tol check after doing the coef updates, so  these would be almost same but not equal.
No n_iter_ in old SciPy (<=0.9)  And as said above, the first iteration seems to be run anyway.
The huber model should also fit poorly on the outliers.
With more samples than features
Currently the only solvers to support sample_weight.
Currently the only solvers to support sample_weight.
Sample weight can be implemented via a simple rescaling  for the square loss.
Ridge with explicit sample_weight
we need more samples than features
Test error is raised when number of targets and penalties do not match.
test that can work with both dense or sparse matrices
check that efficient and brute-force LOO give same results
check that efficient and SVD efficient LOO give same results
check best alpha
check that we get same best alpha with a scorer
check that we get same best alpha with sample weights
simulate several responses
simulate several responses
test dense matrix  test sparse matrix  test that the outputs are the same
we give a small weights to class 1
now the hyperplane should rotate clock-wise and  the prediction on this point should shift
check if class_weight = 'balanced' can handle negative labels.
we give a small weights to class 1
Test _RidgeCV's store_cv_values attribute.
with len(y.shape) == 1
with len(y.shape) == 2
Check using GridSearchCV directly
make sure the "OK" sample weights actually work
Test that self.n_iter_ is correct.
Simple sanity check on a 2 classes dataset  Make sure it predicts the correct result on simple datasets.
Test logistic regression with the iris dataset
Test multinomial LR on a binary problem.
Test sparsify and densify members.
Test that an exception is raised on inconsistent input
Wrong dimensions for training data
Wrong dimensions for test data
Test that we can write to coef_ and intercept_
Test proper NaN handling.  Regression test for Issue 252: fit used to go into an infinite loop.
same result for same random state  different results for different random states
Second check that our intercept implementation is good
First check that _logistic_grad_hess is consistent  with _logistic_loss_and_grad
Now check our hessian along the second direction of the grad
In the fit_intercept=False case, the feature vector of ones is  penalized. This should be taken care of.
Check gradient.
Test that OvR and multinomial are correct using the iris dataset.
The cv indices from stratified kfold (where stratification is done based  on the fine-grained iris classes, i.e, before the classes 0 and 1 are  conflated) is used for both clf and clf1
Train clf on the original dataset where classes 0 and 1 are separated
Conflate classes 0 and 1 and train clf1 on this modified dataset
Ensure that what OvR learns for class2 is same regardless of whether  classes 0 and 1 are separated or not
helper for returning a dictionary instead of an array
Multinomial case: remove 90% of class 0
Binary case: remove 90% of class 0 and 100% of class 2
'auto' is deprecated and will be removed in 0.19
Some basic attributes of Logistic Regression
Compare solutions between lbfgs and the other solvers
extract first column of hessian matrix
Dummy data such that the decision function becomes zero.
Predicted probabilites using the soft-max function should give a  smaller loss than those using the logistic function.
Test that the maximum number of iteration is reached
old scipy doesn't have maxiter
Test that self.n_iter_ has the correct format.
multinomial case
A 1-iteration second fit on same data should give almost same result  with warm starting, and quite different result without warm starting.  Warm starting does not work with liblinear solver.
old scipy doesn't have maxiter
Check if median is solution of the Fermat-Weber location problem  Check when maximum iteration is exceeded a warning is emitted
Check for exact the same results as Least Squares
Check that Theil-Sen can be verbose
Classifier can be retrained on different labels and features.
we give a small weights to class 1
now the hyperplane should rotate clock-wise and  the prediction on this point should shift
partial_fit with class_weight='balanced' not supported
Already balanced, so "balanced" weights should have no effect
should be similar up to some epsilon due to learning rate schedule
Check that the sparse_coef property works
Test ElasticNet for various values of alpha and l1_ratio with sparse X  training samples  X[1, 0] = 0
test samples
generate a ground truth model
generate training ground truth labels
check the convergence is the same as the dense version
check that the coefs are sparse
check that the coefs are sparse
XXX: There is a bug when precompute is not None!
this is used for sag regression
sparse data has a fixed decay of .01
sparse data has a fixed decay of .01
idx = k
sum the squares of the second sample because that's the largest
simple linear function without noise
simple linear function with noise
test if the multinomial loss and gradient computations are consistent
comparison
Generate coordinates of line
Estimate parameters of corrupted data
Ground truth / reference inlier mask
When residual_threshold=0.0 there are no inliers and a  ValueError with a message should be raised
3-D target values
Estimate parameters of corrupted data
Ground truth / reference inlier mask
XXX: Remove in 0.20
one-dimensional
Estimate parameters of corrupted data
Ground truth / reference inlier mask
e = 0%, min_samples = X
e = 0%, min_samples = 10
sanity check
check that mask is correct
check that if base_estimator.fit doesn't support  sample_weight, raises error
holds the sign of covariance
force copy. setting the array to be fortran-ordered  speeds up the calculation of the (partial) Gram matrix  and allows to easily swap columns
interpolation factor 0 <= ss < 1  In the first iteration, all alphas are zero, the formula  below would make ss a NaN
Update the cholesky decomposition for the Gram matrix
least squares solution
This happens because sign_active[:n_active] = 0
is this really needed ?
equiangular direction of variables in the active set  correlation between each unactive variables and  eqiangular vector
if huge number of features, this takes 50% of time, I  think could be avoided if we just update it using an  orthogonal (QR) decomposition of X
update the sign, important for LAR
mimic the effect of incrementing n_iter on the array references
update correlations
See if any coefficient has changed sign
handle the case when idx is not length of 1
handle the case when idx is not length of 1
resize coefs in case of early stop
precompute if n_samples > n_features
init cross-validation generator
Unique also sorts  Take at most max_n_alphas values
Select the alpha that minimizes left-out error
Store our parameters
Now compute the full model  it will call a lasso internally when self if LassoLarsCV  as self.method == 'lasso'
impedance matching for the above Lars.fit (should not be documented)
get the number of degrees of freedom equal to:  Xc = X[:, mask]  Trace(Xc * inv(Xc.T, Xc) * Xc.T) ie the number of non-zero coefs
probabilities of the positive class
Y[i, j] gives the probability that sample i has the label j.  In the multi-label case, these are not disjoint.
Only one estimator, but we still want to return probabilities  for two classes.
Then, probabilities should be normalized to 1.
FIXME: there are more elaborate methods than generating the codebook  randomly.
Set the number of local seeding trials if none is given  This is what Arthur/Vassilvitskii tried, but did not report  specific results for other than mentioning in the conclusion  that it helped.
Pick first center randomly
Initialize list of closest distances and calculate current potential
Pick the remaining n_clusters-1 points  Choose center candidates by sampling with probability proportional  to the squared distance to the closest existing center
Compute distances to center candidates
Decide which candidate is the best  Compute potential when including center candidate
Store result if it is the best local trial so far
Permanently add best center candidate found in local tries
subtract of mean of x for more accurate distance computations  The copy was already done above
precompute squared norms of data points
elkan doesn't make sense for a single cluster, full will produce  the right result.
init
Allocate memory to store the distances for each sample to its  closer center for reallocation in case of ties
iterations  labels assignment is also called the E-step of EM
computation of the means is also called the M-step of EM
rerun E-step in case of non-convergence so that predicted labels  match cluster centers
distances will be changed in-place
Currently, this just skips a copy of the data if it is not in  np.array or CSR format already.  XXX This skips _check_test_data, which may change the dtype;  we should refactor the input validation.
Perform label assignment to nearest centers
reset counts of reassigned centers, but don't reset them too small  to avoid instant reassignment. This is a pretty dirty hack as it  also modifies the learning rates.
implementation for the sparse CSR representation completely written in  cython
dense variant in mostly numpy (not as memory efficient though)  find points from minibatch that are assigned to this center
inplace remove previous count scaling
inplace sum with new points members of this cluster
update the count statistics for this center
inplace rescale to compute mean of all points (old and new)
update the squared diff if necessary
Normalize inertia to be able to compare values when  batch_size changes
Early stopping based on absolute tolerance on squared change of  centers position (using EWA smoothing)
update the convergence context to maintain state across successive calls:
using tol-based early stopping needs the allocation of a  dedicated before which can be expensive for high dim data:  hence we allocate it outside of the main loop
no need for the center buffer if tol-based early stopping is  disabled
Initialize the centers using only a fraction of the data as we  expect n_samples to be very large when using MiniBatchKMeans
Compute the label assignment on the init dataset
Empty context to be used inplace by the convergence check routine
Perform the iterative optimization until the final convergence  criterion  Sample a minibatch from the full dataset
Monitor convergence and do early stopping if necessary
this is the first call partial_fit on this object:  initialize the cluster centers
separate function for each seed's iterative loop  For each seed, climb gradient until convergence or max_iter
Find mean of points within bandwidth
If converged or at max_iter, adds the cluster
nothing near seeds
Bin points
Author: Alexandre Gramfort <alexandre.gramfort@inria.fr>  License: BSD 3 clause
Place preference on the diagonal of S
Intermediate results
Execute parallel affinity propagation updates
tmp = A + S; compute responsibilities
tmp = Rnew
Damping
tmp = Rp; compute availabilities
Damping
Check for convergence
Reduce labels to a sorted, gapless, list
Author: Gael Varoquaux gael.varoquaux@normalesup.org          Brian Cheung          Wei LI <kuantkid@gmail.com>  License: BSD 3 clause
Normalize the rows of the eigenvectors.  Samples should lie on the unit  hypersphere centered at the origin.  This transforms the samples in the  embedding space to the space of partition matrices.
If there is an exception we try to randomize and rerun SVD again  do this max_svd_restarts times.
Initialize first column of rotation matrix with a row of the  eigenvectors
otherwise calculate rotation and continue
Authors: Manoj Kumar <manojkumarsivaraj334@gmail.com>           Alexandre Gramfort <alexandre.gramfort@telecom-paristech.fr>           Joel Nothman <joel.nothman@gmail.com>  License: BSD 3 clause
Keep centroids and squared norm as views. In this way  if we change init_centroids and init_sq_norm_, it is  sufficient,
We need to find the closest subcluster among all the  subclusters so that we can insert our new subcluster.
If the subcluster has a child, we need a recursive strategy.
If it is determined that the child need not be split, we  can just update the closest_subcluster
things not too good. we need to redistribute the subclusters in  our child node, and add a new subcluster in the parent  subcluster to accommodate the new child.
good to go!
not close to any other subclusters, and we still  have space, so add.
We do not have enough space nor is it closer to an  other subcluster. We need to split.
To enable getting back subclusters.
Cannot vectorize. Enough to convince to use cython.
Perform just the final global clustering step.
Called by partial_fit, before fitting.
Should raise an error if one does not fit before predicting.
To use in predict to avoid recalculation.
The global clustering step that clusters the subclusters of  the leaves. It assumes the centroids of the subclusters as  samples and finds the final centroids.
Affinity Propagation algorithm  Compute similarities  Compute Affinity Propagation
Test also with no copy
Test AffinityPropagation.predict
Test exception in AffinityPropagation.predict  Not fitted.
Predict not supported when affinity="precomputed".
Mock object for testing get_submatrix.
Overridden to reproduce old get_submatrix test.
Test Kluger methods on a checkerboard dataset.
cannot take log of sparse matrix
adding any constant to a log-scaled matrix should make it  bistochastic
perform label assignment using the dense array input
perform label assignment using the sparse CSR input
Check that dense and sparse minibatch update give the same results
extract a small minibatch
step 1: compute the dense minibatch update
compute the new inertia on the same batch to check that it decreased
check that the incremental difference computation is matching the  final observed value
step 2: compute the sparse minibatch update
compute the new inertia on the same batch to check that it decreased
check that the incremental difference computation is matching the  final observed value
step 3: check that sparse and dense updates lead to the same results
check that the number of clusters centers and distinct labels match  the expectation
check that the labels assignment are perfect (up to a permutation)
check error on dataset being too small
Reorder the labels so that the first instance is in cluster 0,  the second in cluster 1, ...
check that a warning is raised if the precompute_distances flag is not  supported
two regression tests on bad n_init argument  previous bug: n_init <= 0 threw non-informative TypeError (3858)
Check that a warning is raised, as the number clusters is larger  than the init_size
increase n_init to make random init stable enough
increase n_init to make random init stable enough
do the same with batch-size > X.shape[0] (regression test)  there should not be too many exact zero cluster centers
there should not be too many exact zero cluster centers
Give a perfect initialization, but a large reassignment_ratio,  as a result all the centers should be reassigned and the model  should not longer be good
Small test to check that giving the wrong number of centers  raises a meaningful error
Now check that the fit actually works
use the partial_fit API for online learning
compute the labeling on the complete dataset
Check if copy_x=False returns nearly equal X after de-centering.
check if my_X is centered
centers must not been collapsed
sanity check: predict centroid labels
sanity check: re-predict labeling for training set samples
re-predict labels for training set using fit_predict
sanity check: predict centroid labels
sanity check: re-predict labeling for training set samples
sanity check: re-predict labeling for training set samples
sanity check: predict centroid labels
check that models trained on sparse input also works for dense input at  predict time
sanity check: re-predict labeling for training set samples
sanity check: predict centroid labels
check that models trained on sparse input also works for dense input at  predict time
check that the labels assignment are perfect (up to a permutation)
check warning when centers are passed
to many clusters desired
Test that same global labels are obtained after calling partial_fit  with None
Test the predict method predicts the nearest centroid.
Test that n_clusters = Agglomerative Clustering gives  the same results.
Test that the wrong global clustering step raises an Error.
Test that a small number of clusters raises a warning.
Test that sparse and dense data give same results
Test that nodes have at max branching_factor number of subclusters
Raises error when branching_factor is set to one.
Test that the leaf subclusters have a threshold lesser than radius
Test estimate_bandwidth
Test MeanShift algorithm
Test MeanShift.predict
Non-regression: before fit, there should be not fitted attributes.
With a bin size of 0.01 and min_bin_freq of 1, 6 bins should be found  we bail and use the whole data here.
Authors: Vincent Michel, 2010, Gael Varoquaux 2012,           Matteo Visconti di Oleggio Castello 2014  License: BSD 3 clause
Smoke test FeatureAgglomeration
test hierarchical clustering on a precomputed distances matrix
test hierarchical clustering on a precomputed distances matrix
Test that using ward with another metric than euclidean raises an  exception
Check that fitting with no samples raises a ValueError
Test scikit linkage with full connectivity (i.e. unstructured) vs scipy
Test error management in _hc_cut
test on five random datasets
test that return_distance when set true, gives same  output on both structured and unstructured clustering.
get children
check if we got the same clusters
check if the distances are the same
check that the labels are the same
check that the distances are correct
check that the labels are the same
check that the distances are correct
Test that the full tree is computed if n_clusters is small
When n_clusters is less, the full tree should be built  that is the number of merges should be n_samples - 1
Test n_components returned by linkage, average and ward tree
Connectivity matrix having five components.
We don't care too much that it's good, just that it *worked*.  There does have to be some lower limit on the performance though.
raise error on unknown affinity
Tests the DBSCAN algorithm with a feature vector array.  Parameters chosen specifically for this task.  Different eps to other test, because distance is not normalised.  Compute DBSCAN  parameters chosen for task
number of clusters, ignoring noise if present
Tests the DBSCAN algorithm with a callable metric.  Parameters chosen specifically for this task.  Different eps to other test, because distance is not normalised.  metric is the function reference, not the string key.  Compute DBSCAN  parameters chosen for task
number of clusters, ignoring noise if present
Tests the DBSCAN algorithm with balltree for neighbor calculation.
number of clusters, ignoring noise if present
DBSCAN.fit should accept a list of lists.
ensure sample_weight is validated
sample_weight should work with precomputed distance matrix
sample_weight should work with estimator
Only the sample in the middle of the dense area is core. Its two  neighbors are edge samples. Remaining samples are noise.
It's no longer possible to extract core samples with eps=1:  everything is noise.
Calculate neighborhood for all samples. This leaves the original point  in, which needs to be considered later (i.e. point i is in the  neighborhood of point i. While True, its useless information)
This has worst case O(n^2) memory complexity
Initially, all samples are noise.
A list of all core samples found.
fix for scipy sparse indexing issue
no core samples
initialize with [-1,1] as in ARPACK
Make the connectivity matrix symmetric:
Convert connectivity matrix to LIL
Compute the number of nodes
prepare the main fields
update the moments
List comprehension is faster than a for loop
Separate leaves in children (empty lists up to now)  sort children to get consistent output with unstructured version
2 is scaling factor to compare w/ unstructured version
for the linkage function of hierarchy to work on precomputed  data, provide as first argument an ndarray of the shape returned  by pdist: it is a flat array containing the upper triangular of  the distance matrix.
Translate to something understood by scipy
Put the diagonal to zero
FIXME We compute all the distances, while we could have only computed  the "interesting" distances
create inertia heap and connection matrix
prepare the main fields
recursive merge loop  identify the merge
store distances
Keep track of the number of elements per cluster
Separate leaves in children (empty lists up to now)
return numpy array for efficient caching
Matching names to tree-building strategies
Early stopping is likely to give a speed up only for  a large number of clusters. The actual threshold  implemented here is heuristic
Author: Gael Varoquaux <gael.varoquaux@normalesup.org>  License: BSD 3 clause  Copyright: INRIA
The base class needs this for the score method
Covariance does not make sense for a single feature
The base class needs this for the score method
List of (alpha, scores, covs)
No need to see the convergence warnings on this grid:  they will always be points that will not converge  during the cross-validation  Compute the cross-validated loss on the current grid
Author: Virgile Fritsch <virgile.fritsch@inria.fr>  License: BSD 3 clause
Check early stopping
minimum breakdown value
avoid division truncation
set covariance  set precision
compute empirical covariance of the test set  compute log likelihood
compute mahalanobis distances
Check that the costs always decrease (doesn't hold if alpha == 0)  Check that the 2 approaches give similar results
Small subset of rows to test the rank-deficient case  Need to choose samples such that none of the variances are zero
Smoke test with specified alphas
Medium data set
Large data set
1D data set
Check that the code does not break with X.shape = (3, 1)  (i.e. n_support = n_samples)
test centered case
Tests ShrunkCovariance module on a simple dataset.  compare shrunk covariance obtained from data and from MLE estimate
same test with shrinkage not provided
same test with shrinkage = 0 (<==> empirical_covariance)
test shrinkage coeff on a simple data set (without saving precision)
Tests LedoitWolf module on a simple dataset.  test shrinkage coeff on a simple data set
test shrinkage coeff on a simple data set (without saving precision)
test shrinkage coeff on a simple data set (without saving precision)
Compare our blocked implementation to the naive implementation
check that the result is consistent with not splitting data into blocks.
test shrinkage coeff on a simple data set (without saving precision)
test shrinkage coeff on a simple data set (without saving precision)
avoid division truncation
optionally center data
number of blocks to split the covariance matrix into
formula from Chen et al.'s **implementation**
Not calling the parent object to fit, to avoid computing the  covariance matrix (and potentially the precision)
Calculate Spearman rho estimate and set return accordingly.
Use a 95% CI, i.e., +/-1.96 S.E.  https://en.wikipedia.org/wiki/Fisher_transformation
upper bound on the cost function
single y, constant prediction
Determine increasing if auto-determination requested
Store _X_ and _y_ to maintain backward compat during the deprecation  period of X_ and y_
Handle the left and right bounds on X
The ability to turn off trim_duplicates is only used to it make  easier to unit test that removing duplicates in y does not have  any impact the resulting interpolation function (besides  prediction speed).
Transform y by running the isotonic regression algorithm and  transform X accordingly.
It is necessary to store the non-redundant part of the training set  on the model to make it possible to support model persistence via  the pickle module as the object built by scipy.interp1d is not  picklable directly.
Build the interpolation function
copy __dict__  remove interpolation method
XXX Workaround that will be removed when list of list format is  dropped
To account for pos_label == 0 in the dense case
pick out the known labels from y
preserve label ordering
picks out all indices obtaining the maximum per row
For corner case where last row has a max of 0
Automatically increment on new class
sort classes and reorder columns
Compute the most frequent value in array only
Since two different arrays can be provided in fit(X) and  transform(X), the imputation data will be computed in transform()  when the imputation is done per sample (i.e., when axis=1).
Count the zeros
Mean
Mask the missing elements
Ignore the error, columns with a np.nan statistics_  are not an error at this point. These columns will  be removed in transform
astype necessary for bug in numpy.hsplit before v1.9
Median
Most frequent
Most frequent  scipy.stats.mstats.mode cannot be used because it will no work  properly if the first element is masked and if its frequency  is equal to the frequency of the most frequent valid element  See https://github.com/scipy/scipy/issues/2636
To be able access the elements by columns
Since two different arrays can be provided in fit(X) and  transform(X), the imputation data need to be recomputed  when the imputation is done per sample
Checking one attribute is enough, becase they are all set together  in partial_fit
Reset internal state before fitting
Cast input to array, as we need to check ndim. Prior to 0.17, that was  done inside the scaler object fit_transform.  If copy is required, it will be done inside the scaler object.
Checking one attribute is enough, becase they are all set together  in partial_fit
Reset internal state before fitting
Checking one attribute is enough, becase they are all set together  in partial_fit
Reset internal state before fitting
First pass  Next passes
Cast input to array, as we need to check ndim. Prior to 0.17, that was  done inside the scaler object fit_transform.  If copy is required, it will be done inside the scaler object.
allocate output data
No features selected.
All features selected.
Sparse matrix, axis = 0
Verify the shapes of the imputed matrix for different strategies.
np.median([]) raises a TypeError for numpy >= 1.10.1
np.mean([]) raises a RuntimeWarning for numpy >= 1.10.1
Test imputation using the mean and median strategies, when  missing_values != 0.
Create the columns
Shuffle them the same way
Mean doesn't support columns containing NaNs, median does
Test median imputation with sparse boundary cases
Test imputation within a pipeline + gridsearch.
Test for pickling imputers.
Test imputation with copy
Test scaling of dataset along single axis
check inverse transform
1-d inputs
This does not raise a warning as the number of samples is too low  to trigger the problem in recent numpy
Test scaling of 2d array along first axis
Check that X has been copied
check inverse transform
Check that the data hasn't been modified
Check that X has not been copied
Check that X has not been copied
Test if partial_fit run over many batches of size 1 and 50  gives the same results as fit
Test mean at the end of the process
Test std after 1 step
Test std until the end of partial fits, and
Test if partial_fit run over many batches of size 1 and 50  gives the same results as fit
Test mean at the end of the process
Test std until the end of partial fits, and
with_mean=False is required with sparse input
chunk = sparse.csr_matrix(data_chunks)
Check that sparsity is not destroyed
Check some postconditions after applying partial_fit and transform
(i+1) because the Scaler has been already fitted
raises on invalid range
Check min max scaler on toy data with zero variance features
function interface
Test scaling of dataset along single axis
check inverse transform
Check that X has not been modified (copy)
test that scaler converts integer input to floating  for both sparse and dense matrices
Check that X has not been modified (copy)
Check that StandardScaler.fit does not change input
check scaling and fit with direct calls on sparse data
check transform and inverse_transform after a fit on a dense array
Check if non finite inputs raise ValueError
test csc has same outcome
raises value error on axis != 0
Check that X has not been copied
null scale
function interface
Check warning when scaling integer data
Test scaling of dataset along single axis
check inverse transform
function interface
Test if partial_fit run over many batches of size 1 and 50  gives the same results as fit
Test mean at the end of the process
Test std after 1 step
Test std until the end of partial fits, and
set the row number 3 to zero
set the row number 3 to zero without pruning (can happen in real life)
build the pruned variant using the regular constructor
check inputs that support the no-copy optim
set the row number 3 to zero
set the row number 3 to zero without pruning (can happen in real life)
build the pruned variant using the regular constructor
check inputs that support the no-copy optim
set the row number 3 to zero
set the row number 3 to zero without pruning (can happen in real life)
build the pruned variant using the regular constructor
check inputs that support the no-copy optim
Cannot use threshold < 0 for sparse
center fit time matrix
check outcome
test negative input to fit
test negative input to transform
Edge case: all non-categorical
Edge case: all categorical
Test that one hot encoder raises error for unknown features  present during transform.
Raise error if handle_unknown is neither ignore or error.
Scalers that have a partial_fit method
with a different shape, this may break the scaler unless the internal  state is reset
Test that the numpy.log example still works.
Test that rounding is correct
Test that rounding is correct
Test that rounding is correct
Check that invalid arguments yield ValueError
Fail on y_type
Sequence of seq type should raise ValueError
Fail on the number of classes
Fail on the dimension of 'binary'
Test fit_transform
Check that invalid arguments yield ValueError
Fail on unseen labels
fit_transform()
fit().transform()
ensure fit is no-op as iterable is not consumed
fit().transform()
fit_transform()
Wrong shape
check label_binarize
check inverse
we want all classifiers that don't expose a random_state  to be deterministic (and we don't want to expose this one).
Compute the arithmetic mean of the predictions of the calibrated  classifiers
Normalize the probabilities
XXX : for some reason all probas can be 0
Deal with cases where the predicted probability minimally exceeds 1.0
extra_compile_args=['-O0 -fno-inline'],
FIXME Remove l1/l2 support in 1.0
FIXME Remove l1/l2 support in 1.0
get 1vs1 weights for all n*(n-1) classifiers.  this is somewhat messy.  shape of dual_coef_ is nSV * (n_classes -1)  see docs for details
dual coef for class1 SVs:  dual coef for class2 SVs:  build weight for class1 vs class2
The order of these must match the integer values in LibSVM.  XXX These are actually the same in the dense case. Need to factor  this out.
Used by cross_val_score.
XXX this is ugly.  Regression models should not have a class_weight_ attribute.
Precondition: X is a csr_matrix of dtype np.float64.
NOTE: _validate_for_predict contains check for is_fitted  hence must be placed before any other attributes are used.
In binary case, we need to flip the sign of coef, intercept and  decision function.
coef_ being a read-only property, it's better to mark the value as  immutable to avoid hiding potential bugs for the unsuspecting user.  sparse matrix do not have global flags  regular dense array
binary classifier
Regarding rnd.randint(..) in the above signature:  seed for srand in range [0..INT_MAX); due to limitations in Numpy  on 32-bit platforms, we can't get to the UINT_MAX limit that  srand supports
many class dataset:
test that the result with sorted and unsorted indices in csr is the same  we use a subset of digits as iris, blobs or make_classification didn't  show the problem
make sure dense and sparse SVM give the same result
make sure we scramble the indices
make sure unsorted indices give same result
multi class:
Test that it gives proper exception on deficient input  impossible value of C
impossible value of nu
Similar to test_SVC
check decision_function
sparsify the coefficients on both models and check that they still  produce the same results
Test class weights
Test weights on individual samples
Test that sparse liblinear honours intercept_scaling param
many class dataset:
Test that the "dense_fit" is called even though we use sparse input  meaning that everything works fine.
also load the iris dataset
If random_seed >= 0, the libsvm rng is seeded (by calling `srand`), hence  we should get deterministic results (assuming that there is no other  thread calling this wrapper calling `srand` concurrently).
Gram matrix for test data but compute KT[i,j]  for support vectors j only.
Bad kernel
Test OneClassSVM
Test OneClassSVM decision function
Generate train data
fit the model
Test decision_function  Sanity check, test that decision_function implemented in python  returns the same as the one in libsvm  multi class:
kernel binary:
with five classes:
linear kernel
rbf kernel
Test class weights  we give a small weights to class 1  so all predicted values belong to class 2
Test that it gives proper exception on deficient input  impossible value of C
impossible value of nu
error for precomputed kernelsx
sample_weight bad dimensions
predict with sparse input when trained with dense
Incorrect loss value - test if explicit error message is raised
FIXME remove in 1.0
Test basic routines using LinearSVC
by default should have intercept
the same with l1 penalty
l2 penalty with dual formulation
l2 penalty, l1 loss
test also decision function
similar prediction for ovr and crammer-singer:
classifiers shouldn't be the same
Test Crammer-Singer formulation in the binary case
when intercept_scaling is low the intercept value is highly "penalized"  by regularization
when intercept_scaling is sufficiently high, the intercept value  is not affected by regularization
when intercept_scaling is sufficiently high, the intercept value  doesn't depend on intercept_scaling value
binary-class case
stdout: redirect
actual call
Test that SVR(kernel="linear") has coef_ with the right sign.  Non-regression test for 2933.
wrap dictionary in a singleton list to support either dict  or list of dicts
Product function that can handle iterables (np.product can't).
This is used to make discrete sampling without replacement memory  efficient.  XXX: could memoize information used here
Reverse so most frequent cycling parameter comes first
Try the next grid
check if all distributions are given as lists  in this case we want to sample without replacement
look up sampled parameter settings in parameter grid
Out is a list of triplet: score, estimator, n_test_samples
Find the best parameters by comparing on the mean validation score:  note that `sorted` is deterministic in the way it breaks ties
Author: Mathieu Blondel <mathieu@mblondel.org>          Arnaud Joly <a.joly@ulg.ac.be>          Maheshakya Wijewardena <maheshakya.10@cse.mrt.ac.lk>  License: BSD 3 clause
Checking in case of constant strategy if the constant  provided by the user is in y.
numpy random_state expects Python int and not long as size argument  under Windows
Get same type even for self.n_outputs_ == 1  Compute probability only once
numpy random_state expects Python int and not long as size argument  under Windows
Get same type even for self.n_outputs_ == 1
flag to indicate exit status of fit() method: converged (True) or  n_iter reached (False)
EM algorithms  reset self.converged_ to False
Expectation step
Need to make sure that there are responsibilities to output  Output zeros because it was just a quick initialization
Gaussian mixture parameters estimators (used by the M-Step)
Attributes computation
Check all the parameters values of the derived class
if we enable warm_start, we will have a unique initialisation
ignore underflow
simple 3 cluster dataset
simple 3 cluster dataset
the same for spherical covariances
This function tests the deprecated old GMM class
Create a training set by sampling from the predefined distribution.
This function tests the deprecated old GMM class
This function tests the deprecated old GMM class  Test the aic and bic criteria
we build a dataset with 2 2d component. The components are unbalanced  (respective weights 0.9 and 0.1)
This is a non-regression test for issue 2640. The following call used  to trigger:  numpy.linalg.linalg.LinAlgError: 2-th leading minor not positive definite
Check positive definiteness for all covariance types
This function tests the deprecated old GMM class  Create sample data
This function tests the deprecated old GMM class  Create sample data
test bad parameters
Check good weights matrix
Check good means matrix
Define not positive-definite precisions
Check precisions with bad shapes
Check not positive precisions
Check the correct init of precisions_init
compare the precision matrix compute from the  EmpiricalCovariance.covariance fitted on X*sqrt(resp)  with _sufficient_sk_full, n_components=1
use equation Nk * Sk / N = S_tied
test against 'full' case
computing spherical covariance equals to the variance of one-dimension  data after flattening, n_components=1
test aginst with _naive_lmvnpdf_diag
full covariances
diag covariances
tied
test whether responsibilities are normalized
Check a warning message arrive if we don't do fit
recover the ground truth
needs more data to pass the test with rtol=1e-7
the accuracy depends on the number of data and randomness, rng
Assert the warm_start give the same result for the same number of iter
Assert that by using warm_start we can converge to a good solution
Check if the score increase
We check that each step of the EM without regularization improve  monotonically the training set likelihood
Do one training iteration at a time so we can make sure that the  training log likelihood increases after each iteration.
We train the GaussianMixture on degenerate data by defining two clusters  of a 0 covariance.
Free memory and developers cognitive load:
initialization step
EM algorithms  reset self.converged_ to False
Expectation step
Check for convergence.
Maximization step
Need to make sure that there is a z value to output  Output zeros because it was just a quick initialization
Weight labels by their number of occurrences
Distribute the most frequent labels first
Total weight of each fold
Mapping from label index to fold index
Distribute samples by adding the largest weight to the lightest fold
don't want to use the same seed in each label's shuffle
We make a copy of labels to avoid side-effects during iteration
random partition
pass through: skip indexing
Check for sparse predictions
Adjust length of sample weights
Adjust length of sample weights
cannot compute the kernel values with custom function
Initialization
Elimination  Remaining features
Rank the remaining features
Get ranks
for sparse case ranks is matrix
Eliminate the worse features
Compute step score on the previous selection iteration  because 'estimator' must use features  that have not been eliminated yet
Set final attributes
Compute step score when only n_features_to_select features left
Re-execute an elimination with best_k over the whole set
Fixing a normalization error, n is equal to get_n_splits(X, y) - 1  here, the scores are normalized by get_n_splits(X, y)
Author: Nikolay Mayorov <n59_ru@hotmail.com>  License: 3-clause BSD
Here we rely on NearestNeighbors to select the fastest algorithm.
Algorithm is selected explicitly to allow passing an array as radius  later (not all algorithms support this).
Ignore points with unique labels.
Selection  Fails in Python 3.x when threshold is str;  result is array of True
Check 1d list and other dtype:
Check wrong shape raises error
Check wrong shape raises error
Check 1d list and other dtype:
Check wrong shape raises error
Check wrong shape raises error
Feature 0 is highly informative for class 1;  feature 1 is the same everywhere;  feature 2 is a bit informative for class 2.
== doesn't work on scipy.sparse matrices
Check that chi2 works with a COO matrix  (as returned by CountVectorizer, DictVectorizer)  if we got here without an exception, we're safe
Check if the supports are equal
sparse model
All the noisy variable were filtered out
make sure that cross-validation is stratified
Test when floor(step * n_features) <= 0
Test when step is between (0,1) and floor(step * n_features) > 0
Test when step is an integer
test that is gives the same result as with float
Test whether the F test yields meaningful results  on a simple simulated classification problem
Test whether the F test yields meaningful results  on a simple simulated regression problem
Test whether f_regression returns the same value  for any numeric data_type
Test whether the F test yields meaningful results  on a simple simulated classification problem
Test whether the relative univariate feature selection  gets the correct items in a simple classification problem  with the percentile heuristic
Check other columns are empty
Test whether the relative univariate feature selection  gets the correct items in a simple classification problem  with the k best heuristic
Test whether k="all" correctly returns all features.
Test whether k=0 correctly returns no features.
Test whether the relative univariate feature selection  gets the correct items in a simple classification problem  with the fdr, fwe and fpr heuristics
Test whether the relative univariate feature selection  gets the correct items in a simple regression problem  with the percentile heuristic
Check inverse_transform respects dtype
Test whether the relative univariate feature selection  selects all features when '100%' is asked.
Test whether the relative univariate feature selection  gets the correct items in a simple regression problem  with the k best heuristic
Test whether the relative univariate feature selection  gets the correct items in a simple regression problem  with the fpr, fdr or fwe heuristics
Test that fdr heuristic actually has low FDR.
As per Benjamini-Hochberg, the expected false discovery rate  should be lower than alpha:  FDR = E(FP / (TP + FP)) <= alpha
Make sure that the empirical false discovery rate increases  with alpha:
Test whether the relative univariate feature selection  gets the correct items in a simple regression problem  with the fwe heuristic
Test whether k-best and percentiles work with tied pvalues from chi2.  chi2 will return the same p-values for the following features, but it  will return different scores.
Test for stable sorting in k-best with tied scores.
Assert that SelectKBest and SelectPercentile can handle NaNs.  First feature has zero variance to confuse f_classif (ANOVA) and  make it return a NaN.
In discrete case computations are straightforward and can be done  by hand on given vectors.
Mean of the distribution, irrelevant for mutual information.
Setup covariance matrix with correlation coeff. equal 0.5.
True theoretical mutual information.
Theory and computed values won't be very close, assert that the  first figures after decimal point match.
Assert the same tolerance.
Test that adding unique label doesn't change MI.
Here X[:, 0] is the most informative feature, and X[:, 1] is weakly  informative.
Test VarianceThreshold with custom variance.
Check with sample weights
Check that the model is rewritten if prefit=False and a fitted model is  passed
Check that prefit=True and calling fit raises a ValueError
Calculate the threshold from the estimator directly.
Set a higher threshold to filter out more features.
XXX where should this function be called? fit? scoring functions  themselves?
flatten matrix to vector in sparse case
Reuse f_obs for chi-squared statistics
compute the correlation
Request a stable sort. Mergesort takes more memory (~40MB per  megafeature on x86-64).
Now perform some acrobatics to set the right named parameter in  the selector
check if X has negative values. Doesn't play well with np.log.  zeroth component  1/cosh = sech  cosh(0) = 1.0
In the literature, this is `exp(E[log(theta)])`
diff on `component_` (only calculate it when `cal_diff` is True)
The next one is a copy, since the inner loop overwrites it.
Iterate between `doc_topic_d` and `norm_phi` until convergence
The optimal phi_{dwk} is proportional to  exp(E[log(theta_{dk})]) * exp(E[log(beta_{dw})]).
Contribution of document d to the expected sufficient  statistics for the M step.
In the literature, this is called `lambda`
In the literature, this is `exp(E[log(beta)])`
Run e-step in parallel
merge result
This step finishes computing the sufficient statistics for the  M-step.
E-step
update `component_` related variables
initialize parameters or check
normalize doc_topic_distr
compute E[log p(theta | alpha) - log q(theta | gamma)]
Compensate for the subsampling of the population of documents
E[log p(beta | eta) - log q (beta | lambda)]
some constant terms
handle corner cases first
This is the first partial_fit
Update stats - they are 0 if this is the fisrt step
NNDSVD initialization
and their norms
choose update
The following multiplication with a boolean array is more than twice  as fast as indexing into grad.
max(0.001, tol) to force alternating minimizations of W and H
stopping condition  as discussed in paper
L2 regularization corresponds to increase of the diagonal of HHt  adds l2_reg only on the diagonal  L1 regularization corresponds to decrease of each element of XHt
The following seems to be required on 64-bit Windows w/ Python 3.5.
so W and Ht are both in C order in memory
X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)
X_new = X * V = U * S * V^T * V = U * S
Handle n_components==None
Center data
flip eigenvectors' sign to enforce deterministic output
Get variance explained by singular values
Compute noise covariance using Probabilistic PCA model  The sigma2 maximum likelihood (cf. eq. 12.46)
Center data
sign flipping is done inside
Center data
Authors: Pierre Lafaye de Micheaux, Stefan van der Walt, Gael Varoquaux,           Bertrand Thirion, Alexandre Gramfort, Denis A. Engemann  License: BSD 3 clause
u (resp. s) contains the eigenvectors (resp. square roots of  the eigenvalues) of W * W.T
j is the index of the extracted component
builtin max, abs are faster than numpy counter parts.
Some standard non-linear functions.  XXX: these should be optimized, as they can be a bottleneck.
make interface compatible with other decompositions  a copy is required only for non whitened data
Centering the columns (ie the variables)
Whitening and preprocessing by PCA
see (13.6) p.267 Here X1 is white and data  in X has been projected onto a subspace by PCA
overwriting cov is safe
Not passing in verbose=max(0, verbose-1) because Lars.fit already  corrects the verbosity level.
Not passing in verbose=max(0, verbose-1) because Lars.fit already  corrects the verbosity level.
This ensure that dimensionality of code is always 2,  consistant with the case n_jobs > 1
Enter parallel code block
Avoid integer division problems
Fortran-order dict, as we are going to access its row vectors
If max_iter is 0, number of iterations returned should be zero
Cost function
assert(dE >= -tol * errors[-1])  A line return
Avoid integer division problems
If n_iter is zero, we need to return zero.
Update dictionary  XXX: Can the residuals be of any use?
Maybe we need a stopping criteria based on the amount of  modification in the dictionary
XXX : kwargs is not documented
If sparse and not csr or csc, convert to csr
svds doesn't abide by scipy.linalg.svd/randomized_svd  conventions, so reverse its outputs.
center kernel
compute eigenvectors
sort eigenvectors in descending order
remove eigenvectors with a zero eigenvalue
handle corner cases first
All elements are equal, but some elements are more equal than others.
We need a lot of components for the reconstruction to be "almost  equal" in all positions. XXX Test means or sums instead?
Assert the 1st component is equal
Assert that 20 components has higher explained variance than 10
Assert that all the values are greater than 0
Assert that total explained variance is less than 1
Compare sparse vs. dense
histogram kernel produces singular matrix inside linalg.solve  XXX use a least-squares approximation?
non-regression test: previously, gamma would be 0 by default,  forcing all eigenvalues to 0 under the poly kernel
transform new data
inverse transform
X_fit_ needs to retain the old, unmodified copy of X
transform new data
n_components=None (default) => remove_zero_eig is True
Test the linear separability of the first 2D KPCA transform
2D nested circles are not linearly separable
Project the circles data into the first 2 components of a RBF Kernel  PCA model.  Note that the gamma value is data dependent. If this test breaks  and the gamma value has to be updated, the Kernel PCA example will  have to be updated too.
The data is perfectly linearly separable in that space
PCA on dense arrays
Test get_covariance and get_precision
test explained_variance_ratio_ == 1 with all components
PCA on dense arrays
Loop excluding the extremes, invalid inputs for arpack
Test get_covariance and get_precision
PCA on dense arrays
Loop excluding the 0, invalid for randomized
Test get_covariance and get_precision
test if we avoid numpy warnings for computing over empty arrays
Check that PCA output has unit-variance
the component-wise variance is thus highly varying:
test fit_transform
in that case the output components still have varying variances  we always center, so no test for non-centering.
Ignore warnings from switching to more power iterations in randomized_svd  Check that PCA output has unit-variance
compare to empirical variances
Same with correlated data
Test that the projection of data can be inverted
Test that randomized PCA is inversible on dense data
Test that it gives different scores if whiten=True
case: n_components >= .8 * min(X.shape) => 'full'
Smoke test for the case of more components than features.
Test that sparse matrices are accepted as input
Test that the function is called in the same way, either directly  or through the NMF class
Y is defined by : Y = UV + noise
Test that CD gives similar results
Test that SparsePCA won't return NaN when there is 0 feature in all  samples.
Test that CD gives similar results
function as fun arg
Check that the mixing model described in the docstring holds:
test for issue 697
Test the FastICA algorithm on very simple data.
Mixing matrix
Check that the mixing model described in the docstring holds:
Check that we have estimated the original sources
reversibility test in non-reduction case
Incremental PCA on dense arrays.
Get the reconstruction of the generated data X  Note that Xt has the same "components" as X, just separated  This is what we want to ensure is recreated correctly
Normalize
Make sure that the first element of Yt is ~1, this means  the reconstruction worked as expected
Test that the projection of data can be inverted.
same check that we can find the original data from the transformed  signal (since the data is almost of rank n_components)
Test that n_components is >=1 and <= n_features.
Test that fit and partial_fit get equivalent results.
Test that IncrementalPCA and PCA are approximate (to a sign flip).
Test that IncrementalPCA and PCA are approximate (to a sign flip).
test verbosity
Ignore warnings from switching to more power iterations in randomized_svd  Test FactorAnalysis ability to recover the data covariance structure
Some random settings for the generative model  latent variable of dim 3, 20 of it  using gamma to model different noise variance  per component
generate observations  wlog, mean is 0
Sample Covariance
default prior parameter should be `1 / topics`  and verbose params should not affect result
Test LDA batch learning_offset (`fit` method with 'batch' learning)
Find top 3 words in each LDA component
Find top 3 words in each LDA component
Find top 3 words in each LDA component
test `_check_params` method
test pass dense matrix with sparse negative input.
Test the relationship between LDA score and perplexity
normalize 'votes' into real [0,1] probabilities
Mask mapping each class to its members.  Number of clusters in each class.
callable metric is only valid for brute force and ball_tree
For cross-validation routines to split data correctly
Include an extra neighbor to account for the sample itself being  returned, which is removed later
argpartition doesn't guarantee sorted order, so we sort again
If the query data is the same as the indexed data, we would like  to ignore the first nearest neighbor of every sample, i.e  the sample itself.
Corner case: When the number of duplicates are more  than the number of neighbors, the first NN will not  be the sample, but a duplicate.  In that case mask the first duplicate.
kneighbors does the None handling.
construct CSR matrix representation of the k-NN graph
See https://github.com/numpy/numpy/issues/5456  if you want to understand why this is initialized this way.
If the query data is the same as the indexed data, we would like  to ignore the first nearest neighbor of every sample, i.e  the sample itself.
run the choose algorithm code so that exceptions will happen here  we're using clone() in the GenerativeBayes classifier,  so we can't do this kind of logic in __init__
XXX: perhaps non-copying operation better
needed since _fit_X[np.array([])] doesn't work if _fit_X sparse
Called once on fitting, output is independent of hashes
Number of candidates considered including duplicates  XXX: not sure whether this is being calculated correctly wrt       duplicates from different iterations through a single tree
Creates a g(p,x) for each tree
Calculate hashes of shape (n_samples, n_estimators, [hash_size])
descend phase
Checks whether desired number of neighbors are returned.  It is guaranteed to return the requested number of neighbors  if `min_hash_match` is set to 0. Returned distances should be  in ascending order.
Test unfitted estimator
Desired number of neighbors should be returned.
Test unfitted estimator
Select a random point in the dataset as the query
At least one neighbor should be returned when the radius is the  mean distance from the query to the points of the dataset.
All distances to points in the results of the radius query should  be less than mean_dist
Multiple points
dists and inds should not be 1D arrays or arrays of variable lengths  hence the use of the object dtype.
Radius-based queries do not sort the result points and the order  depends on the method, the random_state and the dataset order. Therefore  we need to sort the results ourselves before performing any comparison.
Distances to exact neighbors are less than or equal to approximate  counterparts as the approximate radius query might have missed some  closer neighbors.
Build an exact nearest neighbors model as reference model to ensure  consistency between exact and approximate methods
Build a LSHForest model with hyperparameter values that always guarantee  exact results on this toy dataset.
define a query aligned with the first axis
Compute the exact cosine distances of the query to the four points of  the dataset
The first point is almost aligned with the query (very small angle),  the cosine distance should therefore be almost null:
The second point form an angle of 45 degrees to the query vector
The third point is orthogonal from the query vector hence at a distance  exactly one:
The last point is almost colinear but with opposite sign to the query  therefore it has a cosine 'distance' very close to the maximum possible  value of 2.
If we query with a radius of one, all the samples except the last sample  should be included in the results. This means that the third sample  is lying on the boundary of the radius query:
Checks whether returned neighbors are from closest to farthest.
Returned neighbors should be from closest to farthest, that is  increasing distance values.
Checks whether `fit` method sets all attribute values correctly.
Checks whether inserting array is consistent with fitted data.  `partial_fit` method should set all attribute values correctly.
Test unfitted estimator
Insert wrong dimension
size of _input_array = samples + 1 after insertion  size of original_indices_[1] = samples + 1  size of trees_[1] = samples + 1
For zero candidates
For candidates less than n_neighbors
Smoke tests for graph methods.
load and shuffle iris dataset
load and shuffle digits
Filter deprecation warnings.
Dist could be multidimensional, flatten it so all values  can be looped
Test unsupervised neighbors methods
test the types of valid input into NearestNeighbors
As a feature matrix (n_samples by n_features)
Check X=None in prediction
Must raise a ValueError if the matrix is not of correct shape
Test unsupervised radius-based query
Test prediction with y_str
Test k-NN classifier on multioutput data
Multioutput prediction
Test k-NN classifier on multioutput data
Multioutput prediction
Check proba
Test k-neighbors in multi-output regression with uniform weight
Test kneighbors_graph to build the k-Nearest Neighbor graph.
n_neighbors = 1
Test kneighbors_graph to build the k-Nearest Neighbor graph  for sparse input.
Test radius_neighbors_graph to build the Nearest Neighbor graph.
Test radius_neighbors_graph to build the Nearest Neighbor graph  for sparse input.
Test bad argument values: these should all raise ValueErrors
Test computing the neighbors for various metrics  create a symmetric matrix
KD tree doesn't support all metrics
Find a reasonable radius.
Test kneighbors et.al when query is None
don't check indices here: if there are any duplicate distances,  the indices may not match.  Distances should not have this problem.
Test if BallTree with callable metric is picklable
simultaneous sort rows using function
simultaneous sort rows using numpy
make boolean arrays: ones and zeros
Check if both callable metric and predefined metric initialized  DistanceMetric object is picklable
don't check indices here: if there are any duplicate distances,  the indices may not match.  Distances should not have this problem.
simultaneous sort rows using function
simultaneous sort rows using numpy
draw a tophat sample
check that samples are in the right range
5 standard deviations is safe for 100 samples, but there's a  very small chance this test could fail.
Smoke test for various metrics and algorithms
toy sample
Check classification on a toy dataset, including sparse versions.
Same test, but with a sparse matrix to fit and test.
Fit with sparse, test with non-sparse
Fit with non-sparse, test with sparse
Fit and predict with non-CSR sparse matrices
classification
repeat input validation for grid search (which calls set_params)
remove the color dimension if useless
divide by the amount of overlap  XXX: is this the most efficient way? memory-wise yes, cpu wise?
handle stop words
normalize white spaces
normalize white spaces
triggers a parameter validation
Alias transform to fit_transform for convenience
Add a new value when a new vocabulary item is seen
Ignore out-of-vocabulary items for fixed_vocab=True
disable defaultdict behaviour
We intentionally don't call the transform method to make  fit_transform overridable without unwanted side effects in  TfidfVectorizer.
use the same matrix-building strategy as fit_transform
We need CSR format for fast row manipulations.
We need to convert X to a matrix, so that the indexing  returns 2D objects
perform idf smoothing if required
log+1 instead of log makes sure terms with zero idf don't get  suppressed entirely.
preserve float family dtype
convert counts or binary occurrences to floats
*= doesn't work
X is already a transformed view of raw_documents so  we set copy to False
Test delayed input validation in fit (useful for grid search).
Assert that no zeros are materialized in the output.
Negative elements are the diagonal: the elements of the original  image. Positive elements are the values of the gradient, they  should all be equal on grad_x and grad_y
Checking that the function works whatever the type of mask is
Newer versions of scipy have face in misc
Newer versions of scipy have face in misc
Newer versions of scipy have face in misc
make a collection of faces
CSR matrices can't be compared for equality
check that the memory layout does not impact the resulting vocabulary
check some classical latin accentuated symbols
mix letters accentuated and not
check some classical latin accentuated symbols
mix letters accentuated and not
decode_error default to strict, so this should fail  First, encode (as bytes) a unicode string.
Then let the Analyzer try to decode it as ascii. It should fail,  because we have given it an incorrect encoding.
fit on stopwords only
check normalization
check normalization
the lack of smoothing make IDF fragile in the presence of feature with  only zeros
raw documents as an iterator
build a vectorizer v1 with the same vocabulary as the one fitted by v1
compare that the two vectorizer give the same output on the test sample
stop word from the fixed list
stop word found automatically by the vectorizer DF thresholding  words that are high frequent across the complete corpus are likely  to be not informative (either real stop words of extraction  artifacts)
test tf-idf with new data
test tf alone
test idf transform with unlearned idf vector
test idf transform with incompatible n_features
L1-normalized term frequencies sum to one
test the direct tfidf vectorizer  (equivalent to term count vectorizer + tfidf transformer)
test the direct tfidf vectorizer with new data
test transform on unfitted vectorizer with empty vocabulary
ascii preprocessor?
error on bad strip_accents param
error with bad analyzer type
Check that the rows are normalized
ngrams generate more non zeros
makes the feature values bounded
Check that the rows are normalized
test for Value error on unfitted/empty vocabulary
test bounded number of extracted features
The most common feature is "the", with frequency 7.
check the ability to change the dtype
check the ability to change the dtype
raw documents
label junk food as -1, the others as +1
split the dataset for model development and final evaluation
find the best parameters for both the feature extraction and the  classifier
Check that the best model found by grid search is 100% correct on the  held out evaluation set.
on this toy dataset bigram representation which is used in the last of  the grid_search is considered the best estimator since they all converge  to 100% accuracy models
raw documents
label junk food as -1, the others as +1
split the dataset for model development and final evaluation
find the best parameters for both the feature extraction and the  classifier
Check that the best model found by grid search is 100% correct on the  held out evaluation set.
raw documents
label junk food as -1, the others as +1
No collisions on such a small dataset
When norm is None and non_negative, the tokens are counted up to  collisions
np.nan can appear when using pandas to load text fields from a csv file  with missing values.
Non-regression test: TfidfVectorizer used to ignore its "binary" param.
Process everything as sparse regardless of setting
XXX we could change values to an array.array as well, but it  would require (heuristic) conversion of dtype to typecode...
COO matrix is not subscriptable
XXX remove in 0.19 when r2_score default for multioutput changes
shallow copy of steps
check if first estimator expects pairwise input
if we have a weight for this transformer, multiply output
Determine output settings
reshape is necessary to preserve the data contiguity against vs  [:, np.newaxis] that does not.
Check parameters
Set min_weight_leaf from min_weight_fraction_leaf
Allow presort to be 'auto', which means True if the dataset is dense,  otherwise it will be False.
Use BestFirst if max_leaf_nodes given; use DepthFirst otherwise
Classification
Regression
Initialize saturation & value; calculate chroma & value shift
Generate the node content string
Should labels be shown?
Write node ID
Clean up any trailing newlines
Add node with description
color cropped nodes grey
Add edge to parent
The depth of each node for plotting with 'leaf' option  The colors to render each node with
Now recurse the tree and add node & edge attributes
Check correctness of export_graphviz
Test multi-output with weighted samples
Test regression output with plot_options
Test classifier with degraded learning set
Check for errors of export_graphviz
Check feature_names error
Check class_names error
also load the boston dataset  and randomly permute it
Check classification on a weighted toy dataset.
Check on a XOR problem
Check the array representation.  Check resize
Check when y is pure.
Check variable importances.
Check if variable importance before fit raises ValueError.
use values of max_features that are invalid
Test that it gives proper exception on deficient input.  predict before fit
Wrong dimensions
Test with arrays that are non-contiguous.
predict before fitting
predict on vector with different dims
wrong sample shape
apply before fitting
test both DepthFirstTreeBuilder and BestFirstTreeBuilder  by setting max_leaf_nodes
test for integer parameter  count samples on nodes, -1 means it is a leaf
test for float parameter  count samples on nodes, -1 means it is a leaf
Test if leaves contain more than leaf_count training examples
test both DepthFirstTreeBuilder and BestFirstTreeBuilder  by setting max_leaf_nodes
drop inner nodes
Check on dense input
Check on sparse input
Test that n_classes_ and classes_ have proper shape.  Classification, single output
Check class rebalancing.
Check that it works no matter the memory layout
Nothing
Contiguous
csr matrix
csc_matrix
Check sample weighting.  Test that zero-weighted samples are not taken into account
Test that low weighted samples are not taken into account at low depth
Test that sample weighting is the same as having duplicates
Check sample weighting raises errors.
Test if class_weight raises errors and warnings when expected.
Invalid preset string
Not a list or preset for multi-output
Incorrect length list for multi-output
Sanity check: we cannot request more memory than the size of the address  space. Currently raises OverflowError.
Non-regression test: MemoryError used to be dropped by Cython  because of missing "except *".
Gain testing time
Check the default (depth first search)
Due to numerical instability of MSE and too strict test, we limit the  maximal depth
n_samples set n_feature to ease construction of a simultaneous  construction of a csr and csc matrix
Ensure that X_sparse_test owns its data, indices and indptr array
Ensure that we have explicit zeros
Perform the comparison
Private function to keep pretty printing in nose yielded tests
Assert that leaves index are correct
Ensure only one leave node per sample
Ensure max depth is consistent with sum of indicator
Currently we don't support sparse y
Authors: Clay Woolam <clay@woolam.org>  Licence: BSD
kernel parameters
clamping factor
actual graph construction (implementations should override this)
label construction  construct a categorical distribution for classification only
initialize distributions
clamp
set the transduction item
this one has different base parameters
iterate over the collected file path to load the jpeg files as numpy  arrays
Checks if jpeg reading worked. Refer to issue 3594 for more  details.
average the color channels to compute a gray levels  representation
wrap the loader in a memoizing function that will return memmaped data  arrays for optimal memory usage
load and memoize the pairs as np arrays
pack the results as a Bunch instance
wrap the loader in a memoizing function that will return memmaped data  arrays for optimal memory usage
load and memoize the pairs as np arrays
pack the results as a Bunch instance
selected abnormal samples:
select all samples with positive logged_in attribute:
The zlib compression format use by joblib is not compatible when  switching from Python 2 to Python 3, let us use a separate folder  under Python 3:
Backward compat for Python 2 users
Samples in X are ordered with sample_id,  whereas in y, they are ordered with sample_id_bis.
save category names in a list, with same order than y
reorder categories in lexicographic order
Python 2
Python 3
Numpy recarray wants Python 2 str but not unicode
Numpy recarray wants Python 3 str but not bytes...
x coordinates of the grid cells  y coordinates of the grid cells
Define parameters for the data files.  These should not be changed  unless the data model changes.  They will be saved in the npz file  with the downloaded data.
Python 2
Python 3+
normalize dataset name
check if this data set has been already downloaded
load dataset matlab file
flatten column names
if target or data names are indices, transform then into names
1) there is only one array => it is considered data  2) there are multiple arrays
Download is not complete as the .tar.gz file is removed after  download.
Use an object array to shuffle: avoids memory copy
we shuffle but use a fixed seed for the memoization
the data is stored as int16 for compactness  but normalize needs floats
XXX remove closing when Python 2.7+/3.1+ required
convert from array.array, give data the right dtype
Python 2
Python 3
Grab the module-level docstring to use as a description of the  dataset
convert to array for fancy indexing
last column is target value
Initialize X and y
Initially draw informative features from the standard normal
Create each cluster; a variant of make_blobs
Fill useless features
Randomly replace labels
Randomly shift and scale
Randomly permute samples
Randomly permute features
pick a nonzero number of labels per document by rejection sampling
pick a non-zero document length by rejection sampling
generate a document of length n_words  if sample does not belong to any class, generate noise word
Randomly generate a well conditioned input set
Randomly generate a low rank, fat tail input set
Generate a ground truth model with only n_informative features being non  zeros (the other features are not correlated to y and should be ignored  by a sparsifying regularizers such as L1 or elastic net)
Add noise
Randomly permute samples and features
Index of the singular values
generate dictionary
encode signal
Permute the lines: we don't want to have asymmetries in the final  SPD matrix
Form the diagonal vector into a row matrix
Build multivariate normal distribution
Sort by distance from origin
Label by quantile
Python 2
Python 3+
Grab the module-level docstring to use as a description of the  dataset
Columns are not in the same order compared to the previous  URL resource on lib.stat.cmu.edu
avg rooms = total rooms / households
avg bed rooms = total bed rooms / households
avg occupancy = population / households
target in units of 100,000
get_data_home will point to a pre-existing folder
clear_data_home will delete both the content and the folder it-self
if the folder is missing it will be created again
Create very separate clusters; check that vertices are unique and  correspond to classes
Cluster by sign, viewed as strings to allow uniquing
Also test return_distributions and return_indicator with True
Test that y ~= np.dot(X, c) + bias + N(0, 1.0).
Test that y ~= np.dot(X, c) + bias + N(0, 1.0)
Check that the number of filenames is consistent with data/target
This test is slow.
create temporary dir
remove temporary dir
create fake data set in cache
transposing the data array
test sparsity
test shuffling and subset
The first 23149 samples are the training samples
test some precise values
test X's shape
test can change X's values
test y
test loading from file descriptor
test X'shape
21 features in file
because we "close" it manually and write to it,  we need to remove it manually.
because we "close" it manually and write to it,  we need to remove it manually.
in python 3 integers are valid file opening arguments (taken as unix  file descriptors)
slicing a csr_matrix can unsort its .indices, so test that we sort  those correctly
make sure y's shape is: (n_samples, n_labels)  when it is sparse
allow a rounding error at the last decimal place
allow a rounding error at the last decimal place
XXX we have to update this to support Python 3.x
The data is croped around the center as a rectangular bounding box  around the face. Colors are converted to gray levels:
the target is array of person integer ids
names of the persons can be found using the target_names array
It is possible to ask for the original data without any croping or color  conversion and not limit on the number of picture per person
The data is croped around the center as a rectangular bounding box  around the face. Colors are converted to gray levels:
the target is whether the person is the same or not
names of the persons can be found using the target_names array
It is possible to ask for the original data without any croping or color  conversion
the ids and class names are the same as previously
Strip trailing space to avoid nightmare in doctests
fetch the constructor or the original constructor before  deprecation wrapping if any  No explicit constructor to introspect
Simple optimisation to gain speed (inspect is slow)
non-optimized default implementation; override when a better  method is possible for a given clustering algorithm
non-optimized default implementation; override when a better  method is possible for a given clustering algorithm  fit method of arity 1 (unsupervised transformation)  fit method of arity 2 (supervised transformation)
We can't have more than one value on y_type => The set is no more needed
No metrics support "multiclass-multioutput" format
intersect y_pred, y_true with labels, eliminate items not in labels  also eliminate weights of eliminated items
If there is no label, it results in a Nan instead, we set  the jaccard to 1: lim_{x->0} x/x = 1  Note with py2.6 and np 1.3: we can't check safely for nan.
remove infs
build appropriate warning  E.g. "Precision and F-score are ill-defined and being set to 0.0 in  labels with no predicted samples"
Only negative labels
calculate weighted counts
labels are now from 0 to len(labels) - 1 -> use bincount
Pathological case
Retain only selected labels
Clipping
This happens in cases when elements in y_pred have type "str".
If y_pred is of single dimension, assume y_true to be binary  and then check.
Renormalize
Handles binary class case  this code assumes that positive and negative labels  are encoded as +1 and -1 respectively
The hinge_loss doesn't penalize good enough predictions.
the exact version is faster for k == 2: use it by default globally in  this module instead of the float approximate variant
Compute the ARI using the contingency data
log(a / b) should be calculated as log(a) - log(b) for  possible loss of precision
B contains 2 of the 3 biclusters in A, so score should be 2/3
Assert 1 < n_labels < n_samples
Check that adjusted scores are almost zero on random labels
Test for regression where contingency cell exceeds 2**16  leading to overflow in np.outer, resulting in EMI > 1
For sample i, store the mean distance of the cluster to which  it belongs in intra_clust_dists[i]
For sample i, store the mean distance of the second closest  cluster in inter_clust_dists[i]
Find inter_clust_dist for all samples belonging to the same  label.
Leave out current sample.
Now iterate over all other labels, finding the mean  cluster distance that is closest to every sample.
pass None as weights to np.average: uniform mean
pass None as weights to np.average: uniform mean
return scores individually
passing to np.average() None as weights results is uniform mean
For multi-output multi-class estimator
Standard regression scores
Standard Classification Scores
Score functions that need decision values
Score function for probabilistic classification
Clustering scores
reorder the data points according to the x axis and using y to  break ties
Reductions such as .sum used internally in np.trapz do not return a  scalar by default for numpy.memmap instances contrary to  regular numpy.ndarray instances.
make y_true a boolean vector
sort scores and corresponding truth values
y_score typically has many tied values. Here we extract  the indices associated with the distinct values. We also  concatenate a value for the end of the curve.  We need to use isclose to avoid spurious repeated thresholds  stemming from floating point roundoff errors.
stop when full recall attained  and reverse the outputs so recall is decreasing
Add an extra threshold position if necessary
doctest: +ELLIPSIS
If all labels are relevant or unrelevant, the score is also  equal to 1. The label ranking has no meaning.
if the scores are ordered, it's possible to count the number of  incorrectly ordered paires in linear time by cumulatively counting  how many false labels of a given score have a score higher than the  accumulated true labels with lower score.
When there is no positive or no negative labels, those values should  be consider as correct, i.e. the ranking doesn't matter.
swap average_weight <-> score_weight
Average the results
Ensure that distances between vectors and themselves are set to 0.0.  This may not be the case due to floating point rounding errors.
Allocate output arrays
Update indices and minimum values using chunk
1.0 - cosine_similarity(X, Y) without copy
Helper functions - distance  If updating this dictionary, update the doc in both distance_metrics()  and also in pairwise_distances()!
Special case to avoid picklability checks in delayed
Make symmetric  NB: out += out.T will produce incorrect results
Calculate diagonal  NB: nonzero diagonals are allowed for both metrics and kernels
import GPKernel locally to prevent circular imports
Test that a value error is raised if the metric is unknown
Test always returns float dtype
Test converts list to array-like
Not all metrics support sparse input  ValueError may be triggered by bad callable
paired_distances should allow callable metric where metric(x, x) != 0  Knowing that the callable is a strict metric would allow the diagonal to  be left uncalculated and set to 0.
Callable version of pairwise.rbf_kernel.
callable function, X=Y
Test that a value error is raised when the lengths of X and Y should not  differ
Check pairwise minimum distances computation for any metric
Non-euclidean Scipy distance (callable)
Compare with naive implementation
Check the pairwise Euclidean distances computation
Check the paired Euclidean distances computation
Check the paired manhattan distances computation
test negative input
different n_features in X and Y
sparse matrices
the diagonal elements of a linear kernel are their squared norm
the diagonal elements of a rbf kernel are 1
the diagonal elements of a laplacian kernel are 1
off-diagonal elements are < 1 but > 0:
Turns a numpy matrix (any n-dimensional array) into tuples.  Tuplify each sub-array in the input.  Single dimension input, just return tuple of contents.
both float32
mismatched A
mismatched B
Those metrics don't support binary inputs
Those metrics don't support multiclass inputs
Metric undefined with "binary" or "multiclass" input
Metrics with an "average" argument
Threshold-based metrics with an "average" argument
Metrics with a "pos_label" argument
pos_label support deprecated; to be removed in 0.18:
Metrics with a "normalize" option
Threshold-based metrics with "multilabel-indicator" format support
Classification metrics with  "multilabel-indicator" format
Regression metrics with "multioutput-continuous" format support
Symmetric with respect to their input arguments y_true and y_pred  metric(y_true, y_pred) == metric(y_pred, y_true).
Asymmetric with respect to their input arguments y_true and y_pred  metric(y_true, y_pred) != metric(y_pred, y_true).
No Sample weight support
not work for confusion_matrix, as its output is a  matrix instead of a number. Testing of  confusion_matrix with sample_weight is in  test_classification.py
Test the symmetry of score and loss functions
We shouldn't forget any metrics
Symmetric metric
Mix format support
NB: We do not test for y1_row, y2_row as these may be  interpreted as multilabel or multioutput data.
Ensure that classification metrics with string labels
Ugly, but handle case with a pos_label and label
Ugly, but handle case with a pos_label and label
Non-regression test: scores should work with a single sample.  This is important for leave-one-out cross validation.  Score functions tested are those that formerly called np.squeeze,  which turns an array of size 1 into a 0-d array (!).
assert that no exception is thrown
Those metrics are not always defined with one sample  or in multiclass classification
Generate some data
To make sure at least one empty label is present
XXX cruel hack to work with partial functions
Check representation invariance
Test in the binary case
Test in the multilabel case
for both random_state 0 and 1, y_true and y_pred has at least one  unlabelled entry
To make sure at least one empty label is present
No averaging
Micro measure
Macro measure
Weighted measure
Test _average_binary_score for weight.sum() == 0
check that the score is invariant under scaling of the weights by a  common factor
Check that if sample_weight.shape[0] != y_true.shape[0], it raised an  error
GC closes the mmap file descriptors
Test that all scorers have a working repr
check that cross_val_score definitely calls the scorer  and doesn't make any assumptions about the estimator apart from having a  fit.
Sanity check on the make_scorer factory function.
test fbeta score that takes an argument
test that custom scorer can be pickled
smoke test the repr:
Test that the scorer work with multilabel-indicator format  for multilabel and multi-output multi-class classifier
get sensible estimators for each metric
Non-regression test for 6147: some score functions would  return singleton memmap when computed on memmap data instead of scalar  float values.
import some data to play with
restrict to a binary classification task
add noisy features to make the problem harder and avoid perfect results
run classifier, get class probabilities and label predictions
only interested in probabilities of the positive case  XXX: do we really want a special API for the binary case?
Test Area under Receiver Operating Characteristic (ROC) curve
Test whether the returned threshold matches up with tpr  make small toy dataset
compare tpr and tpr_correct to see if the thresholds' order was correct
Test to ensure that we don't return spurious repeating thresholds.  Duplicated thresholds can arise due to machine precision issues.
This random forest classifier can only return probabilities  significant to two decimal places
How well can the classifier predict whether a digit is less than 5?  This task contributes floating point roundoff errors to the probabilities
Check for repeating values in the thresholds
roc_curve not applicable for multi-class problems
roc_curve for confidence scores
roc_curve for hard decisions
Incompatible shapes
Too few x values
x is not in order
y_true contains three different class values
Use {-1, 1} for labels; make sure original labels aren't modified
Contains non-binary labels
Test that average_precision_score and roc_auc_score are invariant by  the scaling or shifting of probabilities
No relevant labels
Only relevant labels
Degenerate case: only one label
Check tie handling in score  Basic check with only ties and increasing label space
Check that Label ranking average precision works for various  Basic check with increasing label space size and decreasing score
The best rank correspond to 1. Rank higher than 1 are worse.  The best inverse ranking correspond to n_labels.
Rank need to be corrected to take into account ties  ex: rank 1 ex aequo means that both label are rank 2.
Let's count the number of relevant label with better rank  (smaller rank).
Weight by the rank of the actual label
Score with ties
import some data to play with
restrict to a binary classification task
add noisy features to make the problem harder and avoid perfect results
run classifier, get class probabilities and label predictions
only interested in probabilities of the positive case  XXX: do we really want a special API for the binary case?
Dense label indicator matrix format
Test Precision Recall and F1 Score for binary classification task
ensure the above were meaningful tests:
Test that average_precision_score function returns an error when trying  to compute average_precision_score for multiclass task.
y_true contains three different class values
Bad beta
Bad pos_label
Bad average option
Test confusion matrix - binary classification case
Add spurious labels and ignore them.
corrcoef of same vectors must be 1
corrcoef, when the two vectors are opposites of each other, should be -1
For the zero vector case, the corrcoef cannot be calculated and should  result in a RuntimeWarning
But will output 0
And also for any other vector with 0 variance
But will output 0
Check that sample weight is able to selectively exclude  Now the first half of the vector elements are alone given a weight of 1  and hence the mcc will not be a perfect 0 as in the previous case
Test Precision Recall and F1 Score for multiclass classification task
averaging tests
compute scores with default labels introspection
Test confusion matrix - multi-class case
compute confusion matrix with default labels introspection
Test confusion matrix - multi-class case with subset of labels
compute confusion matrix with only first two labels considered
compute confusion matrix with explicit label ordering for only subset  of labels
Test performance report
Test performance report with added digits in floating point values
Dense label indicator matrix format
sp_hamming only works with 1-D arrays
Dense label indicator matrix format
Ensure warning if f1_score et al.'s average is implicit for multiclass
check binary passes without warning
check that we got all the shapes and axes right  by doubling the length of y_true and y_pred
mean_absolute_error and mean_squared_error are equal because  it is a binary problem.
evecs /= np.linalg.norm(evecs, axis=0)   doesn't work with numpy 1.6
1) within (univariate) scaling by with classes std-dev  avoid division by zero in normalization
2) Within variance scaling  SVD of centered (within)scaled data
Scaling of within covariance is: V' 1/S
OvR normalization, like LibLinear's predict_probability
handle special case of two classes
compute the likelihood of the underlying gaussian models  up to a multiplicative constant.  compute posterior probabilities
XXX : can do better to avoid precision overflows
Objective: C (Kullback-Leibler divergence of P and Q)
Objective: C (Kullback-Leibler divergence of P and Q)
Degrees of freedom of the Student's t-distribution. The suggestion  degrees_of_freedom = n_components - 1 comes from  "Learning a Parametric Embedding by Preserving Local Structure"  Laurens van der Maaten, 2009.  the number of nearest neighbors to find
Use the precomputed distances to find  the k nearest neighbors and their distances
Find the nearest neighbors for every point  LvdM uses 3 * perplexity as the number of neighbors  And we add one to not count the data point itself  In the event that we have very small  of points  set the neighbors to n - 1
Initialize embedding randomly
Don't always calculate the cost since that calculation  can be nearly as expensive as the gradient
Early exaggeration
Save the final number of iterations
Final optimization
Randomly choose initial configuration
overrides the parameter p
Compute distance and monotonic regression
similarities with 0 are considered as missing values
Compute stress
speed up row-wise access to boolean connection mask
sparse graph, find all the connected components
dense graph, find all connected components start from node 0
Whether to drop the first eigenvector
lobpcg used with eigen_solver='amg' has bugs for low number of nodes  for details see the source code in scipy:  https://github.com/scipy/scipy/blob/v0.11.0/scipy/sparse/linalg/eigen  /lobpcg/lobpcg.pyL237  or matlab:  http://www.mathworks.com/matlabcentral/fileexchange/48-lobpcg-m
currently only symmetric affinity_matrix supported
Not symmetric similarity matrix:
Not squared similarity matrix:
init not None and not correct format:
Isomap should preserve distances when all neighbors are used
grid of equidistant points in 2D, n_components = n_dim
distances from each point to all others
Same setup as in test_isomap_simple_grid, with an added dimension
grid of equidistant points in 2D, n_components = n_dim
add noise in a third dimension
compute input kernel
compute output kernel
make sure error agrees
Create S-curve dataset
Compute isomap embedding
Re-embed a noisy version of the points
Make sure the rms error on re-embedding is comparable to noise_scale
Test utility routines
note: ARPACK is numerically unstable, so this test will fail for        some random seeds.  We choose 2 because the tests pass.
re-embed a noisy version of X using the transform method
Test the error raised when parameter passed to lle is invalid
Test stopping conditions of gradient descent.
Test that the highest P_ij are the same when few neighbors are used
Test gradient of Kullback-Leibler divergence.
Test trustworthiness score.
Affine transformation
Early exaggeration factor must be >= 1.
Number of gradient descent iterations must be at least 200.
Precomputed distance matrices must be square matrices.
'init' must be 'pca' or 'random'.
Verbose options write to stdout.
t-SNE should allow metrics that cannot be squared (issue 3526).
When Barnes-Hut's angle=0 this corresponds to the exact method.
Introduce a point into a quad tree where a similar point already exists.  Test will hang if it doesn't complete.
check the case where points are arbitrarily close on both axes  close to machine epsilon - x axis
check the case where points are arbitrarily close on both axes  close to machine epsilon - y axis
Make sure translating between 1D and N-D indices are preserved
Connect all elements within the group at least once via an  arbitrary path that spans the group.
We should retrieve the same component mask by starting by both ends  of the group
connection
Test spectral embedding with amg solver
Test that SpectralClustering fails with an unknown eigensolver
Test that SpectralClustering fails with an unknown affinity type
Verify using manual computation with dense eigh
this might raise a LinalgError if G is singular and has trace  zero
build Hessian estimator
find the eigenvectors and eigenvalues of each local covariance  matrix. We want V[i] to be a [n_neighbors x n_neighbors] matrix,  where the columns are eigenvectors
choose the most efficient way to find the eigenvectors
find regularized weights: this is like normal LLE.  because we've already computed the SVD of each covariance matrix,  it's faster to use this rather than np.linalg.solve
calculate eta: the median of the ratio of small to large eigenvalues  across the points.  This is used to determine s_i, below
Now calculate M.  This is the [N x N] matrix whose null space is the desired embedding
select bottom s_i eigenvectors and calculate alpha
compute Householder matrix which satisfies   Hi*Vi.T*ones(n_neighbors) = alpha_i*ones(s)  using prescription from paper
compute n_components largest eigenvalues of Xi * Xi^T
wrap dictionary in a singleton list to support either dict  or list of dicts
Product function that can handle iterables (np.product can't).
This is used to make discrete sampling without replacement memory  efficient.  XXX: could memoize information used here
Reverse so most frequent cycling parameter comes first
Try the next grid
check if all distributions are given as lists  in this case we want to sample without replacement
look up sampled parameter settings in parameter grid
Out is a list of triplet: score, estimator, n_test_samples
Find the best parameters by comparing on the mean validation score:  note that `sorted` is deterministic in the way it breaks ties
We need this for the build_repr to work properly in py2.7  see 6304
Weight labels by their number of occurrences
Distribute the most frequent labels first
Total weight of each fold
Mapping from label index to fold index
Distribute samples by adding the largest weight to the lightest fold
We make a copy of labels to avoid side-effects during iteration
random partition
int values are checked during split based on the input
int values are checked during split based on the input
cannot compute the kernel values with custom function
training score becomes worse (2 -> 1), test error better (0 -> 1)
Smoke test
test with multioutput y
test with multioutput y
test with X and y as list
test with 3d X and
Check if ValueError (when labels is None) propagates to cross_val_score  and cross_val_predict  And also check if labels is correctly passed to the cv object
Error raised for non-square X
test error is raised when the precomputed kernel is not array-like  or sparse
Default score of the Ridge regression estimator
test with custom scoring object
set random y
Naive loop (should be same as cross_val_predict):
3 fold cv is used --> atleast 3 samples per class  Smoke test
test with multioutput y
test with multioutput y
test with X and y as list
The mockup does not have partial_fit()
Naive loop (should be same as cross_val_predict):
Special case: empty grid (useful to get default estimator settings)
Smoke test the score etc:
Test exception handling on scoring
smoketest grid search
check that best params are equal  check that we can call score and that it gives the correct result
giving no scoring function raises an error
ensure the test is sane
Check if ValueError (when labels is None) propagates to GridSearchCV  And also check if labels is correctly passed to the cv object
Should not raise an error
Test search over a "grid" with only one point.  Non-regression test: grid_scores_ wouldn't be set by GridSearchCV.
Test that grid search will capture errors on data with different  length
Test that grid search works with both dense and sparse matrices
Test that grid search works when the input features are given in the  form of a precomputed kernel matrix
compute the training kernel matrix corresponding to the linear kernel
compute the test kernel matrix
test error is raised when the precomputed kernel is not array-like  or sparse
Regression test for bug in refitting  Simulates re-fitting a broken estimator; this used to break with  sparse SVMs.
Pass X as list in GridSearchCV
Pass y as list in GridSearchCV
check cross_val_score doesn't destroy pandas dataframe
Now without a score, and without y
Make a dataset with a lot of noise to get various kind of prediction  errors across CV folds and parameter settings
Check the consistency with the best_score_ and best_params_ attributes
Test that a fit search can be pickled
Ensure that grid scores were set to zero as required for those fits  that are expected to fail.
refit=False because we want to test the behaviour of the grid search part
FailingClassifier issues a ValueError so this is what we look for.
Test if get_n_splits works correctly
Test if the repr works without any errors
Use python sets to get more informative assertion failure messages
Train and test split should not overlap
Check that the union of train an test split cover all the indices
Check that a all the samples appear at least once in a test fold
Check that the accumulated test samples cover the whole dataset
Check that errors are raised if there is not enough samples
Check that a warning is raised if the least populated class has too few  members.
Check that despite the warning the folds are still computed even  though all the classes are not necessarily represented at on each  side of the split at each split
Check that errors are raised if all n_labels for individual  classes are less than n_folds.
When shuffle is not  a bool:
Check all indices are returned in the test folds
Check all indices are returned in the test folds even when equal-sized  folds are not possible
Check if get_n_splits returns the number of folds
Manually check that KFold preserves the data ordering on toy datasets
Check if get_n_splits returns the number of folds
Check that KFold returns folds with balanced sizes (only when  stratification is possible)  Repeat with shuffling turned off and on
Check the indices are shuffled properly
Assert that there is no complete overlap
Set all test indices in successive iterations of kf2 to 1
Check that all indices are returned in the different test folds
Check that error is raised if there is a class with only one sample
Train size or test size too small
Test the StratifiedShuffleSplit, indices are drawn with a  equal chance
See https://github.com/scikit-learn/scikit-learn/issues/6121 for  the original bug report
Make sure the repr works
Test that the length is correct
Second test: train and test add up to all the data
Third test: train and test are disjoint
n_splits = no of 2 (p) label combinations of the unique labels = 3C2 = 3  n_splits = no of unique labels (C(uniq_lbls, 1) = n_unique_labels)
Use numpy.testing.assert_equal which recursively compares  lists of lists
Check if split works correctly
Check if get_n_splits works correctly
Parameters of the test
Check that folds have approximately the same size
Check that each label appears only in 1 fold
Get the test fold indices from the test set indices of each fold
Check that folds have approximately the same size
Test if nested cross validation works with different combinations of cv
Adjust length of sample weights
Ensure the estimator has implemented the passed decision function
Concatenate the predictions
Check for sparse predictions
Adjust length of sample weights
pass through: skip indexing
Make a list since we will be iterating multiple times over the folds
Because the lengths of folds can be significantly different, it is  not guaranteed that we use all of the available training data when we  use the first 'n_max_training_samples' samples.
split train and test
Naive-Bayes
Check that brier score has improved after calibration
Check invariance against relabeling [0, 1] -> [1, 2]
Check invariance against relabeling [0, 1] -> [-1, 1]
check that calibration can also deal with regressors that have  a decision_function
Check failure cases:  only "isotonic" and "sigmoid" should be accepted as methods
base-estimators should provide either decision_function or  predict_proba (most regressors, for instance, should fail)
LinearSVC does not currently support sample weights but they  can still be used for the calibration step (with a warning)
As the weights are used for the calibration, they should still yield  a different predictions
test multi-class setting with classifier that implements  only decision function
Use categorical labels to check that CalibratedClassifierCV supports  them correctly
Naive-Bayes
check that _SigmoidCalibration().fit only accepts 1d array or 2d column  arrays
probabilities outside [0, 1] should not be accepted when normalize  is set to False
Data is 6 random integer points in a 100 dimensional space classified to  three classes.
Test whether label mismatch between target y and classes raises  an Error  FIXME Remove this test once the more general partial_fit tests are merged
Sample weights all being 1 should not change results
Check that duplicate entries and correspondingly increased sample  weights yield the same result
Fit for the first time the GNB  Partial fit a second time with an incoherent X
Check the ability to predict the learning set.
Verify that np.log(clf.predict_proba(X)) gives the same results as  clf.predict_log_proba(X)
Partial fit on the whole data at once should be the same as fit too
Test input checks for the fit method  check shape consistency for number of samples at fit time
check shape consistency for number of input features at predict time
check shape consistency
classes is required for first call to partial fit
check consistency of consecutive classes values
check consistency of input shape for partial_fit
check consistency of input shape for predict
The 100s below distinguish Bernoulli from multinomial.  FIXME: write a test to show this.
check shape consistency for number of samples at fit time
coef_ and intercept_ should have shapes as in other linear models.  Non-regression test for issue 2127.
Multinomial NB
Bernoulli NB
Gaussian NB
Fit Bernoulli NB w/ alpha = 1.0
Check manual estimate matches
Classes are China (0), Japan (1)
Fit BernoulliBN w/ alpha = 1.0
Check the class prior is correct
Testing data point is:  Chinese Chinese Chinese Tokyo Japan
Check the predictive probabilities are correct
A few test classes
Check that clone raises an error on buggy estimators.
Regression test for cloning estimators with empty arrays
Regression test for cloning estimators with default parameter as np.nan
Smoke test the str of the base estimator
deprecated attribute should not show up as params
test both ClassifierMixin and RegressorMixin
delegation before fit raises an exception
smoke test delegation
training score becomes worse (2 -> 1), test error better (0 -> 1)
The mockup does not have partial_fit()
Check that params are set  Smoke test the repr:
Test with two objects
Check that we can't use the same stage name twice
Check that params are set  Smoke test the repr:
Check that params are not set when naming them wrong
Test clone
Check that apart from estimators, the parameters are the same
Remove estimators that where copied
Test pipeline raises set params error message for nested models.
expected error message
nested model check
check shapes of various prediction functions
test that the fit_predict method is implemented on a pipeline  test that the fit_predict on pipeline yields same results as applying  transform and clustering steps separately
first compute the transform and clustering step separately
check if it does the expected thing
test setting parameters
Test whether pipeline works with a transformer at the end.  Also test pipeline.transform and pipeline.inverse_transform
Test whether pipeline works with a transformer missing fit_transform
test fit_transform:
test that n_jobs work for FeatureUnion
fit_transform should behave the same
transformers should stay fit after fit_transform
Special case: empty grid (useful to get default estimator settings)
Smoke test the score etc:
Test exception handling on scoring
smoketest grid search
check that best params are equal  check that we can call score and that it gives the correct result
giving no scoring function raises an error
Test search over a "grid" with only one point.  Non-regression test: grid_scores_ wouldn't be set by GridSearchCV.
Test that grid search will capture errors on data with different  length
Test that grid search works with both dense and sparse matrices
Test that grid search works when the input features are given in the  form of a precomputed kernel matrix
compute the training kernel matrix corresponding to the linear kernel
compute the test kernel matrix
test error is raised when the precomputed kernel is not array-like  or sparse
Regression test for bug in refitting  Simulates re-fitting a broken estimator; this used to break with  sparse SVMs.
Pass X as list in GridSearchCV
Pass y as list in GridSearchCV
check cross_val_score doesn't destroy pandas dataframe
Now without a score, and without y
Make a dataset with a lot of noise to get various kind of prediction  errors across CV folds and parameter settings
Check the consistency with the best_score_ and best_params_ attributes
Test that a fit search can be pickled
Ensure that grid scores were set to zero as required for those fits  that are expected to fail.
refit=False because we want to test the behaviour of the grid search part
FailingClassifier issues a ValueError so this is what we look for.
Authors: Andreas Mueller <amueller@ais.uni-bonn.de>           Gael Varoquaux gael.varoquaux@normalesup.org  License: BSD 3 clause
Test that estimators are default-constructible, cloneable  and have working repr.
Meta sanity-check to make sure that the estimator introspection runs  properly
some can just not be sensibly default constructed
Tested in test_transformer_n_iter below
Multitask models related to ENet cannot handle  if y is mono-output.
The ProjectedGradientNMF class is deprecated
Dependent on external solvers and hence accessing the iter  param is non-trivial.
The ProjectedGradientNMF class is deprecated
The ProjectedGradientNMF class is deprecated
Check basic properties of random matrix generation
Check some statical properties of Gaussian random matrix  Check that the random matrix follow the proper distribution.  Let's say that each element of a_{ij} of A is taken from    a_ij ~ N(0.0, 1 / n_components).
Check some statical properties of sparse random matrix
tests on random projection transformer
remove 0 distances to avoid division by 0
remove 0 distances to avoid division by 0
check that the automatically tuned values for the density respect the  contract for eps: pairwise distances are preserved according to the  Johnson-Lindenstrauss lemma
when using sparse input, the projected data can be forced to be a  dense numpy array
the output can be left to a sparse matrix instead  output for dense input will stay dense:
output for sparse output will be sparse:
the number of components is adjusted from the shape of the training  set
once the RP is 'fitted' the projection is always the same
fit transform with same random seed will lead to the same results
Try to transform with an input X of size different from fitted.
Test multi target regression raises
no exception should be raised if the base estimator supports weights
train the multi_target_forest and also get the predictions.
train the forest with each column and assert that predictions are equal
test to check meta of meta estimators
train the forest with each column and assert that predictions are equal
compute exact kernel  abbreviations for easier formula
reduce to n_samples_x x n_samples_y by summing over features
approximate kernel mapping
test error is raised on negative input
test error on invalid sample_steps
test that the sample interval is set correctly
test that the sample_interval is initialized correctly
test that the sample_interval is changed in the fit method
test that the sample_interval is set correctly
compute exact kernel  abbreviations for easier formula
approximate kernel mapping
test error is raised on negative input
test that RBFSampler approximates kernel on random data  compute exact kernel
approximate kernel mapping
some basic tests
With n_components = n_samples this is exact
test that nystroem works with singular kernel matrix
Non-regression: Nystroem should pass other parameters beside gamma.
Test Nystroem on a callable.
Test either above import has failed for some reason  "import *" is discouraged outside of the module level, hence we  rely on setting up the variable above
We know that we can have division by zero
We know that we can have division by zero
Correctness oracle
Correctness oracle
Correctness oracle
Correctness oracle
test with 2d array
Correctness oracle
when strategy = 'mean'
import reload  Python 3+ import for reload. Builtin in Python2
Degenerate data with only one feature (still should be separable)
One element class
Assert that it works with 1D data
Primarily test for commit 2f34950 -- "reuse" of priors  LDA shouldn't be able to separate those
Test that priors passed as a list are correctly handled (run to see if  failure)
Test if the coefficients of the solvers are approximately the same.
NOTE: clf_lda_eigen.explained_variance_ratio_ is not of n_components  length. Make it the same length as clf_lda_svd.explained_variance_ratio_  before comparison.
arrange four classes with their means in a kite-shaped pattern  the longer distance should be transformed to the first component, and  the shorter distance to the second component.
Fit LDA and transform the means
the transformed within-class covariance should be the identity matrix
the means of classes 0 and 3 should lie on the first component
the means of classes 1 and 2 should lie on the second component
should be able to separate the data perfectly
QDA classification.  This checks that QDA implements fit and predict and returns  correct values for a simple toy dataset.
Assure that it works with 1D data
QDA shouldn't be able to separate those
Classes should have at least 2 elements
The default is to not set the covariances_ attribute
Test the actual attribute:
the default is reg_param=0. and will cause issues  when there is a constant variable
adding a little regularization fixes the problem
Case n_samples_in_a_class < n_features
ensure that we trigger DeprecationWarning even if the sklearn.lda  was loaded previously by another test.
ensure that we trigger DeprecationWarning even if the sklearn.qda  was loaded previously by another test.
make features correlated
Test that check_classification_target return correct type. 5782
we are doing something sensible
Test predict_proba
predict assigns a label if the probability that the  sample has the label is greater than 0.5.
Test that ovr works with classes that are always present or absent.  Note: tests is the case where _ConstantPredictor is utilised
Build an indicator matrix where two features are always on.  As list of lists, it would be: [[int(i >= 5), 2, 3] for i in range(10)]
y has a constantly absent label
test input as label indicator matrix
test input as label indicator matrix
decision function only estimator. Fails in current implementation.
Estimator with predict_proba disabled, depending on parameters.
predict assigns a label if the probability that the  sample has the label is greater than 0.5.
decision function only estimator. Fails in current implementation.
predict assigns a label if the probability that the  sample has the label is greater than 0.5.
Not fitted exception!  lambda is needed because we don't want coef_ to be evaluated right away
Doesn't have coef_ exception!
Compute the votes
Extract votes and verify
For each sample and each class, there only 3 possible vote levels  because they are only 3 distinct class pairs thus 3 distinct  binary classifiers.  Therefore, sorting predictions based on votes would yield  mostly tied predictions:
Classifiers are in order 0-1, 0-2, 1-2  Use decision_function to compute the votes and the normalized  sum_of_confidences, which is used to disambiguate when there is a tie in  votes.
For the first point, there is one vote per class  For the rest, there is no tie and the prediction is the argmax  For the tie, the prediction is the class with the highest score
test that ties can not only be won by the first two labels
Test that the OvO doesn't mess up the encoding of string labels
Check that we got increasing=True and no warnings
Check that we got increasing=True and no warnings
Check that we got increasing=False and no warnings
Check that we got increasing=False and no warnings
Check that we got increasing=False and CI interval warning
check we don't crash when all x are equal:
Set y and x for decreasing
Check that relationship decreases
Set y and x for decreasing
Check that relationship increases
Set y and x
Create model and fit
Check that an exception is thrown
Set y and x
Create model and fit
Set y and x
Create model and fit
Predict from  training and test x and check that we have two NaNs.
Set y and x
Create model and fit
Make sure that we throw an error for bad out_of_bounds value
Set y and x
Create model and fit
Make sure that we throw an error for bad out_of_bounds value in transform
Create model and fit
Get deterministic RNG with seed
Create regression and samples
Get some random weights and zero out
This will hang in failure case.
we also want to test that everything still works when some weights are 0
Build interpolation function with ALL input data, not just the  non-redundant subset. The following 2 lines are taken from the  .fit() method, without removing unnecessary points
fit with just the necessary data
https://github.com/scikit-learn/scikit-learn/issues/6628
avoid StratifiedKFold's Warning about least populated class in y
Use python sets to get more informative assertion failure messages
Train and test split should not overlap
Check that the union of train an test split cover all the indices
Check that a all the samples appear at least once in a test fold
Check that the accumulated test samples cover the whole dataset
Check that errors are raised if there is not enough samples
Check that a warning is raised if the least populated class has too few  members.
Check that despite the warning the folds are still computed even  though all the classes are not necessarily represented at on each  side of the split at each split
Check that errors are raised if all n_labels for individual  classes are less than n_folds.
When n is not integer:
When n_folds is not integer:
Check all indices are returned in the test folds
Check all indices are returned in the test folds even when equal-sized  folds are not possible
Manually check that KFold preserves the data ordering on toy datasets
Check the indices are shuffled properly, and that all indices are  returned in the different test folds
Parameters of the test
Check that folds have approximately the same size
Check that each label appears only in 1 fold
Check that folds have approximately the same size
Check that each label appears only in 1 fold
Check that no label is on both sides of the split
Should fail if there are more folds than labels
Check that error is raised if there is a class with only one sample
Check that error is raised if the test set size is smaller than n_classes  Check that error is raised if the train set size is smaller than  n_classes
Train size or test size too small
Test the StratifiedShuffleSplit, indices are drawn with a  equal chance
See https://github.com/scikit-learn/scikit-learn/issues/6121 for  the original bug report
Make sure the repr works
Test that the length is correct
Second test: train and test add up to all the data
Third test: train and test are disjoint
Smoke test
test with multioutput y
test with multioutput y
test with X and y as list
test with 3d X and
Error raised for non-square X
test error is raised when the precomputed kernel is not array-like  or sparse
X mock dataframe
test with custom scoring object
set random y
Check that iterating twice on the ShuffleSplit gives the same  sequence of train-test when the random_state is given
Naive loop (should be same as cross_val_predict):
Smoke test
test with multioutput y
test with multioutput y
test with X and y as list
Make a list since we will be iterating multiple times over the folds
Because the lengths of folds can be significantly different, it is  not guaranteed that we use all of the available training data when we  use the first 'n_max_training_samples' samples.
in-place tricks shouldn't have modified X
BernoulliRBM should work on small sparse matrices.
Sparse vs. dense should not affect the output. Also test sparse input  validation.
Test numerical stability (2785): would previously generate infinities  and crash with an exception.
Test that larger alpha yields weights closer to zero"""
Initialize parameters
Compute the number of layers
Pre-allocate gradient matrices
analytically compute the gradients
Test lbfgs on classification.  It should achieve a score higher than 0.95 for the binary and multi-class  versions of the digits dataset.
Test partial_fit on classification.  `partial_fit` should yield the same results as 'fit'for binary and  multi-class classification.
Test partial_fit on regression.  `partial_fit` should yield the same results as 'fit' for regression.
catch convergence warning
Test partial_fit error handling."""
no classes passed
l-bfgs doesn't support partial_fit
Test that invalid parameters raise value error"""
Test that predict_proba works as expected for binary class."""
Test that predict_proba works as expected for multi class."""
Iterate over the hidden layers
For the hidden layers
For the last layer
Forward propagate
Backward propagate
The calculation of delta[last] here works with following  combinations of output activation and loss function:  sigmoid and binary cross entropy, softmax and categorical cross  entropy, and identity with squared loss
Compute gradient for the last layer
set all attributes, allocate weights etc for first call  Initialize parameters
Compute the number of layers
Initialize coefficient and intercept layers
Use the initialization method recommended by  Glorot et al.
this was caught earlier, just to make sure
Make sure self.hidden_layer_sizes is a list
Validate input parameters.
Ensure y is 2D
First time training the model
Initialize lists
Run the Stochastic optimization algorithm
Run the LBFGS algorithm
Store meta information for the parameters
Save sizes and indices of coefficients for faster unpacking
Save sizes and indices of intercepts for faster unpacking
Run LBFGS
update weights
update no_improvement_count based on training loss or  validation score according to early_stopping
for learning rate that needs to be updated at iteration end
restore best weights
compute validation score, use that for stopping
update best parameters  use validation_scores_, not loss_curve_  let's hope no-one overloads .score with mse
Make sure self.hidden_layer_sizes is a list
Initialize layers
forward propagate
Run input checks
Force data to 2D numpy.array
Check shapes of DOE & observations
Run input checks
Check input shapes
Run input checks
Normalize input
Initialize output
Get pairwise componentwise L1-distances to the input training set  Get regression function and correlation
Scaled predictor
Predictor
Universal Kriging
Ordinary Kriging
Mean Squared Error might be slightly negative depending on  machine precision: force to zero!
Use built-in autocorrelation parameters
Initialize output
Retrieve data
Cholesky decomposition of R
Universal Kriging
Ordinary Kriging
The determinant of R is equal to the squared product of the diagonal  elements of its Cholesky decomposition C
Initialize output
Force optimizer to fmin_cobyla if the model is meant to be isotropic
Use specified starting point as first guess
Backup of the given attributes
This will iterate over fmin_cobyla optimizer
Restore the given attributes
Check regression weights if given (Ordinary Kriging)  Force to column vector
Check correlation parameters
Force verbose type to bool
Force normalize type to bool
Check optimizer
Force random_start type to int
Choose hyperparameters based on maximizing the log-marginal  likelihood (potentially starting from several initial values)
First optimize starting from theta specified in kernel
Precompute quantities required for predictions which are independent  of actual query points
Line 6 (compute np.diag(v.T.dot(v)) via einsum)
Compute log-marginal-likelihood Z and also store some temporaries  which can be reused for computing Z's gradient
Compute gradient based on Algorithm 5.1 of GPML  XXX: Get rid of the np.diag() in the next line
Line 9: (use einsum to compute np.diag(C.T.dot(C))))
Line 12: (R.T.ravel().dot(C.ravel()) = np.trace(R.dot(C)))
theta for compound kernel
Simple optimisation to gain speed (inspect is slow)
vector-valued parameter
convert from upper-triangular matrix to square matrix
Hyperparameter l kept fixed
convert from upper-triangular matrix to square matrix
Hyperparameter l kept fixed
gradient with respect to length_scale
gradient with respect to length_scale
gradient with respect to p
We have to fall back to slow way of computing diagonal
Check that values returned in theta are consistent with  hyperparameter values (being their logarithms)
Check that values of theta are modified correctly
Check addition
Check multiplication
modifiable attributes must not be identical
Test auto-kernel  For WhiteKernel: k(X) != k(X,X). This is assumed by  pairwise_kernels
Test cross-kernel
Test get_params()
Test set_params()
Repeat test_1d and test_2d for several built-in correlation  models specified as strings.
test the MSE estimate to be sane.  non-regression test for ignoring off-diagonals of feature covariance,  testing with nugget that renders covariance useless, only  using the mean function, with low effective rank of data
Checks that optimizer improved marginal likelihood
XXX: quite hacky, works only for current kernels
Fit non-normalizing GP on normalized y  Fit normalizing GP on unnormalized y
Compare predicted mean, std-devs and covariances
Test for fixed kernel that first dimension of 2d GP equals the output  of 1d GP and that second dimension is twice as large
Standard deviation and covariance do not depend on output
Test hyperparameter optimization
Checks that optimizer improved marginal likelihood
Normalize target value  demean y
Choose hyperparameters based on maximizing the log-marginal  likelihood (potentially starting from several initial values)
First optimize starting from theta specified in kernel
Precompute quantities required for predictions which are independent  of actual query points
Support multi-dimensional output of self.y_train_
Compute "0.5 * trace(tmp.dot(K_gradient))" without  constructing the full matrix tmp.dot(K_gradient) since only  its diagonal is required
if x[1] != 1 we should have lapack  how do we do that now?
this one turned up on FreeBSD
Orthogonality of weights  ~~~~~~~~~~~~~~~~~~~~~~~~
Orthogonality of latent scores  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
"Non regression test" on canonical PLS    The results were checked against the R-package plspm
x_weights_sign_flip holds columns of 1 or -1, depending on sign flip  between R and python
x_weights = X.dot(x_rotation)  Hence R/python sign flip should be the same in x_weight and x_rotation  This test that R / python give the same result up to column  sign indeterminacy
2) Regression PLS (PLS2): "Non regression test"  ===============================================  The results were checked against the R-packages plspm, misOmics and pls
x_loadings[:, i] = Xi.dot(x_weights[:, i]) \forall i
Orthogonality of weights  ~~~~~~~~~~~~~~~~~~~~~~~~
Orthogonality of latent scores  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Ensure 1d Y is correctly interpreted
Compare 1d to column vector
causes X[:, -1].std() to be zero
Scaling should be idempotent
Author: Edouard Duchesnay <edouard.duchesnay@cea.fr>  License: BSD 3 clause
check_finite=False is an optimization available only in scipy >=0.12
Inner loop of the Wold algo.  1.1 Update u: the X weights  We use slower pinv2 (same as np.linalg.pinv) for stability  reasons
Mode A regress each X column on y_score  If y_score only has zeros x_weights will only have zeros. In  this case add an epsilon to converge to a more acceptable  solution
Mode A regress each Y column on x_score  2.2 Normalize y_weights
Normalize
feature has low resolution use unique vals
create axis based on percentiles and grid resolution
convert feature_names to list  if not feature_names use fx indices as name
explicit loop so "i" is bound for exception below
compute PD functions
create contour levels for two-way plots
prevent x-axis ticks from overlapping
classification
regression
compute leaf for each sample in ``X``.
mask all which are not in sample mask.
update each leaf (= perform line search)
update predictions (both in-bag and out-of-bag)
update predictions
we only need to fit one tree for binary clf.
create one-hot label encoding
we only need to fit one tree for binary clf.
print the header line
plot verbose info each time i % verbose_mod == 0
adjust verbose frequency (powers of 10)
no inplace multiplication!
add tree to ensemble
if is_classification  is regression
do oob?
self.n_estimators is the number of additional est to fit
if do oob resize arrays or create new if not available
if not warmstart - clear the estimator state
init state
fit initial model - FIXME make sample_weight optional
init predictions
Allow presort to be 'auto', which means True if the dataset is dense,  otherwise it will be False.
Set min_weight_leaf from min_weight_fraction_leaf
perform boosting iterations
subsampling  OOB score before adding this stage
fit next stage of trees
we don't need _make_estimator
for use in inner loop, not raveling the output in single-class case,  not doing input validation.
no yield from in Python2.X
Default implementation
n_classes will be equal to 1 in the binary classification or the  regression case.
no yield from in Python2.X
Retrieve settings
Build estimators
Draw features
Draw samples, using sample weights, and then fit
Draw samples, using a mask, and then fit
Resort to voting
Convert data
Remap output
Check parameters
if max_samples is float:
Free allocated memory, if any
Parallel loop
Advance random state to state after training  the first n_estimators
Default implementation
Check data
Parallel loop
Reduce
Check data
Parallel loop
Reduce
Check data
Parallel loop
Reduce
Check data
Parallel loop
Reduce
Validate or convert input data  Pre-sort indices to avoid that each individual tree of the  ensemble sorts the indices.
Remap output
reshape is necessary to preserve the data contiguity against vs  [:, np.newaxis] that does not.
Check parameters
Free allocated memory, if any
We draw from the random state to get the random state we  would have got if we hadn't used a warm_start.
Collect newly grown trees
Decapsulate classes_ attributes
Default implementation
Check data
Assign chunk of trees to jobs
Parallel loop
Reduce
Check data
Assign chunk of trees to jobs
Parallel loop
Reduce
ensure_2d=False because there are actually unit test checking we fail  for 1d.  Pre-sort indices to avoid that each individual tree of the  ensemble sorts the indices.
Set parameters
Don't instantiate estimators now! Parameters of base_estimator might  still change. Eg., when grid-searching with the nested object syntax.  This needs to be filled by the derived classes.
Compute the number of jobs
Partition estimators between jobs
also load the boston dataset  and randomly permute it
also load the iris dataset  and randomly permute it
Check classification on a toy dataset.
test fit before feature importance
deviance requires ``n_classes >= 2``.
Test GradientBoostingClassifier on synthetic dataset used by  Hastie et al. in ESLII Example 12.7.
Friedman1
Friedman2
Friedman3
Predict probabilities.
check if probabilities are in [0, 1].
derive predictions from probabilities
Test input checks (shape and type of X and y).
X has wrong shape
test if max_features is valid.
Test to make sure random state is set properly.
Test if max features is set properly for floats and str.
test if prediction for last stage equals ``predict``
test if prediction for last stage equals ``predict``
test if prediction for last stage equals ``predict_proba``
test that staged_functions make defensive copies
regressor has no staged_predict_proba
Check model serialization.
Check if we can fit even though all targets are equal.
classifier should raise exception
Check if quantile loss with alpha=0.5 equals lad.
Test with non-integer class labels.
Test with float class labels.
Test with float class labels.
This will raise a DataConversionWarning that we want to  "always" raise, elsewhere the warnings gets ignored in the  later tests, and the tests that check for this warning fail
Test if oob improvement has correct shape.
one for 1-10 and then 9 for 20-100
100 lines for n_estimators==100
Test if warm start equals fit.
Test if warm start equals fit - set n_estimators.
last 10 trees have different depth
Test if fit clears state.
Test if warm start with equal n_estimators does nothing
the last 10 are not zeros
Test if monitor return value works.
Test greedy trees with max_depth + 1 leafs.
Test greedy trees with max_depth + 1 leafs.
Test if ZeroEstimator works for classification.
Test precedence of max_leaf_nodes over max_depth.
Predict probabilities.
derive predictions from probabilities
Check BaseEnsemble methods.
also load the iris dataset  and randomly permute it
also load the boston dataset  and randomly permute it
Trained on sparse format
Check regression for various parameter settings on sparse input.
Trained on sparse format
Trained on dense format
Test that bootstrapping samples generate non-perfect base estimators.
without bootstrap, all trees are perfect on the training set
with bootstrap, trees are no longer perfect on the training set
Test that bootstrapping features may generate duplicate features.
Predict probabilities.
Normal case
Degenerate case, where some classes are missing
Check that oob prediction is a good estimation of the generalization  error.
Test with few estimators
Check that oob prediction is a good estimation of the generalization  error.
Test with few estimators
Check singleton ensembles.
Test that it gives proper exception on deficient input.
Test support of decision_function
Check parallel classification.
Classification
predict_proba
decision_function
Check parallel regression.
Check that bagging ensembles can be grid-searched.  Transform iris into a binary classification task
Grid search with scoring based on decision_function
Check base_estimator and its default values.
Classification
Regression
Test if fitting incrementally with warm start gives a forest of the  right size and the same results as a normal fit.
Test that nothing happens when fitting without increasing n_estimators
modify X to nonsense values, this should not change anything
warm started classifier with 5+5 estimators should be equivalent to  one classifier with 10 estimators
Check using oob_score and warm_start simultaneously fails
Load the iris dataset and randomly permute it
Common random state
Toy sample
Load the iris dataset and randomly permute it
Load the boston dataset and randomly permute it
_samme_proba calls estimator.predict_proba.  Make a mock object so I can control what gets returned.
Make sure that the correct elements come out as smallest --  `_samme_proba` should preserve the ordering in each example.
Check classification on a toy dataset.
Check consistency on dataset iris.
Somewhat hacky regression test: prior to  ae7adc880d624615a34bafdb1d75ef67051b8200,  predict_proba returned SAMME.R values for SAMME.
Check consistency on dataset boston house prices.
Check staged predictions.
AdaBoost classification
AdaBoost regression
Check pickability.
Check variable importances.
Test that it gives proper exception on deficient input.
Test different base estimators.
XXX doesn't work with y_class because RF doesn't support classes_  Shouldn't AdaBoost run a LabelBinarizer?
Flatten y to a 1d array
Trained on sparse format
Trained on dense format
predict
decision_function
predict_log_proba
predict_proba
score
staged_decision_function
staged_predict
staged_predict_proba
staged_score
Verify sparsity of data is maintained during training
Trained on sparse format
Trained on dense format
predict
staged_predict
Check binomial deviance loss.  Check against alternative definitions in ESLII.
Check log odds estimator.
Smoke test for init estimators with sample weights.
skip multiclass
check if predictions match
one-hot encoding
also load the iris dataset  and randomly permute it
also load the boston dataset  and randomly permute it
also make a hastie_10_2 dataset
also test apply
Check consistency on dataset iris.
Check consistency on dataset boston house prices.
Regression models should not have a classes_ attribute.
XXX: Remove this test in 0.19 after transform support to estimators  is removed.
Check with parallel
Weight of each B of size k
For all B of size k  For all values B=b
Compute true importances
Estimate importances with totally randomized trees
Check correctness
csc matrix
non-contiguous targets in classification
csc matrix
No bootstrap
Check that base trees can be grid-searched.
Test that n_classes_ and classes_ have proper shape.
Classification, single output
Classification, multi-output
Create the RTE with sparse=False
Assert that type is ndarray, not scipy.sparse.csr.csr_matrix
Assert that dense and sparse hashers have same array.
Ignore warnings from switching to more power iterations in randomized_svd  test random forest hashing on circles dataset  make sure that it is linearly separable.  even after projected to two SVD dimensions  Note: Not all random_states produce perfect results.
test fit and transform:
Single variable with 4 values
Test precedence of max_leaf_nodes over max_depth.
Test if leaves contain more than leaf_count training examples
test boundary value
drop inner nodes
drop inner nodes
Test if leaves contain at least min_weight_fraction_leaf of the  training set
test both DepthFirstTreeBuilder and BestFirstTreeBuilder  by setting max_leaf_nodes
drop inner nodes
Nothing
Contiguous
csr matrix
csc_matrix
coo_matrix
Check class_weights resemble sample_weights behavior.
Test if class_weight raises errors and warnings when expected.
Invalid preset string
Warning warm_start with preset
Not a list or preset for multi-output
Incorrect length list for multi-output
Test if fit clears state and grows a new forest when warm_start==False.
Test if warm start with equal n_estimators does nothing and returns the  same forest and raises a warning.
If we had fit the trees again we would have got a different forest as we  changed the random state.
Test that the warm start computes oob score when asked.  Use 15 estimators to avoid 'some inputs do not have OOB scores' warning.
Test that oob_score is computed even if we don't need to train  additional trees.
load the iris dataset  and randomly permute it
also load the boston dataset  and randomly permute it
Trained on sparse format
Trained on dense format
Generate train/test data
fit the model
predict scores (the lower, the more normal)
check that there is at most 6 errors (false positive or false negative)
toy sample (the last two samples are outliers)
Test LOF
assert detect outliers:
also load the boston dataset
also load the iris dataset
Test partial dependence for classifier
only 4 grid points instead of 5 because only 4 unique X[:,0] vals
now with our own grid
Test partial dependence for multi-class classifier
Test partial dependence for regressor
Test input validation of partial dependence.
first argument must be an instance of BaseGradientBoosting
Gradient boosting estimator must be fit
wrong ndim for grid
Test partial dependence plot function.
check with str features and array feature names
Test partial dependence plot function input checks.
not fitted yet
first argument must be an instance of BaseGradientBoosting
must be larger than -1
too large feature value
str feature but no feature_names
not valid features value
Test partial dependence plot function on multi-class input.
now with symbol labels
label not in gbrt.classes_
label not provided
here above max_features has no links with self.max_features
ensure_2d=False because there are actually unit test checking we fail  for 1d.  Pre-sort indices to avoid that each individual tree of the  ensemble sorts the indices.
ensure that max_sample is in [1, n_samples]:
code structure from ForestClassifier/predict_proba  Check data
Take the opposite of the scores as bigger is better (here less  abnormal) and add 0.5 (this value plays a special role as described  in the original paper) to give a sense to scores = 0:
Check parameters
Initialize weights to 1 / n_samples
Normalize existing weights
Check that the sample weights sum is positive
Check parameters
Clear any previous fit results
Boosting step
Early termination
Stop if error is zero
Stop if the sum of sample weights has become non-positive
Normalize
Displace zero probabilities so the log is defined.  Also fix negative elements which may occur with  negative sample weights.
Check that algorithm is supported
Fit
Instances incorrectly classified
Error fraction
Stop if classification is perfect
Boost weight using multi-class AdaBoost SAMME.R alg
Only boost the weights if it will fit again  Only boost positive weights
Instances incorrectly classified
Error fraction
Stop if classification is perfect
Boost weight using multi-class AdaBoost SAMME alg
Only boost the weights if I will fit again  Only boost positive weights
The weights are all 1. for SAMME.R
The weights are all 1. for SAMME.R
The weights are all 1. for SAMME.R
The weights are all 1. for SAMME.R
Fit
Fit on the bootstrapped sample and obtain a prediction  for all samples in the training set
Calculate the average loss
Stop if fit is perfect
Discard current estimator only if it isn't the only one
Boost weight using AdaBoost.R2 alg
Evaluate predictions of all estimators
Sort the predictions
Find index of median prediction for each sample
Return median predictions
! /usr/bin/env python  Copyright (C) 2007-2009 Cournapeau David <cournape@gmail.com>                2010 Fabian Pedregosa <fabian.pedregosa@inria.fr>  License: 3-clause BSD
We can actually import a restricted version of sklearn that  does not need the compiled code
Avoid non-useful msg:  "Ignoring attempt to set 'name' (from ... "
For these actions, NumPy is not required, nor Cythonization  They are required to succeed without Numpy for example when  pip is used to install Scikit-learn when Numpy is not yet present in  the system.
Generate Cython sources, unless building from source release
WindowsError is not defined on unix systems
changed target file, recompute hash
Update the hashes dict with the new hash
Save hashes once per module. This prevents cythonizing prev.  files again when debugging broken code in a single file
Check whether this commit is part of a pull request or not  The documentation should be always built when executed from one of the  main branches
This PR does not seem to have any documentation related file changed.
Create a temporary folder for the data fetcher
define grammar of a greeting
If this works, then _ustr(obj) has the same behaviour as str(obj), so  it won't break any existing code.
this line is related to debugging the asXML bug
collapse out indents if formatting is not desired
not a bound method, get info directly from __call__ method
no need for special handling if attribute doesnt exist
no need for special handling if attribute doesnt exist
no need for special handling if attribute doesnt exist
argument cache for optimizing repeated calls when backtracking through recursive expressions
Preserve the defining literal.
remove white space from quote chars - wont work anyway
strip off quotes
replace escaped characters
replace escaped quotes
only got here if no expression matched, raise exception for match that made it the furthest
suppress whitespace-stripping in contained parse expressions, but re-enable it on the Combine itself
flatten t tokens
last resort, just use MatchFirst
try to avoid LR with this extra test
it's easy to get these comment structures wrong - they're very common, so may as well make them available
Python 2 compat
Python 3
u'zh': u'http://zh.wikipedia.org/wiki/Wikipedia',
change the User Agent to avoid being blocked by Wikipedia  downloading a couple of articles should not be considered abusive
The training data folder must be passed as first argument
Split the dataset in training and test set:
Print the classification report
Plot the confusion matrix
the training data folder must be passed as first argument
split the dataset in training and test set:
Print the classification report
Print and plot the confusion matrix
The training data folder must be passed as first argument
Split the dataset in training and test set:
TASK: Build a vectorizer that splits strings into sequence of 1 to 3  characters instead of word tokens
TASK: Build a vectorizer / classifier pipeline using the previous analyzer  the pipeline instance should stored in a variable named clf
TASK: Fit the pipeline on the training set
TASK: Predict the outcome on the testing set in a variable named y_predicted
Print the classification report
Plot the confusion matrix
the training data folder must be passed as first argument
split the dataset in training and test set:
TASK: Build a vectorizer / classifier pipeline that filters out tokens  that are too rare or too frequent
TASK: print the cross-validated scores for the each parameters set  explored by the grid search
TASK: Predict the outcome on the testing set and store it in a variable  named y_predicted
Print the classification report
Print and plot the confusion matrix
Try to override the matplotlib configuration as early as possible
Add any paths that contain templates here, relative to this directory.
generate autosummary even if no references
The suffix of source filenames.
The encoding of source files.
Generate the plots for the gallery
The master toctree document.
General information about the project.
The version info for the project you're documenting, acts as replacement for  |version| and |release|, also used in various other places throughout the  built documents.  The short X.Y version.  The full version, including alpha/beta/rc tags.
There are two options for replacing |today|: either, you set today to some  non-false value, then it is used:  Else, today_fmt is used as the format for a strftime call.
List of documents that shouldn't be included in the build.
List of directories, relative to source directory, that shouldn't be  searched for source files.
The reST default role (used for this markup: `text`) to use for all  documents.
If true, '()' will be appended to :func: etc. cross-reference text.
If true, the current module name will be prepended to all description  unit titles (such as .. function::).
If true, sectionauthor and moduleauthor directives will be shown in the  output. They are ignored by default.
The name of the Pygments (syntax highlighting) style to use.
A list of ignored prefixes for module index sorting.
The theme to use for HTML and HTML Help pages.  Major themes that come with  Sphinx are currently 'default' and 'sphinxdoc'.
Theme options are theme-specific and customize the look and feel of a theme  further.  For a list of options available for each theme, see the  documentation.
Add any paths that contain custom themes here, relative to this directory.
The name for this set of Sphinx documents.  If None, it defaults to  "<project> v<release> documentation".
A shorter title for the navigation bar.  Default is the same as html_title.
The name of an image file (relative to this directory) to place at the top  of the sidebar.
The name of an image file (within the static path) to use as favicon of the  docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32  pixels large.
Add any paths that contain custom static files (such as style sheets) here,  relative to this directory. They are copied after the builtin static files,  so a file named "default.css" will overwrite the builtin "default.css".
If not '', a 'Last updated on:' timestamp is inserted at every page bottom,  using the given strftime format.
If true, SmartyPants will be used to convert quotes and dashes to  typographically correct entities.
Custom sidebar templates, maps document names to template names.
Additional templates that should be rendered to pages, maps page names to  template names.
If false, no module index is generated.
If false, no index is generated.
If true, the index is split into individual pages for each letter.
If true, links to the reST sources are added to the pages.
If true, an OpenSearch description file will be output, and all pages will  contain a <link> tag referring to it.  The value of this option must be the  base URL from which the finished HTML is served.
If nonempty, this is the file name suffix for HTML files (e.g. ".xhtml").
Output file base name for HTML help builder.
The paper size ('letter' or 'a4').
The font size ('10pt', '11pt' or '12pt').
Grouping the document tree into LaTeX files. List of tuples  (source start file, target name, title, author, documentclass  [howto/manual]).
The name of an image file (relative to this directory) to place at the top of  the title page.
For "manual" documents, if this is true, then toplevel headings are parts,  not chapters.
Documents to append as an appendix to all manuals.
If false, no module index is generated.
to hide/show the prompt in code examples:
The following is used by sphinx.ext.linkcode to provide links to github
Python 2 built-in
make sure that the Agg backend is set before importing any  matplotlib
this script can be imported by nosetest to find tests to run: we should not  impose the matplotlib requirement in that case.
value is another dictionary
Make sure searchindex uses UTF-8 encoding
parse objects
download and initialize the search index
Decode bytes under Python 3
we don't have it cached  cache it for the future
failed to resolve
replace '\' with '/' so it on the web
for some reason, the relative link goes one directory too high up
heading
modules for which we embed links into example code
resize the image
get the last working module name
This is a.b, not e.g. a().b
need to get a in a().b
Join import path to relative path
The following is a list containing all the figure names
The __doc__ is often printed in the example, we  don't with to echo it
create something to replace the thumbnail
Don't embed hyperlinks when a latex builder is used.
Add resolvers for the packages for which we want to show links
patterns for replacement
ensure greediness
embed links after build is finished
HACK: Stop nosetests running setup() above
string conversion routines
GAEL: Toctree commented out below because it creates  hundreds of sphinx warnings  out += ['.. autosummary::', '   :toctree:', '']
Extra mangling domains
local import to avoid testing dependency
Try Python 2 first, otherwise load from Python 3
Python 2 only
range of number of samples (observation) to embed
range of admissible distortions
range of number of samples (observation) to embed
Need an internet connection hence not enabled by default
select only non-identical samples pairs
cross_val_predict returns an array of the same size as `y` where each entry  is a prediction obtained by cross validation:
Note: the following is identical to X[rows[:, np.newaxis], cols].sum() but  much faster in scipy <= 0.16
Author: Matt Terry <matt.terry@gmail.com>  License: BSD 3 clause
Extract the subject & body
Use FeatureUnion to combine the features from subject and body
Pipeline for pulling features from the post's subject line
Pipeline for pulling ad hoc features from post's body
weight components in FeatureUnion
Use a SVC classifier on the combined features
Generate sample data
Add noise to targets
Visualize training and prediction time
Visualize learning curves
Make sure that it X is 2D
Generate toy data.
Fit the huber regressor over a series of epsilon values.
Display results
import some data to play with
avoid this ugly slicing by using a two-dim dataset
shuffle
standardize
Plot the three one-against-all classifiers
The two Lasso implementations on Dense data
The two Lasso implementations on Sparse data
Load the diabetes dataset
Use only one feature
Split the data into training/testing sets
Split the targets into training/testing sets
Create linear regression object
Train the model using the training sets
Plot outputs
Fit the ARD Regression
we create 50 separable points
fit the model
plot the line, the points, and the nearest vectors to the plane
normalize data as done by Lars to allow for comparison
Display results
Display results
Generating simulated data with Gaussian weights
Fit the Bayesian Ridge Regression and an OLS for comparison
Simulate regression data with a correlated design  The Donoho-Tanner phase transition is around n_samples=25: below we  will completely fail to recover in the well-conditioned case
The coefficients of our model
Plot stability selection path, using a high eps for early stopping  of the path, to save computation time
Plot only the 100 first coefficients
run the classifier
classify small against large digits
print the training scores
Plot the three one-against-all classifiers
X is the 10x10 Hilbert matrix
distort the clean signal
generate some sparse data to play with
add noise
Split data in train set and test set
Lasso
ElasticNet
Fit line using all data
Robustly fit linear model with RANSAC algorithm
Predict data of estimated models
Compare estimated coefficients
generate points used to plot
create matrix versions of these arrays
import some data to play with
we create an instance of Neighbours Classifier and fit the data.
Put the result into a color plot
Generate data
Select the optimal percentage of features with grid search
Attempt to remove the temporary cachedir, but don't worry if it fails
Plot the ground truth
Incorrect number of clusters
Different variance
Unevenly sized blobs
Number of run (with randomly generated dataset) for each strategy so as  to be able to compute an estimate of the standard deviation
k-means models can do several random inits so as to be able to trade  CPU time for convergence robustness
Datasets generation parameters
Generate data (swiss roll dataset)  Make it thinner
Define the structure A of the data. Here a 10 nearest neighbors
Generate data  Newer versions of scipy have face in misc
Resize it to 10% of the original size to speed up the processing
Define the structure A of the data. Pixels connected to their neighbors.
Compute clustering
4 circles
We use a mask that limits to the foreground: the problem that we are  interested in here is not separating the objects from the background,  but separating them one from the other.
Convert the image into a graph with the value of the gradient on the  edges.
Take a decreasing function of the gradient: we take it weakly  dependent from the gradient the segmentation is close to a voronoi
Force the solver to be arpack, since amg is numerically  unstable on this example
2 circles
Load the Summer Palace photo
Convert to floats instead of the default 8 bits integer coding. Dividing by  255 is important so that plt.imshow behaves works well on float data (need to  be in the range [0-1]
Load Image and transform to a 2D numpy array.
Generate sample data
Compute Affinity Propagation
Plot result
in this case the seeding of the centers is deterministic, hence we run the  kmeans algorithm only once with n_init=1
Obtain labels for each point in mesh. Use last trained model.
Generate sample data
Compute DBSCAN
Number of clusters in labels, ignoring noise if present.
Plot result
Generate waveform data
Make the noise sparse
load the raccoon face as a numpy array  Newer versions of scipy have face in misc
Resize it to 10% of the original size to speed up the processing
Convert the image into a graph with the value of the gradient on the  edges.
Take a decreasing function of the gradient: an exponential  The smaller beta is, the more independent the segmentation is of the  actual image. For beta=1, the segmentation is close to a voronoi
Apply spectral clustering (this step goes much faster if you have pyamg  installed)
Create a graph capturing local connectivity. Larger number of neighbors  will give more homogeneous clusters to the cost of computation  time. A very large number of neighbors gives more evenly distributed  cluster sizes, but may not impose the local manifold structure of  the data
normalize dataset for easier parameter selection
estimate bandwidth for mean shift
connectivity matrix for structured Ward  make connectivity symmetric
Newer versions of scipy have face in misc
create an array from labels and values
original face
compressed face
equal bins face
Generate sample data
The following bandwidth can be automatically detected using
Plot result
2D embedding of the digits dataset
Generating the sample data from make_blobs  This particular setting has one distinct cluster and 3 clusters placed close  together.
Create a subplot with 1 row and 2 columns
Initialize the clusterer with n_clusters value and a random generator  seed of 10 for reproducibility.
The silhouette_score gives the average value for all the samples.  This gives a perspective into the density and separation of the formed  clusters
Compute the silhouette scores for each sample
Aggregate the silhouette scores for samples belonging to  cluster i, and sort them
Label the silhouette plots with their cluster numbers at the middle
The vertical line for average silhouette score of all the values
Labeling the clusters  Draw white circles at cluster centers
Generate sample data
Initialise the different array to all False
Use all colors that matplotlib provides by default.
Compute clustering with Birch with and without the final clustering step  and plot.
Plot result
Example settings
Generate the data
Estimate the covariance
Plot the results
fit a Minimum Covariance Determinant (MCD) robust estimator to data
compare estimators learnt from the full data set with true parameters
Display results
Color samples
spanning a range of possible shrinkage coefficient values
under the ground-truth model, which we would not have access to in real  settings
GridSearch for an optimal shrinkage coefficient
Ledoit-Wolf optimal shrinkage coefficient estimate
OAS coefficient estimate
example settings
computation
fit a Minimum Covariance Determinant (MCD) robust estimator to data  compare raw robust estimates with the true location and covariance
compare estimators learned from the full data set with true  parameters
simulation covariance matrix (AR(1) process)
Circle out the test data
plot error lines showing +/- std. errors of the scores
alpha=0.2 controls the translucency of the fill color
Scale data
Classify using k-NN
get the separating hyperplane
add non-discriminative features
Standard scientific Python imports
Import datasets, classifiers and performance metrics
The digits dataset
To apply a classifier on this data, we need to flatten the image, to  turn the data in a (samples, feature) matrix:
Create a classifier: a support vector classifier
We learn the digits on the first half of the digits
Now predict the value of the digit on the second half:
Put the result into a color plot
figure number
fit the model
plot the line, the points, and the nearest vectors to the plane
fit the model
get the separating hyperplane
plot the parallels to the separating hyperplane that pass through the  support vectors
plot the line, the points, and the nearest vectors to the plane
import some data to play with
avoid this ugly slicing by using a two-dim dataset
title for the plots
Plot the decision boundary. For that, we will assign a color to each  point in the mesh [x_min, x_max]x[y_min, y_max].
Put the result into a color plot
set up dataset
l1 data (only 5 informative features)
set up the plot for each regressor
To get nice curve, we need a large number of iterations to  reduce the variance
plot the decision function
fit the model
Generate sample data
Add noise to targets
figure number
fit the model
get the separating hyperplane
plot the parallels to the separating hyperplane that pass through the  support vectors
Put the result into a color plot
fit the model and get the separating hyperplane
get the separating hyperplane using weighted classes
import some data to play with
avoid this ugly slicing by using a two-dim dataset
we create an instance of SVM and fit out data.
Put the result into a color plot
fit the model
plot the decision function for each datapoint on the grid
evaluate decision function in a grid
plot the scores of the grid  grid_scores_ contains parameter settings and scores  We extract just the scores
plot the line, the points, and the nearest vectors to the plane
Plot the cross-validation score as a function of percentile of features
Compute cross-validation score using 1 CPU
Break up the dataset into non-overlapping training (75%) and testing  (25%) sets.  Only take the first fold.
Try GMMs using different types of covariances.
Since we have class labels for the training data, we can  initialize the GMM parameters in a supervised manner.
Train the other parameters using the EM algorithm.
Plot the test data with crosses
generate random sample, two components
generate spherical data centered on (20, 20)
generate zero centered stretched Gaussian data
concatenate the two datasets into the final training set
fit a Gaussian Mixture Model with two components
as the DP will not use every component it has access to  unless it needs it, we shouldn't plot the redundant  components.
Plot an ellipse to show the Gaussian component
Number of samples per component
Number of samples per component
Fit a Gaussian mixture with EM
Plot an ellipse to show the Gaussian component
as the DP will not use every component it has access to  unless it needs it, we shouldn't plot the redundant  components.
Plot an ellipse to show the Gaussian component
Number of samples per component
Generate random sample following a sine curve
import some data to play with
ANOVA SVM-C  1) anova filter, take 3 best ranked features  2) svm
Load the digits dataset
Plot pixel ranking
The iris dataset
Some noisy data not correlated
Add the noisy data to the informative features
Compare to the weights of an SVM
Loading a dataset
Some noisy data not correlated
Add noisy data to the informative features for make the task harder
Build a classification task using 3 informative features
Create the RFE object and compute a cross-validated score.  The "accuracy" scoring is proportional to the number of correct  classifications
Load the boston dataset.
We use the base estimator LassoCV since the L1 norm promotes sparsity of features.
Set a minimum threshold of 0.25
Reset the threshold till the number of features equals two.  Note that the attribute can be set directly instead of repeatedly  fitting the metatransformer.
Generate sample data
Old versions of scipy have face in the top level package
Convert from uint8 representation with values between 0 and 255 to  a floating point representation with values between 0 and 1.
Load faces data
global centering
local centering
List of the different estimators, whether to center and transpose the  problem, and whether the transformer uses the clustering API.
Adding homoscedastic noise
Adding heteroscedastic noise
Generate sample data
Compute ICA
We can `prove` that the ICA model applies by reverting the unmixing.
For comparison, compute PCA
Generate a signal
Percentage of variance explained for each components
Author: Jake Vanderplas <jakevdp@cs.washington.edu>
histogram 1
Plot all available kernels
import some data to play with
avoid this ugly slicing by using a two-dim dataset
Create color maps
we create an instance of Neighbours Classifier and fit the data.
Put the result into a color plot
Generate sample data
Add noise to targets
Fit regression model
Parameters of the study
Initialize the range of `n_samples`
Generate some structured data
Metrics to collect for the plots
pick one query at random to study query time variability in LSHForest
import some data to play with
avoid this ugly slicing by using a two-dim dataset
Create color maps
Put the result into a color plot
if basemap is available, we'll use it.  otherwise, we'll improvise later...
Get matrices/arrays of species IDs and locations
Plot map of South America with distributions of each species
evaluate only on the land: -9999 indicates ocean
plot contours of the density
Initialize size of the database, iterations and required neighbors.
Set `n_estimators` values
load the data
project the 64-dimensional data to a lower dimension
use grid search cross-validation to optimize the bandwidth
use the best estimator to compute the kernel density estimate
sample 44 new points from the data
turn data into a 4x11 grid
Parameters
Load data
We only take the two corresponding features
Train
Plot the decision boundary
The tree structure can be traversed to compute various properties such  as the depth of each node and whether or not it is a leaf.
If we have a test node
For a group of samples, we have the following common node.
Import the necessary modules and libraries
Fit regression model
Predict
compute the entropies of transduced label distributions
select five digit examples that the classifier is most uncertain about
keep track of indices that we get labels for
labeling 5 points, remote from labeled set
generate ring with inner box
Learn with LabelSpreading
shuffle everything around
Learn with LabelSpreading
calculate uncertainty values for each transduced distribution
pick the top 10 most uncertain labels
plot
step size in the mesh
title for the plots
Plot the decision boundary. For that, we will assign a color to each  point in the mesh [x_min, x_max]x[y_min, y_max].
Put the result into a color plot
Plot also the training points
import some data to play with
Use same random seed for multiple calls to make_multilabel_classification to  ensure same distributions
Display progress logs on stdout
introspect the images arrays to find the shapes (for plotting)
for machine learning we use the 2 data directly (as relative pixel  positions info is ignored by this model)
the label to predict is the id of the person
split into a training and testing set
Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled  dataset): unsupervised feature extraction / dimensionality reduction
Hack to detect whether we are running by the sphinx builder
benchmark throughput
initialize random generator
quotes_historical_yahoo_ochl was named quotes_historical_yahoo before matplotlib 1.4
Choose a time period reasonably calm (not too long ago so that we get  high-tech firms, and before the 2008 crash)
The daily variations of the quotes are what carry most information
Learn a graphical structure from the correlations
standardize the time series: using correlations rather than covariance  is more efficient for structure recovery
We use a dense eigen_solver to achieve reproducibility (arpack is  initiated with random vectors that we don't control). In addition, we  use a large number of neighbors to capture the large-scale structure.
Plot the nodes using the coordinates of our embedding
Add a label to each node. The challenge here is that we want to  position the labels to avoid overlap with other labels
Reconstruction with L2 (Ridge) penalization
Reconstruction with L1 (Lasso) penalization  the best value of alpha was determined using cross validation  with LassoCV
Backward compat for Python 2
Whether or not a model has been fitted
update decision surface if already fitted.
Hack to detect whether we are running by the sphinx builder
Main  Create the vectorizer and limit the number of features to a reasonable  maximum
Iterator over parsed Reuters SGML files.
test data statistics
We will feed the classifier with mini-batches of 1000 documents; this means  we have at most 1000 docs in memory at any time.  The smaller the document  batch, the bigger the relative overhead of the partial fit methods.
Create the data_stream that parses Reuters SGML files and iterates on  documents as a stream.
Main loop : iterate on mini-batches of examples
update estimator with examples in the current mini-batch
Plot fitting times
if basemap is available, we'll use it.  otherwise, we'll improvise later...
choose points associated with the desired species
Load the compressed data
Set up the data grid
The grid in x,y coordinates
We'll make use of the fact that coverages[6] has measurements at all  land points.  This will help us decide between land and water.
Fit, predict, and plot for each species.
Standardize features
Predict species distribution using the training data
We'll predict only for the land points.
plot contours of the prediction
stop after 5M links to make it possible to work in RAM
Load the faces datasets
Test on a subset of people
Plot the completed faces
Estimate the score on the entire dataset, with no missing values
Standard scientific Python imports
Import datasets, classifiers and performance metrics
The digits dataset
To apply an classifier on this data, we need to flatten the image, to  turn the data in a (samples, feature) matrix:
We learn the digits on the first half of the digits
Now predict the value of the digit on the second half:
Create a classifier: a support vector classifier
plot the results:  second y axis for timeings
vertical line for dataset dimensionality = 64
visualize the decision surface, projected down to the first  two principal components of the dataset
predict and plot  Plot the decision boundary. For that, we will assign a color to each  point in the mesh [x_min, x_max]x[y_min, y_max].
Put the result into a color plot
Plot also the training points
Plot the PCA spectrum
iterate over datasets  preprocess dataset, split into training and test part
Put the result into a color plot
Load Data
Models we will use
Hyper-parameters. These were set by cross-validation,  using a GridSearchCV. Here we are not performing cross-validation to  save time.  More components tend to give better prediction performance, but larger  fitting time
Training RBM-Logistic Pipeline
Training Logistic regression
rescale the data, use the traditional train/test split
mlp = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=400, alpha=1e-4,                      algorithm='sgd', verbose=10, tol=1e-4, random_state=1)
Next line to silence pyflakes.
Variables for manifold learning.
Create our sphere.
Plot our dataset.
compatibility matplotlib < 1.0
Perform Locally Linear Embedding Manifold learning
don't show points that are too close
Random 2D projection using a random unitary matrix
Spectral embedding of the digits dataset
t-SNE embedding of the digits dataset
Center the data
Rotate the data
Next line to silence pyflakes. This import is needed.
This import is needed to modify the way figure behaves
Create classifiers
Train uncalibrated random forest classifier on whole train and validation  data and evaluate on test data
split train, test for calibration
Gaussian Naive-Bayes with no calibration
Gaussian Naive-Bayes with isotonic calibration
Gaussian Naive-Bayes with sigmoid calibration
Create dataset of classification task with many redundant and few  informative features
Calibrated with isotonic calibration
Calibrated with sigmoid calibration
Logistic regression with no calibration as baseline
Plot calibration curve for Gaussian Naive Bayes
Plot calibration curve for Linear SVC
Evaluate the models using crossvalidation
Display progress logs on stdout
define a pipeline combining a text feature extractor with a simple  classifier
uncommenting more parameters will give better exploring power but will  increase processing time in a combinatorial way
find the best parameters for both the feature extraction and the  classifier
Generate sample data
Split train and test data
Estimate the coef_ on full data with optimal regularization parameter
import some data to play with
setup plot details
Binarize the output
Add noisy features
Split into training and test
Run classifier
get some data
build a classifier
run randomized search
run grid search
import some data to play with
Split the data into a training set and a test set
Run classifier, using a model that is too regularized (C too low) to see  the impact on the results
Compute confusion matrix
import some data to play with
Add noisy features
Run classifier with cross-validation and plot ROC curves
Loading the Digits dataset
To apply an classifier on this data, we need to flatten the image, to  turn the data in a (samples, feature) matrix:
Split the dataset in two equal parts
Import some data to play with
Binarize the output
Add noisy features to make the problem harder
shuffle and split training and test sets
Learn to predict each class against the other
First aggregate all false positive rates
Then interpolate all ROC curves at this points
Finally average it and compute AUC
Cross validation with 100 iterations to get smoother mean test and train  score curves, each time with 20% data randomly selected as a validation set.
This dataset is way to high-dimensional. Better do PCA:
Maybe some original features where good, too?
Use combined features to transform dataset:
A few constants
Observations
medium term irregularity
medium term irregularities
import some data to play with
Plot the predicted probabilities. For that, we will assign a color to  each point in the mesh [x_min, m_max]x[y_min, y_max].
Generate sample data
Specify Gaussian Process
Specify Gaussian Processes with fixed and optimized hyperparameters
First the noiseless case
Observations
Mesh the input space for evaluations of the real function, the prediction and  its MSE
Instanciate a Gaussian Process model
Fit to data using Maximum Likelihood Estimation of the parameters
Make the prediction on the meshed x-axis (ask for MSE as well)
now the noisy case
Instanciate a Gaussian Process model
Fit to data using Maximum Likelihood Estimation of the parameters
Make the prediction on the meshed x-axis (ask for MSE as well)
2 latents vars:
Transform data  ~~~~~~~~~~~~~~
each Yj = 1*X1 + 2*X2 + noize
compare pls2.coef_ with B
note that the number of components exceeds 1 (the dimension of y)
Create and fit an AdaBoosted decision tree
importing necessary libraries
Fit regression model
Predict
predict class probabilities for all classifiers
get class probabilities for the first sample in the dataset
Number of cores to use to perform parallel fitting of the forest model
Load the faces dataset
Build a forest and compute the pixel importances
Plot pixel importances
compute test set deviance
A learning rate of 1. may not be optimal for both SAMME and SAMME.R
Boosting might terminate early, but the following arrays are always  n_estimators long. We crop them to the actual number of trees here:
prevent overlapping y-axis labels
First the noiseless case
Observations
Mesh the input space for evaluations of the real function, the prediction and  its MSE
Make the prediction on the meshed x-axis
Make the prediction on the meshed x-axis
Make the prediction on the meshed x-axis
Loading some example data
Estimate best n_estimator using cross-validation
Compute best n_estimator for test data
negative cumulative sum of oob improvements
min loss according to OOB
min loss according to test (normalize such that first loss is 0)
min loss according to cv (normalize such that first loss is 0)
Predict on new data
It is important to train the ensemble of trees on a different subset  of the training data than the linear regression model to avoid  overfitting, in particular if the total number of leaves is  similar to the number of training samples
Unsupervised transformation based on totally random trees
The gradient boosted model by itself
The random forest model by itself
Parameters
Load data
We only take the two corresponding features
Shuffle
Standardize
Train
Add a title at the top of each column
Build a classification task using 3 informative features
Build a forest and compute the feature importances
Print the feature ranking
make a synthetic dataset
use RandomTreesEmbedding to transform data
Visualize result using PCA
Learn a Naive Bayes classifier on the transformed data
Learn an ExtraTreesClassifier for comparison
scatter plot of original and reduced data
transform grid using RandomTreesEmbedding
transform grid using ExtraTreesClassifier
split 80/20 train-test
Needed on Windows because plot_partial_dependence uses multiprocessing
map labels from {-1, 1} to {0, 1}
compute test set deviance
clf.loss_ assumes that y_test[i] in {0, 1}
fit the model
Change this for exploring the bias-variance decomposition of other  estimators. This should work well for estimators with high variance (e.g.,  decision trees or KNN), but poorly for estimators with low variance (e.g.,  linear models).
Generate data
Loop over estimators to compare  Compute predictions
Bias^2 + Variance + Noise decomposition of the mean squared error
Generate a binary classification dataset.
Map a classifier name to a list of (<n_estimators>, <error rate>) pairs.
Range of `n_estimators` values to explore.
Record the OOB error for each `n_estimators=i` setting.
Generate the "OOB error rate" vs. "n_estimators" plot.
Uncomment the following line to use a larger set (11k+ documents)
Display progress logs on stdout
Perform an IDF normalization on the output of HashingVectorizer
Vectorizer results are normalized, which makes KMeans behave as  spherical k-means for better results. Since LSA/SVD results are  not normalized, we have to redo the normalization.
Show confusion matrix
Display progress logs on stdout
Load some categories from the training set
split a training set and a test set
mapping from integer feature name to original token string
keep selected feature names
Train Liblinear model
Train SGD model
Train SGD with Elastic Net penalty
Train NearestCentroid without threshold
parameters
compute the same step_size than in LR-sag
Split training and testing. Switch train and test subset compared to  LYRL2004 split, to have a larger training dataset.
to store the results
start time  stop time
start time  stop time
Memoize the data extraction and memory map the resulting  train / test splits in readonly mode
Nomenclature in the function follows Lee & Seung
plot the actual surface  dummy point plot to stick the legend to since surface plot do not  support legends (yet?)
start time  stop time
start time  stop time
Option parser
Generate dataset
Set transformer input
Set GaussianRandomProjection input
Set SparseRandomProjection input
Perform benchmark
Shuffle data
add noise
Keep the last samples as held out query vectors: note since we used  shuffle=True we have ensured that index and query vectors are  samples from the same distribution (a mixture of 100 gaussians in this  case)
Initialize index sizes
Plot precision
Plot speed up
If this is enabled, tests are much slower and will crash with the large data
Determine when to switch to batch computation for matrix norms,  in case the reconstructed (dense) matrix is too large
The following datasets can be dowloaded manually from:  CIFAR 10: http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz  SVHN: http://ufldl.stanford.edu/housenumbers/train_32x32.mat
There is a different convention for l here
s = sp.linalg.norm(A, ord=2)   slow
If we're not plotting, dump the timing to stdout
plot the actual surface
dummy point plot to stick the legend to since surface plot do not  support legends (yet?)
RandomizedPCA error is always worse (approx 100x) than other PCA  tests
limit dataset to 5000 people (don't care who they are!)
Memoize the data extraction and memory map the resulting  train / test splits in readonly mode
Normalize features
start time  stop time
Delayed import of matplotlib.pyplot
plot the actual surface  dummy point plot to stick the legend to since surface plot do not  support legends (yet?)
Author: Mathieu Blondel <mathieu@mblondel.org>  License: BSD 3 clause
we remove data with label 4  normal data are then those of class 1
normal data are those with attribute 2  abnormal those with attribute 4
start time  stop time
Option parser
List sampling algorithm  We assume that sampling algorithm has the following signature:    sample(n_population, n_sample)
Set Python core input
Set custom automatic method selection
Set custom tracking based method
Set custom reservoir based method
Set custom reservoir based method
Numpy permutation based
Remove unspecified algorithm
Perform benchmark
Find the first prime element in the specified row. Returns the column index, or -1 if no starred element was found.
Clear all covered matrix cells
Returns whether the input is array-like
Checks whether the estimator's fit method supports the given parameter.Examples  >>> from sklearn.svm import SVC >>> has_fit_parameter(SVC(), "sample_weight") True
Helper to workaround Python 2 limitations of pickling instance methods
Set random state of an estimator if it has the `random_state` param.Classes for whom random_state is deprecated are ignored. Currently DBSCAN is one such class.
Skip test if being run on Travis.
Detect if process is 32bit Python.
Identify hyper parameters of an estimator
Squared Euclidean or Frobenius norm of x.Returns the Euclidean norm when x is a vector, the Frobenius norm when x is a matrix (2-d array). Faster than norm(x) ** 2.
Compute log(det(A)) for A symmetricEquivalent to : np.log(nl.det(A)) but more robust. It returns -Inf if det(A) is non positive or is not defined.
This is a mock delegated function
Parameters  extra: string to be added to the deprecation messages
ARPACK iteration did not converge Attributes  eigenvalues : ndarray Partial result. Converged eigenvalues. eigenvectors : ndarray Partial result. Converged eigenvectors.
Raises a TypeError if X is not a CSR or CSC matrix
Find the value in data augmented with n_zeros for the given rank
Perform classification on an array of test vectors X. Parameters  X : array-like, shape = [n_samples, n_features] Returns  C : array, shape = [n_samples] Predicted target values for X
Calculate the posterior log probability of the samples X
Generate the random projection matrixParameters  n_components : int, Dimensionality of the target projection space. n_features : int, Dimensionality of the original source space. Returns  components : numpy array or CSR matrix [n_components, n_features] The generated random matrix.
Add documentation to a function.
Import module, returning the module after the last dot.
Add an item to six.moves.
Remove item from six.moves.
Return an iterator over the keys of a dictionary.
Return an iterator over the values of a dictionary.
Return an iterator over the (key, value) pairs of a dictionary.
Return an iterator over the (key, [values]) pairs of a dictionary.
Create a base class with a metaclass.
Remove .1s to the time under Windows: this is the time it take tostat files. This is needed to make results similar to timings under Unix, for tests
Class used to hash objects that won't normally pickle
Return True if a is backed by some mmap buffer directly or not
Utility function to cleanup a temporary folder if still existing
Compute the part of part associated with a function.See code of_cache_key_to_dir() for details
Read value from cache and return it.
Clear value from cache
func_dir = _cache_key_to_dir(self.cachedir, self.func, None) if mkdir: mkdirp(func_dir) return func_dir def _hash_func(self): Hash a function to key the online cache
Dispatch more data for parallel processingThis method is meant to be called concurrently by the multiprocessing callback. We rely on the thread-safety of dispatch_one_batch to protect against concurrent consumption of the unprotected iterator.
Approximation of the breakdown point.Parameters  n_samples : int Number of samples. n_subsamples : int Number of subsamples to consider. Returns  breakdown_point : float Approximation of breakdown point.
Return the parameters passed to the estimator
Center the data in X but not in y
sparse representation of the fitted coef
Decision function of the linear modelParameters  X : numpy array or scipy.sparse matrix of shape (n_samples, n_features) Returns  T : array, shape (n_samples,) The predicted decision function
Predict using the linear modelParameters  X : {array-like, sparse matrix}, shape (n_samples, n_features) Returns  array, shape (n_samples,) Predicted target values per element in X.
Predict using the linear modelParameters  X : {array-like, sparse matrix}, shape (n_samples, n_features) Returns  array, shape (n_samples,) Predicted target values per element in X.
Predict using the estimated model.This is a wrapper for `estimator_.predict(X)`. Parameters  X : numpy array of shape [n_samples, n_features] Returns  y : array, shape = [n_samples] or [n_samples, n_targets] Returns predicted values.
Decision function of the linear model.Parameters  X : {array-like, sparse matrix}, shape = (n_samples, n_features) Samples. Returns  C : array, shape = (n_samples,) Returns predicted values.
Predict using the linear modelParameters  X : {array-like, sparse matrix}, shape = (n_samples, n_features) Samples. Returns  C : array, shape = (n_samples,) Returns predicted values.
Get the residues of the fitted model.
Run exactly the same tests using the sparse representation variant
Partially fit a single binary estimator.
Make sure that an estimator implements the necessary methods.
Whether this is a multilabel classifier
Partially fit a single binary estimator(one-vs-one).
Return a tolerance which is independent of the dataset
Compute cluster centers and predict cluster index for each sample.Convenience method; equivalent to calling fit(X) followed by predict(X).
guts of transform method; no input validation
Opposite of the value of X on the K-means objective.Parameters  X : {array-like, sparse matrix}, shape = [n_samples, n_features] New data. Returns  score : float Opposite of the value of X on the K-means objective.
Remove a subcluster from a node and update it with thesplit subclusters.
Return radius of the subcluster
Build a CF Tree for the input data. Parameters  X : {array-like, sparse matrix}, shape (n_samples, n_features) Input data.
Retrieve the leaves of the CF Node. Returns  leaves: array-like List of the leaf nodes.
Check that rows and columns sum to the same constant.
Use the leaf linked list for traversal
Creates a biclustering for X.Parameters  X : array-like, shape (n_samples, n_features)
Fit the hierarchical clustering on the dataParameters  X : array-like, shape = [n_samples, n_features] The data Returns  self
Getter for the precision matrix.Returns  precision_ : array-like, The precision matrix associated to the current covariance object.
Predict new data by linear interpolation.Parameters  T : array-like, shape=(n_samples,) Data to transform. Returns  T_ : array, shape=(n_samples,) Transformed data.
Fit label encoderParameters  y : array-like of shape (n_samples,) Target values. Returns  self : returns an instance of self.
Fit label encoder and return encoded labelsParameters  y : array-like of shape [n_samples] Target values. Returns  y : array-like of shape [n_samples]
Compute the boolean mask X == missing_values.
Do nothing and return the estimator unchangedThis method is just there to implement the usual API and hence work in pipelines.
Scale each non zero row of X to unit normParameters  X : {array-like, sparse matrix}, shape [n_samples, n_features] The data to normalize, row by row. scipy.sparse matrices should be in CSR format to avoid an un-necessary copy.
Do nothing and return the estimator unchangedThis method is just there to implement the usual API and hence work in pipelines.
Binarize each element of XParameters  X : {array-like, sparse matrix}, shape [n_samples, n_features] The data to binarize, element by element. scipy.sparse matrices should be in CSR format to avoid an un-necessary copy.
Fit KernelCentererParameters  K : numpy array of shape [n_samples, n_samples] Kernel matrix. Returns  self : returns an instance of self.
Fit OneHotEncoder to X.Parameters  X : array-like, shape [n_samples, n_feature] Input array of type int. Returns  self
Fit OneHotEncoder to X, then transform X.Equivalent to self.fit(X).transform(X), but more convenient and more efficient. See fit for the parameters, transform for the return value.
Predict the target of new samples. Can be different from theprediction of the uncalibrated classifier. Parameters  X : array-like, shape (n_samples, n_features) The samples. Returns  C : array, shape (n_samples,) The predicted class.
Predict new data by linear interpolation.Parameters  T : array-like, shape (n_samples,) Data to predict from. Returns  T_ : array, shape (n_samples,) The predicted data.
Number of points that will be sampled.
Call predict on the estimator with the best found parameters.Only available if ``refit=True`` and the underlying estimator supports ``predict``. Parameters  X : indexable, length n_samples Must fulfill the input assumptions of the underlying estimator.
Call predict_proba on the estimator with the best found parameters.Only available if ``refit=True`` and the underlying estimator supports ``predict_proba``. Parameters  X : indexable, length n_samples Must fulfill the input assumptions of the underlying estimator.
Call predict_log_proba on the estimator with the best found parameters.Only available if ``refit=True`` and the underlying estimator supports ``predict_log_proba``. Parameters  X : indexable, length n_samples Must fulfill the input assumptions of the underlying estimator.
Call decision_function on the estimator with the best found parameters.Only available if ``refit=True`` and the underlying estimator supports ``decision_function``. Parameters  X : indexable, length n_samples Must fulfill the input assumptions of the underlying estimator.
Call transform on the estimator with the best found parameters.Only available if the underlying estimator supports ``transform`` and ``refit=True``. Parameters  X : indexable, length n_samples Must fulfill the input assumptions of the underlying estimator.
Call inverse_transform on the estimator with the best found parameters.Only available if the underlying estimator implements ``inverse_transform`` and ``refit=True``. Parameters  Xt : indexable, length n_samples Must fulfill the input assumptions of the underlying estimator.
Provide values for covariance.
Predict label for data.Parameters  X : array-like, shape = [n_samples, n_features] Returns  C : array, shape = (n_samples,) component memberships
Bayesian information criterion for the current model fitand the proposed data. Parameters  X : array of shape(n_samples, n_dimensions) Returns  bic: float (the lower the better)
Akaike information criterion for the current model fitand the proposed data. Parameters  X : array of shape(n_samples, n_dimensions) Returns  aic: float (the lower the better)
Compute Gaussian log-density at X for a tied model.
Perform the covariance M step for diagonal cases.
Perform the covariance M step for spherical cases.
Check a precision vector is positive-definite.
Check the precision matrices are symmetric and positive-definite.
Bayesian information criterion for the current model on the input X.Parameters  X : array of shape (n_samples, n_dimensions) Returns  bic: float The greater the better.
Check initial parameters of the derived class.Parameters  X : array-like, shape  (n_samples, n_features)
Initialize the model parameters of the derived class.Parameters  X : array-like, shape  (n_samples, n_features) resp : array-like, shape (n_samples, n_components)
E step.Parameters  X : array-like, shape (n_samples, n_features) Returns  log-likelihood : scalar responsibility : array, shape (n_samples, n_components)
M step.Parameters  X : array-like, shape (n_samples, n_features) resp : array-like, shape (n_samples, n_components)
Estimate the weighted log-probabilities, log P(X | Z) + log weights.Parameters  X : array-like, shape (n_samples, n_features) Returns  weighted_log_prob : array, shape (n_features, n_component)
Estimate log-weights in EM algorithm, E[ log pi ] in VB algorithm.Returns  log_weight : array, shape (n_components, )
Estimate the log-probabilities log P(X | Z).Compute the log-probabilities per each component for each sample. Parameters  X : array-like, shape (n_samples, n_features) Returns  log_prob : array, shape (n_samples, n_component)
helper function to calculate symmetric quadratic form x.T * A * x
Generates boolean masks corresponding to test sets.By default, delegates to _iter_test_indices()
Generates integer indices corresponding to test sets.
Check whether locs is a reordering of the array np.arange(n)Parameters  locs : ndarray integer array to test n : int number of expected elements Returns  is_partition : bool True iff sorted(locs) is range(n)
Auxiliary function for permutation_test_score
Make k-best chi2 selector
Test that SelectFromModel fits on a clone of the estimator.
check X formatcheck X format and make sure no negative value in X. Parameters  X :  array-like or sparse matrix
Calculate approximate log-likelihood as score.Parameters  X : array-like or sparse matrix, shape=(n_samples, n_features) Document word matrix. Returns  score : float Use approximate bound as score.
Dot product-based Euclidean norm implementationSee: http://fseoane.net/blog/2011/computing-the-vector-norm/
Trace of np.dot(X, Y.T).
Hoyer's measure of sparsity for a vector
Parameters  W: {array-like, sparse matrix}, shape (n_samples, n_components) Transformed Data matrix Returns  X: {array-like, sparse matrix}, shape (n_samples, n_features) Data matrix of original shape .. versionadded:: 0.18
Fit the model with X.Parameters  X: array-like, shape (n_samples, n_features) Training data, where n_samples in the number of samples and n_features is the number of features. Returns  self : object Returns the instance itself.
Fit the model to X.Parameters  X : array-like, shape (n_samples, n_features) Training data, where n_samples is the number of samples and n_features is the number of features. Returns  self
Do nothing and return the estimator unchangedThis method is just there to implement the usual API and hence work in pipelines.
Fit LSI model on training data X.Parameters  X : {array-like, sparse matrix}, shape (n_samples, n_features) Training data. Returns  self : object Returns the transformer object.
Perform dimensionality reduction on X.Parameters  X : {array-like, sparse matrix}, shape (n_samples, n_features) New data. Returns  X_new : array, shape (n_samples, n_components) Reduced version of X. This will always be a dense array.
Return the query based on include_self param
Compute the total log probability under the model.Parameters  X : array_like, shape (n_samples, n_features) List of n_features-dimensional data points.  Each row corresponds to a single data point. Returns  logprob : float Total log-likelihood of the data in X.
Finds indices in sorted array of integers.Most significant h bits in the binary representations of the integers are matched with the items' most significant h bits.
Use GaussianRandomProjection to produce a cosine LSH fingerprint
Creates an array of array from list of arrays.
Like d.iteritems, but accepts any collections.Mapping.
Do nothing and return the estimator unchangedThis method is just there to implement the usual API and hence work in pipelines.
Transform accentuated unicode symbols into ascii or nothingWarning: this solution is only suited for languages that have a direct transliteration to ASCII symbols. See also  strip_accents_unicode Remove accentuated char for any unicode symbol.
Basic regexp based HTML / XML tag stripper functionFor serious HTML/XML preprocessing you should rather use an external library such as lxml or BeautifulSoup.
Return a function that splits a string into a sequence of tokens
Build or fetch the effective stop words list
Does nothing: this transformer is stateless.This method is just there to mark the fact that this transformer can work in a streaming setup.
Count the number of non-zero values for each feature in sparse X.
Learn a vocabulary dictionary of all tokens in the raw documents.Parameters  raw_documents : iterable An iterable which yields either str, unicode or file objects. Returns  self
Array mapping from feature integer indices to feature name
Construct an array.array of a type suitable for scipy.sparse indices.
Learn vocabulary and idf from training set.Parameters  raw_documents : iterable an iterable which yields either str, unicode or file objects Returns  self : TfidfVectorizer
Returns a list of feature names, ordered by their indices.If one-of-K coding is applied to categorical features, this will include the constructed feature names but not the original ones.
Applies transforms to the data, and the predict method of thefinal estimator. Valid only if the final estimator implements predict. Parameters  X : iterable Data to predict on. Must fulfill input requirements of first step of the pipeline.
Applies transforms to the data, and the predict_proba method of thefinal estimator. Valid only if the final estimator implements predict_proba. Parameters  X : iterable Data to predict on. Must fulfill input requirements of first step of the pipeline.
Applies transforms to the data, and the decision_function method ofthe final estimator. Valid only if the final estimator implements decision_function. Parameters  X : iterable Data to predict on. Must fulfill input requirements of first step of the pipeline.
Applies transforms to the data, and the predict_log_proba method ofthe final estimator. Valid only if the final estimator implements predict_log_proba. Parameters  X : iterable Data to predict on. Must fulfill input requirements of first step of the pipeline.
Applies transforms to the data, and the transform method of thefinal estimator. Valid only if the final estimator implements transform. Parameters  X : iterable Data to predict on. Must fulfill input requirements of first step of the pipeline.
Fit all transformers using X.Parameters  X : array-like or sparse matrix, shape (n_samples, n_features) Input data, used to fit transformers.
basic convergence check
Performs inductive inference across the model.Parameters  X : array_like, shape = [n_samples, n_features] Returns  y : array_like, shape = [n_samples] Predictions for input data
Scale back to 0-1 range in case of normalization for plotting
Alias for fetch_lfw_people(download_if_missing=False)Check fetch_lfw_people.__doc__ for the documentation and parameter list.
Convert a raw name for a data set in a mldata.org filename.
Given text in "news" format, strip the headers, by removing everything before the first blank line.
Given text in "news" format, strip lines beginning with the quote characters > or |, plus lines that often introduce a quoted section (for example, because they contain the string 'writes:'.)
Delete all the content of the data home cache.
Test fixture (clean up) run once after all tests of this module
Test fixture (clean up) run once after all tests of this module
Convenient way to get row and column indicators together.Returns the ``rows_`` and ``columns_`` members.
Shape of the i'th bicluster.Returns  shape : (int, int) Number of rows and columns (resp.) in the bicluster.
Returns the submatrix corresponding to bicluster `i`.Works with sparse matrices. Only works if ``rows_`` and ``columns_`` attributes exist.
Returns the score of the model on the data XParameters  X : array-like, shape = (n_samples, n_features) Returns  score: float
Returns True if the given estimator is (probably) a classifier.
Return non-default make_scorer arguments for repr.
Function that wraps estimator.score
Dummy estimator to test check_scoring
Dummy estimator to test check_scoring
Dummy estimator to test check_scoring
Dummy estimator to test check_scoring
Dummy scorer that always returns 1.
report = classification_report(y_true, y_pred) assert_equal(report, expected_report) expected_report = \
Estimate log probability.Parameters  X : array-like, shape (n_samples, n_features) Input data. Returns  C : array, shape (n_samples, n_classes) Estimated log probabilities.
Perform classification on an array of test vectors X.The predicted class C for each sample in X is returned. Parameters  X : array-like, shape = [n_samples, n_features] Returns  C : array, shape = [n_samples]
Compute the embedding vectors for data XParameters  X : array-like of shape [n_samples, n_features] training set. Returns  self : returns an instance of self.
Compute the embedding vectors for data X and transform X.Parameters  X : array-like of shape [n_samples, n_features] training set. Returns  X_new: array-like, shape (n_samples, n_components)
Number of points that will be sampled.
Call predict on the estimator with the best found parameters.Only available if ``refit=True`` and the underlying estimator supports ``predict``. Parameters  X : indexable, length n_samples Must fulfill the input assumptions of the underlying estimator.
Call predict_proba on the estimator with the best found parameters.Only available if ``refit=True`` and the underlying estimator supports ``predict_proba``. Parameters  X : indexable, length n_samples Must fulfill the input assumptions of the underlying estimator.
Call predict_log_proba on the estimator with the best found parameters.Only available if ``refit=True`` and the underlying estimator supports ``predict_log_proba``. Parameters  X : indexable, length n_samples Must fulfill the input assumptions of the underlying estimator.
Call decision_function on the estimator with the best found parameters.Only available if ``refit=True`` and the underlying estimator supports ``decision_function``. Parameters  X : indexable, length n_samples Must fulfill the input assumptions of the underlying estimator.
Call transform on the estimator with the best found parameters.Only available if the underlying estimator supports ``transform`` and ``refit=True``. Parameters  X : indexable, length n_samples Must fulfill the input assumptions of the underlying estimator.
Call inverse_transform on the estimator with the best found parameters.Only available if the underlying estimator implements ``inverse_transform`` and ``refit=True``. Parameters  Xt : indexable, length n_samples Must fulfill the input assumptions of the underlying estimator.
Generates boolean masks corresponding to test sets.By default, delegates to _iter_test_indices(X, y, labels)
Generates integer indices corresponding to test sets.
Returns the number of splitting iterations in the cross-validator
An LinearSVC classifier that has no score method.
Check whether indices is a reordering of the array np.arange(n_samples)Parameters  indices : ndarray integer array to test n_samples : int number of expected elements Returns  is_partition : bool True iff sorted(locs) is range(n)
Test whether an error is raised in case of negative priors
Sklearn estimators shouldn't have vargs.
An LinearSVC classifier that has no score method.
Compute the logistic function inplace.Parameters  X : {array-like, sparse matrix}, shape (n_samples, n_features) The input data. Returns  X_new : {array-like, sparse matrix}, shape (n_samples, n_features) The transformed data.
Compute the hyperbolic tan function inplace.Parameters  X : {array-like, sparse matrix}, shape (n_samples, n_features) The input data. Returns  X_new : {array-like, sparse matrix}, shape (n_samples, n_features) The transformed data.
Compute the rectified linear unit function inplace.Parameters  X : {array-like, sparse matrix}, shape (n_samples, n_features) The input data. Returns  X_new : {array-like, sparse matrix}, shape (n_samples, n_features) The transformed data.
Compute the K-way softmax function inplace.Parameters  X : {array-like, sparse matrix}, shape (n_samples, n_features) The input data. Returns  X_new : {array-like, sparse matrix}, shape (n_samples, n_features) The transformed data.
Computes the probabilities P(h=1|v).Parameters  v : array-like, shape (n_samples, n_features) Values of the visible layer. Returns  h : array-like, shape (n_samples, n_components) Corresponding mean field values for the hidden layer.
Update parameters with given gradientsParameters  grads : list, length = len(params) Containing gradients with respect to coefs_ and intercepts_ in MLP model. So length should be aligned with params
Perform update to learning rate and potentially other states at theend of an iteration
Decides whether it is time to stop trainingParameters  msg : str Message passed in for verbose output verbose : bool Print message to stdin if True Returns  is_stopping : bool True if training needs to stop
Perform updates to learning rate and potential other states at theend of an iteration Parameters  time_step : int number of training samples trained on so far, used to update learning rate for 'invscaling'
Pack the parameters into a single vector.
Compute the gradient of loss with respect to coefs and intercept forspecified layer. This function does backpropagation for the specified one layer.
Predict using the multi-layer perceptron classifierParameters  X : {array-like, sparse matrix}, shape (n_samples, n_features) The input data. Returns  y : array-like, shape (n_samples,) or (n_samples, n_classes) The predicted classes.
Predict using the multi-layer perceptron model.Parameters  X : {array-like, sparse matrix}, shape (n_samples, n_features) The input data. Returns  y : array-like, shape (n_samples, n_outputs) The predicted values.
Perform classification on an array of test vectors X.Parameters  X : array-like, shape = (n_samples, n_features) Returns  C : array, shape = (n_samples,) Predicted target values for X, values are from ``classes_``
Returns a clone of self with given hyperparameters theta.
Returns the number of non-fixed hyperparameters of the kernel.
Returns a list of all hyperparameter specifications.
Returns whether the kernel is stationary.
Get parameters of this kernel.Parameters  deep: boolean, optional If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns  params : mapping of string to any Parameter names mapped to their values.
Sets the (flattened, log-transformed) non-fixed hyperparameters.Parameters  theta : array, shape (n_dims,) The non-fixed, log-transformed hyperparameters of the kernel
Returns the log-transformed bounds on the theta.Returns  bounds : array, shape (n_dims, 2) The log-transformed bounds on the kernel's hyperparameters theta
Returns whether the kernel is stationary.
Sets the (flattened, log-transformed) non-fixed hyperparameters.Parameters  theta : array, shape (n_dims,) The non-fixed, log-transformed hyperparameters of the kernel
Returns whether the kernel is stationary.
Sets the (flattened, log-transformed) non-fixed hyperparameters.Parameters  theta : array, shape (n_dims,) The non-fixed, log-transformed hyperparameters of the kernel
Returns the log-transformed bounds on the theta.Returns  bounds : array, shape (n_dims, 2) The log-transformed bounds on the kernel's hyperparameters theta
Returns whether the kernel is stationary.
Returns whether the kernel is stationary.
Returns whether the kernel is stationary.
Test that diag method of kernel returns consistent results.
Test stationarity of kernels.
Test that lml of optimized kernel is stored correctly.
Test that lml of optimized kernel is stored correctly.
Log odds ratio scaled by 0.5 -- for exponential loss.
Default ``init`` estimator for loss function.
1.0 if y - pred > 0.0 else -1.0
Compute the residual (= negative gradient).
Compute negative gradient for the ``k``-th class.
Check that the estimator is initialized, raising an error if not.
Predict class for X.Parameters  X : array-like of shape = [n_samples, n_features] The input samples. Returns  y: array of shape = ["n_samples] The predicted values.
Predict regression target for X.Parameters  X : array-like of shape = [n_samples, n_features] The input samples. Returns  y : array of shape = [n_samples] The predicted values.
Collect results from clf.predict calls.
Private function used to compute decisions within a job.
Private function used to compute predictions within a job.
Check the estimator and set the base_estimator_ attribute.
Check the estimator and set the base_estimator_ attribute.
Private function used to _parallel_build_trees function.
Private function used to forest._set_oob_score function.
Returns the index'th estimator in the ensemble.
Returns iterator over estimators in the ensemble.
Returns True on the 10th iteration.
SVC variant that records the nature of the training set
SVC variant that records the nature of the training set
Modification on fit caries data type for later verification.
Modification on fit caries data type for later verification.
Check the estimator and set the base_estimator_ attribute.
Clean the path
~ def __init_( self, newstring, restartLoc ): ~ self.newParseText = newstring ~ self.reparseLoc = restartLoc class RecursiveGrammarException(Exception): exception thrown by validate() if the grammar could be improperly recursive
Returns all named result keys.
Returns all named result keys and values as a list of tuples.
Returns all named result values.
Returns the parse results as a nested list of matching tokens, all converted to strings.
Returns the named parse results as dictionary.
Add parse action to expression's list of parse actions. See L{I{setParseAction}<setParseAction>}.
Implementation of ~ operator - returns NotAny
An empty token, will always match.
Converter to return the matched tokens as a list - useful for returning tokens of ZeroOrMore and OneOrMore expressions.
return t[0][1:-1] def upcaseTokens(s,l,t): Helper parse action to convert tokens to upper case.
Helper parse action to convert tokens to lower case.
Helper to construct opening and closing tag expressions for HTML, given a tag name
Helper to construct opening and closing tag expressions for XML, given a tag name
Case insensitive but case preserving
Deindent a list of lines maximally
Items of a defaultdict(int) with the highest values.Like Counter.most_common in Python >=2.7.
Notify the observers.
Register an observer.
Refit the model if already fitted.
Plot the support vectors by placing circles over thecorresponding data points and adds the circle collection to the contours list.
Find the index of an article name after redirect resolution
Remove the < and > URI markers and the common URI prefix
Returns the number of non-zero columns in a CSR matrix X.
Extract tokens from doc.This uses a simple regex to break strings into tokens. For a more principled approach, see CountVectorizer or TfidfVectorizer.
Extract a dict mapping tokens from doc to their frequencies.
Trim string to fit on terminal (assuming 80-column display)
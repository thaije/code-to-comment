for contrib_name in os.listdir(contrib_dir): path = os.path.join(contrib_dir, contrib_name, 'locale') if os.path.isdir(path): dirs.append((contrib_name, path)) if contrib_name in HAVE_JS: dirs.append(("%s-js" % contrib_name, path)) if include_core: dirs.insert(0, ('core', os.path.join(os.getcwd(), 'django', 'conf', 'locale')))
if resources is not None: res_names = [d[0] for d in dirs] dirs = [ld for ld in dirs if ld[0] in resources] if len(resources) > len(dirs): print("You have specified some unknown resources. " "Available resource names are: %s" % (', '.join(res_names),)) exit(1) return dirs
_check_diff('core', os.path.join(os.getcwd(), 'conf', 'locale')) for name, dir_ in contrib_dirs: _check_diff(name, dir_)
p = Popen("msgfmt -vc -o /dev/null %(path)s/%(lang)s/LC_MESSAGES/django%(ext)s.po" % { 'path': dir_, 'lang': lang, 'ext': 'js' if name.endswith('-js') else ''}, stdout=PIPE, stderr=PIPE, shell=True) output, errors = p.communicate() if p.returncode == 0: print("%s: %s" % (lang, errors.strip())) else: print("Errors happened when checking %s translation for %s:\n%s" % ( lang, name, errors))
if languages is None: call('tx pull -r %(res)s -a -f --minimum-perc=5' % {'res': _tx_resource_for_name(name)}, shell=True) target_langs = sorted([d for d in os.listdir(dir_) if not d.startswith('_') and d != 'en']) else: for lang in languages: call('tx pull -r %(res)s -f -l %(lang)s' % { 'res': _tx_resource_for_name(name), 'lang': lang}, shell=True) target_langs = languages
for lang in target_langs: po_path = '%(path)s/%(lang)s/LC_MESSAGES/django%(ext)s.po' % { 'path': dir_, 'lang': lang, 'ext': 'js' if name.endswith('-js') else ''} if not os.path.exists(po_path): print("No %(lang)s translation for resource %(name)s" % { 'lang': lang, 'name': name}) continue call('msgcat --no-location -o %s %s' % (po_path, po_path), shell=True) res = call('msgfmt -c -o %s.mo %s' % (po_path[:-3], po_path), shell=True) if res != 0: errors.append((name, lang))
overlay_warning = False if "install" in sys.argv: lib_paths = [get_python_lib()] if lib_paths[0].startswith("/usr/lib/"): lib_paths.append(get_python_lib(prefix="/usr/local")) for lib_path in lib_paths: existing_path = os.path.abspath(os.path.join(lib_path, "django")) if os.path.exists(existing_path): overlay_warning = True break
version = __import__('django').get_version()
simple_option_desc_re = re.compile( r'([-_a-zA-Z0-9]+)(\s*.*?)(?=,\s+(?:/|-|--)|$)')
app.add_directive('snippet', SnippetWithFilename) app.add_node(snippet_with_filename, html=(visit_snippet, depart_snippet_literal), latex=(visit_snippet_latex, depart_snippet_latex), man=(visit_snippet_literal, depart_snippet_literal), text=(visit_snippet_literal, depart_snippet_literal), texinfo=(visit_snippet_literal, depart_snippet_literal)) return {'parallel_read_safe': True}
lang = node['language'] highlight_args['force'] = True
lang = node['language'] highlight_args['force'] = True
fname.replace('_', r'\_'),
raise nodes.SkipNode
def visit_table(self, node): self.context.append(self.compact_p) self.compact_p = True
version_text = { 'versionchanged': 'Changed in Django %s', 'versionadded': 'New in Django %s', }
def visit_section(self, node): old_ids = node.get('ids', []) node['ids'] = ['s-' + i for i in old_ids] node['ids'].extend(old_ids) SmartyPantsHTMLTranslator.visit_section(self, node) node['ids'] = old_ids
sys.setrecursionlimit(2000)
sys.path.insert(1, dirname(dirname(abspath(__file__))))
sys.path.append(abspath(join(dirname(__file__), "_ext")))
extensions = [ "djangodocs", "sphinx.ext.intersphinx", "sphinx.ext.viewcode", "ticket_role", ]
if 'spelling' in sys.argv: extensions.append("sphinxcontrib.spelling")
spelling_lang = 'en_US'
spelling_word_list_filename = 'spelling_wordlist'
source_suffix = '.txt'
master_doc = 'contents'
project = 'Django' copyright = 'Django Software Foundation and contributors'
version = '1.11' try: from django import VERSION, get_version except ImportError: release = version else: def django_release(): pep440ver = get_version() if VERSION[3:5] == ('alpha', 0) and 'dev' not in pep440ver: return pep440ver + '.dev' return pep440ver
django_next_version = '1.11'
locale_dirs = ['locale/']
today_fmt = '%B %d, %Y'
exclude_patterns = ['_build']
add_function_parentheses = True
add_module_names = False
show_authors = False
pygments_style = 'trac'
intersphinx_mapping = { 'python': ('https://docs.python.org/3/', None), 'sphinx': ('http://sphinx-doc.org/', None), 'six': ('https://pythonhosted.org/six/', None), 'formtools': ('https://django-formtools.readthedocs.io/en/latest/', None), 'psycopg2': ('http://initd.org/psycopg/docs/', None), }
html_theme = "djangodocs"
html_theme_path = ["_theme"]
html_last_updated_fmt = '%b %d, %Y'
html_use_smartypants = True
html_translator_class = "djangodocs.DjangoHTMLTranslator"
html_additional_pages = {}
htmlhelp_basename = 'Djangodoc'
latex_documents = [ ('contents', 'django.tex', 'Django Documentation', 'Django Software Foundation', 'manual'), ]
man_pages = [( 'ref/django-admin', 'django-admin', 'Utility script for the Django Web framework', ['Django Software Foundation'], 1 ), ]
texinfo_documents = [( master_doc, "django", "", "", "Django", "Documentation of the Django framework", "Web development", False )]
epub_title = project epub_author = 'Django Software Foundation' epub_publisher = 'Django Software Foundation' epub_copyright = copyright
epub_theme = 'djangodocs-epub'
epub_cover = ('', 'epub-cover.html')
ticket_url = 'https://code.djangoproject.com/ticket/%s'
raise UnserializableContentError("Control characters are not supported in XML 1.0")
class HTMLParseError(Exception): pass
iso8601_duration_re = re.compile( r'^P' r'(?:(?P<days>\d+(.\d+)?)D)?' r'(?:T' r'(?:(?P<hours>\d+(.\d+)?)H)?' r'(?:(?P<minutes>\d+(.\d+)?)M)?' r'(?:(?P<seconds>\d+(.\d+)?)S)?' r')?' r'$' )
if 'max-age' in cc and 'max_age' in kwargs: kwargs['max_age'] = min(int(cc['max-age']), kwargs['max_age'])
if 'private' in cc and 'public' in kwargs: del cc['private'] elif 'public' in cc and 'private' in kwargs: del cc['public']
cookies = response.cookies response = HttpResponseNotModified() response.cookies = cookies return response
if_modified_since = request.META.get('HTTP_IF_MODIFIED_SINCE') if if_modified_since: if_modified_since = parse_http_date_safe(if_modified_since) if_unmodified_since = request.META.get('HTTP_IF_UNMODIFIED_SINCE') if if_unmodified_since: if_unmodified_since = parse_http_date_safe(if_unmodified_since) if_none_match = request.META.get('HTTP_IF_NONE_MATCH') if_match = request.META.get('HTTP_IF_MATCH') etags = [] if if_none_match or if_match: try: etags = parse_etags(if_none_match or if_match) except ValueError: if_none_match = None if_match = None
if response and not (200 <= response.status_code < 300): if_none_match = None if_match = None
if response and response.status_code != 200: if_modified_since = None if_unmodified_since = None
if ((if_none_match and (etag in etags or '*' in etags and etag)) and (not if_modified_since or (last_modified and if_modified_since and last_modified <= if_modified_since))): if request.method in ('GET', 'HEAD'): return _not_modified(request, response) else: return _precondition_failed(request) elif (if_match and ( (not etag and '*' in etags) or (etag and etag not in etags) or (last_modified and if_unmodified_since and last_modified > if_unmodified_since) )): return _precondition_failed(request) elif (not if_none_match and request.method in ('GET', 'HEAD') and last_modified and if_modified_since and last_modified <= if_modified_since): return _not_modified(request, response) elif (not if_match and last_modified and if_unmodified_since and last_modified > if_unmodified_since): return _precondition_failed(request)
if response.has_header('Vary'): vary_headers = cc_delim_re.split(response['Vary']) else: vary_headers = [] existing_headers = set(header.lower() for header in vary_headers) additional_headers = [newheader for newheader in newheaders if newheader.lower() not in existing_headers] response['Vary'] = ', '.join(vary_headers + additional_headers)
cache_key += '.%s' % getattr(request, 'LANGUAGE_CODE', get_language())
tz_name = force_text(get_current_timezone_name(), errors='ignore') cache_key += '.%s' % tz_name.encode('ascii', 'ignore').decode('ascii').replace(' ', '_')
headerlist = [] for header in cc_delim_re.split(response['Vary']): header = header.upper().replace('-', '_') if header == 'ACCEPT_LANGUAGE' and is_accept_language_redundant: continue headerlist.append('HTTP_' + header) headerlist.sort() cache.set(cache_key, headerlist, cache_timeout) return _generate_cache_key(request, request.method, headerlist, key_prefix)
cache.set(cache_key, [], cache_timeout) return _generate_cache_key(request, request.method, [], key_prefix)
DEFAULT_LOGGING = { 'version': 1, 'disable_existing_loggers': False, 'filters': { 'require_debug_false': { '()': 'django.utils.log.RequireDebugFalse', }, 'require_debug_true': { '()': 'django.utils.log.RequireDebugTrue', }, }, 'formatters': { 'django.server': { '()': 'django.utils.log.ServerFormatter', 'format': '[%(server_time)s] %(message)s', } }, 'handlers': { 'console': { 'level': 'INFO', 'filters': ['require_debug_true'], 'class': 'logging.StreamHandler', }, 'django.server': { 'level': 'INFO', 'class': 'logging.StreamHandler', 'formatter': 'django.server', }, 'mail_admins': { 'level': 'ERROR', 'filters': ['require_debug_false'], 'class': 'django.utils.log.AdminEmailHandler' } }, 'loggers': { 'django': { 'handlers': ['console', 'mail_admins'], 'level': 'INFO', }, 'django.server': { 'handlers': ['django.server'], 'level': 'INFO', 'propagate': False, }, } }
logging_config_func = import_string(logging_config)
if logging_settings: logging_config_func(logging_settings)
no_exc_record = copy(record) no_exc_record.exc_info = None no_exc_record.exc_text = None
msg = self.style.HTTP_SUCCESS(msg)
msg = self.style.HTTP_SERVER_ERROR(msg)
TRAILING_PUNCTUATION_RE = re.compile(
DOTS = ['&middot;', '*', '\u2022', '&#149;', '&bull;', '&#8226;']
_js_escapes.update((ord('%c' % z), '\\u%04X' % z) for z in range(32))
value = force_text(value) while '<' in value and '>' in value: new_value = _strip_once(value) if len(new_value) >= len(value): break value = new_value return value
segment = quote(segment, safe=RFC3986_SUBDELIMS + RFC3986_GENDELIMS + str('~')) return force_text(segment)
try: scheme, netloc, path, query, fragment = urlsplit(url) except ValueError: return unquote_quote(url)
query_parts = [(unquote(force_str(q[0])), unquote(force_str(q[1]))) for q in parse_qsl(query, keep_blank_values=True)] query = urlencode(query_parts)
unescaped = unescaped[:-len(trail)]
text += trail trail = ''
trimmed_something = True while trimmed_something: trimmed_something = False
match = TRAILING_PUNCTUATION_RE.match(middle) if match: middle = match.group(1) trail = match.group(2) + trail trimmed_something = True
for opening, closing in WRAPPING_PUNCTUATION: if middle.startswith(opening): middle = middle[len(opening):] lead += opening trimmed_something = True if (middle.endswith(closing) and middle.count(closing) == middle.count(opening) + 1): middle = middle[:-len(closing)] trail = closing + trail trimmed_something = True
lead, middle, trail = '', word, '' lead, middle, trail = trim_punctuation(lead, middle, trail)
url = None nofollow_attr = ' rel="nofollow"' if nofollow else '' if simple_url_re.match(middle): middle, middle_unescaped, trail = unescape(middle, trail) url = smart_urlquote(middle_unescaped) elif simple_url_2_re.match(middle): middle, middle_unescaped, trail = unescape(middle, trail) url = smart_urlquote('http://%s' % middle_unescaped) elif ':' not in middle and simple_email_re.match(middle): local, domain = middle.rsplit('@', 1) try: domain = domain.encode('idna').decode('ascii') except UnicodeError: continue url = 'mailto:%s@%s' % (local, domain) nofollow_attr = ''
if url: trimmed = trim_url(middle) if autoescape and not safe_input: lead, trail = escape(lead), escape(trail) trimmed = escape(trimmed) middle = '<a href="%s"%s>%s</a>' % (escape(url), nofollow_attr, trimmed) words[i] = mark_safe('%s%s%s' % (lead, middle, trail)) else: if safe_input: words[i] = mark_safe(word) elif autoescape: words[i] = escape(word)
if (not normcase(final_path).startswith(normcase(base_path + sep)) and normcase(final_path) != normcase(base_path) and dirname(normcase(base_path)) != normcase(base_path)): raise SuspiciousFileOperation( 'The joined path ({}) is located outside of the base path ' 'component ({})'.format(final_path, base_path)) return final_path
ESCAPE_MAPPINGS = { "A": None, "b": None, "B": None, "d": "0", "D": "x", "s": " ", "S": "x", "w": "x", "W": "!", "Z": None, }
result = [] non_capturing_groups = [] consume_next = True pattern_iter = next_char(iter(pattern)) num_args = 0
try: ch, escaped = next(pattern_iter) except StopIteration: return [('', [])]
result.append(".")
raise NotImplementedError('Awaiting Implementation')
start = non_capturing_groups.pop() inner = NonCapture(result[start:]) result = result[:start] + [inner]
ch, escaped = next(pattern_iter) result.append(ch) ch, escaped = next(pattern_iter) while escaped or ch != ']': ch, escaped = next(pattern_iter)
ch, escaped = next(pattern_iter) if ch != '?' or escaped: name = "_%d" % num_args num_args += 1 result.append(Group((("%%(%s)s" % name), name))) walk_to_end(ch, pattern_iter) else: ch, escaped = next(pattern_iter)
walk_to_end(ch, pattern_iter)
non_capturing_groups.append(len(result))
raise ValueError("Non-reversible reg-exp portion: '(?%s'" % ch)
if ch == '<': terminal_char = '>' else: terminal_char = ')' name = [] ch, escaped = next(pattern_iter) while ch != terminal_char: name.append(ch) ch, escaped = next(pattern_iter) param = ''.join(name) if terminal_char != ')': result.append(Group((("%%(%s)s" % param), param))) walk_to_end(ch, pattern_iter) else: result.append(Group((("%%(%s)s" % param), None)))
count, ch = get_quantifier(ch, pattern_iter) if ch: consume_next = False
result[-1] = Choice([None, result[-1]])
result.append(ch)
return [('', [])]
try: ch, escaped = next(input_iter) except StopIteration: ch = None if ch == '?': ch = None return int(values[0]), ch
no_default = args[:len(args) - len(defaults)] with_default = args[len(args) - len(defaults):] args = [(arg,) for arg in no_default] + zip(with_default, defaults) varargs = [('*' + argspec.varargs,)] if argspec.varargs else [] kwargs = [('**' + argspec.keywords,)] if argspec.keywords else [] return args + varargs + kwargs
if name == 'self': continue if param.kind == inspect.Parameter.VAR_POSITIONAL: name = '*' + name elif param.kind == inspect.Parameter.VAR_KEYWORD: name = '**' + name if param.default != inspect.Parameter.empty: args.append((name, param.default)) else: args.append((name,))
try: argspec = inspect.getargspec(func) except TypeError: try: argspec = inspect.getargspec(func.__call__) except (TypeError, AttributeError): argspec = None return not argspec or argspec[2] is not None
from __future__ import unicode_literals
python_2_unicode_compatible = six.python_2_unicode_compatible
return s
if issubclass(type(s), six.text_type): return s if strings_only and is_protected_type(s): return s try: if not issubclass(type(s), six.string_types): if six.PY3: if isinstance(s, bytes): s = six.text_type(s, encoding, errors) else: s = six.text_type(s) elif hasattr(s, '__unicode__'): s = six.text_type(s) else: s = six.text_type(bytes(s), encoding, errors) else: s = s.decode(encoding, errors) except UnicodeDecodeError as e: if not isinstance(s, Exception): raise DjangoUnicodeDecodeError(s, *e.args) else: s = ' '.join(force_text(arg, encoding, strings_only, errors) for arg in s) return s
return s
if isinstance(s, bytes): if encoding == 'utf-8': return s else: return s.decode('utf-8', errors).encode(encoding, errors) if strings_only and is_protected_type(s): return s if isinstance(s, six.memoryview): return bytes(s) if isinstance(s, Promise): return six.text_type(s).encode(encoding, errors) if not isinstance(s, six.string_types): try: if six.PY3: return six.text_type(s).encode(encoding) else: return bytes(s) except UnicodeEncodeError: if isinstance(s, Exception): return b' '.join(force_bytes(arg, encoding, strings_only, errors) for arg in s) return six.text_type(s).encode(encoding, errors) else: return s.encode(encoding, errors)
smart_unicode = smart_text force_unicode = force_text
if iri is None: return iri return quote(force_bytes(iri), safe=b"/#%[]=:;$&()+,!?*@'~")
return quote(force_bytes(path), safe=b"/:@&+$,-_.!~*'()")
return quote(force_bytes(path).replace(b"\\", b"/"), safe=b"/~!*()'")
return self[key]
return self.getlist(key)
__delitem__ = complain __delslice__ = complain __iadd__ = complain __imul__ = complain __setitem__ = complain __setslice__ = complain append = complain extend = complain insert = complain pop = complain remove = complain sort = complain reverse = complain
PY2 = sys.version_info[0] == 2 PY3 = sys.version_info[0] == 3 PY34 = sys.version_info[0:2] >= (3, 4)
MAXSIZE = int((1 << 31) - 1)
class X(object):
MAXSIZE = int((1 << 31) - 1)
MAXSIZE = int((1 << 63) - 1)
delattr(obj.__class__, self.name)
_moved_attributes = []
return sys.modules[fullname]
if sys.platform == "win32": _moved_attributes += [ MovedModule("winreg", "_winreg"), ]
if (isinstance(fp, file) and isinstance(data, unicode) and fp.encoding is not None): errors = getattr(fp, "errors", None) if errors is None: errors = "strict" data = data.encode(fp.encoding, errors) fp.write(data)
class metaclass(meta):
if sys.meta_path: for i, importer in enumerate(sys.meta_path): if (type(importer).__name__ == "_SixMetaPathImporter" and importer.name == __name__): del sys.meta_path[i] break del i, importer sys.meta_path.append(_importer)
if sys.platform.startswith('java'): memoryview = memoryview else: memoryview = buffer buffer_types = (bytearray, memoryview)
months = ('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec',) days = ('Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun') date = datetime_safe.new_datetime(date) dow = days[date.weekday()] month = months[date.month - 1] time_str = date.strftime('%s, %%d %s %%Y %%H:%%M:%%S ' % (dow, month))
if offset is None: return time_str + '-0000' else: timezone = (offset.days * 24 * 60) + (offset.seconds // 60) hour, minute = divmod(timezone, 60) return time_str + '%+03d%02d' % (hour, minute)
date = datetime_safe.new_datetime(date) time_str = date.strftime('%Y-%m-%dT%H:%M:%S')
if offset is None: return time_str + 'Z' else: timezone = (offset.days * 24 * 60) + (offset.seconds // 60) hour, minute = divmod(timezone, 60) return time_str + '%+03d:%02d' % (hour, minute)
ttl = force_text(ttl)
ttl = force_text(ttl)
return latest_date or datetime.datetime.utcnow().replace(tzinfo=utc)
_version = "2.0"
if item["author_name"] and item["author_email"]: handler.addQuickElement("author", "%s (%s)" % (item['author_email'], item['author_name'])) elif item["author_email"]: handler.addQuickElement("author", item["author_email"]) elif item["author_name"]: handler.addQuickElement( "dc:creator", item["author_name"], {"xmlns:dc": "http://purl.org/dc/elements/1.1/"} )
if item['enclosures']: enclosures = list(item['enclosures']) if len(enclosures) > 1: raise ValueError( "RSS feed items may only have one enclosure, see " "http://www.rssboard.org/rss-profile#element-channel-item-enclosure" ) enclosure = enclosures[0] handler.addQuickElement('enclosure', '', { 'url': enclosure.url, 'length': enclosure.length, 'type': enclosure.mime_type, })
for cat in item['categories']: handler.addQuickElement("category", cat)
content_type = 'application/atom+xml; charset=utf-8' ns = "http://www.w3.org/2005/Atom"
if item['author_name'] is not None: handler.startElement("author", {}) handler.addQuickElement("name", item['author_name']) if item['author_email'] is not None: handler.addQuickElement("email", item['author_email']) if item['author_link'] is not None: handler.addQuickElement("uri", item['author_link']) handler.endElement("author")
if item['unique_id'] is not None: unique_id = item['unique_id'] else: unique_id = get_tag_uri(item['link'], item['pubdate']) handler.addQuickElement("id", unique_id)
if item['description'] is not None: handler.addQuickElement("summary", item['description'], {"type": "html"})
for enclosure in item['enclosures']: handler.addQuickElement('link', '', { 'rel': 'enclosure', 'href': enclosure.url, 'length': enclosure.length, 'type': enclosure.mime_type, })
for cat in item['categories']: handler.addQuickElement("category", "", {"term": cat})
if item['item_copyright'] is not None: handler.addQuickElement("rights", item['item_copyright'])
DefaultFeed = Rss201rev2Feed
if isinstance(obj, datetime.datetime): if is_naive(obj): self.timezone = get_default_timezone() else: self.timezone = obj.tzinfo
return self.data.tzinfo.tzname(self.data) or ""
pass
return ""
return offset.days * 86400 + offset.seconds
return ''
week_number = None jan1_weekday = self.data.replace(month=1, day=1).weekday() + 1 weekday = self.data.weekday() + 1 day_of_year = self.z() if day_of_year <= (8 - jan1_weekday) and jan1_weekday > 4: if jan1_weekday == 5 or (jan1_weekday == 6 and calendar.isleap(self.data.year - 1)): week_number = 53 else: week_number = 52 else: if calendar.isleap(self.data.year): i = 366 else: i = 365 if (i - day_of_year) < (4 - weekday): week_number = 1 else: j = day_of_year + (7 - weekday) + (jan1_weekday - 1) week_number = j // 7 if jan1_weekday > 4: week_number -= 1 return week_number
if isinstance(number, int) and not use_grouping and not decimal_pos: return mark_safe(six.text_type(number)) sign = '' if isinstance(number, Decimal): str_number = '{:f}'.format(number) else: str_number = six.text_type(number) if str_number[0] == '-': sign = '-' str_number = str_number[1:] if '.' in str_number: int_part, dec_part = str_number.split('.') if decimal_pos is not None: dec_part = dec_part[:decimal_pos] else: int_part, dec_part = str_number, '' if decimal_pos is not None: dec_part = dec_part + ('0' * (decimal_pos - len(dec_part))) if dec_part: dec_part = decimal_sep + dec_part if use_grouping: int_part_gd = '' for cnt, digit in enumerate(int_part[::-1]): if cnt and not cnt % grouping: int_part_gd += thousand_sep[::-1] int_part_gd += digit int_part = int_part_gd[::-1] return sign + int_part + dec_part
_format_cache = {} _format_modules_cache = {}
return getattr(settings, format_type)
pass
return LocalTimezone()
return timezone.zone
return timezone.tzname(None)
value = value.astimezone(timezone) if hasattr(timezone, 'normalize'): value = timezone.normalize(value) return value
return datetime.utcnow().replace(tzinfo=utc)
return timezone.localize(value, is_dst=is_dst)
if is_aware(value): raise ValueError( "make_aware expects a naive datetime, got %s" % value) return value.replace(tzinfo=timezone)
value = value.astimezone(timezone) if hasattr(timezone, 'normalize'): value = timezone.normalize(value) return value.replace(tzinfo=None)
x = 0 for digit in str(number): x = x * len(from_digits) + from_digits.index(digit)
if x == 0: res = to_digits[0] else: res = '' while x > 0: digit = x % len(to_digits) res = to_digits[digit] + res x = int(x // len(to_digits)) return neg, res
sections = [' '.join(random.sample(WORDS, random.randint(3, 12))) for i in range(random.randint(1, 5))] s = ', '.join(sections) return '%s%s%s' % (s[0].upper(), s[1:], random.choice('?.'))
default = 'DEFAULT'
if (isinstance(data, Node) and not data.negated and (data.connector == conn_type or len(data) == 1)): self.children.extend(data.children) return self else: self.children.append(data) return data
try: if register_to: before_import_registry = copy.copy(register_to._registry)
if register_to: register_to._registry = before_import_registry
if module_has_submodule(app_config.module, module_to_search): raise
return False
return sys.modules[name] is not None
return False
finder = sys.path_importer_cache[entry] if finder is None: try: file_, _, _ = imp.find_module(module_name, [entry]) if file_: file_.close() return True except ImportError: continue elif finder.find_module(name): return True else: continue
for hook in sys.path_hooks: try: finder = hook(entry) if finder.find_module(name): return True else: break except ImportError: continue else: if os.path.isdir(entry): try: file_, _, _ = imp.find_module(module_name, [entry]) if file_: file_.close() return True except ImportError: pass
return False
paths = list(getattr(module, '__path__', [])) if len(paths) == 1: return paths[0] else: filename = getattr(module, '__file__', None) if filename is not None: return os.path.dirname(filename) raise ValueError("Cannot determine directory containing %s" % module)
def capfirst(x): return x and force_text(x)[0].upper() + force_text(x)[1:] capfirst = keep_lazy_text(capfirst)
re_words = re.compile(r'<.*?>|((?:\w[-\w]*|&.*?;)+)', re.U | re.S) re_chars = re.compile(r'<.*?>|(.)', re.U | re.S) re_tag = re.compile(r'<(/)?([^ ]+?)(?:(\s*/)| .*?)?>', re.S)
if text.endswith(truncate): return text return '%s%s' % (text, truncate)
truncate_len = length for char in self.add_truncation_text('', truncate): if not unicodedata.combining(char): truncate_len -= 1 if truncate_len == 0: break if html: return self._truncate_html(length, truncate, text, truncate_len, False) return self._text_chars(length, truncate, text, truncate_len)
continue
return self.add_truncation_text(text[:end_index or 0], truncate)
return text
pos = 0 end_text_pos = 0 current_len = 0 open_tags = []
break
current_len += 1 if current_len == truncate_len: end_text_pos = pos continue
continue
tagname = tagname.lower() if self_closing or tagname in html4_singlets: pass elif closing_tag: try: i = open_tags.index(tagname) except ValueError: pass else: open_tags = open_tags[i + 1:] else: open_tags.insert(0, tagname)
for tag in open_tags: out += '</%s>' % tag return out
_(', ').join(force_text(i) for i in list_[:-1]), force_text(last_word), force_text(list_[-1]))
def compress_string(s): zbuf = BytesIO() zfile = GzipFile(mode='wb', compresslevel=6, fileobj=zbuf) zfile.write(s) zfile.close() return zbuf.getvalue()
def compress_sequence(sequence): buf = StreamingBuffer() zfile = GzipFile(mode='wb', compresslevel=6, fileobj=buf) yield buf.read() for item in sequence: zfile.write(item) data = buf.read() if data: yield data zfile.close() yield buf.read()
members = [member for member in self._archive.getmembers() if member.name != 'pax_global_header'] leading = self.has_leading_dir(x.name for x in members) for member in members: name = member.name if leading: name = self.split_leading_dir(name)[1] filename = os.path.join(to_path, name) if member.isdir(): if filename and not os.path.exists(filename): os.makedirs(filename) else: try: extracted = self._archive.extractfile(member) except (KeyError, AttributeError) as exc: print("In the tar file %s the member %s is invalid: %s" % (name, member.name, exc)) else: dirname = os.path.dirname(filename) if dirname and not os.path.exists(dirname): os.makedirs(dirname) with open(filename, 'wb') as outfile: shutil.copyfileobj(extracted, outfile) finally: if extracted: extracted.close()
if not os.path.exists(filename): os.makedirs(filename)
import re
ip_str = _explode_shorthand_ip_string(ip_str)
if unpack_ipv4: ipv4_unpacked = _unpack_ipv4(ip_str)
if '.' not in hextets[index]: hextets[index] = hextets[index].lstrip('0') if not hextets[index]: hextets[index] = '0'
if hextets[index] == '0': doublecolon_len += 1 if doublecolon_start == -1: doublecolon_start = index if doublecolon_len > best_doublecolon_len: best_doublecolon_len = doublecolon_len best_doublecolon_start = doublecolon_start else: doublecolon_len = 0 doublecolon_start = -1
if best_doublecolon_len > 1: best_doublecolon_end = (best_doublecolon_start + best_doublecolon_len) if best_doublecolon_end == len(hextets): hextets += [''] hextets[best_doublecolon_start:best_doublecolon_end] = [''] if best_doublecolon_start == 0: hextets = [''] + hextets
return ip_str
return ip_str
if ':' not in ip_str: return False
if ip_str.count('::') > 1: return False
if ':::' in ip_str: return False
if ((ip_str.startswith(':') and not ip_str.startswith('::')) or (ip_str.endswith(':') and not ip_str.endswith('::'))): return False
if ip_str.count(':') > 7: return False
if '::' not in ip_str and ip_str.count(':') != 7: if ip_str.count('.') != 3: return False
for hextet in ip_str.split(':'): if hextet.count('.') == 3: if not ip_str.split(':')[-1] == hextet: return False try: validate_ipv4_address(hextet) except ValidationError: return False else: try: if int(hextet, 16) < 0x0 or int(hextet, 16) > 0xFFFF: return False except ValueError: return False return True
return ip_str
if '.' in ip_str.split(':')[-1]: fill_to = 7 else: fill_to = 8
ret_ip = [] for hextet in new_ip: ret_ip.append(('0' * (4 - len(hextet)) + hextet).lower()) return ':'.join(ret_ip)
if not isinstance(d, datetime.datetime): d = datetime.datetime(d.year, d.month, d.day) if now and not isinstance(now, datetime.datetime): now = datetime.datetime(now.year, now.month, now.day)
delta -= datetime.timedelta(calendar.leapdays(d.year, now.year))
since = delta.days * 24 * 60 * 60 + delta.seconds if since <= 0: return avoid_wrapping(ugettext('0 minutes')) for i, (seconds, name) in enumerate(TIMESINCE_CHUNKS): count = since // seconds if count != 0: break result = avoid_wrapping(name % count) if i + 1 < len(TIMESINCE_CHUNKS): seconds2, name2 = TIMESINCE_CHUNKS[i + 1] count2 = (since - (seconds * count)) // seconds2 if count2 != 0: result += ugettext(', ') + avoid_wrapping(name2 % count2) return result
parts = config_string.lower().split(';') palette = PALETTES[NOCOLOR_PALETTE].copy() for part in parts: if part in PALETTES: palette.update(PALETTES[part]) elif '=' in part: definition = {}
role, instructions = part.split('=') role = role.upper()
colors = styles.pop().split('/') colors.reverse() fg = colors.pop() if fg in color_names: definition['fg'] = fg if colors and colors[-1] in color_names: definition['bg'] = colors[-1]
opts = tuple(s for s in styles if s in opt_dict.keys()) if opts: definition['opts'] = opts
if role in PALETTES[NOCOLOR_PALETTE] and definition: palette[role] = definition
if palette == PALETTES[NOCOLOR_PALETTE]: return None return palette
def _dec(obj): is_class = isinstance(obj, type) if is_class: if name and hasattr(obj, name): func = getattr(obj, name) if not callable(func): raise TypeError( "Cannot decorate '{0}' as it isn't a callable " "attribute of {1} ({2})".format(name, obj, func) ) else: raise ValueError( "The keyword argument `name` must be the name of a method " "of the decorated class: {0}. Got '{1}' instead".format( obj, name, ) ) else: func = obj
return bound_func(*args, **kwargs)
update_wrapper(_wrapper, func)
if not hasattr(decorator, '__iter__'): update_wrapper(_dec, decorator, assigned=available_attrs(decorator)) if hasattr(decorator, '__name__'): _dec.__name__ = 'method_decorator(%s)' % decorator.__name__ else: _dec.__name__ = 'method_decorator(%s)' % decorator.__class__.__name__ return _dec
if hasattr(middleware, 'process_response'): def callback(response): return middleware.process_response(request, response) response.add_post_render_callback(callback)
for regex in RFC1123_DATE, RFC850_DATE, ASCTIME_DATE: m = regex.match(date) if m is not None: break else: raise ValueError("%r is not in a valid HTTP date format" % date) try: year = int(m.group('year')) if year < 100: if year < 70: year += 2000 else: year += 1900 month = MONTHS.index(m.group('mon').lower()) + 1 day = int(m.group('day')) hour = int(m.group('hour')) min = int(m.group('min')) sec = int(m.group('sec')) result = datetime.datetime(year, month, day, hour, min, sec) return calendar.timegm(result.utctimetuple()) except Exception: six.reraise(ValueError, ValueError("%r is not a valid date" % date), sys.exc_info()[2])
if len(s) > 13: raise ValueError("Base36 input too large") value = int(s, 36) if six.PY2 and value > sys.maxint: raise ValueError("Base36 input too large") return value
return [etag_str]
return _is_safe_url(url, host) and _is_safe_url(url.replace('\\', '/'), host)
if url.startswith('///'): return False url_info = urlparse(url) if not url_info.netloc and url_info.scheme: return False if unicodedata.category(url[0])[0] == 'C': return False return ((not url_info.netloc or url_info.netloc == host) and (not url_info.scheme or url_info.scheme in ['http', 'https']))
if keep_blank_values: nv.append('') else: continue
del Trans
pass
_translations = {} _active = local()
_default = None
CONTEXT_SEPARATOR = "\x04"
if len(language[p + 1:]) > 2: return language[:p].lower() + '_' + language[p + 1].upper() + language[p + 2:].lower() return language[:p].lower() + '_' + language[p + 1:].upper()
warnings.warn("localedirs is ignored when domain is 'django'.", RuntimeWarning) localedirs = None
raise IOError("No translation files found for default language %s." % settings.LANGUAGE_CODE)
self._catalog = {}
if self.__language == settings.LANGUAGE_CODE or self.__language.startswith('en'): return if self.domain == 'django': default_translation = translation(settings.LANGUAGE_CODE) else: default_translation = DjangoTranslation( settings.LANGUAGE_CODE, domain=self.domain, localedirs=localedirs ) self.add_fallback(default_translation)
self.plural = other.plural self._info = other._info.copy() self._catalog = other._catalog.copy()
return settings.LANGUAGE_CODE
eol_message = message.replace(str('\r\n'), str('\n')).replace(str('\r'), str('\n'))
result = type(message)("")
result = force_text(message)
result = ungettext(singular, plural, number)
if lang_code is None or not language_code_re.search(lang_code): return False for path in all_locale_paths(): if gettext_module.find('django', path, [to_locale(lang_code)]) is not None: return True return False
possible_lang_codes = [lang_code] try: possible_lang_codes.extend(LANG_INFO[lang_code]['fallback']) except KeyError: pass generic_lang_code = lang_code.split('-')[0] possible_lang_codes.append(generic_lang_code) supported_lang_codes = get_languages()
for supported_code in supported_lang_codes: if supported_code.startswith(generic_lang_code + '-'): return supported_code
raw_prefix = 'u' if six.PY3 else ''
if comment_lineno_cache is not None: cur_lineno = t.lineno + t.contents.count('\n') if comment_lineno_cache == cur_lineno: if t.token_type != TOKEN_COMMENT: for c in lineno_comment_map[comment_lineno_cache]: filemsg = '' if origin: filemsg = 'file %s, ' % origin warn_msg = ( "The translator-targeted comment '%s' " "(%sline %d) was ignored, because it wasn't " "the last item on the line." ) % (c, filemsg, comment_lineno_cache) warnings.warn(warn_msg, TranslatorCommentWarning) lineno_comment_map[comment_lineno_cache] = [] else:
context_match = context_re.match(imatch.group(2)) message_context = context_match.group(1) if message_context[0] == '"': message_context = message_context.strip('"') elif message_context[0] == "'": message_context = message_context.strip("'") out.write(' pgettext({p}{!r}, {p}{!r}) '.format( message_context, g, p=raw_prefix )) message_context = None
context_match = context_re.match(bmatch.group(1)) message_context = context_match.group(1) if message_context[0] == '"': message_context = message_context.strip('"') elif message_context[0] == "'": message_context = message_context.strip("'")
_illegal_formatting = re.compile(r"((^|[^%])(%%)*%[sy])")
sites = [] i = 0 while 1: j = text.find(substr, i) if j == -1: break sites.append(j) i = j + 1 return sites
delta = 2000 - year off = 6 * (delta // 100 + delta // 400) year = year + off
year = year + ((2000 - year) // 28) * 28 timetuple = dt.timetuple() s1 = ttime.strftime(fmt, (year,) + timetuple[1:]) sites1 = _findall(s1, str(year))
def curry(_curried_func, *args, **kwargs): def _curried(*moreargs, **morekwargs): return _curried_func(*(args + moreargs), **dict(kwargs, **morekwargs)) return _curried
if hasattr(cls, method_name): continue meth = cls.__promise__(method_name) setattr(cls, method_name, meth)
def __wrapper__(self, *args, **kw): res = func(*self.__args, **self.__kw) return getattr(res, method_name)(*args, **kw) return __wrapper__
return str(self.__cast())
memo[id(self)] = self return self
return __proxy__(args, kw)
_wrapped = None
self._wrapped = empty
self.__dict__["_wrapped"] = value
def __reduce__(self): if self._wrapped is empty: self._setup() return (unpickle_lazyobject, (self._wrapped,))
def __getstate__(self): return {}
return type(self)()
return copy.copy(self._wrapped)
result = type(self)() memo[id(self)] = result return result
__dir__ = new_method_proxy(dir)
__class__ = property(new_method_proxy(operator.attrgetter("__class__"))) __eq__ = new_method_proxy(operator.eq) __ne__ = new_method_proxy(operator.ne) __hash__ = new_method_proxy(hash)
__getitem__ = new_method_proxy(operator.getitem) __setitem__ = new_method_proxy(operator.setitem) __delitem__ = new_method_proxy(operator.delitem) __iter__ = new_method_proxy(iter) __len__ = new_method_proxy(len) __contains__ = new_method_proxy(operator.contains)
def __repr__(self): if self._wrapped is empty: repr_attr = self._setupfunc else: repr_attr = self._wrapped return '<%s: %r>' % (type(self).__name__, repr_attr)
return SimpleLazyObject(self._setupfunc)
return copy.copy(self._wrapped)
result = SimpleLazyObject(self._setupfunc) memo[id(self)] = result return result
try:
import pyinotify
global _cached_modules, _cached_filenames module_values = set(sys.modules.values()) _cached_filenames = clean_files(_cached_filenames) if _cached_modules == module_values: if only_new: return [] else: return _cached_filenames + clean_files(_error_files)
basedirs = [os.path.join(os.path.dirname(os.path.dirname(__file__)), 'conf', 'locale'), 'locale'] for app_config in reversed(list(apps.get_app_configs())): basedirs.append(os.path.join(npath(app_config.path), 'locale')) basedirs.extend(settings.LOCALE_PATHS) basedirs = [os.path.abspath(basedir) for basedir in basedirs if os.path.isdir(basedir)] for basedir in basedirs: for dirpath, dirnames, locale_filenames in os.walk(basedir): for filename in locale_filenames: if filename.endswith('.mo'): new_filenames.append(os.path.join(dirpath, filename))
return
request_finished.connect(update_watch)
update_watch() notifier.check_events(timeout=None) notifier.read_events() notifier.process_events() notifier.stop()
return EventHandler.modified_code
filename = traceback.extract_tb(tb)[-1][0]
try: random = random.SystemRandom() using_sysrandom = True except NotImplementedError: import warnings warnings.warn('A secure pseudo-random number generator is not available ' 'on your system. Falling back to Mersenne Twister.') using_sysrandom = False
key = hashlib.sha1(key_salt + secret).digest()
return hmac.new(key, msg=force_bytes(value), digestmod=hashlib.sha1)
random.seed( hashlib.sha256( ("%s%s%s" % ( random.getstate(), time.time(), settings.SECRET_KEY)).encode('utf-8') ).digest())
def constant_time_compare(val1, val2): return hmac.compare_digest(force_bytes(val1), force_bytes(val2))
if not new_method and old_method: warnings.warn( "`%s.%s` method should be renamed `%s`." % (class_name, old_method_name, new_method_name), deprecation_warning, 2) setattr(base, new_method_name, old_method) setattr(base, old_method_name, wrapper(old_method))
if not old_method and new_method: setattr(base, old_method_name, wrapper(new_method))
from __future__ import unicode_literals
'div': both_before + [ Tok("punct", literals("/= /"), next='reg'), ] + both_after,
tok = '"REGEX"'
if tok.startswith("'"): guts = re.sub(r"\\.|.", escape_quotes, tok[1:-1]) tok = '"' + guts + '"'
tok = tok.replace("\\", "U")
result = user_function(*args, **kwds) stats[MISSES] += 1 return result
key = make_key(args, kwds, typed)
key = make_key(args, kwds, typed) if kwds or typed else args with lock: link = cache_get(key) if link is not None: root, = nonlocal_root link_prev, link_next, key, result = link link_prev[NEXT] = link_next link_next[PREV] = link_prev last = root[PREV] last[NEXT] = root[PREV] = link link[PREV] = last link[NEXT] = root stats[HITS] += 1 return result result = user_function(*args, **kwds) with lock: root, = nonlocal_root if key in cache: pass elif _len(cache) >= maxsize: oldroot = root oldroot[KEY] = key oldroot[RESULT] = result root = nonlocal_root[0] = oldroot[NEXT] oldkey = root[KEY] oldvalue = root[RESULT] root[KEY] = root[RESULT] = None del cache[oldkey] cache[key] = oldroot else: last = root[PREV] link = [last, root, key, result] last[NEXT] = root[PREV] = cache[key] = link stats[MISSES] += 1 return result
obj = super(klass, cls).__new__(cls) obj._constructor_args = (args, kwargs) return obj
if path: module_name, _, name = path.rpartition('.') else: module_name = obj.__module__ name = obj.__class__.__name__ module = import_module(module_name) if not hasattr(module, name): raise ValueError( "Could not find object %s in %s.\n" "Please note that you cannot serialize things like inner " "classes. Please move the object into the main module " "body to use migrations.\n" "For more information, see " "https://docs.djangoproject.com/en/%s/topics/migrations/#serializing-values" % (name, module_name, get_docs_version())) return ( path or '%s.%s' % (obj.__class__.__module__, name), obj._constructor_args[0], obj._constructor_args[1], )
EscapeUnicode = EscapeText
SafeUnicode = SafeText
self.app_names = [x for x in app_names if x] if app_names else [] self.app_name = ':'.join(self.app_names) self.namespaces = [x for x in namespaces if x] if namespaces else [] self.namespace = ':'.join(self.namespaces)
self._func_path = '.'.join([func.__class__.__module__, func.__class__.__name__])
self._func_path = '.'.join([func.__module__, func.__name__])
ns_resolver = RegexURLResolver(ns_pattern, resolver.url_patterns) return RegexURLResolver(r'^/', [ns_resolver])
self._regex = regex self._regex_dict = {}
kwargs = match.groupdict() args = () if kwargs else match.groups() kwargs.update(self.default_args) return ResolverMatch(self.callback, args, kwargs, self.name)
while isinstance(callback, functools.partial): callback = callback.func if not hasattr(callback, '__name__'): return callback.__module__ + "." + callback.__class__.__name__ else: return callback.__module__ + "." + callback.__name__
self.urlconf_name = urlconf_name self.callback = None self.default_kwargs = default_kwargs or {} self.namespace = namespace self.app_name = app_name self._reverse_dict = {} self._namespace_dict = {} self._app_dict = {} self._callback_strs = set() self._populated = False
urlconf_repr = '<%s list>' % self.urlconf_name[0].__class__.__name__
sub_match_dict = dict(match.groupdict(), **self.default_kwargs) sub_match_dict.update(sub_match.kwargs)
sub_match_args = sub_match.args if not sub_match_dict: sub_match_args = match.groups() + sub_match.args
patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module) try: iter(patterns) except TypeError: msg = ( "The included URLconf '{name}' does not appear to have any " "patterns in it. If you see valid patterns in the file then " "the issue is probably caused by a circular import." ) raise ImproperlyConfigured(msg.format(name=self.urlconf_name)) return patterns
from django.conf import urls callback = getattr(urls, 'handler%s' % view_type)
candidate_pat = _prefix.replace('%', '%%') + result if re.search('^%s%s' % (re.escape(_prefix), pattern), candidate_pat % candidate_subs, re.UNICODE): url = urlquote(candidate_pat % candidate_subs, safe=RFC3986_SUBDELIMS + str('/~:@')) if url.startswith('//'): url = '/%%2F%s' % url[2:] return url
_prefixes = local()
_urlconfs = local()
try: app_list = resolver.app_dict[ns] if current_ns and current_ns in app_list: ns = current_ns elif ns not in app_list: ns = app_list[0] except KeyError: pass
try: dot = callback.rindex('.') except ValueError: return callback, '' return callback[:dot], callback[dot + 1:]
if hasattr(klass, '_default_manager'): return klass._default_manager.all() return klass
if hasattr(to, 'get_absolute_url'): return to.get_absolute_url()
to = force_text(to)
if to.startswith(('./', '../')): return to
try: return reverse(to, args=args, kwargs=kwargs) except NoReverseMatch: if callable(to): raise if '/' not in to and '.' not in to: raise
return to
ctypes, opts = parse_header(content_type.encode('ascii')) boundary = opts.get('boundary') if not boundary or not cgi.valid_boundary(boundary): raise MultiPartParserError('Invalid boundary in multipart: %s' % boundary)
try: content_length = int(META.get('CONTENT_LENGTH', 0)) except (ValueError, TypeError): content_length = 0
raise MultiPartParserError("Invalid content length: %r" % content_length)
possible_sizes = [x.chunk_size for x in upload_handlers if x.chunk_size] self._chunk_size = min([2 ** 31 - 4] + possible_sizes)
from django.http import QueryDict
if self._content_length == 0: return QueryDict(encoding=self._encoding), MultiValueDict()
for handler in handlers: result = handler.handle_raw_input(self._input_data, self._meta, self._content_length, self._boundary, encoding) if result is not None: return result[0], result[1]
self._post = QueryDict(mutable=True) self._files = MultiValueDict()
stream = LazyStream(ChunkIter(self._input_data, self._chunk_size))
old_field_name = None counters = [0] * len(handlers)
num_bytes_read = 0 num_post_keys = 0 read_size = None
self.handle_file_complete(old_field_name, counters) old_field_name = None
num_post_keys += 1 if (settings.DATA_UPLOAD_MAX_NUMBER_FIELDS is not None and settings.DATA_UPLOAD_MAX_NUMBER_FIELDS < num_post_keys): raise TooManyFieldsSent( 'The number of GET/POST parameters exceeded ' 'settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.' )
if settings.DATA_UPLOAD_MAX_MEMORY_SIZE is not None: read_size = settings.DATA_UPLOAD_MAX_MEMORY_SIZE - num_bytes_read
if transfer_encoding == 'base64': raw_data = field_stream.read(size=read_size) num_bytes_read += len(raw_data) try: data = base64.b64decode(raw_data) except _BASE64_DECODE_ERROR: data = raw_data else: data = field_stream.read(size=read_size) num_bytes_read += len(data)
num_bytes_read += len(field_name) + 2 if (settings.DATA_UPLOAD_MAX_MEMORY_SIZE is not None and num_bytes_read > settings.DATA_UPLOAD_MAX_MEMORY_SIZE): raise RequestDataTooBig('Request body exceeded settings.DATA_UPLOAD_MAX_MEMORY_SIZE.')
file_name = disposition.get('filename') if file_name: file_name = force_text(file_name, encoding, errors='replace') file_name = self.IE_sanitize(unescape_entities(file_name)) if not file_name: continue
msg = "Could not decode base64 data: %r" % e six.reraise(MultiPartParserError, MultiPartParserError(msg), sys.exc_info()[2])
break
exhaust(field_stream)
old_field_name = field_name
exhaust(stream)
exhaust(self._input_data)
for handler in handlers: retval = handler.upload_complete() if retval: break
self._files.appendlist( force_text(old_field_name, self._encoding, errors='replace'), file_obj) break
for handler in self._upload_handlers: if hasattr(handler, 'file'): handler.file.close()
if remaining is None: yield b''.join(self) return
while remaining != 0: assert remaining > 0, 'remaining bytes to read should never go negative'
self._rollback = len(boundary) + 6
unused_char = self._stream.read(1) if not unused_char: raise InputStreamExhausted() self._stream.unget(unused_char)
self._done = True return chunk
last = max(0, end - 1) if data[last:last + 1] == b'\n': end -= 1 last = max(0, end - 1) if data[last:last + 1] == b'\r': end -= 1 return end, next
chunk = stream.read(max_header_size)
header_end = chunk.find(b'\r\n\r\n')
stream.unget(chunk) return (RAW, {}, stream)
stream.unget(chunk[header_end + 4:])
for line in header.split(b'\r\n'): try: name, (value, params) = _parse_header(line) except ValueError: continue
yield parse_boundary_stream(sub_stream, 1024)
name = name[:-1] if p.count(b"'") == 2: has_encoding = True
_cookie_allows_colon_in_names = six.PY3
cookie_pickles_properly = ( (sys.version_info[:2] == (2, 7) and sys.version_info >= (2, 7, 9)) or sys.version_info >= (3, 4, 3) )
if isinstance(value, Morsel): dict.__setitem__(self, key, value) else: super(SimpleCookie, self).__setitem__(key, value)
def _BaseCookie__set(self, key, real_value, coded_value): key = force_str(key) try: M = self.get(key, Morsel()) M.set(key, real_value, coded_value) dict.__setitem__(self, key, M) except http_cookies.CookieError: if not hasattr(self, 'bad_cookies'): self.bad_cookies = set() self.bad_cookies.add(key) dict.__setitem__(self, key, http_cookies.Morsel())
key, val = str(''), chunk
cookiedict[key] = http_cookies._unquote(val)
self._headers = {} self._closable_objects = [] self._handler_class = None self.cookies = SimpleCookie() self.closed = False if status is not None: self.status_code = status self._reason_phrase = reason self._charset = charset if content_type is None: content_type = '%s; charset=%s' % (settings.DEFAULT_CONTENT_TYPE, self.charset) self['Content-Type'] = content_type
return responses.get(self.status_code, 'Unknown Status Code')
return matched.group('charset').replace('"', '')
value.encode(charset)
value = value.decode(charset)
value.decode(charset)
value = value.encode(charset)
value = str(Header(value, 'utf-8', maxlinelen=sys.maxsize).encode())
delta = delta + datetime.timedelta(seconds=1) expires = None max_age = max(0, delta.days * 86400 + delta.seconds)
if not expires: self.cookies[key]['expires'] = cookie_date(time.time() + max_age)
if isinstance(value, bytes): return bytes(value) if isinstance(value, six.text_type): return bytes(value.encode(self.charset))
return force_bytes(value, self.charset)
def close(self): for closable in self._closable_objects: try: closable.close() except Exception: pass self.closed = True signals.request_finished.send(sender=self._handler_class)
self.content = content
if hasattr(value, '__iter__') and not isinstance(value, (bytes, six.string_types)): content = b''.join(self.make_bytes(chunk) for chunk in value) if hasattr(value, 'close'): try: value.close() except Exception: pass else: content = self.make_bytes(value) self._container = [content]
self.streaming_content = streaming_content
self._iterator = iter(value) if hasattr(value, 'close'): self._closable_objects.append(value)
_encoding = None _upload_handlers = []
if settings.USE_X_FORWARDED_HOST and ( 'HTTP_X_FORWARDED_HOST' in self.META): host = self.META['HTTP_X_FORWARDED_HOST'] elif 'HTTP_HOST' in self.META: host = self.META['HTTP_HOST'] else: host = self.META['SERVER_NAME'] server_port = self.get_port() if server_port != ('443' if self.is_secure() else '80'): host = '%s:%s' % (host, server_port) return host
if settings.DEBUG: return host
return '%s%s%s' % ( escape_uri_path(self.path), '/' if force_append_slash and not self.path.endswith('/') else '', ('?' + iri_to_uri(self.META.get('QUERY_STRING', ''))) if self.META.get('QUERY_STRING', '') else '' )
location = '//%s' % self.get_full_path()
location = urljoin(current_uri, location)
self._initialize_handlers()
if (settings.DATA_UPLOAD_MAX_MEMORY_SIZE is not None and int(self.META.get('CONTENT_LENGTH', 0)) > settings.DATA_UPLOAD_MAX_MEMORY_SIZE): raise RequestDataTooBig('Request body exceeded settings.DATA_UPLOAD_MAX_MEMORY_SIZE.')
data = BytesIO(self._body)
self._mark_post_parse_error() raise
_mutable = True _encoding = None
try: query_string = query_string.decode(encoding) except UnicodeDecodeError: query_string = query_string.decode('iso-8859-1')
return host, ''
browsers = [] browser = None
if test_class.browser or not any(name.startswith('test') and callable(value) for name, value in attrs.items()): return test_class elif test_class.browsers: first_browser = test_class.browsers[0] test_class.browser = first_browser module = sys.modules[test_class.__module__] for browser in test_class.browsers[1:]: browser_test_class = cls.__new__( cls, str("%s%s" % (capfirst(browser), name)), (test_class,), {'browser': browser, '__module__': test_class.__module__} ) setattr(module, browser_test_class.__name__, browser_test_class) return test_class return unittest.skip('No browsers specified.')(test_class)
if hasattr(cls, 'selenium'): cls.selenium.quit() super(SeleniumTestCase, cls)._tearDownClassInternal()
if tblib is None: err = err[0], err[1], None self.check_picklable(test, err) self.events.append(('addExpectedFailure', self.test_index, err))
if not hasattr(os, 'fork'): return 1 try: return int(os.environ['DJANGO_TEST_PROCESSES']) except KeyError: return multiprocessing.cpu_count()
connection.settings_dict.update(settings_dict) connection.close()
init_worker = _init_worker run_subsuite = _run_subsuite
if not os.path.exists(label_as_path): tests = self.test_loader.loadTestsFromName(label) elif os.path.isdir(label_as_path) and not self.top_level:
break
tests = self.test_loader.discover(start_dir=label, **kwargs)
self.test_loader._top_level_dir = None
parallel_units = len(parallel_suite.subsuites) if self.parallel > parallel_units: self.parallel = parallel_units
if self.parallel > 1: suite = parallel_suite
dependencies_map = {}
for sig, (_, aliases) in test_databases: all_deps = set() for alias in aliases: all_deps.update(dependencies.get(alias, [])) if not all_deps.isdisjoint(aliases): raise ImproperlyConfigured( "Circular dependency: databases %r depend on each other, " "but are aliases." % aliases) dependencies_map[sig] = all_deps
for signature, (db_name, aliases) in test_databases: if dependencies_map[signature].issubset(resolved_databases): resolved_databases.update(aliases) ordered_test_databases.append((signature, (db_name, aliases))) changed = True else: deferred.append((signature, (db_name, aliases)))
mirrored_aliases[alias] = test_settings['MIRROR']
item = test_databases.setdefault( connection.creation.test_db_signature(), (connection.settings_dict['NAME'], set()) ) item[1].add(alias)
if first_alias is None: first_alias = alias connection.creation.create_test_db( verbosity=verbosity, autoclobber=not interactive, keepdb=keepdb, serialize=connection.settings_dict.get("TEST", {}).get("SERIALIZE", True), ) if parallel > 1: for index in range(parallel): connection.creation.clone_test_db( number=index + 1, verbosity=verbosity, keepdb=keepdb, ) else: connections[alias].creation.set_as_test_mirror( connections[first_alias].settings_dict)
for alias, mirror_alias in mirrored_aliases.items(): connections[alias].creation.set_as_test_mirror( connections[mirror_alias].settings_dict)
if isinstance(self.children[-1], six.string_types): if self.children[-1].isspace(): self.children.pop()
for i in range(len(self.attributes)): attr, value = self.attributes[i] other_attr, other_value = element.attributes[i] if value is None: value = attr if other_value is None: other_value = other_attr if attr != other_attr or value != other_value: return False
if isinstance(child, six.string_types): if isinstance(element, six.string_types): if count: i += child.count(element) elif element in child: return 1 else: i += child._count(element, count=count) if not count and i: return i
attrs = [ (name, " ".join(sorted(value.split(" ")))) if name == "class" else (name, value) for name, value in attrs ] element = Element(tag, attrs) self.current.append(element) if tag not in self.SELF_CLOSING_TAGS: self.open_tags.append(element) self.element_positions[element] = self.getpos()
if len(document.children) == 1: if not isinstance(document.children[0], six.string_types): document = document.children[0] return document
try:
COMPLEX_OVERRIDE_SETTINGS = {'DATABASES'}
from django.contrib.staticfiles.finders import get_finder get_finder.cache_clear() from django.core.management import get_commands get_commands.cache_clear() from django.template.utils import get_app_template_dirs get_app_template_dirs.cache_clear() from django.utils.translation import trans_real trans_real._translations = {}
if hasattr(time, 'tzset'): if kwargs['value']: os.environ['TZ'] = kwargs['value'] else: os.environ.pop('TZ', None) time.tzset()
timezone.get_default_timezone.cache_clear()
if kwargs['setting'] in {'TIME_ZONE', 'USE_TZ'}: for conn in connections.all(): try: del conn.timezone except AttributeError: pass try: del conn.timezone_name except AttributeError: pass tz_sql = conn.ops.set_time_zone_sql() if tz_sql and conn.timezone_name: with conn.cursor() as cursor: cursor.execute(tz_sql, [conn.timezone_name])
warnings.warn("Overriding setting %s can lead to unexpected behavior." % kwargs['setting'], stacklevel=5)
if self._middleware_chain is None: self.load_middleware()
request._dont_enforce_csrf_checks = not self.enforce_csrf_checks
response = self.get_response(request)
conditional_content_removal(request, response)
response.wsgi_request = request
if response.streaming: response.streaming_content = closing_iterator_wrapper( response.streaming_content, response.close) else: request_finished.disconnect(close_old_connections)
def is_file(thing): return hasattr(thing, "read") and callable(thing.read)
for (key, value) in data.items(): if is_file(value): lines.extend(encode_file(boundary, key, value)) elif not isinstance(value, six.string_types) and is_iterable(value): for item in value: if is_file(item): lines.extend(encode_file(boundary, key, item)) else: lines.extend(to_bytes(val) for val in [ '--%s' % boundary, 'Content-Disposition: form-data; name="%s"' % key, '', item ]) else: lines.extend(to_bytes(val) for val in [ '--%s' % boundary, 'Content-Disposition: form-data; name="%s"' % key, '', value ])
environ = { 'HTTP_COOKIE': self.cookies.output(header='', sep='; '), 'PATH_INFO': str('/'), 'REMOTE_ADDR': str('127.0.0.1'), 'REQUEST_METHOD': str('GET'), 'SCRIPT_NAME': str(''), 'SERVER_NAME': str('testserver'), 'SERVER_PORT': str('80'), 'SERVER_PROTOCOL': str('HTTP/1.1'), 'wsgi.version': (1, 0), 'wsgi.url_scheme': str('http'), 'wsgi.input': FakePayload(b''), 'wsgi.errors': self.errors, 'wsgi.multiprocess': True, 'wsgi.multithread': False, 'wsgi.run_once': False, } environ.update(self.defaults) environ.update(request) return environ
match = CONTENT_TYPE_RE.match(content_type) if match: charset = match.group(1) else: charset = settings.DEFAULT_CHARSET return force_bytes(data, encoding=charset)
if parsed[3]: path += str(";") + force_str(parsed[3]) path = uri_to_iri(path).encode(UTF_8) return path.decode(ISO_8859_1) if six.PY3 else path
if not r.get('QUERY_STRING'): query_string = force_bytes(parsed[4]) if six.PY3: query_string = query_string.decode('iso-8859-1') r['QUERY_STRING'] = query_string return self.request(**r)
data = {} on_template_render = curry(store_rendered_templates, data) signal_uid = "template-render-%s" % id(request) signals.template_rendered.connect(on_template_render, dispatch_uid=signal_uid) exception_uid = "request-exception-%s" % id(request) got_request_exception.connect(self.store_exc_info, dispatch_uid=exception_uid) try: try: response = self.handler(environ) except TemplateDoesNotExist as e: if e.args != ('500.html',): raise
if self.exc_info: exc_info = self.exc_info self.exc_info = None six.reraise(*exc_info)
response.client = self response.request = request
response.templates = data.get("templates", []) response.context = data.get("context")
response.resolver_match = SimpleLazyObject(lambda: resolve(request['PATH_INFO']))
if response.context and len(response.context) == 1: response.context = response.context[0]
if response.cookies: self.cookies.update(response.cookies)
request = HttpRequest()
request.session.save()
session_cookie = settings.SESSION_COOKIE_NAME self.cookies[session_cookie] = request.session.session_key cookie_data = { 'max-age': None, 'path': '/', 'domain': settings.SESSION_COOKIE_DOMAIN, 'secure': settings.SESSION_COOKIE_SECURE or None, 'expires': None, } self.cookies[session_cookie].update(cookie_data)
path = url.path if not path.startswith('/'): path = urljoin(response.request['PATH_INFO'], path)
raise RedirectCycleError("Redirect loop detected.", last_response=response)
raise RedirectCycleError("Too many redirects.", last_response=response)
if len(test_path) > 1: test_module_name = '.'.join(test_path[:-1]) else: test_module_name = '.' test_module = __import__(test_module_name, {}, {}, force_str(test_path[-1])) test_runner = getattr(test_module, test_path[-1]) return test_runner
if 'INSTALLED_APPS' in self.options: try: apps.set_installed_apps(self.options['INSTALLED_APPS']) except Exception: apps.unset_installed_apps() raise override = UserSettingsHolder(settings._wrapped) for key, new_value in self.options.items(): setattr(override, key, new_value) self.wrapped = settings._wrapped settings._wrapped = override for key, new_value in self.options.items(): setting_changed.send(sender=settings._wrapped.__class__, setting=key, value=new_value, enter=True)
test_func._overridden_settings = dict( test_func._overridden_settings, **self.options)
assert not kwargs self.operations = args[0]
test_func._modified_settings = list( test_func._modified_settings) + self.operations
value = self.options[name]
if isinstance(items, six.string_types): items = [items] if action == 'append': value = value + [item for item in items if item not in value] elif action == 'prepend': value = [item for item in items if item not in value] + value elif action == 'remove': value = [item for item in value if item not in items] else: raise ValueError("Unsupported action: %s" % action)
if not want.startswith('<?xml'): wrapper = '<root>%s</root>' want = wrapper % want got = wrapper % got
want_root = first_node(parseString(want)) got_root = first_node(parseString(got))
captured = input()
client_class = Client _overridden_settings = None _modified_settings = None
allow_database_queries = False
self.assertTrue( len(response.redirect_chain) > 0, msg_prefix + "Response didn't redirect as expected: Response code was %d (expected %d)" % (response.status_code, status_code) )
self.assertEqual( response.status_code, status_code, msg_prefix + "Response didn't redirect as expected: Response code was %d (expected %d)" % (response.status_code, status_code) )
if not path.startswith('/'): url = urljoin(response.request['PATH_INFO'], url) path = urljoin(response.request['PATH_INFO'], path)
self.assertEqual( redirect_response.status_code, target_status_code, msg_prefix + "Couldn't retrieve redirection page '%s': response code was %d (expected %d)" % (path, redirect_response.status_code, target_status_code) )
e_scheme, e_netloc, e_path, e_query, e_fragment = urlsplit(expected_url) relative_url = urlunsplit(('', '', e_path, e_query, e_fragment)) if url == relative_url: warnings.warn( "assertRedirects had to strip the scheme and domain from the " "expected URL, as it was always added automatically to URLs " "before Django 1.9. Please update your expected URLs by " "removing the scheme and domain.", RemovedInDjango20Warning, stacklevel=2) expected_url = relative_url
if hasattr(response, 'render') and callable(response.render) and not response.is_rendered: response.render()
contexts = to_list(response.context) if not contexts: self.fail(msg_prefix + "Response did not use any contexts to render the response")
errors = to_list(errors)
found_form = False for i, context in enumerate(contexts): if form not in context: continue found_form = True for err in errors: if field: if field in context[form].errors: field_errors = context[form].errors[field] self.assertTrue( err in field_errors, msg_prefix + "The field '%s' on form '%s' in" " context %d does not contain the error '%s'" " (actual errors: %s)" % (field, form, i, err, repr(field_errors)) ) elif field in context[form].fields: self.fail( msg_prefix + "The field '%s' on form '%s' in context %d contains no errors" % (field, form, i) ) else: self.fail( msg_prefix + "The form '%s' in context %d does not contain the field '%s'" % (form, i, field) ) else: non_field_errors = context[form].non_field_errors() self.assertTrue( err in non_field_errors, msg_prefix + "The form '%s' in context %d does not" " contain the non-field error '%s'" " (actual errors: %s)" % (form, i, err, non_field_errors) ) if not found_form: self.fail(msg_prefix + "The form '%s' was not used to render the response" % form)
if msg_prefix: msg_prefix += ": "
contexts = to_list(response.context) if not contexts: self.fail(msg_prefix + 'Response did not use any contexts to ' 'render the response')
errors = to_list(errors)
found_formset = False for i, context in enumerate(contexts): if formset not in context: continue found_formset = True for err in errors: if field is not None: if field in context[formset].forms[form_index].errors: field_errors = context[formset].forms[form_index].errors[field] self.assertTrue( err in field_errors, msg_prefix + "The field '%s' on formset '%s', " "form %d in context %d does not contain the " "error '%s' (actual errors: %s)" % (field, formset, form_index, i, err, repr(field_errors)) ) elif field in context[formset].forms[form_index].fields: self.fail( msg_prefix + "The field '%s' on formset '%s', form %d in context %d contains no errors" % (field, formset, form_index, i) ) else: self.fail( msg_prefix + "The formset '%s', form %d in context %d does not contain the field '%s'" % (formset, form_index, i, field) ) elif form_index is not None: non_field_errors = context[formset].forms[form_index].non_field_errors() self.assertFalse( len(non_field_errors) == 0, msg_prefix + "The formset '%s', form %d in context %d " "does not contain any non-field errors." % (formset, form_index, i) ) self.assertTrue( err in non_field_errors, msg_prefix + "The formset '%s', form %d in context %d " "does not contain the non-field error '%s' (actual errors: %s)" % (formset, form_index, i, err, repr(non_field_errors)) ) else: non_form_errors = context[formset].non_form_errors() self.assertFalse( len(non_form_errors) == 0, msg_prefix + "The formset '%s' in context %d does not " "contain any non-form errors." % (formset, i) ) self.assertTrue( err in non_form_errors, msg_prefix + "The formset '%s' in context %d does not " "contain the non-form error '%s' (actual errors: %s)" % (formset, i, err, repr(non_form_errors)) ) if not found_formset: self.fail(msg_prefix + "The formset '%s' was not used to render the response" % formset)
return template_name, None, msg_prefix
return _AssertTemplateUsedContext(self, context_mgr_template)
return _AssertTemplateNotUsedContext(self, context_mgr_template)
callable_obj = kwargs.pop('callable_obj', None) if callable_obj: warnings.warn( 'The callable_obj kwarg is deprecated. Pass the callable ' 'as a positional argument instead.', RemovedInDjango20Warning ) elif len(args): callable_obj = args[0] args = args[1:]
if callable_obj is None: return cm with cm: callable_obj(*args, **kwargs)
for input, output in valid.items(): self.assertEqual(required.clean(input), output) self.assertEqual(optional.clean(input), output) for input, errors in invalid.items(): with self.assertRaises(ValidationError) as context_manager: required.clean(input) self.assertEqual(context_manager.exception.messages, errors)
error_required = [force_text(required.error_messages['required'])] for e in required.empty_values: with self.assertRaises(ValidationError) as context_manager: required.clean(e) self.assertEqual(context_manager.exception.messages, error_required) self.assertEqual(optional.clean(e), empty_value) if issubclass(fieldclass, CharField): field_kwargs.update({'min_length': 2, 'max_length': 20}) self.assertIsInstance(fieldclass(*field_args, **field_kwargs), fieldclass)
reset_sequences = False
available_apps = None
fixtures = None
serialized_rollback = False
allow_database_queries = True
if getattr(cls, 'multi_db', False): return [ alias for alias in connections if include_mirrors or not connections[alias].settings_dict['TEST']['MIRROR'] ] else: return [DEFAULT_DB_ALIAS]
if self.reset_sequences: self._reset_sequences(db_name)
if self.serialized_rollback and hasattr(connections[db_name], "_test_serialized_contents"): if self.available_apps is not None: apps.unset_available_apps() connections[db_name].creation.deserialize_db_from_string( connections[db_name]._test_serialized_contents ) if self.available_apps is not None: apps.set_available_apps(self.available_apps)
call_command('loaddata', *self.fixtures, **{'verbosity': 0, 'database': db_name})
for conn in connections.all(): conn.close()
for db_name in self._databases_names(include_mirrors=False): inhibit_post_migrate = ( self.available_apps is not None or
self.serialized_rollback and hasattr(connections[db_name], '_test_serialized_contents')
if len(values) > 1 and hasattr(qs, 'ordered') and not qs.ordered: raise ValueError("Trying to compare non-ordered queryset " "against more than one ordered values") return self.assertEqual(list(items), values, msg=msg)
self.setUpTestData() return super(TestCase, self)._fixture_setup()
test_item = test_func test_item.__unittest_skip__ = CheckCondition(condition)
final_rel_path = os_rel_path.replace('\\', '/').lstrip('/') return serve(request, final_rel_path, document_root=self.get_base_dir())
for alias, conn in self.connections_override.items(): connections[alias] = conn
handler = self.static_handler(_MediaFilesHandler(WSGIHandler()))
for index, port in enumerate(self.possible_ports): try: self.httpd = self._create_server(port) except socket.error as e: if (index + 1 < len(self.possible_ports) and e.errno == errno.EADDRINUSE): continue else: raise else: self.port = port break
self.httpd.shutdown() self.httpd.server_close()
if conn.vendor == 'sqlite' and conn.is_in_memory_db(conn.settings_dict['NAME']): conn.allow_thread_sharing = True connections_override[conn.alias] = conn
specified_address = os.environ.get( 'DJANGO_LIVE_TEST_SERVER_ADDRESS', 'localhost:8081-8179')
possible_ports = [] try: host, port_ranges = specified_address.split(':') for port_range in port_ranges.split(','): extremes = list(map(int, port_range.split('-'))) assert len(extremes) in [1, 2] if len(extremes) == 1: possible_ports.append(extremes[0]) else: for port in range(extremes[0], extremes[1] + 1): possible_ports.append(port) except Exception: msg = 'Invalid address ("%s") for live server.' % specified_address six.reraise(ImproperlyConfigured, ImproperlyConfigured(msg), sys.exc_info()[2]) cls.server_thread = cls._create_server_thread(host, possible_ports, connections_override) cls.server_thread.daemon = True cls.server_thread.start()
cls.server_thread.is_ready.wait() if cls.server_thread.error: cls._tearDownClassInternal() raise cls.server_thread.error
if hasattr(cls, 'server_thread'): cls.server_thread.terminate() cls.server_thread.join()
for conn in connections.all(): if conn.vendor == 'sqlite' and conn.is_in_memory_db(conn.settings_dict['NAME']): conn.allow_thread_sharing = False
if isinstance(f, models.FileField): file_field_list.append(f) else: f.save_form_data(instance, cleaned_data[f.name])
from django.db.models.fields import Field as ModelField sortable_private_fields = [f for f in opts.private_fields if isinstance(f, ModelField)] for f in sorted(chain(opts.concrete_fields, sortable_private_fields, opts.many_to_many)): if not getattr(f, 'editable', False): if (fields is not None and f.name in fields and (exclude is None or f.name not in exclude)): raise FieldError( "'%s' cannot be specified for %s model form as it is a non-editable field" % ( f.name, model.__name__) ) continue if fields is not None and f.name not in fields: continue if exclude and f.name in exclude: continue
for opt in ['fields', 'exclude', 'localized_fields']: value = getattr(opts, opt) if isinstance(value, six.string_types) and value != ALL_FIELDS: msg = ("%(model)s.Meta.%(opt)s cannot be a string. " "Did you mean to type: ('%(value)s',)?" % { 'model': new_class.__name__, 'opt': opt, 'value': value, }) raise TypeError(msg)
if opts.fields is None and opts.exclude is None: raise ImproperlyConfigured( "Creating a ModelForm without either the 'fields' attribute " "or the 'exclude' attribute is prohibited; form %s " "needs updating." % name )
opts.fields = None
none_model_fields = [k for k, v in six.iteritems(fields) if not v] missing_fields = (set(none_model_fields) - set(new_class.declared_fields.keys())) if missing_fields: message = 'Unknown field(s) (%s) specified for %s' message = message % (', '.join(missing_fields), opts.model.__name__) raise FieldError(message) fields.update(new_class.declared_fields)
self.instance = opts.model() object_data = {}
if initial is not None: object_data.update(initial) self._validate_unique = False super(BaseModelForm, self).__init__( data, files, auto_id, prefix, object_data, error_class, label_suffix, empty_permitted, use_required_attribute=use_required_attribute, ) for field_name in self.fields: formfield = self.fields[field_name] if hasattr(formfield, 'queryset') and hasattr(formfield, 'get_limit_choices_to'): limit_choices_to = formfield.get_limit_choices_to() if limit_choices_to is not None: formfield.queryset = formfield.queryset.complex_filter(limit_choices_to)
for f in self.instance._meta.fields: field = f.name if field not in self.fields: exclude.append(f.name)
elif self._meta.fields and field not in self._meta.fields: exclude.append(f.name) elif self._meta.exclude and field in self._meta.exclude: exclude.append(f.name)
elif field in self._errors.keys(): exclude.append(f.name)
else: form_field = self.fields[field] field_value = self.cleaned_data.get(field) if not f.blank and not form_field.required and field_value in form_field.empty_values: exclude.append(f.name)
opts = self._meta
if hasattr(errors, 'error_dict'): error_dict = errors.error_dict else: error_dict = {NON_FIELD_ERRORS: errors}
for name, field in self.fields.items(): if isinstance(field, InlineForeignKeyField): exclude.append(name)
if self._validate_unique: self.validate_unique()
for f in chain(opts.many_to_many, opts.private_fields): if not hasattr(f, 'save_form_data'): continue if fields and f.name not in fields: continue if exclude and f.name in exclude: continue if f.name in cleaned_data: f.save_form_data(self.instance, cleaned_data[f.name])
self.instance.save() self._save_m2m()
self.save_m2m = self._save_m2m
attrs = {'model': model} if fields is not None: attrs['fields'] = fields if exclude is not None: attrs['exclude'] = exclude if widgets is not None: attrs['widgets'] = widgets if localized_fields is not None: attrs['localized_fields'] = localized_fields if labels is not None: attrs['labels'] = labels if help_texts is not None: attrs['help_texts'] = help_texts if error_messages is not None: attrs['error_messages'] = error_messages if field_classes is not None: attrs['field_classes'] = field_classes
parent = (object,) if hasattr(form, 'Meta'): parent = (form.Meta, object) Meta = type(str('Meta'), parent, attrs) if formfield_callback: Meta.formfield_callback = staticmethod(formfield_callback) class_name = model.__name__ + str('Form')
form_class_attrs = { 'Meta': Meta, 'formfield_callback': formfield_callback }
return type(form)(class_name, (form,), form_class_attrs)
unique_fields = set()
try: kwargs['initial'] = self.initial_extra[i - self.initial_form_count()] except IndexError: pass
if not qs.ordered: qs = qs.order_by(self.model._meta.pk.name)
self._queryset = qs
all_unique_checks = set() all_date_checks = set() forms_to_delete = self.deleted_forms valid_forms = [form for form in self.forms if form.is_valid() and form not in forms_to_delete] for form in valid_forms: exclude = form._get_validation_exclusions() unique_checks, date_checks = form.instance._get_unique_checks(exclude=exclude) all_unique_checks = all_unique_checks.union(set(unique_checks)) all_date_checks = all_date_checks.union(set(date_checks))
for uclass, unique_check in all_unique_checks: seen_data = set() for form in valid_forms: row_data = ( field if field in self.unique_fields else form.cleaned_data[field] for field in unique_check if field in form.cleaned_data ) row_data = tuple(d._get_pk_val() if hasattr(d, '_get_pk_val') else d for d in row_data) if row_data and None not in row_data: if row_data in seen_data: errors.append(self.get_unique_error_message(unique_check)) form._errors[NON_FIELD_ERRORS] = self.error_class([self.get_form_error()]) for field in unique_check: if field in form.cleaned_data: del form.cleaned_data[field] seen_data.add(row_data) for date_check in all_date_checks: seen_data = set() uclass, lookup, field, unique_for = date_check for form in valid_forms: if (form.cleaned_data and form.cleaned_data[field] is not None and form.cleaned_data[unique_for] is not None): if lookup == 'date': date = form.cleaned_data[unique_for] date_data = (date.year, date.month, date.day) else: date_data = (getattr(form.cleaned_data[unique_for], lookup),) data = (form.cleaned_data[field],) + date_data if data in seen_data: errors.append(self.get_date_error_message(date_check)) form._errors[NON_FIELD_ERRORS] = self.error_class([self.get_form_error()]) del form.cleaned_data[field] seen_data.add(data)
if obj.pk is None: continue self.deleted_objects.append(obj) self.delete_existing(obj, commit=commit)
if self.can_delete and self._should_delete_form(form): continue self.new_objects.append(self.save_new(form, commit=commit)) if not commit: self.saved_forms.append(form)
pk_value = None if form.instance._state.adding else form.instance.pk
if self.form._meta.fields and self.fk.name not in self.form._meta.fields: if isinstance(self.form._meta.fields, tuple): self.form._meta.fields = list(self.form._meta.fields) self.form._meta.fields.append(self.fk.name)
form.data[form.add_prefix(self._pk_field.name)] = None
form.data[form.add_prefix(self.fk.name)] = None
fk_value = self.instance.pk if self.fk.remote_field.field_name != self.fk.remote_field.model._meta.pk.name: fk_value = getattr(self.instance, self.fk.remote_field.field_name) fk_value = getattr(fk_value, 'pk', fk_value) setattr(form.instance, self.fk.get_attname(), fk_value) return form
setattr(form.instance, self.fk.name, self.instance) obj = form.save(commit=False) pk_value = getattr(self.instance, self.fk.remote_field.field_name) setattr(obj, self.fk.get_attname(), getattr(pk_value, 'pk', pk_value)) if commit: obj.save() if commit and hasattr(form, 'save_m2m'): form.save_m2m() return obj
name = self.fk.name kwargs = { 'label': getattr(form.fields.get(name), 'label', capfirst(self.fk.verbose_name)) } if self.fk.remote_field.field_name != self.fk.remote_field.model._meta.pk.name: kwargs['to_field'] = self.fk.remote_field.field_name
if self.instance._state.adding: if kwargs.get('to_field') is not None: to_field = self.instance._meta.get_field(kwargs['to_field']) else: to_field = self.instance._meta.pk if to_field.has_default(): setattr(self.instance, to_field.attname, None)
from django.db.models import ForeignKey opts = model._meta if fk_name: fks_to_parent = [f for f in opts.fields if f.name == fk_name] if len(fks_to_parent) == 1: fk = fks_to_parent[0] if not isinstance(fk, ForeignKey) or \ (fk.remote_field.model != parent_model and fk.remote_field.model not in parent_model._meta.get_parent_list()): raise ValueError( "fk_name '%s' is not a ForeignKey to '%s'." % (fk_name, parent_model._meta.label) ) elif len(fks_to_parent) == 0: raise ValueError( "'%s' has no field named '%s'." % (model._meta.label, fk_name) ) else: fks_to_parent = [ f for f in opts.fields if isinstance(f, ForeignKey) and ( f.remote_field.model == parent_model or f.remote_field.model in parent_model._meta.get_parent_list() ) ] if len(fks_to_parent) == 1: fk = fks_to_parent[0] elif len(fks_to_parent) == 0: if can_fail: return raise ValueError( "'%s' has no ForeignKey to '%s'." % ( model._meta.label, parent_model._meta.label, ) ) else: raise ValueError( "'%s' has more than one ForeignKey to '%s'." % ( model._meta.label, parent_model._meta.label, ) ) return fk
if fk.unique: max_num = 1 kwargs = { 'form': form, 'formfield_callback': formfield_callback, 'formset': formset, 'extra': extra, 'can_delete': can_delete, 'can_order': can_order, 'fields': fields, 'exclude': exclude, 'min_num': min_num, 'max_num': max_num, 'widgets': widgets, 'validate_min': validate_min, 'validate_max': validate_max, 'localized_fields': localized_fields, 'labels': labels, 'help_texts': help_texts, 'error_messages': error_messages, 'field_classes': field_classes, } FormSet = modelformset_factory(model, **kwargs) FormSet.fk = fk return FormSet
return self.parent_instance
if not queryset._prefetch_related_lookups: queryset = queryset.iterator() for obj in queryset: yield self.choice(obj)
default_error_messages = { 'invalid_choice': _('Select a valid choice. That choice is not one of' ' the available choices.'), }
Field.__init__(self, required, widget, label, initial, help_text, *args, **kwargs) self.queryset = queryset
result.queryset = result.queryset return result
if hasattr(self, '_choices'): return self._choices
return ModelChoiceIterator(self)
self.run_validators(value) return qs
try: value = frozenset(value) except TypeError: raise ValidationError( self.error_messages['list'], code='list', ) for pk in value: try: self.queryset.filter(**{key: pk}) except (ValueError, TypeError): raise ValidationError( self.error_messages['invalid_pk_value'], code='invalid_pk_value', params={'pk': pk}, ) qs = self.queryset.filter(**{'%s__in' % key: value}) pks = set(force_text(getattr(o, key)) for o in qs) for val in value: if force_text(val) not in pks: raise ValidationError( self.error_messages['invalid_choice'], code='invalid_choice', params={'value': val}, ) return qs
TOTAL_FORM_COUNT = 'TOTAL_FORMS' INITIAL_FORM_COUNT = 'INITIAL_FORMS' MIN_NUM_FORM_COUNT = 'MIN_NUM_FORMS' MAX_NUM_FORM_COUNT = 'MAX_NUM_FORMS' ORDERING_FIELD_NAME = 'ORDER' DELETION_FIELD_NAME = 'DELETE'
DEFAULT_MIN_NUM = 0
DEFAULT_MAX_NUM = 1000
self.base_fields[MIN_NUM_FORM_COUNT] = IntegerField(required=False, widget=HiddenInput) self.base_fields[MAX_NUM_FORM_COUNT] = IntegerField(required=False, widget=HiddenInput) super(ManagementForm, self).__init__(*args, **kwargs)
return min(self.management_form.cleaned_data[TOTAL_FORM_COUNT], self.absolute_max)
if initial_forms > self.max_num >= 0: total_forms = initial_forms elif total_forms > self.max_num >= 0: total_forms = self.max_num
initial_forms = len(self.initial) if self.initial else 0
forms = [self._construct_form(i, **self.get_form_kwargs(i)) for i in range(self.total_form_count())] return forms
'use_required_attribute': False,
if i >= self.initial_form_count() and i >= self.min_num: defaults['empty_permitted'] = True defaults.update(kwargs) form = self.form(**defaults) self.add_fields(form, i) return form
if not hasattr(self, '_deleted_form_indexes'): self._deleted_form_indexes = [] for i in range(0, self.total_form_count()): form = self.forms[i] if i >= self.initial_form_count() and not form.has_changed(): continue if self._should_delete_form(form): self._deleted_form_indexes.append(i) return [self.forms[i] for i in self._deleted_form_indexes]
if not hasattr(self, '_ordering'): self._ordering = [] for i in range(0, self.total_form_count()): form = self.forms[i] if i >= self.initial_form_count() and not form.has_changed(): continue if self.can_delete and self._should_delete_form(form): continue self._ordering.append((i, form.cleaned_data[ORDERING_FIELD_NAME]))
return [self.forms[i[0]] for i in self._ordering]
forms_valid = True self.errors for i in range(0, self.total_form_count()): form = self.forms[i] if self.can_delete: if self._should_delete_form(form): continue forms_valid &= form.is_valid() return forms_valid and not self.non_form_errors()
self.clean()
if index is not None and index < self.initial_form_count(): form.fields[ORDERING_FIELD_NAME] = IntegerField(label=_('Order'), initial=index + 1, required=False) else: form.fields[ORDERING_FIELD_NAME] = IntegerField(label=_('Order'), required=False)
if self.forms: return self.forms[0].media else: return self.empty_form.media
forms = ' '.join(form.as_table() for form in self) return mark_safe('\n'.join([six.text_type(self.management_form), forms]))
absolute_max = max_num + DEFAULT_MAX_NUM attrs = {'form': form, 'extra': extra, 'can_order': can_order, 'can_delete': can_delete, 'min_num': min_num, 'max_num': max_num, 'absolute_max': absolute_max, 'validate_min': validate_min, 'validate_max': validate_max} return type(form.__name__ + str('FormSet'), (formset,), attrs)
current_fields = [] for key, value in list(attrs.items()): if isinstance(value, Field): current_fields.append((key, value)) attrs.pop(key) current_fields.sort(key=lambda x: x[1].creation_counter) attrs['declared_fields'] = OrderedDict(current_fields)
declared_fields = OrderedDict() for base in reversed(new_class.__mro__): if hasattr(base, 'declared_fields'): declared_fields.update(base.declared_fields)
for attr, value in base.__dict__.items(): if value is None and attr in declared_fields: declared_fields.pop(attr)
field_order = None prefix = None use_required_attribute = True
self.label_suffix = label_suffix if label_suffix is not None else _(':') self.empty_permitted = empty_permitted
self.fields = copy.deepcopy(self.base_fields) self._bound_fields_cache = {} self.order_fields(self.field_order if field_order is None else field_order)
bf_errors = self.error_class([conditional_escape(error) for error in bf.errors]) if bf.is_hidden: if bf_errors: top_errors.extend( [_('(Hidden field %(name)s) %(error)s') % {'name': name, 'error': force_text(e)} for e in bf_errors]) hidden_fields.append(six.text_type(bf)) else: css_classes = bf.css_classes() if css_classes: html_class_attr = ' class="%s"' % css_classes
if not last_row.endswith(row_ender): last_row = (normal_row % { 'errors': '', 'label': '', 'field': '', 'help_text': '', 'html_class_attr': html_class_attr, 'css_classes': '', 'field_name': '', }) output.append(last_row) output[-1] = last_row[:-len(row_ender)] + str_hidden + row_ender
output.append(str_hidden)
error = ValidationError(error)
if self.empty_permitted and not self.has_changed(): return
self.cleaned_data[name] = self.initial.get(name, field.initial) continue
data.append(name) continue
media = sorted(self._css.keys()) return chain(*[[ format_html( '<link href="{}" type="text/css" media="{}" rel="stylesheet" />', self.absolute_path(path), medium ) for path in self._css[medium] ] for medium in media])
sup_cls = super(cls, self) try: base = sup_cls.media except AttributeError: base = Media()
definition = getattr(cls, 'Media', None) if definition: extend = getattr(definition, 'extend', True) if extend: if extend is True: m = base else: m = Media() for medium in extend: m = m + base[medium] return m + Media(definition) else: return Media(definition) else: return base
final_attrs['value'] = force_text(self.format_value(value))
input_attrs['id'] = '%s_%s' % (id_, i)
return FILE_INPUT_CONTRADICTION
default_attrs = {'cols': '40', 'rows': '10'} if attrs: default_attrs.update(attrs) super(Textarea, self).__init__(default_attrs)
def boolean_check(v): return not (v is False or v is None or v == '')
self.check_test = boolean_check if check_test is None else check_test
final_attrs['value'] = force_text(value)
return False
values = {'true': True, 'false': False} if isinstance(value, six.string_types): value = values.get(value.lower(), value) return bool(value)
self.choices = list(choices)
selected_choices.remove(option_value)
selected_choices = set(force_text(v) for v in selected_choices) output = [] for option_value, option_label in self.choices: if isinstance(option_label, (list, tuple)): output.append(format_html('<optgroup label="{}">', force_text(option_value))) for option in option_label: output.append(self.render_option(selected_choices, *option)) output.append('</optgroup>') else: output.append(self.render_option(selected_choices, option_value, option_label)) return '\n'.join(output)
renderer = kwargs.pop('renderer', None) if renderer: self.renderer = renderer super(RendererMixin, self).__init__(*args, **kwargs)
if id_: id_ += '_0' return id_
if not isinstance(value, list): value = self.decompress(value) output = [] final_attrs = self.build_attrs(attrs) id_ = final_attrs.get('id') for i, widget in enumerate(self.widgets): try: widget_value = value[i] except IndexError: widget_value = None if id_: final_attrs = dict(final_attrs, id='%s_%s' % (id_, i)) output.append(widget.render(name + '_%s' % i, widget_value, final_attrs)) return mark_safe(self.format_output(output))
if id_: id_ += '_0' return id_
if years: self.years = years else: this_year = datetime.date.today().year self.years = range(this_year, this_year + 10)
if months: self.months = months else: self.months = MONTHS
if isinstance(empty_label, (list, tuple)): if not len(empty_label) == 3: raise ValueError('empty_label list/tuple must have 3 elements.')
info = super(UserList, self).__reduce_ex__(*args, **kwargs) return info[:3] + (None, None)
default_error_messages = { 'required': _('This field is required.'), } empty_values = list(validators.EMPTY_VALUES)
creation_counter = 0
self.required, self.label, self.initial = required, label, initial self.show_hidden_initial = show_hidden_initial self.help_text = help_text self.disabled = disabled self.label_suffix = label_suffix widget = widget or self.widget if isinstance(widget, type): widget = widget()
self.localize = localize if self.localize: widget.is_localized = True
widget.is_required = self.required
extra_attrs = self.widget_attrs(widget) if extra_attrs: widget.attrs.update(extra_attrs)
self.creation_counter = Field.creation_counter Field.creation_counter += 1
initial_value = initial if initial is not None else '' data_value = data if data is not None else '' return initial_value != data_value
attrs['maxlength'] = str(self.max_length)
attrs['minlength'] = str(self.min_length)
kwargs.setdefault('widget', super(IntegerField, self).widget)
try: value = int(self.re_decimal.sub('', str(value))) except (ValueError, TypeError): raise ValidationError(self.error_messages['invalid'], code='invalid') return value
if value != value or value in (Decimal('Inf'), Decimal('-Inf')): raise ValidationError(self.error_messages['invalid'], code='invalid')
if value != value or value == Decimal("Inf") or value == Decimal("-Inf"): raise ValidationError(self.error_messages['invalid'], code='invalid')
step = str(Decimal('1') / 10 ** self.decimal_places).lower()
unicode_value = force_text(value, strings_only=True) if isinstance(unicode_value, six.text_type): value = unicode_value.strip() if isinstance(value, six.text_type): for format in self.input_formats: try: return self.strptime(value, format) except (ValueError, TypeError): continue raise ValidationError(self.error_messages['invalid'], code='invalid')
try: file_name = data.name file_size = data.size except AttributeError: raise ValidationError(self.error_messages['invalid'], code='invalid')
if data is FILE_INPUT_CONTRADICTION: raise ValidationError(self.error_messages['contradiction'], code='contradiction') if data is False: if not self.required: return False data = None if not data and initial: return initial return super(FileField, self).clean(data)
if hasattr(data, 'temporary_file_path'): file = data.temporary_file_path() else: if hasattr(data, 'read'): file = BytesIO(data.read()) else: file = BytesIO(data['content'])
image = Image.open(file) image.verify()
f.image = image f.content_type = Image.MIME.get(image.format)
six.reraise(ValidationError, ValidationError( self.error_messages['invalid_image'], code='invalid_image', ), sys.exc_info()[2])
raise ValidationError(self.error_messages['invalid'], code='invalid')
url_fields[0] = 'http'
url_fields[1] = url_fields[2] url_fields[2] = '' url_fields = split_url(urlunsplit(url_fields))
if isinstance(value, six.string_types) and value.lower() in ('false', '0'): value = False else: value = bool(value) return super(BooleanField, self).to_python(value)
return self.to_python(initial) != self.to_python(data)
if callable(value): value = CallableChoiceIterator(value) else: value = list(value)
for k2, v2 in v: if value == k2 or text_value == force_text(k2): return True
for val in value: if not self.valid_value(val): raise ValidationError( self.error_messages['invalid_choice'], code='invalid_choice', params={'value': val}, )
for f in fields: f.required = False self.fields = fields
f.required = False
if self.required: raise ValidationError(self.error_messages['required'], code='required')
if field.error_messages['incomplete'] not in errors: errors.append(field.error_messages['incomplete']) continue
errors.extend(m for m in e.error_list if m not in errors)
if data_list[0] in self.empty_values: raise ValidationError(self.error_messages['invalid_date'], code='invalid_date') if data_list[1] in self.empty_values: raise ValidationError(self.error_messages['invalid_time'], code='invalid_time') result = datetime.datetime.combine(*data_list) return from_current_timezone(result)
if not isinstance(idx, six.integer_types + (slice,)): raise TypeError return list(self.__iter__())[idx]
if (isinstance(data, (datetime.datetime, datetime.time)) and not self.field.widget.supports_microseconds): data = data.replace(microsecond=0) self._initial_value = data
if label_suffix and contents and contents[-1] not in _(':?.!'): contents = format_html('{}{}', contents, label_suffix) widget = self.field.widget id_ = widget.attrs.get('id') or self.auto_id if id_: id_for_label = widget.id_for_label(id_) if id_for_label: attrs = dict(attrs or {}, **{'for': id_for_label}) if self.field.required and hasattr(self.form, 'required_css_class'): attrs = attrs or {} if 'class' in attrs: attrs['class'] += ' ' + self.form.required_css_class else: attrs['class'] = self.form.required_css_class attrs = flatatt(attrs) if attrs else '' contents = format_html('<label{}>{}</label>', attrs, contents) else: contents = conditional_escape(contents) return mark_safe(contents)
class datetimeobject(datetime, object): pass
try: if timezone.is_naive(value): default_timezone = timezone.get_default_timezone() value = timezone.make_aware(value, default_timezone) except Exception: return ''
if isinstance(arg, tzinfo): tz = arg elif isinstance(arg, six.string_types) and pytz is not None: try: tz = pytz.timezone(arg) except pytz.UnknownTimeZoneError: return '' else: return ''
result = datetimeobject(result.year, result.month, result.day, result.hour, result.minute, result.second, result.microsecond, result.tzinfo) result.convert_to_local_time = False return result
args = token.contents.split() if len(args) != 3 or args[1] != 'as': raise TemplateSyntaxError("'get_current_timezone' requires " "'as variable' (got %r)" % args) return GetCurrentTimezoneNode(args[2])
if len(language[0]) > 1: return translation.get_language_info(language[0]) else: return translation.get_language_info(str(language))
is_safe = isinstance(value, SafeData) value = value.replace('%%', '%') value = mark_safe(value) if is_safe else value if self.asvar: context[self.asvar] = value return '' else: return value
context.update(tmp_context) singular, vars = self.render_token_list(self.singular) if self.plural and self.countervar and self.counter: count = self.counter.resolve(context) context[self.countervar] = count plural, plural_vars = self.render_token_list(self.plural) if message_context: result = translation.npgettext(message_context, singular, plural, count) else: result = translation.ungettext(singular, plural, count) vars.extend(plural_vars) else: if message_context: result = translation.pgettext(message_context, singular) else: result = translation.ugettext(singular) default_value = context.template.engine.string_if_invalid
raise TemplateSyntaxError( "'blocktrans' is unable to format string returned by gettext: %r using %r" % (result, data) )
args = token.contents.split() if len(args) != 3 or args[1] != 'as': raise TemplateSyntaxError("'get_available_languages' requires 'as variable' (got %r)" % args) return GetAvailableLanguagesNode(args[2])
args = token.contents.split() if len(args) != 3 or args[1] != 'as': raise TemplateSyntaxError("'get_current_language' requires 'as variable' (got %r)" % args) return GetCurrentLanguageNode(args[2])
args = token.contents.split() if len(args) != 3 or args[1] != 'as': raise TemplateSyntaxError("'get_current_language_bidi' requires 'as variable' (got %r)" % args) return GetCurrentLanguageBidiNode(args[2])
tokens = token.contents.split() if len(tokens) > 1 and tokens[1] != 'as': raise template.TemplateSyntaxError( "First argument in '%s' must be 'as'" % tokens[0]) if len(tokens) > 1: varname = tokens[2] else: varname = None return cls(varname, name)
self = self_wr() if self._alive: self._alive = False if callback is not None: callback(self)
NO_RECEIVERS = object()
self.sender_receivers_cache = weakref.WeakKeyDictionary() if use_caching else {} self._dead_receivers = False
if settings.configured and settings.DEBUG: assert callable(receiver), "Signal receivers must be callable."
if not func_accepts_kwargs(receiver): raise ValueError("Signal receivers must accept keyword arguments (**kwargs).")
if hasattr(receiver, '__self__') and hasattr(receiver, '__func__'): ref = WeakMethod receiver_object = receiver.__self__ if six.PY3: receiver = ref(receiver) weakref.finalize(receiver_object, self._remove_receiver) else: receiver = ref(receiver, self._remove_receiver)
for receiver in self._live_receivers(sender): try: response = receiver(signal=self, sender=sender, **named) except Exception as err: if not hasattr(err, '__traceback__'): err.__traceback__ = sys.exc_info()[2] responses.append((receiver, err)) else: responses.append((receiver, response)) return responses
if self._dead_receivers: self._dead_receivers = False new_receivers = [] for r in self.receivers: if isinstance(r[1], weakref.ReferenceType) and r[1]() is None: continue new_receivers.append(r) self.receivers = new_receivers
if receivers is NO_RECEIVERS: return []
self.sender_receivers_cache[sender] = receivers
receiver = receiver() if receiver is not None: non_weak_receivers.append(receiver)
self._dead_receivers = True
def reset_queries(**kwargs): for conn in connections.all(): conn.queries_log.clear() signals.request_started.connect(reset_queries)
def close_old_connections(**kwargs): for conn in connections.all(): conn.close_if_unusable_or_obsolete() signals.request_started.connect(close_old_connections) signals.request_finished.connect(close_old_connections)
if hasattr(other, 'name'): return self.name == other.name return self.name == other
open.alters_data = True
if save: self.instance.save()
if hasattr(self, '_file'): self.close() del self.file
return {'name': self.name, 'closed': False, '_committed': True, '_file': None}
file = instance.__dict__[self.field.name]
if isinstance(file, six.string_types) or file is None: attr = self.field.attr_class(instance, self.field, file) instance.__dict__[self.field.name] = attr
elif isinstance(file, File) and not isinstance(file, FieldFile): file_copy = self.field.attr_class(instance, self.field, file.name) file_copy.file = file file_copy._committed = False instance.__dict__[self.field.name] = file_copy
elif isinstance(file, FieldFile) and not hasattr(file, 'field'): file.instance = instance file.field = self.field file.storage = self.field.storage
elif isinstance(file, FieldFile) and instance is not file.instance: file.instance = instance
return instance.__dict__[self.field.name]
attr_class = FieldFile
descriptor_class = FileDescriptor
if value is None: return None return six.text_type(value)
file.save(file.name, file, save=False)
if data is not None: if not data: data = '' setattr(instance, self.name, data)
if 'initial' in kwargs: defaults['required'] = False defaults.update(kwargs) return super(FileField, self).formfield(**defaults)
if previous_file is not None: self.field.update_dimension_fields(instance, force=True)
if hasattr(self, '_dimensions_cache'): del self._dimensions_cache super(ImageFieldFile, self).delete(save)
if not cls._meta.abstract: signals.post_init.connect(self.update_dimension_fields, sender=cls)
has_dimension_fields = self.width_field or self.height_field if not has_dimension_fields: return
file = getattr(instance, self.attname)
if not file and not force: return
if dimension_fields_filled and not force: return
if file: width = file.width height = file.height else: width = None height = None
if self.width_field: setattr(instance, self.width_field, width) if self.height_field: setattr(instance, self.height_field, height)
from __future__ import unicode_literals
__all__ = [str(x) for x in ( 'AutoField', 'BLANK_CHOICE_DASH', 'BigAutoField', 'BigIntegerField', 'BinaryField', 'BooleanField', 'CharField', 'CommaSeparatedIntegerField', 'DateField', 'DateTimeField', 'DecimalField', 'DurationField', 'EmailField', 'Empty', 'Field', 'FieldDoesNotExist', 'FilePathField', 'FloatField', 'GenericIPAddressField', 'IPAddressField', 'IntegerField', 'NOT_PROVIDED', 'NullBooleanField', 'PositiveIntegerField', 'PositiveSmallIntegerField', 'SlugField', 'SmallIntegerField', 'TextField', 'TimeField', 'URLField', 'UUIDField', )]
BLANK_CHOICE_DASH = [("", "---------")]
empty_strings_allowed = True empty_values = list(validators.EMPTY_VALUES)
creation_counter = 0 auto_creation_counter = -1
'unique_for_date': _("%(field_label)s must be unique for " "%(date_field_label)s %(lookup_type)s."),
hidden = False
def _description(self): return _('Field of type: %(field_type)s') % { 'field_type': self.__class__.__name__ } description = property(_description)
if auto_created: self.creation_counter = Field.auto_creation_counter Field.auto_creation_counter -= 1 else: self.creation_counter = Field.creation_counter Field.creation_counter += 1
return [ checks.Error( 'Primary keys must not have null=True.', hint=('Set null=False on the field, or ' 'remove primary_key=True argument.'), obj=self, id='fields.E007', ) ]
keywords = {} possibles = { "verbose_name": None, "primary_key": False, "max_length": None, "unique": False, "blank": False, "null": False, "db_index": False, "default": NOT_PROVIDED, "editable": True, "serialize": True, "unique_for_date": None, "unique_for_month": None, "unique_for_year": None, "choices": [], "help_text": '', "db_column": None, "db_tablespace": settings.DEFAULT_INDEX_TABLESPACE, "auto_created": False, "validators": [], "error_messages": None, } attr_overrides = { "unique": "_unique", "error_messages": "_error_messages", "validators": "_validators", "verbose_name": "_verbose_name", } equals_comparison = {"choices", "validators", "db_tablespace"} for name, default in possibles.items(): value = getattr(self, attr_overrides.get(name, name)) if name == "choices" and isinstance(value, collections.Iterable): value = list(value) if name in equals_comparison: if value != default: keywords[name] = value else: if value is not default: keywords[name] = value path = "%s.%s" % (self.__class__.__module__, self.__class__.__name__) if path.startswith("django.db.models.fields.related"): path = path.replace("django.db.models.fields.related", "django.db.models") if path.startswith("django.db.models.fields.files"): path = path.replace("django.db.models.fields.files", "django.db.models") if path.startswith("django.db.models.fields.proxy"): path = path.replace("django.db.models.fields.proxy", "django.db.models") if path.startswith("django.db.models.fields"): path = path.replace("django.db.models.fields", "django.db.models") return ( force_text(self.name, strings_only=True), path, [], keywords, )
if isinstance(other, Field): return self.creation_counter == other.creation_counter return NotImplemented
if isinstance(other, Field): return self.creation_counter < other.creation_counter return NotImplemented
obj = copy.copy(self) if self.remote_field: obj.remote_field = copy.copy(self.remote_field) if hasattr(self.remote_field, 'field') and self.remote_field.field is self: obj.remote_field.field = obj memodict[id(self)] = obj return obj
obj = Empty() obj.__class__ = self.__class__ obj.__dict__ = self.__dict__.copy() return obj
return _empty, (self.__class__,), self.__dict__
return
for optgroup_key, optgroup_value in option_value: if value == optgroup_key: return
data = DictWrapper(self.__dict__, connection.ops.quote_name, "qn_") try: return connection.data_types[self.get_internal_type()] % data except KeyError: return None
if not getattr(cls, self.attname, None): setattr(cls, self.attname, DeferredAttribute(self.attname, cls))
include_blank = (self.blank or not (self.has_default() or 'initial' in kwargs)) defaults['choices'] = self.get_choices(include_blank=include_blank) defaults['coerce'] = self.to_python if self.null: defaults['empty_value'] = None if choices_form_class is not None: form_class = choices_form_class else: form_class = forms.TypedChoiceField for k in list(kwargs): if k not in ('coerce', 'empty_value', 'choices', 'required', 'widget', 'label', 'initial', 'help_text', 'error_messages', 'show_hidden_initial'): del kwargs[k]
return bool(value)
if self.choices: include_blank = not (self.has_default() or 'initial' in kwargs) defaults = {'choices': self.get_choices(include_blank=include_blank)} else: defaults = {'form_class': forms.BooleanField} defaults.update(kwargs) return super(BooleanField, self).formfield(**defaults)
defaults = {'max_length': self.max_length} defaults.update(kwargs) return super(CharField, self).formfield(**defaults)
mutually_exclusive_options = [self.auto_now_add, self.auto_now, self.has_default()] enabled_options = [option not in (None, False) for option in mutually_exclusive_options].count(True) if enabled_options > 1: return [ checks.Error( "The options auto_now, auto_now_add, and default " "are mutually exclusive. Only one of these options " "may be present.", obj=self, id='fields.E160', ) ] else: return []
pass
return []
default_timezone = timezone.get_default_timezone() value = timezone.make_naive(value, default_timezone)
if not prepared: value = self.get_prep_value(value) return connection.ops.adapt_datefield_value(value)
return []
warnings.warn("DateTimeField %s.%s received a naive datetime " "(%s) while time zone support is active." % (self.model.__name__, self.name, value), RuntimeWarning) default_timezone = timezone.get_default_timezone() value = timezone.make_aware(value, default_timezone)
try: name = '%s.%s' % (self.model.__name__, self.name) except AttributeError: name = '(unbound)' warnings.warn("DateTimeField %s received a naive datetime (%s)" " while time zone support is active." % (name, value), RuntimeWarning) default_timezone = timezone.get_default_timezone() value = timezone.make_aware(value, default_timezone)
if not prepared: value = self.get_prep_value(value) return connection.ops.adapt_datetimefield_value(value)
from django.db.backends import utils return utils.format_number(value, self.max_digits, self.decimal_places)
return int(round(value.total_seconds() * 1000000))
kwargs['max_length'] = kwargs.get('max_length', 254) super(EmailField, self).__init__(*args, **kwargs)
return name, path, args, kwargs
defaults = { 'form_class': forms.EmailField, } defaults.update(kwargs) return super(EmailField, self).formfield(**defaults)
range_validators = [] internal_type = self.get_internal_type() min_value, max_value = connection.ops.integer_field_range(internal_type) if min_value is not None: range_validators.append(validators.MinValueValidator(min_value)) if max_value is not None: range_validators.append(validators.MaxValueValidator(max_value)) return super(IntegerField, self).validators + range_validators
if 'db_index' not in kwargs: kwargs['db_index'] = True self.allow_unicode = kwargs.pop('allow_unicode', False) if self.allow_unicode: self.default_validators = [validators.validate_unicode_slug] super(SlugField, self).__init__(*args, **kwargs)
defaults = {'max_length': self.max_length, 'widget': forms.Textarea} defaults.update(kwargs) return super(TextField, self).formfield(**defaults)
return []
return value.time()
if not prepared: value = self.get_prep_value(value) return connection.ops.adapt_timefield_value(value)
defaults = { 'form_class': forms.URLField, } defaults.update(kwargs) return super(URLField, self).formfield(**defaults)
if isinstance(value, six.text_type): return six.memoryview(b64decode(force_bytes(value))) return value
return type( str('RelatedObjectDoesNotExist'), (self.field.remote_field.model.DoesNotExist, AttributeError), {} )
if self.field.remote_field.is_hidden() or len(self.field.foreign_related_fields) == 1: query = {'%s__in' % related_field.name: set(instance_attr(inst)[0] for inst in instances)} else: query = {'%s__in' % self.field.related_query_name(): instances} queryset = queryset.filter(**query)
if not self.field.remote_field.multiple: rel_obj_cache_name = self.field.remote_field.get_cache_name() for rel_obj in queryset: instance = instances_dict[rel_obj_attr(rel_obj)] setattr(rel_obj, rel_obj_cache_name, instance) return queryset, rel_obj_attr, instance_attr, True, self.cache_name
try: rel_obj = getattr(instance, self.cache_name) except AttributeError: val = self.field.get_local_related_value(instance) if None in val: rel_obj = None else: qs = self.get_queryset(instance=instance) qs = qs.filter(self.field.get_reverse_related_filter(instance)) rel_obj = qs.get() if not self.field.remote_field.multiple: setattr(rel_obj, self.field.remote_field.get_cache_name(), instance) setattr(instance, self.cache_name, rel_obj)
if value is not None and not isinstance(value, self.field.remote_field.model._meta.concrete_model): raise ValueError( 'Cannot assign "%r": "%s.%s" must be a "%s" instance.' % ( value, instance._meta.object_name, self.field.name, self.field.remote_field.model._meta.object_name, ) ) elif value is not None: if instance._state.db is None: instance._state.db = router.db_for_write(instance.__class__, instance=value) elif value._state.db is None: value._state.db = router.db_for_write(value.__class__, instance=instance) elif value._state.db is not None and instance._state.db is not None: if not router.allow_relation(value, instance): raise ValueError('Cannot assign "%r": the current database router prevents this relation.' % value)
if value is None: related = getattr(instance, self.cache_name, None)
if related is not None: setattr(related, self.field.remote_field.get_cache_name(), None)
else: for lh_field, rh_field in self.field.related_fields: setattr(instance, lh_field.attname, getattr(value, rh_field.attname))
setattr(instance, self.cache_name, value)
if value is not None and not self.field.remote_field.multiple: setattr(value, self.field.remote_field.get_cache_name(), instance)
return type( str('RelatedObjectDoesNotExist'), (self.related.related_model.DoesNotExist, AttributeError), {} )
rel_obj_cache_name = self.related.field.get_cache_name() for rel_obj in queryset: instance = instances_dict[rel_obj_attr(rel_obj)] setattr(rel_obj, rel_obj_cache_name, instance) return queryset, rel_obj_attr, instance_attr, True, self.cache_name
try: rel_obj = getattr(instance, self.cache_name) except AttributeError: related_pk = instance._get_pk_val() if related_pk is None: rel_obj = None else: filter_args = self.related.field.get_forward_related_filter(instance) try: rel_obj = self.get_queryset(instance=instance).get(**filter_args) except self.related.related_model.DoesNotExist: rel_obj = None else: setattr(rel_obj, self.related.field.get_cache_name(), instance) setattr(instance, self.cache_name, rel_obj)
try: rel_obj = getattr(instance, self.cache_name) except AttributeError: pass else: delattr(instance, self.cache_name) setattr(rel_obj, self.related.field.name, None)
raise ValueError( 'Cannot assign "%r": "%s.%s" must be a "%s" instance.' % ( value, instance._meta.object_name, self.related.get_accessor_name(), self.related.related_model._meta.object_name, ) )
for index, field in enumerate(self.related.field.local_related_fields): setattr(value, field.attname, related_pk[index])
setattr(instance, self.cache_name, value)
setattr(value, self.related.field.get_cache_name(), instance)
manager = getattr(self.model, kwargs.pop('manager')) manager_class = create_reverse_many_to_one_manager(manager.__class__, rel) return manager_class(self.instance)
for rel_obj in queryset: instance = instances_dict[rel_obj_attr(rel_obj)] setattr(rel_obj, self.field.name, instance) cache_name = self.field.related_query_name() return queryset, rel_obj_attr, instance_attr, False, cache_name
if rel.field.null: def remove(self, *objs, **kwargs): if not objs: return bulk = kwargs.pop('bulk', True) val = self.field.get_foreign_related_value(self.instance) old_ids = set() for obj in objs: if self.field.get_local_related_value(obj) == val: old_ids.add(obj.pk) else: raise self.field.remote_field.model.DoesNotExist( "%r is not related to %r." % (obj, self.instance) ) self._clear(self.filter(pk__in=old_ids), bulk) remove.alters_data = True
queryset.update(**{self.field.name: None})
objs = tuple(objs)
return self.rel.through
if instance.pk is None: raise ValueError("%r instance needs to have a primary key value before " "a many-to-many relationship can be used." % instance.__class__.__name__)
manager = getattr(self.model, kwargs.pop('manager')) manager_class = create_forward_many_to_many_manager(manager.__class__, rel, reverse) return manager_class(instance=self.instance)
removed_vals_filters = (not isinstance(removed_vals, QuerySet) or removed_vals._has_filters()) if removed_vals_filters: filters &= Q(**{'%s__in' % self.target_field_name: removed_vals}) if self.symmetrical: symmetrical_filters = Q(**{self.target_field_name: self.related_val}) if removed_vals_filters: symmetrical_filters &= Q( **{'%s__in' % self.source_field_name: removed_vals}) filters |= symmetrical_filters return filters
fk = self.through._meta.get_field(self.source_field_name) join_table = self.through._meta.db_table connection = connections[queryset.db] qn = connection.ops.quote_name queryset = queryset.extra(select={ '_prefetch_related_val_%s' % f.attname: '%s.%s' % (qn(join_table), qn(f.column)) for f in fk.local_related_fields}) return ( queryset, lambda result: tuple( getattr(result, '_prefetch_related_val_%s' % f.attname) for f in fk.local_related_fields ), lambda inst: tuple( f.get_db_prep_value(getattr(inst, f.attname), connection) for f in fk.foreign_related_fields ), False, self.prefetch_cache_name, )
if self.symmetrical: self._add_items(self.target_field_name, self.source_field_name, *objs)
objs = tuple(objs)
if not self.through._meta.auto_created: opts = self.through._meta raise AttributeError( "Cannot use create() on a ManyToManyField which specifies " "an intermediary model. Use %s.%s's Manager instead." % (opts.app_label, opts.object_name) ) db = router.db_for_write(self.instance.__class__, instance=self.instance) new_obj = super(ManyRelatedManager, self.db_manager(db)).create(**kwargs) self.add(new_obj) return new_obj
if created: self.add(obj) return obj, created
if created: self.add(obj) return obj, created
from django.db.models import Model if objs: new_ids = set() for obj in objs: if isinstance(obj, self.model): if not router.allow_relation(obj, self.instance): raise ValueError( 'Cannot add "%r": instance is on database "%s", value is on database "%s"' % (obj, self.instance._state.db, obj._state.db) ) fk_val = self.through._meta.get_field( target_field_name).get_foreign_related_value(obj)[0] if fk_val is None: raise ValueError( 'Cannot add "%r": the value for field "%s" is None' % (obj, target_field_name) ) new_ids.add(fk_val) elif isinstance(obj, Model): raise TypeError( "'%s' instance expected, got %r" % (self.model._meta.object_name, obj) ) else: new_ids.add(obj)
signals.m2m_changed.send( sender=self.through, action='pre_add', instance=self.instance, reverse=self.reverse, model=self.model, pk_set=new_ids, using=db, )
self.through._default_manager.using(db).bulk_create([ self.through(**{ '%s_id' % source_field_name: self.related_val[0], '%s_id' % target_field_name: obj_id, }) for obj_id in new_ids ])
signals.m2m_changed.send( sender=self.through, action='post_add', instance=self.instance, reverse=self.reverse, model=self.model, pk_set=new_ids, using=db, )
if not objs: return
old_ids = set() for obj in objs: if isinstance(obj, self.model): fk_val = self.target_field.get_foreign_related_value(obj)[0] old_ids.add(fk_val) else: old_ids.add(obj)
signals.m2m_changed.send( sender=self.through, action="pre_remove", instance=self.instance, reverse=self.reverse, model=self.model, pk_set=old_ids, using=db, ) target_model_qs = super(ManyRelatedManager, self).get_queryset() if target_model_qs._has_filters(): old_vals = target_model_qs.using(db).filter(**{ '%s__in' % self.target_field.target_field.attname: old_ids}) else: old_vals = old_ids filters = self._build_remove_filters(old_vals) self.through._default_manager.using(db).filter(filters).delete()
auto_created = True concrete = False editable = False is_relation = True
null = True
@property def to(self): warnings.warn( "Usage of ForeignObjectRel.to attribute has been deprecated. " "Use the model attribute instead.", RemovedInDjango20Warning, 2) return self.model
self.field_name = None
opts = model._meta if model else self.related_model._meta model = model or self.related_model if self.multiple: if self.symmetrical and model == self.model: return None if self.related_name: return self.related_name return opts.model_name + ('_set' if self.multiple else '')
if getattr(lhs.output_field, 'primary_key', False): return (value.pk,) sources = lhs.output_field.get_path_info()[-1].target_fields for source in sources: while not isinstance(value, source.model) and source.remote_field: source = source.remote_field.model._meta.get_field(source.remote_field.field_name) value_list.append(getattr(value, source.attname)) return tuple(value_list)
self.rhs = [get_normalized_value(val, self.lhs)[0] for val in self.rhs] if hasattr(self.lhs.output_field, 'get_path_info'): target_field = self.lhs.output_field.get_path_info()[-1].target_fields[-1] self.rhs = [target_field.get_prep_value(v) for v in self.rhs]
from django.db.models.sql.where import WhereNode, SubqueryConstraint, AND, OR
self.rhs = get_normalized_value(self.rhs, self.lhs)[0] if hasattr(self.lhs.output_field, 'get_path_info'): target_field = self.lhs.output_field.get_path_info()[-1].target_fields[-1] self.rhs = target_field.get_prep_value(self.rhs)
if relation == RECURSIVE_RELATIONSHIP_CONSTANT: relation = scope_model
if isinstance(relation, six.string_types): if "." not in relation: relation = "%s.%s" % (scope_model._meta.app_label, relation)
one_to_many = False one_to_one = False many_to_many = False many_to_one = False
apps.check_models_ready() return self.remote_field.model
if not isinstance(self.remote_field.model, ModelBase): return []
rel_opts = self.remote_field.model._meta rel_is_hidden = self.remote_field.is_hidden()
potential_clashes = rel_opts.fields + rel_opts.many_to_many for clash_field in potential_clashes:
potential_clashes = (r for r in rel_opts.related_objects if r.field is not self) for clash_field in potential_clashes:
return None
if isinstance(self.remote_field.model, six.string_types): to_string = self.remote_field.model else: to_string = self.remote_field.model._meta.label return apps.get_swappable_settings_name(to_string)
limit_choices_to = self.remote_field.limit_choices_to defaults.update({ 'limit_choices_to': limit_choices_to, })
many_to_many = False many_to_one = True one_to_many = False one_to_one = False
if isinstance(self.remote_field.model, six.string_types): kwargs['to'] = self.remote_field.model else: kwargs['to'] = "%s.%s" % ( self.remote_field.model._meta.app_label, self.remote_field.model._meta.object_name, ) swappable_setting = self.swappable_setting if swappable_setting is not None: if hasattr(kwargs['to'], "setting_name"): if kwargs['to'].setting_name != swappable_setting: raise ValueError( "Cannot deconstruct a ForeignKey pointing to a model " "that is swapped in place of more than one model (%s and %s)" % (kwargs['to'].setting_name, swappable_setting) ) from django.db.migrations.writer import SettingsReference kwargs['to'] = SettingsReference( kwargs['to'], swappable_setting, ) return name, path, args, kwargs
if field.primary_key: possible_parent_link = opts.get_ancestor_link(field.model) if (not possible_parent_link or possible_parent_link.primary_key or possible_parent_link.model._meta.abstract): ret.append(instance.pk) continue ret.append(getattr(instance, field.attname))
if not self.remote_field.is_hidden() and not related.related_model._meta.swapped: setattr(cls._meta.concrete_model, related.get_accessor_name(), self.related_accessor_class(related)) if self.remote_field.limit_choices_to: cls._meta.related_fkey_lookups.append(self.remote_field.limit_choices_to)
many_to_many = False many_to_one = True one_to_many = False one_to_one = False
to_field = to_field or (to._meta.pk and to._meta.pk.name)
if self.db_index: del kwargs['db_index'] else: kwargs['db_index'] = False if self.db_constraint is not True: kwargs['db_constraint'] = self.db_constraint to_meta = getattr(self.remote_field.model, "_meta", None) if self.remote_field.field_name and ( not to_meta or (to_meta.pk and self.remote_field.field_name != to_meta.pk.name)): kwargs['to_field'] = self.remote_field.field_name return name, path, args, kwargs
many_to_many = False many_to_one = False one_to_many = False one_to_one = True
return []
return type(str(name), (models.Model,), { 'Meta': meta, '__module__': klass.__module__, from_: models.ForeignKey( klass, related_name='%s+' % name, db_tablespace=field.db_tablespace, db_constraint=field.remote_field.db_constraint, on_delete=CASCADE, ), to: models.ForeignKey( to_model, related_name='%s+' % name, db_tablespace=field.db_tablespace, db_constraint=field.remote_field.db_constraint, on_delete=CASCADE, ) })
many_to_many = True many_to_one = False one_to_many = False one_to_one = False
to = str(to)
errors.append( checks.Error( "Field specifies a many-to-many relation through model " "'%s', which has not been installed." % qualified_model_name, obj=self, id='fields.E331', ) )
to_model = resolve_relation(from_model, self.remote_field.model) from_model_name = from_model._meta.object_name if isinstance(to_model, six.string_types): to_model_name = to_model else: to_model_name = to_model._meta.object_name relationship_model_name = self.remote_field.through._meta.object_name self_referential = from_model == to_model
if (self_referential and self.remote_field.symmetrical and not self.remote_field.through._meta.auto_created): errors.append( checks.Error( 'Many-to-many fields with intermediate tables must not be symmetrical.', obj=self, id='fields.E332', ) )
if self_referential: seen_self = sum( from_model == getattr(field.remote_field, 'model', None) for field in self.remote_field.through._meta.fields )
seen_from = sum( from_model == getattr(field.remote_field, 'model', None) for field in self.remote_field.through._meta.fields ) seen_to = sum( to_model == getattr(field.remote_field, 'model', None) for field in self.remote_field.through._meta.fields )
if self.remote_field.through_fields is not None: if not (len(self.remote_field.through_fields) >= 2 and self.remote_field.through_fields[0] and self.remote_field.through_fields[1]): errors.append( checks.Error( "Field specifies 'through_fields' but does not provide " "the names of the two link fields that should be used " "for the relation through model '%s'." % qualified_model_name, hint="Make sure you specify 'through_fields' as through_fields=('field1', 'field2')", obj=self, id='fields.E337', ) )
else: assert from_model is not None, ( "ManyToManyField with intermediate " "tables cannot be checked if you don't pass the model " "where the field is attached to." )
if self.db_table is not None: kwargs['db_table'] = self.db_table if self.remote_field.db_constraint is not True: kwargs['db_constraint'] = self.remote_field.db_constraint if self.remote_field.related_name is not None: kwargs['related_name'] = self.remote_field.related_name if self.remote_field.related_query_name is not None: kwargs['related_query_name'] = self.remote_field.related_query_name if isinstance(self.remote_field.model, six.string_types): kwargs['to'] = self.remote_field.model else: kwargs['to'] = "%s.%s" % ( self.remote_field.model._meta.app_label, self.remote_field.model._meta.object_name, ) if getattr(self.remote_field, 'through', None) is not None: if isinstance(self.remote_field.through, six.string_types): kwargs['through'] = self.remote_field.through elif not self.remote_field.through._meta.auto_created: kwargs['through'] = "%s.%s" % ( self.remote_field.through._meta.app_label, self.remote_field.through._meta.object_name, ) swappable_setting = self.swappable_setting if swappable_setting is not None: if hasattr(kwargs['to'], "setting_name"): if kwargs['to'].setting_name != swappable_setting: raise ValueError( "Cannot deconstruct a ManyToManyField pointing to a " "model that is swapped in place of more than one model " "(%s and %s)" % (kwargs['to'].setting_name, swappable_setting) )
if found: setattr(self, cache_attr, getattr(f, attr)) break else: found = True
if self.remote_field.symmetrical and ( self.remote_field.model == "self" or self.remote_field.model == cls._meta.object_name): self.remote_field.related_name = "%s_rel_+" % name elif self.remote_field.is_hidden(): self.remote_field.related_name = "_%s_%s_+" % (cls.__name__.lower(), name)
if not cls._meta.abstract: if self.remote_field.through: def resolve_through_model(_, model, field): field.remote_field.through = model lazy_related_operation(resolve_through_model, cls, self.remote_field.through, field=self) elif not cls._meta.swapped: self.remote_field.through = create_many_to_many_intermediary_model(self, cls)
setattr(cls, self.name, ManyToManyDescriptor(self.remote_field, reverse=False))
self.m2m_db_table = curry(self._get_m2m_db_table, cls._meta)
if not self.remote_field.is_hidden() and not related.related_model._meta.swapped: setattr(cls, related.get_accessor_name(), ManyToManyDescriptor(self.remote_field, reverse=True))
self.m2m_column_name = curry(self._get_m2m_attr, related, 'column') self.m2m_reverse_name = curry(self._get_m2m_reverse_attr, related, 'column')
if defaults.get('initial') is not None: initial = defaults['initial'] if callable(initial): initial = initial() defaults['initial'] = [i._get_pk_val() for i in initial] return super(ManyToManyField, self).formfield(**defaults)
return None
'Cast', 'Coalesce', 'Concat', 'ConcatPair', 'Greatest', 'Least', 'Length', 'Lower', 'Now', 'Substr', 'Upper', 'Extract', 'ExtractDay', 'ExtractHour', 'ExtractMinute', 'ExtractMonth', 'ExtractSecond', 'ExtractWeekDay', 'ExtractYear', 'Trunc', 'TruncDate', 'TruncDay', 'TruncHour', 'TruncMinute', 'TruncMonth', 'TruncSecond', 'TruncYear',
tzname = None if settings.USE_TZ: if self.tzinfo is None: tzname = timezone.get_current_timezone_name() else: tzname = timezone._get_timezone_name(self.tzinfo) return tzname
assert False, "Tried to Extract from an invalid type."
if type(field) == DateField and copy.lookup_name in ('hour', 'minute', 'second'): raise ValueError( "Cannot extract time component '%s' from DateField '%s'. " % (copy.lookup_name, field.name) ) return copy
inner_sql = inner_sql.replace('%s', '%%s') if isinstance(self.output_field, DateTimeField): tzname = self.get_tzname() sql, params = connection.ops.datetime_trunc_sql(self.kind, inner_sql, tzname) elif isinstance(self.output_field, DateField): sql = connection.ops.date_trunc_sql(self.kind, inner_sql) params = [] else: raise ValueError('Trunc only valid on DateField or DateTimeField.') return sql, inner_params + params
assert isinstance(field, DateField), ( "%r isn't a DateField or DateTimeField." % field.name ) if not isinstance(copy.output_field, (DateField, DateTimeField)): raise ValueError('output_field must be either DateField or DateTimeField') if type(field) == DateField and ( isinstance(copy.output_field, DateTimeField) or copy.kind in ('hour', 'minute', 'second')): raise ValueError("Cannot truncate DateField '%s' to DateTimeField. " % field.name) return copy
value = value.date()
lhs, lhs_params = compiler.compile(self.lhs) tzname = timezone.get_current_timezone_name() if settings.USE_TZ else None sql, tz_params = connection.ops.datetime_cast_date_sql(lhs, tzname) lhs_params.extend(tz_params) return sql, lhs_params
return self.as_sql(compiler, connection, template='%(expressions)s::%(db_type)s')
if self.output_field.get_internal_type() == 'TextField': class ToNCLOB(Func): function = 'TO_NCLOB'
return super(ConcatPair, self).as_sql( compiler, connection, function='CONCAT_WS', template="%(function)s('', %(expressions)s)" )
c = self.copy() expressions = [ Coalesce(expression, Value('')) for expression in c.get_source_expressions() ] c.set_source_expressions(expressions) return c
if len(expressions) == 2: return ConcatPair(*expressions) return ConcatPair(expressions[0], self._paired(expressions[1:]))
return self.as_sql(compiler, connection, template='STATEMENT_TIMESTAMP()')
PathInfo = namedtuple('PathInfo', 'from_opts to_opts target_fields join_field m2m direct')
AND = 'AND' OR = 'OR' default = AND
clause, joins = query._add_q(self, reuse, allow_joins=allow_joins, split_subq=False) query.promote_joins(joins) return clause
try: f = opts.get_field(self.field_name) except FieldDoesNotExist: f = [f for f in opts.fields if f.attname == self.field_name][0] name = f.name val = self._check_parent_chain(instance, name) if val is None: instance.refresh_from_db(fields=[self.field_name]) val = getattr(instance, self.field_name) data[self.field_name] = val
for parent in inspect.getmro(self.__class__): if 'class_lookups' not in parent.__dict__: continue if lookup_name in parent.class_lookups: return parent.class_lookups[lookup_name]
pass
return ( check(target_opts) or (getattr(field, 'primary_key', False) and check(field.model._meta)) )
LOOKUP_SEP = '__'
partial_method = partial(method, receiver, **kwargs) from django.db import models if isinstance(sender, models.Model) or sender is None: return partial_method(sender) apps = apps or models.base.Options.default_apps apps.lazy_model_operation(partial_method, make_model_tuple(sender))
return (unpickle_inner_exception, (attached_to, name), self.args)
parents = [b for b in bases if isinstance(b, ModelBase)] if not parents: return super_new(cls, name, bases, attrs)
module = attrs.pop('__module__') new_class = super_new(cls, name, bases, {'__module__': module}) attr_meta = attrs.pop('Meta', None) abstract = getattr(attr_meta, 'abstract', False) if not attr_meta: meta = getattr(new_class, 'Meta', None) else: meta = attr_meta base_meta = getattr(new_class, '_meta', None)
app_config = apps.get_containing_app_config(module)
if not hasattr(meta, 'ordering'): new_class._meta.ordering = base_meta.ordering if not hasattr(meta, 'get_latest_by'): new_class._meta.get_latest_by = base_meta.get_latest_by
if is_proxy and base_meta and base_meta.swapped: raise TypeError("%s cannot proxy the swapped model '%s'." % (name, base_meta.swapped))
for obj_name, obj in attrs.items(): new_class.add_to_class(obj_name, obj)
new_fields = chain( new_class._meta.local_fields, new_class._meta.local_many_to_many, new_class._meta.private_fields ) field_names = {f.name for f in new_fields}
if is_proxy: base = None for parent in [kls for kls in parents if hasattr(kls, '_meta')]: if parent._meta.abstract: if parent._meta.fields: raise TypeError( "Abstract base class containing model fields not " "permitted for proxy model '%s'." % name ) else: continue if base is None: base = parent elif parent._meta.concrete_model is not base._meta.concrete_model: raise TypeError("Proxy model '%s' has more than one non-abstract model base class." % name) if base is None: raise TypeError("Proxy model '%s' has no non-abstract model base class." % name) new_class._meta.setup_proxy(base) new_class._meta.concrete_model = base._meta.concrete_model else: new_class._meta.concrete_model = new_class
parent_links = {} for base in reversed([new_class] + parents): if not hasattr(base, '_meta'): continue if base != new_class and not base._meta.abstract: continue for field in base._meta.local_fields: if isinstance(field, OneToOneField): related = resolve_relation(new_class, field.remote_field.model) parent_links[make_model_tuple(related)] = field
inherited_attributes = set() for base in new_class.mro(): if base not in parents or not hasattr(base, '_meta'): inherited_attributes |= set(base.__dict__.keys()) continue
for field in parent_fields: if field.name in field_names: raise FieldError( 'Local field %r in class %r clashes with field of ' 'the same name from base class %r.' % ( field.name, name, base.__name__, ) ) else: inherited_attributes.add(field.name)
base = base._meta.concrete_model base_key = make_model_tuple(base) if base_key in parent_links: field = parent_links[base_key] elif not is_proxy: attr_name = '%s_ptr' % base._meta.model_name field = OneToOneField( base, on_delete=CASCADE, name=attr_name, auto_created=True, parent_link=True, )
if not hasattr(new_class, attr_name): new_class.add_to_class(attr_name, field)
for field in parent_fields: if (field.name not in field_names and field.name not in new_class.__dict__ and field.name not in inherited_attributes): new_field = copy.deepcopy(field) new_class.add_to_class(field.name, new_field) if field.one_to_one: for parent, parent_link in base_parents.items(): if field == parent_link: base_parents[parent] = new_field
new_class._meta.parents.update(base_parents)
for field in base._meta.private_fields: if field.name in field_names: if not base._meta.abstract: raise FieldError( 'Local field %r in class %r clashes with field of ' 'the same name from base class %r.' % ( field.name, name, base.__name__, ) ) else: new_class.add_to_class(field.name, copy.deepcopy(field))
attr_meta.abstract = False new_class.Meta = attr_meta return new_class
if not inspect.isclass(value) and hasattr(value, 'contribute_to_class'): value.contribute_to_class(cls, name) else: setattr(cls, name, value)
if opts.order_with_respect_to.remote_field: wrt = opts.order_with_respect_to remote = wrt.remote_field.model lazy_related_operation(make_foreign_order_accessors, cls, remote)
if cls.__doc__ is None: cls.__doc__ = "%s(%s)" % (cls.__name__, ", ".join(f.name for f in opts.fields))
for manager in opts.managers: originating_model = manager._originating_model if (cls is originating_model or cls._meta.proxy or originating_model._meta.abstract):
else: if not future_default_manager.auto_created: warnings.warn( "Managers from concrete parents will soon qualify as " "default managers. As a result, the 'objects' manager " "won't be created (or recreated) automatically " "anymore on '{model}' and '{future_default_manager}' " "declared on '{future_default_manager_model}' will be " "promoted to default manager. You can declare " "explicitly `objects = models.Manager()` on '{cls}' " "to keep things the way they are or you can switch " "to the new behavior right away by setting " "`Meta.manager_inheritance_from_future` to `True`.".format( cls=cls.__name__, model=opts.label, future_default_manager=future_default_manager.name, future_default_manager_model=future_default_manager._originating_model._meta.label, ), RemovedInDjango20Warning, 2 )
self.adding = True
self._state = ModelState()
args_len = len(args) if args_len > len(self._meta.concrete_fields): raise IndexError("Number of args exceeds number of fields")
for val, field in zip(args, fields_iter): if val is DEFERRED: continue setattr(self, field.attname, val)
fields_iter = iter(self._meta.fields) for val, field in zip(args, fields_iter): if val is DEFERRED: continue setattr(self, field.attname, val) kwargs.pop(field.name, None) if isinstance(field.remote_field, ManyToOneRel): kwargs.pop(field.attname, None)
if field.attname not in kwargs and field.column is None: continue if kwargs: if isinstance(field.remote_field, ForeignObjectRel): try: rel_obj = kwargs.pop(field.name) is_related_object = True except KeyError: try: val = kwargs.pop(field.attname) except KeyError: val = field.get_default() else: if rel_obj is None and field.null: val = None else: try: val = kwargs.pop(field.attname) except KeyError: val = field.get_default() else: val = field.get_default()
if rel_obj is not DEFERRED: setattr(self, field.name, rel_obj)
if (isinstance(getattr(self.__class__, prop), property) or self._meta.get_field(prop)): if kwargs[prop] is not DEFERRED: setattr(self, prop, kwargs[prop]) del kwargs[prop]
deferred_fields = self.get_deferred_fields() if fields is not None: fields = list(fields) db_instance_qs = db_instance_qs.only(*fields) elif deferred_fields: fields = [f.attname for f in self._meta.concrete_fields if f.attname not in deferred_fields] db_instance_qs = db_instance_qs.only(*fields)
continue
if field.is_relation and field.get_cache_name() in self.__dict__: rel_instance = getattr(self, field.get_cache_name()) local_val = getattr(db_instance, field.attname) related_val = None if rel_instance is None else getattr(rel_instance, field.target_field.attname) if local_val != related_val or (local_val is None and related_val is None): del self.__dict__[field.get_cache_name()]
for field in self._meta.concrete_fields: if field.is_relation: try: getattr(self, field.get_cache_name()) except AttributeError: continue obj = getattr(self, field.name, None) if obj and obj.pk is None: if not field.remote_field.multiple: delattr(obj, field.remote_field.get_cache_name()) raise ValueError( "save() prohibited to prevent data loss due to " "unsaved related object '%s'." % field.name )
if len(update_fields) == 0: return
elif not force_insert and deferred_fields and using == self._state.db: field_names = set() for field in self._meta.concrete_fields: if not field.primary_key and not hasattr(field, 'through'): field_names.add(field.attname) loaded_fields = field_names.difference(deferred_fields) if loaded_fields: update_fields = frozenset(loaded_fields)
if cls._meta.proxy: cls = cls._meta.concrete_model meta = cls._meta if not meta.auto_created: signals.pre_save.send(sender=origin, instance=self, raw=raw, using=using, update_fields=update_fields) with transaction.atomic(using=using, savepoint=False): if not raw: self._save_parents(cls, using, update_fields) updated = self._save_table(raw, cls, force_insert, force_update, using, update_fields) self._state.db = using self._state.adding = False
if not meta.auto_created: signals.post_save.send(sender=origin, instance=self, created=(not updated), update_fields=update_fields, raw=raw, using=using)
if (field and getattr(self, parent._meta.pk.attname) is None and getattr(self, field.attname) is not None): setattr(self, parent._meta.pk.attname, getattr(self, field.attname)) self._save_parents(cls=parent, using=using, update_fields=update_fields) self._save_table(cls=parent, using=using, update_fields=update_fields) if field: setattr(self, field.attname, self._get_pk_val(parent._meta)) cache_name = field.get_cache_name() if hasattr(self, cache_name): delattr(self, cache_name)
if pk_set and not force_insert: base_qs = cls._base_manager.using(using) values = [(f, None, (getattr(self, f.attname) if raw else f.pre_save(self, False))) for f in non_pks] forced_update = update_fields or force_update updated = self._do_update(base_qs, using, pk_val, values, update_fields, forced_update) if force_update and not updated: raise DatabaseError("Forced update did not affect any rows.") if update_fields and not updated: raise DatabaseError("Save with update_fields did not affect any rows.") if not updated: if meta.order_with_respect_to: field = meta.order_with_respect_to filter_args = field.get_filter_kwargs_for_object(self) order_value = cls._base_manager.using(using).filter(**filter_args).count() self._order = order_value
return update_fields is not None or filtered.exists()
return filtered._update(values) > 0 or filtered.exists()
if name in exclude: break
date_checks = []
continue
continue
if len(unique_check) != len(lookup_kwargs): continue
model_class_pk = self._get_pk_val(model_class._meta) if not self._state.adding and model_class_pk is not None: qs = qs.exclude(pk=model_class_pk) if qs.exists(): if len(unique_check) == 1: key = unique_check[0] else: key = NON_FIELD_ERRORS errors.setdefault(key, []).append(self.unique_error_message(model_class, unique_check))
date = getattr(self, unique_for) if date is None: continue if lookup_type == 'date': lookup_kwargs['%s__day' % unique_for] = date.day lookup_kwargs['%s__month' % unique_for] = date.month lookup_kwargs['%s__year' % unique_for] = date.year else: lookup_kwargs['%s__%s' % (unique_for, lookup_type)] = getattr(date, lookup_type) lookup_kwargs[field] = getattr(self, field)
if not self._state.adding and self.pk is not None: qs = qs.exclude(pk=self.pk)
if len(unique_check) == 1: field = opts.get_field(unique_check[0]) params['field_label'] = six.text_type(capfirst(field.verbose_name)) return ValidationError( message=field.error_messages['unique'], code='unique', params=params, )
else: field_labels = [capfirst(opts.get_field(f).verbose_name) for f in unique_check] params['field_labels'] = six.text_type(get_text_list(field_labels, _('and'))) return ValidationError( message=_("%(model_name)s with this %(field_labels)s already exists."), code='unique_together', params=params, )
try: self.clean() except ValidationError as e: errors = e.update_error_dict(errors)
if validate_unique: for name in errors.keys(): if name != NON_FIELD_ERRORS and name not in exclude: exclude.append(name) try: self.validate_unique(exclude=exclude) except ValidationError as e: errors = e.update_error_dict(errors)
raw_value = getattr(self, f.attname) if f.blank and raw_value in f.empty_values: continue try: setattr(self, f.attname, f.clean(raw_value, self)) except ValidationError as e: errors[f.name] = e.error_list
if not clash_errors: errors.extend(cls._check_column_name_clashes()) errors.extend(cls._check_index_together()) errors.extend(cls._check_unique_together()) errors.extend(cls._check_ordering())
fields = (f for f in fields if isinstance(f.remote_field.model, ModelBase))
fields = (f for f in fields if isinstance(f.remote_field.through, ModelBase))
if fields and not fields[0].primary_key and cls._meta.pk.name == 'id': return [ checks.Error( "'id' can only be used as a field name if the field also " "sets 'primary_key=True'.", obj=cls, id='models.E004', ) ] else: return []
for parent in cls._meta.get_parent_list(): for f in parent._meta.local_fields: clash = used_fields.get(f.name) or used_fields.get(f.attname) or None if clash: errors.append( checks.Error( "The field '%s' from parent model " "'%s' clashes with the field '%s' " "from parent model '%s'." % ( clash.name, clash.model._meta, f.name, f.model._meta ), obj=cls, id='models.E005', ) ) used_fields[f.name] = f used_fields[f.attname] = f
for parent in cls._meta.get_parent_list(): for f in parent._meta.get_fields(): if f not in used_fields: used_fields[f.name] = f
id_conflict = f.name == "id" and clash and clash.name == "id" and clash.model == cls if clash and not id_conflict: errors.append( checks.Error( "The field '%s' clashes with the field '%s' " "from model '%s'." % ( f.name, clash.name, clash.model._meta ), obj=f, id='models.E006', ) ) used_fields[f.name] = f used_fields[f.attname] = f
used_column_names = [] errors = []
if column_name and column_name in used_column_names: errors.append( checks.Error( "Field '%s' has column name '%s' that is used by " "another field." % (f.name, column_name), hint="Specify a 'db_column' for the field.", obj=cls, id='models.E007' ) ) else: used_column_names.append(column_name)
forward_fields_map = { field.name: field for field in cls._meta._get_fields(reverse=False) }
fields = (f for f in fields if f != '?')
fields = ((f[1:] if f.startswith('-') else f) for f in fields)
fields = (f for f in fields if '__' not in f)
fields = {f for f in fields if f != 'pk'}
invalid_fields = []
opts = cls._meta valid_fields = set(chain.from_iterable( (f.name, f.attname) if not (f.auto_created and not f.concrete) else (f.field.related_query_name(),) for f in chain(opts.fields, opts.related_objects) ))
for db in settings.DATABASES.keys(): if not router.allow_migrate_model(db, cls): continue connection = connections[db] max_name_length = connection.ops.max_name_length() if max_name_length is None or connection.features.truncates_names: continue else: if allowed_len is None: allowed_len = max_name_length db_alias = db elif max_name_length < allowed_len: allowed_len = max_name_length db_alias = db
if f.db_column is None and column_name is not None and len(column_name) > allowed_len: errors.append( checks.Error( 'Autogenerated column name too long for field "%s". ' 'Maximum length is "%s" for database "%s".' % (column_name, allowed_len, db_alias), hint="Set the column name manually using 'db_column'.", obj=cls, id='models.E018', ) )
for m2m in f.remote_field.through._meta.local_fields: _, rel_name = m2m.get_attname_column() if m2m.db_column is None and rel_name is not None and len(rel_name) > allowed_len: errors.append( checks.Error( 'Autogenerated column name too long for M2M field ' '"%s". Maximum length is "%s" for database "%s".' % (rel_name, allowed_len, db_alias), hint=( "Use 'through' to create a separate model for " "M2M and then set column_name using 'db_column'." ), obj=cls, id='models.E019', ) )
with transaction.atomic(using=using, savepoint=False): for i, j in enumerate(id_list): ordered_obj.objects.filter(pk=j, **filter_args).update(_order=i)
model = model_id
exception = getattr(klass, exception_name) return exception.__new__(exception)
REPR_OUTPUT_SIZE = 20
EmptyResultSet = sql.EmptyResultSet
results = compiler.execute_sql() select, klass_info, annotation_col_map = (compiler.select, compiler.klass_info, compiler.annotation_col_map) if klass_info is None: return model_cls = klass_info['model'] select_fields = klass_info['select_fields'] model_fields_start, model_fields_end = select_fields[0], select_fields[-1] + 1 init_list = [f[0].target.attname for f in select[model_fields_start:model_fields_end]] related_populators = get_related_populators(klass_info, select, db) for row in compiler.results_iter(results): obj = model_cls.from_db(db, init_list, row[model_fields_start:model_fields_end]) if related_populators: for rel_populator in related_populators: rel_populator.populate(row, obj) if annotation_col_map: for attr_name, col_pos in annotation_col_map.items(): setattr(obj, attr_name, row[col_pos])
if queryset._known_related_objects: for field, rel_objs in queryset._known_related_objects.items(): if hasattr(obj, field.get_cache_name()): continue pk = getattr(obj, field.get_attname()) try: rel_obj = rel_objs[pk] except KeyError:
names = extra_names + field_names + annotation_names
names = extra_names + field_names + annotation_names
fields = list(queryset._fields) + [f for f in annotation_names if f not in queryset._fields]
from django.db.models.manager import Manager manager = Manager.from_queryset(cls)() manager._built_with_as_manager = True return manager
self._fetch_all() obj_dict = self.__dict__.copy() obj_dict[DJANGO_VERSION_PICKLE_KEY] = get_version() return obj_dict
try: arg.default_alias except (AttributeError, TypeError): raise TypeError("Complex aggregates require an alias") kwargs[arg.default_alias] = arg
assert batch_size is None or batch_size > 0 for parent in self.model._meta.get_parent_list(): if parent._meta.concrete_model is not self.model._meta.concrete_model: raise ValueError("Can't bulk create a multi-table inherited model") if not objs: return objs self._for_write = True connection = connections[self.db] fields = self.model._meta.concrete_fields objs = list(objs) self._populate_pk_values(objs) with transaction.atomic(using=self.db, savepoint=False): if (connection.features.can_combine_inserts_with_and_without_auto_increment_pk and self.model._meta.has_auto_field): self._batched_insert(objs, fields, batch_size) else: objs_with_pk, objs_without_pk = partition(lambda o: o.pk is None, objs) if objs_with_pk: self._batched_insert(objs_with_pk, fields, batch_size) if objs_without_pk: fields = [f for f in fields if not isinstance(f, AutoField)] ids = self._batched_insert(objs_without_pk, fields, batch_size) if connection.features.can_return_ids_from_bulk_insert: assert len(ids) == len(objs_without_pk) for i in range(len(ids)): objs_without_pk[i].pk = ids[i]
self._for_write = True try: return self.get(**lookup), False except self.model.DoesNotExist: return self._create_object_from_params(lookup, params)
del_query._for_write = True
del_query.query.select_for_update = False del_query.query.select_related = False del_query.query.clear_ordering(force_empty=True)
self._result_cache = None return deleted, _rows_count
prefetch_related_objects(self._result_cache, *self._prefetch_related_lookups) self._prefetch_done = True
field_names = list(fields)
try: if arg.default_alias in kwargs: raise ValueError("The named annotation '%s' conflicts with the " "default name for another annotation." % arg.default_alias) except (AttributeError, TypeError): raise TypeError("Complex annotations require an alias") annotations[arg.default_alias] = arg
raise TypeError("Cannot pass None as an argument to only().")
if len(self._fields or self.model._meta.concrete_fields) > 1: raise TypeError('Cannot use multi-field values as a filter value.')
foreign_fields = getattr(field, 'foreign_related_fields', ()) if len(foreign_fields) == 1 and not foreign_fields[0].primary_key: return self.values(foreign_fields[0].name)
if len(self._fields or self.model._meta.concrete_fields) > 1: raise TypeError('Cannot use multi-field values as a filter value.') clone = self._clone()
value_annotation = True
self._hints.update(hints)
if self._fields is not None: return True return check_rel_lookup_compatibility(self.model, opts, field)
db = self.db compiler = connections[db].ops.compiler('SQLCompiler')( self.query, connections[db], db )
skip = set() for field in self.model._meta.fields: if field.attname not in model_init_names: skip.add(field.attname) if skip: if self.model._meta.pk.attname in skip: raise InvalidQuery('Raw query must include the primary key') model_cls = self.model fields = [self.model_fields.get(c) for c in self.columns] converters = compiler.get_converters([ f.get_col(f.model._meta.db_table) if f else None for f in fields ]) for values in query: if converters: values = compiler.apply_converters(values, converters) model_init_values = [values[pos] for pos in model_init_pos] instance = model_cls.from_db(db, model_init_names, model_init_values) if annotation_fields: for column, pos in annotation_fields: setattr(instance, column, values[pos]) yield instance
if hasattr(self.query, 'cursor') and self.query.cursor: self.query.cursor.close()
for (query_name, model_name) in self.translations.items(): try: index = self._columns.index(query_name) self._columns[index] = model_name except ValueError: pass
self.prefetch_through = lookup self.prefetch_to = lookup if queryset is not None and queryset._iterable_class is not ModelIterable: raise ValueError('Prefetch querysets cannot use values().') if to_attr: self.prefetch_to = LOOKUP_SEP.join(lookup.split(LOOKUP_SEP)[:-1] + [to_attr])
obj_list = model_instances
if len(obj_list) == 0: break
obj_list = done_queries[prefetch_to] continue
good_objects = True for obj in obj_list: if not hasattr(obj, '_prefetched_objects_cache'): try: obj._prefetched_objects_cache = {} except (AttributeError, TypeError): good_objects = False break if not good_objects: break
first_obj = obj_list[0] to_attr = lookup.get_current_to_attr(level)[0] prefetcher, descriptor, attr_found, is_fetched = get_prefetcher(first_obj, through_attr, to_attr)
raise ValueError("'%s' does not resolve to an item that supports " "prefetching - this is an invalid parameter to " "prefetch_related()." % lookup.prefetch_through)
if not (lookup in auto_lookups and descriptor in followed_descriptors): done_queries[prefetch_to] = obj_list new_lookups = normalize_prefetch_lookups(additional_lookups, prefetch_to) auto_lookups.update(new_lookups) all_lookups.extendleft(new_lookups) followed_descriptors.add(descriptor)
new_obj_list = [] for obj in obj_list: try: new_obj = getattr(obj, through_attr) except exceptions.ObjectDoesNotExist: continue if new_obj is None: continue if isinstance(new_obj, list): new_obj_list.extend(new_obj) else: new_obj_list.append(new_obj) obj_list = new_obj_list
rel_obj_descriptor = getattr(instance.__class__, through_attr, None) if rel_obj_descriptor is None: attr_found = hasattr(instance, through_attr) else: attr_found = True if rel_obj_descriptor: if hasattr(rel_obj_descriptor, 'get_prefetch_queryset'): prefetcher = rel_obj_descriptor if rel_obj_descriptor.is_cached(instance): is_fetched = True else: rel_obj = getattr(instance, through_attr) if hasattr(rel_obj, 'get_prefetch_queryset'): prefetcher = rel_obj if through_attr != to_attr: is_fetched = hasattr(instance, to_attr) else: is_fetched = through_attr in instance._prefetched_objects_cache return prefetcher, rel_obj_descriptor, attr_found, is_fetched
additional_lookups = [ copy.copy(additional_lookup) for additional_lookup in getattr(rel_qs, '_prefetch_related_lookups', []) ] if additional_lookups: rel_qs._prefetch_related_lookups = []
if as_attr and instances: model = instances[0].__class__ try: model._meta.get_field(to_attr) except exceptions.FieldDoesNotExist: pass else: msg = 'to_attr={} conflicts with a field on the {} model.' raise ValueError(msg.format(to_attr, model.__name__))
leaf = len(lookup.prefetch_through.split(LOOKUP_SEP)) - 1 == level
qs._prefetch_done = True obj._prefetched_objects_cache[cache_name] = qs
select_fields = klass_info['select_fields'] from_parent = klass_info['from_parent'] if not from_parent: self.cols_start = select_fields[0] self.cols_end = select_fields[-1] + 1 self.init_list = [ f[0].target.attname for f in select[self.cols_start:self.cols_end] ] self.reorder_for_init = None else: model_init_attnames = [ f.attname for f in klass_info['model']._meta.concrete_fields ] reorder_map = [] for idx in select_fields: field = select[idx][0].target init_pos = model_init_attnames.index(field.attname) reorder_map.append((init_pos, field.attname, idx)) reorder_map.sort() self.init_list = [v[1] for v in reorder_map] pos_list = [row_pos for _, _, row_pos in reorder_map]
ADD = '+' SUB = '-' MUL = '*' DIV = '/' POW = '^' MOD = '%%'
BITAND = '&' BITOR = '|'
if isinstance(other, datetime.timedelta): other = DurationValue(other, output_field=fields.DurationField()) else: other = Value(other)
is_summary = False _output_field = None
return super(Expression, self).as_sql(compiler, connection)
expression_wrapper = '(%s)' sql = connection.ops.combine_expression(self.connector, expressions) return expression_wrapper % sql, expression_params
expression_wrapper = '(%s)' sql = connection.ops.combine_duration_expression(self.connector, expressions) return expression_wrapper % sql, expression_params
if function is not None: data['function'] = function else: data.setdefault('function', self.function) template = template or data.get('template', self.template) arg_joiner = arg_joiner or data.get('arg_joiner', self.arg_joiner) data['expressions'] = data['field'] = arg_joiner.join(sql_parts) return template % data, params
if self._output_field is not None: if self.for_save: val = self.output_field.get_db_prep_save(val, connection=connection) else: val = self.output_field.get_db_prep_value(val, connection=connection) if val is None: return 'NULL', [] return '%s', [val]
return self
return [self.result._output_field_or_none]
cols = [] for source in self.get_source_expressions(): cols.extend(source.get_group_by_cols()) return cols
AND = 'AND' OR = 'OR'
may_need_split = ( (in_negated and self.connector == AND) or (not in_negated and self.connector == OR)) if may_need_split and self.contains_aggregate: return None, self where_parts = [] having_parts = [] for c in self.children: if hasattr(c, 'split_having'): where_part, having_part = c.split_having(in_negated) if where_part is not None: where_parts.append(where_part) if having_part is not None: having_parts.append(having_part) elif c.contains_aggregate: having_parts.append(c) else: where_parts.append(c) having_node = self.__class__(having_parts, self.connector, self.negated) if having_parts else None where_node = self.__class__(where_parts, self.connector, self.negated) if where_parts else None return where_node, having_node
if empty_needed == 0: if self.negated: return '', [] else: raise EmptyResultSet if full_needed == 0: if self.negated: raise EmptyResultSet else: return '', []
sql_string = 'NOT (%s)' % sql_string
child.relabel_aliases(change_map)
contains_aggregate = False
contains_aggregate = False
if hasattr(query, 'values'): if query._db and connection.alias != query._db: raise ValueError("Can't do subqueries with queries on different DBs.") if query._fields is None: query = query.values(*self.targets) else: query = query._clone() query = query.query if query.can_filter(): query.clear_ordering(True)
QUERY_TERMS = { 'exact', 'iexact', 'contains', 'icontains', 'gt', 'gte', 'lt', 'lte', 'in', 'startswith', 'istartswith', 'endswith', 'iendswith', 'range', 'year', 'month', 'day', 'week_day', 'hour', 'minute', 'second', 'isnull', 'search', 'regex', 'iregex', }
GET_ITERATOR_CHUNK_SIZE = 100
MULTI = 'multi' SINGLE = 'single' CURSOR = 'cursor' NO_RESULTS = 'no results'
INNER = 'INNER JOIN' LOUTER = 'LEFT OUTER JOIN'
self.names_with_path = path_with_names
self.table_name = table_name self.parent_alias = parent_alias self.table_alias = table_alias self.join_type = join_type self.join_cols = join_field.get_joining_columns() self.join_field = join_field self.nullable = nullable
for index, (lhs_col, rhs_col) in enumerate(self.join_cols): join_conditions.append('%s.%s = %s.%s' % ( qn(self.parent_alias), qn2(lhs_col), qn(self.table_alias), qn2(rhs_col), ))
extra_cond = self.join_field.get_extra_restriction( compiler.query.where_class, self.table_alias, self.parent_alias) if extra_cond: extra_sql, extra_params = compiler.compile(extra_cond) join_conditions.append('(%s)' % extra_sql) params.extend(extra_params)
declared_field = getattr(self.join_field, 'field', self.join_field) raise ValueError( "Join generated an empty ON clause. %s did not yield either " "joining columns or extra restrictions." % declared_field.__class__ )
self._execute_query() if not connections[self.using].features.can_use_chunked_reads: result = list(self.cursor) else: result = self.cursor return iter(result)
params_type = self.params_type adapter = connection.ops.adapt_unknown_value if params_type is tuple: params = tuple(adapter(val) for val in self.params) elif params_type is dict: params = dict((key, adapter(val)) for key, val in six.iteritems(self.params)) else: raise RuntimeError("Unexpected params type: %s" % params_type)
self.alias_map = {} self.external_aliases = set()
self.select = []
self.group_by = None self.order_by = []
self.max_depth = 5
self.values_select = []
self.deferred_loading = (set(), True)
obj._annotation_select_cache = None obj.max_depth = self.max_depth obj._extra = self._extra.copy() if self._extra is not None else None if self.extra_select_mask is None: obj.extra_select_mask = None else: obj.extra_select_mask = self.extra_select_mask.copy() if self._extra_select_cache is None: obj._extra_select_cache = None else: obj._extra_select_cache = self._extra_select_cache.copy() obj.extra_tables = self.extra_tables obj.extra_order_by = self.extra_order_by obj.deferred_loading = copy.copy(self.deferred_loading[0]), self.deferred_loading[1] if self.filter_is_sticky and self.used_aliases: obj.used_aliases = self.used_aliases.copy() else: obj.used_aliases = set() obj.filter_is_sticky = False if 'alias_prefix' in self.__dict__: obj.alias_prefix = self.alias_prefix if 'subq_aliases' in self.__dict__: obj.subq_aliases = self.subq_aliases.copy()
orig_exprs = annotation.get_source_expressions() new_exprs = [] for expr in orig_exprs: if isinstance(expr, Ref): new_exprs.append(expr) elif isinstance(expr, Col): col_cnt += 1 col_alias = '__col%d' % col_cnt self.annotations[col_alias] = expr self.append_annotation_mask([col_alias]) new_exprs.append(Ref(col_alias, expr)) else: new_expr, col_cnt = self.rewrite_cols(expr, col_cnt) new_exprs.append(new_expr) annotation.set_source_expressions(new_exprs) return annotation, col_cnt
if (isinstance(self.group_by, list) or has_limit or has_existing_annotations or self.distinct): from django.db.models.sql.subqueries import AggregateQuery outer_query = AggregateQuery(self.model) inner_query = self.clone() inner_query.select_for_update = False inner_query.select_related = False if not has_limit and not self.distinct_fields: inner_query.clear_ordering(True) if not inner_query.distinct: if inner_query.default_cols and has_existing_annotations: inner_query.group_by = [self.model._meta.pk.get_col(inner_query.get_initial_alias())] inner_query.default_cols = False
col_cnt = 0 for alias, expression in list(inner_query.annotation_select.items()): if expression.is_summary: expression, col_cnt = inner_query.rewrite_cols(expression, col_cnt) outer_query.annotations[alias] = expression.relabeled_clone(relabels) del inner_query.annotations[alias] inner_query.set_annotation_mask(inner_query.annotation_select_mask) if inner_query.select == [] and not inner_query.default_cols and not inner_query.annotation_select_mask: inner_query.select = [self.model._meta.pk.get_col(inner_query.get_initial_alias())] try: outer_query.add_subquery(inner_query, using) except EmptyResultSet: return { alias: None for alias in outer_query.annotation_select }
change_map = {} conjunction = (connector == AND)
reuse = set() if conjunction else set(self.tables) self.get_initial_alias() joinpromoter = JoinPromoter(connector, 2, False) joinpromoter.add_votes( j for j in self.alias_map if self.alias_map[j].join_type == INNER) rhs_votes = set() for alias in rhs.tables[1:]: join = rhs.alias_map[alias] join = join.relabeled_clone(change_map) new_alias = self.join(join, reuse=reuse) if join.join_type == INNER: rhs_votes.add(new_alias) reuse.discard(new_alias) if alias != new_alias: change_map[alias] = new_alias if not rhs.alias_refcount[alias]: self.unref_alias(new_alias) joinpromoter.add_votes(rhs_votes) joinpromoter.update_join_types(self)
w = rhs.where.clone() w.relabel_aliases(change_map) self.where.add(w, connector)
self.select = [] for col in rhs.select: self.add_select(col.relabeled_clone(change_map))
if self._extra and rhs._extra: raise ValueError("When merging querysets using 'or', you cannot have extra(select=...) on both sides.")
self.order_by = rhs.order_by[:] if rhs.order_by else self.order_by self.extra_order_by = rhs.extra_order_by or self.extra_order_by
if not is_reverse_o2o(source): must_include[old_model].add(source) add_to_dict(must_include, cur_model, opts.pk)
workset = {} for model, values in six.iteritems(seen): for field in model._meta.fields: if field in values: continue m = field.model._meta.concrete_model add_to_dict(workset, m, field) for model, values in six.iteritems(must_include): if model in workset: workset[model].update(values) for model, values in six.iteritems(workset): callback(target, model, values)
seen[model] = values
if alias_list: alias = '%s%d' % (self.alias_prefix, len(self.alias_map) + 1) alias_list.append(alias) else: alias = table_name self.table_map[alias] = [alias] self.alias_refcount[alias] = 1 self.tables.append(alias) return alias, True
continue
aliases.extend( join for join in self.alias_map.keys() if self.alias_map[join].parent_alias == alias and join not in aliases )
self.where.relabel_aliases(change_map) if isinstance(self.group_by, list): self.group_by = [relabel_column(col) for col in self.group_by] self.select = [col.relabeled_clone(change_map) for col in self.select] if self._annotations: self._annotations = OrderedDict( (key, relabel_column(col)) for key, col in self._annotations.items())
for old_alias, new_alias in six.iteritems(change_map): if old_alias not in self.alias_map: continue alias_data = self.alias_map[old_alias].relabeled_clone(change_map) self.alias_map[new_alias] = alias_data self.alias_refcount[new_alias] = self.alias_refcount[old_alias] del self.alias_refcount[old_alias] del self.alias_map[old_alias]
return
alias, _ = self.table_alias(join.table_name, create=True) if join.join_type: if self.alias_map[join.parent_alias].join_type == LOUTER or join.nullable: join_type = LOUTER else: join_type = INNER join.join_type = join_type join.table_alias = alias self.alias_map[alias] = join return alias
if not curr_opts.parents[int_model]: curr_opts = int_model._meta continue link_field = curr_opts.get_ancestor_link(int_model) _, _, _, joins, _ = self.setup_joins( [link_field.name], curr_opts, alias) curr_opts = int_model._meta alias = seen[int_model] = joins[-1]
used_joins = [] if len(lookups) == 0: lookups = ['exact'] if value is None: if lookups[-1] not in ('exact', 'iexact'): raise ValueError("Cannot use None as a query value") lookups[-1] = 'isnull' value = True elif hasattr(value, 'resolve_expression'): pre_joins = self.alias_refcount.copy() value = value.resolve_expression(self, reuse=can_reuse, allow_joins=allow_joins) used_joins = [k for k, v in self.alias_refcount.items() if v > pre_joins.get(k, 0)] if hasattr(value, 'query') and hasattr(value.query, 'bump_prefix'): value = value._clone() value.query.bump_prefix(self) if hasattr(value, 'bump_prefix'): value = value.clone() value.bump_prefix(self) if (connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls and lookups[-1] == 'exact' and value == ''): value = True lookups[-1] = 'isnull' return value, lookups, used_joins
if hasattr(value, 'is_compatible_query_object_type'): if not value.is_compatible_query_object_type(opts, field): raise ValueError( 'Cannot use QuerySet for "%s": Use a QuerySet for "%s".' % (value.model._meta.model_name, opts.object_name) ) elif hasattr(value, '_meta'): self.check_query_object_type(value, opts, field) elif hasattr(value, '__iter__'): for v in value: self.check_query_object_type(v, opts, field)
if len(lookups) == 1: final_lookup = lhs.get_lookup(name) if not final_lookup: lhs = self.try_transform(lhs, name, lookups) final_lookup = lhs.get_lookup('exact') return final_lookup(lhs, rhs) lhs = self.try_transform(lhs, name, lookups) lookups = lookups[1:]
value, lookups, used_joins = self.prepare_lookup_value(value, lookups, can_reuse, allow_joins)
if isinstance(value, Iterator): value = list(value) self.check_related_objects(field, value, opts)
self._lookup_joins = join_list
num_lookups = len(lookups) if num_lookups > 1: raise FieldError('Related Field got invalid lookup: {}'.format(lookups[0]))
lookup_class = targets[0].get_lookup('isnull') clause.add(lookup_class(targets[0].get_col(alias, sources[0]), False), AND)
existing_inner = set( (a for a in self.alias_map if self.alias_map[a].join_type == INNER)) clause, _ = self._add_q(q_object, self.used_aliases) if clause: self.where.add(clause, AND) self.demote_joins(existing_inner)
if field.is_relation and not field.related_model: raise FieldError( "Field %r does not generate an automatic reverse " "relation and therefore cannot be used for reverse " "querying. If it is a GenericForeignKey, consider " "adding a GenericRelation." % name ) try: model = field.model._meta.concrete_model except AttributeError: model = None
pos -= 1 if pos == -1 or fail_on_missing: field_names = list(get_field_names_from_opts(opts)) available = sorted(field_names + list(self.annotation_select)) raise FieldError("Cannot resolve keyword %r into field. " "Choices are: %s" % (name, ", ".join(available))) break
proxied_model = opts.concrete_model
final_field = field targets = (field,) if fail_on_missing and pos + 1 != len(names): raise FieldError( "Cannot resolve keyword %r into field. Join on '%s'" " not permitted." % (names[pos + 1], name)) break
path, final_field, targets, rest = self.names_to_path( names, opts, allow_many, fail_on_missing=True)
for join in path: opts = join.to_opts if join.direct: nullable = self.is_nullable(join.join_field) else: nullable = True connection = Join(opts.db_table, alias, None, INNER, join.join_field, nullable) reuse = can_reuse if join.m2m else None alias = self.join(connection, reuse=reuse) joins.append(alias) return final_field, targets, opts, joins, path
return Ref(name, self.annotation_select[name])
query = Query(self.model) query.add_filter(filter_expr) query.clear_ordering(True) trimmed_prefix, contains_louter = query.trim_start(names_with_path)
col = query.select[0] select_field = col.target alias = col.alias if self.is_nullable(select_field): lookup_class = select_field.get_lookup('isnull') lookup = lookup_class(select_field.get_col(alias), False) query.where.add(lookup, AND) if alias in can_reuse: pk = select_field.model._meta.pk query.bump_prefix(self) lookup_class = select_field.get_lookup('exact') lookup = lookup_class(pk.get_col(query.select[0].alias), pk.get_col(alias)) query.where.add(lookup, AND) query.external_aliases.add(alias)
return condition, needed_inner
_, targets, _, joins, path = self.setup_joins( name.split(LOOKUP_SEP), opts, alias, allow_many=allow_m2m) targets, final_alias, joins = self.trim_joins(targets, joins, path) for target in targets: self.add_select(target.get_col(final_alias))
raise
select_pairs = OrderedDict() if select_params: param_iter = iter(select_params) else: param_iter = iter([]) for name, entry in select.items(): entry = force_text(entry) entry_params = [] pos = entry.find("%s") while pos != -1: if pos == 0 or entry[pos - 1] != '%': entry_params.append(next(param_iter)) pos = entry.find("%s", pos + 2) select_pairs[name] = (entry, entry_params) self.extra.update(select_pairs)
existing, defer = self.deferred_loading if defer: self.deferred_loading = existing.union(field_names), True else: self.deferred_loading = existing.difference(field_names), False
self.deferred_loading = field_names.difference(existing), False
self.deferred_loading = field_names, False
try: return self._loaded_field_names_cache except AttributeError: collection = {} self.deferred_to_data(collection, self.get_loaded_field_names_cb) self._loaded_field_names_cache = collection return collection
lookup_tables = [t for t in self.tables if t in self._lookup_joins or t == self.tables[0]] for trimmed_paths, path in enumerate(all_paths): if path.m2m: break if self.alias_map[lookup_tables[trimmed_paths + 1]].join_type == LOUTER: contains_louter = True alias = lookup_tables[trimmed_paths] self.unref_alias(alias) join_field = path.join_field.field paths_in_prefix = trimmed_paths trimmed_prefix = [] for name, path in names_with_path: if paths_in_prefix - len(path) < 0: break trimmed_prefix.append(name) paths_in_prefix -= len(path) trimmed_prefix.append( join_field.foreign_related_fields[0].name) trimmed_prefix = LOOKUP_SEP.join(trimmed_prefix) if self.alias_map[lookup_tables[trimmed_paths + 1]].join_type != LOUTER: select_fields = [r[0] for r in join_field.related_fields] select_alias = lookup_tables[trimmed_paths + 1] self.unref_alias(lookup_tables[trimmed_paths]) extra_restriction = join_field.get_extra_restriction( self.where_class, None, lookup_tables[trimmed_paths + 1]) if extra_restriction: self.where.add(extra_restriction, AND) else: select_fields = [r[1] for r in join_field.related_fields] select_alias = lookup_tables[trimmed_paths] for table in self.tables: if self.alias_refcount[table] > 0: self.alias_map[table] = BaseTable(self.alias_map[table].table_name, table) break self.set_select([f.get_col(select_alias) for f in select_fields]) return trimmed_prefix, contains_louter
if connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls and field.empty_strings_allowed: return True else: return field.null
self.votes = Counter()
for table, votes in self.votes.items(): if self.effective_connector == 'OR' and votes < self.num_children: to_promote.add(table) if self.effective_connector == 'AND' or ( self.effective_connector == 'OR' and votes == self.num_children): to_demote.add(table) query.promote_joins(to_promote) query.demote_joins(to_demote) return to_demote
self.select = None self.annotation_col_map = None self.klass_info = None self.ordering_parts = re.compile(r'(.*)\s(ASC|DESC)(.*)') self.subquery = False
if self.query.group_by is None: return [] expressions = [] if self.query.group_by is not True: for expr in self.query.group_by: if not hasattr(expr, 'as_sql'): expressions.append(self.query.resolve_ref(expr)) else: expressions.append(expr) for expr, _, _ in select: cols = expr.get_group_by_cols() for col in cols: expressions.append(col) for expr, (sql, params, is_ref) in order_by: if expr.contains_aggregate: continue if is_ref: continue expressions.extend(expr.get_source_expressions()) having_group_by = self.having.get_group_by_cols() if self.having else () for expr in having_group_by: expressions.append(expr) result = [] seen = set() expressions = self.collapse_group_by(expressions, having_group_by)
if self.connection.features.allows_group_by_pk: pk = None for expr in expressions: if (getattr(expr, 'target', None) == self.query.model._meta.pk and getattr(expr, 'alias', None) == self.query.tables[0]): pk = expr break if pk: expressions = [pk] + [expr for expr in expressions if expr in having] elif self.connection.features.allows_group_by_selected_pks: pks = {expr for expr in expressions if hasattr(expr, 'target') and expr.target.primary_key} aliases = {expr.alias for expr in pks} expressions = [ expr for expr in expressions if expr in pks or getattr(expr, 'alias', None) not in aliases ] return expressions
for col in self.query.select: select.append((col, None)) select_idx += 1 for alias, annotation in self.query.annotation_select.items(): annotations[alias] = select_idx select.append((annotation, alias)) select_idx += 1
order_by.append(( OrderBy(Ref(col, self.query.annotation_select[col]), descending=descending), True)) continue
order_by.append(( OrderBy(self.query.annotations[col], descending=descending), False)) continue
table, col = col.split('.', 1) order_by.append(( OrderBy( RawSQL('%s.%s' % (self.quote_name_unless_alias(table), col), []), descending=descending ), False)) continue
order_by.extend(self.find_ordering_name( field, self.query.get_meta(), default_order=asc))
without_ordering = self.ordering_parts.search(sql).group(1) if (without_ordering, tuple(params)) in seen: continue seen.add((without_ordering, tuple(params))) result.append((resolved, (sql, params, is_ref)))
from_, f_params = self.get_from_clause()
nowait = self.query.select_for_update_nowait if nowait and not self.connection.features.has_select_for_update_nowait: raise DatabaseError('NOWAIT is not supported on this database backend.') result.append(self.connection.ops.for_update_sql(nowait=nowait))
self.query.reset_refcounts(refcounts_before)
obj.clear_ordering(True)
seen_models = {None: start_alias}
if model == opts.model: model = None if from_parent and model is not None and issubclass( from_parent._meta.concrete_model, model._meta.concrete_model): continue if field.model in only_load and field.attname not in only_load[field.model]: continue alias = self.query.join_parent_model(opts, model, start_alias, seen_models) column = field.get_col(alias) result.append(column)
if field.is_relation and opts.ordering and getattr(field, 'attname', None) != name: if not already_seen: already_seen = set() join_tuple = tuple(getattr(self.query.alias_map[j], 'join_cols', None) for j in joins) if join_tuple in already_seen: raise FieldError('Infinite loop caused by ordering.') already_seen.add(join_tuple)
continue
if alias not in self.query.alias_map or self.query.alias_refcount[alias] == 1: result.append(', %s' % self.quote_name_unless_alias(alias))
return related_klass_infos
fields_found = set() if requested is None: if isinstance(self.query.select_related, dict): requested = self.query.select_related restricted = True else: restricted = False
if next or f.name in requested: raise FieldError( "Non-relational field given in select_related: '%s'. " "Choices are: %s" % ( f.name, ", ".join(_get_field_choices()) or '(none)', ) )
self.query.add_extra({'a': 1}, None, None, None, None, None) self.query.set_extra_mask(['a']) return bool(self.execute_sql(SINGLE))
return cursor
cursor.close()
return list(result)
cursor.close()
sql, params = val, []
sql, params = self.compile(val)
sql, params = field.get_placeholder(val, self, self.connection), [val]
sql, params = '%s', [val]
params = self.connection.ops.modify_insert_params(sql, params)
if value.contains_column_references: raise ValueError( 'Failed to insert expression "%s" on %s. F() expressions ' 'can only be used to update, not to insert.' % (value, field) ) if value.contains_aggregate: raise FieldError("Aggregate functions are not allowed in this query")
rows_of_fields_as_sql = ( (self.field_as_sql(field, v) for field, v in zip(fields, row)) for row in value_rows )
sql_and_param_pair_rows = (zip(*row) for row in rows_of_fields_as_sql)
placeholder_rows, param_rows = zip(*sql_and_param_pair_rows)
param_rows = [[p for ps in row for p in ps] for row in param_rows]
qn = self.connection.ops.quote_name opts = self.query.get_meta() result = ['INSERT INTO %s' % qn(opts.db_table)]
value_rows = [[self.connection.ops.pk_default_value()] for _ in self.query.objs] fields = [None]
can_bulk = (not self.return_id and self.connection.features.has_bulk_insert)
if r_fmt: result.append(r_fmt % col) params += [r_params] return [(" ".join(result), tuple(chain.from_iterable(params)))]
if hasattr(field, 'get_placeholder'): placeholder = field.get_placeholder(val, self, self.connection) else: placeholder = '%s' name = field.column if hasattr(val, 'as_sql'): sql, params = self.compile(val) values.append('%s = %s' % (qn(name), sql)) update_params.extend(params) elif val is not None: values.append('%s = %s' % (qn(name), placeholder)) update_params.append(val) else: values.append('%s = NULL' % qn(name))
self.query.get_initial_alias() count = self.query.count_active_tables() if not self.query.related_updates and count == 1: return query = self.query.clone(klass=Query) query.select_related = False query.clear_ordering(True) query._extra = {} query.select = [] query.add_fields([query.get_meta().pk.name]) super(SQLUpdateCompiler, self).pre_sql_setup()
self.query.where = self.query.where_class() if self.query.related_updates or must_pre_select: idents = [] for rows in query.get_compiler(self.using).execute_sql(MULTI): idents.extend(r[0] for r in rows) self.query.add_filter(('pk__in', idents)) self.query.related_ids = idents else: self.query.add_filter(('pk__in', query)) self.query.reset_refcounts(refcounts_before)
if not self.query.subquery: raise EmptyResultSet sql, params = [], [] for annotation in self.query.annotation_select.values(): ann_sql, ann_params = self.compile(annotation, select_format=True) sql.append(ann_sql) params.extend(ann_params) self.col_count = len(self.query.annotation_select) sql = ', '.join(sql) params = tuple(params)
num_deleted = 0 if not field: field = self.get_meta().pk for offset in range(0, len(pk_list), GET_ITERATOR_CHUNK_SIZE): self.where = self.where_class() self.add_q(Q( **{field.attname + '__in': pk_list[offset:offset + GET_ITERATOR_CHUNK_SIZE]})) num_deleted += self.do_query(self.get_meta().db_table, self.where, using=using) return num_deleted
innerq.get_initial_alias() self.get_initial_alias() innerq_used_tables = [t for t in innerq.tables if innerq.alias_refcount[t]] if not innerq_used_tables or innerq_used_tables == self.tables: self.where = innerq.where else: pk = query.model._meta.pk if not connections[using].features.update_can_self_select: values = list(query.values_list('pk', flat=True)) if not values: return 0 return self.delete_batch(values, using) else: innerq.clear_select_clause() innerq.select = [ pk.get_col(self.get_initial_alias()) ] values = innerq self.where = self.where_class() self.add_q(Q(pk__in=values)) cursor = self.get_compiler(using).execute_sql(CURSOR) return cursor.rowcount if cursor else 0
c = super(Aggregate, self).resolve_expression(query, allow_joins, reuse, summarize) if not summarize: expressions = c.get_source_expressions() for index, expr in enumerate(expressions): if expr.contains_aggregate: before_resolved = self.get_source_expressions()[index] name = before_resolved.name if hasattr(before_resolved, 'name') else repr(before_resolved) raise FieldError("Cannot compute %s('%s'): '%s' is an aggregate" % (c.name, name, name)) return c
return tuple(tuple(ot) for ot in option_together)
return option_together
self.proxy_for_model = None self.concrete_model = None self.swappable = None self.parents = OrderedDict() self.auto_created = False
self.related_fkey_lookups = []
self.apps = self.default_apps
return self.apps.app_configs.get(self.app_label)
self.object_name = cls.__name__ self.model_name = self.object_name.lower() self.verbose_name = camel_case_to_spaces(self.object_name)
self.original_attrs = {}
if self.meta: meta_attrs = self.meta.__dict__.copy() for name in self.meta.__dict__: if name.startswith('_'): del meta_attrs[name] for attr_name in DEFAULT_NAMES: if attr_name in meta_attrs: setattr(self, attr_name, meta_attrs.pop(attr_name)) self.original_attrs[attr_name] = getattr(self, attr_name) elif hasattr(self.meta, attr_name): setattr(self, attr_name, getattr(self.meta, attr_name)) self.original_attrs[attr_name] = getattr(self, attr_name)
if self.verbose_name_plural is None: self.verbose_name_plural = string_concat(self.verbose_name, 's')
self._ordering_clash = bool(self.ordering and self.order_with_respect_to)
if meta_attrs != {}: raise TypeError("'class Meta' got invalid attribute(s): %s" % ','.join(meta_attrs.keys()))
if not self.db_table: self.db_table = "%s_%s" % (self.app_label, self.model_name) self.db_table = truncate_name(self.db_table, connection.ops.max_name_length())
query = self.order_with_respect_to try: self.order_with_respect_to = next( f for f in self._get_fields(reverse=False) if f.name == query or f.attname == query ) except StopIteration: raise FieldDoesNotExist('%s has no field named %r' % (self.object_name, query))
field = next(six.itervalues(self.parents)) already_created = [fld for fld in self.local_fields if fld.name == field.name] if already_created: field = already_created[0] field.primary_key = True self.setup_pk(field) if not field.remote_field.parent_link: warnings.warn( 'Add parent_link=True to %s as an implicit link is ' 'deprecated.' % field, RemovedInDjango20Warning )
if private: self.private_fields.append(field) elif field.is_relation and field.many_to_many: self.local_many_to_many.insert(bisect(self.local_many_to_many, field), field) else: self.local_fields.insert(bisect(self.local_fields, field), field) self.setup_pk(field)
if field.is_relation and hasattr(field.remote_field, 'model') and field.remote_field.model: try: field.remote_field.model._meta._expire_cache(forward=False) except AttributeError: pass self._expire_cache() else: self._expire_cache(reverse=False)
return swapped_for
manager._originating_model = base
for parent in self.model.mro()[1:]: if hasattr(parent, '_meta'): if parent._base_manager.name != '_base_manager': base_manager_name = parent._base_manager.name break
for i, base_manager_class in enumerate(self.default_manager.__class__.mro()): if getattr(base_manager_class, 'use_for_related_fields', False): if not getattr(base_manager_class, 'silence_use_for_related_fields_deprecation', False): warnings.warn( "use_for_related_fields is deprecated, instead " "set Meta.base_manager_name on '{}'.".format(self.model._meta.label), RemovedInDjango20Warning, 2 )
for parent in self.model.mro()[1:]: if hasattr(parent, '_meta'): default_manager_name = parent._meta.default_manager_name break
def is_not_an_m2m_field(f): return not (f.is_relation and f.many_to_many)
try: res[field.attname] = field except AttributeError: pass
try: res[field.attname] = field except AttributeError: pass
return self._forward_fields_map[field_name]
if not self.apps.models_ready: raise FieldDoesNotExist( "%s has no field named %r. The app cache isn't ready yet, " "so if this is an auto-created related field, it won't " "be available yet." % (self.object_name, field_name) )
return self.fields_map[field_name]
parent_link = parent._meta.get_ancestor_link(ancestor) if parent_link: return self.parents[parent] or parent_link
if opts.abstract: continue fields_with_relations = ( f for f in opts._get_fields(reverse=False, include_parents=False) if f.is_relation and f.related_model is not None ) for f in fields_with_relations: if not isinstance(f.remote_field.model, six.string_types): related_objects_graph[f.remote_field.model._meta.concrete_model._meta].append(f)
related_objects = related_objects_graph[model._meta.concrete_model._meta] model._meta.__dict__['_relation_tree'] = related_objects
if forward: for cache_key in self.FORWARD_PROPERTIES: if cache_key in self.__dict__: delattr(self, cache_key) if reverse and not self.abstract: for cache_key in self.REVERSE_PROPERTIES: if cache_key in self.__dict__: delattr(self, cache_key) self._get_fields_cache = {}
topmost_call = False if seen_models is None: seen_models = set() topmost_call = True seen_models.add(self.model)
cache_key = (forward, reverse, include_parents, include_hidden, topmost_call)
return self._get_fields_cache[cache_key]
if include_parents is not False: for parent in self.parents: if parent in seen_models: continue if (parent._meta.concrete_model != self.concrete_model and include_parents == PROXY_PARENTS): continue for obj in parent._meta._get_fields( forward=forward, reverse=reverse, include_parents=include_parents, include_hidden=include_hidden, seen_models=seen_models): if getattr(obj, 'parent_link', False) and obj.model != self.concrete_model: continue fields.append(obj) if reverse and not self.proxy: all_fields = self._relation_tree for field in all_fields: if include_hidden or not field.remote_field.hidden: fields.append(field.remote_field)
if topmost_call: fields.extend( f for f in self.private_fields )
fields = make_immutable_fields_list("get_fields()", fields)
self._get_fields_cache[cache_key] = fields return fields
creation_counter = 0
auto_created = False
obj = super(BaseManager, cls).__new__(cls) obj._constructor_args = (args, kwargs) return obj
return (
module = import_module(module_name) if not hasattr(module, name): raise ValueError( "Could not find manager %s in %s.\n" "Please note that you need to inherit from managers you " "dynamically generated with 'from_queryset()'." % (name, module_name) ) return (
predicate = inspect.isfunction if six.PY3 else inspect.ismethod for name, method in inspect.getmembers(queryset_class, predicate=predicate): if hasattr(cls, name): continue queryset_only = getattr(method, 'queryset_only', None) if queryset_only or (queryset_only is None and name.startswith('_')): continue new_methods[name] = create_method(name, method) return new_methods
return self.get_queryset()
from django.db.models.query import QuerySet if isinstance(rhs, QuerySet): raise NotImplementedError("Bilateral transformations on nested querysets are not supported.")
value = Value(value, output_field=self.lhs.output_field)
if hasattr(value, 'get_compiler'): value = value.get_compiler(connection=connection) if hasattr(value, 'as_sql'): sql, params = compiler.compile(value) return '(' + sql + ')', params if hasattr(value, '_as_sql'): sql, params = value._as_sql(connection=connection) return '(' + sql + ')', params else: return self.get_db_prep_lookup(value, connection)
field = getattr(self.lhs.output_field, 'field', None) get_db_prep_value = getattr(field, 'get_db_prep_value', None) if not get_db_prep_value: get_db_prep_value = self.lhs.output_field.get_db_prep_value return ( '%s', [get_db_prep_value(v, connection, prepared=True) for v in value] if self.get_db_prep_lookup_value_is_iterable else [get_db_prep_value(value, connection, prepared=True)] )
sqls, sqls_params = self.batch_process_rhs(compiler, connection, rhs) placeholder = '(' + ', '.join(sqls) + ')' return (placeholder, sqls_params)
max_in_list_size = connection.ops.max_in_list_size() lhs, lhs_params = self.process_lhs(compiler, connection) rhs, rhs_params = self.batch_process_rhs(compiler, connection) in_clause_elements = ['('] params = [] for offset in range(0, len(rhs_params), max_in_list_size): if offset > 0: in_clause_elements.append(' OR ') in_clause_elements.append('%s IN (' % lhs) params.extend(lhs_params) sqls = rhs[offset: offset + max_in_list_size] sqls_params = rhs_params[offset: offset + max_in_list_size] param_group = ', '.join(sqls) in_clause_elements.append(param_group) in_clause_elements.append(')') params.extend(sqls_params) in_clause_elements.append(')') return ''.join(in_clause_elements), params
if (hasattr(self.rhs, 'get_compiler') or hasattr(self.rhs, 'as_sql') or hasattr(self.rhs, '_as_sql') or self.bilateral_transforms): pattern = connection.pattern_ops[self.lookup_name].format(connection.pattern_esc) return pattern.format(rhs) else: return super(PatternLookup, self).get_rhs_op(connection, rhs)
return self.batch_process_rhs(compiler, connection)
lhs_sql, params = self.process_lhs(compiler, connection, self.lhs.lhs) rhs_sql, rhs_params = self.process_rhs(compiler, connection) rhs_sql = self.get_rhs_op(connection, rhs_sql) start, finish = self.year_lookup_bounds(connection, rhs_params[0]) params.append(self.get_bound(start, finish)) return '%s %s' % (lhs_sql, rhs_sql), params
lhs_sql, params = self.process_lhs(compiler, connection, self.lhs.lhs) rhs_sql, rhs_params = self.process_rhs(compiler, connection) try: int(rhs_params[0]) except (IndexError, TypeError, ValueError): return super(Exact, self).as_sql(compiler, connection) bounds = self.year_lookup_bounds(connection, rhs_params[0]) params.extend(bounds) return '%s BETWEEN %%s AND %%s' % lhs_sql, params
return ( f for f in opts.get_fields(include_hidden=True) if f.auto_created and not f.concrete and (f.one_to_one or f.one_to_many) )
self.data = OrderedDict()
self.fast_deletes = []
if source is not None and not nullable: if reverse_dependency: source, model = model, source self.dependencies.setdefault( source._meta.concrete_model, set()).add(model._meta.concrete_model) return new_objs
opts = model._meta if any(link != from_field for link in opts.concrete_model._meta.parents.values()): return False for related in get_candidate_relations_to_delete(opts): if related.field.remote_field.on_delete is not DO_NOTHING: return False for field in model._meta.private_fields: if hasattr(field, 'bulk_related_objects'): return False return True
concrete_model = model._meta.concrete_model for ptr in six.itervalues(concrete_model._meta.parents): if ptr: parent_objs = [getattr(obj, ptr.name) for obj in new_objs] self.collect(parent_objs, source=model, source_attr=ptr.remote_field.related_name, collect_related=False, reverse_dependency=True)
sub_objs = field.bulk_related_objects(new_objs, self.using) self.collect(sub_objs, source=model, nullable=True)
for model, instances in self.data.items(): self.data[model] = sorted(instances, key=attrgetter("pk"))
self.sort() deleted_counter = Counter()
for model, obj in self.instances_with_model(): if not model._meta.auto_created: signals.pre_delete.send( sender=model, instance=obj, using=self.using )
for qs in self.fast_deletes: count = qs._raw_delete(using=self.using) deleted_counter[qs.model._meta.label] += count
for model, instances_for_fieldvalues in six.iteritems(self.field_updates): query = sql.UpdateQuery(model) for (field, value), instances in six.iteritems(instances_for_fieldvalues): query.update_batch([obj.pk for obj in instances], {field.name: value}, self.using)
for instances in six.itervalues(self.data): instances.reverse()
for model, instances in six.iteritems(self.data): query = sql.DeleteQuery(model) pk_list = [obj.pk for obj in instances] count = query.delete_batch(pk_list, self.using) deleted_counter[model._meta.label] += count
for model, instances_for_fieldvalues in six.iteritems(self.field_updates): for (field, value), instances in six.iteritems(instances_for_fieldvalues): for obj in instances: setattr(obj, field.attname, value) for model, instances in six.iteritems(self.data): for instance in instances: setattr(instance, model._meta.pk.attname, None) return sum(deleted_counter.values()), dict(deleted_counter)
if getattr(field, 'remote_field', None) is None: field_type = field.db_type(connection)
if field_type is None: return errors
rows = list(cursor.fetchall()) multicol_indexes = set() for row in rows: if row[3] > 1: multicol_indexes.add(row[2]) indexes = {} for row in rows: if row[2] in multicol_indexes: continue if row[4] not in indexes: indexes[row[4]] = {'primary_key': False, 'unique': False} if row[2] == 'PRIMARY': indexes[row[4]]['primary_key'] = True if not row[1]: indexes[row[4]]['unique'] = True return indexes
cursor.execute("SHOW INDEX FROM %s" % self.connection.ops.quote_name(table_name)) for table, non_unique, index, colseq, column in [x[:5] for x in cursor.fetchall()]: if index not in constraints: constraints[index] = { 'columns': OrderedSet(), 'primary_key': False, 'unique': False, 'index': True, 'check': False, 'foreign_key': None, } constraints[index]['index'] = True constraints[index]['columns'].add(column) for constraint in constraints.values(): constraint['columns'] = list(constraint['columns']) return constraints
integer_field_ranges = dict( BaseDatabaseOperations.integer_field_ranges, PositiveSmallIntegerField=(0, 65535), PositiveIntegerField=(0, 4294967295), )
if lookup_type == 'week_day': return "DAYOFWEEK(%s)" % field_name else: return "EXTRACT(%s FROM %s)" % (lookup_type.upper(), field_name)
return 'MATCH (%s) AGAINST (%%s IN BOOLEAN MODE)' % field_name
return force_text(getattr(cursor, '_last_executed', None), errors='replace')
return 18446744073709551615
if tables: sql = ['SET FOREIGN_KEY_CHECKS = 0;'] for table in tables: sql.append('%s %s;' % ( style.SQL_KEYWORD('TRUNCATE'), style.SQL_FIELD(self.quote_name(table)), )) sql.append('SET FOREIGN_KEY_CHECKS = 1;') sql.extend(self.sequence_reset_by_name_sql(style, sequences)) return sql else: return []
if value == 0: raise ValueError('The database backend does not accept 0 as a ' 'value for AutoField.') return value
if timezone.is_aware(value): if settings.USE_TZ: value = timezone.make_naive(value, self.connection.timezone) else: raise ValueError("MySQL backend does not support timezone-aware datetimes when USE_TZ is False.")
if timezone.is_aware(value): raise ValueError("MySQL backend does not support timezone-aware times.")
import MySQLdb.converters return MySQLdb.escape(value, MySQLdb.converters.conversions)
if self.skip_default(field) and field.default not in (None, NOT_PROVIDED): effective_default = self.effective_default(field) self.execute('UPDATE %(table)s SET %(column)s = %%s' % { 'table': self.quote_name(model._meta.db_table), 'column': self.quote_name(field.column), }, [effective_default])
field.db_index = False
version = Database.version_info if (version < (1, 2, 1) or ( version[:3] == (1, 2, 1) and (len(version) < 5 or version[3] != 'final' or version[4] < 2))): from django.core.exceptions import ImproperlyConfigured raise ImproperlyConfigured("MySQLdb-1.2.1p2 or newer is required; you have %s" % Database.__version__)
if settings.USE_TZ and timezone.is_aware(value): warnings.warn( "The MySQL database adapter received an aware datetime (%s), " "probably from cursor.execute(). Update your code to pass a " "naive datetime in the database connection's time zone (UTC by " "default).", RemovedInDjango20Warning) value = value.astimezone(timezone.utc).replace(tzinfo=None) return Thing2Literal(value.strftime("%Y-%m-%d %H:%M:%S.%f"), conv)
django_conversions = conversions.copy() django_conversions.update({ FIELD_TYPE.TIME: backend_utils.typecast_time, FIELD_TYPE.DECIMAL: backend_utils.typecast_decimal, FIELD_TYPE.NEWDECIMAL: backend_utils.typecast_decimal, datetime.datetime: adapt_datetime_warn_on_aware_datetime, })
server_version_re = re.compile(r'(\d{1,2})\.(\d{1,2})\.(\d{1,2})')
return self.cursor.execute(query, args)
if e.args[0] in self.codes_for_integrityerror: six.reraise(utils.IntegrityError, utils.IntegrityError(*tuple(e.args)), sys.exc_info()[2]) raise
if e.args[0] in self.codes_for_integrityerror: six.reraise(utils.IntegrityError, utils.IntegrityError(*tuple(e.args)), sys.exc_info()[2]) raise
self.close()
_data_types = { 'AutoField': 'integer AUTO_INCREMENT', 'BigAutoField': 'bigint AUTO_INCREMENT', 'BinaryField': 'longblob', 'BooleanField': 'bool', 'CharField': 'varchar(%(max_length)s)', 'CommaSeparatedIntegerField': 'varchar(%(max_length)s)', 'DateField': 'date', 'DateTimeField': 'datetime', 'DecimalField': 'numeric(%(max_digits)s, %(decimal_places)s)', 'DurationField': 'bigint', 'FileField': 'varchar(%(max_length)s)', 'FilePathField': 'varchar(%(max_length)s)', 'FloatField': 'double precision', 'IntegerField': 'integer', 'BigIntegerField': 'bigint', 'IPAddressField': 'char(15)', 'GenericIPAddressField': 'char(39)', 'NullBooleanField': 'bool', 'OneToOneField': 'integer', 'PositiveIntegerField': 'integer UNSIGNED', 'PositiveSmallIntegerField': 'smallint UNSIGNED', 'SlugField': 'varchar(%(max_length)s)', 'SmallIntegerField': 'smallint', 'TextField': 'longtext', 'TimeField': 'time', 'UUIDField': 'char(32)', }
pattern_esc = r"REPLACE(REPLACE(REPLACE({}, '\\', '\\\\'), '%%', '\%%'), '_', '\_')" pattern_ops = { 'contains': "LIKE BINARY CONCAT('%%', {}, '%%')", 'icontains': "LIKE CONCAT('%%', {}, '%%')", 'startswith': "LIKE BINARY CONCAT({}, '%%')", 'istartswith': "LIKE CONCAT({}, '%%')", 'endswith': "LIKE BINARY CONCAT('%%', {})", 'iendswith': "LIKE CONCAT('%%', {})", }
kwargs['client_flag'] = CLIENT.FOUND_ROWS kwargs.update(settings_dict['OPTIONS']) return kwargs
cursor.execute('SET SQL_AUTO_IS_NULL = 0')
self.needs_rollback, needs_rollback = False, self.needs_rollback try: self.cursor().execute('SET foreign_key_checks=1') finally: self.needs_rollback = needs_rollback
return self.connection.mysql_version >= (5, 6, 4) and Database.version_info >= (1, 2, 5)
if pytz is None: return False
with self.connection.cursor() as cursor: cursor.execute("SELECT 1 FROM mysql.time_zone LIMIT 1") return cursor.fetchone() is not None
VERSION_RE = re.compile(r'\S+ (\d+)\.(\d+)\.?(\d+)?')
data_types_reverse = { 16: 'BooleanField', 17: 'BinaryField', 20: 'BigIntegerField', 21: 'SmallIntegerField', 23: 'IntegerField', 25: 'TextField', 700: 'FloatField', 701: 'FloatField', 869: 'GenericIPAddressField',
cursor.execute(self._get_indexes_query, [table_name]) indexes = {} for row in cursor.fetchall(): if ' ' in row[1]: continue if row[0] not in indexes: indexes[row[0]] = {'primary_key': False, 'unique': False} if row[3]: indexes[row[0]]['primary_key'] = True if row[2]: indexes[row[0]]['unique'] = True return indexes
return 'CAST(%%s AS %s)' % output_field.db_type(self.connection).split('(')[0]
if lookup_type == 'week_day': return "EXTRACT('dow' FROM %s) + 1" % field_name else: return "EXTRACT('%s' FROM %s)" % (lookup_type, field_name)
return "DATE_TRUNC('%s', %s)" % (lookup_type, field_name)
sql = "DATE_TRUNC('%s', %s)" % (lookup_type, field_name) return sql, params
if lookup_type in ('iexact', 'contains', 'icontains', 'startswith', 'istartswith', 'endswith', 'iendswith', 'regex', 'iregex'): if internal_type in ('IPAddressField', 'GenericIPAddressField'): lookup = "HOST(%s)" else: lookup = "%s::text"
if lookup_type in ('iexact', 'icontains', 'istartswith', 'iendswith'): lookup = 'UPPER(%s)' % lookup
cursor.execute("SELECT CURRVAL(pg_get_serial_sequence('%s','%s'))" % ( self.quote_name(table_name), pk_name)) return cursor.fetchone()[0]
tables_sql = ', '.join( style.SQL_FIELD(self.quote_name(table)) for table in tables) if allow_cascade: sql = ['%s %s %s;' % ( style.SQL_KEYWORD('TRUNCATE'), tables_sql, style.SQL_KEYWORD('CASCADE'), )] else: sql = ['%s %s;' % ( style.SQL_KEYWORD('TRUNCATE'), tables_sql, )] sql.extend(self.sequence_reset_by_name_sql(style, sequences)) return sql
sql = [] for sequence_info in sequences: table_name = sequence_info['table'] column_name = sequence_info['column'] if not (column_name and len(column_name) > 0): column_name = 'id' sql.append("%s setval(pg_get_serial_sequence('%s','%s'), 1, false);" % ( style.SQL_KEYWORD('SELECT'), style.SQL_TABLE(self.quote_name(table_name)), style.SQL_FIELD(column_name), )) return sql
if cursor.query is not None: return cursor.query.decode('utf-8') return None
if '[' in db_type: return None if db_type.startswith('varchar'): return self._create_index_sql(model, [field], suffix='_like', sql=self.sql_create_varchar_index) elif db_type.startswith('text'): return self._create_index_sql(model, [field], suffix='_like', sql=self.sql_create_text_index)
if not old_field.db_index and not old_field.unique and (new_field.db_index or new_field.unique): like_index_statement = self._create_like_index_sql(model, new_field) if like_index_statement is not None: self.execute(like_index_statement)
if (old_field.db_index or old_field.unique) and not (new_field.db_index or new_field.unique): index_to_remove = self._create_index_name(model, [old_field.column], suffix='_like') index_names = self._constraint_names(model, [old_field.column], index=True) for index_name in index_names: if index_name == index_to_remove: self.execute(self._delete_constraint_sql(self.sql_delete_index, model, index_name))
self.connection.close()
INETARRAY_OID = 1041 INETARRAY = psycopg2.extensions.new_array_type( (INETARRAY_OID,), 'INETARRAY', psycopg2.extensions.UNICODE, ) psycopg2.extensions.register_type(INETARRAY)
data_types = { 'AutoField': 'serial', 'BigAutoField': 'bigserial', 'BinaryField': 'bytea', 'BooleanField': 'boolean', 'CharField': 'varchar(%(max_length)s)', 'CommaSeparatedIntegerField': 'varchar(%(max_length)s)', 'DateField': 'date', 'DateTimeField': 'timestamp with time zone', 'DecimalField': 'numeric(%(max_digits)s, %(decimal_places)s)', 'DurationField': 'interval', 'FileField': 'varchar(%(max_length)s)', 'FilePathField': 'varchar(%(max_length)s)', 'FloatField': 'double precision', 'IntegerField': 'integer', 'BigIntegerField': 'bigint', 'IPAddressField': 'inet', 'GenericIPAddressField': 'inet', 'NullBooleanField': 'boolean', 'OneToOneField': 'integer', 'PositiveIntegerField': 'integer', 'PositiveSmallIntegerField': 'smallint', 'SlugField': 'varchar(%(max_length)s)', 'SmallIntegerField': 'smallint', 'TextField': 'text', 'TimeField': 'time', 'UUIDField': 'uuid', } data_type_check_constraints = { 'PositiveIntegerField': '"%(column)s" >= 0', 'PositiveSmallIntegerField': '"%(column)s" >= 0', } operators = { 'exact': '= %s', 'iexact': '= UPPER(%s)', 'contains': 'LIKE %s', 'icontains': 'LIKE UPPER(%s)', 'regex': '~ %s', 'iregex': '~* %s', 'gt': '> %s', 'gte': '>= %s', 'lt': '< %s', 'lte': '<= %s', 'startswith': 'LIKE %s', 'endswith': 'LIKE %s', 'istartswith': 'LIKE UPPER(%s)', 'iendswith': 'LIKE UPPER(%s)', }
pattern_esc = r"REPLACE(REPLACE(REPLACE({}, '\', '\\'), '%%', '\%%'), '_', '\_')" pattern_ops = { 'contains': "LIKE '%%' || {} || '%%'", 'icontains': "LIKE '%%' || UPPER({}) || '%%'", 'startswith': "LIKE {} || '%%'", 'istartswith': "LIKE UPPER({}) || '%%'", 'endswith': "LIKE '%%' || {}", 'iendswith': "LIKE '%%' || UPPER({})", }
if settings_dict['NAME'] == '': raise ImproperlyConfigured( "settings.DATABASES is improperly configured. " "Please supply the NAME value.") conn_params = { 'database': settings_dict['NAME'] or 'postgres', } conn_params.update(settings_dict['OPTIONS']) conn_params.pop('isolation_level', None) if settings_dict['USER']: conn_params['user'] = settings_dict['USER'] if settings_dict['PASSWORD']: conn_params['password'] = force_str(settings_dict['PASSWORD']) if settings_dict['HOST']: conn_params['host'] = settings_dict['HOST'] if settings_dict['PORT']: conn_params['port'] = settings_dict['PORT'] return conn_params
options = self.settings_dict['OPTIONS'] try: self.isolation_level = options['isolation_level'] except KeyError: self.isolation_level = connection.isolation_level else: if self.isolation_level != connection.isolation_level: connection.set_session(isolation_level=self.isolation_level)
if not self.get_autocommit(): self.connection.commit()
self.connection.cursor().execute("SELECT 1")
temp_pgpass = NamedTemporaryFile(mode='w+') try: print_( _escape_pgpass(host) or '*', str(port) or '*', _escape_pgpass(name) or '*', _escape_pgpass(user) or '*', _escape_pgpass(passwd), file=temp_pgpass, sep=':', flush=True, ) os.environ['PGPASSFILE'] = temp_pgpass.name except UnicodeEncodeError: pass
data_types_reverse = { cx_Oracle.BLOB: 'BinaryField', cx_Oracle.CLOB: 'TextField', cx_Oracle.DATETIME: 'DateField', cx_Oracle.FIXED_CHAR: 'CharField', cx_Oracle.NCLOB: 'TextField', cx_Oracle.NUMBER: 'DecimalField', cx_Oracle.STRING: 'CharField', cx_Oracle.TIMESTAMP: 'DateTimeField', }
if data_type == cx_Oracle.NUMBER: precision, scale = description[4:6] if scale == 0: if precision > 11: return 'BigIntegerField' elif precision == 1: return 'BooleanField' else: return 'IntegerField' elif scale == -127: return 'FloatField'
if constraint not in constraints: constraints[constraint] = { "columns": [], "primary_key": pk, "unique": unique, "foreign_key": None, "check": check,
if constraint not in constraints: constraints[constraint] = { "columns": [], "primary_key": False, "unique": False, "foreign_key": None, "check": False, "index": True, } constraints[constraint]['columns'].append(column)
integer_field_ranges = { 'SmallIntegerField': (-99999999999, 99999999999), 'IntegerField': (-99999999999, 99999999999), 'BigIntegerField': (-9999999999999999999, 9999999999999999999), 'PositiveSmallIntegerField': (0, 99999999999), 'PositiveIntegerField': (0, 99999999999), }
return "TO_CHAR(%s, 'D')" % field_name
return "EXTRACT(%s FROM %s)" % (lookup_type.upper(), field_name)
if lookup_type in ('year', 'month'): return "TRUNC(%s, '%s')" % (field_name, lookup_type.upper()) else: return "TRUNC(%s)" % field_name
_tzname_re = re.compile(r'^[\w/:+-]+$')
field_name = "(FROM_TZ(%s, '0:00') AT TIME ZONE '%s')" % (field_name, tzname)
return "CAST(%s AS TIMESTAMP)" % field_name
if lookup_type in ('year', 'month'): sql = "TRUNC(%s, '%s')" % (field_name, lookup_type.upper()) elif lookup_type == 'day': sql = "TRUNC(%s)" % field_name elif lookup_type == 'hour': sql = "TRUNC(%s, 'HH24')" % field_name elif lookup_type == 'minute': sql = "TRUNC(%s, 'MI')" % field_name else:
field = expression.output_field if value is None and field.empty_strings_allowed: value = '' if field.get_internal_type() == 'BinaryField': value = b'' return value
statement = cursor.statement
return super(DatabaseOperations, self).last_executed_query(cursor, statement, params)
if not name.startswith('"') and not name.endswith('"'): name = '"%s"' % truncate_name(name.upper(), self.max_name_length()) name = name.replace('%', '%%') return name.upper()
if tables: sql = ['%s %s %s;' % ( style.SQL_KEYWORD('DELETE'), style.SQL_KEYWORD('FROM'), style.SQL_FIELD(self.quote_name(table)) ) for table in tables] sql.extend(self.sequence_reset_by_name_sql(style, sequences)) return sql else: return []
break
if timezone.is_aware(value): if settings.USE_TZ: value = timezone.make_naive(value, self.connection.timezone) else: raise ValueError("Oracle backend does not support timezone-aware datetimes when USE_TZ is False.")
if timezone.is_aware(value): raise ValueError("Oracle backend does not support timezone-aware times.")
if 'ORA-22858' in description or 'ORA-22859' in description: self._alter_field_type_workaround(model, old_field, new_field) else: raise
new_temp_field = copy.deepcopy(new_field) new_temp_field.null = True new_temp_field.column = self._generate_temp_name(new_field.column) self.add_field(model, new_temp_field) new_value = self.quote_name(old_field.column) old_type = old_field.db_type(self.connection) if re.match('^N?CLOB', old_type): new_value = "TO_CHAR(%s)" % new_value old_type = 'VARCHAR2' if re.match('^N?VARCHAR2', old_type): new_internal_type = new_field.get_internal_type() if new_internal_type == 'DateField': new_value = "TO_DATE(%s, 'YYYY-MM-DD')" % new_value elif new_internal_type == 'DateTimeField': new_value = "TO_TIMESTAMP(%s, 'YYYY-MM-DD HH24:MI:SS.FF')" % new_value elif new_internal_type == 'TimeField': new_value = "TO_TIMESTAMP(CONCAT('1900-01-01 ', %s), 'YYYY-MM-DD HH24:MI:SS.FF')" % new_value self.execute("UPDATE %s set %s=%s" % ( self.quote_name(model._meta.db_table), self.quote_name(new_temp_field.column), new_value, )) self.remove_field(model, old_field) super(DatabaseSchemaEditor, self).alter_field(model, new_temp_field, new_field)
if keepdb: return sys.stderr.write("Got an error creating the test database: %s\n" % e) if not autoclobber: confirm = input( "It appears the test database, %s, already exists. " "Type 'yes' to delete it, or 'no' to cancel: " % parameters['user']) if autoclobber or confirm == 'yes': if verbosity >= 1: print("Destroying old test database for alias '%s'..." % self.connection.alias) try: self._execute_test_db_destruction(cursor, parameters, verbosity) except DatabaseError as e: if 'ORA-29857' in str(e): self._handle_objects_preventing_db_destruction(cursor, parameters, verbosity, autoclobber) else: sys.stderr.write("Got an error destroying the old test database: %s\n" % e) sys.exit(2) except Exception as e: sys.stderr.write("Got an error destroying the old test database: %s\n" % e) sys.exit(2) try: self._execute_test_db_creation(cursor, parameters, verbosity, keepdb) except Exception as e: sys.stderr.write("Got an error recreating the test database: %s\n" % e) sys.exit(2) else: print("Tests cancelled.") sys.exit(1)
if keepdb: return sys.stderr.write("Got an error creating the test user: %s\n" % e) if not autoclobber: confirm = input( "It appears the test user, %s, already exists. Type " "'yes' to delete it, or 'no' to cancel: " % parameters['user']) if autoclobber or confirm == 'yes': try: if verbosity >= 1: print("Destroying old test user...") self._destroy_test_user(cursor, parameters, verbosity) if verbosity >= 1: print("Creating test user...") self._create_test_user(cursor, parameters, verbosity, keepdb) except Exception as e: sys.stderr.write("Got an error recreating the test user: %s\n" % e) sys.exit(2) else: print("Tests cancelled.") sys.exit(1)
print("There are objects in the old test database which prevent its destruction.") print("If they belong to the test user, deleting the user will allow the test " "database to be recreated.") print("Otherwise, you will need to find and remove each of these objects, " "or use a different tablespace.\n") if self._test_user_create(): if not autoclobber: confirm = input("Type 'yes' to delete user %s: " % parameters['user']) if autoclobber or confirm == 'yes': try: if verbosity >= 1: print("Destroying old test user...") self._destroy_test_user(cursor, parameters, verbosity) except Exception as e: sys.stderr.write("Got an error destroying the test user: %s\n" % e) sys.exit(2) try: if verbosity >= 1: print("Destroying old test database for alias '%s'..." % self.connection.alias) self._execute_test_db_destruction(cursor, parameters, verbosity) except Exception as e: sys.stderr.write("Got an error destroying the test database: %s\n" % e) sys.exit(2) else: print("Tests cancelled -- test database cannot be recreated.") sys.exit(1) else: print("Django is configured to use pre-existing test user '%s'," " and will not attempt to delete it.\n" % parameters['user']) print("Tests cancelled -- test database cannot be recreated.") sys.exit(1)
acceptable_ora_err = 'ORA-01543' if keepdb else None self._execute_allow_fail_statements(cursor, statements, parameters, verbosity, acceptable_ora_err)
acceptable_ora_err = 'ORA-01920' if keepdb else None self._execute_allow_fail_statements(cursor, statements, parameters, verbosity, acceptable_ora_err) extra = "GRANT CREATE VIEW TO %(user)s" success = self._execute_allow_fail_statements(cursor, [extra], parameters, verbosity, 'ORA-01031') if not success and verbosity >= 2: print("Failed to grant CREATE VIEW permission to test user. This may be ok.")
allow_quiet_fail = acceptable_ora_err is not None and len(acceptable_ora_err) > 0 self._execute_statements(cursor, statements, parameters, verbosity, allow_quiet_fail=allow_quiet_fail) return True
if platform.system().upper().startswith('CYGWIN'): try: import ctypes except ImportError as e: from django.core.exceptions import ImproperlyConfigured raise ImproperlyConfigured("Error loading ctypes: %s; " "the Oracle backend requires ctypes to " "operate correctly under Cygwin." % e) kernel32 = ctypes.CDLL('kernel32') for name, value in environ: kernel32.SetEnvironmentVariableA(name, value) else: os.environ.update(environ)
('NLS_LANG', '.UTF8'), ('ORA_NCHAR_LITERAL_REPLACE', 'TRUE'),
if instance is None: raise AttributeError("operators not available as class attribute") instance.cursor().close() return instance.__dict__['operators']
data_types = { 'AutoField': 'NUMBER(11)', 'BigAutoField': 'NUMBER(19)', 'BinaryField': 'BLOB', 'BooleanField': 'NUMBER(1)', 'CharField': 'NVARCHAR2(%(max_length)s)', 'CommaSeparatedIntegerField': 'VARCHAR2(%(max_length)s)', 'DateField': 'DATE', 'DateTimeField': 'TIMESTAMP', 'DecimalField': 'NUMBER(%(max_digits)s, %(decimal_places)s)', 'DurationField': 'INTERVAL DAY(9) TO SECOND(6)', 'FileField': 'NVARCHAR2(%(max_length)s)', 'FilePathField': 'NVARCHAR2(%(max_length)s)', 'FloatField': 'DOUBLE PRECISION', 'IntegerField': 'NUMBER(11)', 'BigIntegerField': 'NUMBER(19)', 'IPAddressField': 'VARCHAR2(15)', 'GenericIPAddressField': 'VARCHAR2(39)', 'NullBooleanField': 'NUMBER(1)', 'OneToOneField': 'NUMBER(11)', 'PositiveIntegerField': 'NUMBER(11)', 'PositiveSmallIntegerField': 'NUMBER(11)', 'SlugField': 'NVARCHAR2(%(max_length)s)', 'SmallIntegerField': 'NUMBER(11)', 'TextField': 'NCLOB', 'TimeField': 'TIMESTAMP', 'URLField': 'VARCHAR2(%(max_length)s)', 'UUIDField': 'VARCHAR2(32)', } data_type_check_constraints = { 'BooleanField': '%(qn_column)s IN (0,1)', 'NullBooleanField': '(%(qn_column)s IN (0,1)) OR (%(qn_column)s IS NULL)', 'PositiveIntegerField': '%(qn_column)s >= 0', 'PositiveSmallIntegerField': '%(qn_column)s >= 0', }
pattern_esc = r"REPLACE(REPLACE(REPLACE({}, '\', '\\'), '%%', '\%%'), '_', '\_')" _pattern_ops = { 'contains': "'%%' || {} || '%%'", 'icontains': "'%%' || UPPER({}) || '%%'", 'startswith': "{} || '%%'", 'istartswith': "UPPER({}) || '%%'", 'endswith': "'%%' || {}", 'iendswith': "'%%' || UPPER({})", }
cursor.execute("ALTER SESSION SET NLS_TERRITORY = 'AMERICA'") cursor.execute( "ALTER SESSION SET NLS_DATE_FORMAT = 'YYYY-MM-DD HH24:MI:SS'" " NLS_TIMESTAMP_FORMAT = 'YYYY-MM-DD HH24:MI:SS.FF'" + (" TIME_ZONE = 'UTC'" if settings.USE_TZ else '') ) cursor.close() if 'operators' not in self.__dict__: cursor = self.create_cursor() try: cursor.execute("SELECT 1 FROM DUAL WHERE DUMMY %s" % self._standard_operators['contains'], ['X']) except DatabaseError: self.operators = self._likec_operators self.pattern_ops = self._likec_pattern_ops else: self.operators = self._standard_operators self.pattern_ops = self._standard_pattern_ops cursor.close()
pass
x = e.args[0] if hasattr(x, 'code') and hasattr(x, 'message') \ and x.code == 2091 and 'ORA-02291' in x.message: six.reraise(utils.IntegrityError, utils.IntegrityError(*tuple(e.args)), sys.exc_info()[2]) raise
def _savepoint_commit(self, sid): if self.queries_logged: self.queries_log.append({ 'sql': '-- RELEASE SAVEPOINT %s (faked)' % self.ops.quote_name(sid), 'time': '0.000', })
if settings.USE_TZ and (isinstance(param, datetime.datetime) and not isinstance(param, Oracle_datetime)): if timezone.is_aware(param): warnings.warn( "The Oracle database adapter received an aware datetime (%s), " "probably from cursor.execute(). Update your code to pass a " "naive datetime in the database connection's time zone (UTC by " "default).", RemovedInDjango20Warning) param = param.astimezone(timezone.utc).replace(tzinfo=None) param = Oracle_datetime.from_datetime(param)
if param is True: param = 1 elif param is False: param = 0 if hasattr(param, 'bind_parameter'): self.force_bytes = param.bind_parameter(cursor) elif isinstance(param, Database.Binary): self.force_bytes = param else: self.force_bytes = convert_unicode(param, cursor.charset, strings_only) if isinstance(self.force_bytes, six.string_types): string_size = len(force_bytes(param, cursor.charset, strings_only)) if hasattr(param, 'input_size'): self.input_size = param.input_size elif string_size > 4000: self.input_size = Database.CLOB else: self.input_size = None
self.cursor.numbersAsStrings = True self.cursor.arraysize = 100
if hasattr(params_list[0], 'keys'): sizes = {} for params in params_list: for k, value in params.items(): if value.input_size: sizes[k] = value.input_size self.setinputsizes(**sizes) else: sizes = [None] * len(params_list[0]) for params in params_list: for i, value in enumerate(params): if value.input_size: sizes[i] = value.input_size self.setinputsizes(*sizes)
if hasattr(params, 'items'): return {k: v.force_bytes for k, v in params.items()} else: return [p.force_bytes for p in params]
if query.endswith(';') or query.endswith('/'): query = query[:-1] if params is None: params = [] query = convert_unicode(query, self.charset) elif hasattr(params, 'keys'): args = {k: ":%s" % k for k in params.keys()} query = convert_unicode(query % args, self.charset) else: args = [(':arg%d' % i) for i in range(len(params))] query = convert_unicode(query % tuple(args), self.charset) return query, self._format_params(params)
if hasattr(e.args[0], 'code') and e.args[0].code == 1400 and not isinstance(e, IntegrityError): six.reraise(utils.IntegrityError, utils.IntegrityError(*tuple(e.args)), sys.exc_info()[2]) raise
return None
formatted = [firstparams] + [self._format_params(p) for p in params_iter] self._guess_input_sizes(formatted) try: return self.cursor.executemany(query, [self._param_generator(p) for p in formatted]) except Database.DatabaseError as e: if hasattr(e.args[0], 'code') and e.args[0].code == 1400 and not isinstance(e, IntegrityError): six.reraise(utils.IntegrityError, utils.IntegrityError(*tuple(e.args)), sys.exc_info()[2]) raise
pass
casted = [] for value, desc in zip(row, cursor.description): if value is not None and desc[1] is Database.NUMBER: precision, scale = desc[4:6] if scale == -127: if precision == 0: if '.' in value: value = decimal.Decimal(value) else: value = int(value) else: value = float(value) elif precision > 0: if scale == 0: value = int(value) else: value = decimal.Decimal(value) elif '.' in value: value = decimal.Decimal(value) else: value = int(value) elif desc[1] in (Database.STRING, Database.FIXED_CHAR, Database.LONG_STRING): value = to_unicode(value) casted.append(value) return tuple(casted)
do_offset = with_limits and (self.query.high_mark is not None or self.query.low_mark) if not do_offset: sql, params = super(SQLCompiler, self).as_sql( with_limits=False, with_col_aliases=with_col_aliases, subquery=subquery, ) else: sql, params = super(SQLCompiler, self).as_sql( with_limits=False, with_col_aliases=True, subquery=subquery, ) high_where = '' if self.query.high_mark is not None: high_where = 'WHERE ROWNUM <= %d' % (self.query.high_mark,) sql = ( 'SELECT * FROM (SELECT "_SUB".*, ROWNUM AS "_RN" FROM (%s) ' '"_SUB" %s) WHERE "_RN" > %d' % (sql, high_where, self.query.low_mark) )
supports_select_for_update_with_limit = False supports_temporal_subtraction = True
if int(Database.version.split('.', 1)[0]) >= 5 and \ (int(Database.version.split('.', 2)[1]) >= 1 or not hasattr(Database, 'UNICODE')): convert_unicode = force_text else: convert_unicode = force_bytes
TableInfo = namedtuple('TableInfo', ['name', 'type'])
FieldInfo = namedtuple('FieldInfo', 'name type_code display_size internal_size precision scale null_ok')
if f.remote_field.through is None: sequence_list.append({'table': f.m2m_db_table(), 'column': None})
integer_field_ranges = { 'SmallIntegerField': (-32768, 32767), 'IntegerField': (-2147483648, 2147483647), 'BigIntegerField': (-9223372036854775808, 9223372036854775807), 'PositiveSmallIntegerField': (0, 32767), 'PositiveIntegerField': (0, 2147483647), }
raise NotImplementedError('Full-text search is not implemented for this database backend')
def to_unicode(s): return force_text(s, strings_only=True, errors='replace') if isinstance(params, (list, tuple)): u_params = tuple(to_unicode(val) for val in params) elif params is None: u_params = () else: u_params = {to_unicode(k): to_unicode(v) for k, v in params.items()}
prep_for_iexact_query = prep_for_like_query
return zip( (obj for obj in old_field.model._meta.related_objects if not obj.field.many_to_many), (obj for obj in new_field.model._meta.related_objects if not obj.field.many_to_many) )
sql_create_table = "CREATE TABLE %(table)s (%(definition)s)" sql_rename_table = "ALTER TABLE %(old_table)s RENAME TO %(new_table)s" sql_retablespace_table = "ALTER TABLE %(table)s SET TABLESPACE %(new_tablespace)s" sql_delete_table = "DROP TABLE %(table)s CASCADE"
logger.debug("%s; (params %r)", sql, params, extra={'params': params, 'sql': sql}) if self.collect_sql: ending = "" if sql.endswith(";") else ";" if params is not None: self.collected_sql.append((sql % tuple(map(self.quote_value, params))) + ending) else: self.collected_sql.append(sql + ending) else: with self.connection.cursor() as cursor: cursor.execute(sql, params)
db_params = field.db_parameters(connection=self.connection) sql = db_params['type'] params = [] if sql is None: return None, None null = field.null include_default = include_default and not self.skip_default(field) if include_default: default_value = self.effective_default(field) if default_value is not None: if self.connection.features.requires_literal_defaults: sql += " DEFAULT %s" % self.prepare_default(default_value) else: sql += " DEFAULT %s" params += [default_value] if (field.empty_strings_allowed and not field.primary_key and self.connection.features.interprets_empty_strings_as_nulls): null = True if null and not self.connection.features.implied_column_null: sql += " NULL" elif not null: sql += " NOT NULL" if field.primary_key: sql += " PRIMARY KEY" elif field.unique: sql += " UNIQUE" tablespace = field.db_tablespace or model._meta.db_tablespace if tablespace and self.connection.features.supports_tablespaces and field.unique: sql += " %s" % self.connection.ops.tablespace_sql(tablespace, inline=True) return sql, params
if callable(default): default = default() default = field.get_db_prep_save(default, self.connection) return default
column_sqls = [] params = [] for field in model._meta.local_fields: definition, extra_params = self.column_sql(model, field) if definition is None: continue db_params = field.db_parameters(connection=self.connection) if db_params['check']: definition += " CHECK (%s)" % db_params['check'] col_type_suffix = field.db_type_suffix(connection=self.connection) if col_type_suffix: definition += " %s" % col_type_suffix params.extend(extra_params) if field.remote_field and field.db_constraint: to_table = field.remote_field.model._meta.db_table to_column = field.remote_field.model._meta.get_field(field.remote_field.field_name).column if self.connection.features.supports_foreign_keys: self.deferred_sql.append(self._create_fk_sql(model, field, "_fk_%(to_table)s_%(to_column)s")) elif self.sql_create_inline_fk: definition += " " + self.sql_create_inline_fk % { "to_table": self.quote_name(to_table), "to_column": self.quote_name(to_column), } column_sqls.append("%s %s" % ( self.quote_name(field.column), definition, )) if field.get_internal_type() in ("AutoField", "BigAutoField"): autoinc_sql = self.connection.ops.autoinc_sql(model._meta.db_table, field.column) if autoinc_sql: self.deferred_sql.extend(autoinc_sql)
for fields in model._meta.unique_together: columns = [model._meta.get_field(field).column for field in fields] self.deferred_sql.append(self._create_unique_sql(model, columns)) sql = self.sql_create_table % { "table": self.quote_name(model._meta.db_table), "definition": ", ".join(column_sqls) } if model._meta.db_tablespace: tablespace_sql = self.connection.ops.tablespace_sql(model._meta.db_tablespace) if tablespace_sql: sql += ' ' + tablespace_sql self.execute(sql, params or None)
self.deferred_sql.extend(self._model_indexes_sql(model))
for field in model._meta.local_many_to_many: if field.remote_field.through._meta.auto_created: self.create_model(field.remote_field.through)
for field in model._meta.local_many_to_many: if field.remote_field.through._meta.auto_created: self.delete_model(field.remote_field.through)
self.execute(self.sql_delete_table % { "table": self.quote_name(model._meta.db_table), })
for fields in olds.difference(news): self._delete_composed_index(model, fields, {'unique': True}, self.sql_delete_unique) for fields in news.difference(olds): columns = [model._meta.get_field(field).column for field in fields] self.execute(self._create_unique_sql(model, columns))
for fields in olds.difference(news): self._delete_composed_index(model, fields, {'index': True}, self.sql_delete_index) for field_names in news.difference(olds): fields = [model._meta.get_field(field) for field in field_names] self.execute(self._create_index_sql(model, fields, suffix="_idx"))
if field.many_to_many and field.remote_field.through._meta.auto_created: return self.create_model(field.remote_field.through) definition, params = self.column_sql(model, field, include_default=True) if definition is None: return db_params = field.db_parameters(connection=self.connection) if db_params['check']: definition += " CHECK (%s)" % db_params['check'] sql = self.sql_create_column % { "table": self.quote_name(model._meta.db_table), "column": self.quote_name(field.column), "definition": definition, } self.execute(sql, params) if not self.skip_default(field) and field.default is not None: sql = self.sql_alter_column % { "table": self.quote_name(model._meta.db_table), "changes": self.sql_alter_column_no_default % { "column": self.quote_name(field.column), } } self.execute(sql) if field.db_index and not field.unique: self.deferred_sql.append(self._create_index_sql(model, [field])) if field.remote_field and self.connection.features.supports_foreign_keys and field.db_constraint: self.deferred_sql.append(self._create_fk_sql(model, field, "_fk_%(to_table)s_%(to_column)s")) if self.connection.features.connection_persists_old_columns: self.connection.close()
if field.many_to_many and field.remote_field.through._meta.auto_created: return self.delete_model(field.remote_field.through) if field.db_parameters(connection=self.connection)['type'] is None: return if field.remote_field: fk_names = self._constraint_names(model, [field.column], foreign_key=True) for fk_name in fk_names: self.execute(self._delete_constraint_sql(self.sql_delete_fk, model, fk_name)) sql = self.sql_delete_column % { "table": self.quote_name(model._meta.db_table), "column": self.quote_name(field.column), } self.execute(sql) if self.connection.features.connection_persists_old_columns: self.connection.close()
old_db_params = old_field.db_parameters(connection=self.connection) old_type = old_db_params['type'] new_db_params = new_field.db_parameters(connection=self.connection) new_type = new_db_params['type'] if ((old_type is None and old_field.remote_field is None) or (new_type is None and new_field.remote_field is None)): raise ValueError( "Cannot alter field %s into %s - they do not properly define " "db_type (are you using a badly-written custom field?)" % (old_field, new_field), ) elif old_type is None and new_type is None and ( old_field.remote_field.through and new_field.remote_field.through and old_field.remote_field.through._meta.auto_created and new_field.remote_field.through._meta.auto_created): return self._alter_many_to_many(model, old_field, new_field, strict) elif old_type is None and new_type is None and ( old_field.remote_field.through and new_field.remote_field.through and not old_field.remote_field.through._meta.auto_created and not new_field.remote_field.through._meta.auto_created): return elif old_type is None or new_type is None: raise ValueError( "Cannot alter field %s into %s - they are not compatible types " "(you cannot alter to or from M2M fields, or add or remove " "through= on M2M fields)" % (old_field, new_field) )
fks_dropped = set() if old_field.remote_field and old_field.db_constraint: fk_names = self._constraint_names(model, [old_field.column], foreign_key=True) if strict and len(fk_names) != 1: raise ValueError("Found wrong number (%s) of foreign key constraints for %s.%s" % ( len(fk_names), model._meta.db_table, old_field.column, )) for fk_name in fk_names: fks_dropped.add((old_field.column,)) self.execute(self._delete_constraint_sql(self.sql_delete_fk, model, fk_name)) if old_field.unique and (not new_field.unique or (not old_field.primary_key and new_field.primary_key)): constraint_names = self._constraint_names(model, [old_field.column], unique=True) if strict and len(constraint_names) != 1: raise ValueError("Found wrong number (%s) of unique constraints for %s.%s" % ( len(constraint_names), model._meta.db_table, old_field.column, )) for constraint_name in constraint_names: self.execute(self._delete_constraint_sql(self.sql_delete_unique, model, constraint_name)) if old_field.primary_key and new_field.primary_key and old_type != new_type: for _old_rel, new_rel in _related_non_m2m_objects(old_field, new_field): rel_fk_names = self._constraint_names( new_rel.related_model, [new_rel.field.column], foreign_key=True ) for fk_name in rel_fk_names: self.execute(self._delete_constraint_sql(self.sql_delete_fk, new_rel.related_model, fk_name)) if (old_field.db_index and not new_field.db_index and not old_field.unique and not (not new_field.unique and old_field.unique)): index_names = self._constraint_names(model, [old_field.column], index=True) for index_name in index_names: self.execute(self._delete_constraint_sql(self.sql_delete_index, model, index_name)) if old_db_params['check'] != new_db_params['check'] and old_db_params['check']: constraint_names = self._constraint_names(model, [old_field.column], check=True) if strict and len(constraint_names) != 1: raise ValueError("Found wrong number (%s) of check constraints for %s.%s" % ( len(constraint_names), model._meta.db_table, old_field.column, )) for constraint_name in constraint_names: self.execute(self._delete_constraint_sql(self.sql_delete_check, model, constraint_name)) if old_field.column != new_field.column: self.execute(self._rename_field_sql(model._meta.db_table, old_field, new_field, new_type)) actions = [] null_actions = [] post_actions = [] if old_type != new_type: fragment, other_actions = self._alter_column_type_sql( model._meta.db_table, old_field, new_field, new_type ) actions.append(fragment) post_actions.extend(other_actions) old_default = self.effective_default(old_field) new_default = self.effective_default(new_field) needs_database_default = ( old_default != new_default and new_default is not None and not self.skip_default(new_field) ) if needs_database_default: if self.connection.features.requires_literal_defaults: actions.append(( self.sql_alter_column_default % { "column": self.quote_name(new_field.column), "type": new_type, "default": self.prepare_default(new_default), }, [], )) else: actions.append(( self.sql_alter_column_default % { "column": self.quote_name(new_field.column), "type": new_type, "default": "%s", }, [new_default], )) if old_field.null != new_field.null: if (self.connection.features.interprets_empty_strings_as_nulls and new_field.get_internal_type() in ("CharField", "TextField")): pass elif new_field.null: null_actions.append(( self.sql_alter_column_null % { "column": self.quote_name(new_field.column), "type": new_type, }, [], )) else: null_actions.append(( self.sql_alter_column_not_null % { "column": self.quote_name(new_field.column), "type": new_type, }, [], )) four_way_default_alteration = ( new_field.has_default() and (old_field.null and not new_field.null) ) if actions or null_actions: if not four_way_default_alteration: actions = actions + null_actions if self.connection.features.supports_combined_alters and actions: sql, params = tuple(zip(*actions)) actions = [(", ".join(sql), sum(params, []))] for sql, params in actions: self.execute( self.sql_alter_column % { "table": self.quote_name(model._meta.db_table), "changes": sql, }, params, ) if four_way_default_alteration: self.execute( self.sql_update_with_default % { "table": self.quote_name(model._meta.db_table), "column": self.quote_name(new_field.column), "default": "%s", }, [new_default], ) for sql, params in null_actions: self.execute( self.sql_alter_column % { "table": self.quote_name(model._meta.db_table), "changes": sql, }, params, ) if post_actions: for sql, params in post_actions: self.execute(sql, params) if (not old_field.unique and new_field.unique) or ( old_field.primary_key and not new_field.primary_key and new_field.unique ): self.execute(self._create_unique_sql(model, [new_field.column])) if (not old_field.db_index and new_field.db_index and not new_field.unique and not (not old_field.unique and new_field.unique)): self.execute(self._create_index_sql(model, [new_field], suffix="_uniq")) rels_to_update = [] if old_field.primary_key and new_field.primary_key and old_type != new_type: rels_to_update.extend(_related_non_m2m_objects(old_field, new_field)) if not old_field.primary_key and new_field.primary_key: constraint_names = self._constraint_names(model, primary_key=True) if strict and len(constraint_names) != 1: raise ValueError("Found wrong number (%s) of PK constraints for %s" % ( len(constraint_names), model._meta.db_table, )) for constraint_name in constraint_names: self.execute(self._delete_constraint_sql(self.sql_delete_pk, model, constraint_name)) self.execute( self.sql_create_pk % { "table": self.quote_name(model._meta.db_table), "name": self.quote_name(self._create_index_name(model, [new_field.column], suffix="_pk")), "columns": self.quote_name(new_field.column), } ) rels_to_update.extend(_related_non_m2m_objects(old_field, new_field)) for old_rel, new_rel in rels_to_update: rel_db_params = new_rel.field.db_parameters(connection=self.connection) rel_type = rel_db_params['type'] fragment, other_actions = self._alter_column_type_sql( new_rel.related_model._meta.db_table, old_rel.field, new_rel.field, rel_type ) self.execute( self.sql_alter_column % { "table": self.quote_name(new_rel.related_model._meta.db_table), "changes": fragment[0], }, fragment[1], ) for sql, params in other_actions: self.execute(sql, params) if (new_field.remote_field and (fks_dropped or not old_field.remote_field or not old_field.db_constraint) and new_field.db_constraint): self.execute(self._create_fk_sql(model, new_field, "_fk_%(to_table)s_%(to_column)s")) if old_field.primary_key and new_field.primary_key and old_type != new_type: for rel in new_field.model._meta.related_objects: if not rel.many_to_many: self.execute(self._create_fk_sql(rel.related_model, rel.field, "_fk")) if old_db_params['check'] != new_db_params['check'] and new_db_params['check']: self.execute( self.sql_create_check % { "table": self.quote_name(model._meta.db_table), "name": self.quote_name(self._create_index_name(model, [new_field.column], suffix="_check")), "column": self.quote_name(new_field.column), "check": new_db_params['check'], } ) if needs_database_default: sql = self.sql_alter_column % { "table": self.quote_name(model._meta.db_table), "changes": self.sql_alter_column_no_default % { "column": self.quote_name(new_field.column), "type": new_type, } } self.execute(sql) if self.connection.features.connection_persists_old_columns: self.connection.close()
if old_field.remote_field.through._meta.db_table != new_field.remote_field.through._meta.db_table: self.alter_db_table(old_field.remote_field.through, old_field.remote_field.through._meta.db_table, new_field.remote_field.through._meta.db_table) self.alter_field( new_field.remote_field.through, old_field.remote_field.through._meta.get_field(old_field.m2m_reverse_field_name()), new_field.remote_field.through._meta.get_field(new_field.m2m_reverse_field_name()), ) self.alter_field( new_field.remote_field.through, old_field.remote_field.through._meta.get_field(old_field.m2m_field_name()), new_field.remote_field.through._meta.get_field(new_field.m2m_field_name()), )
if len(column_names) == 1 and not suffix: return truncate_name( '%s_%s' % (model._meta.db_table, self._digest(column_names[0])), self.connection.ops.max_name_length() ) table_name = model._meta.db_table.replace('"', '').replace('.', '_') index_unique_name = '_%s' % self._digest(table_name, *column_names) max_length = self.connection.ops.max_name_length() or 200 index_name = ('%s_%s%s%s' % ( table_name, column_names[0], index_unique_name, suffix, )).replace('"', '').replace('.', '_') if len(index_name) > max_length: part = ('_%s%s%s' % (column_names[0], index_unique_name, suffix)) index_name = '%s%s' % (table_name[:(max_length - len(part))], part) if index_name[0] == "_": index_name = index_name[1:] if len(index_name) > max_length: index_name = hashlib.md5(force_bytes(index_name)).hexdigest()[:max_length] if index_name[0].isdigit(): index_name = "D%s" % index_name[:-1] return index_name
TEST_DATABASE_PREFIX = 'test_'
from django.core.management import call_command
self._create_test_db(verbosity, autoclobber, keepdb)
call_command( 'migrate', verbosity=max(verbosity - 1, 0), interactive=False, database=self.connection.alias, run_syncdb=True, )
if serialize: self.connection._test_serialized_contents = self.serialize_db_to_string()
self.connection.ensure_connection()
from django.db.migrations.loader import MigrationLoader loader = MigrationLoader(self.connection) app_list = [] for app_config in apps.get_app_configs(): if ( app_config.models_module is not None and app_config.label in loader.migrated_apps and app_config.name not in settings.TEST_NON_SERIALIZED_APPS ): app_list.append((app_config, None))
def get_objects(): for model in serializers.sort_dependencies(app_list): if (model._meta.can_migrate(self.connection) and router.allow_migrate_model(self.connection.alias, model)): queryset = model._default_manager.using(self.connection.alias).order_by(model._meta.pk.name) for obj in queryset.iterator(): yield obj out = StringIO() serializers.serialize("json", get_objects(), indent=None, stream=out) return out.getvalue()
with self._nodb_connection.cursor() as cursor: try: cursor.execute( "CREATE DATABASE %s %s" % (qn(test_database_name), suffix)) except Exception as e: if keepdb: return test_database_name
self._clone_test_db(number, verbosity, keepdb)
orig_settings_dict = self.connection.settings_dict new_settings_dict = orig_settings_dict.copy() new_settings_dict['NAME'] = '{}_{}'.format(orig_settings_dict['NAME'], number) return new_settings_dict
if not keepdb: self._destroy_test_db(test_database_name, verbosity)
if old_database_name is not None: settings.DATABASES[self.connection.alias]["NAME"] = old_database_name self.connection.settings_dict["NAME"] = old_database_name
with self.connection._nodb_connection.cursor() as cursor: time.sleep(1) cursor.execute("DROP DATABASE %s" % self.connection.ops.quote_name(test_database_name))
data_types = {} data_types_suffix = {} data_type_check_constraints = {} ops = None vendor = 'unknown' SchemaEditorClass = None
self.connection = None self.settings_dict = settings_dict self.alias = alias self.queries_log = deque(maxlen=self.queries_limit) self.force_debug_cursor = False
self.autocommit = False self.in_atomic_block = False self.savepoint_state = 0 self.savepoint_ids = [] self.commit_on_exit = True self.needs_rollback = False
self.close_at = None self.closed_in_transaction = False self.errors_occurred = False
self.allow_thread_sharing = allow_thread_sharing self._thread_ident = thread.get_ident()
self.run_on_commit = []
self.run_commit_hooks_on_set_autocommit_on = False
return pytz.timezone(self.settings_dict['TIME_ZONE'])
self.check_settings() self.in_atomic_block = False self.savepoint_ids = [] self.needs_rollback = False max_age = self.settings_dict['CONN_MAX_AGE'] self.close_at = None if max_age is None else time.time() + max_age self.closed_in_transaction = False self.errors_occurred = False conn_params = self.get_connection_params() self.connection = self.get_new_connection(conn_params) self.set_autocommit(self.settings_dict['AUTOCOMMIT']) self.init_connection_state() connection_created.send(sender=self.__class__, connection=self)
self.errors_occurred = False self.run_commit_hooks_on_set_autocommit_on = True
self.errors_occurred = False
if self.closed_in_transaction or self.connection is None: return try: self._close() finally: if self.in_atomic_block: self.closed_in_transaction = True self.needs_rollback = True else: self.connection = None
return self.features.uses_savepoints and not self.get_autocommit()
self.run_on_commit = [ (sids, func) for (sids, func) in self.run_on_commit if sid not in sids ]
if self.get_autocommit() != self.settings_dict['AUTOCOMMIT']: self.close() return
if self.errors_occurred: if self.is_usable(): self.errors_occurred = False else: self.close() return
self.run_on_commit.append((set(self.savepoint_ids), func))
func()
executable_name = None
self.connection = connection
interprets_empty_strings_as_nulls = False
supports_nullable_unique_constraints = True
supports_partially_nullable_unique_constraints = True
related_fields_match_type = False allow_sliced_subqueries = True has_select_for_update = False has_select_for_update_nowait = False
test_db_allows_multiple_connections = True
supports_unspecified_pk = False
supports_forward_references = True
truncates_names = False
has_real_datatype = False supports_subqueries_in_group_by = True supports_bitwise_or = True
has_native_uuid_field = False
has_native_duration_field = False
supports_temporal_subtraction = False
driver_supports_timedelta_args = False
supports_microsecond_precision = True
supports_regex_backreferencing = True
supports_date_lookup_using_string = True
supports_timezones = True
has_zoneinfo_database = True
requires_explicit_null_ordering_when_grouping = False
nulls_order_largest = False
supports_1000_query_parameters = True
allows_auto_pk_0 = True
can_defer_constraint_checks = False
supports_mixed_date_datetime_comparisons = True
supports_tablespaces = False
supports_sequence_reset = True
can_introspect_max_length = True
can_introspect_null = True
can_introspect_default = True
can_introspect_foreign_keys = True
can_introspect_autofield = False
can_introspect_big_integer_field = True
can_introspect_binary_field = True
can_introspect_decimal_field = True
can_introspect_ip_address_field = False
can_introspect_positive_integer_field = False
can_introspect_small_integer_field = False
can_introspect_time_field = True
can_distinct_on_fields = False
autocommits_when_autocommit_is_off = False
atomic_transactions = True
can_rollback_ddl = False
supports_combined_alters = False
supports_foreign_keys = True
supports_column_check_constraints = True
supports_paramstyle_pyformat = True
requires_literal_defaults = False
connection_persists_old_columns = False
closed_cursor_error_class = ProgrammingError
has_case_insensitive_like = True
requires_sqlparse_for_splitting = True
bare_select_suffix = ''
implied_column_null = False
supports_select_for_update_with_limit = True
greatest_least_ignores_nulls = False
can_clone_databases = False
class FlexibleFieldLookupDict(object): base_data_types_reverse = { 'bool': 'BooleanField', 'boolean': 'BooleanField', 'smallint': 'SmallIntegerField', 'smallint unsigned': 'PositiveSmallIntegerField', 'smallinteger': 'SmallIntegerField', 'int': 'IntegerField', 'integer': 'IntegerField', 'bigint': 'BigIntegerField', 'integer unsigned': 'PositiveIntegerField', 'decimal': 'DecimalField', 'real': 'FloatField', 'text': 'TextField', 'char': 'CharField', 'blob': 'BinaryField', 'date': 'DateField', 'datetime': 'DateTimeField', 'time': 'TimeField', }
if self.connection.Database.sqlite_version_info < (3, 7, 15): return name.split('.')[-1].strip('"') else: return name
relations = {}
cursor.execute("SELECT sql FROM sqlite_master WHERE tbl_name = %s AND type = %s", [table_name, "table"]) try: results = cursor.fetchone()[0].strip() except TypeError: return relations results = results[results.index('(') + 1:results.rindex(')')]
for field_desc in results.split(','): field_desc = field_desc.strip() if field_desc.startswith("UNIQUE"): continue
m = re.match('FOREIGN KEY\(([^\)]*)\).*', field_desc, re.I) field_name = m.groups()[0].strip('"')
cursor.execute("SELECT sql FROM sqlite_master WHERE tbl_name = %s AND type = %s", [table_name, "table"]) results = cursor.fetchone()[0].strip() results = results[results.index('(') + 1:results.rindex(')')]
for field_index, field_desc in enumerate(results.split(',')): field_desc = field_desc.strip() if field_desc.startswith("UNIQUE"): continue
key_columns.append(tuple(s.strip('"') for s in m.groups()))
for index, unique in [(field[1], field[2]) for field in cursor.fetchall()]: cursor.execute('PRAGMA index_info(%s)' % self.connection.ops.quote_name(index)) info = cursor.fetchall() if len(info) != 1: continue
cursor.execute("SELECT sql FROM sqlite_master WHERE tbl_name = %s AND type = %s", [table_name, "table"]) row = cursor.fetchone() if row is None: raise ValueError("Table %s does not exist" % table_name) results = row[0].strip() results = results[results.index('(') + 1:results.rindex(')')] for field_desc in results.split(','): field_desc = field_desc.strip() m = re.search('"(.*)".*PRIMARY KEY( AUTOINCREMENT)?$', field_desc) if m: return m.groups()[0] return None
return [{ 'name': field[1], 'type': field[2], 'size': get_field_size(field[2]), 'null_ok': not field[3], 'default': field[4],
cursor.execute("PRAGMA index_list(%s)" % self.connection.ops.quote_name(table_name)) for row in cursor.fetchall(): number, index, unique = row[:3] cursor.execute('PRAGMA index_info(%s)' % self.connection.ops.quote_name(index)) for index_rank, column_rank, column in cursor.fetchall(): if index not in constraints: constraints[index] = { "columns": [], "primary_key": False, "unique": bool(unique), "foreign_key": False, "check": False, "index": True, } constraints[index]['columns'].append(column) pk_column = self.get_primary_key_column(cursor, table_name) if pk_column: constraints["__primary__"] = { "columns": [pk_column], "primary_key": True,
pass
return "django_date_extract('%s', %s)" % (lookup_type.lower(), field_name)
return "django_date_trunc('%s', %s)" % (lookup_type.lower(), field_name)
self._require_pytz() return "django_datetime_extract('%s', %s, %%s)" % ( lookup_type.lower(), field_name), [tzname]
self._require_pytz() return "django_datetime_trunc('%s', %s, %%s)" % ( lookup_type.lower(), field_name), [tzname]
return "django_time_extract('%s', %s)" % (lookup_type.lower(), field_name)
BATCH_SIZE = 999 if len(params) > BATCH_SIZE: results = () for index in range(0, len(params), BATCH_SIZE): chunk = params[index:index + BATCH_SIZE] results += self._quote_params_for_last_executed_query(chunk) return results
cursor = self.connection.connection.cursor() try: return cursor.execute(sql, params).fetchone() finally: cursor.close()
if params: if isinstance(params, (list, tuple)): params = self._quote_params_for_last_executed_query(params) else: keys = params.keys() values = tuple(params.values()) values = self._quote_params_for_last_executed_query(values) params = dict(zip(keys, values)) return sql % params else: return sql
sql = ['%s %s %s;' % ( style.SQL_KEYWORD('DELETE'), style.SQL_KEYWORD('FROM'), style.SQL_FIELD(self.quote_name(table)) ) for table in tables] return sql
if timezone.is_aware(value): if settings.USE_TZ: value = timezone.make_naive(value, self.connection.timezone) else: raise ValueError("SQLite backend does not support timezone-aware datetimes when USE_TZ is False.")
if timezone.is_aware(value): raise ValueError("SQLite backend does not support timezone-aware times.")
if connector == '^': return 'django_power(%s)' % ','.join(sub_expressions) return super(DatabaseOperations, self).combine_expression(connector, sub_expressions)
return (None, None)
c.execute('PRAGMA foreign_keys') self._initial_pragma_fk = c.fetchone()[0] c.execute('PRAGMA foreign_keys = 0')
c.execute('PRAGMA foreign_keys = %s' % int(self._initial_pragma_fk))
try: import sqlite3 value = sqlite3.adapt(value) except ImportError: pass except sqlite3.ProgrammingError: pass if isinstance(value, type(True)): return str(int(value)) elif isinstance(value, (Decimal, float)): return str(value) elif isinstance(value, six.integer_types): return str(value) elif isinstance(value, six.string_types): return "'%s'" % six.text_type(value).replace("\'", "\'\'") elif value is None: return "NULL" elif isinstance(value, (bytes, bytearray, six.memoryview)): value = bytes(value) hex_encoder = codecs.getencoder('hex_codec') value_hex, _length = hex_encoder(value) return "X'%s'" % value_hex.decode('ascii') else: raise ValueError("Cannot quote parameter value %r of type %s" % (value, type(value)))
def is_self_referential(f): return f.is_relation and f.remote_field.model is model body = { f.name: f.clone() if is_self_referential(f) else f for f in model._meta.local_concrete_fields } mapping = {f.column: self.quote_name(f.column) for f in model._meta.local_concrete_fields} rename_mapping = {} restore_pk_field = None if any(f.primary_key for f in create_fields) or any(n.primary_key for o, n in alter_fields): for name, field in list(body.items()): if field.primary_key: field.primary_key = False restore_pk_field = field if field.auto_created: del body[name] del mapping[field.column] for field in create_fields: body[field.name] = field if not field.many_to_many and field.concrete: mapping[field.column] = self.quote_value( self.effective_default(field) ) for (old_field, new_field) in alter_fields: body.pop(old_field.name, None) mapping.pop(old_field.column, None) body[new_field.name] = new_field if old_field.null and not new_field.null: case_sql = "coalesce(%(col)s, %(default)s)" % { 'col': self.quote_name(old_field.column), 'default': self.quote_value(self.effective_default(new_field)) } mapping[new_field.column] = case_sql else: mapping[new_field.column] = self.quote_name(old_field.column) rename_mapping[old_field.name] = new_field.name for field in delete_fields: del body[field.name] del mapping[field.column] if field.many_to_many and field.remote_field.through._meta.auto_created: return self.delete_model(field.remote_field.through) apps = Apps()
body = copy.deepcopy(body)
if override_uniques is None: override_uniques = [ [rename_mapping.get(n, n) for n in unique] for unique in model._meta.unique_together ]
if override_indexes is None: override_indexes = [ [rename_mapping.get(n, n) for n in index] for index in model._meta.index_together ]
meta_contents = { 'app_label': model._meta.app_label, 'db_table': model._meta.db_table, 'unique_together': override_uniques, 'index_together': override_indexes, 'apps': apps, } meta = type("Meta", tuple(), meta_contents) body['Meta'] = meta body['__module__'] = model.__module__
@contextlib.contextmanager def altered_table_name(model, temporary_table_name): original_table_name = model._meta.db_table model._meta.db_table = temporary_table_name yield model._meta.db_table = original_table_name
self.alter_db_table(model, temp_model._meta.db_table, model._meta.db_table)
self.deferred_sql = [x for x in self.deferred_sql if temp_model._meta.db_table not in x] self.create_model(temp_model)
field_maps = list(mapping.items()) self.execute("INSERT INTO %s (%s) SELECT %s FROM %s" % ( self.quote_name(temp_model._meta.db_table), ', '.join(self.quote_name(x) for x, y in field_maps), ', '.join(y for x, y in field_maps), self.quote_name(model._meta.db_table), ))
self.delete_model(model, handle_autom2m=False)
for sql in self.deferred_sql: self.execute(sql) self.deferred_sql = [] if restore_pk_field: restore_pk_field.primary_key = True
self.execute(self.sql_delete_table % { "table": self.quote_name(model._meta.db_table), })
if field.many_to_many and field.remote_field.through._meta.auto_created: return self.create_model(field.remote_field.through) self._remake_table(model, create_fields=[field])
if field.many_to_many: if field.remote_field.through._meta.auto_created: self.delete_model(field.remote_field.through) else: if field.db_parameters(connection=self.connection)['type'] is None: return self._remake_table(model, delete_fields=[field])
self._remake_table(model, alter_fields=[(old_field, new_field)])
self._remake_table( old_field.remote_field.through, alter_fields=[( old_field.remote_field.through._meta.get_field(old_field.m2m_reverse_field_name()), new_field.remote_field.through._meta.get_field(new_field.m2m_reverse_field_name()), )], override_uniques=(new_field.m2m_field_name(), new_field.m2m_reverse_field_name()), ) return
self.create_model(new_field.remote_field.through) self.execute("INSERT INTO %s (%s) SELECT %s FROM %s" % ( self.quote_name(new_field.remote_field.through._meta.db_table), ', '.join([ "id", new_field.m2m_column_name(), new_field.m2m_reverse_name(), ]), ', '.join([ "id", old_field.m2m_column_name(), old_field.m2m_reverse_name(), ]), self.quote_name(old_field.remote_field.through._meta.db_table), )) self.delete_model(old_field.remote_field.through)
if verbosity >= 1: print("Destroying old test database for alias %s..." % ( self._get_database_display_str(verbosity, test_database_name), )) if os.access(test_database_name, os.F_OK): if not autoclobber: confirm = input( "Type 'yes' if you would like to try deleting the test " "database '%s', or 'no' to cancel: " % test_database_name ) if autoclobber or confirm == 'yes': try: os.remove(test_database_name) except Exception as e: sys.stderr.write("Got an error deleting the old test database: %s\n" % e) sys.exit(2) else: print("Tests cancelled.") sys.exit(1)
if not self.connection.is_in_memory_db(source_database_name): if os.access(target_database_name, os.F_OK): if keepdb: return if verbosity >= 1: print("Destroying old test database for alias %s..." % ( self._get_database_display_str(verbosity, target_database_name), )) try: os.remove(target_database_name) except Exception as e: sys.stderr.write("Got an error deleting the old test database: %s\n" % e) sys.exit(2) try: shutil.copy(source_database_name, target_database_name) except Exception as e: sys.stderr.write("Got an error cloning the test database: %s\n" % e) sys.exit(2)
os.remove(test_database_name)
if settings.USE_TZ and timezone.is_aware(value): warnings.warn( "The SQLite database adapter received an aware datetime (%s), " "probably from cursor.execute(). Update your code to pass a " "naive datetime in the database connection's time zone (UTC by " "default).", RemovedInDjango20Warning) value = value.astimezone(timezone.utc).replace(tzinfo=None) return value.isoformat(str(" "))
data_types = { 'AutoField': 'integer', 'BigAutoField': 'integer', 'BinaryField': 'BLOB', 'BooleanField': 'bool', 'CharField': 'varchar(%(max_length)s)', 'CommaSeparatedIntegerField': 'varchar(%(max_length)s)', 'DateField': 'date', 'DateTimeField': 'datetime', 'DecimalField': 'decimal', 'DurationField': 'bigint', 'FileField': 'varchar(%(max_length)s)', 'FilePathField': 'varchar(%(max_length)s)', 'FloatField': 'real', 'IntegerField': 'integer', 'BigIntegerField': 'bigint', 'IPAddressField': 'char(15)', 'GenericIPAddressField': 'char(39)', 'NullBooleanField': 'bool', 'OneToOneField': 'integer', 'PositiveIntegerField': 'integer unsigned', 'PositiveSmallIntegerField': 'smallint unsigned', 'SlugField': 'varchar(%(max_length)s)', 'SmallIntegerField': 'smallint', 'TextField': 'text', 'TimeField': 'time', 'UUIDField': 'char(32)', } data_types_suffix = { 'AutoField': 'AUTOINCREMENT', 'BigAutoField': 'AUTOINCREMENT', } operators = { 'exact': '= %s', 'iexact': "LIKE %s ESCAPE '\\'", 'contains': "LIKE %s ESCAPE '\\'", 'icontains': "LIKE %s ESCAPE '\\'", 'regex': 'REGEXP %s', 'iregex': "REGEXP '(?i)' || %s", 'gt': '> %s', 'gte': '>= %s', 'lt': '< %s', 'lte': '<= %s', 'startswith': "LIKE %s ESCAPE '\\'", 'endswith': "LIKE %s ESCAPE '\\'", 'istartswith': "LIKE %s ESCAPE '\\'", 'iendswith': "LIKE %s ESCAPE '\\'", }
pattern_esc = r"REPLACE(REPLACE(REPLACE({}, '\', '\\'), '%%', '\%%'), '_', '\_')" pattern_ops = { 'contains': r"LIKE '%%' || {} || '%%' ESCAPE '\'", 'icontains': r"LIKE '%%' || UPPER({}) || '%%' ESCAPE '\'", 'startswith': r"LIKE {} || '%%' ESCAPE '\'", 'istartswith': r"LIKE UPPER({}) || '%%' ESCAPE '\'", 'endswith': r"LIKE '%%' || {} ESCAPE '\'", 'iendswith': r"LIKE '%%' || UPPER({}) ESCAPE '\'", }
if 'check_same_thread' in kwargs and kwargs['check_same_thread']: warnings.warn( 'The `check_same_thread` option was provided and set to ' 'True. It will be overridden with False. Use the ' '`DatabaseWrapper.allow_thread_sharing` property instead ' 'for controlling thread shareability.', RuntimeWarning ) kwargs.update({'check_same_thread': False}) if self.features.can_share_in_memory_db: kwargs.update({'uri': True}) return kwargs
if not self.is_in_memory_db(self.settings_dict['NAME']): BaseDatabaseWrapper.close(self)
return self.features.uses_savepoints and self.in_atomic_block
level = ''
return str(out)
can_use_chunked_reads = False test_db_allows_multiple_connections = False supports_unspecified_pk = True supports_timezones = False supports_1000_query_parameters = False supports_mixed_date_datetime_comparisons = False has_bulk_insert = True can_combine_inserts_with_and_without_auto_increment_pk = False supports_foreign_keys = False supports_column_check_constraints = False autocommits_when_autocommit_is_off = True can_introspect_decimal_field = False can_introspect_positive_integer_field = True can_introspect_small_integer_field = True supports_transactions = True atomic_transactions = False can_rollback_ddl = True supports_paramstyle_pyformat = False supports_sequence_reset = False can_clone_databases = True supports_temporal_subtraction = True
_cursor = complain ensure_connection = complain _commit = complain _rollback = ignore _close = ignore _savepoint = ignore _savepoint_commit = complain _savepoint_rollback = ignore _set_autocommit = complain
try: self.close() except self.db.Database.Error: pass
if not s: return None if ' ' not in s: return typecast_date(s) d, t = s.split() if '-' in t: t, tz = t.split('-', 1) tz = '-' + tz elif '+' in t: t, tz = t.split('+', 1) tz = '+' + tz else: tz = '' dates = d.split('-') times = t.split(':') seconds = times[2]
_check_for_duplicates('fields', (name for name, _ in self.fields)) _check_for_duplicates('bases', ( base._meta.label_lower if hasattr(base, '_meta') else base.lower() if isinstance(base, six.string_types) else base for base in self.bases )) _check_for_duplicates('managers', (name for name, _ in self.managers))
for base in self.bases: if isinstance(base, six.string_types): strings_to_check.append(base.split(".")[-1]) for fname, field in self.fields: if field.remote_field: if isinstance(field.remote_field.model, six.string_types): strings_to_check.append(field.remote_field.model.split(".")[-1]) for string in strings_to_check: if string.lower() == name.lower(): return True return False
if hasattr(operation.field, "remote_field") and operation.field.remote_field: for between in in_between: app_label, object_name = self.model_to_key(operation.field.remote_field.model) if between.references_model(object_name, app_label): return False if getattr(operation.field.remote_field, "through", None): app_label, object_name = self.model_to_key(operation.field.remote_field.through) if between.references_model(object_name, app_label): return False return [ CreateModel( self.name, fields=self.fields + [(operation.name, operation.field)], options=self.options, bases=self.bases, managers=self.managers, ), ]
all_related_objects = ( f for f in model._meta.get_fields(include_hidden=True) if f.auto_created and not f.concrete and (not f.hidden or f.many_to_many) ) state.models[app_label, self.new_name_lower] = state.models[app_label, self.old_name_lower] state.models[app_label, self.new_name_lower].name = self.new_name state.remove_model(app_label, self.old_name_lower) for related_object in all_related_objects: if related_object.model is not model: continue if related_object.related_model == model: related_key = (app_label, self.new_name_lower) else: related_key = ( related_object.related_model._meta.app_label, related_object.related_model._meta.model_name, ) new_fields = [] for name, field in state.models[related_key].fields: if name == related_object.field.name: field = field.clone() field.remote_field.model = "%s.%s" % (app_label, self.new_name) new_fields.append((name, field)) state.models[related_key].fields = new_fields state.reload_model(*related_key) related_models = { f.remote_field.model for f in model._meta.fields if getattr(f.remote_field, 'model', None) } model_name = '%s.%s' % (app_label, self.old_name) for related_model in related_models: if related_model == model: related_key = (app_label, self.new_name_lower) else: related_key = (related_model._meta.app_label, related_model._meta.model_name) new_fields = [] changed = False for name, field in state.models[related_key].fields: if field.is_relation and field.many_to_many and field.remote_field.through == model_name: field = field.clone() field.remote_field.through = '%s.%s' % (app_label, self.new_name) changed = True new_fields.append((name, field)) if changed: state.models[related_key].fields = new_fields state.reload_model(*related_key) state.reload_model(app_label, self.new_name_lower)
schema_editor.alter_db_table( new_model, old_model._meta.db_table, new_model._meta.db_table, ) for related_object in old_model._meta.related_objects: if related_object.related_model == old_model: model = new_model related_key = (app_label, self.new_name_lower) else: model = related_object.related_model related_key = ( related_object.related_model._meta.app_label, related_object.related_model._meta.model_name, ) to_field = to_state.apps.get_model( *related_key )._meta.get_field(related_object.field.name) schema_editor.alter_field( model, related_object.field, to_field, ) fields = zip(old_model._meta.local_many_to_many, new_model._meta.local_many_to_many) for (old_field, new_field) in fields: if new_field.model == new_field.related_model or not new_field.remote_field.through._meta.auto_created: continue old_m2m_model = old_field.remote_field.through new_m2m_model = new_field.remote_field.through schema_editor.alter_db_table( new_m2m_model, old_m2m_model._meta.db_table, new_m2m_model._meta.db_table, ) schema_editor.alter_field( new_m2m_model, old_m2m_model._meta.get_field(old_model._meta.model_name), new_m2m_model._meta.get_field(new_model._meta.model_name), )
return ( super(ModelOperation, self).reduce(operation, in_between, app_label=app_label) or not operation.references_model(self.new_name, app_label) )
for (old_field, new_field) in zip(old_model._meta.local_many_to_many, new_model._meta.local_many_to_many): if new_field.remote_field.through._meta.auto_created: schema_editor.alter_db_table( new_field.remote_field.through, old_field.remote_field.through._meta.db_table, new_field.remote_field.through._meta.db_table, )
if from_model._meta.order_with_respect_to and not to_model._meta.order_with_respect_to: schema_editor.remove_field(from_model, from_model._meta.get_field("_order")) elif to_model._meta.order_with_respect_to and not from_model._meta.order_with_respect_to: field = to_model._meta.get_field("_order") if not field.has_default(): field.default = 0 schema_editor.add_field( from_model, field, )
ALTER_OPTION_KEYS = [ "get_latest_by", "managed", "ordering", "permissions", "default_permissions", "select_on_save", "verbose_name", "verbose_name_plural", ]
reversible = True
reduces_to_sql = True
atomic = False
elidable = False
self = object.__new__(cls) self._constructor_args = (args, kwargs) return self
for database_operation in self.database_operations: to_state = from_state.clone() database_operation.state_forwards(app_label, to_state) database_operation.database_forwards(app_label, schema_editor, from_state, to_state) from_state = to_state
to_states = {} for dbop in self.database_operations: to_states[dbop] = to_state to_state = to_state.clone() dbop.state_forwards(app_label, to_state) for database_operation in reversed(self.database_operations): from_state = to_state to_state = to_states[database_operation] database_operation.database_backwards(app_label, schema_editor, from_state, to_state)
if not callable(code): raise ValueError("RunPython must be supplied with a callable") self.code = code if reverse_code is None: self.reverse_code = None else: if not callable(reverse_code): raise ValueError("RunPython must be supplied with callable arguments") self.reverse_code = reverse_code self.hints = hints or {} self.elidable = elidable
pass
self.code(from_state.apps, schema_editor)
if not self.preserve_default: field = self.field.clone() field.default = NOT_PROVIDED else: field = self.field state.models[app_label, self.model_name_lower].fields.append((self.name, field)) state.reload_model(app_label, self.model_name_lower)
state.models[app_label, self.model_name_lower].fields = [ (self.new_name if n == self.old_name else n, f) for n, f in state.models[app_label, self.model_name_lower].fields ] options = state.models[app_label, self.model_name_lower].options for option in ('index_together', 'unique_together'): if option in options: options[option] = [ [self.new_name if n == self.old_name else n for n in together] for together in options[option] ] state.reload_model(app_label, self.model_name_lower)
return ( super(FieldOperation, self).reduce(operation, in_between, app_label=app_label) or not operation.references_field(self.model_name, self.new_name, app_label) )
enum = None
if getattr(migrations, name, None) == self.operation.__class__: self.feed('migrations.%s(' % name) else: imports.add('import %s' % (self.operation.__class__.__module__)) self.feed('%s.%s(' % (self.operation.__class__.__module__, name))
for arg_name in operation_args[i:]:
operations = [] for operation in self.migration.operations: operation_string, operation_imports = OperationWriter(operation).serialize() imports.update(operation_imports) operations.append(operation_string) items["operations"] = "\n".join(operations) + "\n" if operations else ""
dependencies = [] for dependency in self.migration.dependencies: if dependency[0] == "__setting__": dependencies.append(" migrations.swappable_dependency(settings.%s)," % dependency[1]) imports.add("from django.conf import settings") else: dependency = tuple(force_text(s) for s in dependency) dependencies.append(" %s," % self.serialize(dependency)[0]) items["dependencies"] = "\n".join(dependencies) + "\n" if dependencies else ""
migration_imports = set() for line in list(imports): if re.match("^import (.*)\.\d+[^\s]*$", line): migration_imports.add(line.split("import")[1].strip()) imports.remove(line) self.needs_manual_porting = True
if "from django.db import models" in imports: imports.discard("from django.db import models") imports.add("from django.db import migrations, models") else: imports.add("from django.db import migrations")
sorted_imports = sorted(imports, key=lambda i: i.split()[1]) items["imports"] = "\n".join(sorted_imports) + "\n" if imports else "" if migration_imports: items["imports"] += (
if self.migration.replaces: items['replaces_str'] = "\n replaces = %s\n" % self.serialize(self.migration.replaces)[0] items.update( version=get_version(), timestamp=now().strftime("%Y-%m-%d %H:%M"), )
try: migrations_module = import_module(migrations_package_name) except ImportError: pass else: try: return upath(module_dir(migrations_module)) except ValueError: pass
app_config = apps.get_app_config(self.migration.app_label) maybe_app_name, _, migrations_package_basename = migrations_package_name.rpartition(".") if app_config.name == maybe_app_name: return os.path.join(app_config.path, migrations_package_basename)
existing_dirs, missing_dirs = migrations_package_name.split("."), [] while existing_dirs: missing_dirs.insert(0, existing_dirs.pop(-1)) try: base_module = import_module(".".join(existing_dirs)) except ImportError: continue else: try: base_dir = upath(module_dir(base_module)) except ValueError: continue else: break else: raise ValueError( "Could not locate an appropriate location to create " "migrations package %s. Make sure the toplevel " "package exists and can be imported." % migrations_package_name)
from __future__ import unicode_literals
module_name = self.migrations_module(app_config.label) if module_name is None: self.unmigrated_apps.add(app_config.label) continue was_loaded = module_name in sys.modules try: module = import_module(module_name) except ImportError as e: if "No module named" in str(e) and MIGRATIONS_MODULE_NAME in str(e): self.unmigrated_apps.add(app_config.label) continue raise else: if not hasattr(module, '__file__'): self.unmigrated_apps.add(app_config.label) continue if not hasattr(module, '__path__'): self.unmigrated_apps.add(app_config.label) continue if was_loaded: six.moves.reload_module(module) self.migrated_apps.add(app_config.label) directory = os.path.dirname(module.__file__) migration_names = set() for name in os.listdir(directory): if name.endswith(".py"): import_name = name.rsplit(".", 1)[0] if import_name[0] not in "_.~": migration_names.add(import_name) for migration_name in migration_names: migration_module = import_module("%s.%s" % (module_name, migration_name)) if not hasattr(migration_module, "Migration"): raise BadMigrationError( "Migration %s in app %s has no Migration class" % (migration_name, app_config.label) ) self.disk_migrations[app_config.label, migration_name] = migration_module.Migration( migration_name, app_config.label, )
results = [] for l, n in self.disk_migrations: if l == app_label and n.startswith(name_prefix): results.append((l, n)) if len(results) > 1: raise AmbiguityError( "There is more than one migration for '%s' with the prefix '%s'" % (app_label, name_prefix) ) elif len(results) == 0: raise KeyError("There no migrations for '%s' with the prefix '%s'" % (app_label, name_prefix)) else: return self.disk_migrations[results[0]]
if key[0] == current_app: return if key[0] in self.unmigrated_apps: return if key[0] in self.migrated_apps: try: if key[1] == "__first__": return list(self.graph.root_nodes(key[0]))[0]
continue
if key[0] == parent[0]: continue parent = self.check_key(parent, key[0]) if parent is not None: self.graph.add_dependency(migration, key, parent, skip_validation=True)
self.load_disk() if self.connection is None: self.applied_migrations = set() else: recorder = MigrationRecorder(self.connection) self.applied_migrations = recorder.applied_migrations() self.graph = MigrationGraph() self.replacements = {} for key, migration in self.disk_migrations.items(): self.graph.add_node(key, migration) self.add_internal_dependencies(key, migration) if migration.replaces: self.replacements[key] = migration for key, migration in self.disk_migrations.items(): self.add_external_dependencies(key, migration) for key, migration in self.replacements.items(): applied_statuses = [(target in self.applied_migrations) for target in migration.replaces] if all(applied_statuses): self.applied_migrations.add(key) else: self.applied_migrations.discard(key) if all(applied_statuses) or (not any(applied_statuses)): self.graph.remove_replaced_nodes(key, migration.replaces) else: self.graph.remove_replacement_node(key, migration.replaces) try: self.graph.validate_consistency() except NodeNotFoundError as exc: reverse_replacements = {} for key, migration in self.replacements.items(): for replaced in migration.replaces: reverse_replacements.setdefault(replaced, set()).add(key) if exc.node in reverse_replacements: candidates = reverse_replacements.get(exc.node, set()) is_replaced = any(candidate in self.graph.nodes for candidate in candidates) if not is_replaced: tries = ', '.join('%s.%s' % c for c in candidates) exc_value = NodeNotFoundError( "Migration {0} depends on nonexistent node ('{1}', '{2}'). " "Django tried to replace migration {1}.{2} with any of [{3}] " "but wasn't able to because some of the replaced migrations " "are already applied.".format( exc.origin, exc.node[0], exc.node[1], tries ), exc.node ) exc_value.__cause__ = exc if not hasattr(exc, '__traceback__'): exc.__traceback__ = sys.exc_info()[2] six.reraise(NodeNotFoundError, exc_value, sys.exc_info()[2]) raise exc
if migration not in self.graph.nodes: continue for parent in self.graph.node_map[migration].parents: if parent not in applied: raise InconsistentMigrationHistory( "Migration {}.{} is applied before its dependency {}.{}".format( migration[0], migration[1], parent[0], parent[1], ) )
if self.Migration._meta.db_table in self.connection.introspection.table_names(self.connection.cursor()): return try: with self.connection.schema_editor() as editor: editor.create_model(self.Migration) except DatabaseError as exc: raise MigrationSchemaMissing("Unable to create the django_migrations table (%s)" % exc)
enum = None
value_repr = 'b' + value_repr
if self.value.__name__ == '<lambda>': raise ValueError("Cannot serialize function: lambda") if self.value.__module__ is None: raise ValueError("Cannot serialize function %r: No module" % self.value) if getattr(self.value, "__qualname__", None) and getattr(self.value, "__module__", None):
module_name = self.value.__module__ module = import_module(module_name) if not hasattr(module, self.value.__name__): raise ValueError( "Could not find function %s in %s.\n" "Please note that due to Python 2 limitations, you cannot " "serialize unbound method functions (e.g. a method " "declared and used in the same class body). Please move " "the function into the main module body to use migrations.\n" "For more information, see " "https://docs.djangoproject.com/en/%s/topics/migrations/#serializing-values" % (self.value.__name__, module_name, get_docs_version()) ) if module_name == '__builtin__': return self.value.__name__, set() return "%s.%s" % (module_name, self.value.__name__), {"import %s" % module_name}
func_string, func_imports = serializer_factory(self.value.func).serialize() args_string, args_imports = serializer_factory(self.value.args).serialize() keywords_string, keywords_imports = serializer_factory(self.value.keywords).serialize() imports.update(func_imports) imports.update(args_imports) imports.update(keywords_imports) return ( "functools.partial(%s, *%s, **%s)" % ( func_string, args_string, keywords_string, ), imports, )
value = "(%s)" if len(strings) != 1 else "(%s,)" return value % (", ".join(strings)), imports
return string.rstrip(','), imports
return "set([%s])"
value_repr = value_repr[1:]
return "(%s)" if len(self.value) != 1 else "(%s,)"
value = value.__reduce__()[1][0]
if hasattr(value, 'deconstruct'): return DeconstructableSerializer(value)
if isinstance(value, frozenset): return FrozensetSerializer(value) if isinstance(value, list): return SequenceSerializer(value) if isinstance(value, set): return SetSerializer(value) if isinstance(value, tuple): return TupleSerializer(value) if isinstance(value, dict): return DictionarySerializer(value) if enum and isinstance(value, enum.Enum): return EnumSerializer(value) if isinstance(value, datetime.datetime): return DatetimeSerializer(value) if isinstance(value, datetime.date): return DateSerializer(value) if isinstance(value, datetime.time): return TimeSerializer(value) if isinstance(value, datetime.timedelta): return TimedeltaSerializer(value) if isinstance(value, SettingsReference): return SettingsReferenceSerializer(value) if isinstance(value, float): return FloatSerializer(value) if isinstance(value, six.integer_types + (bool, type(None))): return BaseSimpleSerializer(value) if isinstance(value, six.binary_type): return ByteTypeSerializer(value) if isinstance(value, six.text_type): return TextTypeSerializer(value) if isinstance(value, decimal.Decimal): return DecimalSerializer(value) if isinstance(value, functools.partial): return FunctoolsPartialSerializer(value) if isinstance(value, (types.FunctionType, types.BuiltinFunctionType)): return FunctionTypeSerializer(value) if isinstance(value, collections.Iterable): return IterableSerializer(value) if isinstance(value, (COMPILED_REGEX_TYPE, RegexObject)): return RegexSerializer(value) raise ValueError( "Cannot serialize: %r\nThere are some values Django cannot serialize into " "migration files.\nFor more, see https://docs.djangoproject.com/en/%s/" "topics/migrations/#migration-serializing" % (value, get_docs_version()) )
def ancestors(self): if '_ancestors' not in self.__dict__: ancestors = deque([self.key]) for parent in sorted(self.parents): ancestors.extendleft(reversed(parent.ancestors())) self.__dict__['_ancestors'] = list(OrderedSet(ancestors)) return self.__dict__['_ancestors']
def descendants(self): if '_descendants' not in self.__dict__: descendants = deque([self.key]) for child in sorted(self.children): descendants.extendleft(reversed(child.descendants())) self.__dict__['_descendants'] = list(OrderedSet(descendants)) return self.__dict__['_descendants']
dummy_node = self.node_map.get(key) if dummy_node: dummy_node.promote() else: node = Node(key) self.node_map[key] = node self.nodes[key] = migration self.clear_cache()
replaced = set(replaced) try: replacement_node = self.node_map[replacement] except KeyError as exc: exc_value = NodeNotFoundError( "Unable to find replacement node %r. It was either never added" " to the migration graph, or has been removed." % (replacement, ), replacement ) exc_value.__cause__ = exc if not hasattr(exc, '__traceback__'): exc.__traceback__ = sys.exc_info()[2] six.reraise(NodeNotFoundError, exc_value, sys.exc_info()[2]) for replaced_key in replaced: self.nodes.pop(replaced_key, None) replaced_node = self.node_map.pop(replaced_key, None) if replaced_node: for child in replaced_node.children: child.parents.remove(replaced_node) if child.key not in replaced: replacement_node.add_child(child) child.add_parent(replacement_node) for parent in replaced_node.parents: parent.children.remove(replaced_node) if parent.key not in replaced: replacement_node.add_parent(parent) parent.add_child(replacement_node) self.clear_cache()
replaced_nodes -= replaced_nodes_parents for child in replacement_node.children: child.parents.remove(replacement_node) for replaced_node in replaced_nodes: replaced_node.add_child(child) child.add_parent(replaced_node) for parent in replacement_node.parents: parent.children.remove(replacement_node) self.clear_cache()
self.ensure_not_cyclic(target, lambda x: (parent.key for parent in self.node_map[x].parents)) self.cached = True node = self.node_map[target] try: return node.ancestors() except RuntimeError: warnings.warn(RECURSION_DEPTH_WARNING, RuntimeWarning) return self.iterative_dfs(node)
self.ensure_not_cyclic(target, lambda x: (child.key for child in self.node_map[x].children)) self.cached = True node = self.node_map[target] try: return node.descendants() except RuntimeError: warnings.warn(RECURSION_DEPTH_WARNING, RuntimeWarning) return self.iterative_dfs(node, forwards=False)
stack.extendleft(children)
todo = set(self.nodes) while todo: node = todo.pop() stack = [node] while stack: top = stack[-1] for node in get_children(top): if node in stack: cycle = stack[stack.index(node):] raise CircularDependencyError(", ".join("%s.%s" % n for n in cycle)) if node in todo: stack.append(node) todo.remove(node) break else: node = stack.pop()
if app_label in self.specified_apps: return True try: app_config = apps.get_app_config(app_label)
return self.defaults.get("ask_initial", False)
return None
return None
return None
code = input(prompt)
sys.exit(3)
return NOT_PROVIDED
sys.exit(3)
todo = {node: (dependencies - current) for node, dependencies in todo.items() if node not in current}
self._iterations = 0 while True: result = self.optimize_inner(operations, app_label) self._iterations += 1 if result == operations: return result operations = result
for j, other in enumerate(operations[i + 1:]): in_between = operations[i + 1:i + j + 1] result = operation.reduce(other, in_between, app_label) if isinstance(result, list): new_operations.extend(result) new_operations.extend(in_between) new_operations.extend(operations[i + j + 2:]) return new_operations if not result: new_operations.append(operation) break else: new_operations.append(operation)
operations = []
dependencies = []
run_before = []
replaces = []
initial = None
atomic = True
self.operations = list(self.__class__.operations) self.dependencies = list(self.__class__.dependencies) self.run_before = list(self.__class__.run_before) self.replaces = list(self.__class__.replaces)
if collect_sql: schema_editor.collected_sql.append("--") if not operation.reduces_to_sql: schema_editor.collected_sql.append( "-- MIGRATION NOW PERFORMS OPERATION THAT CANNOT BE WRITTEN AS SQL:" ) schema_editor.collected_sql.append("-- %s" % operation.describe()) schema_editor.collected_sql.append("--") if not operation.reduces_to_sql: continue old_state = project_state.clone() operation.state_forwards(self.app_label, project_state) atomic_operation = operation.atomic or (self.atomic and operation.atomic is not False) if not schema_editor.atomic_migration and atomic_operation: with atomic(schema_editor.connection.alias): operation.database_forwards(self.app_label, schema_editor, old_state, project_state) else: operation.database_forwards(self.app_label, schema_editor, old_state, project_state)
to_run = [] new_state = project_state for operation in self.operations: if not operation.reversible: raise IrreversibleError("Operation %s in %s is not reversible" % (operation, self)) new_state = new_state.clone() old_state = new_state.clone() operation.state_forwards(self.app_label, new_state) to_run.insert(0, (operation, old_state, new_state))
for operation, to_state, from_state in to_run: if collect_sql: schema_editor.collected_sql.append("--") if not operation.reduces_to_sql: schema_editor.collected_sql.append( "-- MIGRATION NOW PERFORMS OPERATION THAT CANNOT BE WRITTEN AS SQL:" ) schema_editor.collected_sql.append("-- %s" % operation.describe()) schema_editor.collected_sql.append("--") if not operation.reduces_to_sql: continue if not schema_editor.connection.features.can_rollback_ddl and operation.atomic: with atomic(schema_editor.connection.alias): operation.database_backwards(self.app_label, schema_editor, from_state, to_state) else: operation.database_backwards(self.app_label, schema_editor, from_state, to_state) return project_state
if target[1] is None: for root in self.loader.graph.root_nodes(): if root[0] == target[0]: for migration in self.loader.graph.backwards_plan(root): if migration in applied: plan.append((self.loader.graph.nodes[migration], True)) applied.remove(migration) elif target in applied: next_in_app = sorted( n for n in self.loader.graph.node_map[target].children if n[0] == target[0] ) for node in next_in_app: for migration in self.loader.graph.backwards_plan(node): if migration in applied: plan.append((self.loader.graph.nodes[migration], True)) applied.remove(migration) else: for migration in self.loader.graph.forwards_plan(target): if migration not in applied: plan.append((self.loader.graph.nodes[migration], False)) applied.add(migration)
full_plan = self.migration_plan(self.loader.graph.leaf_nodes(), clean_start=True)
state = self._create_project_state()
raise InvalidMigrationPlan( "Migration plans with both forwards and backwards migrations " "are not supported. Please split your migration process into " "separate plans of only forwards OR backwards migrations.", plan )
state = self._migrate_all_backwards(plan, full_plan, fake=fake)
break
migration.mutate_state(state, preserve=False) applied_migrations.remove(migration)
states = {} state = self._create_project_state() applied_migrations = { self.loader.graph.nodes[key] for key in self.loader.applied_migrations if key in self.loader.graph.nodes } if self.progress_callback: self.progress_callback("render_start") for migration, _ in full_plan: if not migrations_to_run: break if migration in migrations_to_run: if 'apps' not in state.__dict__:
states[migration] = state state = migration.mutate_state(state, preserve=True) migrations_to_run.remove(migration)
migration.mutate_state(state, preserve=False)
last_unapplied_migration = plan[-1][0] state = states[last_unapplied_migration] for index, (migration, _) in enumerate(full_plan): if migration == last_unapplied_migration: for migration, _ in full_plan[index:]: if migration in applied_migrations: migration.mutate_state(state, preserve=False) break
applied, state = self.detect_soft_applied(state, migration) if applied: fake = True
with self.connection.schema_editor(atomic=migration.atomic) as schema_editor: state = migration.apply(state, schema_editor)
if self.progress_callback: self.progress_callback("apply_success", migration, fake) return state
if migration.replaces: for app_label, name in migration.replaces: self.recorder.record_unapplied(app_label, name) else: self.recorder.record_unapplied(migration.app_label, migration.name) if self.progress_callback: self.progress_callback("unapply_success", migration, fake) return state
if any(app == migration.app_label for app, name in migration.dependencies): return False, project_state
return False, project_state
for operation in migration.operations: if isinstance(operation, migrations.CreateModel): model = apps.get_model(migration.app_label, operation.name) if model._meta.swapped: model = global_apps.get_model(model._meta.swapped) if should_skip_detecting_model(migration, model): continue if model._meta.db_table not in existing_table_names: return False, project_state found_create_model_migration = True elif isinstance(operation, migrations.AddField): model = apps.get_model(migration.app_label, operation.model_name) if model._meta.swapped: model = global_apps.get_model(model._meta.swapped) if should_skip_detecting_model(migration, model): continue
if field.many_to_many: if field.remote_field.through._meta.db_table not in existing_table_names: return False, project_state else: found_add_field_migration = True continue
return (found_create_model_migration or found_add_field_migration), after_state
opts = m._meta if opts.proxy and m in related_fields_models: related_models.append(opts.concrete_model) return related_models
self.real_apps = real_apps or []
self.apps.clear_cache()
related_models = get_related_models_recursive(old_model)
model_state = self.models[(app_label, model_name)] direct_related_models = set() for name, field in model_state.fields: if field.is_relation: if field.remote_field.model == RECURSIVE_RELATIONSHIP_CONSTANT: continue rel_app_label, rel_model_name = _get_app_label_and_model_name(field.related_model, app_label) direct_related_models.add((rel_app_label, rel_model_name.lower()))
related_models.update(direct_related_models) for rel_app_label, rel_model_name in direct_related_models: try: rel_model = self.apps.get_model(rel_app_label, rel_model_name) except LookupError: pass else: related_models.update(get_related_models_recursive(rel_model))
related_models.add((app_label, model_name))
with self.apps.bulk_update(): for rel_app_label, rel_model_name in related_models: self.apps.unregister_model(rel_app_label, rel_model_name)
for model_state in self.apps.real_models: if (model_state.app_label, model_state.name_lower) in related_models: states_to_be_rendered.append(model_state)
for rel_app_label, rel_model_name in related_models: try: model_state = self.models[rel_app_label, rel_model_name] except KeyError: pass else: states_to_be_rendered.append(model_state)
self.apps.render_multiple(states_to_be_rendered)
path = ''
super(AppConfigStub, self).__init__(label, None)
self.real_models = [] for app_label in real_apps: app = global_apps.get_app_config(app_label) for model in app.get_models(): self.real_models.append(ModelState.from_model(model, exclude_rels=True)) app_labels = {model_state.app_label for model_state in models.values()} app_configs = [AppConfigStub(label) for label in sorted(real_apps + list(app_labels))] super(StateApps, self).__init__(app_configs)
from django.core.checks.model_checks import _check_lazy_references ignore = {make_model_tuple(settings.AUTH_USER_MODEL)} if ignore_swappable else set() errors = _check_lazy_references(self, ignore=ignore) if errors: raise ValueError("\n".join(error.msg for error in errors))
ready = self.ready self.ready = False try: yield finally: self.ready = ready self.clear_cache()
if not model_states: return with self.bulk_update(): unrendered_models = model_states while unrendered_models: new_unrendered_models = [] for model in unrendered_models: try: model.render(self) except InvalidBasesError: new_unrendered_models.append(model) if len(new_unrendered_models) == len(unrendered_models): raise InvalidBasesError( "Cannot resolve bases for %r\nThis can happen if you are inheriting models from an " "app with migrations (e.g. contrib.auth)\n in an app with no migrations; see " "https://docs.djangoproject.com/en/%s/topics/migrations/#dependencies " "for more" % (new_unrendered_models, get_docs_version()) ) unrendered_models = new_unrendered_models
clone.real_models = self.real_models return clone
if isinstance(self.fields, dict): raise ValueError("ModelState.fields cannot be a dict - it must be a list of 2-tuples.") for name, field in fields: if hasattr(field, 'model'): raise ValueError( 'ModelState.fields cannot be bound to a model - "%s" is.' % name ) if field.is_relation and hasattr(field.related_model, '_meta'): raise ValueError( 'ModelState.fields cannot refer to a model class - "%s.to" does. ' 'Use a string reference instead.' % name ) if field.many_to_many and hasattr(field.remote_field.through, '_meta'): raise ValueError( 'ModelState.fields cannot refer to a model class - "%s.through" does. ' 'Use a string reference instead.' % name )
fields = [] for field in model._meta.local_fields: if getattr(field, "remote_field", None) and exclude_rels: continue if isinstance(field, OrderWrt): continue name = force_text(field.name, strings_only=True) try: fields.append((name, field.clone())) except TypeError as e: raise TypeError("Couldn't reconstruct field %s on %s: %s" % ( name, model._meta.label, e, )) if not exclude_rels: for field in model._meta.local_many_to_many: name = force_text(field.name, strings_only=True) try: fields.append((name, field.clone())) except TypeError as e: raise TypeError("Couldn't reconstruct m2m field %s on %s: %s" % ( name, model._meta.object_name, e, )) options = {} for name in DEFAULT_NAMES: if name in ["apps", "app_label"]: continue elif name in model._meta.original_attrs: if name == "unique_together": ut = model._meta.original_attrs["unique_together"] options[name] = set(normalize_together(ut)) elif name == "index_together": it = model._meta.original_attrs["index_together"] options[name] = set(normalize_together(it)) else: options[name] = model._meta.original_attrs[name] options = cls.force_text_recursive(options) if exclude_rels: for key in ["unique_together", "index_together", "order_with_respect_to"]: if key in options: del options[key] elif options.get('order_with_respect_to') in {field.name for field in model._meta.private_fields}: del options['order_with_respect_to']
flattened_bases = sorted(set(flatten_bases(model)), key=lambda x: model.__mro__.index(x))
bases = tuple( ( base._meta.label_lower if hasattr(base, "_meta") else base ) for base in flattened_bases ) if not any((isinstance(base, six.string_types) or issubclass(base, models.Model)) for base in bases): bases = (models.Model,)
if not model._default_manager.auto_created: if model._default_manager.use_in_migrations: default_manager = copy.copy(model._default_manager) default_manager._set_creation_counter()
else: default_manager = models.Manager() default_manager.model = model default_manager.name = model._default_manager.name managers.append((force_text(default_manager.name), default_manager))
return cls( model._meta.app_label, model._meta.object_name, fields, options, bases, managers, )
sorted_managers = sorted(self.managers, key=lambda v: v[1].creation_counter) for mgr_name, manager in sorted_managers: mgr_name = force_text(mgr_name) as_manager, manager_path, qs_path, args, kwargs = manager.deconstruct() if as_manager: qs_class = import_string(qs_path) yield mgr_name, qs_class.as_manager() else: manager_class = import_string(manager_path) yield mgr_name, manager_class(*args, **kwargs)
meta_contents = {'app_label': self.app_label, "apps": apps} meta_contents.update(self.options) meta = type(str("Meta"), tuple(), meta_contents) try: bases = tuple( (apps.get_model(base) if isinstance(base, six.string_types) else base) for base in self.bases ) except LookupError: raise InvalidBasesError("Cannot resolve one or more bases from %r" % (self.bases,)) body = {name: field.clone() for name, field in self.fields} body['Meta'] = meta body['__module__'] = "__fake__"
body.update(self.construct_managers())
return type( str(self.name), bases, body, )
return obj
deconstructed = deconstructed[1:]
self.generated_operations = {}
self.old_apps = self.from_state.concrete_apps self.new_apps = self.to_state.apps self.old_model_keys = [] self.old_proxy_keys = [] self.old_unmanaged_keys = [] self.new_model_keys = [] self.new_proxy_keys = [] self.new_unmanaged_keys = [] for al, mn in sorted(self.from_state.models.keys()): model = self.old_apps.get_model(al, mn) if not model._meta.managed: self.old_unmanaged_keys.append((al, mn)) elif al not in self.from_state.real_apps: if model._meta.proxy: self.old_proxy_keys.append((al, mn)) else: self.old_model_keys.append((al, mn))
self.generate_renamed_models()
self._prepare_field_lists() self._generate_through_model_map()
self.generate_deleted_models() self.generate_created_models() self.generate_deleted_proxies() self.generate_created_proxies() self.generate_altered_options() self.generate_altered_managers()
self.generate_renamed_fields() self.generate_removed_fields() self.generate_added_fields() self.generate_altered_fields() self.generate_altered_unique_together() self.generate_altered_index_together() self.generate_altered_db_table() self.generate_altered_order_with_respect_to()
for app_label in sorted(self.generated_operations.keys()): chopped = [] dependencies = set() for operation in list(self.generated_operations[app_label]): deps_satisfied = True operation_dependencies = set() for dep in operation._auto_deps: is_swappable_dep = False if dep[0] == "__setting__": resolved_app_label, resolved_object_name = getattr(settings, dep[1]).split('.') original_dep = dep dep = (resolved_app_label, resolved_object_name.lower(), dep[2], dep[3]) is_swappable_dep = True if dep[0] != app_label and dep[0] != "__setting__": for other_operation in self.generated_operations.get(dep[0], []): if self.check_dependency(other_operation, dep): deps_satisfied = False break if not deps_satisfied: break else: if is_swappable_dep: operation_dependencies.add((original_dep[0], original_dep[1])) elif dep[0] in self.migrations: operation_dependencies.add((dep[0], self.migrations[dep[0]][-1].name)) else: if chop_mode: if graph and graph.leaf_nodes(dep[0]): operation_dependencies.add(graph.leaf_nodes(dep[0])[0]) else: operation_dependencies.add((dep[0], "__first__")) else: deps_satisfied = False if deps_satisfied: chopped.append(operation) dependencies.update(operation_dependencies) self.generated_operations[app_label] = self.generated_operations[app_label][1:] else: break if dependencies or chopped: if not self.generated_operations[app_label] or chop_mode: subclass = type(str("Migration"), (Migration,), {"operations": [], "dependencies": []}) instance = subclass("auto_%i" % (len(self.migrations.get(app_label, [])) + 1), app_label) instance.dependencies = list(dependencies) instance.operations = chopped instance.initial = app_label not in self.existing_apps self.migrations.setdefault(app_label, []).append(instance) chop_mode = False else: self.generated_operations[app_label] = chopped + self.generated_operations[app_label] new_num_ops = sum(len(x) for x in self.generated_operations.values()) if new_num_ops == num_ops: if not chop_mode: chop_mode = True else: raise ValueError("Cannot resolve operation dependencies: %r" % self.generated_operations) num_ops = new_num_ops
dependency_graph = {op: set() for op in ops} for op in ops: for dep in op._auto_deps: if dep[0] == app_label: for op2 in ops: if self.check_dependency(op2, dep): dependency_graph[op].add(op2)
self.generated_operations[app_label] = stable_topological_sort(ops, dependency_graph)
for app_label, migrations in self.migrations.items(): for m1, m2 in zip(migrations, migrations[1:]): m2.dependencies.append((app_label, m1.name))
for app_label, migrations in self.migrations.items(): for migration in migrations: migration.dependencies = list(set(migration.dependencies))
for app_label, migrations in self.migrations.items(): for migration in migrations: migration.operations = MigrationOptimizer().optimize(migration.operations, app_label=app_label)
if dependency[2] is None and dependency[3] is True: return ( isinstance(operation, operations.CreateModel) and operation.name_lower == dependency[1].lower() ) elif dependency[2] is not None and dependency[3] is True: return ( ( isinstance(operation, operations.CreateModel) and operation.name_lower == dependency[1].lower() and any(dependency[2] == x for x, y in operation.fields) ) or ( isinstance(operation, operations.AddField) and operation.model_name_lower == dependency[1].lower() and operation.name_lower == dependency[2].lower() ) ) elif dependency[2] is not None and dependency[3] is False: return ( isinstance(operation, operations.RemoveField) and operation.model_name_lower == dependency[1].lower() and operation.name_lower == dependency[2].lower() ) elif dependency[2] is None and dependency[3] is False: return ( isinstance(operation, operations.DeleteModel) and operation.name_lower == dependency[1].lower() ) elif dependency[2] is not None and dependency[3] == "alter": return ( isinstance(operation, operations.AlterField) and operation.model_name_lower == dependency[1].lower() and operation.name_lower == dependency[2].lower() ) elif dependency[2] is not None and dependency[3] == "order_wrt_unset": return ( isinstance(operation, operations.AlterOrderWithRespectTo) and operation.name_lower == dependency[1].lower() and (operation.order_with_respect_to or "").lower() != dependency[2].lower() ) elif dependency[2] is not None and dependency[3] == "foo_together_change": return ( isinstance(operation, (operations.AlterUniqueTogether, operations.AlterIndexTogether)) and operation.name_lower == dependency[1].lower() ) else: raise ValueError("Can't handle dependency %r" % (dependency, ))
operation._auto_deps = dependencies or [] if beginning: self.generated_operations.setdefault(app_label, []).insert(0, operation) else: self.generated_operations.setdefault(app_label, []).append(operation)
related_fields = {} primary_key_rel = None for field in model_opts.local_fields: if field.remote_field: if field.remote_field.model: if field.primary_key: primary_key_rel = field.remote_field.model elif not field.remote_field.parent_link: related_fields[field.name] = field if (getattr(field.remote_field, "through", None) and not field.remote_field.through._meta.auto_created): related_fields[field.name] = field for field in model_opts.local_many_to_many: if field.remote_field.model: related_fields[field.name] = field if getattr(field.remote_field, "through", None) and not field.remote_field.through._meta.auto_created: related_fields[field.name] = field unique_together = model_state.options.pop('unique_together', None) index_together = model_state.options.pop('index_together', None) order_with_respect_to = model_state.options.pop('order_with_respect_to', None) dependencies = [ (app_label, model_name, None, False), ] for base in model_state.bases: if isinstance(base, six.string_types) and "." in base: base_app_label, base_name = base.split(".", 1) dependencies.append((base_app_label, base_name, None, True)) if primary_key_rel: dependencies.append(( primary_key_rel._meta.app_label, primary_key_rel._meta.object_name, None, True )) self.add_operation( app_label, operations.CreateModel( name=model_state.name, fields=[d for d in model_state.fields if d[0] not in related_fields], options=model_state.options, bases=model_state.bases, managers=model_state.managers, ), dependencies=dependencies, beginning=True, )
if not model_opts.managed: continue
for name, field in sorted(related_fields.items()): dependencies = self._get_dependecies_for_foreign_key(field) dependencies.append((app_label, model_name, None, True)) self.add_operation( app_label, operations.AddField( model_name=model_name, name=name, field=field, ), dependencies=list(set(dependencies)), ) related_dependencies = [ (app_label, model_name, name, True) for name, field in sorted(related_fields.items()) ] related_dependencies.append((app_label, model_name, None, True)) if unique_together: self.add_operation( app_label, operations.AlterUniqueTogether( name=model_name, unique_together=unique_together, ), dependencies=related_dependencies ) if index_together: self.add_operation( app_label, operations.AlterIndexTogether( name=model_name, index_together=index_together, ), dependencies=related_dependencies ) if order_with_respect_to: self.add_operation( app_label, operations.AlterOrderWithRespectTo( name=model_name, order_with_respect_to=order_with_respect_to, ), dependencies=[ (app_label, model_name, order_with_respect_to, True), (app_label, model_name, None, True), ] )
dependencies = [ (app_label, model_name, None, False), ] for base in model_state.bases: if isinstance(base, six.string_types) and "." in base: base_app_label, base_name = base.split(".", 1) dependencies.append((base_app_label, base_name, None, True)) self.add_operation( app_label, operations.CreateModel( name=model_state.name, fields=[], options=model_state.options, bases=model_state.bases, managers=model_state.managers, ), dependencies=dependencies, )
continue
related_fields = {} for field in model._meta.local_fields: if field.remote_field: if field.remote_field.model: related_fields[field.name] = field if (getattr(field.remote_field, "through", None) and not field.remote_field.through._meta.auto_created): related_fields[field.name] = field for field in model._meta.local_many_to_many: if field.remote_field.model: related_fields[field.name] = field if getattr(field.remote_field, "through", None) and not field.remote_field.through._meta.auto_created: related_fields[field.name] = field unique_together = model_state.options.pop('unique_together', None) index_together = model_state.options.pop('index_together', None) if unique_together: self.add_operation( app_label, operations.AlterUniqueTogether( name=model_name, unique_together=None, ) ) if index_together: self.add_operation( app_label, operations.AlterIndexTogether( name=model_name, index_together=None, ) ) for name, field in sorted(related_fields.items()): self.add_operation( app_label, operations.RemoveField( model_name=model_name, name=name, ) ) dependencies = [] for related_object in model._meta.related_objects: related_object_app_label = related_object.related_model._meta.app_label object_name = related_object.related_model._meta.object_name field_name = related_object.field.name dependencies.append((related_object_app_label, object_name, field_name, False)) if not related_object.many_to_many: dependencies.append((related_object_app_label, object_name, field_name, "alter"))
through_user = self.through_users.get((app_label, model_state.name_lower)) if through_user: dependencies.append((through_user[0], through_user[1], through_user[2], False)) self.add_operation( app_label, operations.DeleteModel( name=model_state.name, ), dependencies=list(set(dependencies)), )
field_dec = self.deep_deconstruct(field) for rem_app_label, rem_model_name, rem_field_name in sorted(self.old_field_keys - self.new_field_keys): if rem_app_label == app_label and rem_model_name == model_name: old_field_dec = self.deep_deconstruct(old_model_state.get_field_by_name(rem_field_name)) if field.remote_field and field.remote_field.model and 'to' in old_field_dec[2]: old_rel_to = old_field_dec[2]['to'] if old_rel_to in self.renamed_models_rel: old_field_dec[2]['to'] = self.renamed_models_rel[old_rel_to] if old_field_dec == field_dec: if self.questioner.ask_rename(model_name, rem_field_name, field_name, field): self.add_operation( app_label, operations.RenameField( model_name=model_name, old_name=rem_field_name, new_name=field_name, ) ) self.old_field_keys.remove((rem_app_label, rem_model_name, rem_field_name)) self.old_field_keys.add((app_label, model_name, field_name)) self.renamed_fields[app_label, model_name, field_name] = rem_field_name break
dependencies = [] if field.remote_field and field.remote_field.model: dependencies.extend(self._get_dependecies_for_foreign_key(field)) preserve_default = True time_fields = (models.DateField, models.DateTimeField, models.TimeField) if (not field.null and not field.has_default() and not field.many_to_many and not (field.blank and field.empty_strings_allowed) and not (isinstance(field, time_fields) and field.auto_now)): field = field.clone() if isinstance(field, time_fields) and field.auto_now_add: field.default = self.questioner.ask_auto_now_add_addition(field_name, model_name) else: field.default = self.questioner.ask_not_null_addition(field_name, model_name) preserve_default = False self.add_operation( app_label, operations.AddField( model_name=model_name, name=field_name, field=field, preserve_default=preserve_default, ), dependencies=dependencies, )
dependencies=[ (app_label, model_name, field_name, "order_wrt_unset"), (app_label, model_name, field_name, "foo_together_change"), ],
old_model_name = self.renamed_models.get((app_label, model_name), model_name) old_field_name = self.renamed_fields.get((app_label, model_name, field_name), field_name) old_field = self.old_apps.get_model(app_label, old_model_name)._meta.get_field(old_field_name) new_field = self.new_apps.get_model(app_label, model_name)._meta.get_field(field_name) if hasattr(new_field, "remote_field") and getattr(new_field.remote_field, "model", None): rename_key = ( new_field.remote_field.model._meta.app_label, new_field.remote_field.model._meta.model_name, ) if rename_key in self.renamed_models: new_field.remote_field.model = old_field.remote_field.model if hasattr(new_field, "remote_field") and getattr(new_field.remote_field, "through", None): rename_key = ( new_field.remote_field.through._meta.app_label, new_field.remote_field.through._meta.model_name, ) if rename_key in self.renamed_models: new_field.remote_field.through = old_field.remote_field.through old_field_dec = self.deep_deconstruct(old_field) new_field_dec = self.deep_deconstruct(new_field) if old_field_dec != new_field_dec: both_m2m = old_field.many_to_many and new_field.many_to_many neither_m2m = not old_field.many_to_many and not new_field.many_to_many if both_m2m or neither_m2m: preserve_default = True if (old_field.null and not new_field.null and not new_field.has_default() and not new_field.many_to_many): field = new_field.clone() new_default = self.questioner.ask_not_null_alteration(field_name, model_name) if new_default is not models.NOT_PROVIDED: field.default = new_default preserve_default = False else: field = new_field self.add_operation( app_label, operations.AlterField( model_name=model_name, name=field_name, field=field, preserve_default=preserve_default, ) ) else: self._generate_removed_field(app_label, model_name, field_name) self._generate_added_field(app_label, model_name, field_name)
swappable_setting = getattr(field, 'swappable_setting', None) if swappable_setting is not None: dep_app_label = "__setting__" dep_object_name = swappable_setting else: dep_app_label = field.remote_field.model._meta.app_label dep_object_name = field.remote_field.model._meta.object_name dependencies = [(dep_app_label, dep_object_name, None, True)] if getattr(field.remote_field, "through", None) and not field.remote_field.through._meta.auto_created: dependencies.append(( field.remote_field.through._meta.app_label, field.remote_field.through._meta.object_name, None, True, )) return dependencies
old_value = old_model_state.options.get(option_name) or set() if old_value: old_value = { tuple( self.renamed_fields.get((app_label, model_name, n), n) for n in unique ) for unique in old_value }
set(self.old_unmanaged_keys).intersection(self.new_model_keys)
set(self.old_model_keys).intersection(self.new_unmanaged_keys)
dependencies = [] if new_model_state.options.get("order_with_respect_to"): dependencies.append(( app_label, model_name, new_model_state.options["order_with_respect_to"], True, )) self.add_operation( app_label, operations.AlterOrderWithRespectTo( name=model_name, order_with_respect_to=new_model_state.options.get('order_with_respect_to'), ), dependencies=dependencies, )
app_leaf = None for leaf in leaves: if leaf[0] == app_label: app_leaf = leaf break if app_leaf is None and not self.questioner.ask_initial(app_label): for migration in migrations: name_map[(app_label, migration.name)] = (app_label, "__first__") del changes[app_label] continue if app_leaf is None: next_number = 1 else: next_number = (self.parse_number(app_leaf[1]) or 0) + 1 for i, migration in enumerate(migrations): if i == 0 and app_leaf: migration.dependencies.append(app_leaf) if i == 0 and not app_leaf: new_name = "0001_%s" % migration_name if migration_name else "0001_initial" else: new_name = "%04i_%s" % ( next_number, migration_name or self.suggest_name(migration.operations)[:100], ) name_map[(app_label, migration.name)] = (app_label, new_name) next_number += 1 migration.name = new_name
app_dependencies = {} for app_label, migrations in changes.items(): for migration in migrations: for dep_app_label, name in migration.dependencies: app_dependencies.setdefault(app_label, set()).add(dep_app_label) required_apps = set(app_labels) old_required_apps = None while old_required_apps != required_apps: old_required_apps = set(required_apps) for app_label in list(required_apps): required_apps.update(app_dependencies.get(app_label, set())) for app_label in list(changes.keys()): if app_label not in required_apps: del changes[app_label] return changes
connection.commit_on_exit = True connection.needs_rollback = False if not connection.get_autocommit(): if connection.features.autocommits_when_autocommit_is_off: raise TransactionManagementError( "Your database backend doesn't behave properly when " "autocommit is off. Turn it on before using 'atomic'.") connection.in_atomic_block = True connection.commit_on_exit = False
if self.savepoint and not connection.needs_rollback: sid = connection.savepoint() connection.savepoint_ids.append(sid) else: connection.savepoint_ids.append(None)
connection.in_atomic_block = False
pass
if sid is not None: try: connection.savepoint_commit(sid) except DatabaseError: try: connection.savepoint_rollback(sid) connection.savepoint_commit(sid) except Error: connection.needs_rollback = True raise
try: connection.commit() except DatabaseError: try: connection.rollback() except Error: connection.close() raise
connection.needs_rollback = False if connection.in_atomic_block: if sid is None: connection.needs_rollback = True else: try: connection.savepoint_rollback(sid) connection.savepoint_commit(sid) except Error: connection.needs_rollback = True else: try: connection.rollback() except Error: connection.close()
if not connection.in_atomic_block: if connection.closed_in_transaction: connection.connection = None else: connection.set_autocommit(True) elif not connection.savepoint_ids and not connection.commit_on_exit: if connection.closed_in_transaction: connection.connection = None else: connection.in_atomic_block = False
if callable(using): return Atomic(DEFAULT_DB_ALIAS, savepoint)(using) else: return Atomic(using, savepoint)
if dj_exc_type not in (DataError, IntegrityError): self.wrapper.errors_occurred = True six.reraise(dj_exc_type, dj_exc_value, traceback)
def inner(*args, **kwargs): with self: return func(*args, **kwargs) return inner
if backend_name == 'django.db.backends.postgresql_psycopg2': backend_name = 'django.db.backends.postgresql'
backend_dir = os.path.join(os.path.dirname(upath(__file__)), 'backends') try: builtin_backends = [ name for _, name, ispkg in pkgutil.iter_modules([npath(backend_dir)]) if ispkg and name not in {'base', 'dummy', 'postgresql_psycopg2'} ] except EnvironmentError: builtin_backends = [] if backend_name not in ['django.db.backends.%s' % b for b in builtin_backends]: backend_reprs = map(repr, sorted(builtin_backends)) error_msg = ("%r isn't an available database backend.\n" "Try using 'django.db.backends.XXX', where XXX " "is one of:\n %s\nError was: %s" % (backend_name, ", ".join(backend_reprs), e_user)) raise ImproperlyConfigured(error_msg) else: raise
pass
pass
continue
EMPTY_VALUES = (None, '', [], (), {})
if isinstance(regex, six.string_types): return re.compile(regex, flags) else: assert not flags, "flags must be empty if regex is passed pre-compiled" return regex
ipv4_re = r'(?:25[0-5]|2[0-4]\d|[0-1]?\d?\d)(?:\.(?:25[0-5]|2[0-4]\d|[0-1]?\d?\d)){3}'
hostname_re = r'[a-z' + ul + r'0-9](?:[a-z' + ul + r'0-9-]{0,61}[a-z' + ul + r'0-9])?' domain_re = r'(?:\.(?!-)[a-z' + ul + r'0-9-]{1,63}(?<!-))*' tld_re = (
scheme = value.split('://')[0].lower() if scheme not in self.schemes: raise ValidationError(self.message, code=self.code)
try: super(URLValidator, self).__call__(value) except ValidationError as e: if value: scheme, netloc, path, query, fragment = urlsplit(value) try:
host_match = re.search(r'^\[(.+)\](?::\d{2,5})?$', urlsplit(value).netloc) if host_match: potential_ip = host_match.groups()[0] try: validate_ipv6_address(potential_ip) except ValidationError: raise ValidationError(self.message, code=self.code) url = value
if len(urlsplit(value).netloc) > 253: raise ValidationError(self.message, code=self.code)
r'((?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+)(?:[A-Z0-9-]{2,63}(?<!-))\Z', re.IGNORECASE)
r'\[([A-f0-9:\.]+)\]\Z', re.IGNORECASE)
try: domain_part = domain_part.encode('idna').decode('ascii') if self.validate_domain_part(domain_part): return except UnicodeError: pass raise ValidationError(self.message, code=self.code)
digits = len(digit_tuple) if decimals > digits: digits = decimals whole_digits = digits - decimals
if name is None: name = content.name
while self.exists(name) or (max_length and len(name) > max_length): name = os.path.join(dir_name, "%s_%s%s" % (file_root, get_random_string(7), file_ext)) if max_length is None: continue truncation = len(name) - max_length if truncation > 0: file_root = file_root[:-truncation] if not file_root: raise SuspiciousFileOperation( 'Storage can not find an available filename for "%s". ' 'Please make sure that the corresponding file field ' 'allows sufficient "max_length".' % name ) name = os.path.join(dir_name, "%s_%s%s" % (file_root, get_random_string(7), file_ext)) return name
dirname, filename = os.path.split(filename) return os.path.normpath(os.path.join(dirname, self.get_valid_name(filename)))
warnings.warn( 'Storage.accessed_time() is deprecated. ' 'Storage backends should implement get_accessed_time().', RemovedInDjango20Warning, stacklevel=2, ) dt = self.accessed_time(name) return _possibly_make_aware(dt)
warnings.warn( 'Storage.created_time() is deprecated. ' 'Storage backends should implement get_created_time().', RemovedInDjango20Warning, stacklevel=2, ) dt = self.created_time(name) return _possibly_make_aware(dt)
warnings.warn( 'Storage.modified_time() is deprecated. ' 'Storage backends should implement get_modified_time().', RemovedInDjango20Warning, stacklevel=2, ) dt = self.modified_time(name) return _possibly_make_aware(dt)
if settings.USE_TZ: tz = timezone.get_default_timezone() return timezone.make_aware(dt, tz).astimezone(timezone.utc) else: return dt
directory = os.path.dirname(full_path) if not os.path.exists(directory): try: if self.directory_permissions_mode is not None: old_umask = os.umask(0) try: os.makedirs(directory, self.directory_permissions_mode) finally: os.umask(old_umask) else: os.makedirs(directory) except OSError as e: if e.errno != errno.EEXIST: raise if not os.path.isdir(directory): raise IOError("%s exists and is not a directory." % directory)
if hasattr(content, 'temporary_file_path'): file_move_safe(content.temporary_file_path(), full_path)
else: flags = (os.O_WRONLY | os.O_CREAT | os.O_EXCL | getattr(os, 'O_BINARY', 0)) fd = os.open(full_path, flags, 0o666) _file = None try: locks.lock(fd, locks.LOCK_EX) for chunk in content.chunks(): if _file is None: mode = 'wb' if isinstance(chunk, bytes) else 'wt' _file = os.fdopen(fd, mode) _file.write(chunk) finally: locks.unlock(fd) if _file is not None: _file.close() else: os.close(fd)
name = self.get_available_name(name) full_path = self.path(name)
break
return force_text(name.replace('\\', '/'))
try: os.remove(name) except OSError as e: if e.errno != errno.ENOENT: raise
return datetime.utcfromtimestamp(ts).replace(tzinfo=timezone.utc)
if hasattr(os.path, 'samefile'): try: return os.path.samefile(src, dst) except OSError: return False
return (os.path.normcase(os.path.abspath(src)) == os.path.normcase(os.path.abspath(dst)))
if _samefile(old_file_name, new_file_name): return
if not allow_overwrite and os.access(new_file_name, os.F_OK): raise IOError("Destination file %s exists and allow_overwrite is False" % new_file_name)
pass
with open(old_file_name, 'rb') as old_file: fd = os.open(new_file_name, (os.O_WRONLY | os.O_CREAT | getattr(os, 'O_BINARY', 0) | (os.O_EXCL if not allow_overwrite else 0))) try: locks.lock(fd, locks.LOCK_EX) current_chunk = None while current_chunk != b'': current_chunk = old_file.read(chunk_size) os.write(fd, current_chunk) finally: locks.unlock(fd) os.close(fd) copystat(old_file_name, new_file_name)
if getattr(e, 'winerror', 0) != 32 and getattr(e, 'errno', 0) != 13: raise
if name is not None: name = os.path.basename(name)
if len(name) > 255: name, ext = os.path.splitext(name) ext = ext[:255] name = name[:255 - len(ext)] + ext
raise
return False
chunk_size = 1024 while 1: data = file.read(chunk_size) if not data: break try: p.feed(data) except zlib.error as e: if e.args[0].startswith("Error -5"): pass else: raise except struct.error: pass if p.image: return p.image.size chunk_size *= 2 return (None, None)
if sizeof(c_ulong) != sizeof(c_void_p): ULONG_PTR = c_int64 else: ULONG_PTR = c_ulong PVOID = c_void_p
class _OFFSET(Structure): _fields_ = [ ('Offset', DWORD), ('OffsetHigh', DWORD)]
LockFileEx = windll.kernel32.LockFileEx LockFileEx.restype = BOOL LockFileEx.argtypes = [HANDLE, DWORD, DWORD, DWORD, DWORD, LPOVERLAPPED] UnlockFileEx = windll.kernel32.UnlockFileEx UnlockFileEx.restype = BOOL UnlockFileEx.argtypes = [HANDLE, DWORD, DWORD, DWORD, LPOVERLAPPED]
LOCK_EX = LOCK_SH = LOCK_NB = 0
def lock(f, flags): return False
return True
buffer_ = None for chunk in self.chunks(): for line in chunk.splitlines(True): if buffer_: if endswith_cr(buffer_) and not equals_lf(line): yield buffer_ else: line = buffer_ + line buffer_ = None
if endswith_lf(line): yield line else: buffer_ = line
if content_length > settings.FILE_UPLOAD_MAX_MEMORY_SIZE: self.activated = False else: self.activated = True
unlink = os.unlink
is_compressed = False
compressed = zlib.compress(data) if len(compressed) < (len(data) - 1): data = compressed is_compressed = True
base64d = force_bytes(TimestampSigner(key, salt=salt).unsign(s, max_age=max_age)) decompress = False if base64d[:1] == b'.': base64d = base64d[1:] decompress = True data = b64_decode(base64d) if decompress: data = zlib.decompress(data) return serializer().loads(data)
self.key = key or settings.SECRET_KEY self.sep = force_str(sep) if _SEP_UNSAFE.match(self.sep): raise ValueError( 'Unsafe Signer separator: %r (cannot be empty or consist of ' 'only A-z0-9-_=)' % sep, ) self.salt = force_str(salt or '%s.%s' % (self.__class__.__module__, self.__class__.__name__))
return force_str(signature)
age = time.time() - timestamp if age > max_age: raise SignatureExpired( 'Signature age %s > %s seconds' % (age, max_age))
from __future__ import unicode_literals
return errors
checks = [check for check in checks if not hasattr(check, 'tags') or Tags.database not in check.tags]
warnings.extend(check_resolver(pattern))
warnings.extend(get_warning_for_invalid_pattern(pattern))
from __future__ import unicode_literals
from __future__ import unicode_literals
DEBUG = 10 INFO = 20 WARNING = 30 ERROR = 40 CRITICAL = 50
obj = self.obj._meta.label
from __future__ import unicode_literals
from __future__ import unicode_literals
if not pending_models: return []
args.extend(getattr(operation, 'args', []) or []) keywords.update(getattr(operation, 'keywords', {}) or {}) operation = operation.func
if isinstance(receiver, types.FunctionType): description = "The function '%s'" % receiver.__name__ elif isinstance(receiver, types.MethodType): description = "Bound method '%s.%s'" % (receiver.__self__.__class__.__name__, receiver.__name__) else: description = "An instance of class '%s'" % receiver.__class__.__name__ signal_name = model_signals.get(func.__self__, 'unknown') params = { 'model': '.'.join(model_key), 'receiver': description, 'signal': signal_name, 'model_error': app_model_error(model_key), } return Error(error_msg % params, obj=receiver.__module__, id='signals.E001')
known_lazy = { ('django.db.models.fields.related', 'resolve_related_class'): field_error, ('django.db.models.fields.related', 'set_managed'): None, ('django.dispatch.dispatcher', 'connect'): signal_connect_error, }
from __future__ import unicode_literals
pass
if app_list_value is not None: if model not in app_list_value: app_list_value.append(model)
app_label = label try: app_config = apps.get_app_config(app_label) except LookupError as e: raise CommandError(str(e)) if app_config.models_module is None or app_config in excluded_apps: continue app_list[app_config] = None
if format not in serializers.get_public_serializer_formats(): try: serializers.get_serializer(format) except serializers.SerializerDoesNotExist: pass
if (output and self.stdout.isatty() and options['verbosity'] > 0): progress_output = self.stdout object_count = sum(get_objects(count_only=True)) stream = open(output, 'w') if output else None try: serializers.serialize( format, get_objects(), indent=indent, use_natural_foreign_keys=use_natural_foreign_keys, use_natural_primary_keys=use_natural_primary_keys, stream=stream or self.stdout, progress_output=progress_output, object_count=object_count, ) finally: if stream: stream.close()
for tablename in tablenames: self.create_table(db, tablename, dry_run)
models.CharField(name='cache_key', max_length=255, unique=True, primary_key=True), models.TextField(name='value'), models.DateTimeField(name='expires', db_index=True),
raise CommandError( 'You appear not to have the %r program installed or on your path.' % connection.client.executable_name )
if transaction.get_autocommit(self.using): connections[self.using].close()
self.fixture_count = 0 self.loaded_object_count = 0 self.fixture_object_count = 0 self.models = set()
self.compression_formats = { None: (open, 'rb'), 'gz': (gzip.GzipFile, 'rb'), 'zip': (SingleZipReader, 'r'), } if has_bz2: self.compression_formats['bz2'] = (bz2.BZ2File, 'r')
for fixture_label in fixture_labels: if self.find_fixtures(fixture_label): break else: return
table_names = [model._meta.db_table for model in self.models] try: connection.check_constraints(table_names=table_names) except Exception as e: e.args = ("Problem installing fixtures: %s" % e,) raise
if self.loaded_object_count > 0: sequence_sql = connection.ops.sequence_reset_sql(no_style(), self.models) if sequence_sql: if self.verbosity >= 2: self.stdout.write("Resetting sequences\n") with connection.cursor() as cursor: for line in sequence_sql: cursor.execute(line)
if objects_in_fixture == 0: warnings.warn( "No fixture data found for '%s'. (File format may be " "invalid.)" % fixture_name, RuntimeWarning )
fixture_files_in_dir.append((candidate, fixture_dir, fixture_name))
if len(fixture_files_in_dir) > 1: raise CommandError( "Multiple fixtures named '%s' in %s. Aborting." % (fixture_name, humanize(fixture_dir))) fixture_files.extend(fixture_files_in_dir)
requires_system_checks = False leave_locale_alone = True
os.environ[str("DJANGO_COLORS")] = str("nocolor")
autoreload.raise_last_exception()
shutdown_message = options.get('shutdown_message', '') quit_command = 'CTRL-BREAK' if sys.platform == 'win32' else 'CONTROL-C'
self.check_migrations() now = datetime.now().strftime('%B %d, %Y - %X') if six.PY2: now = now.decode(get_system_encoding()) self.stdout.write(now) self.stdout.write(( "Django version %(version)s, using settings %(settings)r\n" "Starting development server at http://%(addr)s:%(port)s/\n" "Quit the server with %(quit_command)s.\n" ) % { "version": self.get_version(), "settings": settings.SETTINGS_MODULE, "addr": '[%s]' % self.addr if self._raw_ipv6 else self.addr, "port": self.port, "quit_command": quit_command, })
ERRORS = { errno.EACCES: "You don't have permission to access that port.", errno.EADDRINUSE: "That port is already in use.", errno.EADDRNOTAVAIL: "That IP address can't be assigned to.", } try: error_text = ERRORS[e.errno] except KeyError: error_text = force_text(e) self.stderr.write("Error: %s" % error_text) os._exit(1)
BaseRunserverCommand = Command
table_name_filter = options.get('table_name_filter')
if column_name in indexes: if indexes[column_name]['primary_key']: extra_params['primary_key'] = True elif indexes[column_name]['unique']: extra_params['unique'] = True
field_type, field_params, field_notes = self.get_field_type(connection, table_name, row) extra_params.update(field_params) comment_notes.extend(field_notes)
if att_name == 'id' and extra_params == {'primary_key': True}: if field_type == 'AutoField(': continue elif field_type == 'IntegerField(' and not connection.features.can_introspect_autofield: comment_notes.append('AutoField?')
'' if '.' in field_type else 'models.', field_type,
field_notes.append("Field renamed because it contained more than one '_' in a row.")
if type(field_type) is tuple: field_type, new_params = field_type field_params.update(new_params)
if field_type == 'CharField' and row[3]: field_params['max_length'] = int(row[3])
tup = '(' + ', '.join("'%s'" % column_to_field_name[c] for c in columns) + ')' unique_together.append(tup)
from django.conf import settings, global_settings
settings._setup()
loader = MigrationLoader(connections[DEFAULT_DB_ALIAS]) if app_label not in loader.migrated_apps: raise CommandError( "App '%s' does not have migrations (so squashmigrations on " "it makes no sense)" % app_label )
migrations_to_squash = [ loader.get_migration(al, mn) for al, mn in loader.graph.forwards_plan((migration.app_label, migration.name)) if al == migration.app_label ]
if self.verbosity > 0 or self.interactive: self.stdout.write(self.style.MIGRATE_HEADING("Will squash the following migrations:")) for migration in migrations_to_squash: self.stdout.write(" - %s" % migration.name)
operations = [] dependencies = set() first_migration = True for smigration in migrations_to_squash: if smigration.replaces: raise CommandError( "You cannot squash squashed migrations! Please transition " "it to a normal migration first: " "https://docs.djangoproject.com/en/%s/topics/migrations/#squashing-migrations" % get_docs_version() ) operations.extend(smigration.operations) for dependency in smigration.dependencies: if isinstance(dependency, SwappableTuple): if settings.AUTH_USER_MODEL == dependency.setting: dependencies.add(("__setting__", "AUTH_USER_MODEL")) else: dependencies.add(dependency) elif dependency[0] != smigration.app_label or first_migration: dependencies.add(dependency) first_migration = False
replaces = [] for migration in migrations_to_squash: if migration.replaces: replaces.extend(migration.replaces) else: replaces.append((migration.app_label, migration.name))
subclass = type("Migration", (migrations.Migration, ), { "dependencies": dependencies, "operations": new_operations, "replaces": replaces, }) if start_migration_name: new_migration = subclass("%s_squashed_%s" % (start_migration.name, migration.name), app_label) else: new_migration = subclass("0001_squashed_%s" % migration.name, app_label) new_migration.initial = True
writer = MigrationWriter(new_migration) with open(writer.path, "wb") as fh: fh.write(writer.as_string())
if os.name == 'nt': old_path = self.work_path new_path = self.path else: old_path = self.work_path[2:] new_path = self.path[2:]
if os.path.exists(self.work_path): os.unlink(self.work_path)
if lines_list and lines_list[-1]: lines_list.append('') return '\n'.join(lines_list)
lines = dropwhile(len, pot_lines)
if settings.configured: settings.USE_I18N = True else: settings.configure(USE_I18N=True)
if options['no_wrap']: self.msgmerge_options = self.msgmerge_options[:] + ['--no-wrap'] self.msguniq_options = self.msguniq_options[:] + ['--no-wrap'] self.msgattrib_options = self.msgattrib_options[:] + ['--no-wrap'] self.xgettext_options = self.xgettext_options[:] + ['--no-wrap'] if options['no_location']: self.msgmerge_options = self.msgmerge_options[:] + ['--no-location'] self.msguniq_options = self.msguniq_options[:] + ['--no-location'] self.msgattrib_options = self.msgattrib_options[:] + ['--no-location'] self.xgettext_options = self.xgettext_options[:] + ['--no-location']
if os.path.isdir('locale'): self.locale_paths.append(os.path.abspath('locale')) if self.locale_paths: self.default_locale_path = self.locale_paths[0] if not os.path.exists(self.default_locale_path): os.makedirs(self.default_locale_path)
locale_dirs = filter(os.path.isdir, glob.glob('%s/*' % self.default_locale_path)) all_locales = map(os.path.basename, locale_dirs)
if process_all: locales = all_locales else: locales = locale or all_locales locales = set(locales) - set(exclude)
for locale in locales: if self.verbosity > 0: self.stdout.write("processing locale %s\n" % locale) for potfile in potfiles: self.write_po_file(potfile, locale)
out, err, status = popen_wrapper( ['xgettext', '--version'], stdout_encoding=DEFAULT_LOCALE_ENCODING, ) m = re.search(r'(\d+)\.(\d+)\.?(\d+)?', out) if m: return tuple(int(d) for d in m.groups() if d is not None) else: raise CommandError("Unable to get gettext version. Is it installed?")
self.stdout.write(errors)
from __future__ import unicode_literals
options['no_color'] = True return super(Command, self).execute(*args, **options)
connection = connections[options['database']]
executor = MigrationExecutor(connection)
app_label, migration_name = options['app_label'], options['migration_name'] if app_label not in executor.loader.migrated_apps: raise CommandError("App '%s' does not have migrations" % app_label) try: migration = executor.loader.get_migration_by_prefix(app_label, migration_name) except AmbiguityError: raise CommandError("More than one migration matches '%s' in app '%s'. Please be more specific." % ( migration_name, app_label)) except KeyError: raise CommandError("Cannot find a migration matching '%s' from app '%s'. Is it in INSTALLED_APPS?" % ( migration_name, app_label)) targets = [(app_label, migration.name)]
self.output_transaction = migration.atomic
plan = [(executor.loader.graph.nodes[targets[0]], options['backwards'])] sql_statements = executor.collect_sql(plan) return '\n'.join(sql_statements)
db_name = connection.creation.create_test_db(verbosity=verbosity, autoclobber=not interactive, serialize=False)
call_command('loaddata', *fixture_labels, **{'verbosity': verbosity})
shutdown_message = ( '\nServer stopped.\nNote that the test database, %r, has not been ' 'deleted. You can explore it on your own.' % db_name ) use_threading = connection.features.test_db_allows_multiple_connections call_command( 'runserver', addrport=options['addrport'], shutdown_message=shutdown_message, use_reloader=False, use_ipv6=options['use_ipv6'], use_threading=use_threading )
reset_sequences = options.get('reset_sequences', True) allow_cascade = options.get('allow_cascade', False) inhibit_post_migrate = options.get('inhibit_post_migrate', False)
for app_config in apps.get_app_configs(): try: import_module('.management', app_config.name) except ImportError: pass
if sql_list and not inhibit_post_migrate: emit_post_migrate_signal(verbosity, interactive, database)
try: import_module(app_name) except ImportError: pass else: raise CommandError( "%r conflicts with the name of an existing Python module and " "cannot be used as an app name. Please try another name." % app_name )
raise ImportError("No IPython")
imported_objects = {}
import rlcompleter readline.set_completer(rlcompleter.Completer(imported_objects).complete) readline_doc = getattr(readline, '__doc__', '') if readline_doc is not None and 'libedit' in readline_doc: readline.parse_and_bind("bind ^I rl_complete") else: readline.parse_and_bind("tab:complete")
if not options['no_startup']: for pythonrc in (os.environ.get("PYTHONSTARTUP"), '~/.pythonrc.py'): if not pythonrc: continue pythonrc = os.path.expanduser(pythonrc) if not os.path.isfile(pythonrc): continue try: with open(pythonrc) as handle: exec(compile(handle.read(), pythonrc, 'exec'), imported_objects) except NameError: pass code.interact(local=imported_objects)
if options['command']: exec(options['command']) return
try: with open(path, 'a'): os.utime(path, None) except (IOError, OSError): return False return True
for dirpath, dirnames, filenames in os.walk('.', topdown=True): for dirname in dirnames: if dirname == 'locale': basedirs.append(os.path.join(dirpath, dirname))
basedirs = set(map(os.path.abspath, filter(os.path.isdir, basedirs)))
all_locales = [] for basedir in basedirs: locale_dirs = filter(os.path.isdir, glob.glob('%s/*' % basedir)) all_locales.extend(map(os.path.basename, locale_dirs))
locales = locale or all_locales locales = set(locales) - set(exclude)
if i == 0 and not is_writable(npath(base_path + '.mo')): self.stderr.write("The po files under %s are in a seemingly not writable location. " "mo files will not be updated/created." % dirpath) return
from __future__ import unicode_literals
db = options['database'] connection = connections[db]
loader = MigrationLoader(connection, ignore_no_migrations=True) graph = loader.graph if app_names: invalid_apps = [] for app_name in app_names: if app_name not in loader.migrated_apps: invalid_apps.append(app_name) if invalid_apps: raise CommandError("No migrations present for: %s" % (", ".join(invalid_apps))) else: app_names = sorted(loader.migrated_apps) for app_name in app_names: self.stdout.write(app_name, self.style.MIGRATE_LABEL) shown = set() for node in graph.leaf_nodes(app_name): for plan_node in graph.forwards_plan(node): if plan_node not in shown and plan_node[0] == app_name: title = plan_node[1] if graph.nodes[plan_node].replaces: title += " (%s squashed migrations)" % len(graph.nodes[plan_node].replaces) if plan_node in loader.applied_migrations: self.stdout.write(" [X] %s" % title) else: self.stdout.write(" [ ] %s" % title) shown.add(plan_node) if not shown: self.stdout.write(" (no migrations)", self.style.ERROR)
loader = MigrationLoader(connection) graph = loader.graph targets = graph.leaf_nodes() plan = [] seen = set()
for target in targets: for migration in graph.forwards_plan(target): if migration not in seen: node = graph.node_map[migration] plan.append(node) seen.add(migration)
def print_deps(node): out = [] for parent in sorted(node.parents): out.append("%s.%s" % parent.key) if out: return " ... (%s)" % ", ".join(out) return ""
try: import_module(project_name) except ImportError: pass else: raise CommandError( "%r conflicts with the name of an existing Python module and " "cannot be used as a project name. Please try another name." % project_name )
options['secret_key'] = get_random_secret_key()
from __future__ import unicode_literals
for app_config in apps.get_app_configs(): if module_has_submodule(app_config.module, "management"): import_module('.management', app_config.name)
db = options['database'] connection = connections[db]
connection.prepare_database() executor = MigrationExecutor(connection, self.migration_progress_callback)
executor.loader.check_consistent_history(connection)
conflicts = executor.loader.detect_conflicts() if conflicts: name_str = "; ".join( "%s in %s" % (", ".join(names), app) for app, names in conflicts.items() ) raise CommandError( "Conflicting migrations detected; multiple leaf nodes in the " "migration graph: (%s).\nTo fix them run " "'python manage.py makemigrations --merge'" % name_str )
target_app_labels_only = True if options['app_label'] and options['migration_name']: app_label, migration_name = options['app_label'], options['migration_name'] if app_label not in executor.loader.migrated_apps: raise CommandError( "App '%s' does not have migrations." % app_label ) if migration_name == "zero": targets = [(app_label, None)] else: try: migration = executor.loader.get_migration_by_prefix(app_label, migration_name) except AmbiguityError: raise CommandError( "More than one migration matches '%s' in app '%s'. " "Please be more specific." % (migration_name, app_label) ) except KeyError: raise CommandError("Cannot find a migration matching '%s' from app '%s'." % ( migration_name, app_label)) targets = [(app_label, migration.name)] target_app_labels_only = False elif options['app_label']: app_label = options['app_label'] if app_label not in executor.loader.migrated_apps: raise CommandError( "App '%s' does not have migrations." % app_label ) targets = [key for key in executor.loader.graph.leaf_nodes() if key[0] == app_label] else: targets = executor.loader.graph.leaf_nodes()
if self.verbosity >= 1: self.stdout.write(self.style.MIGRATE_HEADING("Operations to perform:")) if run_syncdb: self.stdout.write( self.style.MIGRATE_LABEL(" Synchronize unmigrated apps: ") + (", ".join(sorted(executor.loader.unmigrated_apps))) ) if target_app_labels_only: self.stdout.write( self.style.MIGRATE_LABEL(" Apply all migrations: ") + (", ".join(sorted(set(a for a, n in targets))) or "(none)") ) else: if targets[0][1] is None: self.stdout.write(self.style.MIGRATE_LABEL( " Unapply all migrations: ") + "%s" % (targets[0][0], ) ) else: self.stdout.write(self.style.MIGRATE_LABEL( " Target specific migration: ") + "%s, from %s" % (targets[0][1], targets[0][0]) )
if run_syncdb: if self.verbosity >= 1: self.stdout.write(self.style.MIGRATE_HEADING("Synchronizing apps without migrations:")) self.sync_apps(connection, executor.loader.unmigrated_apps)
if self.verbosity >= 1: self.stdout.write(self.style.MIGRATE_HEADING("Running migrations:")) if not plan: executor.check_replacements() if self.verbosity >= 1: self.stdout.write(" No migrations to apply.") autodetector = MigrationAutodetector( executor.loader.project_state(), ProjectState.from_apps(apps), ) changes = autodetector.changes(graph=executor.loader.graph) if changes: self.stdout.write(self.style.NOTICE( " Your models have changes that are not yet reflected " "in a migration, and so won't be applied." )) self.stdout.write(self.style.NOTICE( " Run 'manage.py makemigrations' to make new " "migrations, and then re-run 'manage.py migrate' to " "apply them." )) post_migrate_apps = pre_migrate_apps else: fake = options['fake'] fake_initial = options['fake_initial'] post_migrate_project_state = executor.migrate( targets, plan, fake=fake, fake_initial=fake_initial ) post_migrate_apps = post_migrate_project_state.apps
with post_migrate_apps.bulk_update(): model_keys = [] for model_state in post_migrate_apps.real_models: model_key = model_state.app_label, model_state.name_lower model_keys.append(model_key) post_migrate_apps.unregister_model(*model_key) post_migrate_apps.render_multiple([ ModelState.from_model(apps.get_model(*model_key)) for model_key in model_keys ])
emit_post_migrate_signal( self.verbosity, self.interactive, connection.alias, apps=post_migrate_apps, plan=plan, )
tables = connection.introspection.table_names(cursor) created_models = set()
all_models = [ (app_config.label, router.get_migratable_models(app_config, connection.alias, include_auto_created=False)) for app_config in apps.get_app_configs() if app_config.models_module is not None and app_config.label in app_labels ]
return not ( (converter(opts.db_table) in tables) or (opts.auto_created and converter(opts.auto_created._meta.db_table) in tables) )
if self.verbosity >= 1: self.stdout.write(" Creating tables...\n") with transaction.atomic(using=connection.alias, savepoint=connection.features.can_rollback_ddl): deferred_sql = [] for app_name, model_list in manifest.items(): for model in model_list: if not model._meta.can_migrate(connection): continue if self.verbosity >= 3: self.stdout.write( " Processing %s.%s model\n" % (app_name, model._meta.object_name) ) with connection.schema_editor() as editor: if self.verbosity >= 1: self.stdout.write(" Creating table %s\n" % model._meta.db_table) editor.create_model(model) deferred_sql.extend(editor.deferred_sql) editor.deferred_sql = [] created_models.add(model)
app_labels = set(app_labels) bad_app_labels = set() for app_label in app_labels: try: apps.get_app_config(app_label) except LookupError: bad_app_labels.add(app_label) if bad_app_labels: for app_label in bad_app_labels: self.stderr.write("App '%s' could not be found. Is it in INSTALLED_APPS?" % app_label) sys.exit(2)
loader = MigrationLoader(None, ignore_no_migrations=True)
for db in connections: loader.check_consistent_history(connections[db])
conflicts = loader.detect_conflicts()
if app_labels: conflicts = { app_label: conflict for app_label, conflict in iteritems(conflicts) if app_label in app_labels }
if self.merge and not conflicts: self.stdout.write("No conflicts detected to merge.") return
if self.merge and conflicts: return self.handle_merge(loader, conflicts)
autodetector = MigrationAutodetector( loader.project_state(), ProjectState.from_apps(apps), questioner, )
if self.empty: if not app_labels: raise CommandError("You must supply at least one app label when using --empty.") changes = { app: [Migration("custom", app)] for app in app_labels } changes = autodetector.arrange_for_graph( changes=changes, graph=loader.graph, migration_name=self.migration_name, ) self.write_migration_files(changes) return
changes = autodetector.changes( graph=loader.graph, trim_to_apps=app_labels or None, convert_apps=app_labels or None, migration_name=self.migration_name, )
if self.verbosity >= 1: if len(app_labels) == 1: self.stdout.write("No changes detected in app '%s'" % app_labels.pop()) elif len(app_labels) > 1: self.stdout.write("No changes detected in apps '%s'" % ("', '".join(app_labels))) else: self.stdout.write("No changes detected")
writer = MigrationWriter(migration) if self.verbosity >= 1: migration_string = os.path.relpath(writer.path) if migration_string.startswith('..'): migration_string = writer.path self.stdout.write(" %s:\n" % (self.style.MIGRATE_LABEL(migration_string),)) for operation in migration.operations: self.stdout.write(" - %s\n" % operation.describe()) if not self.dry_run: migrations_directory = os.path.dirname(writer.path) if not directory_created.get(app_label): if not os.path.isdir(migrations_directory): os.mkdir(migrations_directory) init_path = os.path.join(migrations_directory, "__init__.py") if not os.path.isfile(init_path): open(init_path, "w").close() directory_created[app_label] = True migration_string = writer.as_string() with open(writer.path, "wb") as fh: fh.write(migration_string) elif self.verbosity == 3: self.stdout.write(self.style.MIGRATE_HEADING( "Full migrations file '%s':" % writer.filename) + "\n" ) self.stdout.write("%s\n" % writer.as_string())
merge_migrations = [] for migration_name in migration_names: migration = loader.get_migration(app_label, migration_name) migration.ancestry = [ mig for mig in loader.graph.forwards_plan((app_label, migration_name)) if mig[0] == migration.app_label ] merge_migrations.append(migration)
for migration in merge_migrations: migration.branch = migration.ancestry[common_ancestor_count:] migrations_ops = (loader.get_migration(node_app, node_name).operations for node_app, node_name in migration.branch) migration.merged_operations = sum(migrations_ops, []) if self.verbosity > 0: self.stdout.write(self.style.MIGRATE_HEADING("Merging %s" % app_label)) for migration in merge_migrations: self.stdout.write(self.style.MIGRATE_LABEL(" Branch %s" % migration.name)) for operation in migration.merged_operations: self.stdout.write(" - %s\n" % operation.describe()) if questioner.ask_merge(app_label): numbers = [ MigrationAutodetector.parse_number(migration.name) for migration in merge_migrations ] try: biggest_number = max(x for x in numbers if x is not None) except ValueError: biggest_number = 1 subclass = type("Migration", (Migration, ), { "dependencies": [(app_label, migration.name) for migration in merge_migrations], }) migration_name = "%04i_%s" % ( biggest_number + 1, self.migration_name or ("merge_%s" % get_migration_name_timestamp()) ) new_migration = subclass(migration_name, app_label) writer = MigrationWriter(new_migration)
with open(writer.path, "wb") as fh: fh.write(writer.as_string()) if self.verbosity > 0: self.stdout.write("\nCreated new merge migration %s" % writer.path)
self.stdout.write(self.style.MIGRATE_HEADING( "Full merge migrations file '%s':" % writer.filename) + "\n" ) self.stdout.write("%s\n" % writer.as_string())
command = command_name command_name = command.__class__.__module__.split('.')[-1]
try: app_name = get_commands()[command_name] except KeyError: raise CommandError("Unknown command: %r" % command_name)
command = app_name
parser = command.create_parser('', command_name) opt_mapping = { sorted(s_opt.option_strings)[0].lstrip('-').replace('-', '_'): s_opt.dest for s_opt in parser._actions if s_opt.option_strings } arg_options = {opt_mapping.get(key, key): value for key, value in options.items()} defaults = parser.parse_args(args=[force_text(a) for a in args]) defaults = dict(defaults._get_kwargs(), **arg_options) args = defaults.pop('args', ()) if 'skip_checks' not in options: defaults['skip_checks'] = True
if self.settings_exception is not None: usage.append(style.NOTICE( "Note that only Django core commands are listed " "as settings are not properly configured (error: %s)." % self.settings_exception))
commands = get_commands() try: app_name = commands[subcommand] except KeyError: if os.environ.get('DJANGO_SETTINGS_MODULE'): settings.INSTALLED_APPS else: sys.stderr.write("No Django settings specified.\n") sys.stderr.write( "Unknown command: %r\nType '%s help' for usage.\n" % (subcommand, self.prog_name) ) sys.exit(1) if isinstance(app_name, BaseCommand): klass = app_name else: klass = load_command_class(app_name, subcommand) return klass
if 'DJANGO_AUTO_COMPLETE' not in os.environ: return
if cword == 1: print(' '.join(sorted(filter(lambda x: x.startswith(curr), subcommands)))) elif cwords[0] in subcommands and cwords[0] != 'help': subcommand_cls = self.fetch_command(cwords[0]) if cwords[0] in ('dumpdata', 'sqlmigrate', 'sqlsequencereset', 'test'): try: app_configs = apps.get_app_configs() options.extend((app_config.label, 0) for app_config in app_configs) except ImportError: pass parser = subcommand_cls.create_parser('', cwords[0]) options.extend( (sorted(s_opt.option_strings)[0], s_opt.nargs != 0) for s_opt in parser._actions if s_opt.option_strings ) prev_opts = [x.split('=')[0] for x in cwords[1:cword - 1]] options = [opt for opt in options if opt[0] not in prev_opts]
options = sorted((k, v) for k, v in options if k.startswith(curr)) for option in options: opt_label = option[0] if option[1]: opt_label += '=' print(opt_label)
parser = CommandParser(None, usage="%(prog)s subcommand [options] [args]", add_help=False) parser.add_argument('--settings') parser.add_argument('--pythonpath')
if subcommand in no_settings_commands: settings.configure()
if subcommand == 'runserver' and '--noreload' not in self.argv: try: autoreload.check_errors(django.setup)() except Exception: apps.all_models = defaultdict(OrderedDict) apps.app_configs = OrderedDict() apps.apps_ready = apps.models_ready = apps.ready = True
else: django.setup()
elif subcommand == 'version' or self.argv[1:] == ['--version']: sys.stdout.write(django.get_version() + '\n') elif self.argv[1:] in (['--help'], ['-h']): sys.stdout.write(self.main_help_text() + '\n') else: self.fetch_command(subcommand).run_from_argv(self.argv)
can_import_settings = False url_schemes = ['http', 'https', 'ftp'] leave_locale_alone = True rewrite_template_suffixes = ( ('.py-tpl', '.py'), )
if target is None: top_dir = path.join(os.getcwd(), name) try: os.makedirs(top_dir) except OSError as e: if e.errno == errno.EEXIST: message = "'%s' already exists" % top_dir else: message = e raise CommandError(message) else: top_dir = os.path.abspath(path.expanduser(target)) if not os.path.exists(top_dir): raise CommandError("Destination directory '%s' does not " "exist, please create it first." % top_dir)
from django.conf import settings if not settings.configured: settings.configure()
continue
with open(old_path, 'rb') as template_file: content = template_file.read() if new_path.endswith(extensions) or filename in extra_files: content = content.decode('utf-8') template = Engine().from_string(content) content = template.render(context) content = content.encode('utf-8') with open(new_path, 'wb') as new_file: new_file.write(content)
absolute_path = self.download(template)
if six.PY2: if not re.search(r'^[_a-zA-Z]\w*$', name): if not re.search(r'^[_a-zA-Z]', name): message = 'make sure the name begins with a letter or underscore' else: message = 'use only numbers, letters and underscores' raise CommandError("%r is not a valid %s name. Please %s." % (name, app_or_project, message)) else: if not name.isidentifier(): raise CommandError( "%r is not a valid %s name. Please make sure the name is " "a valid identifier." % (name, app_or_project) )
content_disposition = info.get('content-disposition') if content_disposition: _, params = cgi.parse_header(content_disposition) guessed_filename = params.get('filename') or used_name else: guessed_filename = used_name
ext = self.splitext(guessed_filename)[1] content_type = info.get('content-type') if not ext and content_type: ext = mimetypes.guess_extension(content_type) if ext: guessed_filename += ext
if used_name != guessed_filename: guessed_path = path.join(tempdir, guessed_filename) shutil.move(the_path, guessed_path) return guessed_path
return the_path
return
if (hasattr(self.cmd, 'missing_args_message') and not (args or any(not arg.startswith('-') for arg in args))): self.error(self.cmd.missing_args_message) return super(CommandParser, self).parse_args(args, namespace)
help = ''
_called_from_command_line = False can_import_settings = True
args = cmd_options.pop('args', ()) handle_default_options(options) try: self.execute(*args, **cmd_options) except Exception as e: if options.traceback or not isinstance(e, CommandError): raise
if isinstance(e, SystemCheckError): self.stderr.write(str(e), lambda x: x) else: self.stderr.write('%s: %s' % (e.__class__.__name__, e)) sys.exit(1)
if not self.can_import_settings: raise CommandError("Incompatible values of 'leave_locale_alone' " "(%s) and 'can_import_settings' (%s) command " "options." % (self.leave_locale_alone, self.can_import_settings)) from django.utils import translation saved_locale = translation.get_language() translation.deactivate_all()
return
is_a_tty = hasattr(sys.stdout, 'isatty') and sys.stdout.isatty() if not supported_platform or not is_a_tty: return False return True
for role in termcolors.PALETTES[termcolors.NOCOLOR_PALETTE]: if color_settings: format = color_settings.get(role, {}) style_func = termcolors.make_style(**format) else: def style_func(x): return x setattr(style, role, style_func)
style.ERROR_OUTPUT = style.ERROR
if pathext is None: pathext = os.environ.get('PATHEXT', '.COM;.EXE;.BAT;.CMD').split(os.pathsep) for ext in pathext: if cmd.endswith(ext): pathext = [''] break for p in path: f = os.path.join(p, cmd) if os.path.isfile(f): return f for ext in pathext: fext = f + ext if os.path.isfile(fext): return fext return None
for app_config in apps.get_app_configs(): if app_config.models_module is None: continue if verbosity >= 2: print("Running pre-migrate handlers for application %s" % app_config.label) models.signals.pre_migrate.send( sender=app_config, app_config=app_config, verbosity=verbosity, interactive=interactive, using=db, **kwargs )
for app_config in apps.get_app_configs(): if app_config.models_module is None: continue if verbosity >= 2: print("Running post-migrate handlers for application %s" % app_config.label) models.signals.post_migrate.send( sender=app_config, app_config=app_config, verbosity=verbosity, interactive=interactive, using=db, **kwargs )
try: conf = settings.CACHES[backend] except KeyError: try: import_string(backend) except ImportError as e: raise InvalidCacheBackendError("Could not find backend '%s': %s" % ( backend, e)) location = kwargs.pop('LOCATION', '') params = kwargs else: params = conf.copy() params.update(kwargs) backend = params.pop('BACKEND') location = params.pop('LOCATION', '') backend_cls = import_string(backend)
for cache in caches.all(): cache.close()
if e.errno != errno.ENOENT: raise
filelist = random.sample(filelist, int(num_entries / self._cull_frequency)) for fname in filelist: self._delete(fname)
self.LibraryValueNotFoundException = value_not_found_exception
return 0
timeout = -1
timeout += int(time.time())
return force_str(super(BaseMemcachedCache, self).make_key(key, version))
self._cache.delete(key)
if delta < 0: return self._cache.decr(key, -delta) try: val = self._cache.incr(key, delta)
except self.LibraryValueNotFoundException: val = None if val is None: raise ValueError("Key '%s' not found" % key) return val
if delta < 0: return self._cache.incr(key, -delta) try: val = self._cache.decr(key, delta)
except self.LibraryValueNotFoundException: val = None if val is None: raise ValueError("Key '%s' not found" % key) return val
_caches = {} _expire_info = {} _locks = {}
if six.PY3: b64encoded = b64encoded.decode('latin1') try: with transaction.atomic(using=db): cursor.execute("SELECT cache_key, expires FROM %s " "WHERE cache_key = %%s" % table, [key]) result = cursor.fetchone()
return False
DEFAULT_TIMEOUT = object()
MEMCACHE_MAX_KEY_LENGTH = 250
timeout = -1
return self.get(key, default, version=version)
return self.has_key(key)
return len(self.object_list)
if not isinstance(self.object_list, list): self.object_list = list(self.object_list) return self.object_list[index]
if self.paginator.count == 0: return 0 return (self.paginator.per_page * (self.number - 1)) + 1
if self.number == self.paginator.num_pages: return self.paginator.count return self.number * self.paginator.per_page
super(ValidationError, self).__init__(message, code, params)
elif not hasattr(message, 'message' if six.PY3 else 'code'): message = message.error_list else: message, code, params = message.message, message.code, message.params
if not isinstance(message, ValidationError): message = ValidationError(message) if hasattr(message, 'error_dict'): self.error_list.extend(sum(message.error_dict.values(), [])) else: self.error_list.extend(message.error_list)
getattr(self, 'error_dict')
ISO_8859_1, UTF_8 = str('iso-8859-1'), str('utf-8')
chunk = self._read_limited(size - len(self.buffer))
path_info = '/'
self.path = '%s/%s' % (script_name.rstrip('/'), path_info.replace('/', '', 1)) self.META = environ self.META['PATH_INFO'] = path_info self.META['SCRIPT_NAME'] = script_name self.method = environ['REQUEST_METHOD'].upper() self.content_type, self.content_params = cgi.parse_header(environ.get('CONTENT_TYPE', '')) if 'charset' in self.content_params: try: codecs.lookup(self.content_params['charset']) except LookupError: pass else: self.encoding = self.content_params['charset'] self._post_parse_error = False try: content_length = int(environ.get('CONTENT_LENGTH')) except (ValueError, TypeError): content_length = 0 self._stream = LimitedStream(self.environ['wsgi.input'], content_length) self._read_started = False self.resolver_match = None
raw_query_string = get_bytes_from_wsgi(self.environ, 'QUERY_STRING', '') return http.QueryDict(raw_query_string, encoding=self._encoding)
script_url = get_bytes_from_wsgi(environ, 'SCRIPT_URL', '') if not script_url: script_url = get_bytes_from_wsgi(environ, 'REDIRECT_URL', '')
script_url = _slashes_re.sub(b'/', script_url)
return value.encode(ISO_8859_1) if six.PY3 else value
self._middleware_chain = handler
try: response = callback(request, **dict(param_dict, exception=exception)) except TypeError: warnings.warn( "Error handlers should accept an exception parameter. Update " "your code as this parameter will be required in Django 2.0", RemovedInDjango20Warning, stacklevel=2 ) response = callback(request, **param_dict)
set_urlconf(settings.ROOT_URLCONF)
for middleware_method in self._response_middleware: response = middleware_method(request, response) if response is None: raise ValueError( "%s.process_response didn't return an " "HttpResponse object. It returned None instead." % (middleware_method.__self__.__class__.__name__))
if not getattr(response, 'is_rendered', True) and callable(getattr(response, 'render', None)): response = response.render()
for middleware_method in self._view_middleware: response = middleware_method(request, callback, callback_args, callback_kwargs) if response: return response
if response is None:
elif hasattr(response, 'render') and callable(response.render): for middleware_method in self._template_response_middleware: response = middleware_method(request, response) if response is None: raise ValueError( "%s.process_template_response didn't return an " "HttpResponse object. It returned None instead." % (middleware_method.__self__.__class__.__name__) )
if resolver.urlconf_module is None: six.reraise(*exc_info) callback, param_dict = resolver.resolve_error_handler(500) return callback(request, **param_dict)
for middleware_method in self._request_middleware: response = middleware_method(request) if response: break
from django.core.mail.message import ( DEFAULT_ATTACHMENT_MIME_TYPE, BadHeaderError, EmailMessage, EmailMultiAlternatives, SafeMIMEMultipart, SafeMIMEText, forbid_multi_line_headers, make_msgid, ) from django.core.mail.utils import DNS_NAME, CachedDnsName from django.utils.module_loading import import_string
return False
connection_params = {'local_hostname': DNS_NAME.get_fqdn()} if self.timeout is not None: connection_params['timeout'] = self.timeout if self.use_ssl: connection_params.update({ 'keyfile': self.ssl_keyfile, 'certfile': self.ssl_certfile, }) try: self.connection = connection_class(self.host, self.port, **connection_params)
if not self.use_ssl and self.use_tls: self.connection.ehlo() self.connection.starttls(keyfile=self.ssl_keyfile, certfile=self.ssl_certfile) self.connection.ehlo() if self.username and self.password: self.connection.login(self.username, self.password) return True
self.connection.close()
return
if not isinstance(self.file_path, six.string_types): raise ImproperlyConfigured('Path for saving emails is invalid: %r' % self.file_path) self.file_path = os.path.abspath(self.file_path) if os.path.exists(self.file_path) and not os.path.isdir(self.file_path): raise ImproperlyConfigured( 'Path for saving email messages exists, but is not a directory: %s' % self.file_path ) elif not os.path.exists(self.file_path): try: os.makedirs(self.file_path) except OSError as err: raise ImproperlyConfigured( 'Could not create directory for saving email messages: %s (%s)' % (self.file_path, err) ) if not os.access(self.file_path, os.W_OK): raise ImproperlyConfigured('Could not write to directory: %s' % self.file_path) kwargs['stream'] = None super(EmailBackend, self).__init__(*args, **kwargs)
class CachedDnsName(object): def __str__(self): return self.get_fqdn()
utf8_charset = Charset.Charset('utf-8')
DEFAULT_ATTACHMENT_MIME_TYPE = 'application/octet-stream'
domain = DNS_NAME
ADDRESS_HEADERS = { 'from', 'sender', 'reply-to', 'to', 'cc', 'bcc', 'resent-from', 'resent-sender', 'resent-to', 'resent-cc', 'resent-bcc', }
try: localpart.encode('ascii') except UnicodeEncodeError: localpart = Header(localpart, encoding).encode() domain = domain.encode('idna').decode('ascii')
from email.utils import formataddr if localpart and domain: addr = '@'.join([localpart, domain]) return formataddr((nm, addr))
from email.headerregistry import Address from email.errors import InvalidHeaderDefect, NonASCIILocalPartDefect
name, val = forbid_multi_line_headers(name, val, 'ascii') MIMEMessage.__setitem__(self, name, val)
MIMEText.__init__(self, _text, _subtype, None) del self['Content-Transfer-Encoding'] has_long_lines = any(len(l) > RFC5322_EMAIL_LINE_LENGTH_LIMIT for l in _text.splitlines()) self.set_payload(_text, utf8_charset_qp if has_long_lines else utf8_charset) self.replace_header('Content-Type', 'text/%s; charset="%s"' % (_subtype, _charset))
MIMEText.__init__(self, _text, _subtype)
header_names = [key.lower() for key in self.extra_headers] if 'date' not in header_names: msg['Date'] = formatdate() if 'message-id' not in header_names: msg['Message-ID'] = make_msgid(domain=DNS_NAME) for name, value in self.extra_headers.items():
return 0
pass
if content is None: with open(path, 'rb') as f: content = f.read() mimetype = DEFAULT_ATTACHMENT_MIME_TYPE
if isinstance(content, EmailMessage): content = content.message() elif not isinstance(content, Message): content = message_from_string(content)
attachment = MIMEBase(basetype, subtype) attachment.set_payload(content) Encoders.encode_base64(attachment)
class ServerHandler(simple_server.ServerHandler, object): def handle_error(self): if not is_broken_pipe_error(): super(ServerHandler, self).handle_error()
return self.client_address[0]
if args[0].startswith(str('\x16\x03')): extra['status_code'] = 500 logger.error( "You're accessing the development server over HTTPS, but " "it only supports HTTP.\n", extra=extra, ) return
for k, v in self.headers.items(): if '_' in k: del self.headers[k]
env['PATH_INFO'] = path.decode(ISO_8859_1) if six.PY3 else path
httpd.daemon_threads = True
try: from yaml import CSafeLoader as SafeLoader from yaml import CSafeDumper as SafeDumper except ImportError: from yaml import SafeLoader, SafeDumper
if isinstance(field, models.TimeField) and getattr(obj, field.name) is not None: self._current[field.name] = str(getattr(obj, field.name)) else: super(Serializer, self).handle_field(obj, field)
return super(PythonSerializer, self).getvalue()
six.reraise(DeserializationError, DeserializationError(e), sys.exc_info()[2])
if getattr(obj, field.name) is not None: try: self.xml.characters(field.value_to_string(obj)) except UnserializableContentError: raise ValueError("%s.%s (pk:%s) contains unserializable characters" % ( obj.__class__.__name__, field.name, obj._get_pk_val())) else: self.xml.addQuickElement("None")
related = related.natural_key() for key_value in related: self.xml.startElement("natural", {}) self.xml.characters(smart_text(key_value)) self.xml.endElement("natural")
def handle_m2m(value): natural = value.natural_key() self.xml.startElement("object", {}) for key_value in natural: self.xml.startElement("natural", {}) self.xml.characters(smart_text(key_value)) self.xml.endElement("natural") self.xml.endElement("object")
Model = self._get_model_from_node(node, "model")
data = {} if node.hasAttribute('pk'): data[Model._meta.pk.attname] = Model._meta.pk.to_python( node.getAttribute('pk'))
m2m_data = {}
for field_node in node.getElementsByTagName("field"): field_name = field_node.getAttribute("name") if not field_name: raise base.DeserializationError("<field> node is missing the 'name' attribute")
if self.ignore and field_name not in field_names: continue field = Model._meta.get_field(field_name)
if field.remote_field and isinstance(field.remote_field, models.ManyToManyRel): m2m_data[field.name] = self._handle_m2m_field_node(field_node, field) elif field.remote_field and isinstance(field.remote_field, models.ManyToOneRel): data[field.attname] = self._handle_fk_field_node(field_node, field) else: if field_node.getElementsByTagName('None'): value = None else: value = field.to_python(getInnerText(field_node).strip()) data[field.name] = value
return base.DeserializedObject(obj, m2m_data)
if node.getElementsByTagName('None'): return None else: model = field.remote_field.model if hasattr(model._default_manager, 'get_by_natural_key'): keys = node.getElementsByTagName('natural') if keys: field_value = [getInnerText(k).strip() for k in keys] obj = model._default_manager.db_manager(self.db).get_by_natural_key(*field_value) obj_pk = getattr(obj, field.remote_field.field_name) if field.remote_field.model._meta.pk.remote_field: obj_pk = obj_pk.pk else: field_value = getInnerText(node).strip() obj_pk = model._meta.get_field(field.remote_field.field_name).to_python(field_value) return obj_pk else: field_value = getInnerText(node).strip() return model._meta.get_field(field.remote_field.field_name).to_python(field_value)
field_value = [getInnerText(k).strip() for k in keys] obj_pk = default_manager.db_manager(self.db).get_by_natural_key(*field_value).pk
obj_pk = model._meta.pk.to_python(n.getAttribute('pk'))
inner_text = [] for child in node.childNodes: if child.nodeType == child.TEXT_NODE or child.nodeType == child.CDATA_SECTION_NODE: inner_text.append(child.data) elif child.nodeType == child.ELEMENT_NODE: inner_text.extend(getInnerText(child)) else: pass return "".join(inner_text)
raise EntitiesForbidden(name, None, base, sysid, pubid, notation_name)
BUILTIN_SERIALIZERS = { "xml": "django.core.serializers.xml_serializer", "python": "django.core.serializers.python", "json": "django.core.serializers.json", "yaml": "django.core.serializers.pyyaml", }
model_dependencies = [] models = set() for app_config, model_list in app_list: if model_list is None: model_list = app_config.get_models()
if hasattr(model, 'natural_key'): deps = getattr(model.natural_key, 'dependencies', []) if deps: deps = [apps.get_model(dep) for dep in deps] else: deps = []
for field in model._meta.fields: if field.remote_field: rel_model = field.remote_field.model if hasattr(rel_model, 'natural_key') and rel_model != model: deps.append(rel_model) for field in model._meta.many_to_many: if field.remote_field.through._meta.auto_created: rel_model = field.remote_field.model if hasattr(rel_model, 'natural_key') and rel_model != model: deps.append(rel_model) model_dependencies.append((model, deps))
model_list = [] while model_dependencies: skipped = [] changed = False while model_dependencies: model, deps = model_dependencies.pop()
found = True for candidate in ((d not in models or d in model_list) for d in deps): if not candidate: found = False if found: model_list.append(model) changed = True else: skipped.append((model, deps))
if is_protected_type(value): self._current[field.name] = value else: self._current[field.name] = field.value_to_string(obj)
try: Model = _get_model(d["model"]) except base.DeserializationError: if ignore: continue else: raise data = {} if 'pk' in d: try: data[Model._meta.pk.attname] = Model._meta.pk.to_python(d.get('pk')) except Exception as e: raise base.DeserializationError.WithData(e, d['model'], d.get('pk'), None) m2m_data = {}
for (field_name, field_value) in six.iteritems(d["fields"]):
continue
if field.remote_field and isinstance(field.remote_field, models.ManyToManyRel): model = field.remote_field.model if hasattr(model._default_manager, 'get_by_natural_key'): def m2m_convert(value): if hasattr(value, '__iter__') and not isinstance(value, six.text_type): return model._default_manager.db_manager(db).get_by_natural_key(*value).pk else: return force_text(model._meta.pk.to_python(value), strings_only=True) else: def m2m_convert(v): return force_text(model._meta.pk.to_python(v), strings_only=True)
elif field.remote_field and isinstance(field.remote_field, models.ManyToOneRel): model = field.remote_field.model if field_value is not None: try: default_manager = model._default_manager field_name = field.remote_field.field_name if hasattr(default_manager, 'get_by_natural_key'): if hasattr(field_value, '__iter__') and not isinstance(field_value, six.text_type): obj = default_manager.db_manager(db).get_by_natural_key(*field_value) value = getattr(obj, field.remote_field.field_name) if model._meta.pk.remote_field: value = value.pk else: value = model._meta.get_field(field_name).to_python(field_value) data[field.attname] = value else: data[field.attname] = model._meta.get_field(field_name).to_python(field_value) except Exception as e: raise base.DeserializationError.WithData(e, d['model'], d.get('pk'), field_value) else: data[field.attname] = None
else: try: data[field.name] = field.to_python(field_value) except Exception as e: raise base.DeserializationError.WithData(e, d['model'], d.get('pk'), field_value)
from __future__ import absolute_import, unicode_literals
self.options.update({'use_decimal': False})
self.json_kwargs['separators'] = (',', ': ')
indent = self.options.get("indent") if not self.first: self.stream.write(",") if not indent: self.stream.write(" ") if indent: self.stream.write("\n") json.dump(self.get_dump_object(obj), self.stream, cls=DjangoJSONEncoder, **self.json_kwargs) self._current = None
return super(PythonSerializer, self).getvalue()
six.reraise(DeserializationError, DeserializationError(e), sys.exc_info()[2])
if isinstance(o, datetime.datetime): r = o.isoformat() if o.microsecond: r = r[:23] + r[26:] if r.endswith('+00:00'): r = r[:-6] + 'Z' return r elif isinstance(o, datetime.date): return o.isoformat() elif isinstance(o, datetime.time): if is_aware(o): raise ValueError("JSON can't represent timezone-aware times.") r = o.isoformat() if o.microsecond: r = r[:12] return r elif isinstance(o, decimal.Decimal): return str(o) elif isinstance(o, uuid.UUID): return str(o) elif isinstance(o, Promise): return six.text_type(o) else: return super(DjangoJSONEncoder, self).default(o)
DateTimeAwareJSONEncoder = DjangoJSONEncoder
internal_use_only = False progress_class = ProgressBar
concrete_model = obj._meta.concrete_model for field in concrete_model._meta.local_fields: if field.serialize: if field.remote_field is None: if self.selected_fields is None or field.attname in self.selected_fields: self.handle_field(obj, field) else: if self.selected_fields is None or field.attname[:-3] in self.selected_fields: self.handle_fk_field(obj, field) for field in concrete_model._meta.many_to_many: if field.serialize: if self.selected_fields is None or field.attname in self.selected_fields: self.handle_m2m_field(obj, field) self.end_object(obj) progress_bar.update(count) if self.first: self.first = False
models.Model.save_base(self.object, using=using, raw=True, **kwargs) if self.m2m_data and save_m2m: for accessor_name, object_list in self.m2m_data.items(): getattr(self.object, accessor_name).set(object_list)
self.m2m_data = None
from django.template import engines from django.template.backends.django import DjangoTemplates django_engines = [engine for engine in engines.all() if isinstance(engine, DjangoTemplates)] if len(django_engines) == 1: return django_engines[0].engine elif len(django_engines) == 0: raise ImproperlyConfigured( "No DjangoTemplates backend is configured.") else: raise ImproperlyConfigured( "Several DjangoTemplates backends are configured. " "You must select one explicitly.")
try: return loader(name, dirs) except TemplateDoesNotExist: pass
template = Template(template, origin, template_name, engine=self)
if isinstance(context, Context): return t.render(context) else: return t.render(Context(context))
raise TemplateDoesNotExist(', '.join(not_found))
_dec._decorated_function = getattr(func, '_decorated_function', func)
pos_inf = 1e200 * 1e200 neg_inf = -1e200 * 1e200 nan = (1e200 * 1e200) // (1e200 * 1e200) special_floats = [str(pos_inf), str(neg_inf), str(nan)]
tupl = d.as_tuple() units = len(tupl[1]) - tupl[2] prec = abs(p) + units + 1
sign, digits, exponent = d.quantize(exp, ROUND_HALF_UP, Context(prec=prec)).as_tuple() digits = [six.text_type(digit) for digit in reversed(digits)] while len(digits) <= abs(exponent): digits.append('0') digits.insert(-exponent, '.') if sign: digits.append('-') number = ''.join(reversed(digits)) return mark_safe(formats.number_format(number, abs(p)))
width = six.text_type(len(six.text_type(len(lines)))) if not autoescape or isinstance(value, SafeData): for i, line in enumerate(lines): lines[i] = ("%0" + width + "d. %s") % (i + 1, line) else: for i, line in enumerate(lines): lines[i] = ("%0" + width + "d. %s") % (i + 1, escape(line)) return mark_safe('\n'.join(lines))
warnings.simplefilter('ignore', category=RemovedInDjango20Warning) return mark_for_escaping(value)
yes, no, maybe = bits[0], bits[1], bits[1]
from __future__ import absolute_import
from __future__ import absolute_import
continue
from __future__ import absolute_import
template_dirs = tuple(self.dirs) if self.app_dirs: template_dirs += get_app_template_dirs(self.app_dirname) return template_dirs
pass
from __future__ import absolute_import
from __future__ import absolute_import
raise parser.error_class( "Not expecting '%s' in this position in if tag." % self.id )
raise parser.error_class( "Not expecting '%s' as infix operator in if tag." % self.id )
return False
OPERATORS = { 'or': infix(6, lambda context, x, y: x.eval(context) or y.eval(context)), 'and': infix(7, lambda context, x, y: x.eval(context) and y.eval(context)), 'not': prefix(8, lambda context, x: not x.eval(context)), 'in': infix(9, lambda context, x, y: x.eval(context) in y.eval(context)), 'not in': infix(9, lambda context, x, y: x.eval(context) not in y.eval(context)), 'is': infix(10, lambda context, x, y: x.eval(context) is y.eval(context)), 'is not': infix(10, lambda context, x, y: x.eval(context) is not y.eval(context)), '==': infix(10, lambda context, x, y: x.eval(context) == y.eval(context)), '!=': infix(10, lambda context, x, y: x.eval(context) != y.eval(context)), '>': infix(10, lambda context, x, y: x.eval(context) > y.eval(context)), '>=': infix(10, lambda context, x, y: x.eval(context) >= y.eval(context)), '<': infix(10, lambda context, x, y: x.eval(context) < y.eval(context)), '<=': infix(10, lambda context, x, y: x.eval(context) <= y.eval(context)), }
for key, op in OPERATORS.items(): op.id = key
id = "literal" lbp = 0
l = len(tokens) mapped_tokens = [] i = 0 while i < l: token = tokens[i] if token == "is" and i + 1 < l and tokens[i + 1] == "not": token = "is not"
if self.current_token is not EndToken: raise self.error_class("Unused '%s' at end of if expression." % self.current_token.display()) return retval
if settings.DEBUG: warnings.warn( "A {% csrf_token %} was used in a template, but the context " "did not provide the value. This is usually caused by not " "using RequestContext." ) return ''
context.render_context[self] = itertools_cycle(self.cyclevars)
with context.push(var=output): return self.filter_expr.resolve(context)
loop_dict = context['forloop'] = {'parentloop': parentloop} for i, item in enumerate(values): loop_dict['counter0'] = i loop_dict['counter'] = i + 1 loop_dict['revcounter'] = len_values - i loop_dict['revcounter0'] = len_values - i - 1 loop_dict['first'] = (i == 0) loop_dict['last'] = (i == len_values - 1)
if not isinstance(item, (list, tuple)): len_item = 1 else: len_item = len(item) if num_loopvars != len_item: raise ValueError( "Need {} values to unpack in for loop; got {}. " .format(num_loopvars, len_item), ) try: unpacked_vars = dict(zip(self.loopvars, item)) except TypeError: pass else: pop_context = True context.update(unpacked_vars)
context.pop()
state_frame = self._get_context_stack_frame(context) if self not in state_frame: state_frame[self] = None
compare_to = [var.resolve(context, True) for var in self._varlist]
compare_to = nodelist_true_output = self.nodelist_true.render(context)
return nodelist_true_output or self.nodelist_true.render(context)
if 'forloop' in context: return context['forloop'] else: return context.render_context
context[self.var_name] = obj return self.expression.resolve(context, True)
context[self.var_name] = [] return ''
url = '' try: url = reverse(view_name, args=args, kwargs=kwargs, current_app=current_app) except NoReverseMatch: if self.asvar is None: raise
self.extra_context = extra_context or {} if name: self.extra_context[name] = var
args = token.contents.split() if len(args) != 2: raise TemplateSyntaxError("'autoescape' tag requires exactly one argument.") arg = args[1] if arg not in ('on', 'off'): raise TemplateSyntaxError("'autoescape' argument should be 'on' or 'off'") nodelist = parser.parse(('endautoescape',)) parser.delete_first_token() return AutoEscapeControlNode((arg == 'on'), nodelist)
name = args[1] if not hasattr(parser, '_namedCycleNodes'): raise TemplateSyntaxError("No named cycles in template. '%s' is not defined" % name) if name not in parser._namedCycleNodes: raise TemplateSyntaxError("Named cycle '%s' does not exist" % name) return parser._namedCycleNodes[name]
if args[-3] == "as": if args[-1] != "silent": raise TemplateSyntaxError("Only 'silent' flag is allowed after cycle's name, not '%s'." % args[-1]) as_form = True silent = True args = args[:-1] elif args[-2] == "as": as_form = True silent = False
_, rest = token.contents.split(None, 1) filter_expr = parser.compile_filter("var|%s" % (rest)) for func, unused in filter_expr.filters: filter_name = getattr(func, '_filter_name', None) if filter_name in ('escape', 'safe'): raise TemplateSyntaxError('"filter %s" is not permitted. Use the "autoescape" tag instead.' % filter_name) nodelist = parser.parse(('endfilter',)) parser.delete_first_token() return FilterNode(filter_expr, nodelist)
bits = token.split_contents()[1:] condition = TemplateIfParser(parser, bits).parse() nodelist = parser.parse(('elif', 'else', 'endif')) conditions_nodelists = [(condition, nodelist)] token = parser.next_token()
while token.contents.startswith('elif'): bits = token.split_contents()[1:] condition = TemplateIfParser(parser, bits).parse() nodelist = parser.parse(('elif', 'else', 'endif')) conditions_nodelists.append((condition, nodelist)) token = parser.next_token()
if token.contents == 'else': nodelist = parser.parse(('endif',)) conditions_nodelists.append((None, nodelist)) token = parser.next_token()
if token.contents != 'endif': raise TemplateSyntaxError('Malformed template tag at line {0}: "{1}"'.format(token.lineno, token.contents))
bits = token.contents.split() if len(bits) >= 4 and bits[-2] == "from": name = bits[-1] lib = find_library(parser, name) subset = load_from_library(lib, name, bits[1:-2]) parser.add_library(subset) else: for name in bits[1:]: lib = find_library(parser, name) parser.add_library(lib) return LoadNode()
common = bits[-1] != 'random' if not common: bits.pop() if bits[-1] in ('w', 'p', 'b'): method = bits.pop() else: method = 'b' if len(bits) > 1: count = bits.pop() else: count = '1' count = parser.compile_filter(count) if len(bits) != 1: raise TemplateSyntaxError("Incorrect format for %r tag" % tagname) return LoremNode(count, method, common)
expression = parser.compile_filter(var_name + VARIABLE_ATTRIBUTE_SEPARATOR + bits[3]) return RegroupNode(target, expression, var_name)
bits = token.contents.split() if len(bits) != 2: raise TemplateSyntaxError("'templatetag' statement takes one argument") tag = bits[1] if tag not in TemplateTagNode.mapping: raise TemplateSyntaxError("Invalid templatetag argument: '%s'." " Must be one of: %s" % (tag, list(TemplateTagNode.mapping))) return TemplateTagNode(tag)
_builtin_context_processors = ('django.template.context_processors.csrf',)
return self.flatten() == other.flatten()
return False
self.template = None super(Context, self).__init__(dict_)
self.update({})
self.update({})
processors = (template.engine.template_context_processors + self._processors) updates = {} for processor in processors: updates.update(processor(self.request)) self.dicts[self._processors_index] = updates
self.dicts[self._processors_index] = {}
if hasattr(new_context, '_processors_index'): del new_context._processors_index return new_context
original_context = context context = RequestContext(request, **kwargs) if original_context: context.push(original_context)
FILTER_SEPARATOR = '|' FILTER_ARGUMENT_SEPARATOR = ':' VARIABLE_ATTRIBUTE_SEPARATOR = '.' BLOCK_TAG_START = '{%' BLOCK_TAG_END = '%}' VARIABLE_TAG_START = '{{' VARIABLE_TAG_END = '}}' COMMENT_TAG_START = '{#' COMMENT_TAG_END = '#}' TRANSLATOR_COMMENT_MARK = 'Translators' SINGLE_BRACE_START = '{' SINGLE_BRACE_END = '}'
UNKNOWN_SOURCE = '<unknown source>'
tag_re = (re.compile('(%s.*?%s|%s.*?%s|%s.*?%s)' % (re.escape(BLOCK_TAG_START), re.escape(BLOCK_TAG_END), re.escape(VARIABLE_TAG_START), re.escape(VARIABLE_TAG_END), re.escape(COMMENT_TAG_START), re.escape(COMMENT_TAG_END))))
if engine is None: from .engine import Engine engine = Engine.get_default() if origin is None: origin = Origin(UNKNOWN_SOURCE) self.name = name self.origin = origin self.engine = engine self.source = template_string self.nodelist = self.compile_nodelist()
try: message = force_text(exception.args[0]) except (IndexError, UnicodeDecodeError): message = '(Could not get exception message)'
if bit.startswith(('_("', "_('")): sentinel = bit[2] + ')' trans_bit = [bit] while not bit.endswith(sentinel): bit = next(bits) trans_bit.append(bit) bit = ' '.join(trans_bit) split.append(bit)
block_content = token_string[2:-2].strip() if self.verbatim and block_content == self.verbatim: self.verbatim = False
self.prepend_token(token) return nodelist
try: compile_func = self.tags[command] except KeyError: self.invalid_block_tag(token, command, parse_until) try: compiled_result = compile_func(self, token) except Exception as e: raise self.error(token, e) self.extend_nodelist(nodelist, compiled_result, token) self.command_stack.pop()
if node.must_be_first and nodelist.contains_nontext: raise self.error( token, '%r must be the first tag in the template.' % node, ) if isinstance(nodelist, NodeList) and not isinstance(node, TextNode): nodelist.contains_nontext = True node.token = token node.origin = self.origin nodelist.append(node)
warnings.simplefilter('ignore', category=RemovedInDjango20Warning) obj = mark_for_escaping(new_obj) escape_isnt_last_filter = False
plen = len(provided) + 1 func = getattr(func, '_decorated_function', func)
if plen < (alen - dlen) or plen > alen: raise TemplateSyntaxError("%s requires %d arguments, %d provided" % (name, alen - dlen, plen))
self.literal = float(var)
if '.' not in var and 'e' not in var.lower(): self.literal = int(self.literal)
if var.endswith('.'): raise ValueError
if var.startswith('_(') and var.endswith(')'): self.translate = True var = var[2:-1] try: self.literal = mark_safe(unescape_string_literal(var)) except ValueError: if var.find(VARIABLE_ATTRIBUTE_SEPARATOR + '_') > -1 or var[0] == '_': raise TemplateSyntaxError("Variables and attributes may " "not begin with underscores: '%s'" % var) self.lookups = tuple(var.split(VARIABLE_ATTRIBUTE_SEPARATOR))
value = self._resolve_lookup(context)
value = self.literal
except (TypeError, AttributeError, KeyError, ValueError, IndexError):
if isinstance(current, BaseContext) and getattr(type(current), bit): raise AttributeError current = getattr(current, bit)
if (isinstance(e, AttributeError) and not isinstance(current, BaseContext) and bit in dir(current)): raise
must_be_first = False child_nodelists = ('nodelist',) token = None
contains_nontext = False
return ''
kwarg_re = re.compile(r"(?:(\w+)=)?(.+)")
from __future__ import unicode_literals
continue
if func_supports_parameter(loader.get_template_sources, 'template_dirs'): args.append(template_dirs) for origin in loader.get_template_sources(*args): yield origin
if template_tuple is TemplateDoesNotExist: raise TemplateDoesNotExist(template_name) elif template_tuple is None: template, origin = self.find_template(template_name, template_dirs) if not hasattr(template, 'render'): try: template = Template(template, origin, template_name, self.engine) except TemplateDoesNotExist: self.template_cache[key] = (template, origin) self.template_cache[key] = (template, None) return self.template_cache[key]
return self.load_template(template_name, template_dirs)
if func_supports_parameter(self.get_template_sources, 'template_dirs'): args.append(template_dirs)
return source, display_name
default_name = tpl['BACKEND'].rsplit('.', 2)[-2]
params = params.copy() backend = params.pop('BACKEND') engine_cls = import_string(backend) engine = engine_cls(params)
return tuple(template_dirs)
self.blocks = defaultdict(list)
block = type(self)(block.name, block.nodelist) block.context = context context['block'] = block result = block.nodelist.render(context) if push is not None: block_context.push(self.name, push)
for loader in context.template.engine.template_loaders: if not loader.supports_recursion: history = context.render_context.setdefault( self.context_key, [context.template.origin.template_name], ) if template_name in history: raise ExtendsError( "Cannot extend templates recursively when using " "non-recursive template loaders", ) template = context.template.engine.get_template(template_name) history.append(template_name) return template
return parent
return parent.template
block_context.add_blocks(self.blocks)
for node in compiled_parent.nodelist: if not isinstance(node, TextNode): if not isinstance(node, ExtendsNode): blocks = {n.name: n for n in compiled_parent.nodelist.get_nodes_by_type(BlockNode)} block_context.add_blocks(blocks) break
return compiled_parent._render(context)
if not callable(getattr(template, 'render', None)): template_name = template cache = context.render_context.setdefault(self.context_key, {}) template = cache.get(template_name) if template is None: template = context.template.engine.get_template(template_name) cache[template_name] = template values = { name: var.resolve(context) for name, var in six.iteritems(self.extra_context) } if self.isolated_context: return template.render(context.new(values)) with context.push(**values): return template.render(context)
bits = token.contents.split() if len(bits) != 2: raise TemplateSyntaxError("'%s' tag takes only one argument" % bits[0]) block_name = bits[1] try: if block_name in parser.__loaded_blocks: raise TemplateSyntaxError("'%s' tag with name '%s' appears more than once" % (bits[0], block_name)) parser.__loaded_blocks.append(block_name)
endblock = parser.next_token() acceptable_endblocks = ('endblock', 'endblock %s' % block_name) if endblock.contents not in acceptable_endblocks: parser.invalid_block_tag(endblock, 'endblock', acceptable_endblocks)
return relative_name
return self.tag_function
return self.tag_function(name)
def dec(func): return self.tag(name, func) return dec
self.tags[name] = compile_function return compile_function
def dec(func): return self.filter_function(func, **flags) return dec
return self.filter_function(name, **flags)
def dec(func): return self.filter(name, func, **flags) return dec
self.filters[name] = filter_func for attr in ('expects_localtime', 'is_safe', 'needs_autoescape'): if attr in flags: value = flags[attr] setattr(filter_func, attr, value) if hasattr(filter_func, "_decorated_function"): setattr(filter_func._decorated_function, attr, value) filter_func._filter_name = name return filter_func
return dec
return dec(func)
csrf_token = context.get('csrf_token') if csrf_token is not None: new_context['csrf_token'] = csrf_token return t.render(new_context)
kwarg = token_kwargs([bit], parser) if kwarg: param, value = kwarg.popitem() if param not in params and varkw is None: raise TemplateSyntaxError( "'%s' received unexpected keyword argument '%s'" % (name, param)) elif param in kwargs: raise TemplateSyntaxError( "'%s' received multiple values for keyword argument '%s'" % (name, param)) else: kwargs[str(param)] = value if param in unhandled_params: unhandled_params.remove(param) else: if kwargs: raise TemplateSyntaxError( "'%s' received some positional argument(s) after some " "keyword argument(s)" % name) else: args.append(parser.compile_filter(bit)) try: unhandled_params.pop(0) except IndexError: if varargs is None: raise TemplateSyntaxError( "'%s' received too many positional arguments" % name)
unhandled_params = unhandled_params[:-len(defaults)]
raise TemplateSyntaxError( "'%s' did not receive value(s) for the argument(s): %s" % (name, ", ".join("'%s'" % p for p in unhandled_params)))
self.template_name = template self.context_data = context
self._request = None
super(SimpleTemplateResponse, self).__init__('', content_type, status, charset)
self._is_rendered = False
return 'NOTPROVIDED'
context_extras['sql_queries'] = lazy( lambda: list(itertools.chain(*[connections[x].queries for x in connections])), list )
sitemap_url = reverse('django.contrib.sitemaps.views.index')
sitemap_url = reverse('django.contrib.sitemaps.views.sitemap')
limit = 50000
protocol = None
if self.protocol is not None: protocol = self.protocol if protocol is None: protocol = 'http'
if site is None: if django_apps.is_installed('django.contrib.sites'): Site = django_apps.get_model('sites.Site') try: site = Site.objects.get_current() except Site.DoesNotExist: pass if site is None: raise ImproperlyConfigured( "To use sitemaps, either enable the sites framework or pass " "a Site/RequestSite object in your view." ) domain = site.domain
return self.queryset.filter()
response['Last-Modified'] = http_date(timegm(lastmod))
url = '%s:%s' % (protocol, url)
response['Last-Modified'] = http_date( timegm(feedgen.latest_post_date().utctimetuple()))
return escape(force_text(item))
try: code = six.get_function_code(attr) except AttributeError: code = six.get_function_code(attr.__call__)
data_source = DataSource(data_source)
_mapping = {}
for field in data_source[layer_key].fields: mfield = field.lower() if mfield[-1:] == '_': mfield += 'field' _mapping[mfield] = field gtype = data_source[layer_key].geom_type if multi_geom: gtype.to_multi() _mapping[geom_name] = str(gtype).upper() return _mapping
from django.contrib.gis.utils import ogrinspect shp_file = 'data/mapping_hacks/world_borders.shp' model_name = 'WorldBorders'
if isinstance(data_source, six.string_types): data_source = DataSource(data_source) elif isinstance(data_source, DataSource): pass else: raise TypeError('Data source parameter must be a string or a DataSource object.')
layer = data_source[layer_key] ogr_fields = layer.fields
def process_kwarg(kwarg): if isinstance(kwarg, (list, tuple)): return [s.lower() for s in kwarg] elif kwarg: return [s.lower() for s in ogr_fields] else: return [] null_fields = process_kwarg(null) blank_fields = process_kwarg(blank) decimal_fields = process_kwarg(decimal)
def get_kwargs_str(field_name): kwlist = [] if field_name.lower() in null_fields: kwlist.append('null=True') if field_name.lower() in blank_fields: kwlist.append('blank=True') if kwlist: return ', ' + ', '.join(kwlist) else: return ''
if imports:
mfield = field_name.lower() if mfield[-1:] == '_': mfield += 'field'
kwargs_str = get_kwargs_str(field_name)
if field_name.lower() in decimal_fields: yield ' %s = models.DecimalField(max_digits=%d, decimal_places=%d%s)' % ( mfield, width, precision, kwargs_str ) else: yield ' %s = models.FloatField(%s)' % (mfield, kwargs_str[2:])
gtype = layer.geom_type if multi_geom: gtype.to_multi() geom_field = gtype.django
if srid is None: if layer.srs is None: srid_str = 'srid=-1' else: srid = layer.srs.srid if srid is None: srid_str = 'srid=-1' elif srid == 4326: srid_str = '' else: srid_str = 'srid=%s' % srid else: srid_str = 'srid=%s' % srid
if not isinstance(srs, SpatialReference): srs = SpatialReference(srs)
kwargs = {'srid': srs.srid, 'auth_name': auth_name, 'auth_srid': auth_srid or srs.srid, 'proj4text': srs.proj4, }
srs_field_names = {f.name for f in SpatialRefSys._meta.get_fields()} if 'srtext' in srs_field_names: kwargs['srtext'] = srs.wkt if 'ref_sys_name' in srs_field_names: kwargs['ref_sys_name'] = ref_sys_name or srs.name
try: SpatialRefSys.objects.using(database).get(srid=srs.srid) except SpatialRefSys.DoesNotExist: SpatialRefSys.objects.using(database).create(**kwargs)
coord_fmt = ' '.join([num_fmt, num_fmt])
class LayerMapError(Exception): pass
MULTI_TYPES = {1: OGRGeomType('MultiPoint'), 2: OGRGeomType('MultiLineString'), 3: OGRGeomType('MultiPolygon'), OGRGeomType('Point25D').num: OGRGeomType('MultiPoint25D'), OGRGeomType('LineString25D').num: OGRGeomType('MultiLineString25D'), OGRGeomType('Polygon25D').num: OGRGeomType('MultiPolygon25D'), }
FIELD_TYPES = { models.AutoField: OFTInteger, models.BigAutoField: OFTInteger64, models.IntegerField: (OFTInteger, OFTReal, OFTString), models.FloatField: (OFTInteger, OFTReal), models.DateField: OFTDate, models.DateTimeField: OFTDateTime, models.EmailField: OFTString, models.TimeField: OFTTime, models.DecimalField: (OFTInteger, OFTReal), models.CharField: OFTString, models.SlugField: OFTString, models.TextField: OFTString, models.URLField: OFTString, models.BigIntegerField: (OFTInteger, OFTReal, OFTString), models.SmallIntegerField: (OFTInteger, OFTReal, OFTString), models.PositiveSmallIntegerField: (OFTInteger, OFTReal, OFTString), }
if isinstance(data, six.string_types): self.ds = DataSource(data, encoding=encoding) else: self.ds = data self.layer = self.ds[layer]
self.mapping = mapping self.model = model
self.check_layer()
if connections[self.using].features.supports_transform: self.geo_field = self.geometry_field() else: transform = False
if transform: self.source_srs = self.check_srs(source_srs) self.transform = self.coord_transform() else: self.transform = transform
if encoding: from codecs import lookup lookup(encoding) self.encoding = encoding else: self.encoding = None
self.transaction_mode = transaction_mode if transaction_mode == 'autocommit': self.transaction_decorator = None elif transaction_mode == 'commit_on_success': self.transaction_decorator = transaction.atomic else: raise LayerMapError('Unrecognized transaction mode: %s' % transaction_mode)
def check_fid_range(self, fid_range): "This checks the `fid_range` keyword." if fid_range: if isinstance(fid_range, (tuple, list)): return slice(*fid_range) elif isinstance(fid_range, slice): return fid_range else: raise TypeError else: return None
self.geom_field = False self.fields = {}
ogr_fields = self.layer.fields ogr_field_types = self.layer.field_types
def check_ogr_fld(ogr_map_fld): try: idx = ogr_fields.index(ogr_map_fld) except ValueError: raise LayerMapError('Given mapping OGR field "%s" not found in OGR Layer.' % ogr_map_fld) return idx
for field_name, ogr_name in self.mapping.items(): try: model_field = self.model._meta.get_field(field_name) except FieldDoesNotExist: raise LayerMapError('Given mapping field "%s" not in given Model fields.' % field_name)
fld_name = model_field.__class__.__name__
coord_dim = model_field.dim
ltype = self.layer.geom_type if not (ltype.name.startswith(gtype.name) or self.make_multi(ltype, model_field)): raise LayerMapError('Invalid mapping geometry; model has %s%s, ' 'layer geometry type is %s.' % (fld_name, '(dim=3)' if coord_dim == 3 else '', ltype))
self.geom_field = field_name self.coord_dim = coord_dim fields_val = model_field
rel_model = model_field.remote_field.model for rel_name, ogr_field in ogr_name.items(): idx = check_ogr_fld(ogr_field) try: rel_model._meta.get_field(rel_name) except FieldDoesNotExist: raise LayerMapError('ForeignKey mapping field "%s" not in %s fields.' % (rel_name, rel_model.__class__.__name__)) fields_val = rel_model
if model_field.__class__ not in self.FIELD_TYPES: raise LayerMapError('Django field type "%s" has no OGR mapping (yet).' % fld_name)
idx = check_ogr_fld(ogr_name) ogr_field = ogr_field_types[idx]
if not issubclass(ogr_field, self.FIELD_TYPES[model_field.__class__]): raise LayerMapError('OGR field "%s" (of type %s) cannot be mapped to Django %s.' % (ogr_field, ogr_field.__name__, fld_name)) fields_val = model_field
sr = self.layer.srs
for attr in unique: if attr not in self.mapping: raise ValueError
if unique not in self.mapping: raise ValueError
kwargs = {}
for field_name, ogr_name in self.mapping.items(): model_field = self.fields[field_name]
try: val = self.verify_geom(feat.geom, model_field) except GDALException: raise LayerMapError('Could not retrieve geometry from feature.')
val = self.verify_fk(feat, model_field, ogr_name)
val = self.verify_ogr_field(feat[ogr_name], model_field)
kwargs[field_name] = val
val = force_text(ogr_field.value, self.encoding)
d = Decimal(str(ogr_field.value))
dtup = d.as_tuple() digits = dtup[1]
max_prec = model_field.max_digits - model_field.decimal_places
if d_idx < 0: n_prec = len(digits[:d_idx]) else: n_prec = len(digits) + d_idx
if n_prec > max_prec: raise InvalidDecimal( 'A DecimalField with max_digits %d, decimal_places %d must ' 'round to an absolute value less than 10^%d.' % (model_field.max_digits, model_field.decimal_places, max_prec) ) val = d
try: val = int(ogr_field.value) except ValueError: raise InvalidInteger('Could not construct integer from: %s' % ogr_field.value)
fk_kwargs = {} for field_name, ogr_name in rel_mapping.items(): fk_kwargs[field_name] = self.verify_ogr_field(feat[ogr_name], rel_model._meta.get_field(field_name))
try: return rel_model.objects.using(self.using).get(**fk_kwargs) except ObjectDoesNotExist: raise MissingForeignKey( 'No ForeignKey %s model found with keyword arguments: %s' % (rel_model.__name__, fk_kwargs) )
if self.coord_dim != geom.coord_dim: geom.coord_dim = self.coord_dim
multi_type = self.MULTI_TYPES[geom.geom_type.num] g = OGRGeometry(multi_type) g.add(geom)
if self.transform: g.transform(self.transform)
return g.wkt
def coord_transform(self): "Returns the coordinate transformation object." SpatialRefSys = self.spatial_backend.spatial_ref_sys() try: target_srs = SpatialRefSys.objects.using(self.using).get(srid=self.geo_field.srid).srs
return CoordTransform(self.source_srs, target_srs)
opts = self.model._meta return opts.get_field(self.geom_field)
default_range = self.check_fid_range(fid_range)
if progress: if progress is True or not isinstance(progress, int): progress_interval = 1000 else: progress_interval = progress
try: kwargs = self.feature_kwargs(feat) except LayerMapError as msg: if strict: raise elif not silent: stream.write('Ignoring Feature ID %s because: %s\n' % (feat.fid, msg)) else: is_update = False if self.unique: try: u_kwargs = self.unique_kwargs(kwargs) m = self.model.objects.using(self.using).get(**u_kwargs) is_update = True
geom = getattr(m, self.geom_field).ogr new = OGRGeometry(kwargs[self.geom_field]) for g in new: geom.add(g) setattr(m, self.geom_field, geom.wkt)
m = self.model(**kwargs)
m.save(using=self.using) num_saved += 1 if verbose: stream.write('%s: %s\n' % ('Updated' if is_update else 'Saved', m))
if not silent: stream.write( 'Failed to save the feature (id: %s) into the ' 'model with the keyword arguments:\n' % feat.fid ) stream.write('%s\n' % kwargs) raise
if progress and num_feat % progress_interval == 0: stream.write('Processed %d features, saved %d ...\n' % (num_feat, num_saved))
return num_saved, num_feat
if default_range: raise LayerMapError('The `step` keyword may not be used in conjunction with the `fid_range` keyword.') beg, num_feat, num_saved = (0, 0, 0) indices = range(step, nfeat, step) n_i = len(indices)
if i + 1 == n_i: step_slice = slice(beg, None) else: step_slice = slice(beg, end)
_save()
if isinstance(data_source, str): data_source = DataSource(data_source) elif isinstance(data_source, DataSource): pass else: raise Exception('Data source parameter must be a string or a DataSource object.')
self.locations = self._build_kml_sources(locations)
from django.contrib.gis.sitemaps.kml import KMLSitemap, KMZSitemap
placemarks = klass._default_manager.using(using).annotate(kml=AsKML(field_name))
placemarks = [] if connection.features.has_Transform_function: qs = klass._default_manager.using(using).annotate( **{'%s_4326' % field_name: Transform(field_name, 4326)}) field_name += '_4326' else: qs = klass._default_manager.using(using).all() for mod in qs: mod.kml = getattr(mod, field_name).kml placemarks.append(mod)
if compress: render = render_to_kmz else: render = render_to_kml return render('gis/kml/placemarks.kml', {'places': placemarks})
geo_context = {'LANGUAGE_BIDI': translation.get_language_bidi()} logger = logging.getLogger('django.contrib.gis')
if attrs: self.params.update(attrs) self.params['editable'] = self.params['modifiable'] else: self.params['editable'] = True
self.params['wkt'] = ''
if isinstance(value, six.string_types): try: value = GEOSGeometry(value) except (GEOSException, ValueError) as err: logger.error("Error creating geometry from value '%s' (%s)", value, err) value = None
self.params['map_options'] = self.map_options()
self.params['name'] = name js_safe_name = self.params['name'].replace('-', '_') self.params['module'] = 'geodjango_%s' % js_safe_name
srid = self.params['srid'] if value.srid != srid: try: ogr = value.ogr ogr.transform(srid) wkt = ogr.wkt except GDALException as err: logger.error( "Error transforming geometry from srid '%s' to srid '%s' (%s)", value.srid, srid, err ) wkt = '' else: wkt = value.wkt
self.params['wkt'] = wkt
def ol_bounds(extent): return 'new OpenLayers.Bounds(%s)' % str(extent)
map_types = [('srid', 'projection', 'srid'), ('display_srid', 'displayProjection', 'srid'), ('units', 'units', str), ('max_resolution', 'maxResolution', float), ('max_extent', 'maxExtent', 'bounds'), ('num_zoom', 'numZoomLevels', int), ('max_zoom', 'maxZoomLevels', int), ('min_zoom', 'minZoomLevel', int), ]
map_options = {} for param_name, js_name, option_type in map_types: if self.params.get(param_name, False): if option_type == 'srid': value = ol_projection(self.params[param_name]) elif option_type == 'bounds': value = ol_bounds(self.params[param_name]) elif option_type in (float, int): value = self.params[param_name] elif option_type in (str,): value = '"%s"' % self.params[param_name] else: raise TypeError map_options[js_name] = value return map_options
default_lon = 0 default_lat = 0 default_zoom = 4 display_wkt = False display_srid = False extra_js = [] num_zoom = 18 max_zoom = False min_zoom = False units = False max_resolution = False max_extent = False modifiable = True mouse_position = True scale_text = True layerswitcher = True scrollable = True map_width = 600 map_height = 400 map_srid = 4326 map_template = 'gis/admin/openlayers.html' openlayers_url = 'http://openlayers.org/api/2.13.1/OpenLayers.js' point_zoom = num_zoom - 6 wms_url = 'http://vmap0.tiles.osgeo.org/wms/vmap0' wms_layer = 'basic' wms_name = 'OpenLayers WMS' wms_options = {'format': 'image/jpeg'} debug = False widget = OpenLayersWidget
kwargs['widget'] = self.get_map_widget(db_field) return db_field.formfield(**kwargs)
GEOIP_SETTINGS = { 'GEOIP_PATH': getattr(settings, 'GEOIP_PATH', None), 'GEOIP_CITY': getattr(settings, 'GEOIP_CITY', 'GeoLite2-City.mmdb'), 'GEOIP_COUNTRY': getattr(settings, 'GEOIP_COUNTRY', 'GeoLite2-Country.mmdb'), }
MODE_AUTO = 0 MODE_MMAP_EXT = 1 MODE_MMAP = 2 MODE_FILE = 4 MODE_MEMORY = 8 cache_options = {opt: None for opt in (0, 1, 2, 4, 8)}
_city_file = '' _country_file = ''
_city = None _country = None
if cache in self.cache_options: self._cache = cache else: raise GeoIP2Exception('Invalid GeoIP caching option: %s' % cache)
if not path: path = GEOIP_SETTINGS['GEOIP_PATH'] if not path: raise GeoIP2Exception('GeoIP path must be provided via parameter or the GEOIP_PATH setting.') if not isinstance(path, six.string_types): raise TypeError('Invalid path type: %s' % type(path).__name__)
country_db = os.path.join(path, country or GEOIP_SETTINGS['GEOIP_COUNTRY']) if os.path.isfile(country_db): self._country = geoip2.database.Reader(country_db, mode=cache) self._country_file = country_db
reader = geoip2.database.Reader(path, mode=cache) db_type = reader.metadata().database_type
self._city = reader self._city_file = path
self._country = reader self._country_file = path
if self._reader: self._reader.close()
if not isinstance(query, six.string_types): raise TypeError('GeoIP query must be a string, not type %s' % type(query).__name__)
if city_or_country and not (self._country or self._city): raise GeoIP2Exception('Invalid GeoIP country and city data files.') elif country and not self._country: raise GeoIP2Exception('Invalid GeoIP country data file: %s' % self._country_file) elif city and not self._city: raise GeoIP2Exception('Invalid GeoIP city data file: %s' % self._city_file)
if not (ipv4_re.match(query) or is_valid_ipv6_address(query)): query = socket.gethostbyname(query)
enc_query = self._check_query(query, city_or_country=True) return Country(self._country_or_city(enc_query))
def coords(self, query, ordering=('longitude', 'latitude')): cdict = self.city(query) if cdict is None: return None else: return tuple(cdict[o] for o in ordering)
@property def info(self): "Return information about the GeoIP library and databases in use." meta = self._reader.metadata() return 'GeoIP Library:\n\t%s.%s\n' % (meta.binary_format_major_version, meta.binary_format_minor_version)
try: import numpy except ImportError: numpy = False
try: ds = gdal.DataSource(data_source) except gdal.GDALException as msg: raise CommandError(msg)
from django.contrib.gis.utils.ogrinspect import _ogrinspect, mapping ogr_options = {k: v for k, v in options.items() if k in get_func_args(_ogrinspect) and v is not None} output = [s for s in _ogrinspect(ds, model_name, **ogr_options)]
kwargs = { 'geom_name': options['geom_name'], 'layer_key': options['layer_key'], 'multi_geom': options['multi_geom'], } mapping_dict = mapping(ds, **kwargs) rev_mapping = {v: k for k, v in mapping_dict.items()}
field_type, geo_params = connection.introspection.get_geometry_type(table_name, geo_col) field_params.update(geo_params)
if isinstance(value, six.string_types): value = self.deserialize(value)
if value.srid != self.map_srid: try: ogr = value.ogr ogr.transform(self.map_srid) value = ogr except gdal.GDALException as err: logger.error( "Error transforming geometry from srid '%s' to srid '%s' (%s)", value.srid, self.map_srid, err )
if gdal.HAS_GDAL: return 3857 else: return 900913
self.srid = kwargs.pop('srid', None) self.geom_type = kwargs.pop('geom_type', self.geom_type) super(GeometryField, self).__init__(**kwargs) self.widget.attrs['geom_type'] = self.geom_type
if not value.srid: try: value.srid = self.widget.map_srid except AttributeError: if self.srid: value.srid = self.srid return value
if str(geom.geom_type).upper() != self.geom_type and not self.geom_type == 'GEOMETRY': raise forms.ValidationError(self.error_messages['invalid_geom_type'], code='invalid_geom_type')
if self.srid and self.srid != -1 and self.srid != geom.srid: try: geom.transform(self.srid) except GEOSException: raise forms.ValidationError( self.error_messages['transform_error'], code='transform_error')
if initial and data: data.transform(initial.srid) return not initial.equals_exact(data, tolerance=0.000001) else: return bool(initial) != bool(data)
self.envelope = poly.envelope
self.points = self.latlng_from_coords(poly.shell.coords)
self.stroke_color, self.stroke_opacity, self.stroke_weight = stroke_color, stroke_opacity, stroke_weight
self.fill_color, self.fill_opacity = fill_color, fill_opacity
if isinstance(geom, six.string_types): geom = fromstr(geom) if isinstance(geom, (tuple, list)): geom = Polygon(geom) if isinstance(geom, (LineString, LinearRing)): self.latlngs = self.latlng_from_coords(geom.coords) elif isinstance(geom, Polygon): self.latlngs = self.latlng_from_coords(geom.shell.coords) else: raise TypeError('GPolyline may only initialize on GEOS LineString, LinearRing, and/or Polygon geometries.')
self.envelope = geom.envelope self.color, self.weight, self.opacity = color, weight, opacity super(GPolyline, self).__init__()
return hash(self.__class__) ^ hash(self.varname)
if isinstance(geom, six.string_types): geom = fromstr(geom) if isinstance(geom, (tuple, list)): geom = Point(geom) if isinstance(geom, Point): self.latlng = self.latlng_from_coords(geom.coords) else: raise TypeError('GMarker may only initialize on GEOS Point geometry.') self.envelope = geom.envelope self.title = title self.draggable = draggable self.icon = icon super(GMarker, self).__init__()
GOOGLE_MAPS_URL = 'http://maps.google.com/maps?file=api&v=%s&key='
if not key: try: self.key = settings.GOOGLE_MAPS_API_KEY except AttributeError: raise GoogleMapException( 'Google Maps API Key not found (try adding ' 'GOOGLE_MAPS_API_KEY to your settings).' ) else: self.key = key
if not version: self.version = getattr(settings, 'GOOGLE_MAPS_API_VERSION', '2.x') else: self.version = version
if not api_url: self.api_url = getattr(settings, 'GOOGLE_MAPS_URL', GOOGLE_MAPS_URL) % self.version else: self.api_url = api_url
self.dom_id = dom_id self.extra_context = extra_context self.js_module = js_module self.template = template self.kml_urls = kml_urls
overlay_info = [[GMarker, markers, 'markers'], [GPolygon, polygons, 'polygons'], [GPolyline, polylines, 'polylines']]
self.calc_zoom = False if self.polygons or self.polylines or self.markers: if center is None or zoom is None: self.calc_zoom = True
if zoom is None: zoom = 4 self.zoom = zoom if center is None: center = (0, 0) self.center = center
template = kwargs.pop('template', 'gis/google/google-multi.js')
self.map_template = kwargs.pop('map_template', 'gis/google/google-single.js')
super(GoogleMapSet, self).__init__(**kwargs) self.template = template
if isinstance(args[0], (tuple, list)): self.maps = args[0] else: self.maps = args
self.dom_ids = ['map%d' % i for i in range(len(self.maps))]
tmp = (gmap.template, gmap.dom_id) gmap.template = self.map_template gmap.dom_id = dom_id result.append(gmap.js) gmap.template, gmap.dom_id = tmp
return mark_safe('onload="%s.load()"' % self.js_module)
DTOR = pi / 180. RTOD = 180. / pi
self._tilesize = tilesize
self._nzoom = num_zoom
z *= 2
lon, lat = self.get_lon_lat(lonlat) npix = self._npix[zoom]
px_x = round(npix + (lon * self._degpp[zoom]))
fac = min(max(sin(DTOR * lat), -0.9999), 0.9999)
px_y = round(npix + (0.5 * log((1 + fac) / (1 - fac)) * (-1.0 * self._radpp[zoom])))
return (px_x, px_y)
npix = self._npix[zoom]
lon = (px[0] - npix) / self._degpp[zoom]
lat = RTOD * (2 * atan(exp((px[1] - npix) / (-1.0 * self._radpp[zoom]))) - 0.5 * pi)
return (lon, lat)
delta = self._tilesize / 2
px = self.lonlat_to_pixel(lonlat, zoom)
ll = self.pixel_to_lonlat((px[0] - delta, px[1] - delta), zoom) ur = self.pixel_to_lonlat((px[0] + delta, px[1] + delta), zoom)
return Polygon(LinearRing(ll, (ll[0], ur[1]), ur, (ur[0], ll[1]), ll), srid=4326)
if not isinstance(geom, GEOSGeometry) or geom.srid != 4326: raise TypeError('get_zoom() expects a GEOS Geometry with an SRID of 4326.')
env = geom.envelope env_w, env_h = self.get_width_height(env.extent) center = env.centroid
tile_w, tile_h = self.get_width_height(self.tile(center, z).extent)
if (env_w > tile_w) or (env_h > tile_h): if z == 0: raise GoogleMapException('Geometry width and height should not exceed that of the Earth.') return z - 1
return self._nzoom - 1
ll = Point(extent[:2]) ul = Point(extent[0], extent[3]) ur = Point(extent[2:]) height = ll.distance(ul) width = ul.distance(ur) return width, height
('dma_code', c_int), ('area_code', c_int), ('charset', c_int), ('continent_code', c_char_p), ]
if hasattr(lgeoip, 'GeoIP_lib_version'): GeoIP_lib_version = lgeoip.GeoIP_lib_version GeoIP_lib_version.argtypes = None GeoIP_lib_version.restype = c_char_p else: GeoIP_lib_version = None
GeoIPRecord_delete = lgeoip.GeoIPRecord_delete GeoIPRecord_delete.argtypes = [RECTYPE] GeoIPRecord_delete.restype = None
def check_record(result, func, cargs): if result: rec = result.contents record = {fld: getattr(rec, fld) for fld, ctype in rec._fields_}
encoding = geoip_encodings[record['charset']] for char_field in geoip_char_fields: if record[char_field]: record[char_field] = record[char_field].decode(encoding)
GeoIPRecord_delete(result) return record
GeoIP_open = lgeoip.GeoIP_open GeoIP_open.restype = DBTYPE GeoIP_delete = lgeoip.GeoIP_delete GeoIP_delete.argtypes = [DBTYPE] GeoIP_delete.restype = None
class geoip_char_p(c_char_p): pass
def string_output(func): def _err_check(result, func, cargs): if result: return result.decode(GEOIP_DEFAULT_ENCODING) return result func.restype = c_char_p func.errcheck = _err_check return func
GEOIP_SETTINGS = {key: getattr(settings, key) for key in ('GEOIP_PATH', 'GEOIP_LIBRARY_PATH', 'GEOIP_COUNTRY', 'GEOIP_CITY') if hasattr(settings, key)} lib_path = GEOIP_SETTINGS.get('GEOIP_LIBRARY_PATH')
if lib_path: lib_name = None else: lib_name = 'GeoIP'
if lib_name: lib_path = find_library(lib_name) if lib_path is None: raise RuntimeError('Could not find the GeoIP library (tried "%s"). ' 'Try setting GEOIP_LIBRARY_PATH in your settings.' % lib_name) lgeoip = CDLL(lib_path)
if os.name == 'nt': libc = CDLL('msvcrt') else: libc = CDLL(None) free = libc.free
free_regex = re.compile(r'^GEO-\d{3}FREE') lite_regex = re.compile(r'^GEO-\d{3}LITE')
GEOIP_STANDARD = 0 GEOIP_MEMORY_CACHE = 1 GEOIP_CHECK_CACHE = 2 GEOIP_INDEX_CACHE = 4 GEOIP_MMAP_CACHE = 8 cache_options = {opt: None for opt in (0, 1, 2, 4, 8)}
_city_file = '' _country_file = ''
_city = None _country = None
if cache in self.cache_options: self._cache = cache else: raise GeoIPException('Invalid GeoIP caching option: %s' % cache)
if not path: path = GEOIP_SETTINGS.get('GEOIP_PATH') if not path: raise GeoIPException('GeoIP path must be provided via parameter or the GEOIP_PATH setting.') if not isinstance(path, six.string_types): raise TypeError('Invalid path type: %s' % type(path).__name__)
country_db = os.path.join(path, country or GEOIP_SETTINGS.get('GEOIP_COUNTRY', 'GeoIP.dat')) if os.path.isfile(country_db): self._country = GeoIP_open(force_bytes(country_db), cache) self._country_file = country_db
ptr = GeoIP_open(force_bytes(path), cache) info = GeoIP_database_info(ptr) if lite_regex.match(info): self._city = ptr self._city_file = path elif free_regex.match(info): self._country = ptr self._country_file = path else: raise GeoIPException('Unable to recognize database edition: %s' % info)
if GeoIP_delete is None: return if self._country: GeoIP_delete(self._country) if self._city: GeoIP_delete(self._city)
if not isinstance(query, six.string_types): raise TypeError('GeoIP query must be a string, not type %s' % type(query).__name__)
if city_or_country and not (self._country or self._city): raise GeoIPException('Invalid GeoIP country and city data files.') elif country and not self._country: raise GeoIPException('Invalid GeoIP country data file: %s' % self._country_file) elif city and not self._city: raise GeoIPException('Invalid GeoIP city data file: %s' % self._city_file)
return force_bytes(query)
return GeoIP_record_by_addr(self._city, c_char_p(enc_query))
return GeoIP_record_by_name(self._city, c_char_p(enc_query))
return {'country_code': self.country_code(query), 'country_name': self.country_name(query), }
def coords(self, query, ordering=('longitude', 'latitude')): cdict = self.city(query) if cdict is None: return None else: return tuple(cdict[o] for o in ordering)
@property def country_info(self): "Returns information about the GeoIP country database." if self._country is None: ci = 'No GeoIP Country data in "%s"' % self._country_file else: ci = GeoIP_database_info(self._country) return ci
@classmethod def open(cls, full_path, cache): return GeoIP(full_path, cache)
res.source_expressions[pos] = Transform(expr, base_srid).resolve_expression(*args, **kwargs)
source_fields = self.get_source_fields() if len(source_fields): source_field = source_fields[0] if source_field.geodetic(connection): raise NotImplementedError('Area on geodetic coordinate systems not supported.') units_name = source_field.units_name(connection) if units_name: self.output_field.area_att = AreaMeasure.unit_attname(units_name)
self.source_expressions.pop(0) return super(AsKML, self).as_sql(compiler, connection)
for pos, expr in enumerate( self.source_expressions[self.geom_param_pos + 1:], start=self.geom_param_pos + 1): if isinstance(expr, GeomValue): expr.geography = True
if self.spheroid:
self.source_expressions[2] = Value(geo_field._spheroid)
self.function = 'ST_Length_Spheroid' self.source_expressions.append(Value(geo_field._spheroid))
expressions.extend( [self._handle_param(arg, '', NUMERIC_TYPES) for arg in args[2:]] ) expressions.extend( [self._handle_param(arg, '', NUMERIC_TYPES) for arg in args[0:2]] )
return self.source_expressions[self.geom_param_pos + 1].value
value.srid = self.srid
self.source_expressions.append(Value(0))
procedure_args, geo_field = self._spatial_setup( 'area', field_name=kwargs.get('field_name')) s = {'procedure_args': procedure_args, 'geo_field': geo_field, 'setup': False, } connection = connections[self.db] backend = connection.ops if backend.oracle: s['procedure_fmt'] = '%(geo_col)s,%(tolerance)s' s['procedure_args']['tolerance'] = tolerance
s['select_field'] = AreaField('sq_m')
s['select_field'] = AreaField(Area.unit_attname(geo_field.units_name(connection)))
raise Exception('Area on geodetic coordinate systems not supported.')
connection = connections[self.db] func = getattr(connection.ops, att, False) if desc is None: desc = att if not func: raise NotImplementedError('%s stored procedure not available on ' 'the %s backend.' % (desc, connection.ops.name))
procedure_args = {'function': func}
geo_field = self._geo_field(field_name) if not geo_field: raise TypeError('%s output only available on GeometryFields.' % func)
if geo_field_type is not None and not isinstance(geo_field, geo_field_type): raise TypeError('"%s" stored procedures may only be called on %ss.' % (func, geo_field_type.__name__))
procedure_args['geo_col'] = self._geocol_select(geo_field, field_name)
settings.setdefault('desc', None) settings.setdefault('geom_args', ()) settings.setdefault('geom_field', None) settings.setdefault('procedure_args', {}) settings.setdefault('procedure_fmt', '%(geo_col)s') settings.setdefault('select_params', [])
if settings.get('setup', True): default_args, geo_field = self._spatial_setup( att, desc=settings['desc'], field_name=field_name, geo_field_type=settings.get('geo_field_type')) for k, v in six.iteritems(default_args): settings['procedure_args'].setdefault(k, v) else: geo_field = settings['geo_field']
if not isinstance(model_att, six.string_types): model_att = att
for name in settings['geom_args']: geom = geo_field.get_prep_value(settings['procedure_args'][name]) params = geo_field._get_db_prep_lookup('contains', geom, connection=connection) geom_placeholder = geo_field.get_placeholder(geom, None, connection)
old_fmt = '%%(%s)s' % name new_fmt = geom_placeholder % '%%s' settings['procedure_fmt'] = settings['procedure_fmt'].replace(old_fmt, new_fmt) settings['select_params'].extend(params)
fmt = '%%(function)s(%s)' % settings['procedure_fmt']
if settings.get('select_field'): select_field = settings['select_field'] if connection.ops.oracle: select_field.empty_strings_allowed = False else: select_field = Field()
self.query.add_annotation( RawSQL(fmt % settings['procedure_args'], settings['select_params'], select_field), model_att) return self
procedure_args, geo_field = self._spatial_setup(func, field_name=kwargs.get('field_name'))
connection = connections[self.db] geodetic = geo_field.geodetic(connection) geography = geo_field.geography
distance = func == 'distance' length = func == 'length' perimeter = func == 'perimeter' if not (distance or length or perimeter): raise ValueError('Unknown distance function: %s' % func) geom_3d = geo_field.dim == 3
lookup_params = [geom or 'POINT (0 0)', 0]
backend = connection.ops
if spheroid or (backend.postgis and geodetic and (not geography) and length): lookup_params.append('spheroid') lookup_params = geo_field.get_prep_value(lookup_params) params = geo_field._get_db_prep_lookup('distance_lte', lookup_params, connection=connection)
geom_args = bool(geom)
srid = self.query.get_context('transformed_srid') if srid: u, unit_name, s = get_srid_info(srid, connection) geodetic = unit_name.lower() in geo_field.geodetic_units
geom_args = False procedure_fmt = '%s(%%(geo_col)s, %s)' % (backend.transform, srid) if geom.srid is None or geom.srid == srid: if backend.spatialite: procedure_fmt += ', %s(%%%%s, %s)' % (backend.from_text, srid) else: procedure_fmt += ', %%s' else: if backend.spatialite: procedure_fmt += (', %s(%s(%%%%s, %s), %s)' % ( backend.transform, backend.from_text, geom.srid, srid)) else: procedure_fmt += ', %s(%%%%s, %s)' % (backend.transform, srid)
procedure_fmt = '%(geo_col)s,%(geom)s'
if not backend.geography: if not isinstance(geo_field, PointField): raise ValueError('Spherical distance calculation only supported on PointFields.') if not str(Geometry(six.memoryview(params[0].ewkb)).geom_type) == 'Point': raise ValueError( 'Spherical distance calculation only supported with ' 'Point Geometry parameters' ) if spheroid: procedure_fmt += ",'%(spheroid)s'" procedure_args.update({'function': backend.distance_spheroid, 'spheroid': params[1]}) else: procedure_args.update({'function': backend.distance_sphere})
procedure_fmt += ",'%(spheroid)s'" procedure_args.update({'function': backend.length_spheroid, 'spheroid': params[1]})
if perimeter: procedure_args.update({'function': backend.perimeter3d}) elif length: procedure_args.update({'function': backend.length3d})
s = {'select_field': DistanceField(dist_att), 'setup': False, 'geo_field': geo_field, 'procedure_args': procedure_args, 'procedure_fmt': procedure_fmt, } if geom_args: s['geom_args'] = ('geom',) s['procedure_args']['geom'] = geom elif geom: s['select_params'] = [backend.Adapter(geom)] return self._spatial_attribute(func, s, **kwargs)
self.query.add_select_related([field_name.rsplit(LOOKUP_SEP, 1)[0]]) compiler.pre_sql_setup() for col, _, _ in compiler.select: if col.output_field == geo_field: return col.as_sql(compiler, compiler.connection)[0] raise ValueError("%r not in compiler's related_select_cols" % geo_field)
parent_model = geo_field.model._meta.concrete_model return self._field_column(compiler, geo_field, parent_model._meta.db_table)
for field in self.model._meta.fields: if isinstance(field, GeometryField): return field return False
return GISLookup._check_geo_field(self.model._meta, field_name)
if isinstance(value, Decimal): value = float(value) if value is not None and self.area_att: value = Area(**{self.area_att: value}) return value
geom_type = None
connection.ops.check_expression_support(self) self.function = connection.ops.spatial_aggregate_name(self.name) return super(GeoAggregate, self).as_sql(compiler, connection)
_srid_cache = {}
SpatialRefSys = connection.ops.spatial_ref_sys()
return None, None, None
_srid_cache[connection.alias] = {}
sr = SpatialRefSys.objects.using(connection.alias).get(srid=srid) units, units_name = sr.units spheroid = SpatialRefSys.get_spheroid(sr.wkt) _srid_cache[connection.alias][srid] = (units, units_name, spheroid)
sel_fmt = connection.ops.select % sel_fmt
geodetic_units = ('decimal degree', 'degree')
self.spatial_index = spatial_index
self.srid = srid
kwargs['verbose_name'] = verbose_name
kwargs['srid'] = self.srid if self.spatial_index is not True: kwargs['spatial_index'] = self.spatial_index return name, path, args, kwargs
def _get_srid_info(self, connection): self._units, self._units_name, self._spheroid = get_srid_info(self.srid, connection)
return units_name.lower() in self.geodetic_units if units_name else self.srid == 4326
if isinstance(value, (Expression, bool)): return value elif isinstance(value, (tuple, list)): obj = value[0] seq_value = True else: obj = value seq_value = False
if isinstance(obj, Geometry): pass else: is_candidate = isinstance(obj, (bytes, six.string_types)) or hasattr(obj, '__geo_interface__') raster = False if HAS_GDAL: raster = self.get_raster_prep_value(obj, is_candidate)
obj.srid = self.get_srid(obj)
geom_type = 'GEOMETRY'
self.dim = dim
self.geography = geography
self._extent = kwargs.pop('extent', (-180.0, -90.0, 180.0, 90.0)) self._tolerance = kwargs.pop('tolerance', 0.05)
if self.dim != 2: kwargs['dim'] = self.dim if self.geography is not False: kwargs['geography'] = self.geography return name, path, args, kwargs
def contribute_to_class(self, cls, name, **kwargs): super(GeometryField, self).contribute_to_class(cls, name, **kwargs)
setattr(cls, self.attname, SpatialProxy(Geometry, self))
if isinstance(value, (tuple, list)): params = [connection.ops.Adapter(value[0])] params += self.get_distance(value[1:], lookup_type, connection) else: params = [connection.ops.Adapter(value)] return params
class PointField(GeometryField): geom_type = 'POINT' form_class = forms.PointField description = _("Point")
if not connection.features.gis_enabled or not connection.features.supports_raster: raise ImproperlyConfigured('Raster fields require backends with raster support.')
if not prepared: value = connection.ops.deconstruct_raster(value) return super(RasterField, self).get_db_prep_value(value, connection, prepared)
from django.contrib.gis.gdal import GDALRaster setattr(cls, self.attname, SpatialProxy(GDALRaster, self))
use_for_related_fields = True
silence_use_for_related_fields_deprecation = True
field_list = lookup.split(LOOKUP_SEP)
field_list.reverse() fld_name = field_list.pop()
while len(field_list): opts = geo_fld.remote_field.model._meta geo_fld = opts.get_field(field_list.pop())
if isinstance(geo_fld, BaseSpatialField): return geo_fld else: return False
if only_lhs: self.band_rhs = 1 self.band_lhs = self.lhs.band_index + 1 return
if isinstance(value, (tuple, list)): params = [connection.ops.Adapter(value[0])] + list(value)[1:] else: params = [connection.ops.Adapter(value)] return ('%s', params)
return super(GISLookup, self).process_rhs(compiler, connection)
geo_fld = self.rhs.output_field if not hasattr(geo_fld, 'srid'): raise ValueError('No geographic field found in expression.') self.rhs.srid = geo_fld.srid
if ((len(self.rhs) == 2 and not self.lookup_name == 'relate') or (len(self.rhs) == 3 and self.lookup_name == 'relate')): self.process_band_indices() elif len(self.rhs) > 2: raise ValueError('Tuple too long for lookup %s.' % self.lookup_name)
return connection.ops.gis_operators[self.lookup_name]
lookup_name = 'exact'
backend_op = connection.ops.gis_operators[self.lookup_name] if hasattr(backend_op, 'check_relate_argument'): backend_op.check_relate_argument(value[1]) else: pattern = value[1] if not isinstance(pattern, six.string_types) or not self.pattern_regex.match(pattern): raise ValueError('Invalid intersection matrix pattern "%s".' % pattern) return super(RelateLookup, self).get_db_prep_lookup(value, connection)
if len(self.rhs) > 2 and not self.rhs[2] == 'spheroid': self.process_band_indices()
dist_param = self.rhs[1] if hasattr(dist_param, 'resolve_expression'): dist_param = dist_param.resolve_expression(compiler.query) sql, expr_params = compiler.compile(dist_param) self.template_params['value'] = sql params.extend(expr_params) else: params += connection.ops.get_distance( self.lhs.output_field, (dist_param,) + self.rhs[2:], self.lookup_name, handle_spheroid=False ) rhs = connection.ops.get_geom_placeholder(self.lhs.output_field, params[0], compiler) return (rhs, params)
return self
try: geo_value = instance.__dict__[self._field.attname] except KeyError: geo_value = super(SpatialProxy, self).__get__(instance, cls)
geo_obj = self._klass(geo_value) setattr(instance, self._field.attname, geo_obj)
gtype = self._field.geom_type
pass
if value.srid is None: value.srid = self._field.srid
pass
instance.__dict__[self._field.attname] = value return value
data_types_reverse = DatabaseIntrospection.data_types_reverse.copy() data_types_reverse[FIELD_TYPE.GEOMETRY] = 'GeometryField'
cursor.execute('DESCRIBE %s' % self.connection.ops.quote_name(table_name)) for column, typ, null, key, default, extra in cursor.fetchall(): if column == geo_col: field_type = OGRGeomType(typ).django field_params = {} break
storage_engine = self.get_storage_engine(cursor, table_name) return ( (storage_engine == 'InnoDB' and self.connection.mysql_version >= (5, 7, 5)) or storage_engine == 'MyISAM' )
isinstance(field, GeometryField)
if isinstance(field, GeometryField) and field.spatial_index and not field.null: qn = self.connection.ops.quote_name db_table = model._meta.db_table self.geometry_sql.append( self.sql_add_spatial_index % { 'index': qn(self._create_spatial_index_name(model, field)), 'table': qn(db_table), 'column': qn(field.column), } ) return column_sql
GDAL_TO_POSTGIS = [None, 4, 6, 5, 8, 7, 10, 11, None, None, None, None]
POSTGIS_TO_GDAL = [1, 1, 1, 3, 1, 3, 2, 5, 4, None, 6, 7, None, None]
POSTGIS_HEADER_STRUCTURE = 'B H H d d d d d d i H H'
GDAL_TO_STRUCT = [ None, 'B', 'H', 'h', 'L', 'l', 'f', 'd', None, None, None, None, ]
STRUCT_SIZE = {
if self.is_geometry: self.ewkb = bytes(obj.ewkb) self._adapter = Binary(self.ewkb) else: self.ewkb = to_pgraster(obj)
if proto == ISQLQuote: return self else: raise Exception('Error implementing psycopg2 protocol. Is psycopg2 installed?')
return str('%s(%s)' % ( 'ST_GeogFromWKB' if self.geography else 'ST_GeomFromEWKB', self._adapter.getquoted().decode()) )
return "'%s'::raster" % self.ewkb
postgis_types_reverse = {}
('geography', ('GeometryField', {'geography': True})),
oid_sql = 'SELECT "oid" FROM "pg_type" WHERE "typname" = %s' cursor = self.connection.cursor() try: for field_type in field_types: cursor.execute(oid_sql, (field_type[0],)) for result in cursor.fetchall(): postgis_types[result[0]] = field_type[1] finally: cursor.close()
self.postgis_types_reverse = self.get_postgis_types() self.data_types_reverse.update(self.postgis_types_reverse)
cursor.execute('SELECT "coord_dimension", "srid", "type" ' 'FROM "geometry_columns" ' 'WHERE "f_table_name"=%s AND "f_geometry_column"=%s', (table_name, geo_col)) row = cursor.fetchone() if not row: raise GeoIntrospectionError
field_type = OGRGeomType(row[2]).django
dim = row[0] srid = row[1] field_params = {} if srid != 4326: field_params['srid'] = srid if dim != 2: field_params['dim'] = dim
BILATERAL = 'bilateral'
self.geography = geography self.raster = raster super(PostGISOperator, self).__init__(**kwargs)
if isinstance(lookup.rhs, (tuple, list)): rhs_val = lookup.rhs[0] spheroid = lookup.rhs[-1] == 'spheroid' else: rhs_val = lookup.rhs spheroid = False
lhs_is_raster = lookup.lhs.field.geom_type == 'RASTER' rhs_is_raster = isinstance(rhs_val, GDALRaster)
if lookup.band_lhs is not None and lhs_is_raster: if not self.func: raise ValueError('Band indices are not allowed for this operator, it works on bbox only.') template_params['lhs'] = '%s, %s' % (template_params['lhs'], lookup.band_lhs)
if not self.raster or spheroid: if lhs_is_raster: template_params['lhs'] = 'ST_Polygon(%s)' % template_params['lhs'] if rhs_is_raster: template_params['rhs'] = 'ST_Polygon(%s)' % template_params['rhs'] elif self.raster == BILATERAL: if lhs_is_raster and not rhs_is_raster: template_params['lhs'] = 'ST_Polygon(%s)' % template_params['lhs'] elif rhs_is_raster and not lhs_is_raster: template_params['rhs'] = 'ST_Polygon(%s)' % template_params['rhs']
sql_params.insert(1, lookup.lhs.output_field._spheroid)
if hasattr(settings, 'POSTGIS_VERSION'): version = settings.POSTGIS_VERSION else: self._get_postgis_func('version')
if f.dim == 3: geom_type = f.geom_type + 'Z' else: geom_type = f.geom_type return 'geometry(%s,%d)' % (geom_type, f.srid)
value = dist_val[0]
geodetic = f.geodetic(self.connection) geography = f.geography
dist_param = value
if handle_spheroid and len(dist_val) > 1: option = dist_val[1] if not geography and geodetic and lookup_type != 'dwithin' and option == 'spheroid': params.insert(0, f._spheroid) return params
if value is None: value_srid = None elif f.geom_type == 'RASTER' and isinstance(value, six.string_types): value_srid = get_pgraster_srid(value) else: value_srid = value.srid
if value_srid is None or value_srid == f.srid: placeholder = '%s' elif f.geom_type == 'RASTER' and isinstance(value, six.string_types): placeholder = '%s((%%s)::raster, %s)' % (self.transform, f.srid) else: placeholder = '%s(%%s, %s)' % (self.transform, f.srid)
sql, _ = compiler.compile(value) placeholder = placeholder % sql
with self.connection.temporary_connection() as cursor: cursor.execute('SELECT %s()' % func) return cursor.fetchone()[0]
version = self.postgis_lib_version() m = self.version_regex.match(version)
def geometry_columns(self): return PostGISGeometryColumns
def parse_raster(self, value): return from_pgraster(value)
field_column = self.quote_name(field.column) if field.geom_type == 'RASTER': field_column = self.rast_index_wrapper % field_column index_ops = '' elif field.geography: index_ops = '' else: if field.dim > 2: index_ops = self.geom_index_ops_nd else: index_ops = '' self.geometry_sql.append( self.sql_add_spatial_index % { "index": self.quote_name('%s_%s_id' % (model._meta.db_table, field.column)), "table": self.quote_name(model._meta.db_table), "column": field_column, "index_type": self.geom_index_type, "ops": index_ops, } )
for sql in self.geometry_sql: self.execute(sql) self.geometry_sql = []
for sql in self.geometry_sql: self.execute(sql) self.geometry_sql = []
return unpack('i', data[106:114])[0]
header, data = chunk(data, 122) header = unpack(POSTGIS_HEADER_STRUCTURE, header)
bands = [] pixeltypes = [] while data: pixeltype, data = chunk(data, 2) pixeltype = unpack('B', pixeltype)[0]
has_nodata = pixeltype >= 64 if has_nodata: pixeltype -= 64
pixeltype = POSTGIS_TO_GDAL[pixeltype] pack_type = GDAL_TO_STRUCT[pixeltype] pack_size = 2 * STRUCT_SIZE[pack_type]
nodata, data = chunk(data, pack_size) nodata = unpack(pack_type, nodata)[0]
band, data = chunk(data, pack_size * header[10] * header[11]) band_result = {'data': binascii.unhexlify(band)}
if has_nodata: band_result['nodata_value'] = nodata
bands.append(band_result)
pixeltypes.append(pixeltype)
if len(set(pixeltypes)) != 1: raise ValidationError("Band pixeltypes are not all equal.")
if rast is None or rast == '': return
rasterheader = ( 1, 0, len(rast.bands), rast.scale.x, rast.scale.y, rast.origin.x, rast.origin.y, rast.skew.x, rast.skew.y, rast.srs.srid, rast.width, rast.height, )
result = pack(POSTGIS_HEADER_STRUCTURE, rasterheader)
structure = 'B' + GDAL_TO_STRUCT[band.datatype()]
pixeltype = GDAL_TO_POSTGIS[band.datatype()]
if band.nodata_value is not None: pixeltype += 64
bandheader = pack(structure, (pixeltype, band.nodata_value or 0))
band_data_hex = binascii.hexlify(band.data(as_memoryview=True)).upper()
result += bandheader + band_data_hex
return result.decode()
with self.cursor() as cursor: cursor.execute("CREATE EXTENSION IF NOT EXISTS postgis")
cs_bounds = models.PolygonField(null=True) objects = models.GeoManager()
if self._isClockwise(poly.exterior_ring): poly.exterior_ring = list(reversed(poly.exterior_ring))
for i, geom in enumerate(coll): if isinstance(geom, Polygon): coll[i] = self._fix_polygon(geom)
n = len(coords) area = 0.0 for i in range(n): j = (i + 1) % n area += coords[i][0] * coords[j][1] area -= coords[j][0] * coords[i][1] return area < 0.0
data_types_reverse = DatabaseIntrospection.data_types_reverse.copy() data_types_reverse[cx_Oracle.OBJECT] = 'GeometryField'
try: cursor.execute( 'SELECT "DIMINFO", "SRID" FROM "USER_SDO_GEOM_METADATA" ' 'WHERE "TABLE_NAME"=%s AND "COLUMN_NAME"=%s', (table_name.upper(), geo_col.upper()) ) row = cursor.fetchone() except Exception as msg: new_msg = ( 'Could not find entry in USER_SDO_GEOM_METADATA ' 'corresponding to "%s"."%s"\n' 'Error message: %s.') % (table_name, geo_col, msg) six.reraise(Exception, Exception(new_msg), sys.exc_info()[2])
field_type = 'GeometryField'
field_params = {} dim, srid = row if srid != 4326: field_params['srid'] = srid dim = len(dim) if dim != 2: field_params['dim'] = dim
select = 'SDO_UTIL.TO_WKTGEOMETRY(%s)'
ext_geom = Geometry(clob.read(), srid) gtype = str(ext_geom.geom_type) if gtype == 'Polygon': shell = ext_geom.shell ll, ur = shell[0][:2], shell[2][:2] elif gtype == 'Point': ll = ext_geom.coords[:2] ur = ll else: raise Exception('Unexpected geometry type returned for extent: %s' % gtype) xmin, ymin = ll xmax, ymax = ur return (xmin, ymin, xmax, ymax)
if lookup_type == 'dwithin': dist_param = 'distance=%s' % dist_param
sql, _ = compiler.compile(value) return placeholder % sql
def geometry_columns(self): from django.contrib.gis.db.backends.oracle.models import OracleGeometryColumns return OracleGeometryColumns
return truncate_name('%s_%s_id' % (model._meta.db_table, field.column), 30)
spheroid_regex = re.compile(r'.+SPHEROID\[\"(?P<name>.+)\",(?P<major>\d+(\.\d+)?),(?P<flattening>\d{3}\.\d+),')
units_regex = re.compile(r'.+UNIT ?\["(?P<unit_name>[\w \.\'\(\)]+)", ?(?P<unit>[^ ,\]]+)', re.DOTALL)
if hasattr(self, '_srs'): return self._srs.clone() else:
try: self._srs = gdal.SpatialReference(self.wkt) return self.srs except Exception as msg: pass
if len(sphere_params) == 3: radius, flattening = sphere_params[0], sphere_params[2] else: radius, flattening = sphere_params return 'SPHEROID["%s",%s,%s]' % (sphere_name, radius, flattening)
postgis = False spatialite = False mysql = False oracle = False spatial_version = None
select = None
geography = False geometry = False
disallowed_aggregates = ()
function_names = {}
unsupported_functions = { 'Area', 'AsGeoJSON', 'AsGML', 'AsKML', 'AsSVG', 'BoundingCircle', 'Centroid', 'Difference', 'Distance', 'Envelope', 'ForceRHR', 'GeoHash', 'Intersection', 'IsValid', 'Length', 'MakeValid', 'MemSize', 'NumGeometries', 'NumPoints', 'Perimeter', 'PointOnSurface', 'Reverse', 'Scale', 'SnapToGrid', 'SymDifference', 'Transform', 'Translate', 'Union', }
geohash = False geojson = False gml = False kml = False svg = False
from_text = False from_wkb = False
def convert_extent(self, box, srid): raise NotImplementedError('Aggregate extent not implemented for this spatial backend.')
def geo_quote_name(self, name): return "'%s'" % name
def geometry_columns(self): raise NotImplementedError('Subclasses of BaseSpatialOperations must provide a geometry_columns() method.')
has_spatialrefsys_table = True
supports_add_srs_entry = True supports_geometry_field_introspection = True
supports_3d_storage = False supports_3d_functions = False supports_transform = True supports_real_shape_operations = True supports_null_geometries = True supports_distance_geodetic = True supports_length_geodetic = True supports_perimeter_geodetic = False supports_num_points_poly = True
supports_distances_lookups = True supports_left_right_lookups = False
supports_raster = False
supports_geometry_field_unique_index = True
geoqueryset_methods = ( 'area', 'bounding_circle', 'centroid', 'difference', 'distance', 'distance_spheroid', 'envelope', 'force_rhr', 'geohash', 'gml', 'intersection', 'kml', 'length', 'mem_size', 'num_geom', 'num_points', 'perimeter', 'point_on_surface', 'reverse', 'scale', 'snap_to_grid', 'svg', 'sym_difference', 'transform', 'translate', 'union', 'unionagg', )
@property def supports_collect_aggr(self): return aggregates.Collect not in self.connection.ops.disallowed_aggregates
setattr(self.__class__, 'has_%s_method' % method, property(partial(BaseSpatialFeatures.has_ops_method, method=method)))
cursor.execute('SELECT coord_dimension, srid, geometry_type ' 'FROM geometry_columns ' 'WHERE f_table_name=%s AND f_geometry_column=%s', (table_name, geo_col)) row = cursor.fetchone() if not row: raise Exception('Could not find a geometry column for "%s"."%s"' % (table_name, geo_col))
ogr_type = row[2] if isinstance(ogr_type, six.integer_types) and ogr_type > 1000: ogr_type = ogr_type % 1000 + OGRGeomType.wkb25bit field_type = OGRGeomType(ogr_type).django
dim = row[0] srid = row[1] field_params = {} if srid != 4326: field_params['srid'] = srid if (isinstance(dim, six.string_types) and 'Z' in dim) or dim == 3: field_params['dim'] = 3
'contained': SpatialOperator(func='MbrWithin'), 'bbcontains': SpatialOperator(func='MbrContains'), 'bboverlaps': SpatialOperator(func='MbrOverlaps'), 'same_as': SpatialOperator(func='Equals'), 'exact': SpatialOperator(func='Equals'),
sql, _ = compiler.compile(value) return placeholder % sql
return '%s(%s(%%s,%s), %s)' % (self.transform, self.from_text, value.srid, f.srid)
def geometry_columns(self): from django.contrib.gis.db.backends.spatialite.models import SpatialiteGeometryColumns return SpatialiteGeometryColumns
self.geometry_sql.append( self.sql_add_geometry_column % { "table": self.geo_quote_name(model._meta.db_table), "column": self.geo_quote_name(field.column), "srid": field.srid, "geom_type": self.geo_quote_name(field.geom_type), "dim": field.dim, "null": int(not field.null), } )
for sql in self.geometry_sql: self.execute(sql) self.geometry_sql = []
for field in model._meta.local_fields: if isinstance(field, GeometryField): self.remove_geometry_metadata(model, field) for geom_table in self.geometry_tables: try: self.execute( self.sql_discard_geometry_columns % { "geom_table": geom_table, "table": self.quote_name(model._meta.db_table), } ) except DatabaseError: pass super(SpatialiteSchemaEditor, self).delete_model(model, **kwargs)
self.column_sql(model, field) for sql in self.geometry_sql: self.execute(sql) self.geometry_sql = []
if isinstance(field, GeometryField): self._remake_table(model, delete_fields=[field]) else: super(SpatialiteSchemaEditor, self).remove_field(model, field)
for field in model._meta.local_fields: if isinstance(field, GeometryField): self.execute( self.sql_remove_geometry_metadata % { "table": self.quote_name(old_db_table), "column": self.quote_name(field.column), } ) super(SpatialiteSchemaEditor, self).alter_db_table(model, old_db_table, new_db_table) for geom_table in self.geometry_tables: try: self.execute( self.sql_update_geometry_columns % { "geom_table": geom_table, "old_table": self.quote_name(old_db_table), "new_table": self.quote_name(new_db_table), } ) except DatabaseError: pass for field in model._meta.local_fields: if isinstance(field, GeometryField): self.execute(self.sql_add_geometry_column % { "table": self.geo_quote_name(new_db_table), "column": self.geo_quote_name(field.column), "srid": field.srid, "geom_type": self.geo_quote_name(field.geom_type), "dim": field.dim, "null": int(not field.null), }) if getattr(field, 'spatial_index', False): self.execute(self.sql_rename_table % { "old_table": self.quote_name("idx_%s_%s" % (old_db_table, field.column)), "new_table": self.quote_name("idx_%s_%s" % (new_db_table, field.column)), })
if Database.version_info < (2, 5, 0): raise ImproperlyConfigured('Only versions of pysqlite 2.5+ are ' 'compatible with SpatiaLite and GeoDjango.')
self.spatialite_lib = getattr(settings, 'SPATIALITE_LIBRARY_PATH', find_library('spatialite')) if not self.spatialite_lib: raise ImproperlyConfigured('Unable to locate the SpatiaLite library. ' 'Make sure it is in your library path, or set ' 'SPATIALITE_LIBRARY_PATH in your settings.' ) super(DatabaseWrapper, self).__init__(*args, **kwargs) self.features = DatabaseFeatures(self) self.ops = SpatiaLiteOperations(self) self.client = SpatiaLiteClient(self) self.introspection = SpatiaLiteIntrospection(self)
try: conn.enable_load_extension(True) except AttributeError: raise ImproperlyConfigured( 'The pysqlite library does not support C extension loading. ' 'Both SQLite and pysqlite must be configured to allow ' 'the loading of extensions to use SpatiaLite.') cur = conn.cursor(factory=SQLiteCursorWrapper) try: cur.execute("SELECT load_extension(%s)", (self.spatialite_lib,)) except Exception as msg: new_msg = ( 'Unable to load the SpatiaLite library extension ' '"%s" because: %s') % (self.spatialite_lib, msg) six.reraise(ImproperlyConfigured, ImproperlyConfigured(new_msg), sys.exc_info()[2]) cur.close() return conn
with self.cursor() as cursor: cursor.execute("PRAGMA table_info(geometry_columns);") if cursor.fetchall() == []: arg = "1" if self.features.supports_initspatialmetadata_in_one_transaction else "" cursor.execute("SELECT InitSpatialMetaData(%s)" % arg)
supports_num_points_poly = False
return self.connection.ops.spatial_version >= (4, 1, 0)
ALIAS = { 'centimeter': 'cm', 'foot': 'ft', 'inches': 'inch', 'kilometer': 'km', 'kilometre': 'km', 'meter': 'm', 'metre': 'm', 'micrometer': 'um', 'micrometre': 'um', 'millimeter': 'mm', 'millimetre': 'mm', 'mile': 'mi', 'yard': 'yd', 'British chain (Benoit 1895 B)': 'british_chain_benoit', 'British chain (Sears 1922)': 'british_chain_sears', 'British chain (Sears 1922 truncated)': 'british_chain_sears_truncated', 'British foot (Sears 1922)': 'british_ft', 'British foot': 'british_ft', 'British yard (Sears 1922)': 'british_yd', 'British yard': 'british_yd', "Clarke's Foot": 'clarke_ft', "Clarke's link": 'clarke_link', 'Chain (Benoit)': 'chain_benoit', 'Chain (Sears)': 'chain_sears', 'Foot (International)': 'ft', 'German legal metre': 'german_m', 'Gold Coast foot': 'gold_coast_ft', 'Indian yard': 'indian_yd', 'Link (Benoit)': 'link_benoit', 'Link (Sears)': 'link_sears', 'Nautical Mile': 'nm', 'Nautical Mile (UK)': 'nm_uk', 'US survey foot': 'survey_ft', 'U.S. Foot': 'survey_ft', 'Yard (Indian)': 'indian_yd', 'Yard (Sears)': 'sears_yd' } LALIAS = {k.lower(): v for k, v in ALIAS.items()}
UNITS = {'%s%s' % (AREA_PREFIX, k): v ** 2 for k, v in Distance.UNITS.items()} ALIAS = {k: '%s%s' % (AREA_PREFIX, v) for k, v in Distance.ALIAS.items()} LALIAS = {k.lower(): v for k, v in ALIAS.items()}
D = Distance A = Area
origLen = len(self) if isinstance(index, six.integer_types): index = self._checkindex(index) indexRange = [index] else: indexRange = range(*index.indices(origLen))
def __add__(self, other): 'add another list-like object' return self.__class__(list(self) + list(other))
return False
return True
def count(self, val): "Standard list count method" count = 0 for i in self: if val == i: count += 1 return count
def append(self, val): "Standard list append method" self[len(self):] = [val]
def _rebuild(self, newLen, newItems): if newLen and newLen < self._minlength: raise ValueError('Must have at least %d items' % self._minlength) if self._maxlength is not None and newLen > self._maxlength: raise ValueError('Cannot have more than %d items' % self._maxlength)
if index.step is None: self._assign_simple_slice(start, stop, valueList) else: self._assign_extended_slice(start, stop, step, valueList)
if len(valueList) != len(indexList): raise ValueError('attempt to assign sequence of size %d ' 'to extended slice of size %d' % (len(valueList), len(indexList)))
newLen = len(self) newVals = dict(zip(indexList, valueList))
if len(valueList) != len(indexList): raise ValueError('attempt to assign sequence of size %d ' 'to extended slice of size %d' % (len(valueList), len(indexList)))
self._base_geom = geom from .geometry import GEOSGeometry if not isinstance(geom, GEOSGeometry): raise TypeError self.ptr = capi.geos_prepare(geom.ptr)
if isinstance(file_h, six.string_types): with open(file_h, 'rb') as file_h: buf = file_h.read() else: buf = file_h.read()
if isinstance(buf, bytes): try: decoded = buf.decode() if wkt_regex.match(decoded) or hex_regex.match(decoded): return GEOSGeometry(decoded) except UnicodeDecodeError: pass else: return GEOSGeometry(buf)
if len(args) == 1: if isinstance(args[0], (tuple, list)): init_geoms = args[0] else: init_geoms = args else: init_geoms = args
self._check_allowed(init_geoms)
collection = self._create_collection(len(init_geoms), iter(init_geoms)) super(GeometryCollection, self).__init__(collection, **kwargs)
def _create_collection(self, length, items): geoms = get_pointer_arr(length) for i, g in enumerate(items): geoms[i] = capi.geom_clone(getattr(g, 'ptr', g))
return GEOSGeometry(capi.geom_clone(self._get_single_internal(index)), srid=self.srid)
class MultiPoint(GeometryCollection): _allowed = Point _typeid = 4
GeometryCollection._allowed = (Point, LineString, LinearRing, Polygon, MultiPoint, MultiLineString, MultiPolygon)
ext_ring = args[0] init_holes = args[1:] n_holes = len(init_holes)
if n_holes == 1 and isinstance(init_holes[0], (tuple, list)): if len(init_holes[0]) == 0: init_holes = () n_holes = 0 elif isinstance(init_holes[0][0], LinearRing): init_holes = init_holes[0] n_holes = len(init_holes)
def _create_polygon(self, length, items): if not length: return capi.create_empty_polygon()
prev_ptr = self.ptr srid = self.srid self.ptr = self._create_polygon(length, items) if srid: self.srid = srid capi.destroy_geom(prev_ptr)
return capi.get_intring(self.ptr, index - 1)
@property def num_interior_rings(self): "Returns the number of interior rings." return capi.get_nrings(self.ptr)
exterior_ring = property(_get_ext_ring, _set_ext_ring) shell = exterior_ring
coords = x
if isinstance(z, six.integer_types + (float,)): coords = [x, y, z] else: coords = [x, y]
super(Point, self).__init__(point, srid=srid)
raise GEOSException('Geometry resulting from slice deletion was invalid.')
@property def tuple(self): "Returns a tuple of the point." return self._cs.tuple
coords = tuple
free = GEOSFuncFactory('GEOSFree') free.argtypes = [c_void_p]
if result != 1: return None return last_arg_byref(cargs)
s = string_at(result, last_arg_byref(cargs)) free(result) return s
s = string_at(result) free(result) return s
geos_prepare = GEOSFuncFactory('GEOSPrepare', argtypes=[GEOM_PTR], restype=PREPGEOM_PTR) prepared_destroy = GEOSFuncFactory('GEOSPreparedGeom_destroy', argtypes=[PREPGEOM_PTR])
class PreparedPredicate(GEOSFuncFactory): argtypes = [PREPGEOM_PTR, GEOM_PTR] restype = c_char errcheck = staticmethod(check_predicate)
self.ptr = lgeos.initGEOS_r(notice_h, error_h)
class GEOSContext(threading.local): handle = None
self.cfunc = getattr(lgeos, func_name + '_r') self.threaded = True self.thread_context = thread_context
self.cfunc = getattr(lgeos, func_name) self.threaded = False
if not self.thread_context.handle: self.thread_context.handle = GEOSContextHandle() return self.cfunc(self.thread_context.handle.ptr, *args)
def _get_argtypes(self): return self.cfunc.argtypes
def _get_restype(self): return self.cfunc.restype
def _get_errcheck(self): return self.cfunc.errcheck
class UnaryPredicate(GEOSFuncFactory): "For GEOS unary predicate functions." argtypes = [GEOM_PTR] restype = c_char errcheck = staticmethod(check_predicate)
geos_hasz = UnaryPredicate('GEOSHasZ') geos_isclosed = UnaryPredicate('GEOSisClosed') geos_isempty = UnaryPredicate('GEOSisEmpty') geos_isring = UnaryPredicate('GEOSisRing') geos_issimple = UnaryPredicate('GEOSisSimple') geos_isvalid = UnaryPredicate('GEOSisValid')
geos_contains = BinaryPredicate('GEOSContains') geos_covers = BinaryPredicate('GEOSCovers') geos_crosses = BinaryPredicate('GEOSCrosses') geos_disjoint = BinaryPredicate('GEOSDisjoint') geos_equals = BinaryPredicate('GEOSEquals') geos_equalsexact = BinaryPredicate('GEOSEqualsExact', argtypes=[GEOM_PTR, GEOM_PTR, c_double]) geos_intersects = BinaryPredicate('GEOSIntersects') geos_overlaps = BinaryPredicate('GEOSOverlaps') geos_relatepattern = BinaryPredicate('GEOSRelatePattern', argtypes=[GEOM_PTR, GEOM_PTR, c_char_p]) geos_touches = BinaryPredicate('GEOSTouches') geos_within = BinaryPredicate('GEOSWithin')
geos_boundary = Topology('GEOSBoundary') geos_buffer = Topology('GEOSBuffer', argtypes=[GEOM_PTR, c_double, c_int]) geos_centroid = Topology('GEOSGetCentroid') geos_convexhull = Topology('GEOSConvexHull') geos_difference = Topology('GEOSDifference', argtypes=[GEOM_PTR, GEOM_PTR]) geos_envelope = Topology('GEOSEnvelope') geos_intersection = Topology('GEOSIntersection', argtypes=[GEOM_PTR, GEOM_PTR]) geos_linemerge = Topology('GEOSLineMerge') geos_pointonsurface = Topology('GEOSPointOnSurface') geos_preservesimplify = Topology('GEOSTopologyPreserveSimplify', argtypes=[GEOM_PTR, c_double]) geos_simplify = Topology('GEOSSimplify', argtypes=[GEOM_PTR, c_double]) geos_symdifference = Topology('GEOSSymDifference', argtypes=[GEOM_PTR, GEOM_PTR]) geos_union = Topology('GEOSUnion', argtypes=[GEOM_PTR, GEOM_PTR])
geos_relate = GEOSFuncFactory( 'GEOSRelate', argtypes=[GEOM_PTR, GEOM_PTR], restype=geos_char_p, errcheck=check_string )
geos_project = GEOSFuncFactory( 'GEOSProject', argtypes=[GEOM_PTR, GEOM_PTR], restype=c_double, errcheck=check_minus_one ) geos_interpolate = Topology('GEOSInterpolate', argtypes=[GEOM_PTR, c_double])
geos_area = DblFromGeom('GEOSArea') geos_distance = DblFromGeom('GEOSDistance', num_geom=2) geos_length = DblFromGeom('GEOSLength') geos_isvalidreason = GEOSFuncFactory( 'GEOSisValidReason', restype=geos_char_p, errcheck=check_string, argtypes=[GEOM_PTR] )
c_uchar_p = POINTER(c_ubyte)
class geos_char_p(c_char_p): pass
class BinConstructor(GEOSFuncFactory): "Generates a prototype for binary construction (HEX, WKB) GEOS routines." argtypes = [c_char_p, c_size_t] restype = GEOM_PTR errcheck = staticmethod(check_geom)
class BinOutput(GEOSFuncFactory): "Generates a prototype for the routines that return a sized string." argtypes = [GEOM_PTR, POINTER(c_size_t)] restype = c_uchar_p errcheck = staticmethod(check_sized_string)
from_hex = BinConstructor('GEOSGeomFromHEX_buf') from_wkb = BinConstructor('GEOSGeomFromWKB_buf') from_wkt = GeomOutput('GEOSGeomFromWKT', [c_char_p])
to_hex = BinOutput('GEOSGeomToHEX_buf') to_wkb = BinOutput('GEOSGeomToWKB_buf') to_wkt = StringFromGeom('GEOSGeomToWKT')
geos_normalize = IntFromGeom('GEOSNormalize') geos_type = StringFromGeom('GEOSGeomType') geos_typeid = IntFromGeom('GEOSGeomTypeId') get_dims = GEOSFuncFactory('GEOSGeom_getDimensions', argtypes=[GEOM_PTR], restype=c_int) get_num_coords = IntFromGeom('GEOSGetNumCoordinates') get_num_geoms = IntFromGeom('GEOSGetNumGeometries')
create_point = GeomOutput('GEOSGeom_createPoint', [CS_PTR]) create_linestring = GeomOutput('GEOSGeom_createLineString', [CS_PTR]) create_linearring = GeomOutput('GEOSGeom_createLinearRing', [CS_PTR])
create_polygon = GeomOutput('GEOSGeom_createPolygon', None) create_empty_polygon = GeomOutput('GEOSGeom_createEmptyPolygon', None) create_collection = GeomOutput('GEOSGeom_createCollection', None)
get_extring = GeomOutput('GEOSGetExteriorRing', [GEOM_PTR]) get_intring = GeomOutput('GEOSGetInteriorRingN', [GEOM_PTR, c_int]) get_nrings = IntFromGeom('GEOSGetNumInteriorRings')
get_geomn = GeomOutput('GEOSGetGeometryN', [GEOM_PTR, c_int])
geom_clone = GEOSFuncFactory('GEOSGeom_clone', argtypes=[GEOM_PTR], restype=GEOM_PTR)
destroy_geom = GEOSFuncFactory('GEOSGeom_destroy', argtypes=[GEOM_PTR])
geos_get_srid = GEOSFuncFactory('GEOSGetSRID', argtypes=[GEOM_PTR], restype=c_int) geos_set_srid = GEOSFuncFactory('GEOSSetSRID', argtypes=[GEOM_PTR, c_int])
def check_cs_op(result, func, cargs): "Checks the status code of a coordinate sequence operation." if result == 0: raise GEOSException('Could not set value on coordinate sequence') else: return result
return last_arg_byref(cargs)
class CsInt(GEOSFuncFactory): "For coordinate sequence routines that return an integer." argtypes = [CS_PTR, POINTER(c_uint)] restype = c_int errcheck = staticmethod(check_cs_get)
self.errcheck = check_cs_get dbl_param = POINTER(c_double)
self.argtypes = [CS_PTR, c_uint, c_uint, dbl_param]
cs_clone = CsOutput('GEOSCoordSeq_clone', [CS_PTR]) create_cs = CsOutput('GEOSCoordSeq_create', [c_uint, c_uint]) get_cs = CsOutput('GEOSGeom_getCoordSeq', [GEOM_PTR])
cs_getordinate = CsOperation('GEOSCoordSeq_getOrdinate', ordinate=True, get=True) cs_setordinate = CsOperation('GEOSCoordSeq_setOrdinate', ordinate=True)
cs_getx = CsOperation('GEOSCoordSeq_getX', get=True) cs_gety = CsOperation('GEOSCoordSeq_getY', get=True) cs_getz = CsOperation('GEOSCoordSeq_getZ', get=True)
cs_setx = CsOperation('GEOSCoordSeq_setX') cs_sety = CsOperation('GEOSCoordSeq_setY') cs_setz = CsOperation('GEOSCoordSeq_setZ')
cs_getsize = CsInt('GEOSCoordSeq_getSize') cs_getdims = CsInt('GEOSCoordSeq_getDimensions')
class WKTReader_st(Structure): pass
wkt_reader_create = GEOSFuncFactory('GEOSWKTReader_create', restype=WKT_READ_PTR) wkt_reader_destroy = GEOSFuncFactory('GEOSWKTReader_destroy', argtypes=[WKT_READ_PTR])
wkt_writer_create = GEOSFuncFactory('GEOSWKTWriter_create', restype=WKT_WRITE_PTR) wkt_writer_destroy = GEOSFuncFactory('GEOSWKTWriter_destroy', argtypes=[WKT_WRITE_PTR])
wkb_reader_create = GEOSFuncFactory('GEOSWKBReader_create', restype=WKB_READ_PTR) wkb_reader_destroy = GEOSFuncFactory('GEOSWKBReader_destroy', argtypes=[WKB_READ_PTR])
argtypes = [WKB_READ_PTR, c_char_p, c_size_t] restype = GEOM_PTR errcheck = staticmethod(check_geom)
wkb_writer_create = GEOSFuncFactory('GEOSWKBWriter_create', restype=WKB_WRITE_PTR) wkb_writer_destroy = GEOSFuncFactory('GEOSWKBWriter_destroy', argtypes=[WKB_WRITE_PTR])
class WKBWriteFunc(GEOSFuncFactory): argtypes = [WKB_WRITE_PTR, GEOM_PTR, POINTER(c_size_t)] restype = c_uchar_p errcheck = staticmethod(check_sized_string)
class WKBWriterGet(GEOSFuncFactory): argtypes = [WKB_WRITE_PTR] restype = c_int
class IOBase(GEOSBase): "Base class for GEOS I/O objects." def __init__(self): self.ptr = self._constructor() self._destructor.func = self._destructor.get_func( *self._destructor.args, **self._destructor.kwargs )
try: self._destructor(self._ptr) except (AttributeError, TypeError):
class _WKTReader(IOBase): _constructor = wkt_reader_create _destructor = wkt_reader_destroy ptr_type = WKT_READ_PTR
class WKTWriter(IOBase): _constructor = wkt_writer_create _destructor = wkt_writer_destroy ptr_type = WKT_WRITE_PTR
def _get_byteorder(self): return wkb_writer_get_byteorder(self.ptr)
@property def outdim(self): return wkb_writer_get_outdim(self.ptr)
@property def srid(self): return bool(ord(wkb_writer_get_include_srid(self.ptr)))
class ThreadLocalIO(threading.local): wkt_r = None wkt_w = None wkb_r = None wkb_w = None ewkb_w = None
def wkt_r(): if not thread_context.wkt_r: thread_context.wkt_r = _WKTReader() return thread_context.wkt_r
_ptr = None
ptr_type = c_void_p
def _get_ptr(self): if self._ptr: return self._ptr else: raise GEOSException('NULL GEOS %s pointer encountered.' % self.__class__.__name__)
if ptr is None or isinstance(ptr, self.ptr_type): self._ptr = ptr else: raise TypeError('Incompatible pointer type')
ptr = property(_get_ptr, _set_ptr)
if len(args) == 1: coords = args[0] else: coords = args
srid = kwargs.get('srid')
ndim = None for coord in coords: if not isinstance(coord, (tuple, list, Point)): raise TypeError('Each coordinate should be a sequence (list or tuple)')
cs = GEOSCoordSeq(capi.create_cs(ncoords, ndim), z=bool(ndim == 3))
super(LineString, self).__init__(self._init_func(cs.ptr), srid=srid)
cs = GEOSCoordSeq(capi.create_cs(length, ndim), z=hasz) for i, c in enumerate(items): cs[i] = c
raise GEOSException('Geometry resulting from slice deletion was invalid.')
@property def tuple(self): "Returns a tuple version of the geometry from the coordinate sequence." return self._cs.tuple coords = tuple
class LinearRing(LineString): _minlength = 4 _init_func = capi.create_linearring
if wkt_m.group('srid'): srid = int(wkt_m.group('srid')) g = wkt_r().read(force_bytes(wkt_m.group('wkt')))
g = wkb_r().read(force_bytes(geo_input))
if not gdal.HAS_GDAL: raise ValueError('Initializing geometry from JSON input requires GDAL.') g = wkb_r().read(gdal.OGRGeometry(geo_input).wkb)
g = geo_input
g = wkb_r().read(geo_input)
raise TypeError('Improper geometry input type: %s' % str(type(geo_input)))
self.ptr = g
self._post_init(srid)
if srid and isinstance(srid, int): self.srid = srid
if GEOSGeometry._GEOS_CLASSES is None: from .linestring import LineString, LinearRing from .point import Point from .polygon import Polygon from .collections import ( GeometryCollection, MultiPoint, MultiLineString, MultiPolygon) GEOSGeometry._GEOS_CLASSES = { 0: Point, 1: LineString, 2: LinearRing, 3: Polygon, 4: MultiPoint, 5: MultiLineString, 6: MultiPolygon, 7: GeometryCollection, } self.__class__ = GEOSGeometry._GEOS_CLASSES[self.geom_typeid]
self._set_cs()
def __getstate__(self): return bytes(self.wkb), self.srid
wkb, srid = state ptr = wkb_r().read(six.memoryview(wkb)) if not ptr: raise GEOSException('Invalid Geometry loaded from pickled state.') self.ptr = ptr self._post_init(srid)
def __or__(self, other): "Returns the union of this Geometry and the other." return self.union(other)
def __and__(self, other): "Returns the intersection of this Geometry and the other." return self.intersection(other)
def __sub__(self, other): "Return the difference this Geometry and the other." return self.difference(other)
def __xor__(self, other): "Return the symmetric difference of this Geometry and the other." return self.sym_difference(other)
def _set_cs(self): "Sets the coordinate sequence for this Geometry." if self.has_cs: self._cs = GEOSCoordSeq(capi.get_cs(self.ptr), self.hasz) else: self._cs = None
@property def geom_type(self): "Returns a string representing the Geometry type, e.g. 'Polygon'" return capi.geos_type(self.ptr).decode()
def contains(self, other): "Returns true if other.within(this) returns true." return capi.geos_contains(self.ptr, other.ptr)
@property def srid(self): "Gets the SRID for the geometry, returns None if no SRID is set." s = capi.geos_get_srid(self.ptr) if s == 0: return None else: return s
return wkb_w(dim=3 if self.hasz else 2).write_hex(self)
@property def ogr(self): "Returns the OGR Geometry for this Geometry." if not gdal.HAS_GDAL: raise GEOSException('GDAL required to convert to an OGRGeometry.') if self.srid: try: return gdal.OGRGeometry(self.wkb, self.srid) except gdal.SRSException: pass return gdal.OGRGeometry(self.wkb)
if clone: return self.clone() else: return
srid = None
g = gdal.OGRGeometry(self.wkb, srid) g.transform(ct) ptr = wkb_r().read(g.wkb) if clone: return GEOSGeometry(ptr, srid=g.srid) if ptr: capi.destroy_geom(self.ptr) self.ptr = ptr self._post_init(g.srid) else: raise GEOSException('Transformed WKB was invalid.')
def _topology(self, gptr): "Helper routine to return Geometry from the given pointer." return GEOSGeometry(gptr, srid=self.srid)
@property def area(self): "Returns the area of the Geometry." return capi.geos_area(self.ptr, byref(c_double()))
try: from django.conf import settings lib_path = settings.GEOS_LIBRARY_PATH except (AttributeError, EnvironmentError, ImportError, ImproperlyConfigured): lib_path = None
if lib_path: lib_names = None elif os.name == 'nt': lib_names = ['geos_c', 'libgeos_c-1'] elif os.name == 'posix': lib_names = ['geos_c', 'GEOS'] else: raise ImportError('Unsupported OS "%s"' % os.name)
if lib_names: for lib_name in lib_names: lib_path = find_library(lib_name) if lib_path is not None: break
if lib_path is None: raise ImportError( 'Could not find the GEOS library (tried "%s"). ' 'Try setting GEOS_LIBRARY_PATH in your settings.' % '", "'.join(lib_names) ) _lgeos = CDLL(lib_path) _lgeos.initGEOS_r.restype = CONTEXT_PTR _lgeos.finishGEOS_r.argtypes = [CONTEXT_PTR] return _lgeos
NOTICEFUNC = CFUNCTYPE(None, c_char_p, c_char_p)
class GEOSGeom_t(Structure): pass
GEOM_PTR = POINTER(GEOSGeom_t) PREPGEOM_PTR = POINTER(GEOSPrepGeom_t) CS_PTR = POINTER(GEOSCoordSeq_t) CONTEXT_PTR = POINTER(GEOSContextHandle_t)
def get_pointer_arr(n): "Gets a ctypes pointer array (of length `n`) for GEOSGeom_t opaque pointer." GeomArr = GEOM_PTR * n return GeomArr()
geos_version = GEOSFuncFactory('GEOSversion', restype=c_char_p)
version_regex = re.compile( r'^(?P<version>(?P<major>\d+)\.(?P<minor>\d+)\.(?P<subminor>\d+))' r'((rc(?P<release_candidate>\d+))|dev)?-CAPI-(?P<capi_version>\d+\.\d+\.\d+)( r\d+)?$' )
if isinstance(value, (list, tuple)): pass elif numpy and isinstance(value, numpy.ndarray): pass else: raise TypeError('Must set coordinate with a sequence (list, tuple, or numpy array).') if self.dims == 3 and self._z: n_args = 3 set_3d = True else: n_args = 2 set_3d = False if len(value) != n_args: raise TypeError('Dimension of value does not match.') self.setX(index, value[0]) self.setY(index, value[1]) if set_3d: self.setZ(index, value[2])
def _checkindex(self, index): "Checks the given index." sz = self.size if (sz < 1) or (index < 0) or (index >= sz): raise IndexError('invalid GEOS Geometry index: %s' % str(index))
def getOrdinate(self, dimension, index): "Returns the value for the given dimension and index." self._checkindex(index) self._checkdim(dimension) return capi.cs_getordinate(self.ptr, index, dimension, byref(c_double()))
@property def size(self): "Returns the size of this coordinate sequence." return capi.cs_getsize(self.ptr, byref(c_uint()))
def clone(self): "Clones this coordinate sequence." return GEOSCoordSeq(capi.cs_clone(self.ptr), self.hasz)
if self.hasz: substr = '%s,%s,%s ' else: substr = '%s,%s,0 ' return '<coordinates>%s</coordinates>' % \ ''.join(substr % self[i] for i in range(len(self))).strip()
class WKBReader(_WKBReader): def read(self, wkb): "Returns a GEOSGeometry for the given WKB buffer." return GEOSGeometry(super(WKBReader, self).read(wkb))
geom = item.get('geometry') if geom is not None: if isinstance(geom, (list, tuple)): box_coords = None if isinstance(geom[0], (list, tuple)): if len(geom) == 2: box_coords = geom else: raise ValueError('Only should be two sets of coordinates.') else: if len(geom) == 2: self.add_georss_point(handler, geom, w3c_geo=w3c_geo) elif len(geom) == 4: box_coords = (geom[:2], geom[2:]) else: raise ValueError('Only should be 2 or 4 numeric elements.') if box_coords is not None: if w3c_geo: raise ValueError('Cannot use simple GeoRSS box in W3C Geo feeds.') handler.addQuickElement('georss:box', self.georss_coords(box_coords)) else: gtype = str(geom.geom_type).lower() if gtype == 'point': self.add_georss_point(handler, geom.coords, w3c_geo=w3c_geo) else: if w3c_geo: raise ValueError('W3C Geo only supports Point geometries.') if gtype in ('linestring', 'linearring'): handler.addQuickElement('georss:line', self.georss_coords(geom.coords)) elif gtype in ('polygon',): handler.addQuickElement('georss:polygon', self.georss_coords(geom[0].coords)) else: raise ValueError('Geometry type "%s" not supported.' % geom.geom_type)
class GeoRSSFeed(Rss201rev2Feed, GeoFeedMixin): def rss_attributes(self): attrs = super(GeoRSSFeed, self).rss_attributes() attrs['xmlns:georss'] = 'http://www.georss.org/georss' return attrs
hex_regex = re.compile(r'^[0-9A-F]+$', re.I) wkt_regex = re.compile(r'^(SRID=(?P<srid>\-?\d+);)?' r'(?P<wkt>' r'(?P<type>POINT|LINESTRING|LINEARRING|POLYGON|MULTIPOINT|' r'MULTILINESTRING|MULTIPOLYGON|GEOMETRYCOLLECTION)' r'[ACEGIMLONPSRUTYZ\d,\.\-\(\) ]+)$', re.I) json_regex = re.compile(r'^(\s+)?\{.*}(\s+)?$', re.DOTALL)
for field in obj._meta.fields: if hasattr(field, 'geom_type'): self.geometry_field = field.name break
if not HAS_GDAL: raise SerializationError( 'Unable to convert geometry to SRID %s when GDAL is not installed.' % self.srid ) if self._geometry.srid not in self._cts: srs = SpatialReference(self.srid) self._cts[self._geometry.srid] = CoordTransform(self._geometry.srs, srs) self._geometry.transform(self._cts[self._geometry.srid])
smin, smax, smean, sstd = c_double(), c_double(), c_double(), c_double() stats_args = [ self._ptr, c_int(approximate), byref(smin), byref(smax), byref(smean), byref(sstd), c_void_p(), c_void_p(), ]
force = True stats_args.insert(2, c_int(force)) func = capi.get_band_statistics
try: func(*stats_args) result = smin.value, smax.value, smean.value, sstd.value except GDALException: result = (None, None, None, None)
nodata_exists = c_int() value = capi.get_band_nodata_value(self._ptr, nodata_exists) if not nodata_exists: value = None elif self.datatype() in GDAL_INTEGER_TYPES: value = int(value) return value
ctypes_array = GDAL_TO_CTYPES[self.datatype()] * (shape[0] * shape[1])
access_flag = 0 data_array = ctypes_array()
access_flag = 1
if isinstance(data, (bytes, six.memoryview)) or (numpy and isinstance(data, numpy.ndarray)): data_array = ctypes_array.from_buffer_copy(data) else: data_array = ctypes_array(*data)
capi.band_io(self._ptr, access_flag, offset[0], offset[1], size[0], size[1], byref(data_array), shape[0], shape[1], self.datatype(), 0, 0)
if data is None: if as_memoryview: return memoryview(data_array) elif numpy: return numpy.frombuffer( data_array, dtype=numpy.dtype(data_array) ).reshape(tuple(reversed(size))) else: return list(data_array) else: self._flush()
GDAL_PIXEL_TYPES = {
GDAL_INTEGER_TYPES = [1, 2, 3, 4, 5]
GDAL_TO_CTYPES = [ None, c_ubyte, c_uint16, c_int16, c_uint32, c_int32, c_float, c_double, None, None, None, None ]
GDAL_RESAMPLE_ALGORITHMS = { 'NearestNeighbour': 0, 'Bilinear': 1, 'Cubic': 2, 'CubicSpline': 3, 'Lanczos': 4, 'Average': 5, 'Mode': 6, }
if isinstance(ds_input, six.string_types) and json_regex.match(ds_input): ds_input = json.loads(ds_input)
if isinstance(ds_input, six.string_types): if not os.path.exists(ds_input): raise GDALException('Unable to read raster source input "{}"'.format(ds_input)) try: self._ptr = capi.open_ds(force_bytes(ds_input), self._write) except GDALException as err: raise GDALException('Could not open the datasource at "{}" ({}).'.format(ds_input, err)) elif isinstance(ds_input, dict): self._write = 1
driver = Driver(ds_input.get('driver', 'MEM'))
if driver.name != 'MEM' and 'name' not in ds_input: raise GDALException('Specify name for creation of raster with driver "{}".'.format(driver.name))
if 'width' not in ds_input or 'height' not in ds_input: raise GDALException('Specify width and height attributes for JSON or dict input.')
if 'srid' not in ds_input: raise GDALException('Specify srid for JSON or dict input.')
self._ptr = capi.create_ds( driver._ptr, force_bytes(ds_input.get('name', '')), ds_input['width'], ds_input['height'], ds_input.get('nr_of_bands', len(ds_input.get('bands', []))), ds_input.get('datatype', 6), None )
for i, band_input in enumerate(ds_input.get('bands', [])): band = self.bands[i] band.data(band_input['data']) if 'nodata_value' in band_input: band.nodata_value = band_input['nodata_value']
self.srs = ds_input.get('srid')
if 'origin' in ds_input: self.origin.x, self.origin.y = ds_input['origin']
self._ptr = ds_input
if not self._write: raise GDALException('Raster needs to be opened in write mode to change values.') capi.flush_ds(self._ptr)
gtf = (c_double * 6)() capi.get_ds_geotransform(self._ptr, byref(gtf)) return list(gtf)
values = (c_double * 6)(*values) capi.set_ds_geotransform(self._ptr, byref(values)) self._flush()
xval = self.origin.x + self.scale.x * self.width yval = self.origin.y + self.scale.y * self.height xmin = min(xval, self.origin.x) xmax = max(xval, self.origin.x) ymin = min(yval, self.origin.y) ymax = max(yval, self.origin.y)
if 'width' not in ds_input: ds_input['width'] = self.width
if 'driver' not in ds_input: ds_input['driver'] = self.driver.name
ds_input['nr_of_bands'] = len(self.bands)
target = GDALRaster(ds_input, write=True)
for index, band in enumerate(self.bands): target.bands[index].nodata_value = band.nodata_value
algorithm = GDAL_RESAMPLE_ALGORITHMS[resampling]
capi.reproject_image( self._ptr, self.srs.wkt.encode(), target._ptr, target.srs.wkt.encode(), algorithm, 0.0, max_error, c_void_p(), c_void_p(), c_void_p() )
target._flush()
algorithm = GDAL_RESAMPLE_ALGORITHMS[resampling]
target_srs = SpatialReference(srid)
target = capi.auto_create_warped_vrt( self._ptr, self.srs.wkt.encode(), target_srs.wkt.encode(), algorithm, max_error, c_void_p() ) target = GDALRaster(target)
data = { 'srid': srid, 'width': target.width, 'height': target.height, 'origin': [target.origin.x, target.origin.y], 'scale': [target.scale.x, target.scale.y], 'skew': [target.skew.x, target.skew.y], }
if driver: data['driver'] = driver
return self.warp(data, resampling=resampling, max_error=max_error)
if isinstance(srs_input, six.text_type): srs_input = srs_input.encode('ascii') try: srid = int(srs_input) srs_input = 'EPSG:%d' % srid except ValueError: pass
srs_type = 'epsg'
srs = srs_input
buf = c_char_p(b'') srs = capi.new_srs(buf)
if not srs: raise SRSException('Could not create spatial reference from: %s' % srs_input) else: self.ptr = srs
if srs_type == 'user': self.import_user_input(srs_input) elif srs_type == 'epsg': self.import_epsg(srs_input)
@property def name(self): "Returns the name of this Spatial Reference." if self.projected: return self.attr_value('PROJCS') elif self.geographic: return self.attr_value('GEOGCS') elif self.local: return self.attr_value('LOCAL_CS') else: return None
@property def linear_name(self): "Returns the name of the linear units." units, name = capi.linear_units(self.ptr, byref(c_char_p())) return name
def import_epsg(self, epsg): "Imports the Spatial Reference from the EPSG code (an integer)." capi.from_epsg(self.ptr, epsg)
@property def wkt(self): "Returns the WKT representation of this Spatial Reference." return capi.to_wkt(self.ptr, byref(c_char_p()))
try:
_alias = { 'esri': 'ESRI Shapefile', 'shp': 'ESRI Shapefile', 'shape': 'ESRI Shapefile', 'tiger': 'TIGER', 'tiger/line': 'TIGER', 'tiff': 'GTiff', 'tif': 'GTiff', 'jpeg': 'JPEG', 'jpg': 'JPEG', }
self.ensure_registered()
if dr_input.lower() in self._alias: name = self._alias[dr_input.lower()] else: name = dr_input
for iface in (vcapi, rcapi): driver = iface.get_driver_by_name(force_bytes(name)) if driver: break
if not driver: raise GDALException('Could not initialize GDAL/OGR Driver on input: %s' % str(dr_input)) self.ptr = driver
if not cls.driver_count(): vcapi.register_all() rcapi.register_all()
self._feat = feat self._index = index
fld_ptr = capi.get_feat_field_defn(feat.ptr, index) if not fld_ptr: raise GDALException('Cannot create OGR Field, invalid pointer given.') self.ptr = fld_ptr
self.__class__ = OGRFieldTypes[self.type]
if isinstance(self, OFTReal) and self.precision == 0: self.__class__ = OFTInteger self._double = True
def as_double(self): "Retrieves the Field's value as a double (float)." return capi.get_field_as_double(self._feat.ptr, self._index)
@property def name(self): "Returns the name of this Field." name = capi.get_field_name(self.ptr) return force_text(name, encoding=self._feat.encoding, strings_only=True)
return self.as_string()
class OFTInteger(Field): _double = False _bit64 = False
return int(self.as_double())
class OFTString(Field): pass
class OFTDate(Field): @property def value(self): "Returns a Python `date` object for the OFTDate field." try: yy, mm, dd, hh, mn, ss, tz = self.as_datetime() return date(yy.value, mm.value, dd.value) except (ValueError, GDALException): return None
try: yy, mm, dd, hh, mn, ss, tz = self.as_datetime() return datetime(yy.value, mm.value, dd.value, hh.value, mn.value, ss.value) except (ValueError, GDALException): return None
class OFTIntegerList(Field): pass
OGRFieldTypes = { 0: OFTInteger, 1: OFTIntegerList, 2: OFTReal, 3: OFTRealList, 4: OFTString, 5: OFTStringList, 6: OFTWideString, 7: OFTWideStringList, 8: OFTBinary, 9: OFTDate, 10: OFTTime, 11: OFTDateTime, 12: OFTInteger64, 13: OFTInteger64List, } ROGRFieldTypes = {cls: num for num, cls in OGRFieldTypes.items()}
def arg_byref(args, offset=-1): "Returns the pointer argument's by-reference value." return args[offset]._obj.value
ptr = result if not ptr: s = None else: s = string_at(result)
check_err(result) ptr = ptr_byref(cargs, offset) s = ptr.value
def check_envelope(result, func, cargs, offset=-1): "Checks a function that returns an OGR Envelope by reference." env = ptr_byref(cargs, offset) return env
def check_geom(result, func, cargs): "Checks a function that returns a geometry." if isinstance(result, six.integer_types): result = c_void_p(result) if not result: raise GDALException('Invalid geometry pointer returned from "%s".' % func.__name__) return result
def check_srs(result, func, cargs): if isinstance(result, six.integer_types): result = c_void_p(result) if not result: raise SRSException('Invalid spatial reference pointer returned from "%s".' % func.__name__) return result
clone_srs = srs_output(std_call('OSRClone'), [c_void_p]) new_srs = srs_output(std_call('OSRNewSpatialReference'), [c_char_p]) release_srs = void_output(lgdal.OSRRelease, [c_void_p], errcheck=False) destroy_srs = void_output(std_call('OSRDestroySpatialReference'), [c_void_p], errcheck=False) srs_validate = void_output(lgdal.OSRValidate, [c_void_p])
semi_major = srs_double(lgdal.OSRGetSemiMajor) semi_minor = srs_double(lgdal.OSRGetSemiMinor) invflattening = srs_double(lgdal.OSRGetInvFlattening)
from_wkt = void_output(lgdal.OSRImportFromWkt, [c_void_p, POINTER(c_char_p)]) from_proj = void_output(lgdal.OSRImportFromProj4, [c_void_p, c_char_p]) from_epsg = void_output(std_call('OSRImportFromEPSG'), [c_void_p, c_int]) from_xml = void_output(lgdal.OSRImportFromXML, [c_void_p, c_char_p]) from_user_input = void_output(std_call('OSRSetFromUserInput'), [c_void_p, c_char_p])
morph_to_esri = void_output(lgdal.OSRMorphToESRI, [c_void_p]) morph_from_esri = void_output(lgdal.OSRMorphFromESRI, [c_void_p])
identify_epsg = void_output(lgdal.OSRAutoIdentifyEPSG, [c_void_p])
linear_units = units_func(lgdal.OSRGetLinearUnits) angular_units = units_func(lgdal.OSRGetAngularUnits)
to_wkt = string_output(std_call('OSRExportToWkt'), [c_void_p, POINTER(c_char_p)], decoding='ascii') to_proj = string_output(std_call('OSRExportToProj4'), [c_void_p, POINTER(c_char_p)], decoding='ascii') to_pretty_wkt = string_output( std_call('OSRExportToPrettyWkt'), [c_void_p, POINTER(c_char_p), c_int], offset=-2, decoding='ascii' )
to_xml = string_output(lgdal.OSRExportToXML, [c_void_p, POINTER(c_char_p), c_char_p], offset=-2, decoding='ascii')
get_attr_value = const_string_output(std_call('OSRGetAttrValue'), [c_void_p, c_char_p, c_int], decoding='ascii') get_auth_name = const_string_output(lgdal.OSRGetAuthorityName, [c_void_p, c_char_p], decoding='ascii') get_auth_code = const_string_output(lgdal.OSRGetAuthorityCode, [c_void_p, c_char_p], decoding='ascii')
isgeographic = int_output(lgdal.OSRIsGeographic, [c_void_p]) islocal = int_output(lgdal.OSRIsLocal, [c_void_p]) isprojected = int_output(lgdal.OSRIsProjected, [c_void_p])
new_ct = srs_output(std_call('OCTNewCoordinateTransformation'), [c_void_p, c_void_p]) destroy_ct = void_output(std_call('OCTDestroyCoordinateTransformation'), [c_void_p], errcheck=False)
register_all = void_output(lgdal.OGRRegisterAll, [], errcheck=False) cleanup_all = void_output(lgdal.OGRCleanupAll, [], errcheck=False) get_driver = voidptr_output(lgdal.OGRGetDriver, [c_int]) get_driver_by_name = voidptr_output(lgdal.OGRGetDriverByName, [c_char_p], errcheck=False) get_driver_count = int_output(lgdal.OGRGetDriverCount, []) get_driver_name = const_string_output(lgdal.OGR_Dr_GetName, [c_void_p], decoding='ascii')
open_ds = voidptr_output(lgdal.OGROpen, [c_char_p, c_int, POINTER(c_void_p)]) destroy_ds = void_output(lgdal.OGR_DS_Destroy, [c_void_p], errcheck=False) release_ds = void_output(lgdal.OGRReleaseDataSource, [c_void_p]) get_ds_name = const_string_output(lgdal.OGR_DS_GetName, [c_void_p]) get_layer = voidptr_output(lgdal.OGR_DS_GetLayer, [c_void_p, c_int]) get_layer_by_name = voidptr_output(lgdal.OGR_DS_GetLayerByName, [c_void_p, c_char_p]) get_layer_count = int_output(lgdal.OGR_DS_GetLayerCount, [c_void_p])
get_extent = void_output(lgdal.OGR_L_GetExtent, [c_void_p, POINTER(OGREnvelope), c_int]) get_feature = voidptr_output(lgdal.OGR_L_GetFeature, [c_void_p, c_long]) get_feature_count = int_output(lgdal.OGR_L_GetFeatureCount, [c_void_p, c_int]) get_layer_defn = voidptr_output(lgdal.OGR_L_GetLayerDefn, [c_void_p]) get_layer_srs = srs_output(lgdal.OGR_L_GetSpatialRef, [c_void_p]) get_next_feature = voidptr_output(lgdal.OGR_L_GetNextFeature, [c_void_p]) reset_reading = void_output(lgdal.OGR_L_ResetReading, [c_void_p], errcheck=False) test_capability = int_output(lgdal.OGR_L_TestCapability, [c_void_p, c_char_p]) get_spatial_filter = geom_output(lgdal.OGR_L_GetSpatialFilter, [c_void_p]) set_spatial_filter = void_output(lgdal.OGR_L_SetSpatialFilter, [c_void_p, c_void_p], errcheck=False) set_spatial_filter_rect = void_output( lgdal.OGR_L_SetSpatialFilterRect, [c_void_p, c_double, c_double, c_double, c_double], errcheck=False )
get_fd_geom_type = int_output(lgdal.OGR_FD_GetGeomType, [c_void_p]) get_fd_name = const_string_output(lgdal.OGR_FD_GetName, [c_void_p]) get_feat_name = const_string_output(lgdal.OGR_FD_GetName, [c_void_p]) get_field_count = int_output(lgdal.OGR_FD_GetFieldCount, [c_void_p]) get_field_defn = voidptr_output(lgdal.OGR_FD_GetFieldDefn, [c_void_p, c_int])
clone_feature = voidptr_output(lgdal.OGR_F_Clone, [c_void_p]) destroy_feature = void_output(lgdal.OGR_F_Destroy, [c_void_p], errcheck=False) feature_equal = int_output(lgdal.OGR_F_Equal, [c_void_p, c_void_p]) get_feat_geom_ref = geom_output(lgdal.OGR_F_GetGeometryRef, [c_void_p]) get_feat_field_count = int_output(lgdal.OGR_F_GetFieldCount, [c_void_p]) get_feat_field_defn = voidptr_output(lgdal.OGR_F_GetFieldDefnRef, [c_void_p, c_int]) get_fid = int_output(lgdal.OGR_F_GetFID, [c_void_p]) get_field_as_datetime = int_output( lgdal.OGR_F_GetFieldAsDateTime, [c_void_p, c_int, c_int_p, c_int_p, c_int_p, c_int_p, c_int_p, c_int_p] ) get_field_as_double = double_output(lgdal.OGR_F_GetFieldAsDouble, [c_void_p, c_int]) get_field_as_integer = int_output(lgdal.OGR_F_GetFieldAsInteger, [c_void_p, c_int]) if GDAL_VERSION >= (2, 0): get_field_as_integer64 = int64_output(lgdal.OGR_F_GetFieldAsInteger64, [c_void_p, c_int]) get_field_as_string = const_string_output(lgdal.OGR_F_GetFieldAsString, [c_void_p, c_int]) get_field_index = int_output(lgdal.OGR_F_GetFieldIndex, [c_void_p, c_char_p])
get_field_name = const_string_output(lgdal.OGR_Fld_GetNameRef, [c_void_p]) get_field_precision = int_output(lgdal.OGR_Fld_GetPrecision, [c_void_p]) get_field_type = int_output(lgdal.OGR_Fld_GetType, [c_void_p]) get_field_type_name = const_string_output(lgdal.OGR_GetFieldTypeName, [c_int]) get_field_width = int_output(lgdal.OGR_Fld_GetWidth, [c_void_p])
void_output = partial(void_output, cpl=True) const_string_output = partial(const_string_output, cpl=True) double_output = partial(double_output, cpl=True)
register_all = void_output(std_call('GDALAllRegister'), []) get_driver = voidptr_output(std_call('GDALGetDriver'), [c_int]) get_driver_by_name = voidptr_output(std_call('GDALGetDriverByName'), [c_char_p], errcheck=False) get_driver_count = int_output(std_call('GDALGetDriverCount'), []) get_driver_description = const_string_output(std_call('GDALGetDescription'), [c_void_p])
create_ds = voidptr_output(std_call('GDALCreate'), [c_void_p, c_char_p, c_int, c_int, c_int, c_int, c_void_p]) open_ds = voidptr_output(std_call('GDALOpen'), [c_char_p, c_int]) if GDAL_VERSION >= (2, 0): close_ds = voidptr_output(std_call('GDALClose'), [c_void_p]) else: close_ds = void_output(std_call('GDALClose'), [c_void_p]) flush_ds = int_output(std_call('GDALFlushCache'), [c_void_p]) copy_ds = voidptr_output( std_call('GDALCreateCopy'), [c_void_p, c_char_p, c_void_p, c_int, POINTER(c_char_p), c_void_p, c_void_p] ) add_band_ds = void_output(std_call('GDALAddBand'), [c_void_p, c_int]) get_ds_description = const_string_output(std_call('GDALGetDescription'), [c_void_p]) get_ds_driver = voidptr_output(std_call('GDALGetDatasetDriver'), [c_void_p]) get_ds_xsize = int_output(std_call('GDALGetRasterXSize'), [c_void_p]) get_ds_ysize = int_output(std_call('GDALGetRasterYSize'), [c_void_p]) get_ds_raster_count = int_output(std_call('GDALGetRasterCount'), [c_void_p]) get_ds_raster_band = voidptr_output(std_call('GDALGetRasterBand'), [c_void_p, c_int]) get_ds_projection_ref = const_string_output(std_call('GDALGetProjectionRef'), [c_void_p]) set_ds_projection_ref = void_output(std_call('GDALSetProjection'), [c_void_p, c_char_p]) get_ds_geotransform = void_output(std_call('GDALGetGeoTransform'), [c_void_p, POINTER(c_double * 6)], errcheck=False) set_ds_geotransform = void_output(std_call('GDALSetGeoTransform'), [c_void_p, POINTER(c_double * 6)])
band_io = void_output( std_call('GDALRasterIO'), [c_void_p, c_int, c_int, c_int, c_int, c_int, c_void_p, c_int, c_int, c_int, c_int, c_int] ) get_band_xsize = int_output(std_call('GDALGetRasterBandXSize'), [c_void_p]) get_band_ysize = int_output(std_call('GDALGetRasterBandYSize'), [c_void_p]) get_band_index = int_output(std_call('GDALGetBandNumber'), [c_void_p]) get_band_description = const_string_output(std_call('GDALGetDescription'), [c_void_p]) get_band_ds = voidptr_output(std_call('GDALGetBandDataset'), [c_void_p]) get_band_datatype = int_output(std_call('GDALGetRasterDataType'), [c_void_p]) get_band_nodata_value = double_output(std_call('GDALGetRasterNoDataValue'), [c_void_p, POINTER(c_int)]) set_band_nodata_value = void_output(std_call('GDALSetRasterNoDataValue'), [c_void_p, c_double]) if GDAL_VERSION >= (2, 1): delete_band_nodata_value = void_output(std_call('GDALDeleteRasterNoDataValue'), [c_void_p]) else: delete_band_nodata_value = None get_band_statistics = void_output( std_call('GDALGetRasterStatistics'), [ c_void_p, c_int, c_int, POINTER(c_double), POINTER(c_double), POINTER(c_double), POINTER(c_double), c_void_p, c_void_p, ], ) compute_band_statistics = void_output( std_call('GDALComputeRasterStatistics'), [c_void_p, c_int, POINTER(c_double), POINTER(c_double), POINTER(c_double), POINTER(c_double), c_void_p, c_void_p], )
reproject_image = void_output( std_call('GDALReprojectImage'), [c_void_p, c_char_p, c_void_p, c_char_p, c_int, c_double, c_double, c_void_p, c_void_p, c_void_p] ) auto_create_warped_vrt = voidptr_output( std_call('GDALAutoCreateWarpedVRT'), [c_void_p, c_char_p, c_char_p, c_int, c_double, c_void_p] )
func.argtypes = argtypes
func.restype = c_void_p func.errcheck = check_geom
func.restype = c_int
func.restype = gdal_char_p
func.restype = c_int
def _check_str(result, func, cargs): res = check_string(result, func, cargs, offset=offset, str_result=str_result) if res and decoding: res = res.decode(decoding) return res func.errcheck = _check_str return func
func.restype = c_int func.errcheck = partial(check_errcode, cpl=cpl)
def env_func(f, argtypes): "For getting OGREnvelopes." f.argtypes = argtypes f.restype = None f.errcheck = check_envelope return f
from_json = geom_output(lgdal.OGR_G_CreateGeometryFromJson, [c_char_p]) to_json = string_output(lgdal.OGR_G_ExportToJson, [c_void_p], str_result=True, decoding='ascii') to_kml = string_output(lgdal.OGR_G_ExportToKML, [c_void_p, c_char_p], str_result=True, decoding='ascii')
getx = pnt_func(lgdal.OGR_G_GetX) gety = pnt_func(lgdal.OGR_G_GetY) getz = pnt_func(lgdal.OGR_G_GetZ)
from_wkb = geom_output(lgdal.OGR_G_CreateFromWkb, [c_char_p, c_void_p, POINTER(c_void_p), c_int], offset=-2) from_wkt = geom_output(lgdal.OGR_G_CreateFromWkt, [POINTER(c_char_p), c_void_p, POINTER(c_void_p)], offset=-1) create_geom = geom_output(lgdal.OGR_G_CreateGeometry, [c_int]) clone_geom = geom_output(lgdal.OGR_G_Clone, [c_void_p]) get_geom_ref = geom_output(lgdal.OGR_G_GetGeometryRef, [c_void_p, c_int]) get_boundary = geom_output(lgdal.OGR_G_GetBoundary, [c_void_p]) geom_convex_hull = geom_output(lgdal.OGR_G_ConvexHull, [c_void_p]) geom_diff = geom_output(lgdal.OGR_G_Difference, [c_void_p, c_void_p]) geom_intersection = geom_output(lgdal.OGR_G_Intersection, [c_void_p, c_void_p]) geom_sym_diff = geom_output(lgdal.OGR_G_SymmetricDifference, [c_void_p, c_void_p]) geom_union = geom_output(lgdal.OGR_G_Union, [c_void_p, c_void_p])
add_geom = void_output(lgdal.OGR_G_AddGeometry, [c_void_p, c_void_p]) import_wkt = void_output(lgdal.OGR_G_ImportFromWkt, [c_void_p, POINTER(c_char_p)])
destroy_geom = void_output(lgdal.OGR_G_DestroyGeometry, [c_void_p], errcheck=False)
assign_srs = void_output(lgdal.OGR_G_AssignSpatialReference, [c_void_p, c_void_p], errcheck=False) get_geom_srs = srs_output(lgdal.OGR_G_GetSpatialReference, [c_void_p])
get_area = double_output(lgdal.OGR_G_GetArea, [c_void_p]) get_centroid = void_output(lgdal.OGR_G_Centroid, [c_void_p, c_void_p]) get_dims = int_output(lgdal.OGR_G_GetDimension, [c_void_p]) get_coord_dim = int_output(lgdal.OGR_G_GetCoordinateDimension, [c_void_p]) set_coord_dim = void_output(lgdal.OGR_G_SetCoordinateDimension, [c_void_p, c_int], errcheck=False)
ogr_contains = topology_func(lgdal.OGR_G_Contains) ogr_crosses = topology_func(lgdal.OGR_G_Crosses) ogr_disjoint = topology_func(lgdal.OGR_G_Disjoint) ogr_equals = topology_func(lgdal.OGR_G_Equals) ogr_intersects = topology_func(lgdal.OGR_G_Intersects) ogr_overlaps = topology_func(lgdal.OGR_G_Overlaps) ogr_touches = topology_func(lgdal.OGR_G_Touches) ogr_within = topology_func(lgdal.OGR_G_Within)
geom_transform = void_output(lgdal.OGR_G_Transform, [c_void_p, c_void_p]) geom_transform_to = void_output(lgdal.OGR_G_TransformTo, [c_void_p, c_void_p])
get_envelope = env_func(lgdal.OGR_G_GetEnvelope, [c_void_p, POINTER(OGREnvelope)])
class GDALException(Exception): pass
OGRException = GDALException
OGRERR_DICT = { 1: (GDALException, 'Not enough data.'), 2: (GDALException, 'Not enough memory.'), 3: (GDALException, 'Unsupported geometry type.'), 4: (GDALException, 'Unsupported operation.'), 5: (GDALException, 'Corrupt data.'), 6: (GDALException, 'OGR failure.'), 7: (SRSException, 'Unsupported SRS.'), 8: (GDALException, 'Invalid handle.'), }
CPLERR_DICT = { 1: (GDALException, 'AppDefined'), 2: (GDALException, 'OutOfMemory'), 3: (GDALException, 'FileIO'), 4: (GDALException, 'OpenFailed'), 5: (GDALException, 'IllegalArg'), 6: (GDALException, 'NotSupported'), 7: (GDALException, 'AssertionFailed'), 8: (GDALException, 'NoWriteAccess'), 9: (GDALException, 'UserInterrupt'), 10: (GDALException, 'ObjectNull'), }
_types = {0: 'Unknown', 1: 'Point', 2: 'LineString', 3: 'Polygon', 4: 'MultiPoint', 5: 'MultiLineString', 6: 'MultiPolygon', 7: 'GeometryCollection', 100: 'None', 101: 'LinearRing', 1 + wkb25bit: 'Point25D', 2 + wkb25bit: 'LineString25D', 3 + wkb25bit: 'Polygon25D', 4 + wkb25bit: 'MultiPoint25D', 5 + wkb25bit: 'MultiLineString25D', 6 + wkb25bit: 'MultiPolygon25D', 7 + wkb25bit: 'GeometryCollection25D', } _str_types = {v.lower(): k for k, v in _types.items()}
self.num = num
class OGREnvelope(Structure): "Represents the OGREnvelope C Structure." _fields_ = [("MinX", c_double), ("MaxX", c_double), ("MinY", c_double), ("MaxY", c_double), ]
self._envelope = args[0]
if len(args[0]) != 4: raise GDALException('Incorrect number of tuple elements (%d).' % len(args[0])) else: self._from_sequence(args[0])
self._from_sequence([float(a) for a in args])
if self.min_x > self.max_x: raise GDALException('Envelope minimum X > maximum X.') if self.min_y > self.max_y: raise GDALException('Envelope minimum Y > maximum Y.')
if len(args) == 1: if isinstance(args[0], Envelope): return self.expand_to_include(args[0].tuple) elif hasattr(args[0], 'x') and hasattr(args[0], 'y'): return self.expand_to_include(args[0].x, args[0].y, args[0].x, args[0].y) elif isinstance(args[0], (tuple, list)): if len(args[0]) == 2: return self.expand_to_include((args[0][0], args[0][1], args[0][0], args[0][1])) elif len(args[0]) == 4: (minx, miny, maxx, maxy) = args[0] if minx < self._envelope.MinX: self._envelope.MinX = minx if miny < self._envelope.MinY: self._envelope.MinY = miny if maxx > self._envelope.MaxX: self._envelope.MaxX = maxx if maxy > self._envelope.MaxY: self._envelope.MaxY = maxy else: raise GDALException('Incorrect number of tuple elements (%d).' % len(args[0])) else: raise TypeError('Incorrect type of argument: %s' % str(type(args[0]))) elif len(args) == 2: return self.expand_to_include((args[0], args[1], args[0], args[1])) elif len(args) == 4: return self.expand_to_include(args) else: raise GDALException('Incorrect number (%d) of arguments.' % len(args[0]))
return 'POLYGON((%s %s,%s %s,%s %s,%s %s,%s %s))' % \ (self.min_x, self.min_y, self.min_x, self.max_y, self.max_x, self.max_y, self.max_x, self.min_y, self.min_x, self.min_y)
try: from django.conf import settings lib_path = settings.GDAL_LIBRARY_PATH except (AttributeError, EnvironmentError, ImportError, ImproperlyConfigured): lib_path = None
lib_names = ['gdal111', 'gdal110', 'gdal19', 'gdal18', 'gdal17']
lib_names = ['gdal', 'GDAL', 'gdal1.11.0', 'gdal1.10.0', 'gdal1.9.0', 'gdal1.8.0', 'gdal1.7.0']
if lib_names: for lib_name in lib_names: lib_path = find_library(lib_name) if lib_path is not None: break
lgdal = CDLL(lib_path)
if os.name == 'nt': from ctypes import WinDLL lwingdal = WinDLL(lib_path)
_version_info = std_call('GDALVersionInfo') _version_info.argtypes = [c_char_p] _version_info.restype = c_char_p
CPLErrorHandler = CFUNCTYPE(None, c_int, c_int, c_char_p)
class Layer(GDALBase): "A class that wraps an OGR Layer, needs to be instantiated from a DataSource object."
self._random_read = self.test_capability(b'RandomRead')
if index < 0: raise OGRIndexError('Negative indices are not allowed on OGR Layers.') return self._make_feature(index)
start, stop, stride = index.indices(self.num_feat) return [self._make_feature(fid) for fid in range(start, stop, stride)]
capi.reset_reading(self._ptr) for i in range(self.num_feat): yield Feature(capi.get_next_feature(self._ptr), self)
try: return Feature(capi.get_feature(self.ptr, feat_id), self) except GDALException: pass
for feat in self: if feat.fid == feat_id: return feat
@property def extent(self): "Returns the extent (an Envelope) of this layer." env = OGREnvelope() capi.get_extent(self.ptr, byref(env), 1) return Envelope(env)
xmin, ymin, xmax, ymax = map(c_double, filter) capi.set_spatial_filter_rect(self.ptr, xmin, ymin, xmax, ymax)
class OGRGeometry(GDALBase): "Generally encapsulates an OGR geometry."
if str_instance and hex_regex.match(geom_input): geom_input = six.memoryview(a2b_hex(geom_input.upper().encode())) str_instance = False
if str_instance: wkt_m = wkt_regex.match(geom_input) json_m = json_regex.match(geom_input) if wkt_m: if wkt_m.group('srid'): srs = int(wkt_m.group('srid')) if wkt_m.group('type').upper() == 'LINEARRING': g = capi.create_geom(OGRGeomType(wkt_m.group('type')).num) capi.import_wkt(g, byref(c_char_p(wkt_m.group('wkt').encode()))) else: g = capi.from_wkt(byref(c_char_p(wkt_m.group('wkt').encode())), None, byref(c_void_p())) elif json_m: g = capi.from_json(geom_input.encode()) else: OGRGeomType(geom_input) g = capi.create_geom(OGRGeomType(geom_input).num) elif isinstance(geom_input, six.memoryview): g = capi.from_wkb(bytes(geom_input), None, byref(c_void_p()), len(geom_input)) elif isinstance(geom_input, OGRGeomType): g = capi.create_geom(geom_input.num) elif isinstance(geom_input, self.ptr_type): g = geom_input else: raise GDALException('Invalid input type for OGR Geometry construction: %s' % type(geom_input))
if not g: raise GDALException('Cannot create OGR Geometry from input: %s' % str(geom_input)) self.ptr = g
if srs: self.srs = srs
self.__class__ = GEO_CLASSES[self.geom_type.num]
def __getstate__(self): srs = self.srs if srs: srs = srs.wkt else: srs = None return bytes(self.wkb), srs
def __or__(self, other): "Returns the union of the two geometries." return self.union(other)
def __and__(self, other): "Returns the intersection of this Geometry and the other." return self.intersection(other)
def __sub__(self, other): "Return the difference this Geometry and the other." return self.difference(other)
def __xor__(self, other): "Return the symmetric difference of this Geometry and the other." return self.sym_difference(other)
@property def dimension(self): "Returns 0 for points, 1 for lines, and 2 for surfaces." return capi.get_dims(self.ptr)
return Envelope(capi.get_envelope(self.ptr, byref(OGREnvelope())))
def _get_srs(self): "Returns the Spatial Reference for this Geometry." try: srs_ptr = capi.get_geom_srs(self.ptr) return SpatialReference(srs_api.clone_srs(srs_ptr)) except SRSException: return None
if isinstance(srs, SpatialReference): srs_ptr = srs.ptr elif isinstance(srs, six.integer_types + six.string_types): sr = SpatialReference(srs) srs_ptr = sr.ptr elif srs is None: srs_ptr = None else: raise TypeError('Cannot assign spatial reference with object of type: %s' % type(srs)) capi.assign_srs(self.ptr, srs_ptr)
def _get_srid(self): srs = self.srs if srs: return srs.srid return None
@property def geos(self): "Returns a GEOSGeometry object from this OGRGeometry." from django.contrib.gis.geos import GEOSGeometry return GEOSGeometry(self.wkb, self.srid)
buf = (c_ubyte * sz)() capi.to_wkb(self.ptr, byteorder, byref(buf)) return six.memoryview(string_at(buf, sz))
def clone(self): "Clones this OGR Geometry." return OGRGeometry(capi.clone_geom(self.ptr), self.srs)
capi.geom_close_rings(self.ptr)
if isinstance(coord_trans, CoordTransform): capi.geom_transform(self.ptr, coord_trans.ptr) elif isinstance(coord_trans, SpatialReference): capi.geom_transform_to(self.ptr, coord_trans.ptr) elif isinstance(coord_trans, six.integer_types + six.string_types): sr = SpatialReference(coord_trans) capi.geom_transform_to(self.ptr, sr.ptr) else: raise TypeError('Transform only accepts CoordTransform, ' 'SpatialReference, string, and integer objects.')
return func(self.ptr, other.ptr)
def _geomgen(self, gen_func, other=None): "A helper routine for the OGR routines that generate geometries." if isinstance(other, OGRGeometry): return OGRGeometry(gen_func(self.ptr, other.ptr), self.srs) else: return OGRGeometry(gen_func(self.ptr), self.srs)
class Point(OGRGeometry):
class LinearRing(LineString): pass
@property def shell(self): "Returns the shell of this Polygon."
return sum(self[i].point_count for i in range(self.geom_count))
p = OGRGeometry(OGRGeomType('Point')) capi.get_centroid(self.ptr, p.ptr) return p
class GeometryCollection(OGRGeometry): "The Geometry Collection class."
return sum(self[i].point_count for i in range(self.geom_count))
class MultiPoint(GeometryCollection): pass
GEO_CLASSES = {1: Point, 2: LineString, 3: Polygon, 4: MultiPoint, 5: MultiLineString, 6: MultiPolygon, 7: GeometryCollection, 101: LinearRing, 1 + OGRGeomType.wkb25bit: Point, 2 + OGRGeomType.wkb25bit: LineString, 3 + OGRGeomType.wkb25bit: Polygon, 4 + OGRGeomType.wkb25bit: MultiPoint, 5 + OGRGeomType.wkb25bit: MultiLineString, 6 + OGRGeomType.wkb25bit: MultiPolygon, 7 + OGRGeomType.wkb25bit: GeometryCollection, }
_ptr = None
ptr_type = c_void_p
def _get_ptr(self): if self._ptr: return self._ptr else: raise GDALException('GDAL %s pointer no longer valid.' % self.__class__.__name__)
if isinstance(ptr, six.integer_types): self._ptr = self.ptr_type(ptr) elif ptr is None or isinstance(ptr, self.ptr_type): self._ptr = ptr else: raise TypeError('Incompatible pointer type')
@property def encoding(self): return self._layer._ds.encoding
geom_ptr = capi.get_feat_geom_ref(self.ptr) return OGRGeometry(geom_api.clone_geom(geom_ptr))
g = feature.geom
desc = feature['description']
for field in feature: nm = field.name
t = field.type
class DataSource(GDALBase): "Wraps an OGR Data Source object."
if write: self._write = 1 else: self._write = 0 self.encoding = encoding
ds_driver = Driver.ptr_type() try: ds = capi.open_ds(force_bytes(ds_input), self._write, byref(ds_driver)) except GDALException: raise GDALException('Could not open the datasource at "%s"' % ds_input)
raise GDALException('Invalid data source file "%s"' % ds_input)
if messages is None: break if messages: self._used_storages.add(storage) all_messages.extend(messages) if all_retrieved: break
elif storage in self._used_storages: storage._store([], response) self._used_storages.remove(storage)
is_safedata = 1 if isinstance(obj.message, SafeData) else 0 message = [self.message_key, is_safedata, obj.level, obj.message] if obj.extra_tags: message.append(obj.extra_tags) return message
return Message(*obj[1:])
max_cookie_size = 2048 not_finished = '__messagesnotfinished__'
messages.pop()
return json.loads(value, cls=MessageDecoder)
self.used = True return None
level = int(level) if level < self.level: return self.added_new = True message = Message(level, message, extra_tags=extra_tags) self._queued_messages.append(message)
if hasattr(request, '_messages'): unstored_messages = request._messages.update(response) if unstored_messages and settings.DEBUG: raise ValueError('Not all temporary messages could be stored.') return response
if not modeladmin.has_delete_permission(request): raise PermissionDenied
deletable_objects, model_count, perms_needed, protected = get_deleted_objects( queryset, opts, request.user, modeladmin.admin_site, using)
if request.POST.get('post') and not protected: if perms_needed: raise PermissionDenied n = queryset.count() if n: for obj in queryset: obj_display = force_text(obj) modeladmin.log_deletion(request, obj, obj_display) queryset.delete() modeladmin.message_user(request, _("Successfully deleted %(count)d %(items)s.") % { "count": n, "items": model_ngettext(modeladmin.opts, n) }, messages.SUCCESS) return None
return TemplateResponse(request, modeladmin.delete_selected_confirmation_template or [ "admin/%s/%s/delete_selected_confirmation.html" % (app_label, opts.model_name), "admin/%s/delete_selected_confirmation.html" % app_label, "admin/delete_selected_confirmation.html" ], context)
object_repr = models.CharField(_('object repr'), max_length=200) action_flag = models.PositiveSmallIntegerField(_('action flag')) change_message = models.TextField(_('change message'), blank=True)
self.wait_for('body')
pass
with self.disable_implicit_wait(): self.wait_until( lambda driver: len(driver.find_elements_by_css_selector(options_selector)) == 0 )
from django.contrib.admin.decorators import register from django.contrib.admin.filters import ( AllValuesFieldListFilter, BooleanFieldListFilter, ChoicesFieldListFilter, DateFieldListFilter, FieldListFilter, ListFilter, RelatedFieldListFilter, RelatedOnlyFieldListFilter, SimpleListFilter, ) from django.contrib.admin.helpers import ACTION_CHECKBOX_NAME from django.contrib.admin.options import ( HORIZONTAL, VERTICAL, ModelAdmin, StackedInline, TabularInline, ) from django.contrib.admin.sites import AdminSite, site from django.utils.module_loading import autodiscover_modules
self.used_parameters = {} if self.title is None: raise ImproperlyConfigured( "The list filter '%s' does not specify " "a 'title'." % self.__class__.__name__)
parameter_name = None
cls._field_list_filters.insert( cls._take_priority_index, (test, list_filter_class)) cls._take_priority_index += 1
if timezone.is_aware(now): now = timezone.localtime(now)
class AllValuesFieldListFilter(FieldListFilter): def __init__(self, field, request, params, model, model_admin, field_path): self.lookup_kwarg = field_path self.lookup_kwarg_isnull = '%s__isnull' % field_path self.lookup_val = request.GET.get(self.lookup_kwarg) self.lookup_val_isnull = request.GET.get(self.lookup_kwarg_isnull) self.empty_value_display = model_admin.get_empty_value_display() parent_model, reverse_path = reverse_field_path(model, field_path) if model == parent_model: queryset = model_admin.get_queryset(request) else: queryset = parent_model._default_manager.all() self.lookup_choices = (queryset .distinct() .order_by(field.name) .values_list(field.name, flat=True)) super(AllValuesFieldListFilter, self).__init__( field, request, params, model, model_admin, field_path)
return self.field.label_tag( contents=mark_safe(contents), attrs=attrs, label_suffix='' if self.is_checkbox else None, )
if callable(field): class_name = field.__name__ if field.__name__ != '<lambda>' else '' else: class_name = field
if self.form._meta.model._meta.has_auto_field or not self.form._meta.model._meta.pk.editable: return True for parent in self.form._meta.model._meta.get_parent_list(): if parent._meta.has_auto_field: return True return False
from __future__ import unicode_literals
operations = [ migrations.AlterField( model_name='logentry', name='action_time', field=models.DateTimeField( verbose_name='action time', default=timezone.now, editable=False, ), ), ]
from __future__ import unicode_literals
for line in fieldset: for field in line: count += 1
count += 1
return _static(path)
if paginator.num_pages <= 10: page_range = range(paginator.num_pages) else: page_range = [] if page_num > (ON_EACH_SIDE + ON_ENDS): page_range.extend(range(0, ON_ENDS)) page_range.append(DOT) page_range.extend(range(page_num - ON_EACH_SIDE, page_num + 1)) else: page_range.extend(range(0, page_num + 1)) if page_num < (paginator.num_pages - ON_EACH_SIDE - ON_ENDS - 1): page_range.extend(range(page_num + 1, page_num + ON_EACH_SIDE + 1)) page_range.append(DOT) page_range.extend(range(paginator.num_pages - ON_ENDS, paginator.num_pages)) else: page_range.extend(range(page_num + 1, paginator.num_pages))
if field_name == 'action_checkbox': yield { "text": text, "class_attrib": mark_safe(' class="action-checkbox-column"'), "sortable": False, } continue
yield { "text": text, "class_attrib": format_html(' class="column-{}"', field_name), "sortable": False, } continue
th_classes = ['sortable', 'column-{}'.format(field_name)] order_type = '' new_order_type = 'asc' sort_priority = 0 sorted = False if i in ordering_field_columns: sorted = True order_type = ordering_field_columns.get(i).lower() sort_priority = list(ordering_field_columns).index(i) + 1 th_classes.append('sorted %sending' % order_type) new_order_type = {'asc': 'desc', 'desc': 'asc'}[order_type]
o_list_primary.insert(0, param) o_list_toggle.append(param)
if link_in_col(first, field_name, cl): table_tag = 'th' if first else 'td' first = False
try: url = cl.url_for_result(result) except NoReverseMatch: link_or_text = result_repr else: url = add_preserved_filters({'preserved_filters': cl.preserved_filters, 'opts': cl.opts}, url) if cl.to_field: attr = str(cl.to_field) else: attr = pk value = result.serializable_value(attr) link_or_text = format_html( '<a href="{}"{}>{}</a>', url, format_html( ' data-popup-opener="{}"', value ) if cl.is_popup else '', result_repr)
if (form and field_name in form.fields and not ( field_name == cl.model._meta.pk.name and form[cl.model._meta.pk.name].is_hidden)): bf = form[field_name] result_repr = mark_safe(force_text(bf.errors) + force_text(bf)) yield format_html('<td{}>{}</td>', row_class, result_repr)
def __init__(self, form, *items): self.form = form super(ResultList, self).__init__(*items)
date_range = cl.queryset.aggregate(first=models.Min(field_name), last=models.Max(field_name)) if date_range['first'] and date_range['last']: if date_range['first'].year == date_range['last'].year: year_lookup = date_range['first'].year if date_range['first'].month == date_range['last'].month: month_lookup = date_range['first'].month
site_title = ugettext_lazy('Django site admin')
site_header = ugettext_lazy('Django administration')
index_title = ugettext_lazy('Site administration')
site_url = '/'
if not model._meta.swapped: if options: options['__module__'] = __name__ admin_class = type("%sAdmin" % model.__name__, (admin_class,), options)
admin_obj = admin_class(model, self) if admin_class is not ModelAdmin and settings.DEBUG: system_check_errors.extend(admin_obj.check())
from django.contrib.auth.views import redirect_to_login return redirect_to_login( request.get_full_path(), reverse('admin:login', current_app=self.name) )
if not getattr(view, 'csrf_exempt', False): inner = csrf_protect(inner) return update_wrapper(inner, view)
from django.contrib.contenttypes import views as contenttype_views
urlpatterns = [ url(r'^$', wrap(self.index), name='index'), url(r'^login/$', self.login, name='login'), url(r'^logout/$', wrap(self.logout), name='logout'), url(r'^password_change/$', wrap(self.password_change, cacheable=True), name='password_change'), url(r'^password_change/done/$', wrap(self.password_change_done, cacheable=True), name='password_change_done'), url(r'^jsi18n/$', wrap(self.i18n_javascript, cacheable=True), name='jsi18n'), url(r'^r/(?P<content_type_id>\d+)/(?P<object_id>.+)/$', wrap(contenttype_views.shortcut), name='view_on_site'), ]
valid_app_labels = [] for model, model_admin in self._registry.items(): urlpatterns += [ url(r'^%s/%s/' % (model._meta.app_label, model._meta.model_name), include(model_admin.urls)), ] if model._meta.app_label not in valid_app_labels: valid_app_labels.append(model._meta.app_label)
if valid_app_labels: regex = r'^(?P<app_label>' + '|'.join(valid_app_labels) + ')/$' urlpatterns += [ url(regex, wrap(self.app_index), name='app_list'), ] return urlpatterns
has_permission=False, **(extra_context or {})
index_path = reverse('admin:index', current_app=self.name) return HttpResponseRedirect(index_path)
from django.contrib.admin.forms import AdminAuthenticationForm context = dict( self.each_context(request), title=_('Log in'), app_path=request.get_full_path(), username=request.user.get_username(), ) if (REDIRECT_FIELD_NAME not in request.GET and REDIRECT_FIELD_NAME not in request.POST): context[REDIRECT_FIELD_NAME] = reverse('admin:index', current_app=self.name) context.update(extra_context or {})
if True not in perms.values(): continue
app_list = sorted(app_dict.values(), key=lambda x: x['name'].lower())
for app in app_list: app['models'].sort(key=lambda x: x['name'])
app_dict['models'].sort(key=lambda x: x['name']) app_name = apps.get_app_config(app_label).verbose_name context = dict( self.each_context(request), title=_('%(app)s administration') % {'app': app_name}, app_list=[app_dict], app_label=app_label, ) context.update(extra_context or {})
site = AdminSite()
ALL_VAR = 'all' ORDER_VAR = 'o' ORDER_TYPE_VAR = 'ot' PAGE_VAR = 'p' SEARCH_VAR = 'q' ERROR_FLAG = 'e'
try: self.page_num = int(request.GET.get(PAGE_VAR, 0)) except ValueError: self.page_num = 0 self.show_all = ALL_VAR in request.GET self.is_popup = IS_POPUP_VAR in request.GET to_field = request.GET.get(TO_FIELD_VAR) if to_field and not model_admin.to_field_allowed(request, to_field): raise DisallowedModelAdminToField("The field %s cannot be referenced." % to_field) self.to_field = to_field self.params = dict(request.GET.items()) if PAGE_VAR in self.params: del self.params[PAGE_VAR] if ERROR_FLAG in self.params: del self.params[ERROR_FLAG]
for ignored in IGNORED_PARAMS: if ignored in lookup_params: del lookup_params[ignored] return lookup_params
spec = list_filter(request, lookup_params, self.model, self.model_admin)
field, field_list_filter_class = list_filter
field, field_list_filter_class = list_filter, FieldListFilter.create
use_distinct = use_distinct or lookup_needs_distinct(self.lookup_opts, field_path)
try: for key, value in lookup_params.items(): lookup_params[key] = prepare_lookup_value(key, value) use_distinct = use_distinct or lookup_needs_distinct(self.lookup_opts, key) return filter_specs, bool(filter_specs), lookup_params, use_distinct except FieldDoesNotExist as e: six.reraise(IncorrectLookupParameters, IncorrectLookupParameters(e), sys.exc_info()[2])
result_count = paginator.count
if self.model_admin.show_full_result_count: full_result_count = self.root_queryset.count() else: full_result_count = None can_show_all = result_count <= self.list_max_show_all multi_page = result_count > self.list_per_page
if (self.show_all and can_show_all) or not multi_page: result_list = self.queryset._clone() else: try: result_list = paginator.page(self.page_num + 1).object_list except InvalidPage: raise IncorrectLookupParameters
self.show_admin_actions = not self.show_full_result_count or bool(full_result_count) self.full_result_count = full_result_count self.result_list = result_list self.can_show_all = can_show_all self.multi_page = multi_page self.paginator = paginator
if callable(field_name): attr = field_name elif hasattr(self.model_admin, field_name): attr = getattr(self.model_admin, field_name) else: attr = getattr(self.model, field_name) return getattr(attr, 'admin_order_field', None)
ordering = [] order_params = params[ORDER_VAR].split('.') for p in order_params: try: none, pfx, idx = p.rpartition('-') field_name = self.list_display[int(idx)] order_field = self.get_ordering_field(field_name) if not order_field:
if order_field.startswith('-') and pfx == "-": ordering.append(order_field[1:]) else: ordering.append(pfx + order_field)
ordering.extend(queryset.query.order_by)
pk_name = self.lookup_opts.pk.name if not (set(ordering) & {'pk', '-pk', pk_name, '-' + pk_name}): ordering.append('-pk')
ordering = self._get_default_ordering() ordering_fields = OrderedDict() if ORDER_VAR not in self.params: for field in ordering: if field.startswith('-'): field = field[1:] order_type = 'desc' else: order_type = 'asc' for index, attr in enumerate(self.list_display): if self.get_ordering_field(attr) == field: ordering_fields[index] = order_type break else: for p in self.params[ORDER_VAR].split('.'): none, pfx, idx = p.rpartition('-') try: idx = int(idx) except ValueError:
(self.filter_specs, self.has_filters, remaining_lookup_params, filters_use_distinct) = self.get_filters(request)
qs = self.root_queryset for filter_spec in self.filter_specs: new_qs = filter_spec.queryset(request, qs) if new_qs is not None: qs = new_qs
qs = qs.filter(**remaining_lookup_params)
raise
raise IncorrectLookupParameters(e)
ordering = self.get_ordering(request, qs) qs = qs.order_by(*ordering)
qs, search_use_distinct = self.model_admin.get_search_results(request, qs, self.query)
if filters_use_distinct | search_use_distinct: return qs.distinct() else: return qs
forms.MultiWidget.__init__(self, widgets, attrs)
related_url = reverse( 'admin:%s_%s_changelist' % ( rel_to._meta.app_label, rel_to._meta.model_name, ), current_app=self.admin_site.name, )
extra.append( '<a href="%s%s" class="related-lookup" id="lookup_id_%s" title="%s"></a>' % (related_url, url, name, _('Lookup')) )
attrs['class'] = 'vManyToManyRawIdAdminField'
if can_add_related is None: can_add_related = rel.model in admin_site._registry self.can_add_related = can_add_related multiple = getattr(widget, 'allow_multiple_selected', False) self.can_change_related = not multiple and can_change_related cascade = getattr(rel, 'on_delete', None) is CASCADE self.can_delete_related = not multiple and not cascade and can_delete_related self.admin_site = admin_site
from django.contrib.contenttypes.models import ContentType return ContentType.objects.get_for_model(obj, for_concrete_model=False)
overrides = copy.deepcopy(FORMFIELD_FOR_DBFIELD_DEFAULTS) for k, v in self.formfield_overrides.items(): overrides.setdefault(k, {}).update(v) self.formfield_overrides = overrides
if db_field.choices: return self.formfield_for_choice_field(db_field, request, **kwargs)
if isinstance(db_field, models.ManyToManyField) or isinstance(db_field, models.ForeignKey): if db_field.__class__ in self.formfield_overrides: kwargs = dict(self.formfield_overrides[db_field.__class__], **kwargs)
if isinstance(db_field, models.ForeignKey): formfield = self.formfield_for_foreignkey(db_field, request, **kwargs) elif isinstance(db_field, models.ManyToManyField): formfield = self.formfield_for_manytomany(db_field, request, **kwargs)
if formfield and db_field.name not in self.raw_id_fields: related_modeladmin = self.admin_site._registry.get(db_field.remote_field.model) wrapper_kwargs = {} if related_modeladmin: wrapper_kwargs.update( can_add_related=related_modeladmin.has_add_permission(request), can_change_related=related_modeladmin.has_change_permission(request), can_delete_related=related_modeladmin.has_delete_permission(request), ) formfield.widget = widgets.RelatedFieldWidgetWrapper( formfield.widget, db_field.remote_field, self.admin_site, **wrapper_kwargs )
for klass in db_field.__class__.mro(): if klass in self.formfield_overrides: kwargs = dict(copy.deepcopy(self.formfield_overrides[klass]), **kwargs) return db_field.formfield(**kwargs)
return db_field.formfield(**kwargs)
if db_field.name in self.radio_fields: if 'widget' not in kwargs: kwargs['widget'] = widgets.AdminRadioSelect(attrs={ 'class': get_ul_class(self.radio_fields[db_field.name]), }) if 'choices' not in kwargs: kwargs['choices'] = db_field.get_choices( include_blank=db_field.blank, blank_choice=[('', _('None'))] ) return db_field.formfield(**kwargs)
if not db_field.remote_field.through._meta.auto_created: return None db = kwargs.get('using')
return reverse('admin:view_on_site', kwargs={ 'content_type_id': get_content_type_for_model(obj).pk, 'object_id': obj.pk })
ordering = self.get_ordering(request) if ordering: qs = qs.order_by(*ordering) return qs
for l in model._meta.related_fkey_lookups: if callable(l): l = l() for k, v in widgets.url_params_from_lookup_dict(l).items(): if k == lookup and v == value: return True
break
break
return True
if field.primary_key: return True
for many_to_many in opts.many_to_many: if many_to_many.m2m_target_field_name() == to_field: return True
registered_models = set() for model, admin in self.admin_site._registry.items(): registered_models.add(model) for inline in admin.inlines: registered_models.add(inline.model)
add_form_template = None change_form_template = None change_list_template = None delete_confirmation_template = None delete_selected_confirmation_template = None object_history_template = None
actions = [] action_form = helpers.ActionForm actions_on_top = True actions_on_bottom = False actions_selection_counter = True checks_class = ModelAdminChecks
url(r'^(.+)/$', wrap(RedirectView.as_view( pattern_name='%s:%s_%s_change' % ((self.admin_site.name,) + info) ))),
exclude.extend(self.form._meta.exclude)
new_attrs = OrderedDict( (f, None) for f in readonly_fields if f in self.form.declared_fields ) form = type(self.form.__name__, (self.form,), new_attrs)
if self.actions is None or IS_POPUP_VAR in request.GET: return OrderedDict()
for (name, func) in self.admin_site.actions: description = getattr(func, 'short_description', name.replace('_', ' ')) actions.append((func, name, description))
for klass in self.__class__.mro()[::-1]: class_actions = getattr(klass, 'actions', []) if not class_actions: continue actions.extend(self.get_action(action) for action in class_actions)
actions = filter(None, actions)
actions = OrderedDict( (name, (func, name, desc)) for func, name, desc in actions )
if callable(action): func = action action = action.__name__
elif hasattr(self.__class__, action): func = getattr(self.__class__, action)
else: try: func = self.admin_site.get_action(action) except KeyError: return None
return list(list_display)[:1]
def construct_search(field_name): if field_name.startswith('^'): return "%s__istartswith" % field_name[1:] elif field_name.startswith('='): return "%s__iexact" % field_name[1:] elif field_name.startswith('@'): return "%s__search" % field_name[1:] else: return "%s__icontains" % field_name
try: level = getattr(messages.constants, level.upper()) except AttributeError: levels = messages.constants.DEFAULT_TAGS.values() levels_repr = ', '.join('`%s`' % l for l in levels) raise ValueError( 'Bad message level string: `%s`. Possible values are: %s' % (level, levels_repr) )
if self.has_change_permission(request, obj): obj_repr = format_html('<a href="{}">{}</a>', urlquote(obj_url), obj) else: obj_repr = force_text(obj) msg_dict = { 'name': force_text(opts.verbose_name), 'obj': obj_repr, }
"_saveasnew" in request.POST and self.save_as_continue and self.has_change_permission(request, obj)
value = request.resolver_match.args[0] new_value = obj.serializable_value(attr) popup_response_data = json.dumps({ 'action': 'change', 'value': six.text_type(value), 'obj': six.text_type(obj), 'new_value': six.text_type(new_value), }) return SimpleTemplateResponse('admin/popup_response.html', { 'popup_response_data': popup_response_data, })
try: action_index = int(request.POST.get('index', 0)) except ValueError: action_index = 0
data = request.POST.copy() data.pop(helpers.ACTION_CHECKBOX_NAME, None) data.pop("index", None)
try: data.update({'action': data.getlist('action')[action_index]}) except IndexError: pass
if action_form.is_valid(): action = action_form.cleaned_data['action'] select_across = action_form.cleaned_data['select_across'] func = self.get_actions(request)[action][0]
selected = request.POST.getlist(helpers.ACTION_CHECKBOX_NAME) if not selected and not select_across: msg = _("Items must be selected in order to perform " "actions on them. No items have been changed.") self.message_user(request, msg, messages.WARNING) return None
queryset = queryset.filter(pk__in=selected)
if isinstance(response, HttpResponseBase): return response else: return HttpResponseRedirect(request.get_full_path())
if isinstance(f, models.ManyToManyField): initial[k] = initial[k].split(",")
if request.method == 'POST' and not form_validated and "_saveasnew" in request.POST: context['show_save'] = False context['show_save_and_continue'] = False add = False
actions = self.get_actions(request) if actions: list_display = ['action_checkbox'] + list(list_display)
if ERROR_FLAG in request.GET.keys(): return SimpleTemplateResponse('admin/invalid_setup.html', { 'title': _('Database error'), }) return HttpResponseRedirect(request.path + '?' + ERROR_FLAG + '=1')
action_failed = False selected = request.POST.getlist(helpers.ACTION_CHECKBOX_NAME)
if (actions and request.method == 'POST' and 'index' in request.POST and '_save' not in request.POST): if selected: response = self.response_action(request, queryset=cl.get_queryset(request)) if response: return response else: action_failed = True else: msg = _("Items must be selected in order to perform " "actions on them. No items have been changed.") self.message_user(request, msg, messages.WARNING) action_failed = True
if (actions and request.method == 'POST' and helpers.ACTION_CHECKBOX_NAME in request.POST and 'index' not in request.POST and '_save' not in request.POST): if selected: response = self.response_action(request, queryset=cl.get_queryset(request)) if response: return response else: action_failed = True
formset = cl.formset = None
if (request.method == "POST" and cl.list_editable and '_save' in request.POST and not action_failed): FormSet = self.get_changelist_formset(request) formset = cl.formset = FormSet(request.POST, request.FILES, queryset=self.get_queryset(request)) if formset.is_valid(): changecount = 0 for form in formset.forms: if form.has_changed(): obj = self.save_form(request, form, change=True) self.save_model(request, obj, form, change=True) self.save_related(request, form, formsets=[], change=True) change_msg = self.construct_change_message(request, form, None) self.log_change(request, obj, change_msg) changecount += 1
elif cl.list_editable: FormSet = self.get_changelist_formset(request) formset = cl.formset = FormSet(queryset=cl.result_list)
if formset: media = self.media + formset.media else: media = self.media
if actions: action_form = self.action_form(auto_id=None) action_form.fields['action'].choices = self.get_action_choices(request) else: action_form = None
(deleted_objects, model_count, perms_needed, protected) = get_deleted_objects( [obj], opts, request.user, self.admin_site, using)
model = self.model obj = self.get_object(request, unquote(object_id)) if obj is None: raise Http404(_('%(name)s object with primary key %(key)r does not exist.') % { 'name': force_text(model._meta.verbose_name), 'key': escape(object_id), })
opts = model._meta app_label = opts.app_label action_list = LogEntry.objects.filter( object_id=unquote(object_id), content_type=get_content_type_for_model(model) ).select_related().order_by('action_time')
exclude.extend(self.form._meta.exclude)
_('%(class_name)s %(instance)s') % { 'class_name': p._meta.verbose_name, 'instance': p}
return self.has_change_permission(request)
for field in opts.fields: if field.remote_field and field.remote_field.model != self.parent_model: opts = field.remote_field.model._meta break
return self.has_change_permission(request, obj)
if lookup_fields[-1] in QUERY_TERMS: lookup_fields = lookup_fields[:-1] for field_name in lookup_fields: field = opts.get_field(field_name) if hasattr(field, 'get_path_info'): path_info = field.get_path_info() opts = path_info[-1].to_opts if any(path.m2m for path in path_info): return True return False
if key.endswith('__in'): value = value.split(',') if key.endswith('__isnull'): if value.lower() in ('', 'false', '0'): value = False else: value = True return value
return no_edit_link
return format_html('{}: <a href="{}">{}</a>', capfirst(opts.verbose_name), admin_url, obj)
return no_edit_link
if callable(name): attr = name value = attr(obj) elif (model_admin is not None and hasattr(model_admin, name) and not name == '__str__' and not name == '__unicode__'): attr = getattr(model_admin, name) value = attr(obj) else: attr = getattr(obj, name) if callable(attr): value = attr() else: value = attr f = None
((field.many_to_one and not field.related_model) or field.one_to_many)):
label = field.related_model._meta.verbose_name
elif isinstance(field, models.BooleanField) or isinstance(field, models.NullBooleanField): return _boolean_icon(value) elif value is None: return empty_value_display elif isinstance(field, models.DateTimeField): return formats.localize(timezone.template_localtime(value)) elif isinstance(field, (models.DateField, models.TimeField)): return formats.localize(value) elif isinstance(field, models.DecimalField): return formats.number_format(value, field.decimal_places) elif isinstance(field, (models.IntegerField, models.FloatField)): return formats.number_format(value) elif isinstance(field, models.FileField) and value: return format_html('<a href="{}">{}</a>', value.url, value) else: return display_for_value(value, empty_value_display)
if field.is_relation and not (field.auto_created and not field.concrete): related_name = field.related_query_name() parent = field.remote_field.model else: related_name = field.field.name parent = field.related_model reversed_path.insert(0, related_name)
from __future__ import unicode_literals
if not apps.is_installed('django.contrib.contenttypes'): missing_app = checks.Error( "'django.contrib.contenttypes' must be in INSTALLED_APPS in order " "to use the admin application.", id="admin.E401", ) errors.append(missing_app) try: default_template_engine = Engine.get_default() except Exception: pass else: if ('django.contrib.auth.context_processors.auth' not in default_template_engine.context_processors and 'django.contrib.auth.backends.ModelBackend' in settings.AUTHENTICATION_BACKENDS): missing_template = checks.Error( "'django.contrib.auth.context_processors.auth' must be in " "TEMPLATES in order to use the admin application.", id="admin.E402" ) errors.append(missing_template) return errors
return []
return []
return []
try: field = model._meta.get_field(item) except FieldDoesNotExist: try: field = getattr(model, item) except AttributeError: field = None
checks.Error( "The value of '%s' refers to '%s', which is not a callable, " "an attribute of '%s', or an attribute or method on '%s.%s'." % ( label, item, obj.__class__.__name__, model._meta.app_label, model._meta.object_name ), obj=obj.__class__, id='admin.E108', )
if not issubclass(item, ListFilter): return must_inherit_from(parent='ListFilter', option=label, obj=obj, id='admin.E113') elif issubclass(item, FieldListFilter): return [ checks.Error( "The value of '%s' must not inherit from 'FieldListFilter'." % label, obj=obj.__class__, id='admin.E114', ) ] else: return []
field, list_filter_class = item if not issubclass(list_filter_class, FieldListFilter): return must_inherit_from(parent='FieldListFilter', option='%s[1]' % label, obj=obj, id='admin.E115') else: return []
field = item
try: get_fields_from_path(model, field) except (NotRelationField, FieldDoesNotExist): return [ checks.Error( "The value of '%s' refers to '%s', which does not refer to a Field." % (label, field), obj=obj.__class__, id='admin.E116', ) ] else: return []
elif (obj.list_display[0] == field_name and not obj.list_display_links and obj.list_display_links is not None): return [ checks.Error( "The value of '%s' refers to the first field in 'list_display' ('%s'), " "which cannot be used unless 'list_display_links' is set." % ( label, obj.list_display[0] ), obj=obj.__class__, id='admin.E124', ) ] elif not field.editable: return [ checks.Error( "The value of '%s' refers to '%s', which is not editable through the admin." % ( label, field_name ), obj=obj.__class__, id='admin.E125', ) ] else: return []
errors = super(InlineModelAdminChecks, self)._check_exclude(obj) if errors: return []
if self._check_relation(obj, parent_model): return []
MODEL_METHODS_EXCLUDE = ('_', 'add_', 'delete', 'save', 'set_')
self.template_name = 'admin_doc/missing_docutils.html' return self.render_to_response(admin.site.each_context(request))
pass
pass
try: app_config = apps.get_app_config(self.kwargs['app_label']) except LookupError: raise Http404(_("App %(app_label)r not found") % self.kwargs) try: model = app_config.get_model(model_name) except LookupError: raise Http404(_("Model %(model_name)r not found in app %(app_label)r") % self.kwargs)
fields = [] for field in opts.fields: if isinstance(field, models.ForeignKey): data_type = field.remote_field.model.__name__ app_label = field.remote_field.model._meta.app_label verbose = utils.parse_rst( (_("the related `%(app_label)s.%(data_type)s` object") % { 'app_label': app_label, 'data_type': data_type, }), 'model', _('model:') + data_type, ) else: data_type = get_readable_field_data_type(field) verbose = field.verbose_name fields.append({ 'name': field.name, 'data_type': data_type, 'verbose': verbose or '', 'help_text': field.help_text, })
for field in opts.many_to_many: data_type = field.remote_field.model.__name__ app_label = field.remote_field.model._meta.app_label verbose = _("related `%(app_label)s.%(object_name)s` objects") % { 'app_label': app_label, 'object_name': data_type, } fields.append({ 'name': "%s.all" % field.name, "data_type": 'List', 'verbose': utils.parse_rst(_("all %s") % verbose, 'model', _('model:') + opts.model_name), }) fields.append({ 'name': "%s.count" % field.name, 'data_type': 'Integer', 'verbose': utils.parse_rst(_("number of %s") % verbose, 'model', _('model:') + opts.model_name), })
for func_name, func in model.__dict__.items(): if inspect.isfunction(func): try: for exclude in MODEL_METHODS_EXCLUDE: if func_name.startswith(exclude): raise StopIteration except StopIteration: continue verbose = func.__doc__ if verbose: verbose = utils.parse_rst(utils.trim_docstring(verbose), 'model', _('model:') + opts.model_name) if func_has_no_args(func) and not func_accepts_kwargs(func) and not func_accepts_var_args(func): fields.append({ 'name': func_name, 'data_type': get_return_data_type(func_name), 'verbose': verbose or '', }) else: arguments = get_func_full_args(func) print_arguments = arguments print_arguments = ', '.join([ '='.join(list(arg_el[:1]) + [repr(el) for el in arg_el[1:]]) for arg_el in arguments ]) methods.append({ 'name': func_name, 'arguments': print_arguments, 'verbose': verbose or '', })
for rel in opts.related_objects: verbose = _("related `%(app_label)s.%(object_name)s` objects") % { 'app_label': rel.related_model._meta.app_label, 'object_name': rel.related_model._meta.object_name, } accessor = rel.get_accessor_name() fields.append({ 'name': "%s.all" % accessor, 'data_type': 'List', 'verbose': utils.parse_rst(_("all %s") % verbose, 'model', _('model:') + opts.model_name), }) fields.append({ 'name': "%s.count" % accessor, 'data_type': 'Integer', 'verbose': utils.parse_rst(_("number of %s") % verbose, 'model', _('model:') + opts.model_name), }) kwargs.update({ 'name': '%s.%s' % (opts.app_label, opts.object_name), 'summary': title, 'description': body, 'fields': fields, 'methods': methods, }) return super(ModelDetailView, self).get_context_data(**kwargs)
pass
for index, directory in enumerate(default_engine.dirs): template_file = os.path.join(directory, template) templates.append({ 'file': template_file, 'exists': os.path.exists(template_file), 'contents': lambda: open(template_file).read() if os.path.exists(template_file) else '', 'order': index, })
pattern = named_group_matcher.sub(lambda m: m.group(1), pattern)
pattern = non_named_group_matcher.sub("<var>", pattern)
pattern = pattern.replace('^', '').replace('$', '').replace('?', '').replace('//', '/').replace('\\', '') if not pattern.startswith('/'): pattern = '/' + pattern return pattern
lines = docstring.expandtabs().splitlines() indent = min(len(line) - len(line.lstrip()) for line in lines if line.lstrip()) trimmed = [lines[0].lstrip()] + [line[indent:].rstrip() for line in lines[1:]] return "\n".join(trimmed).strip()
ROLES = { 'model': '%s/models/%s/', 'view': '%s/views/%s/', 'template': '%s/templates/%s/', 'filter': '%s/filters/#%s', 'tag': '%s/tags/#%s', }
session_data = None
for i in range(10000): self._session_key = self._get_new_session_key() try: self.save(must_create=True) except CreateError: continue self.modified = True return raise RuntimeError( "Unable to create a new session key. " "It is likely that the cache is unavailable.")
max_age=settings.SESSION_COOKIE_AGE, salt='django.contrib.sessions.backends.signed_cookies',
self.create()
from django.contrib.sessions.models import Session return Session
self.save(must_create=True)
continue
data = None
try: s = self.model.objects.get( session_key=self.session_key, expire_date__gt=timezone.now() ) data = self.decode(s.session_data) self._cache.set(self.cache_key, data, self.get_expiry_age(expiry=s.expire_date)) except (self.model.DoesNotExist, SuspiciousOperation) as e: if isinstance(e, SuspiciousOperation): logger = logging.getLogger('django.security.%s' % e.__class__.__name__) logger.warning(force_text(e)) self._session_key = None data = {}
if not os.path.isdir(storage_path): raise ImproperlyConfigured( "The session storage path %r doesn't exist. Please set your" " SESSION_FILE_PATH setting to an existing directory in which" " Django can store session data." % storage_path)
if not set(session_key).issubset(set(VALID_KEY_CHARS)): raise InvalidSessionKey( "Invalid characters in session key")
if file_data: try: session_data = self.decode(file_data) except (EOFError, SuspiciousOperation) as e: if isinstance(e, SuspiciousOperation): logger = logging.getLogger('django.security.%s' % e.__class__.__name__) logger.warning(force_text(e)) self.create()
expiry_age = self.get_expiry_age(expiry=self._expiry_date(session_data)) if expiry_age <= 0: session_data = {} self.delete() self.create()
session_data = self._get_session(no_load=must_create)
flags = os.O_WRONLY | getattr(os, 'O_BINARY', 0) if must_create: flags |= os.O_EXCL | os.O_CREAT fd = os.open(session_file_name, flags) os.close(fd)
dir, prefix = os.path.split(session_file_name)
shutil.move(output_file_name, session_file_name) renamed = True
session.create = lambda: None session.load()
VALID_KEY_CHARS = string.ascii_lowercase + string.digits
hash, serialized = encoded_data.split(b':', 1) expected_hash = self._hash(serialized) if not constant_time_compare(hash.decode(), expected_hash): raise SuspiciousSession("Session data corrupted") else: return self.serializer().loads(serialized)
if isinstance(e, SuspiciousOperation): logger = logging.getLogger('django.security.%s' % e.__class__.__name__) logger.warning(force_text(e)) return {}
self._session_cache = {} self.accessed = True self.modified = True
try: expiry = kwargs['expiry'] except KeyError: expiry = self.get('_session_expiry')
try: expiry = kwargs['expiry'] except KeyError: expiry = self.get('_session_expiry')
try: del self['_session_expiry'] except KeyError: pass return
from __future__ import unicode_literals
if settings.SESSION_COOKIE_NAME in request.COOKIES and empty: response.delete_cookie(settings.SESSION_COOKIE_NAME, domain=settings.SESSION_COOKIE_DOMAIN) else: if accessed: patch_vary_headers(response, ('Cookie',)) if (modified or settings.SESSION_SAVE_EVERY_REQUEST) and not empty: if request.session.get_expire_at_browser_close(): max_age = None expires = None else: max_age = request.session.get_expiry_age() expires_time = time.time() + max_age expires = cookie_date(expires_time) if response.status_code != 500: try: request.session.save() except UpdateError: return redirect(request.path) response.set_cookie( settings.SESSION_COOKIE_NAME, request.session.session_key, max_age=max_age, expires=expires, domain=settings.SESSION_COOKIE_DOMAIN, path=settings.SESSION_COOKIE_PATH, secure=settings.SESSION_COOKIE_SECURE or None, httponly=settings.SESSION_COOKIE_HTTPONLY or None, )
from __future__ import unicode_literals
return mark_safe("%d%s" % (value, suffixes[value % 10]))
intword_converters = ( (6, lambda number: ( ungettext('%(value).1f million', '%(value).1f million', number), ungettext('%(value)s million', '%(value)s million', number), )), (9, lambda number: ( ungettext('%(value).1f billion', '%(value).1f billion', number), ungettext('%(value)s billion', '%(value)s billion', number), )), (12, lambda number: ( ungettext('%(value).1f trillion', '%(value).1f trillion', number), ungettext('%(value)s trillion', '%(value)s trillion', number), )), (15, lambda number: ( ungettext('%(value).1f quadrillion', '%(value).1f quadrillion', number), ungettext('%(value)s quadrillion', '%(value)s quadrillion', number), )), (18, lambda number: ( ungettext('%(value).1f quintillion', '%(value).1f quintillion', number), ungettext('%(value)s quintillion', '%(value)s quintillion', number), )), (21, lambda number: ( ungettext('%(value).1f sextillion', '%(value).1f sextillion', number), ungettext('%(value)s sextillion', '%(value)s sextillion', number), )), (24, lambda number: ( ungettext('%(value).1f septillion', '%(value).1f septillion', number), ungettext('%(value)s septillion', '%(value)s septillion', number), )), (27, lambda number: ( ungettext('%(value).1f octillion', '%(value).1f octillion', number), ungettext('%(value)s octillion', '%(value)s octillion', number), )), (30, lambda number: ( ungettext('%(value).1f nonillion', '%(value).1f nonillion', number), ungettext('%(value)s nonillion', '%(value)s nonillion', number), )), (33, lambda number: ( ungettext('%(value).1f decillion', '%(value).1f decillion', number), ungettext('%(value)s decillion', '%(value)s decillion', number), )), (100, lambda number: ( ungettext('%(value).1f googol', '%(value).1f googol', number), ungettext('%(value)s googol', '%(value)s googol', number), )), )
return value
return value
'a second ago', '%(count)sseconds ago', delta.seconds
'a minute ago', '%(count)sminutes ago', count
'an hour ago', '%(count)shours ago', count
'a second from now', '%(count)sseconds from now', delta.seconds
'a minute from now', '%(count)sminutes from now', count
'an hour from now', '%(count)shours from now', count
if hasattr(self.base_field, 'from_db_value'): self.from_db_value = self._from_db_value super(ArrayField, self).__init__(**kwargs)
base_errors = self.base_field.check() if base_errors: messages = '\n '.join('%s (%s)' % (error.msg, error.id) for error in base_errors) errors.append( checks.Error( 'Base field for array has errors:\n %s' % messages, obj=self, id='postgres.E001' ) )
vals = json.loads(value) value = [self.base_field.to_python(val) for val in vals]
return ( 'CASE WHEN %(lhs)s IS NULL THEN NULL ELSE ' 'coalesce(array_length(%(lhs)s, 1), 0) END' ) % {'lhs': lhs}, params
return [tuple(value) for value in values]
if hasattr(self, 'base_field'): self.base_field = self.base_field() super(RangeField, self).__init__(*args, **kwargs)
vals = json.loads(value) for end in ('lower', 'upper'): if end in vals: vals[end] = self.base_field.to_python(vals[end]) value = self.range_type(**vals)
register_hstore_handler(schema_editor.connection)
pass
if id_: id_ += '_0' return id_
for key, val in value.items(): value[key] = six.text_type(val) return value
initial_value = self.to_python(initial) return super(HStoreField, self).has_changed(initial_value, data)
def __or__(self, other): return self._combine(other, self.BITOR, False)
message=string_concat( SimpleLazyObject(lambda: prefix % params), SimpleLazyObject(lambda: error.message % error_params), ), code=code, params=dict(error_params, **params),
if not location: self.base_location = None self.location = None
return name
if '?#' in name and not unparsed_name[3]: unparsed_name[2] += '?' return urlunsplit(unparsed_name)
if url.startswith(('http:', 'https:', '//', '#', 'data:')): return matched
if url.startswith('/') and not url.startswith(settings.STATIC_URL): return matched
url_path, fragment = urldefrag(url)
assert url_path.startswith(settings.STATIC_URL) target_name = url_path[len(settings.STATIC_URL):]
source_name = name if os.sep == '/' else name.replace(os.sep, '/') target_name = posixpath.join(posixpath.dirname(source_name), url_path)
hashed_url = self.url(unquote(target_name), force=True)
if fragment: transformed_url += ('?#' if '?#' in url else '#') + fragment
return template % unquote(transformed_url)
if dry_run: return
hashed_files = OrderedDict()
adjustable_paths = [ path for path in paths if matches_patterns(path, self._patterns.keys()) ]
def path_level(name): return len(name.split(os.sep))
storage, path = paths[name] with storage.open(path) as original_file:
hashed_name = self.hashed_name(name, original_file)
if hasattr(original_file, 'seek'): original_file.seek(0)
if name in adjustable_paths: content = original_file.read().decode(settings.FILE_CHARSET) for extension, patterns in iteritems(self._patterns): if matches_patterns(path, (extension,)): for pattern, template in patterns: converter = self.url_converter(name, template) try: content = pattern.sub(converter, content) except ValueError as exc: yield name, None, exc if hashed_file_exists: self.delete(hashed_name) content_file = ContentFile(force_bytes(content)) saved_name = self._save(hashed_name, content_file) hashed_name = force_text(self.clean_name(saved_name)) processed = True else: if not hashed_file_exists: processed = True saved_name = self._save(hashed_name, original_file) hashed_name = force_text(self.clean_name(saved_name))
hashed_files[self.hash_key(name)] = hashed_name yield name, hashed_name, processed
self.hashed_files.update(hashed_files)
self.hashed_files[hash_key] = cache_name
self.hashed_files = _MappingCache(default_cache)
if settings.DEBUG and not urlpatterns: urlpatterns += staticfiles_urlpatterns()
if getattr(storage, 'prefix', None): prefixed_path = os.path.join(storage.prefix, path) else: prefixed_path = path
if self.post_process and hasattr(self.storage, 'post_process'): processor = self.storage.post_process(found_files, dry_run=self.dry_run) for original_path, processed_path, processed in processor: if isinstance(processed, Exception): self.stderr.write("Post-processing '%s' failed!" % original_path) self.stderr.write("") raise processed if processed: self.log("Post-processed '%s' as '%s'" % (original_path, processed_path), level=1) self.post_processed_files.append(original_path) else: self.log("Skipped post-processing '%s'" % original_path)
os.unlink(full_path)
target_last_modified = self.storage.get_modified_time(prefixed_path)
pass
source_last_modified = source_storage.get_modified_time(path)
if self.local: full_path = self.storage.path(prefixed_path) else: full_path = None if (target_last_modified.replace(microsecond=0) >= source_last_modified.replace(microsecond=0) and full_path and not (self.symlink ^ os.path.islink(full_path))): if prefixed_path not in self.unmodified_files: self.unmodified_files.append(prefixed_path) self.log("Skipping '%s' (not modified)" % path) return False
if prefixed_path in self.symlinked_files: return self.log("Skipping '%s' (already linked earlier)" % path) if not self.delete_file(path, prefixed_path, source_storage): return source_path = source_storage.path(path) if self.dry_run: self.log("Pretending to link '%s'" % source_path, level=1) else: self.log("Linking '%s'" % source_path, level=1) full_path = self.storage.path(prefixed_path) try: os.makedirs(os.path.dirname(full_path)) except OSError: pass try: if os.path.lexists(full_path): os.unlink(full_path) os.symlink(source_path, full_path) except AttributeError: import platform raise CommandError("Symlinking is not supported by Python %s." % platform.python_version()) except NotImplementedError: import platform raise CommandError("Symlinking is not supported in this " "platform (%s)." % platform.platform()) except OSError as e: raise CommandError(e) if prefixed_path not in self.symlinked_files: self.symlinked_files.append(prefixed_path)
if prefixed_path in self.copied_files: return self.log("Skipping '%s' (already copied earlier)" % path) if not self.delete_file(path, prefixed_path, source_storage): return source_path = source_storage.path(path) if self.dry_run: self.log("Pretending to copy '%s'" % source_path, level=1) else: self.log("Copying '%s'" % source_path, level=1) with source_storage.open(path) as source_file: self.storage.save(prefixed_path, source_file) self.copied_files.append(prefixed_path)
handles_files = True
return _static(path)
return _do_static(parser, token)
searched_locations = []
self.locations = [] self.storages = OrderedDict() if not isinstance(settings.STATICFILES_DIRS, (list, tuple)): raise ImproperlyConfigured( "Your STATICFILES_DIRS setting is not a tuple or list; " "perhaps you forgot a trailing comma?") for root in settings.STATICFILES_DIRS: if isinstance(root, (list, tuple)): prefix, root = root else: prefix = '' if settings.STATIC_ROOT and os.path.abspath(settings.STATIC_ROOT) == os.path.abspath(root): raise ImproperlyConfigured( "The STATICFILES_DIRS setting should " "not contain the STATIC_ROOT setting") if (prefix, root) not in self.locations: self.locations.append((prefix, root)) for prefix, root in self.locations: filesystem_storage = FileSystemStorage(location=root) filesystem_storage.prefix = prefix self.storages[root] = filesystem_storage super(FileSystemFinder, self).__init__(*args, **kwargs)
self.apps = [] self.storages = OrderedDict() app_configs = apps.get_app_configs() if app_names: app_names = set(app_names) app_configs = [ac for ac in app_configs if ac.name in app_names] for app_config in app_configs: app_storage = self.storage_class( os.path.join(app_config.path, self.source_dir)) if os.path.isdir(app_storage.location): self.storages[app_config.name] = app_storage if app_config.name not in self.apps: self.apps.append(app_config.name) super(AppDirectoriesFinder, self).__init__(*args, **kwargs)
if storage.exists(path): matched_path = storage.path(path) if matched_path: return matched_path
if not isinstance(self.storage, (Storage, LazyObject)): self.storage = self.storage() super(BaseStorageFinder, self).__init__(*args, **kwargs)
return [] if all else None
if host not in SITE_CACHE: SITE_CACHE[host] = self.get(domain__iexact=host) return SITE_CACHE[host]
domain, port = split_domain_port(host) if not port: raise if domain not in SITE_CACHE: SITE_CACHE[domain] = self.get(domain__iexact=domain) return SITE_CACHE[domain]
if apps.is_installed('django.contrib.sites'): from .models import Site return Site.objects.get_current(request) else: from .requests import RequestSite return RequestSite(request)
from __future__ import unicode_literals
from __future__ import unicode_literals
if verbosity >= 2: print("Creating example.com Site object") Site(pk=getattr(settings, 'SITE_ID', 1), domain="example.com", name="example.com").save(using=using)
sequence_sql = connections[using].ops.sequence_reset_sql(no_style(), [Site]) if sequence_sql: if verbosity >= 2: print("Resetting sequence") with connections[using].cursor() as cursor: for command in sequence_sql: cursor.execute(command)
from __future__ import unicode_literals
from __future__ import unicode_literals
response_gone_class = http.HttpResponseGone response_redirect_class = http.HttpResponsePermanentRedirect
if response.status_code != 404: return response
return response
self._cache = {}
try: ct = self.get(app_label=opts.app_label, model=opts.model_name) except self.model.DoesNotExist: ct, created = self.get_or_create( app_label=opts.app_label, model=opts.model_name, ) self._add_to_cache(self.db, ct) return ct
results = {} needed_app_labels = set() needed_models = set() needed_opts = set() for model in models: opts = self._get_opts(model, for_concrete_models) try: ct = self._get_from_cache(opts) except KeyError: needed_app_labels.add(opts.app_label) needed_models.add(opts.model_name) needed_opts.add(opts) else: results[model] = ct if needed_opts: cts = self.filter( app_label__in=needed_app_labels, model__in=needed_models ) for ct in cts: model = ct.model_class() if model._meta in needed_opts: results[model] = ct needed_opts.remove(model._meta) self._add_to_cache(self.db, ct) for opts in needed_opts: ct = self.create( app_label=opts.app_label, model=opts.model_name, ) self._add_to_cache(self.db, ct) results[ct.model_class()] = ct return results
ct = self.get(pk=id) self._add_to_cache(self.db, ct)
key = (ct.app_label, ct.model) self._cache.setdefault(using, {})[key] = ct self._cache.setdefault(using, {})[ct.id] = ct
try: content_type = ContentType.objects.get(pk=content_type_id) if not content_type.model_class(): raise http.Http404(_("Content type %(ct_id)s object has no associated model") % {'ct_id': content_type_id}) obj = content_type.get_object_for_this_type(pk=object_id) except (ObjectDoesNotExist, ValueError): raise http.Http404(_("Content type %(ct_id)s object %(obj_id)s doesn't exist") % {'ct_id': content_type_id, 'obj_id': object_id})
if absurl.startswith(('http://', 'https://', '//')): return http.HttpResponseRedirect(absurl)
object_domain = None
for field in opts.many_to_many: if field.remote_field.model is Site: try: object_domain = getattr(obj, field.name).all()[0].domain except IndexError: pass if object_domain is not None: break
if object_domain is None: for field in obj._meta.fields: if field.remote_field and field.remote_field.model is Site: try: site = getattr(obj, field.name) except Site.DoesNotExist: continue if site is not None: object_domain = site.domain if object_domain is not None: break
if object_domain is None: try: object_domain = Site.objects.get_current(request).domain except Site.DoesNotExist: pass
object_domain = RequestSite(request).domain
if object_domain is not None: protocol = request.scheme return http.HttpResponseRedirect('%s://%s%s' % (protocol, object_domain, absurl)) else: return http.HttpResponseRedirect(absurl)
return []
try: obj.model._meta.get_field(obj.ct_field) except FieldDoesNotExist: return [ checks.Error( "'ct_field' references '%s', which is not a field on '%s.%s'." % ( obj.ct_field, obj.model._meta.app_label, obj.model._meta.object_name ), obj=obj.__class__, id='admin.E302' ) ]
for gfk in gfks: if gfk.ct_field == obj.ct_field and gfk.fk_field == obj.ct_fk_field: return []
exclude.extend(self.form._meta.exclude)
ct_field = opts.get_field(ct_field) if not isinstance(ct_field, models.ForeignKey) or ct_field.remote_field.model != ContentType: raise Exception("fk_name '%s' is not a ForeignKey to ContentType" % ct_field)
from __future__ import unicode_literals
from __future__ import unicode_literals
content_type.model = old_model
ContentType.objects.clear_cache()
try: ContentType = apps.get_model('contenttypes', 'ContentType') except LookupError: available = False else: if not router.allow_migrate_model(using, ContentType): return available = True
if backward: break else: available = True continue
if apps is not global_apps: global_apps.get_model('contenttypes', 'ContentType').objects.clear_cache()
content_types = { ct.model: ct for ct in ContentType.objects.using(using).filter(app_label=app_label) } to_remove = [ ct for (model_name, ct) in six.iteritems(content_types) if model_name not in app_models ]
auto_created = False concrete = False editable = False hidden = False
raise Exception("Impossible arguments to GFK.get_content_type!")
fk_dict = defaultdict(set) instance_dict = {} ct_attname = self.model._meta.get_field(self.ct_field).get_attname() for instance in instances: ct_id = getattr(instance, ct_attname) if ct_id is not None: fk_val = getattr(instance, self.fk_field) if fk_val is not None: fk_dict[ct_id].add(fk_val) instance_dict[ct_id] = instance
def gfk_key(obj): ct_id = getattr(obj, ct_attname) if ct_id is None: return None else: model = self.get_content_type(id=ct_id, using=obj._state.db).model_class() return (model._meta.pk.get_prep_value(getattr(obj, self.fk_field)), model)
f = self.model._meta.get_field(self.ct_field) ct_id = getattr(instance, f.get_attname(), None) pk_val = getattr(instance, self.fk_field)
auto_created = False
super(GenericRelation, self).__init__( to, from_fields=[object_id_field], to_fields=[], **kwargs)
path = [] opts = self.remote_field.model._meta parent_opts = opts.get_field(self.object_id_field_name).model._meta target = parent_opts.pk path.append(PathInfo(self.model._meta, parent_opts, (target,), self.remote_field, True, False)) parent_field_chain = [] while parent_opts != opts: field = opts.get_ancestor_link(parent_opts.model) parent_field_chain.append(field) opts = field.remote_field.model._meta parent_field_chain.reverse() for field in parent_field_chain: path.extend(field.remote_field.get_path_info()) return path
if not cls._meta.abstract:
manager = getattr(self.model, kwargs.pop('manager')) manager_class = create_generic_related_manager(manager.__class__, rel) return manager_class(instance=self.instance)
object_id_converter = instances[0]._meta.pk.to_python return (queryset.filter(**query), lambda relobj: object_id_converter(getattr(relobj, self.object_id_field_name)), lambda obj: obj._get_pk_val(), False, self.prefetch_cache_name)
queryset.delete()
objs = tuple(objs)
from __future__ import unicode_literals
return iri_to_uri(get_script_prefix().rstrip('/') + self.url)
if f.registration_required and not request.user.is_authenticated: from django.contrib.auth.views import redirect_to_login return redirect_to_login(request.path) if f.template_name: template = loader.select_template((f.template_name, DEFAULT_TEMPLATE)) else: template = loader.get_template(DEFAULT_TEMPLATE)
f.title = mark_safe(f.title) f.content = mark_safe(f.content)
from __future__ import unicode_literals
if self.starts_with: flatpages = flatpages.filter( url__startswith=self.starts_with.resolve(context))
if self.user: user = self.user.resolve(context) if not user.is_authenticated: flatpages = flatpages.filter(registration_required=False) else: flatpages = flatpages.filter(registration_required=False)
if len(bits) >= 3 and len(bits) <= 6:
if len(bits) % 2 == 0: prefix = bits[1] else: prefix = None
if bits[-2] != 'as': raise template.TemplateSyntaxError(syntax_message) context_name = bits[-1]
if len(bits) >= 5: if bits[-4] != 'for': raise template.TemplateSyntaxError(syntax_message) user = bits[-3] else: user = None
super(FlatpageFallbackMiddleware, self).__init__(get_response)
except Http404: return response except Exception: if settings.DEBUG: raise return response
try: ts_b36, hash = token.split("-") except ValueError: return False
if not constant_time_compare(self._make_token_with_timestamp(user, ts), token): return False
if (self._num_days(self._today()) - ts) > settings.PASSWORD_RESET_TIMEOUT_DAYS: return False
ts_b36 = int_to_base36(timestamp)
login_timestamp = '' if user.last_login is None else user.last_login.replace(microsecond=0, tzinfo=None) return ( six.text_type(user.pk) + user.password + six.text_type(login_timestamp) + six.text_type(timestamp) )
return date.today()
def _user_get_all_permissions(user, obj): permissions = set() for backend in auth.get_backends(): if hasattr(backend, "get_all_permissions"): permissions.update(backend.get_all_permissions(user, obj)) return permissions
if self.is_active and self.is_superuser: return True
return _user_has_perm(self, perm, obj)
if self.is_active and self.is_superuser: return True
return get_user_model()._meta.pk.to_python(request.session[SESSION_KEY])
continue
break
user.backend = backend_path return user
user_login_failed.send(sender=__name__, credentials=_clean_credentials(credentials))
request.session.flush()
user = getattr(request, 'user', None) if hasattr(user, 'is_authenticated') and not user.is_authenticated: user = None user_logged_out.send(sender=user.__class__, request=request, user=user)
language = request.session.get(LANGUAGE_SESSION_KEY)
if hasattr(user, 'get_session_auth_hash'): session_hash = request.session.get(HASH_SESSION_KEY) session_hash_verified = session_hash and constant_time_compare( session_hash, user.get_session_auth_hash() ) if not session_hash_verified: request.session.flush() user = None
self._password = None
self._password = None self.save(update_fields=["password"])
self.password = make_password(None)
from django.contrib.auth import ( REDIRECT_FIELD_NAME, get_user_model, login as auth_login, logout as auth_logout, update_session_auth_hash, ) from django.contrib.auth.decorators import login_required from django.contrib.auth.forms import ( AuthenticationForm, PasswordChangeForm, PasswordResetForm, SetPasswordForm, ) from django.contrib.auth.tokens import default_token_generator from django.contrib.sites.shortcuts import get_current_site from django.http import HttpResponseRedirect, QueryDict from django.shortcuts import resolve_url from django.template.response import TemplateResponse from django.urls import reverse from django.utils.deprecation import RemovedInDjango20Warning from django.utils.encoding import force_text from django.utils.http import is_safe_url, urlsafe_base64_decode from django.utils.six.moves.urllib.parse import urlparse, urlunparse from django.utils.translation import ugettext as _ from django.views.decorators.cache import never_cache from django.views.decorators.csrf import csrf_protect from django.views.decorators.debug import sensitive_post_parameters
if not is_safe_url(url=redirect_to, host=request.get_host()): return resolve_url(settings.LOGIN_REDIRECT_URL) return redirect_to
if not is_safe_url(url=next_page, host=request.get_host()): next_page = request.path
return HttpResponseRedirect(next_page)
uid = force_text(urlsafe_base64_decode(uidb64)) user = UserModel._default_manager.get(pk=uid)
update_session_auth_hash(request, form.user) return HttpResponseRedirect(post_change_redirect)
kwargs['queryset'] = qs.select_related('content_type')
if lookup.startswith('password'): return False return super(UserAdmin, self).lookup_allowed(lookup, value)
if not self.has_change_permission(request): if self.has_add_permission(request) and settings.DEBUG: raise Http404( 'Your user does not have the "Change user" permission. In ' 'order to add users, Django requires that your user ' 'account have both the "Add user" and "Change user" ' 'permissions set.') raise PermissionDenied if extra_context is None: extra_context = {} username_field = self.model._meta.get_field(self.model.USERNAME_FIELD) defaults = { 'auto_populated_fields': (), 'username_help_text': username_field.help_text, } extra_context.update(defaults) return super(UserAdmin, self).add_view(request, form_url, extra_context)
if '_addanother' not in request.POST and IS_POPUP_VAR not in request.POST: request.POST['_continue'] = 1 return super(UserAdmin, self).response_add(request, obj, post_url_continue)
return initial
return self.initial["password"]
UserModel = get_user_model() self.username_field = UserModel._meta.get_field(UserModel.USERNAME_FIELD) if self.fields['username'].label is None: self.fields['username'].label = capfirst(self.username_field.verbose_name)
subject = ''.join(subject.splitlines()) body = loader.render_to_string(email_template_name, context)
continue
password = None user_data = {} fake_user_data = {}
if not options['interactive']: try: if not username: raise CommandError("You must use --%s with --noinput." % self.UserModel.USERNAME_FIELD) username = self.username_field.clean(username, None)
default_username = get_default_username() try:
verbose_field_name = self.username_field.verbose_name while username is None: input_msg = capfirst(verbose_field_name) if default_username: input_msg += " (leave blank to use '%s')" % default_username username_rel = self.username_field.remote_field input_msg = force_str('%s%s: ' % ( input_msg, ' (%s.%s)' % ( username_rel.model._meta.object_name, username_rel.field_name ) if username_rel else '') ) username = self.get_input_data(self.username_field, input_msg, default_username) if not username: continue if self.username_field.unique: try: self.UserModel._default_manager.db_manager(database).get_by_natural_key(username) except self.UserModel.DoesNotExist: pass else: self.stderr.write("Error: That %s is already taken." % verbose_field_name) username = None
if field.remote_field: fake_user_data[field_name] = field.remote_field.model(input_value)
while password is None: password = getpass.getpass() password2 = getpass.getpass(force_str('Password (again): ')) if password != password2: self.stderr.write("Error: Your passwords didn't match.") password = None continue
continue
searched_perms = list() ctypes = set() for klass in app_config.get_models(): ctype = ContentType.objects.db_manager(using).get_for_model(klass)
all_perms = set(Permission.objects.using(using).filter( content_type__in=ctypes, ).values_list( "content_type", "codename" ))
return ''
return ''
from django.contrib.auth import models as auth_app
if auth_app.User._meta.swapped: return ''
try: auth_app.User._meta.get_field('username').run_validators(default_username) except exceptions.ValidationError: return ''
if check_db and default_username: try: auth_app.User._default_manager.get(username=default_username) except auth_app.User.DoesNotExist: pass else: return '' return default_username
UserModel().set_password(password)
create_unknown_user = True
if self.create_unknown_user: user, created = UserModel._default_manager.get_or_create(**{ UserModel.USERNAME_FIELD: username }) if created: user = self.configure_user(user) else: try: user = UserModel._default_manager.get_by_natural_key(username) except UserModel.DoesNotExist: pass return user if self.user_can_authenticate(user) else None
from __future__ import unicode_literals
]
from __future__ import unicode_literals
operations = [ migrations.AlterField( model_name='user', name='username', field=models.CharField( error_messages={'unique': 'A user with that username already exists.'}, max_length=30, validators=[validators.UnicodeUsernameValidator() if six.PY3 else validators.ASCIIUsernameValidator()], help_text='Required. 30 characters or fewer. Letters, digits and @/./+/-/_ only.', unique=True, verbose_name='username' ), ), ]
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
db.reset_queries()
if not is_correct and not hasher_changed and must_update: hasher.harden_runtime(password, encoded)
if ((len(encoded) == 32 and '$' not in encoded) or (len(encoded) == 37 and encoded.startswith('md5$$'))): algorithm = 'unsalted_md5' elif len(encoded) == 46 and encoded.startswith('sha1$$'): algorithm = 'unsalted_sha1' else: algorithm = encoded.split('$', 1)[0] return get_hasher(algorithm)
pass
algorithm, variety, raw_params, salt, data = bits version = 0x10
if self.digest is not None: password = binascii.hexlify(self.digest(force_bytes(password)).digest()) else: password = force_bytes(password)
diff = 2**(self.rounds - int(rounds)) - 1 while diff > 0: self.encode(password, force_bytes(salt)) diff -= 1
return "%s$%s$%s" % (self.algorithm, '', data)
login_scheme, login_netloc = urlparse(resolved_login_url)[:2] current_scheme, current_netloc = urlparse(path)[:2] if ((not login_scheme or login_scheme == current_scheme) and (not login_netloc or login_netloc == current_netloc)): path = request.get_full_path() from django.contrib.auth.views import redirect_to_login return redirect_to_login( path, resolved_login_url, redirect_field_name)
if user.has_perms(perms): return True if raise_exception: raise PermissionDenied return False
from __future__ import unicode_literals
return []
if not isinstance(cls.REQUIRED_FIELDS, (list, tuple)): errors.append( checks.Error( "'REQUIRED_FIELDS' must be a list or tuple.", obj=cls, id='auth.E001', ) )
if cls.USERNAME_FIELD in cls.REQUIRED_FIELDS: errors.append( checks.Error( "The field named as the 'USERNAME_FIELD' " "for a custom user model must not be included in 'REQUIRED_FIELDS'.", obj=cls, id='auth.E002', ) )
if not cls._meta.get_field(cls.USERNAME_FIELD).unique: if (settings.AUTHENTICATION_BACKENDS == ['django.contrib.auth.backends.ModelBackend']): errors.append( checks.Error( "'%s.%s' must be unique because it is named as the 'USERNAME_FIELD'." % ( cls._meta.object_name, cls.USERNAME_FIELD ), obj=cls, id='auth.E003', ) ) else: errors.append( checks.Warning( "'%s.%s' is named as the 'USERNAME_FIELD', but it is not unique." % ( cls._meta.object_name, cls.USERNAME_FIELD ), hint='Ensure that your authentication backend(s) can handle non-unique usernames.', obj=cls, id='auth.W004', ) )
max_builtin_permission_name_length = max(len(name) for name in builtin_permissions.values()) if max_builtin_permission_name_length > permission_name_max_length: verbose_name_max_length = ( permission_name_max_length - (max_builtin_permission_name_length - len(opts.verbose_name_raw)) ) errors.append( checks.Error( "The verbose_name of model '%s.%s' must be at most %d characters " "for its builtin permission names to be at most %d characters." % ( opts.app_label, opts.object_name, verbose_name_max_length, permission_name_max_length ), obj=model, id='auth.E007', ) ) codenames = set() for codename, name in opts.permissions: if len(name) > permission_name_max_length: errors.append( checks.Error( "The permission named '%s' of model '%s.%s' is longer than %d characters." % ( name, opts.app_label, opts.object_name, permission_name_max_length ), obj=model, id='auth.E008', ) ) if codename in builtin_permissions: errors.append( checks.Error( "The permission codenamed '%s' clashes with a builtin permission " "for model '%s.%s'." % ( codename, opts.app_label, opts.object_name ), obj=model, id='auth.E005', ) ) elif codename in codenames: errors.append( checks.Error( "The permission codenamed '%s' is duplicated for model '%s.%s'." % ( codename, opts.app_label, opts.object_name ), obj=model, id='auth.E006', ) ) codenames.add(codename)
header = "REMOTE_USER" force_logout_if_no_header = True
if not hasattr(request, 'user'): raise ImproperlyConfigured( "The Django remote user auth middleware requires the" " authentication middleware to be installed. Edit your" " MIDDLEWARE setting to insert" " 'django.contrib.auth.middleware.AuthenticationMiddleware'" " before the RemoteUserMiddleware class.") try: username = request.META[self.header] except KeyError: if self.force_logout_if_no_header and request.user.is_authenticated: self._remove_invalid_user(request) return if request.user.is_authenticated: if request.user.get_username() == self.clean_username(username, request): return else: self._remove_invalid_user(request)
user = auth.authenticate(remote_user=username) if user: request.user = user auth.login(request, user)
auth.logout(request)
raise TypeError("PermLookupDict is not iterable.")
raise TypeError("PermWrapper is not iterable.")
return bool(self[perm_name])
try: urlconf_module, app_name = arg except ValueError: if namespace: raise ImproperlyConfigured( 'Cannot override the namespace for a dynamic module that provides a namespace' ) warnings.warn( 'Passing a 3-tuple to django.conf.urls.include() is deprecated. ' 'Pass a 2-tuple containing the list of patterns and app_name, ' 'and provide the namespace argument to include() instead.', RemovedInDjango20Warning, stacklevel=2 ) urlconf_module, app_name, namespace = arg
urlconf_module = arg
if isinstance(patterns, (list, tuple)): for url_pattern in patterns: if isinstance(url_pattern, LocaleRegexURLResolver): raise ImproperlyConfigured( 'Using i18n_patterns in an included URLconf is not allowed.')
urlconf_module, app_name, namespace = view return RegexURLResolver(regex, urlconf_module, kwargs, app_name=app_name, namespace=namespace)
if not settings.DEBUG or (prefix and '://' in prefix): return [] elif not prefix: raise ImproperlyConfigured("Empty static prefix not permitted") return [ url(r'^%s(?P<path>.*)$' % re.escape(prefix.lstrip('/')), view, kwargs=kwargs), ]
if self._wrapped is empty: return '<LazySettings [Unevaluated]>' return '<LazySettings "%(settings_module)s">' % { 'settings_module': self._wrapped.SETTINGS_MODULE, }
for setting in dir(global_settings): if setting.isupper(): setattr(self, setting, getattr(global_settings, setting))
self.SETTINGS_MODULE = settings_module
zoneinfo_root = '/usr/share/zoneinfo' if (os.path.exists(zoneinfo_root) and not os.path.exists(os.path.join(zoneinfo_root, *(self.TIME_ZONE.split('/'))))): raise ValueError("Incorrect timezone setting: %s" % self.TIME_ZONE) os.environ['TZ'] = self.TIME_ZONE time.tzset()
SETTINGS_MODULE = None
from __future__ import unicode_literals
DATE_FORMAT = 'd F Y' TIME_FORMAT = 'H:i' DATETIME_FORMAT = 'j. F Y H:i' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j. F' SHORT_DATE_FORMAT = 'j.m.Y' SHORT_DATETIME_FORMAT = 'j.m.Y H:i' FIRST_DAY_OF_WEEK = 1
DATE_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = 'Y. F j.' TIME_FORMAT = 'G.i' DATETIME_FORMAT = 'Y. F j. G.i' YEAR_MONTH_FORMAT = 'Y. F' MONTH_DAY_FORMAT = 'F j.' SHORT_DATE_FORMAT = 'Y.m.d.' SHORT_DATETIME_FORMAT = 'Y.m.d. G.i'
DATE_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = 'j. F Y' TIME_FORMAT = 'H:i' DATETIME_FORMAT = 'j. F Y H:i' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j. F' SHORT_DATE_FORMAT = 'd.m.Y' SHORT_DATETIME_FORMAT = 'd.m.Y H:i'
DATE_INPUT_FORMATS = [
] DATETIME_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = 'd. F Y' TIME_FORMAT = 'H:i' DATETIME_FORMAT = 'j. F Y. H:i' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j. F' SHORT_DATE_FORMAT = 'j. M. Y' SHORT_DATETIME_FORMAT = 'j.n.Y. H:i' FIRST_DAY_OF_WEEK = 0
DATE_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = 'Ynj' TIME_FORMAT = 'G:i' DATETIME_FORMAT = 'YnjG:i' YEAR_MONTH_FORMAT = 'Yn' MONTH_DAY_FORMAT = 'nj' SHORT_DATE_FORMAT = 'Y/m/d' SHORT_DATETIME_FORMAT = 'Y/m/d G:i'
DECIMAL_SEPARATOR = '.' THOUSAND_SEPARATOR = ','
from __future__ import unicode_literals
DATE_FORMAT = 'j. F Y' TIME_FORMAT = 'G:i' DATETIME_FORMAT = 'j. F Y G:i' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j. F' SHORT_DATE_FORMAT = 'd.m.Y' SHORT_DATETIME_FORMAT = 'd.m.Y G:i'
DATE_INPUT_FORMATS = [
] DATETIME_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = 'd/m/Y' TIME_FORMAT = 'P' DATETIME_FORMAT = 'd/m/Y P' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'd/m/Y' SHORT_DATETIME_FORMAT = 'd/m/Y P'
DATE_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = r'Y \m. E j \d.' TIME_FORMAT = 'H:i' DATETIME_FORMAT = r'Y \m. E j \d., H:i' YEAR_MONTH_FORMAT = r'Y \m. F' MONTH_DAY_FORMAT = r'E j \d.' SHORT_DATE_FORMAT = 'Y-m-d' SHORT_DATETIME_FORMAT = 'Y-m-d H:i'
DATE_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = 'j. F Y.' TIME_FORMAT = 'H:i' DATETIME_FORMAT = 'j. F Y. H:i' YEAR_MONTH_FORMAT = 'F Y.' MONTH_DAY_FORMAT = 'j. F' SHORT_DATE_FORMAT = 'j.m.Y.' SHORT_DATETIME_FORMAT = 'j.m.Y. H:i' FIRST_DAY_OF_WEEK = 1
DATE_INPUT_FORMATS = [
] DATETIME_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = 'j F, Y' TIME_FORMAT = 'g:i A' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'j M, Y'
from __future__ import unicode_literals
DATE_FORMAT = 'j F Y' TIME_FORMAT = 'H:i' DATETIME_FORMAT = 'j F Y H:i' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'd/m/Y' SHORT_DATETIME_FORMAT = 'd/m/Y H:i'
DECIMAL_SEPARATOR = '.' THOUSAND_SEPARATOR = ','
from __future__ import unicode_literals
DATE_INPUT_FORMATS = [
] DATETIME_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = 'N j, Y' TIME_FORMAT = 'P' DATETIME_FORMAT = 'N j, Y, P' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'F j' SHORT_DATE_FORMAT = 'm/d/Y' SHORT_DATETIME_FORMAT = 'm/d/Y P'
DATE_INPUT_FORMATS = [
] DATETIME_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = 'j F Y' TIME_FORMAT = 'H:i' DATETIME_FORMAT = 'j F Y H:i' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'Y-m-d' SHORT_DATETIME_FORMAT = 'Y-m-d H:i' FIRST_DAY_OF_WEEK = 1
DATE_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = r'\N\g\y d \t\h\n\g n \n\m Y' TIME_FORMAT = 'H:i' DATETIME_FORMAT = r'H:i \N\g\y d \t\h\n\g n \n\m Y' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'd-m-Y' SHORT_DATETIME_FORMAT = 'H:i d-m-Y'
DECIMAL_SEPARATOR = ',' THOUSAND_SEPARATOR = '.'
from __future__ import unicode_literals
DATE_FORMAT = 'j F Y' TIME_FORMAT = 'g:i A' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'j M Y'
from __future__ import unicode_literals
DATE_FORMAT = 'j. F Y.' TIME_FORMAT = 'H:i' DATETIME_FORMAT = 'j. F Y. H:i' YEAR_MONTH_FORMAT = 'F Y.' MONTH_DAY_FORMAT = 'j. F' SHORT_DATE_FORMAT = 'j.m.Y.' SHORT_DATETIME_FORMAT = 'j.m.Y. H:i' FIRST_DAY_OF_WEEK = 1
DATE_INPUT_FORMATS = [
] DATETIME_INPUT_FORMATS = [
from __future__ import unicode_literals
from __future__ import unicode_literals
DATE_INPUT_FORMATS = [
] DATETIME_INPUT_FORMATS = [
DECIMAL_SEPARATOR = ','
from __future__ import unicode_literals
DATE_FORMAT = 'd F Y' TIME_FORMAT = 'g:i A' SHORT_DATE_FORMAT = 'j M Y'
from __future__ import unicode_literals
DATE_FORMAT = 'j F Y' TIME_FORMAT = 'h:i A' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'j M Y'
from __future__ import unicode_literals
from __future__ import unicode_literals
DATE_FORMAT = 'l, j F, Y' TIME_FORMAT = 'h:i a' DATETIME_FORMAT = 'j F, Y h:i a' YEAR_MONTH_FORMAT = 'F, Y' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'j.M.Y' SHORT_DATETIME_FORMAT = 'j.M.Y H:i'
DATE_INPUT_FORMATS = [
] DATETIME_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = 'j. F Y' TIME_FORMAT = 'H:i' DATETIME_FORMAT = 'j. F Y H:i' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j. F' SHORT_DATE_FORMAT = 'd.m.Y' SHORT_DATETIME_FORMAT = 'd.m.Y H:i' FIRST_DAY_OF_WEEK = 1
DATE_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = r'Yeko M\re\n d\a' TIME_FORMAT = 'H:i' SHORT_DATE_FORMAT = 'Y M j'
DECIMAL_SEPARATOR = ',' THOUSAND_SEPARATOR = '.'
from __future__ import unicode_literals
DATE_FORMAT = 'N j, Y' TIME_FORMAT = 'P' DATETIME_FORMAT = 'N j, Y, P' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'F j' SHORT_DATE_FORMAT = 'm/d/Y' SHORT_DATETIME_FORMAT = 'm/d/Y P'
DATE_INPUT_FORMATS = [
] DATETIME_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = 'j F Y' TIME_FORMAT = 'G:i' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'd.m.Y'
DECIMAL_SEPARATOR = ','
from __future__ import unicode_literals
DATE_FORMAT = 'j. F Y' TIME_FORMAT = 'H:i' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j. F' SHORT_DATE_FORMAT = 'j.n.Y'
DECIMAL_SEPARATOR = ',' THOUSAND_SEPARATOR = '.' NUMBER_GROUPING = 3
from __future__ import unicode_literals
DATE_FORMAT = r'j \d\e F \d\e Y' TIME_FORMAT = 'H:i' DATETIME_FORMAT = r'j \d\e F \d\e Y \\s H:i' YEAR_MONTH_FORMAT = r'F \d\e Y' MONTH_DAY_FORMAT = r'j \d\e F' SHORT_DATE_FORMAT = 'd-m-Y' SHORT_DATETIME_FORMAT = 'd-m-Y, H:i'
DECIMAL_SEPARATOR = ',' THOUSAND_SEPARATOR = '.'
from __future__ import unicode_literals
DATE_FORMAT = 'j F Y' TIME_FORMAT = 'H:i' DATETIME_FORMAT = 'j F Y H:i' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'j N Y' SHORT_DATETIME_FORMAT = 'j N Y H:i'
DATE_INPUT_FORMATS = [
] DATETIME_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = 'j. E Y' TIME_FORMAT = 'G.i' DATETIME_FORMAT = r'j. E Y \k\e\l\l\o G.i' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j. F' SHORT_DATE_FORMAT = 'j.n.Y' SHORT_DATETIME_FORMAT = 'j.n.Y G.i'
DATE_INPUT_FORMATS = [
DATE_FORMAT = 'j E Y .' TIME_FORMAT = 'H:i' DATETIME_FORMAT = 'j E Y . H:i' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'j M Y'
DECIMAL_SEPARATOR = ',' THOUSAND_SEPARATOR = ''
from __future__ import unicode_literals
DATE_FORMAT = 'j F Y' TIME_FORMAT = 'h:ia' DATETIME_FORMAT = 'j F Y h:ia' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'j M Y' SHORT_DATETIME_FORMAT = 'j M Y h:ia'
DECIMAL_SEPARATOR = '.' THOUSAND_SEPARATOR = ','
from __future__ import unicode_literals
DATE_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = r'j N Y' TIME_FORMAT = r'H:i' DATETIME_FORMAT = r'j N Y H:i' YEAR_MONTH_FORMAT = r'F Y' MONTH_DAY_FORMAT = r'j \d\e F' SHORT_DATE_FORMAT = r'd/m/Y' SHORT_DATETIME_FORMAT = r'd/m/Y H:i'
DATE_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = 'j F Y' TIME_FORMAT = 'G:i' DATETIME_FORMAT = 'j F Y  G:i' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'Y/n/j' SHORT_DATETIME_FORMAT = 'Y/n/j G:i' FIRST_DAY_OF_WEEK = 6
DECIMAL_SEPARATOR = '.' THOUSAND_SEPARATOR = ','
from __future__ import unicode_literals
DATE_INPUT_FORMATS = [
] DATETIME_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = 'j. E Y.' TIME_FORMAT = 'H:i' DATETIME_FORMAT = 'j. E Y. H:i' YEAR_MONTH_FORMAT = 'F Y.' MONTH_DAY_FORMAT = 'j. F' SHORT_DATE_FORMAT = 'j.m.Y.' SHORT_DATETIME_FORMAT = 'j.m.Y. H:i' FIRST_DAY_OF_WEEK = 1
DATE_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = 'd F Y' TIME_FORMAT = 'g.i.A' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'Y-m-d'
DECIMAL_SEPARATOR = ',' THOUSAND_SEPARATOR = '.'
from __future__ import unicode_literals
DATE_FORMAT = 'j. F Y' TIME_FORMAT = 'H:i' DATETIME_FORMAT = 'j. F Y H:i' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j. F' SHORT_DATE_FORMAT = 'd.m.Y' SHORT_DATETIME_FORMAT = 'd.m.Y H:i'
DATE_INPUT_FORMATS = [
] DATETIME_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_INPUT_FORMATS = [
] TIME_INPUT_FORMATS = [
'%d-%m-%Y %H:%M:%S', '%d-%m-%y %H:%M:%S', '%Y-%m-%d %H:%M:%S', '%d/%m/%Y %H:%M:%S', '%d/%m/%y %H:%M:%S', '%Y/%m/%d %H:%M:%S', '%d-%m-%Y %H:%M:%S.%f', '%d-%m-%y %H:%M:%S.%f', '%Y-%m-%d %H:%M:%S.%f', '%d/%m/%Y %H:%M:%S.%f', '%d/%m/%y %H:%M:%S.%f', '%Y/%m/%d %H:%M:%S.%f',
] DECIMAL_SEPARATOR = ',' THOUSAND_SEPARATOR = '.' NUMBER_GROUPING = 3
from __future__ import unicode_literals
DATE_FORMAT = 'j. F Y' TIME_FORMAT = 'H:i' DATETIME_FORMAT = 'j. F Y H:i' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j. F' SHORT_DATE_FORMAT = 'd.m.Y' SHORT_DATETIME_FORMAT = 'd.m.Y H:i'
DATE_INPUT_FORMATS = [
] DATETIME_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = 'j. E Y' TIME_FORMAT = 'G:i' DATETIME_FORMAT = 'j. E Y G:i' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j. F' SHORT_DATE_FORMAT = 'd.m.Y' SHORT_DATETIME_FORMAT = 'd.m.Y G:i'
DATE_INPUT_FORMATS = [
] TIME_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = 'j F Y' TIME_FORMAT = 'H:i' DATETIME_FORMAT = 'j F Y, H:i' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'd.m.Y' SHORT_DATETIME_FORMAT = 'd.m.Y, H:i'
DECIMAL_SEPARATOR = ',' THOUSAND_SEPARATOR = '.'
from __future__ import unicode_literals
DATE_FORMAT = 'Y n j' TIME_FORMAT = 'A g:i' DATETIME_FORMAT = 'Y n j g:i A' YEAR_MONTH_FORMAT = 'Y n' MONTH_DAY_FORMAT = 'n j' SHORT_DATE_FORMAT = 'Y-n-j.' SHORT_DATETIME_FORMAT = 'Y-n-j H:i'
DATE_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = 'j F Y' TIME_FORMAT = 'g:i A' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'd-m-Y'
DECIMAL_SEPARATOR = '.' THOUSAND_SEPARATOR = ','
from __future__ import unicode_literals
DATE_FORMAT = 'j F Y' TIME_FORMAT = 'H:i' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'j M Y'
DECIMAL_SEPARATOR = '.' THOUSAND_SEPARATOR = ','
from __future__ import unicode_literals
DATE_FORMAT = 'd F Y' TIME_FORMAT = 'H:i' DATETIME_FORMAT = 'd F Y H:i' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'd F' SHORT_DATE_FORMAT = 'd M Y' SHORT_DATETIME_FORMAT = 'd M Y H:i'
DATE_INPUT_FORMATS = [
] DATETIME_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = 'j F, Y' TIME_FORMAT = 'g:i A' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'j M, Y'
DECIMAL_SEPARATOR = '.' THOUSAND_SEPARATOR = ','
from __future__ import unicode_literals
from __future__ import unicode_literals
DATE_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = 'j F Y' TIME_FORMAT = 'g:i A' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'd/m/Y'
DECIMAL_SEPARATOR = ',' THOUSAND_SEPARATOR = '.'
from __future__ import unicode_literals
DATE_FORMAT = 'j  F  Y' TIME_FORMAT = 'G:i' DATETIME_FORMAT = 'j  F  Y, G:i' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'j M Y' SHORT_DATETIME_FORMAT = 'j M Y, G:i'
DECIMAL_SEPARATOR = ',' THOUSAND_SEPARATOR = '.'
from __future__ import unicode_literals
DATE_FORMAT = 'd F Y' TIME_FORMAT = 'H:i' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'd.m.Y'
DECIMAL_SEPARATOR = ','
from __future__ import unicode_literals
DATE_FORMAT = r'j \d\e F \d\e Y' TIME_FORMAT = 'H:i' DATETIME_FORMAT = r'j \d\e F \d\e Y \s H:i' YEAR_MONTH_FORMAT = r'F \d\e Y' MONTH_DAY_FORMAT = r'j \d\e F' SHORT_DATE_FORMAT = 'd/m/Y' SHORT_DATETIME_FORMAT = 'd/m/Y H:i'
DATE_INPUT_FORMATS = [
] DATETIME_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = 'j E Y .' TIME_FORMAT = 'G:i' DATETIME_FORMAT = 'j E Y . G:i' YEAR_MONTH_FORMAT = 'F Y .' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'd.m.Y' SHORT_DATETIME_FORMAT = 'd.m.Y H:i'
DATE_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = 'j E Y .' TIME_FORMAT = 'G:i' DATETIME_FORMAT = 'j E Y . G:i' YEAR_MONTH_FORMAT = 'F Y .' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'd.m.Y' SHORT_DATETIME_FORMAT = 'd.m.Y H:i'
DATE_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = r'Y. \g\a\d\a j. F' TIME_FORMAT = 'H:i' DATETIME_FORMAT = r'Y. \g\a\d\a j. F, H:i' YEAR_MONTH_FORMAT = r'Y. \g. F' MONTH_DAY_FORMAT = 'j. F' SHORT_DATE_FORMAT = r'j.m.Y' SHORT_DATETIME_FORMAT = 'j.m.Y H:i'
DATE_INPUT_FORMATS = [
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
DATE_FORMAT = r'j \d\e F \d\e Y' TIME_FORMAT = 'H:i' DATETIME_FORMAT = r'j \d\e F \d\e Y \s H:i' YEAR_MONTH_FORMAT = r'F \d\e Y' MONTH_DAY_FORMAT = r'j \d\e F' SHORT_DATE_FORMAT = 'd/m/Y' SHORT_DATETIME_FORMAT = 'd/m/Y H:i'
DATE_INPUT_FORMATS = [
] DATETIME_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_INPUT_FORMATS = [
from __future__ import unicode_literals
'%d/%m/%Y', '%d/%m/%y'
from __future__ import unicode_literals
DATE_FORMAT = 'j N Y' DATETIME_FORMAT = "j N Y, G.i" TIME_FORMAT = 'G.i' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'd-m-Y' SHORT_DATETIME_FORMAT = 'd-m-Y G.i'
DATE_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = r'j \d\e F \d\e Y' TIME_FORMAT = 'H:i' DATETIME_FORMAT = r'j \d\e F \d\e Y \a \l\a\s H:i' YEAR_MONTH_FORMAT = r'F \d\e Y' MONTH_DAY_FORMAT = r'j \d\e F' SHORT_DATE_FORMAT = 'd/m/Y' SHORT_DATETIME_FORMAT = 'd/m/Y H:i'
DATE_INPUT_FORMATS = [ '%d/%m/%Y', '%d/%m/%y' ] DATETIME_INPUT_FORMATS = [ '%d/%m/%Y %H:%M:%S', '%d/%m/%Y %H:%M:%S.%f', '%d/%m/%Y %H:%M', '%d/%m/%y %H:%M:%S', '%d/%m/%y %H:%M:%S.%f', '%d/%m/%y %H:%M', ] DECIMAL_SEPARATOR = ',' THOUSAND_SEPARATOR = '.' NUMBER_GROUPING = 3
from __future__ import unicode_literals
DATE_FORMAT = 'j E Y' TIME_FORMAT = 'H:i' DATETIME_FORMAT = 'j E Y H:i' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'd-m-Y' SHORT_DATETIME_FORMAT = 'd-m-Y H:i'
DATE_INPUT_FORMATS = [
] DATETIME_INPUT_FORMATS = [
from __future__ import unicode_literals
DATE_FORMAT = 'j. N Y.' TIME_FORMAT = 'G:i' DATETIME_FORMAT = 'j. N. Y. G:i T' YEAR_MONTH_FORMAT = 'F Y.' MONTH_DAY_FORMAT = 'j. F' SHORT_DATE_FORMAT = 'Y M j'
DECIMAL_SEPARATOR = ',' THOUSAND_SEPARATOR = '.'
from __future__ import unicode_literals
DATE_FORMAT = r'j \d\e F \d\e Y' TIME_FORMAT = 'G:i' DATETIME_FORMAT = r'j \d\e F \d\e Y \a \l\e\s G:i' YEAR_MONTH_FORMAT = r'F \d\e\l Y' MONTH_DAY_FORMAT = r'j \d\e F' SHORT_DATE_FORMAT = 'd/m/Y' SHORT_DATETIME_FORMAT = 'd/m/Y G:i'
DATE_INPUT_FORMATS = [ '%d/%m/%Y', '%d/%m/%y' ] DATETIME_INPUT_FORMATS = [ '%d/%m/%Y %H:%M:%S', '%d/%m/%Y %H:%M:%S.%f', '%d/%m/%Y %H:%M', '%d/%m/%y %H:%M:%S', '%d/%m/%y %H:%M:%S.%f', '%d/%m/%y %H:%M', ] DECIMAL_SEPARATOR = ',' THOUSAND_SEPARATOR = '.' NUMBER_GROUPING = 3
from __future__ import unicode_literals
DATE_FORMAT = 'j F Y' TIME_FORMAT = 'G:i' DATETIME_FORMAT = 'j F Y, G:i' YEAR_MONTH_FORMAT = 'F Y' MONTH_DAY_FORMAT = 'j F' SHORT_DATE_FORMAT = 'j M Y' SHORT_DATETIME_FORMAT = 'j M Y, G:i'
DECIMAL_SEPARATOR = '.' THOUSAND_SEPARATOR = ','
def gettext_noop(s): return s
DEBUG_PROPAGATE_EXCEPTIONS = False
USE_ETAGS = False
ADMINS = []
INTERNAL_IPS = []
ALLOWED_HOSTS = []
TIME_ZONE = 'America/Chicago'
USE_TZ = False
LANGUAGE_CODE = 'en-us'
LANGUAGES = [ ('af', gettext_noop('Afrikaans')), ('ar', gettext_noop('Arabic')), ('ast', gettext_noop('Asturian')), ('az', gettext_noop('Azerbaijani')), ('bg', gettext_noop('Bulgarian')), ('be', gettext_noop('Belarusian')), ('bn', gettext_noop('Bengali')), ('br', gettext_noop('Breton')), ('bs', gettext_noop('Bosnian')), ('ca', gettext_noop('Catalan')), ('cs', gettext_noop('Czech')), ('cy', gettext_noop('Welsh')), ('da', gettext_noop('Danish')), ('de', gettext_noop('German')), ('el', gettext_noop('Greek')), ('en', gettext_noop('English')), ('en-au', gettext_noop('Australian English')), ('en-gb', gettext_noop('British English')), ('eo', gettext_noop('Esperanto')), ('es', gettext_noop('Spanish')), ('es-ar', gettext_noop('Argentinian Spanish')), ('es-co', gettext_noop('Colombian Spanish')), ('es-mx', gettext_noop('Mexican Spanish')), ('es-ni', gettext_noop('Nicaraguan Spanish')), ('es-ve', gettext_noop('Venezuelan Spanish')), ('et', gettext_noop('Estonian')), ('eu', gettext_noop('Basque')), ('fa', gettext_noop('Persian')), ('fi', gettext_noop('Finnish')), ('fr', gettext_noop('French')), ('fy', gettext_noop('Frisian')), ('ga', gettext_noop('Irish')), ('gd', gettext_noop('Scottish Gaelic')), ('gl', gettext_noop('Galician')), ('he', gettext_noop('Hebrew')), ('hi', gettext_noop('Hindi')), ('hr', gettext_noop('Croatian')), ('hu', gettext_noop('Hungarian')), ('ia', gettext_noop('Interlingua')), ('id', gettext_noop('Indonesian')), ('io', gettext_noop('Ido')), ('is', gettext_noop('Icelandic')), ('it', gettext_noop('Italian')), ('ja', gettext_noop('Japanese')), ('ka', gettext_noop('Georgian')), ('kk', gettext_noop('Kazakh')), ('km', gettext_noop('Khmer')), ('kn', gettext_noop('Kannada')), ('ko', gettext_noop('Korean')), ('lb', gettext_noop('Luxembourgish')), ('lt', gettext_noop('Lithuanian')), ('lv', gettext_noop('Latvian')), ('mk', gettext_noop('Macedonian')), ('ml', gettext_noop('Malayalam')), ('mn', gettext_noop('Mongolian')), ('mr', gettext_noop('Marathi')), ('my', gettext_noop('Burmese')), ('nb', gettext_noop('Norwegian Bokml')), ('ne', gettext_noop('Nepali')), ('nl', gettext_noop('Dutch')), ('nn', gettext_noop('Norwegian Nynorsk')), ('os', gettext_noop('Ossetic')), ('pa', gettext_noop('Punjabi')), ('pl', gettext_noop('Polish')), ('pt', gettext_noop('Portuguese')), ('pt-br', gettext_noop('Brazilian Portuguese')), ('ro', gettext_noop('Romanian')), ('ru', gettext_noop('Russian')), ('sk', gettext_noop('Slovak')), ('sl', gettext_noop('Slovenian')), ('sq', gettext_noop('Albanian')), ('sr', gettext_noop('Serbian')), ('sr-latn', gettext_noop('Serbian Latin')), ('sv', gettext_noop('Swedish')), ('sw', gettext_noop('Swahili')), ('ta', gettext_noop('Tamil')), ('te', gettext_noop('Telugu')), ('th', gettext_noop('Thai')), ('tr', gettext_noop('Turkish')), ('tt', gettext_noop('Tatar')), ('udm', gettext_noop('Udmurt')), ('uk', gettext_noop('Ukrainian')), ('ur', gettext_noop('Urdu')), ('vi', gettext_noop('Vietnamese')), ('zh-hans', gettext_noop('Simplified Chinese')), ('zh-hant', gettext_noop('Traditional Chinese')), ]
LANGUAGES_BIDI = ["he", "ar", "fa", "ur"]
USE_I18N = True LOCALE_PATHS = []
LANGUAGE_COOKIE_NAME = 'django_language' LANGUAGE_COOKIE_AGE = None LANGUAGE_COOKIE_DOMAIN = None LANGUAGE_COOKIE_PATH = '/'
USE_L10N = False
MANAGERS = ADMINS
DEFAULT_CONTENT_TYPE = 'text/html' DEFAULT_CHARSET = 'utf-8'
FILE_CHARSET = 'utf-8'
SERVER_EMAIL = 'root@localhost'
DATABASES = {}
DATABASE_ROUTERS = []
EMAIL_BACKEND = 'django.core.mail.backends.smtp.EmailBackend'
EMAIL_HOST = 'localhost'
EMAIL_PORT = 25
EMAIL_HOST_USER = '' EMAIL_HOST_PASSWORD = '' EMAIL_USE_TLS = False EMAIL_USE_SSL = False EMAIL_SSL_CERTFILE = None EMAIL_SSL_KEYFILE = None EMAIL_TIMEOUT = None
INSTALLED_APPS = []
DEFAULT_FROM_EMAIL = 'webmaster@localhost'
EMAIL_SUBJECT_PREFIX = '[Django] '
APPEND_SLASH = True
PREPEND_WWW = False
FORCE_SCRIPT_NAME = None
DISALLOWED_USER_AGENTS = []
IGNORABLE_404_URLS = []
SECRET_KEY = ''
DEFAULT_FILE_STORAGE = 'django.core.files.storage.FileSystemStorage'
MEDIA_ROOT = ''
MEDIA_URL = ''
STATIC_ROOT = None
STATIC_URL = None
FILE_UPLOAD_HANDLERS = [ 'django.core.files.uploadhandler.MemoryFileUploadHandler', 'django.core.files.uploadhandler.TemporaryFileUploadHandler', ]
DATA_UPLOAD_MAX_NUMBER_FIELDS = 1000
FILE_UPLOAD_TEMP_DIR = None
FILE_UPLOAD_PERMISSIONS = None
FILE_UPLOAD_DIRECTORY_PERMISSIONS = None
FORMAT_MODULE_PATH = None
DATE_FORMAT = 'N j, Y'
DATETIME_FORMAT = 'N j, Y, P'
TIME_FORMAT = 'P'
YEAR_MONTH_FORMAT = 'F Y'
MONTH_DAY_FORMAT = 'F j'
SHORT_DATE_FORMAT = 'm/d/Y'
SHORT_DATETIME_FORMAT = 'm/d/Y P'
DATE_INPUT_FORMATS = [
TIME_INPUT_FORMATS = [
DATETIME_INPUT_FORMATS = [
FIRST_DAY_OF_WEEK = 0
DECIMAL_SEPARATOR = '.'
USE_THOUSAND_SEPARATOR = False
NUMBER_GROUPING = 0
THOUSAND_SEPARATOR = ','
DEFAULT_TABLESPACE = '' DEFAULT_INDEX_TABLESPACE = ''
X_FRAME_OPTIONS = 'SAMEORIGIN'
WSGI_APPLICATION = None
SECURE_PROXY_SSL_HEADER = None
MIDDLEWARE_CLASSES = [ 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', ]
SESSION_CACHE_ALIAS = 'default' SESSION_COOKIE_NAME = 'sessionid' SESSION_COOKIE_AGE = 60 * 60 * 24 * 7 * 2 SESSION_COOKIE_DOMAIN = None SESSION_COOKIE_SECURE = False SESSION_COOKIE_PATH = '/' SESSION_COOKIE_HTTPONLY = True SESSION_SAVE_EVERY_REQUEST = False SESSION_EXPIRE_AT_BROWSER_CLOSE = False SESSION_ENGINE = 'django.contrib.sessions.backends.db' SESSION_FILE_PATH = None SESSION_SERIALIZER = 'django.contrib.sessions.serializers.JSONSerializer'
CACHES = { 'default': { 'BACKEND': 'django.core.cache.backends.locmem.LocMemCache', } } CACHE_MIDDLEWARE_KEY_PREFIX = '' CACHE_MIDDLEWARE_SECONDS = 600 CACHE_MIDDLEWARE_ALIAS = 'default'
PASSWORD_RESET_TIMEOUT_DAYS = 3
PASSWORD_HASHERS = [ 'django.contrib.auth.hashers.PBKDF2PasswordHasher', 'django.contrib.auth.hashers.PBKDF2SHA1PasswordHasher', 'django.contrib.auth.hashers.Argon2PasswordHasher', 'django.contrib.auth.hashers.BCryptSHA256PasswordHasher', 'django.contrib.auth.hashers.BCryptPasswordHasher', ]
CSRF_FAILURE_VIEW = 'django.views.csrf.csrf_failure'
CSRF_COOKIE_NAME = 'csrftoken' CSRF_COOKIE_AGE = 60 * 60 * 24 * 7 * 52 CSRF_COOKIE_DOMAIN = None CSRF_COOKIE_PATH = '/' CSRF_COOKIE_SECURE = False CSRF_COOKIE_HTTPONLY = False CSRF_HEADER_NAME = 'HTTP_X_CSRFTOKEN' CSRF_TRUSTED_ORIGINS = []
MESSAGE_STORAGE = 'django.contrib.messages.storage.fallback.FallbackStorage'
LOGGING_CONFIG = 'logging.config.dictConfig'
LOGGING = {}
DEFAULT_EXCEPTION_REPORTER_FILTER = 'django.views.debug.SafeExceptionReporterFilter'
TEST_RUNNER = 'django.test.runner.DiscoverRunner'
TEST_NON_SERIALIZED_APPS = []
FIXTURE_DIRS = []
STATICFILES_DIRS = []
STATICFILES_STORAGE = 'django.contrib.staticfiles.storage.StaticFilesStorage'
STATICFILES_FINDERS = [ 'django.contrib.staticfiles.finders.FileSystemFinder', 'django.contrib.staticfiles.finders.AppDirectoriesFinder', ]
MIGRATION_MODULES = {}
SILENCED_SYSTEM_CHECKS = []
SECURE_BROWSER_XSS_FILTER = False SECURE_CONTENT_TYPE_NOSNIFF = False SECURE_HSTS_INCLUDE_SUBDOMAINS = False SECURE_HSTS_SECONDS = 0 SECURE_REDIRECT_EXEMPT = [] SECURE_SSL_HOST = None SECURE_SSL_REDIRECT = False
t = Engine().from_string(CSRF_FAILURE_TEMPLATE)
raise
try: message = exception.args[0] except (AttributeError, IndexError): pass else: if isinstance(message, six.text_type): exception_repr = message context = { 'request_path': request.path, 'exception': exception_repr, } try: template = loader.get_template(template_name) body = template.render(context, request)
raise
raise
raise
return http.HttpResponseBadRequest(template.render())
raise
def _reject(self, request, reason): return None
get_token(request) return retval
def wrapped_view(*args, **kwargs): return view_func(*args, **kwargs) wrapped_view.csrf_exempt = True return wraps(view_func, assigned=available_attrs(view_func))(wrapped_view)
if len(args) != 1 or callable(args[0]): raise TypeError("cache_page has a single mandatory positional argument: timeout") cache_timeout = args[0] cache_alias = kwargs.pop('cache', None) key_prefix = kwargs.pop('key_prefix', None) if kwargs: raise TypeError("cache_page has two optional keyword arguments: cache and key_prefix")
def get_last_modified(): if last_modified_func: dt = last_modified_func(request, *args, **kwargs) if dt: return timegm(dt.utctimetuple())
if res_last_modified and not response.has_header('Last-Modified'): response['Last-Modified'] = http_date(res_last_modified) if res_etag and not response.has_header('ETag'): response['ETag'] = quote_etag(res_etag)
def etag(etag_func): return condition(etag_func=etag_func)
if self.get_paginate_by(self.object_list) is not None and hasattr(self.object_list, 'exists'): is_empty = not self.object_list.exists() else: is_empty = len(self.object_list) == 0 if is_empty: raise Http404(_("Empty list and '%(class_name)s.allow_empty' is False.") % { 'class_name': self.__class__.__name__, })
names = []
if hasattr(self.object_list, 'model'): opts = self.object_list.model._meta names.append("%s/%s%s.html" % (opts.app_label, opts.model_name, self.template_name_suffix))
url = force_text(self.success_url)
model = self.model
model = self.object.__class__
model = self.get_queryset().model
def put(self, *args, **kwargs): return self.post(*args, **kwargs)
def post(self, request, *args, **kwargs): return self.delete(request, *args, **kwargs)
return {date_field: date}
is_empty = len(qs) == 0 if paginate_by is None else not qs.exists() if is_empty: raise Http404(_("No %(verbose_name_plural)s available") % { 'verbose_name_plural': force_text(qs.model._meta.verbose_name_plural) })
qs = qs.none()
qs = self.get_queryset() if queryset is None else queryset
lookup_kwargs = self._make_single_date_lookup(date) qs = qs.filter(**lookup_kwargs)
start, end = get_current(date), get_next(date)
if allow_empty: if is_previous: result = get_current(start - datetime.timedelta(days=1)) else: result = end
else: if is_previous: lookup = {'%s__lt' % date_field: generic_view._make_date_lookup_arg(start)} ordering = '-%s' % date_field else: lookup = {'%s__gte' % date_field: generic_view._make_date_lookup_arg(end)} ordering = date_field
if not allow_future: if generic_view.uses_datetime_field: now = timezone.now() else: now = timezone_today() lookup['%s__lte' % date_field] = now
try: result = getattr(qs[0], date_field) except IndexError: return None
if generic_view.uses_datetime_field: if settings.USE_TZ: result = timezone.localtime(result) result = result.date()
return get_current(result)
for key, value in six.iteritems(kwargs): setattr(self, key, value)
update_wrapper(view, cls, updated=())
update_wrapper(view, cls.dispatch, assigned=()) return view
if request.method.lower() in self.http_method_names: handler = getattr(self, request.method.lower(), self.http_method_not_allowed) else: handler = self.http_method_not_allowed return handler(request, *args, **kwargs)
if queryset is None: queryset = self.get_queryset()
pk = self.kwargs.get(self.pk_url_kwarg) slug = self.kwargs.get(self.slug_url_kwarg) if pk is not None: queryset = queryset.filter(pk=pk)
if slug is not None and (pk is None or self.query_pk_and_slug): slug_field = self.get_slug_field() queryset = queryset.filter(**{slug_field: slug})
if pk is None and slug is None: raise AttributeError("Generic detail view %s must be called with " "either an object pk or a slug." % self.__class__.__name__)
obj = queryset.get()
names = []
if self.object and self.template_name_field: name = getattr(self.object, self.template_name_field, None) if name: names.insert(0, name)
if isinstance(self.object, models.Model): object_meta = self.object._meta names.append("%s/%s%s.html" % ( object_meta.app_label, object_meta.model_name, self.template_name_suffix )) elif hasattr(self, 'model') and self.model is not None and issubclass(self.model, models.Model): names.append("%s/%s%s.html" % ( self.model._meta.app_label, self.model._meta.model_name, self.template_name_suffix ))
if not names: raise
for package in packages: p = importlib.import_module(package) path = os.path.join(os.path.dirname(upath(p.__file__)), 'locale') paths.append(path)
plural = [el.strip() for el in plural.split(';') if el.strip().startswith('plural=')][0].split('=', 1)[1]
}, "formats": { },
packages = kwargs.get('packages', '').split('+') or self.packages paths = self.get_paths(packages) if packages else None self.translation = DjangoTranslation(locale, domain=domain, localedirs=paths) context = self.get_context_data(**kwargs) return self.render_to_response(context)
return [os.path.join(app.path, 'locale') for app in app_configs]
plural = [el.strip() for el in plural.split(';') if el.strip().startswith('plural=')][0].split('=', 1)[1]
}, "formats": { },
continue
continue
statobj = os.stat(fullpath) if not was_modified_since(request.META.get('HTTP_IF_MODIFIED_SINCE'), statobj.st_mtime, statobj.st_size): return HttpResponseNotModified() content_type, encoding = mimetypes.guess_type(fullpath) content_type = content_type or 'application/octet-stream' response = FileResponse(open(fullpath, 'rb'), content_type=content_type) response["Last-Modified"] = http_date(statobj.st_mtime) if stat.S_ISREG(statobj.st_mode): response["Content-Length"] = statobj.st_size if encoding: response["Content-Encoding"] = encoding return response
DEBUG_ENGINE = Engine(debug=True)
cleansed = value
cleansed = CallableSettingWrapper(cleansed)
return import_string(settings.DEFAULT_EXCEPTION_REPORTER_FILTER)()
for k, v in cleansed.items(): cleansed[k] = CLEANSED_SUBSTITUTE return cleansed
for param in sensitive_post_parameters: if param in cleansed: cleansed[param] = CLEANSED_SUBSTITUTE return cleansed
is_multivalue_dict = isinstance(value, MultiValueDict)
value = self.get_cleansed_multivaluedict(request, value)
current_frame = tb_frame.f_back sensitive_variables = None while current_frame is not None: if (current_frame.f_code.co_name == 'sensitive_variables_wrapper' and 'sensitive_variables_wrapper' in current_frame.f_locals): wrapper = current_frame.f_locals['sensitive_variables_wrapper'] sensitive_variables = getattr(wrapper, 'sensitive_variables', None) break current_frame = current_frame.f_back
for name, value in tb_frame.f_locals.items(): cleansed[name] = CLEANSED_SUBSTITUTE
for name, value in tb_frame.f_locals.items(): if name in sensitive_variables: value = CLEANSED_SUBSTITUTE else: value = self.cleanse_special_types(request, value) cleansed[name] = value
for name, value in tb_frame.f_locals.items(): cleansed[name] = self.cleanse_special_types(request, value)
cleansed['func_args'] = CLEANSED_SUBSTITUTE cleansed['func_kwargs'] = CLEANSED_SUBSTITUTE
if isinstance(self.exc_type, six.string_types): self.exc_value = Exception('Deprecated String Exception: %r' % self.exc_type) self.exc_type = type(self.exc_value)
if isinstance(v, six.binary_type):
if len(v) > 4096: v = '%s... <trimmed %d bytes string>' % (v[0:4096], len(v)) frame_vars.append((k, force_escape(v)))
if self.exc_type: c['exception_type'] = self.exc_type.__name__ if self.exc_value: c['exception_value'] = smart_text(self.exc_value, errors='replace') if frames: c['lastframe'] = frames[-1] return c
if isinstance(source[0], six.binary_type): encoding = 'ascii' for line in source[:2]: match = re.search(br'coding[:=]\s*([-\w.]+)', line) if match: encoding = match.group(1).decode('ascii') break source = [six.text_type(sline, encoding, 'replace') for sline in source]
exceptions = [] exc_value = self.exc_value while exc_value: exceptions.append(exc_value) exc_value = explicit_or_implicit_cause(exc_value)
if not exceptions: return frames
exc_value = exceptions.pop() tb = self.tb if six.PY2 or not exceptions else exc_value.__traceback__
if tb.tb_frame.f_locals.get('__traceback_hide__'): tb = tb.tb_next continue filename = tb.tb_frame.f_code.co_filename function = tb.tb_frame.f_code.co_name lineno = tb.tb_lineno - 1 loader = tb.tb_frame.f_globals.get('__loader__') module_name = tb.tb_frame.f_globals.get('__name__') or '' pre_context_lineno, pre_context, context_line, post_context = self._get_lines_from_file( filename, lineno, 7, loader, module_name, ) if pre_context_lineno is not None: frames.append({ 'exc_cause': explicit_or_implicit_cause(exc_value), 'exc_cause_explicit': getattr(exc_value, '__cause__', True), 'tb': tb, 'type': 'django' if module_name.startswith('django.') else 'user', 'filename': filename, 'function': function, 'lineno': lineno + 1, 'vars': self.filter.get_traceback_frame_variables(self.request, tb.tb_frame), 'id': id(tb), 'pre_context': pre_context, 'context_line': context_line, 'post_context': post_context, 'pre_context_lineno': pre_context_lineno + 1, })
if six.PY2: tb = tb.tb_next elif not tb.tb_next and exceptions: exc_value = exceptions.pop() tb = exc_value.__traceback__ else: tb = tb.tb_next
if installed_apps is None and hasattr(sys.modules[__name__], 'apps'): raise RuntimeError("You must supply an installed_apps argument.")
self.all_models = defaultdict(OrderedDict)
self.app_configs = OrderedDict()
self.stored_app_configs = []
self.apps_ready = self.models_ready = self.ready = False
self._lock = threading.Lock()
self._pending_operations = defaultdict(list)
if installed_apps is not None: self.populate(installed_apps)
with self._lock: if self.ready: return
if self.app_configs: raise RuntimeError("populate() isn't reentrant")
for entry in installed_apps: if isinstance(entry, AppConfig): app_config = entry else: app_config = AppConfig.create(entry) if app_config.label in self.app_configs: raise ImproperlyConfigured( "Application labels aren't unique, " "duplicates: %s" % app_config.label)
counts = Counter( app_config.name for app_config in self.app_configs.values()) duplicates = [ name for name, count in counts.most_common() if count > 1] if duplicates: raise ImproperlyConfigured( "Application names aren't unique, " "duplicates: %s" % ", ".join(duplicates))
for app_config in self.app_configs.values(): all_models = self.all_models[app_config.label] app_config.import_models(all_models)
model_name = model._meta.model_name app_models = self.all_models[app_label] if model_name in app_models: if (model.__name__ == app_models[model_name].__name__ and model.__module__ == app_models[model_name].__module__): warnings.warn( "Model '%s.%s' was already registered. " "Reloading models is not advised as it can lead to inconsistencies, " "most notably with related models." % (app_label, model_name), RuntimeWarning, stacklevel=2) else: raise RuntimeError( "Conflicting '%s' models in application '%s': %s and %s." % (model_name, app_label, app_models[model_name], model)) app_models[model_name] = model self.do_pending_operations(model) self.clear_cache()
if swapped and swapped == to_string: return model._meta.swappable if model._meta.swappable and model._meta.label == to_string: return model._meta.swappable
self.get_models.cache_clear() if self.ready: for app_config in self.app_configs.values(): for model in app_config.get_models(include_auto_created=True): model._meta._expire_cache()
if not model_keys: function() else: next_model, more_models = model_keys[0], model_keys[1:]
def apply_next_model(model): next_function = partial(apply_next_model.func, model) self.lazy_model_operation(next_function, *more_models) apply_next_model.func = function
try: model_class = self.get_registered_model(*next_model) except LookupError: self._pending_operations[next_model].append(apply_next_model) else: apply_next_model(model_class)
self.name = app_name
self.module = app_module
if not hasattr(self, 'label'): self.label = app_name.rpartition(".")[2]
if not hasattr(self, 'verbose_name'): self.verbose_name = self.label.title()
if not hasattr(self, 'path'): self.path = self._path_from_module(app_module)
self.models_module = None
self.models = None
paths = list(getattr(module, '__path__', [])) if len(paths) != 1: filename = getattr(module, '__file__', None) if filename is not None: paths = [os.path.dirname(filename)] else: paths = list(set(paths)) if len(paths) > 1: raise ImproperlyConfigured( "The app module %r has multiple filesystem locations (%r); " "you must configure this app with an AppConfig subclass " "with a 'path' class attribute." % (module, paths)) elif not paths: raise ImproperlyConfigured( "The app module %r has no filesystem location, " "you must configure this app with an AppConfig subclass " "with a 'path' class attribute." % (module,)) return upath(paths[0])
module = import_module(entry)
module = None
if not mod_path: raise
entry = module.default_app_config
return cls(entry, module)
mod = import_module(mod_path) try: cls = getattr(mod, cls_name) except AttributeError: if module is None: import_module(entry) else: raise
if not issubclass(cls, AppConfig): raise ImproperlyConfigured( "'%s' isn't a subclass of AppConfig." % entry)
try: app_name = cls.name except AttributeError: raise ImproperlyConfigured( "'%s' must supply a name attribute." % entry)
app_module = import_module(app_name)
return cls(app_name, app_module)
self.models = all_models
if re.search('[^a-zA-Z0-9]', force_text(token)): return _get_new_csrf_token() elif len(token) == CSRF_TOKEN_LENGTH: return token elif len(token) == CSRF_SECRET_LENGTH: return _salt_cipher_secret(token) return _get_new_csrf_token()
return constant_time_compare( _unsalt_cipher_token(request_csrf_token), _unsalt_cipher_token(csrf_token), )
def _accept(self, request): request.csrf_processing_done = True return None
request.csrf_cookie_needs_reset = True
if getattr(callback, 'csrf_exempt', False): return None
if request.method not in ('GET', 'HEAD', 'OPTIONS', 'TRACE'): if getattr(request, '_dont_enforce_csrf_checks', False): return self._accept(request)
referer = force_text( request.META.get('HTTP_REFERER'), strings_only=True, errors='replace' ) if referer is None: return self._reject(request, REASON_NO_REFERER)
if '' in (referer.scheme, referer.netloc): return self._reject(request, REASON_MALFORMED_REFERER)
if referer.scheme != 'https': return self._reject(request, REASON_INSECURE_REFERER)
if settings.CSRF_COOKIE_DOMAIN is None: good_referer = request.get_host() else: good_referer = settings.CSRF_COOKIE_DOMAIN server_port = request.get_port() if server_port not in ('443', '80'): good_referer = '%s:%s' % (good_referer, server_port)
good_hosts = list(settings.CSRF_TRUSTED_ORIGINS) good_hosts.append(good_referer)
return self._reject(request, REASON_NO_CSRF_COOKIE)
request_csrf_token = "" if request.method == "POST": try: request_csrf_token = request.POST.get('csrfmiddlewaretoken', '') except IOError: pass
request_csrf_token = request.META.get(settings.CSRF_HEADER_NAME, '')
response.set_cookie(settings.CSRF_COOKIE_NAME, request.META["CSRF_COOKIE"], max_age=settings.CSRF_COOKIE_AGE, domain=settings.CSRF_COOKIE_DOMAIN, path=settings.CSRF_COOKIE_PATH, secure=settings.CSRF_COOKIE_SECURE, httponly=settings.CSRF_COOKIE_HTTPONLY ) patch_vary_headers(response, ('Cookie',)) response.csrf_cookie_set = True return response
security_logger = logging.getLogger('django.security.%s' % exc.__class__.__name__) security_logger.error( force_text(exc), extra={'status_code': 400, 'request': request}, ) if settings.DEBUG: return debug.technical_500_response(request, *sys.exc_info(), status_code=400)
raise
signals.got_request_exception.send(sender=self.handler.__class__, request=request) response = self.handler.handle_uncaught_exception(request, get_resolver(get_urlconf()), sys.exc_info())
return response
if not request.COOKIES and response.cookies and has_vary_header(response, 'Cookie'): return response
timeout = get_max_age(response) if timeout is None: timeout = self.cache_timeout elif timeout == 0: return response patch_response_headers(response, timeout) if timeout: cache_key = learn_cache_key(request, response, timeout, self.key_prefix, cache=self.cache) if hasattr(response, 'render') and callable(response.render): response.add_post_render_callback( lambda r: self.cache.set(cache_key, r, timeout) ) else: self.cache.set(cache_key, response, timeout) return response
cache_key = get_cache_key(request, self.key_prefix, 'GET', cache=self.cache) if cache_key is None: request._cache_update_cache = True
if response is None and request.method == 'HEAD': cache_key = get_cache_key(request, self.key_prefix, 'HEAD', cache=self.cache) response = self.cache.get(cache_key)
request._cache_update_cache = False return response
if response.get('X-Frame-Options') is not None: return response
if getattr(response, 'xframe_options_exempt', False): return response
super(LocaleMiddleware, self).__init__(get_response)
language_url = request.get_full_path(force_append_slash=path_needs_slash).replace( script_prefix, '%s%s/' % (script_prefix, language), 1 ) return self.response_redirect_class(language_url)
if 'HTTP_USER_AGENT' in request.META: for user_agent_regex in settings.DISALLOWED_USER_AGENTS: if user_agent_regex.search(request.META['HTTP_USER_AGENT']): raise PermissionDenied('Forbidden user agent')
host = request.get_host() must_prepend = settings.PREPEND_WWW and host and not host.startswith('www.') redirect_url = ('%s://www.%s' % (request.scheme, host)) if must_prepend else ''
if self.should_redirect_with_slash(request): path = self.get_full_path_with_slash(request) else: path = request.get_full_path()
if redirect_url or path != request.get_full_path(): redirect_url += path return self.response_redirect_class(redirect_url)
if response.status_code == 404: if self.should_redirect_with_slash(request): return self.response_redirect_class(self.get_full_path_with_slash(request))
return bool(re.match("^https?://%s/" % re.escape(domain), referer))
if not referer: return True
if settings.APPEND_SLASH and uri.endswith('/') and referer == uri[:-1]: return True
if not self.is_internal_request(domain, referer) and '?' in referer: return True
parsed_referer = urlparse(referer) if parsed_referer.netloc in ['', domain] and parsed_referer.path == uri: return True
if not response.streaming and len(response.content) < 200: return response
if response.has_header('Content-Encoding'): return response
response.streaming_content = compress_sequence(response.streaming_content) del response['Content-Length']
compressed_content = compress_string(response.content) if len(compressed_content) >= len(response.content): return response response.content = compressed_content response['Content-Length'] = str(len(response.content))
from __future__ import unicode_literals
verbose_name = "\xc3\x85ngstr\xc3\xb6m's Articles"
movie_id = models.AutoField(primary_key=True) name = models.CharField(max_length=60)
return b'Name\xff: %s'.decode() % self.name
class Model1(models.Model): pkey = models.IntegerField(unique=True, db_index=True)
query.get_compiler(using=db).as_sql()
a = Article.objects.create( headline="Look at me!", pub_date=datetime.datetime.now() ) self.assertIs(a.get_status_display(), None)
a = Article.objects.get(pk=a.pk) self.assertEqual(a.misc_data, '') self.assertIs(type(a.misc_data), six.text_type)
a = Article.objects.create( headline="Really, really big", pub_date=datetime.datetime.now(), article_text="ABCDE" * 1000 ) a = Article.objects.get(pk=a.pk) self.assertEqual(len(a.article_text), 5000)
a = Article.objects.create( headline="Really, really big", pub_date=datetime.datetime.now(), article_text='\u05d0\u05d1\u05d2' * 1000 ) a = Article.objects.get(pk=a.pk) self.assertEqual(len(a.article_text), 3000)
Party.objects.create(when=datetime.datetime(1999, 12, 31)) Party.objects.create(when=datetime.datetime(1998, 12, 31)) Party.objects.create(when=datetime.datetime(1999, 1, 1)) Party.objects.create(when=datetime.datetime(1, 3, 3)) self.assertQuerysetEqual( Party.objects.filter(when__month=2), [] ) self.assertQuerysetEqual( Party.objects.filter(when__month=1), [ datetime.date(1999, 1, 1) ], attrgetter("when") ) self.assertQuerysetEqual( Party.objects.filter(when__month=12), [ datetime.date(1999, 12, 31), datetime.date(1998, 12, 31), ], attrgetter("when"), ordered=False ) self.assertQuerysetEqual( Party.objects.filter(when__year=1998), [ datetime.date(1998, 12, 31), ], attrgetter("when") ) self.assertQuerysetEqual( Party.objects.filter(when__day="31"), [ datetime.date(1999, 12, 31), datetime.date(1998, 12, 31), ], attrgetter("when"), ordered=False ) self.assertQuerysetEqual( Party.objects.filter(when__month="12"), [ datetime.date(1999, 12, 31), datetime.date(1998, 12, 31), ], attrgetter("when"), ordered=False ) self.assertQuerysetEqual( Party.objects.filter(when__year="1998"), [ datetime.date(1998, 12, 31), ], attrgetter("when") )
self.assertQuerysetEqual( Party.objects.filter(when__year=1), [ datetime.date(1, 3, 3), ], attrgetter("when") ) self.assertQuerysetEqual( Party.objects.filter(when__year='1'), [ datetime.date(1, 3, 3), ], attrgetter("when") )
Party.objects.create(when=datetime.datetime(1999, 1, 1)) Party.objects.create() p = Party.objects.filter(when__month=1)[0] self.assertEqual(p.when, datetime.date(1999, 1, 1)) self.assertQuerysetEqual( Party.objects.filter(pk=p.pk).dates("when", "month"), [ 1 ], attrgetter("month") )
Event.objects.create(when=datetime.datetime(2000, 1, 1, 16, 0, 0)) Event.objects.create(when=datetime.datetime(2000, 1, 1, 6, 1, 1)) Event.objects.create(when=datetime.datetime(2000, 1, 1, 13, 1, 1)) e = Event.objects.create(when=datetime.datetime(2000, 1, 1, 12, 0, 20, 24))
d = Department.objects.create(id=10, name="IT") w = Worker.objects.create(department=d, name="Full-time") self.assertEqual(six.text_type(w), "Full-time")
b = BrokenUnicodeMethod.objects.create(name="Jerry") self.assertEqual(repr(b), "<BrokenUnicodeMethod: [Bad Unicode data]>")
dt1 = datetime.datetime(2008, 8, 31, 16, 20, tzinfo=get_fixed_timezone(600)) dt2 = datetime.datetime(2008, 8, 31, 17, 20, tzinfo=get_fixed_timezone(600)) obj = Article.objects.create( headline="A headline", pub_date=dt1, article_text="foo" ) obj.pub_date = dt2 obj.save() self.assertEqual( Article.objects.filter(headline="A headline").update(pub_date=dt1), 1 )
m3 = Model3.objects.get(model2=1000) m3.model2
qs = RevisionableModel.objects.extra( where=["%(table)s.id IN (SELECT MAX(rev.id) FROM %(table)s rev GROUP BY rev.base_id)" % { 'table': RevisionableModel._meta.db_table, }] )
qs2 = RevisionableModel.objects.filter(title__contains="Revision") self.assertQuerysetEqual( qs2, [ ('First Revision', 'First Revision'), ('Second Revision', 'First Revision'), ], transform=lambda r: (r.title, r.base.title), ordered=False )
self.assertQuerysetEqual( qs & qs2, [('Second Revision', 'First Revision')], transform=lambda r: (r.title, r.base.title), ordered=False )
qs = User.objects.extra( select=OrderedDict((("alpha", "%s"), ("beta", "2"), ("gamma", "%s"))), select_params=(1, 3) ) qs = qs.extra(select={"beta": 4}) qs = qs.extra(select={"alpha": "%s"}, select_params=[5]) self.assertEqual( list(qs.filter(id=self.u.id).values('alpha', 'beta', 'gamma')), [{'alpha': 5, 'beta': 4, 'gamma': 3}] )
self.assertEqual( list( TestObject.objects .values() .extra(select=OrderedDict((('foo', 'first'), ('bar', 'second'), ('whiz', 'third')))) ), [{ 'bar': 'second', 'third': 'third', 'second': 'second', 'whiz': 'third', 'foo': 'first', 'id': obj.pk, 'first': 'first' }] )
self.assertEqual( list( TestObject.objects .extra(select=OrderedDict((('foo', 'first'), ('bar', 'second'), ('whiz', 'third')))) .values('first', 'second') ), [{'second': 'second', 'first': 'first'}] )
self.assertEqual( list( TestObject.objects .values('first', 'second') .extra(select=OrderedDict((('foo', 'first'), ('bar', 'second'), ('whiz', 'third')))) ), [{'second': 'second', 'first': 'first'}] )
self.assertEqual( list( TestObject.objects .extra(select=OrderedDict((('foo', 'first'), ('bar', 'second'), ('whiz', 'third')))) .values('first', 'second', 'foo') ), [{'second': 'second', 'foo': 'first', 'first': 'first'}] )
self.assertEqual( list( TestObject.objects .extra(select=OrderedDict((('foo', 'first'), ('bar', 'second'), ('whiz', 'third')))) .values('foo', 'whiz') ), [{'foo': 'first', 'whiz': 'third'}] )
self.assertEqual( list( TestObject.objects .extra(select=OrderedDict((('foo', 'first'), ('bar', 'second'), ('whiz', 'third')))) .values_list() ), [('first', 'second', 'third', obj.pk, 'first', 'second', 'third')] )
self.assertEqual( list( TestObject.objects .values_list() .extra(select=OrderedDict((('foo', 'first'), ('bar', 'second'), ('whiz', 'third')))) ), [('first', 'second', 'third', obj.pk, 'first', 'second', 'third')] )
self.assertEqual( list( TestObject.objects .extra(select=OrderedDict((('foo', 'first'), ('bar', 'second'), ('whiz', 'third')))) .values_list('first', 'second') ), [('first', 'second')] )
self.assertEqual( list( TestObject.objects .values_list('first', 'second') .extra(select=OrderedDict((('foo', 'first'), ('bar', 'second'), ('whiz', 'third')))) ), [('first', 'second')] )
self.assertEqual( list( TestObject.objects .extra(select=OrderedDict((('foo', 'first'), ('bar', 'second'), ('whiz', 'third')))) .values_list('first', 'second', 'whiz') ), [('first', 'second', 'third')] )
self.assertEqual( list( TestObject.objects .extra(select=OrderedDict((('foo', 'first'), ('bar', 'second'), ('whiz', 'third')))) .values_list('foo', 'whiz') ), [('first', 'third')] )
self.assertEqual( list( TestObject.objects .extra(select=OrderedDict((('foo', 'first'), ('bar', 'second'), ('whiz', 'third')))) .values_list('whiz', 'foo') ), [('third', 'first')] )
t = TestObject(first='a', second='a', third='a') t.save() t = TestObject(first='b', second='a', third='a') t.save() t = TestObject(first='a', second='a', third='b') t.save() t = TestObject(first='b', second='a', third='b') t.save() t = TestObject(first='b', second='b', third='a') t.save() t = TestObject(first='a', second='b', third='b') t.save()
self.assertQuerysetEqual( qs.order_by('-second_extra').values_list('first', flat=True), ['a', 'a'], lambda x: x)
try: if sys.platform.startswith('java'): os.remove(re.sub(r'\.py$', '$py.class', full_name)) else: os.remove(full_name + 'c') except OSError: pass cache_name = os.path.join(self.test_dir, '__pycache__') if os.path.isdir(cache_name): shutil.rmtree(cache_name)
tests_dir = os.path.dirname(os.path.dirname(upath(__file__))) django_dir = os.path.dirname(tests_dir) ext_backend_base_dirs = self._ext_backend_paths()
test_environ = os.environ.copy() if sys.platform.startswith('java'): python_path_var_name = 'JYTHONPATH' else: python_path_var_name = 'PYTHONPATH'
if settings_file: test_environ['DJANGO_SETTINGS_MODULE'] = str(settings_file) elif 'DJANGO_SETTINGS_MODULE' in test_environ: del test_environ['DJANGO_SETTINGS_MODULE'] python_path = [base_dir, django_dir, tests_dir] python_path.extend(ext_backend_base_dirs) test_environ[str(python_path_var_name)] = npath(os.pathsep.join(python_path)) test_environ[str('PYTHONWARNINGS')] = str('')
os.chdir(self.test_dir) out, err = subprocess.Popen( [sys.executable, script] + args, stdout=subprocess.PIPE, stderr=subprocess.PIPE, env=test_environ, universal_newlines=True, ).communicate() os.chdir(old_cwd)
address_predefined = 'DJANGO_LIVE_TEST_SERVER_ADDRESS' in os.environ old_address = os.environ.get('DJANGO_LIVE_TEST_SERVER_ADDRESS')
self.assertEqual('DJANGO_LIVE_TEST_SERVER_ADDRESS' in os.environ, address_predefined) self.assertEqual(os.environ.get('DJANGO_LIVE_TEST_SERVER_ADDRESS'), old_address)
self.assertEqual(os.environ['DJANGO_LIVE_TEST_SERVER_ADDRESS'], 'blah')
if address_predefined: os.environ['DJANGO_LIVE_TEST_SERVER_ADDRESS'] = old_address else: del os.environ['DJANGO_LIVE_TEST_SERVER_ADDRESS']
call_command(self.cmd, addrport="beef:7654") self.assertServerSettings('beef', '7654')
call_command(self.cmd, addrport="deadbeef:7654") self.assertServerSettings('deadbeef', '7654')
self.assertIn("Not checking migrations", self.output.getvalue())
self.assertEqual(set(self.run_manage(args1)), set(self.run_manage(args2)))
style = color.make_style('') self.assertIn('Hello, world!', style.ERROR('Hello, world!')) self.assertNotEqual(style.ERROR('Hello, world!'), 'Hello, world!')
with self.assertRaises(TypeError): command.run_from_argv(['', ''])
command.execute = raise_command_error err.truncate(0) with self.assertRaises(SystemExit): command.run_from_argv(['', '']) err_message = err.getvalue() self.assertNotIn("Traceback", err_message) self.assertIn("CommandError", err_message)
err.truncate(0) with self.assertRaises(CommandError): command.run_from_argv(['', '', '--traceback'])
self.assertTrue(mock_connections.close_all.called)
out, err = self.run_django_admin(args) self.assertNoOutput(out) self.assertOutput(err, "already exists")
out, err = self.run_django_admin(args) self.assertNoOutput(out) self.assertOutput(err, "already exists")
self.write_settings('alternate_settings.py') self.addCleanup(self.remove_settings, 'alternate_settings.py') template_path = os.path.join(custom_templates_dir, 'project_template') args = [ 'custom_startproject', '--template', template_path, 'another_project', 'project_dir', '--extra', '<&>', '--settings=alternate_settings', ] testproject_dir = os.path.join(self.test_dir, 'project_dir') os.mkdir(testproject_dir) self.addCleanup(shutil.rmtree, testproject_dir) out, err = self.run_manage(args) self.assertNoOutput(err) test_manage_py = os.path.join(testproject_dir, 'additional_dir', 'extra.py') with open(test_manage_py, 'r') as fp: content = fp.read() self.assertIn("<&>", content)
from __future__ import unicode_literals
class UserProfile(models.Model): user = models.OneToOneField(User, models.CASCADE, primary_key=True)
from __future__ import unicode_literals
with self.assertNumQueries(0): self.assertEqual(obj.name, "first") self.assertEqual(obj.other_value, 0)
i = Item.objects.create(name="no I'm first", value=37) items = Item.objects.only("value").order_by("-value") self.assertEqual(items[0].name, "first") self.assertEqual(items[1].name, "no I'm first")
c1 = Child.objects.create(name="c1", value=42) c2 = Child.objects.create(name="c2", value=37) Leaf.objects.create(name="l1", child=c1, second_child=c2)
ctype = ContentType.objects.get_for_model c1 = ctype(Item.objects.all()[0]) c2 = ctype(Item.objects.defer("name")[0]) c3 = ctype(Item.objects.only("name")[0]) self.assertTrue(c1 is c2 is c3)
results = Leaf.objects.only("name", "child", "second_child").select_related() self.assertEqual(results[0].child.name, "c1") self.assertEqual(results[0].second_child.name, "c2")
self.assertIsInstance( list(SimpleItem.objects.annotate(Count('feature')).defer('name')), list) self.assertIsInstance( list(SimpleItem.objects.annotate(Count('feature')).only('name')), list)
SESSION_KEY = '2b1189a188b44ad18c35e1baac6ceead'
self.assertIsInstance( list(SimpleItem.objects.annotate(Count('feature')).defer('name')), list) self.assertIsInstance( list(SimpleItem.objects.annotate(Count('feature')).only('name')), list)
proxy = Proxy.objects.create(name="proxy", value=42)
msg = 'QuerySet.defer() return bogus results with proxy models' dp = Proxy.objects.defer('name', 'text', 'value').get(pk=proxy.pk) self.assertEqual(dp.name, proxy.name, msg=msg) self.assertEqual(dp.value, proxy.value, msg=msg)
item = Item.objects.create(name="first", value=42) o2o = OneToOneItem.objects.create(item=item, name="second") self.assertEqual(len(Item.objects.defer('one_to_one_item__name')), 1) self.assertEqual(len(Item.objects.select_related('one_to_one_item')), 1) self.assertEqual(len(Item.objects.select_related( 'one_to_one_item').defer('one_to_one_item__name')), 1) self.assertEqual(len(Item.objects.select_related('one_to_one_item').defer('value')), 1) self.assertEqual(len(Item.objects.only('one_to_one_item')), 1) with self.assertNumQueries(1): i = Item.objects.select_related('one_to_one_item')[0] self.assertEqual(i.one_to_one_item.pk, o2o.pk) self.assertEqual(i.one_to_one_item.name, "second") with self.assertNumQueries(1): i = Item.objects.select_related('one_to_one_item').defer( 'value', 'one_to_one_item__name')[0] self.assertEqual(i.one_to_one_item.pk, o2o.pk) self.assertEqual(i.name, "first") with self.assertNumQueries(1): self.assertEqual(i.one_to_one_item.name, "second") with self.assertNumQueries(1): self.assertEqual(i.value, 42)
item = Item.objects.create(name="first", value=47) RelatedItem.objects.create(item=item) obj = ProxyRelated.objects.all().select_related().only('item__name')[0] with self.assertNumQueries(0): self.assertEqual(obj.item.name, "first") with self.assertNumQueries(1): self.assertEqual(obj.item.value, 47)
item = SimpleItem.objects.create(name='first', value=47) feature = Feature.objects.create(item=item) SpecialFeature.objects.create(feature=feature)
specimens = models.Manager()
db_table = "Fixtures_regress_plant"
class Channel(models.Model): name = models.CharField(max_length=255)
class SpecialArticle(Article): pass
class CommonFeature(Article):
@python_2_unicode_compatible class Widget(models.Model): name = models.CharField(max_length=255)
class TestManager(models.Manager): def get_by_natural_key(self, key): return self.get(name=key)
def natural_key(self): return (self.name,) natural_key.dependencies = ['fixtures_regress.store']
class Circle1(models.Model): name = models.CharField(max_length=255)
class Thingy(models.Model): name = models.CharField(max_length=255)
natural_key.dependencies = ["fixtures_regress.M2MComplexCircular2A"]
from __future__ import unicode_literals
management.call_command( 'loaddata', 'sequence', verbosity=0, )
management.call_command( 'loaddata', 'pretty.xml', verbosity=0, ) self.assertEqual(Stuff.objects.all()[0].name, None) self.assertEqual(Stuff.objects.all()[0].owner, None)
management.call_command( 'loaddata', 'pretty.xml', verbosity=0, ) self.assertEqual(Stuff.objects.all()[0].name, '') self.assertEqual(Stuff.objects.all()[0].owner, None)
self.assertEqual( list(articles.values_list('id', flat=True)), [1, 2, 3, 4, 5, 6, 7, 8] )
data = out.getvalue()
data = re.sub('0{6,}[0-9]', '', data)
self.assertEqual(sorted_deps[-1], M2MThroughAB)
self.assertEqual(sorted_deps[:3], [A, B, C]) self.assertEqual(sorted_deps[3:], [AtoB, BtoC, CtoA])
relative_prefix = os.path.relpath(current_dir, os.getcwd()).replace('\\', '/') fixtures = [relative_prefix + '/fixtures/absolute.json']
from __future__ import absolute_import
template = self.engine.from_string('hello {{ foo }}!') content = template.render(context={'self': 'self', 'foo': 'world'}) self.assertEqual(content, 'hello world!')
engine = DjangoTemplates({ 'DIRS': [], 'APP_DIRS': False, 'NAME': 'django', 'OPTIONS': { 'context_processors': [test_processor_name], }, })
content = template.render({}, request) self.assertEqual(content, 'yes')
content = template.render({'processors': 'no'}, request) self.assertEqual(content, 'no')
self.assertEqual( engine.engine.libraries['good_tags'], 'template_backends.apps.good.templatetags.good_tags', ) self.assertEqual( engine.engine.libraries['subpackage.tags'], 'template_backends.apps.good.templatetags.subpackage.tags', ) self.assertEqual( engine.engine.libraries['static'], 'django.templatetags.static', ) self.assertEqual( engine.engine.libraries['alternate'], 'template_backends.apps.good.templatetags.good_tags', ) self.assertEqual( engine.engine.libraries['override'], 'template_backends.apps.good.templatetags.good_tags', )
if self.backend_name == 'dummy': self.skipTest("test doesn't apply to dummy backend") with self.assertRaises(TemplateSyntaxError): self.engine.get_template('template_backends/syntax_error.html')
'APP_DIRS': True, 'OPTIONS': {'loaders': []},
if fields is not None: fields = set(fields) deferred_fields = self.get_deferred_fields() if fields.intersection(deferred_fields): fields = fields.union(deferred_fields) super(RefreshPrimaryProxy, self).refresh_from_db(using, fields, **kwargs)
self.assert_delayed(qs.only("pk")[0], 3) self.assert_delayed(self.s1.primary_set.all().only('pk')[0], 2)
self.assertEqual(Primary.objects.defer("name").values()[0], { "id": self.p1.id, "name": "p1", "value": "xx", "related_id": self.s1.id, })
qs = Primary.objects.all() self.assert_delayed(qs.defer("name").get(pk=self.p1.pk), 1) self.assert_delayed(qs.only("name").get(pk=self.p1.pk), 2)
with self.assertNumQueries(1): obj = Primary.objects.defer("related").select_related()[0] self.assert_delayed(obj, 1) self.assertEqual(obj.related.id, self.s1.pk)
Primary.objects.create(name="p2", value="xy", related=self.s1) obj = Primary.objects.defer("value").get(name="p2") obj.name = "a new name" obj.save() self.assertQuerysetEqual( Primary.objects.all(), [ "p1", "a new name", ], lambda p: p.name, ordered=False, )
Child.objects.create(name="c1", value="foo", related=self.s1) obj = Child.objects.defer("value").get(name="c1") self.assert_delayed(obj, 1) self.assertEqual(obj.name, "c1") self.assertEqual(obj.value, "foo")
Child.objects.create(name="c1", value="foo", related=self.s1) obj = Child.objects.only("name").get(name="c1") self.assert_delayed(obj, 3) self.assertEqual(obj.name, "c1") self.assertEqual(obj.value, "foo")
obj = BigChild.objects.defer("value").get(name="b1") self.assert_delayed(obj, 1) self.assertEqual(obj.name, "b1") self.assertEqual(obj.value, "foo") self.assertEqual(obj.other, "bar")
obj = BigChild.objects.defer("other").get(name="b1") self.assert_delayed(obj, 1) self.assertEqual(obj.name, "b1") self.assertEqual(obj.value, "foo") self.assertEqual(obj.other, "bar")
obj = BigChild.objects.only("name").get(name="b1") self.assert_delayed(obj, 4) self.assertEqual(obj.name, "b1") self.assertEqual(obj.value, "foo") self.assertEqual(obj.other, "bar")
obj = BigChild.objects.only("other").get(name="b1") self.assert_delayed(obj, 4) self.assertEqual(obj.name, "b1") self.assertEqual(obj.value, "foo") self.assertEqual(obj.other, "bar")
self.assertEqual(rf2.name, 'new foo') self.assertEqual(rf2.value, 'new bar')
with transaction.atomic(): self.do(1) try: with transaction.atomic(): self.do(2) raise ForcedError() except ForcedError: pass with transaction.atomic(): self.do(3)
self.assertDone([1, 3])
((ten, 4, 0, False), (10, 3, [1, 2, 3])), ((ten, 4, 1, False), (10, 3, [1, 2, 3])), ((ten, 4, 2, False), (10, 2, [1, 2])), ((ten, 4, 5, False), (10, 2, [1, 2])), ((ten, 4, 6, False), (10, 1, [1])), ((ten, 4, 0, True), (10, 3, [1, 2, 3])), ((ten, 4, 1, True), (10, 3, [1, 2, 3])), ((ten, 4, 2, True), (10, 2, [1, 2])), ((ten, 4, 5, True), (10, 2, [1, 2])), ((ten, 4, 6, True), (10, 1, [1])), (([1], 4, 0, False), (1, 1, [1])), (([1], 4, 1, False), (1, 1, [1])), (([1], 4, 2, False), (1, 1, [1])), (([1], 4, 0, True), (1, 1, [1])), (([1], 4, 1, True), (1, 1, [1])), (([1], 4, 2, True), (1, 1, [1])), (([], 4, 0, False), (0, 0, [])), (([], 4, 1, False), (0, 0, [])), (([], 4, 2, False), (0, 0, [])), (([], 4, 0, True), (0, 1, [1])), (([], 4, 1, True), (0, 1, [1])), (([], 4, 2, True), (0, 1, [1])), (([], 1, 0, True), (0, 1, [1])), (([], 1, 0, False), (0, 0, [])), (([1], 2, 0, True), (1, 1, [1])), ((nine, 10, 0, True), (9, 1, [1])), (([1], 1, 0, True), (1, 1, [1])), (([1, 2], 2, 0, True), (2, 1, [1])), ((ten, 10, 0, True), (10, 1, [1])), (([1, 2], 1, 0, True), (2, 2, [1, 2])), (([1, 2, 3], 2, 0, True), (3, 2, [1, 2])), ((eleven, 10, 0, True), (11, 2, [1, 2])), (([1, 2], 1, 1, True), (2, 1, [1])), (([1, 2, 3], 2, 1, True), (3, 1, [1])), ((eleven, 10, 1, True), (11, 1, [1])), ((ten, '4', 1, False), (10, 3, [1, 2, 3])), ((ten, '4', 1, False), (10, 3, [1, 2, 3])), ((ten, 4, '1', False), (10, 3, [1, 2, 3])), ((ten, 4, '1', False), (10, 3, [1, 2, 3])),
paginator = Paginator([], 2) self.assertEqual(paginator.validate_number(1), 1)
paginator = Paginator(CountContainer(), 10) self.assertEqual(42, paginator.count) self.assertEqual(5, paginator.num_pages) self.assertEqual([1, 2, 3, 4, 5], list(paginator.page_range))
class LenContainer(object): def __len__(self): return 42 paginator = Paginator(LenContainer(), 10) self.assertEqual(42, paginator.count) self.assertEqual(5, paginator.num_pages) self.assertEqual([1, 2, 3, 4, 5], list(paginator.page_range))
((ten, 1, 0, True), (1, 1), (10, 10)), ((ten, 2, 0, True), (1, 2), (9, 10)), ((ten, 3, 0, True), (1, 3), (10, 10)), ((ten, 5, 0, True), (1, 5), (6, 10)), ((ten, 1, 1, True), (1, 1), (9, 10)), ((ten, 1, 2, True), (1, 1), (8, 10)), ((ten, 3, 1, True), (1, 3), (7, 10)), ((ten, 3, 2, True), (1, 3), (7, 10)), ((ten, 3, 4, True), (1, 3), (4, 10)), ((ten, 5, 1, True), (1, 5), (6, 10)), ((ten, 5, 2, True), (1, 5), (6, 10)), ((ten, 5, 5, True), (1, 10), (1, 10)), (([1], 4, 0, False), (1, 1), (1, 1)), (([1], 4, 1, False), (1, 1), (1, 1)), (([1], 4, 2, False), (1, 1), (1, 1)), (([1], 4, 0, True), (1, 1), (1, 1)), (([1], 4, 1, True), (1, 1), (1, 1)), (([1], 4, 2, True), (1, 1), (1, 1)), (([], 4, 0, True), (0, 0), (0, 0)), (([], 4, 1, True), (0, 0), (0, 0)), (([], 4, 2, True), (0, 0), (0, 0)),
with self.assertRaises(EmptyPage): self.check_indexes(([], 4, 0, False), 1, None) with self.assertRaises(EmptyPage): self.check_indexes(([], 4, 1, False), 1, None) with self.assertRaises(EmptyPage): self.check_indexes(([], 4, 2, False), 1, None)
for x in range(1, 10): a = Article(headline='Article %s' % x, pub_date=datetime(2005, 7, 29)) a.save()
self.assertIsNone(p.object_list._result_cache) with self.assertRaises(TypeError): p['has_previous'] self.assertIsNone(p.object_list._result_cache) self.assertNotIsInstance(p.object_list, list)
self.assertEqual(p[0], Article.objects.get(headline='Article 1')) self.assertQuerysetEqual(p[slice(2)], [ "<Article: Article 1>", "<Article: Article 2>", ] ) self.assertIsInstance(p.object_list, list)
models.signals.m2m_changed.disconnect( self.m2m_changed_signal_receiver, Car.default_parts.through ) models.signals.m2m_changed.disconnect( self.m2m_changed_signal_receiver, Car.optional_parts.through ) models.signals.m2m_changed.disconnect( self.m2m_changed_signal_receiver, Person.fans.through ) models.signals.m2m_changed.disconnect( self.m2m_changed_signal_receiver, Person.friends.through )
self.vw.default_parts.add(self.sunroof)
self.doors.car_set.add(self.bmw, self.toyota) expected_messages.append({ 'instance': self.doors, 'action': 'pre_add', 'reverse': True, 'model': Car, 'objects': [self.bmw, self.toyota], }) expected_messages.append({ 'instance': self.doors, 'action': 'post_add', 'reverse': True, 'model': Car, 'objects': [self.bmw, self.toyota], }) self.assertEqual(self.m2m_changed_messages, expected_messages)
self.vw.default_parts.remove(self.engine, self.airbag) self.assertEqual(self.m2m_changed_messages, [ { 'instance': self.vw, 'action': 'pre_remove', 'reverse': False, 'model': Part, 'objects': [self.airbag, self.engine], }, { 'instance': self.vw, 'action': 'post_remove', 'reverse': False, 'model': Part, 'objects': [self.airbag, self.engine], } ])
self.vw.optional_parts.add(self.airbag, self.sunroof) expected_messages.append({ 'instance': self.vw, 'action': 'pre_add', 'reverse': False, 'model': Part, 'objects': [self.airbag, self.sunroof], }) expected_messages.append({ 'instance': self.vw, 'action': 'post_add', 'reverse': False, 'model': Part, 'objects': [self.airbag, self.sunroof], }) self.assertEqual(self.m2m_changed_messages, expected_messages)
self.airbag.cars_optional.add(self.vw, self.bmw, self.toyota) expected_messages.append({ 'instance': self.airbag, 'action': 'pre_add', 'reverse': True, 'model': Car, 'objects': [self.bmw, self.toyota], }) expected_messages.append({ 'instance': self.airbag, 'action': 'post_add', 'reverse': True, 'model': Car, 'objects': [self.bmw, self.toyota], }) self.assertEqual(self.m2m_changed_messages, expected_messages)
self.airbag.cars_optional.remove(self.vw) self.assertEqual(self.m2m_changed_messages, [ { 'instance': self.airbag, 'action': 'pre_remove', 'reverse': True, 'model': Car, 'objects': [self.vw], }, { 'instance': self.airbag, 'action': 'post_remove', 'reverse': True, 'model': Car, 'objects': [self.vw], } ])
self.vw.default_parts.clear() self.assertEqual(self.m2m_changed_messages, [ { 'instance': self.vw, 'action': 'pre_clear', 'reverse': False, 'model': Part, }, { 'instance': self.vw, 'action': 'post_clear', 'reverse': False, 'model': Part, } ])
self.doors.car_set.clear() self.assertEqual(self.m2m_changed_messages, [ { 'instance': self.doors, 'action': 'pre_clear', 'reverse': True, 'model': Car, }, { 'instance': self.doors, 'action': 'post_clear', 'reverse': True, 'model': Car, } ])
self.airbag.cars_optional.clear() self.assertEqual(self.m2m_changed_messages, [ { 'instance': self.airbag, 'action': 'pre_clear', 'reverse': True, 'model': Car, }, { 'instance': self.airbag, 'action': 'post_clear', 'reverse': True, 'model': Car, } ])
self.vw.default_parts.create(name='Windows') p6 = Part.objects.get(name='Windows') expected_messages.append({ 'instance': self.vw, 'action': 'pre_add', 'reverse': False, 'model': Part, 'objects': [p6], }) expected_messages.append({ 'instance': self.vw, 'action': 'post_add', 'reverse': False, 'model': Part, 'objects': [p6], }) self.assertEqual(self.m2m_changed_messages, expected_messages)
self.vw.default_parts.set([self.wheelset, self.doors, self.engine]) expected_messages.append({ 'instance': self.vw, 'action': 'pre_remove', 'reverse': False, 'model': Part, 'objects': [p6], }) expected_messages.append({ 'instance': self.vw, 'action': 'post_remove', 'reverse': False, 'model': Part, 'objects': [p6], }) expected_messages.append({ 'instance': self.vw, 'action': 'pre_add', 'reverse': False, 'model': Part, 'objects': [self.doors, self.engine, self.wheelset], }) expected_messages.append({ 'instance': self.vw, 'action': 'post_add', 'reverse': False, 'model': Part, 'objects': [self.doors, self.engine, self.wheelset], }) self.assertEqual(self.m2m_changed_messages, expected_messages)
self.vw.default_parts.set([self.wheelset, self.doors, self.engine], clear=True) expected_messages.append({ 'instance': self.vw, 'action': 'pre_clear', 'reverse': False, 'model': Part, }) expected_messages.append({ 'instance': self.vw, 'action': 'post_clear', 'reverse': False, 'model': Part, }) expected_messages.append({ 'instance': self.vw, 'action': 'pre_add', 'reverse': False, 'model': Part, 'objects': [self.doors, self.engine, self.wheelset], }) expected_messages.append({ 'instance': self.vw, 'action': 'post_add', 'reverse': False, 'model': Part, 'objects': [self.doors, self.engine, self.wheelset], }) self.assertEqual(self.m2m_changed_messages, expected_messages)
self.vw.default_parts.set([self.wheelset, self.doors], clear=False) expected_messages.append({ 'instance': self.vw, 'action': 'pre_remove', 'reverse': False, 'model': Part, 'objects': [self.engine], }) expected_messages.append({ 'instance': self.vw, 'action': 'post_remove', 'reverse': False, 'model': Part, 'objects': [self.engine], }) self.assertEqual(self.m2m_changed_messages, expected_messages)
c4 = SportsCar.objects.create(name='Bugatti', price='1000000') c4b = Car.objects.get(name='Bugatti') c4.default_parts.set([self.doors]) expected_messages.append({ 'instance': c4, 'action': 'pre_add', 'reverse': False, 'model': Part, 'objects': [self.doors], }) expected_messages.append({ 'instance': c4, 'action': 'post_add', 'reverse': False, 'model': Part, 'objects': [self.doors], }) self.assertEqual(self.m2m_changed_messages, expected_messages)
models.signals.m2m_changed.connect( self.m2m_changed_signal_receiver, Person.fans.through ) models.signals.m2m_changed.connect( self.m2m_changed_signal_receiver, Person.friends.through )
@python_2_unicode_compatible class Membership(models.Model): person = models.ForeignKey('Person', models.CASCADE) group = models.ForeignKey('Group', models.CASCADE) price = models.IntegerField(default=100)
@python_2_unicode_compatible class UserMembership(models.Model): id = models.AutoField(db_column='usermembership_id', primary_key=True) user = models.ForeignKey(User, models.CASCADE) group = models.ForeignKey('Group', models.CASCADE) price = models.IntegerField(default=100)
members = models.ManyToManyField(Person, through=Membership) user_members = models.ManyToManyField(User, through='UserMembership')
class A(models.Model): a_text = models.CharField(max_length=20)
@python_2_unicode_compatible class Car(models.Model): make = models.CharField(max_length=20, unique=True, null=True) drivers = models.ManyToManyField('Driver', through='CarDriver')
cls.bob_rock = Membership.objects.create(person=cls.bob, group=cls.rock) cls.bob_roll = Membership.objects.create(person=cls.bob, group=cls.roll, price=50) cls.jim_rock = Membership.objects.create(person=cls.jim, group=cls.rock, price=50)
cls.frank_rock = UserMembership.objects.create(user=cls.frank, group=cls.rock) cls.frank_roll = UserMembership.objects.create(user=cls.frank, group=cls.roll) cls.jane_rock = UserMembership.objects.create(user=cls.jane, group=cls.rock)
self.unused_driver = Driver.objects.create(name="Barney Gumble") self.unused_car1 = Car.objects.create(make="Trabant") self.unused_car2 = Car.objects.create(make="Wartburg")
def test_add(self): self.assertQuerysetEqual( self.car.drivers.all(), ["<Driver: Ryan Briscoe>"] ) self.car.drivers._add_items('car', 'driver', self.unused_driver) self.assertQuerysetEqual( self.car.drivers.all(), ["<Driver: Barney Gumble>", "<Driver: Ryan Briscoe>"] )
no = models.IntegerField(verbose_name='number', blank=True, null=True)
self.alfred = User.objects.create_user('alfred', 'alfred@example.com') self.bob = User.objects.create_user('bob', 'bob@example.com') self.lisa = User.objects.create_user('lisa', 'lisa@example.com')
self.djangonaut_book = Book.objects.create( title='Djangonaut: an art of living', year=2009, author=self.alfred, is_best_seller=True, date_registered=self.today, ) self.bio_book = Book.objects.create( title='Django: a biography', year=1999, author=self.alfred, is_best_seller=False, no=207, ) self.django_book = Book.objects.create( title='The Django Book', year=None, author=self.bob, is_best_seller=None, date_registered=self.today, no=103, ) self.guitar_book = Book.objects.create( title='Guitar for dummies', year=2002, is_best_seller=True, date_registered=self.one_week_ago, ) self.guitar_book.contributors.set([self.bob, self.lisa])
self.dev = Department.objects.create(code='DEV', description='Development') self.design = Department.objects.create(code='DSN', description='Design')
self.john = Employee.objects.create(name='John Blue', department=self.dev) self.jack = Employee.objects.create(name='Jack Red', department=self.design)
queryset = changelist.get_queryset(request) self.assertEqual(list(queryset), [self.django_book, self.djangonaut_book])
filterspec = changelist.get_filters(request)[0][4] self.assertEqual(force_text(filterspec.title), 'date registered') choice = select_by(filterspec.choices(changelist), "display", "Today") self.assertEqual(choice['selected'], True) self.assertEqual( choice['query_string'], '?date_registered__gte=%s&date_registered__lt=%s' % ( self.today, self.tomorrow, ) )
queryset = changelist.get_queryset(request) if (self.today.year, self.today.month) == (self.one_week_ago.year, self.one_week_ago.month): self.assertEqual(list(queryset), [self.guitar_book, self.django_book, self.djangonaut_book]) else: self.assertEqual(list(queryset), [self.django_book, self.djangonaut_book])
filterspec = changelist.get_filters(request)[0][4] self.assertEqual(force_text(filterspec.title), 'date registered') choice = select_by(filterspec.choices(changelist), "display", "This month") self.assertEqual(choice['selected'], True) self.assertEqual( choice['query_string'], '?date_registered__gte=%s&date_registered__lt=%s' % ( self.today.replace(day=1), self.next_month, ) )
queryset = changelist.get_queryset(request) if self.today.year == self.one_week_ago.year: self.assertEqual(list(queryset), [self.guitar_book, self.django_book, self.djangonaut_book]) else: self.assertEqual(list(queryset), [self.django_book, self.djangonaut_book])
filterspec = changelist.get_filters(request)[0][4] self.assertEqual(force_text(filterspec.title), 'date registered') choice = select_by(filterspec.choices(changelist), "display", "This year") self.assertEqual(choice['selected'], True) self.assertEqual( choice['query_string'], '?date_registered__gte=%s&date_registered__lt=%s' % ( self.today.replace(month=1, day=1), self.next_year, ) )
queryset = changelist.get_queryset(request) self.assertEqual(list(queryset), [self.guitar_book, self.django_book, self.djangonaut_book])
filterspec = changelist.get_filters(request)[0][4] self.assertEqual(force_text(filterspec.title), 'date registered') choice = select_by(filterspec.choices(changelist), "display", "Past 7 days") self.assertEqual(choice['selected'], True) self.assertEqual( choice['query_string'], '?date_registered__gte=%s&date_registered__lt=%s' % ( str(self.one_week_ago), str(self.tomorrow), ) )
request = self.request_factory.get('/', {'date_registered__isnull': 'True'}) changelist = self.get_changelist(request, Book, modeladmin)
queryset = changelist.get_queryset(request) self.assertEqual(queryset.count(), 1) self.assertEqual(queryset[0], self.bio_book)
filterspec = changelist.get_filters(request)[0][4] self.assertEqual(force_text(filterspec.title), 'date registered') choice = select_by(filterspec.choices(changelist), 'display', 'No date') self.assertEqual(choice['selected'], True) self.assertEqual(choice['query_string'], '?date_registered__isnull=True')
queryset = changelist.get_queryset(request) self.assertEqual(queryset.count(), 3) self.assertEqual(list(queryset), [self.guitar_book, self.django_book, self.djangonaut_book])
filterspec = changelist.get_filters(request)[0][4] self.assertEqual(force_text(filterspec.title), 'date registered') choice = select_by(filterspec.choices(changelist), 'display', 'Has date') self.assertEqual(choice['selected'], True) self.assertEqual(choice['query_string'], '?date_registered__isnull=False')
self.test_datefieldlistfilter()
queryset = changelist.get_queryset(request) self.assertEqual(list(queryset), [self.django_book])
filterspec = changelist.get_filters(request)[0][0] self.assertEqual(force_text(filterspec.title), 'year') choices = list(filterspec.choices(changelist)) self.assertEqual(choices[-1]['selected'], True) self.assertEqual(choices[-1]['query_string'], '?year__isnull=True')
filterspec = changelist.get_filters(request)[0][0] self.assertEqual(force_text(filterspec.title), 'year') choices = list(filterspec.choices(changelist)) self.assertEqual(choices[2]['selected'], True) self.assertEqual(choices[2]['query_string'], '?year=2002')
modeladmin = BookAdminWithCustomQueryset(self.alfred, Book, site) request = self.request_factory.get('/') changelist = self.get_changelist(request, Book, modeladmin)
self.assertEqual(3, len(choices)) self.assertEqual(choices[0]['query_string'], '?') self.assertEqual(choices[1]['query_string'], '?year=1999') self.assertEqual(choices[2]['query_string'], '?year=2009')
filterspec = changelist.get_filters(request)[0][1] expected = [(self.alfred.pk, 'alfred'), (self.bob.pk, 'bob'), (self.lisa.pk, 'lisa')] self.assertEqual(sorted(filterspec.lookup_choices), sorted(expected))
queryset = changelist.get_queryset(request) self.assertEqual(list(queryset), [self.guitar_book])
filterspec = changelist.get_filters(request)[0][1] self.assertEqual(force_text(filterspec.title), 'Verbose Author') choices = list(filterspec.choices(changelist)) self.assertEqual(choices[-1]['selected'], True) self.assertEqual(choices[-1]['query_string'], '?author__isnull=True')
filterspec = changelist.get_filters(request)[0][1] self.assertEqual(force_text(filterspec.title), 'Verbose Author') choice = select_by(filterspec.choices(changelist), "display", "alfred") self.assertEqual(choice['selected'], True) self.assertEqual(choice['query_string'], '?author__id__exact=%d' % self.alfred.pk)
filterspec = changelist.get_filters(request)[0][2] expected = [(self.alfred.pk, 'alfred'), (self.bob.pk, 'bob'), (self.lisa.pk, 'lisa')] self.assertEqual(sorted(filterspec.lookup_choices), sorted(expected))
queryset = changelist.get_queryset(request) self.assertEqual(list(queryset), [self.django_book, self.bio_book, self.djangonaut_book])
filterspec = changelist.get_filters(request)[0][2] self.assertEqual(force_text(filterspec.title), 'Verbose Contributors') choices = list(filterspec.choices(changelist)) self.assertEqual(choices[-1]['selected'], True) self.assertEqual(choices[-1]['query_string'], '?contributors__isnull=True')
filterspec = changelist.get_filters(request)[0][2] self.assertEqual(force_text(filterspec.title), 'Verbose Contributors') choice = select_by(filterspec.choices(changelist), "display", "bob") self.assertEqual(choice['selected'], True) self.assertEqual(choice['query_string'], '?contributors__id__exact=%d' % self.bob.pk)
request = self.request_factory.get('/', {'books_authored__isnull': 'True'}) changelist = self.get_changelist(request, User, modeladmin)
queryset = changelist.get_queryset(request) self.assertEqual(list(queryset), [self.lisa])
filterspec = changelist.get_filters(request)[0][0] self.assertEqual(force_text(filterspec.title), 'book') choices = list(filterspec.choices(changelist)) self.assertEqual(choices[-1]['selected'], True) self.assertEqual(choices[-1]['query_string'], '?books_authored__isnull=True')
filterspec = changelist.get_filters(request)[0][0] self.assertEqual(force_text(filterspec.title), 'book') choice = select_by(filterspec.choices(changelist), "display", self.bio_book.title) self.assertEqual(choice['selected'], True) self.assertEqual(choice['query_string'], '?books_authored__id__exact=%d' % self.bio_book.pk)
request = self.request_factory.get('/', {'books_contributed__isnull': 'True'}) changelist = self.get_changelist(request, User, modeladmin)
queryset = changelist.get_queryset(request) self.assertEqual(list(queryset), [self.alfred])
filterspec = changelist.get_filters(request)[0][1] self.assertEqual(force_text(filterspec.title), 'book') choices = list(filterspec.choices(changelist)) self.assertEqual(choices[-1]['selected'], True) self.assertEqual(choices[-1]['query_string'], '?books_contributed__isnull=True')
filterspec = changelist.get_filters(request)[0][1] self.assertEqual(force_text(filterspec.title), 'book') choice = select_by(filterspec.choices(changelist), "display", self.django_book.title) self.assertEqual(choice['selected'], True) self.assertEqual(choice['query_string'], '?books_contributed__id__exact=%d' % self.django_book.pk)
Book.objects.exclude(pk=self.djangonaut_book.pk).delete() filterspec = changelist.get_filters(request)[0] self.assertEqual(len(filterspec), 2) Book.objects.all().delete() filterspec = changelist.get_filters(request)[0] self.assertEqual(len(filterspec), 0)
filterspec = changelist.get_filters(request)[0][4] expected = [(self.alfred.pk, 'alfred'), (self.bob.pk, 'bob')] self.assertEqual(sorted(filterspec.lookup_choices), sorted(expected))
filterspec = changelist.get_filters(request)[0][6] expected = [ (self.dev.code, str(self.dev)), (self.design.code, str(self.design)), ] self.assertEqual(sorted(filterspec.lookup_choices), sorted(expected))
filterspec = changelist.get_filters(request)[0][5] expected = [(self.bob.pk, 'bob'), (self.lisa.pk, 'lisa')] self.assertEqual(sorted(filterspec.lookup_choices), sorted(expected))
queryset = changelist.get_queryset(request) self.assertEqual(list(queryset), [self.bio_book])
filterspec = changelist.get_filters(request)[0][3] self.assertEqual(force_text(filterspec.title), 'is best seller') choice = select_by(filterspec.choices(changelist), "display", "No") self.assertEqual(choice['selected'], True) self.assertEqual(choice['query_string'], '?is_best_seller__exact=0')
queryset = changelist.get_queryset(request) self.assertEqual(list(queryset), [self.guitar_book, self.djangonaut_book])
filterspec = changelist.get_filters(request)[0][3] self.assertEqual(force_text(filterspec.title), 'is best seller') choice = select_by(filterspec.choices(changelist), "display", "Yes") self.assertEqual(choice['selected'], True) self.assertEqual(choice['query_string'], '?is_best_seller__exact=1')
queryset = changelist.get_queryset(request) self.assertEqual(list(queryset), [self.django_book])
filterspec = changelist.get_filters(request)[0][3] self.assertEqual(force_text(filterspec.title), 'is best seller') choice = select_by(filterspec.choices(changelist), "display", "Unknown") self.assertEqual(choice['selected'], True) self.assertEqual(choice['query_string'], '?is_best_seller__isnull=True')
queryset = changelist.get_queryset(request) self.assertEqual(list(queryset), [self.bio_book, self.djangonaut_book])
request = self.request_factory.get('/', {}) changelist = self.get_changelist(request, Book, modeladmin)
queryset = changelist.get_queryset(request) self.assertEqual(list(queryset), list(Book.objects.all().order_by('-id')))
filterspec = changelist.get_filters(request)[0][1] self.assertEqual(force_text(filterspec.title), 'publication decade') choices = list(filterspec.choices(changelist)) self.assertEqual(choices[0]['display'], 'All') self.assertEqual(choices[0]['selected'], True) self.assertEqual(choices[0]['query_string'], '?')
request = self.request_factory.get('/', {'publication-decade': 'the 80s'}) changelist = self.get_changelist(request, Book, modeladmin)
queryset = changelist.get_queryset(request) self.assertEqual(list(queryset), [])
filterspec = changelist.get_filters(request)[0][1] self.assertEqual(force_text(filterspec.title), 'publication decade') choices = list(filterspec.choices(changelist)) self.assertEqual(choices[1]['display'], 'the 1980\'s') self.assertEqual(choices[1]['selected'], True) self.assertEqual(choices[1]['query_string'], '?publication-decade=the+80s')
request = self.request_factory.get('/', {'publication-decade': 'the 90s'}) changelist = self.get_changelist(request, Book, modeladmin)
queryset = changelist.get_queryset(request) self.assertEqual(list(queryset), [self.bio_book])
filterspec = changelist.get_filters(request)[0][1] self.assertEqual(force_text(filterspec.title), 'publication decade') choices = list(filterspec.choices(changelist)) self.assertEqual(choices[2]['display'], 'the 1990\'s') self.assertEqual(choices[2]['selected'], True) self.assertEqual(choices[2]['query_string'], '?publication-decade=the+90s')
request = self.request_factory.get('/', {'publication-decade': 'the 00s'}) changelist = self.get_changelist(request, Book, modeladmin)
queryset = changelist.get_queryset(request) self.assertEqual(list(queryset), [self.guitar_book, self.djangonaut_book])
filterspec = changelist.get_filters(request)[0][1] self.assertEqual(force_text(filterspec.title), 'publication decade') choices = list(filterspec.choices(changelist)) self.assertEqual(choices[3]['display'], 'the 2000\'s') self.assertEqual(choices[3]['selected'], True) self.assertEqual(choices[3]['query_string'], '?publication-decade=the+00s')
request = self.request_factory.get('/', {'publication-decade': 'the 00s', 'author__id__exact': self.alfred.pk}) changelist = self.get_changelist(request, Book, modeladmin)
queryset = changelist.get_queryset(request) self.assertEqual(list(queryset), [self.djangonaut_book])
filterspec = changelist.get_filters(request)[0][1] self.assertEqual(force_text(filterspec.title), 'publication decade') choices = list(filterspec.choices(changelist)) self.assertEqual(choices[3]['display'], 'the 2000\'s') self.assertEqual(choices[3]['selected'], True) self.assertEqual( choices[3]['query_string'], '?author__id__exact=%s&publication-decade=the+00s' % self.alfred.pk )
queryset = changelist.get_queryset(request) self.assertEqual(list(queryset), [self.bio_book])
modeladmin = DecadeFilterBookAdminParameterEndsWith__In(Book, site) request = self.request_factory.get('/', {'decade__in': 'the 90s'}) changelist = self.get_changelist(request, Book, modeladmin)
queryset = changelist.get_queryset(request) self.assertEqual(list(queryset), [self.bio_book])
filterspec = changelist.get_filters(request)[0][0] self.assertEqual(force_text(filterspec.title), 'publication decade') choices = list(filterspec.choices(changelist)) self.assertEqual(choices[2]['display'], 'the 1990\'s') self.assertEqual(choices[2]['selected'], True) self.assertEqual(choices[2]['query_string'], '?decade__in=the+90s')
modeladmin = DecadeFilterBookAdminParameterEndsWith__Isnull(Book, site) request = self.request_factory.get('/', {'decade__isnull': 'the 90s'}) changelist = self.get_changelist(request, Book, modeladmin)
queryset = changelist.get_queryset(request) self.assertEqual(list(queryset), [self.bio_book])
filterspec = changelist.get_filters(request)[0][0] self.assertEqual(force_text(filterspec.title), 'publication decade') choices = list(filterspec.choices(changelist)) self.assertEqual(choices[2]['display'], 'the 1990\'s') self.assertEqual(choices[2]['selected'], True) self.assertEqual(choices[2]['query_string'], '?decade__isnull=the+90s')
queryset = changelist.get_queryset(request) self.assertEqual(list(queryset), [self.jack, self.john])
queryset = changelist.get_queryset(request) self.assertEqual(list(queryset), [self.john])
from django.conf.urls import url
url = reverse('admin_custom_urls:%s_action_change' % Action._meta.app_label, args=(quote('add'),)) response = self.client.get(url) self.assertContains(response, 'Change action')
url = reverse( 'admin_custom_urls:%s_action_change' % Action._meta.app_label, args=(quote("path/to/html/document.html"),) ) response = self.client.get(url) self.assertContains(response, 'Change action') self.assertContains(response, 'value="path/to/html/document.html"')
self.a.friends.add(self.b, self.c)
self.d.friends.add(self.a, self.c)
self.assertQuerysetEqual( self.a.friends.all(), [ "Bill", "Chuck", "David" ], attrgetter("name"), ordered=False ) self.assertQuerysetEqual( self.b.friends.all(), [ "Anne", ], attrgetter("name") ) self.assertQuerysetEqual( self.c.friends.all(), [ "Anne", "David" ], attrgetter("name"), ordered=False ) self.assertQuerysetEqual( self.d.friends.all(), [ "Anne", "Chuck", ], attrgetter("name"), ordered=False )
self.b.friends.add(self.a)
self.assertQuerysetEqual( self.a.friends.all(), [ "Bill", "Chuck", "David", ], attrgetter("name"), ordered=False ) self.assertQuerysetEqual( self.b.friends.all(), [ "Anne", ], attrgetter("name") )
self.b.friends.remove(self.a)
self.assertQuerysetEqual( self.a.friends.all(), [ "Chuck", "David", ], attrgetter("name"), ordered=False ) self.assertQuerysetEqual( self.b.friends.all(), [] )
self.a.friends.clear()
self.assertQuerysetEqual( self.a.friends.all(), [] )
self.assertQuerysetEqual( self.c.friends.all(), [ "David", ], attrgetter("name") )
self.assertQuerysetEqual( self.d.friends.all(), [ "Chuck", ], attrgetter("name") )
self.d.stalkers.add(self.a)
self.assertQuerysetEqual( self.a.idols.all(), [ "David", ], attrgetter("name"), ordered=False ) self.assertQuerysetEqual( self.a.stalkers.all(), [], attrgetter("name") )
self.a.idols.add(self.d)
self.d.stalkers.add(self.a)
self.assertQuerysetEqual( self.a.idols.all(), [ "David", ], attrgetter("name"), ordered=False ) self.assertEqual(self.a.idols.all().count(), 1)
self.a.idols.add(self.a)
self.assertQuerysetEqual( self.a.idols.all(), [ "Anne", ], attrgetter("name"), ordered=False ) self.assertQuerysetEqual( self.a.stalkers.all(), [ "Anne", ], attrgetter("name") )
with self.assertRaises(AttributeError): setattr(self.a, 'full_name', 'Paul McCartney')
with self.assertRaisesMessage(TypeError, "'full_name' is an invalid keyword argument"): Person(full_name='Paul McCartney')
a2 = Person(full_name_2='Paul McCartney') a2.save() self.assertEqual(a2.first_name, 'Paul')
number2 = models.IntegerField(blank=True, default=Numbers.get_static_number)
class SomeModel(models.Model): somefield = models.IntegerField()
original = Event.DoesNotExist("Doesn't exist") unpickled = pickle.loads(pickle.dumps(original))
self.assertEqual(original.__class__, unpickled.__class__) self.assertEqual(original.args, unpickled.args)
Container.SomeModel.objects.create(somefield=1) original = Container.SomeModel.objects.defer('somefield')[0] dumped = pickle.dumps(original) reloaded = pickle.loads(dumped) self.assertEqual(original, reloaded) self.assertEqual(original.somefield, reloaded.somefield)
self.assert_pickles( Event.objects.select_related('group').order_by('title').values_list('title', 'group__name') )
groups = pickle.loads(pickle.dumps(groups)) self.assertQuerysetEqual(groups, [g], lambda x: x)
groups = pickle.loads(pickle.dumps(groups)) self.assertQuerysetEqual(groups, [g], lambda x: x)
qs = Happening.objects.annotate(latest_time=models.Max('when')) self.assert_pickles(qs)
dummy1 = _("This is a translatable string.")
dummy2 = _("This is another translatable string.")
number = 3 dummy3 = ungettext("%(number)s Foo", "%(number)s Foos", number) % {'number': number}
dummy5 = _('This literal should be included.')
from __future__ import unicode_literals
for key, value in settings.items(): _format_cache[(key, lang)] = value try: yield finally: reset_format_cache()
s1 = ugettext_lazy('Add %(name)s') self.assertEqual(s, s1) s2 = gettext_lazy('Add %(name)s') s3 = gettext_lazy('Add %(name)s') self.assertEqual(s2, s3) self.assertEqual(s, s2) s4 = ugettext_lazy('Some other string') self.assertNotEqual(s, s4)
self.assertEqual(repr(gettext(b"Time")), repr(b"Time")) self.assertEqual(repr(gettext("Time")), repr("Time"))
self.assertEqual(gettext_lazy(b"test").upper(), b"TEST") self.assertEqual((ngettext_lazy(b"%d test", b"%d tests") % 1).upper(), b"1 TEST")
self.assertEqual(ugettext_lazy(b"test").upper(), "TEST") self.assertEqual((ungettext_lazy(b"%d test", b"%d tests") % 1).upper(), "1 TEST") self.assertEqual(pgettext_lazy(b"context", b"test").upper(), "TEST") self.assertEqual( (npgettext_lazy(b"context", b"%d test", b"%d tests") % 1).upper(), "1 TEST" )
result = ungettext_lazy( '%(name)s has %(num)d good result', '%(name)s has %(num)d good results',
t = Template('{% load i18n %}{% trans "May" context "unexisting" %}') rendered = t.render(Context()) self.assertEqual(rendered, 'May')
t = Template('{% load i18n %}{% trans "May" context "month name" %}') rendered = t.render(Context()) self.assertEqual(rendered, 'Mai') t = Template('{% load i18n %}{% trans "May" context "verb" %}') rendered = t.render(Context()) self.assertEqual(rendered, 'Kann')
t = Template('{% load i18n %}{% trans "May" context message_context %}') rendered = t.render(Context({'message_context': 'month name'})) self.assertEqual(rendered, 'Mai') t = Template('{% load i18n %}{% trans "May" context message_context %}') rendered = t.render(Context({'message_context': 'verb'})) self.assertEqual(rendered, 'Kann')
t = Template('{% load i18n %}{% trans "May" context message_context|lower %}') rendered = t.render(Context({'message_context': 'MONTH NAME'})) self.assertEqual(rendered, 'Mai') t = Template('{% load i18n %}{% trans "May" context message_context|lower %}') rendered = t.render(Context({'message_context': 'VERB'})) self.assertEqual(rendered, 'Kann')
t = Template('{% load i18n %}{% trans "May" context "month name" as var %}Value: {{ var }}') rendered = t.render(Context()) self.assertEqual(rendered, 'Value: Mai') t = Template('{% load i18n %}{% trans "May" as var context "verb" %}Value: {{ var }}') rendered = t.render(Context()) self.assertEqual(rendered, 'Value: Kann')
t = Template('{% load i18n %}{% blocktrans context "unexisting" %}May{% endblocktrans %}') rendered = t.render(Context()) self.assertEqual(rendered, 'May')
t = Template('{% load i18n %}{% blocktrans context "month name" %}May{% endblocktrans %}') rendered = t.render(Context()) self.assertEqual(rendered, 'Mai') t = Template('{% load i18n %}{% blocktrans context "verb" %}May{% endblocktrans %}') rendered = t.render(Context()) self.assertEqual(rendered, 'Kann')
t = Template('{% load i18n %}{% blocktrans context message_context %}May{% endblocktrans %}') rendered = t.render(Context({'message_context': 'month name'})) self.assertEqual(rendered, 'Mai') t = Template('{% load i18n %}{% blocktrans context message_context %}May{% endblocktrans %}') rendered = t.render(Context({'message_context': 'verb'})) self.assertEqual(rendered, 'Kann')
t = Template('{% load i18n %}{% blocktrans context message_context|lower %}May{% endblocktrans %}') rendered = t.render(Context({'message_context': 'MONTH NAME'})) self.assertEqual(rendered, 'Mai') t = Template('{% load i18n %}{% blocktrans context message_context|lower %}May{% endblocktrans %}') rendered = t.render(Context({'message_context': 'VERB'})) self.assertEqual(rendered, 'Kann')
t = Template( '{% load i18n %}{% blocktrans count number=1 context "super search" %}' '{{ number }} super result{% plural %}{{ number }} super results{% endblocktrans %}' ) rendered = t.render(Context()) self.assertEqual(rendered, '1 Super-Ergebnis') t = Template( '{% load i18n %}{% blocktrans count number=2 context "super search" %}{{ number }}' ' super result{% plural %}{{ number }} super results{% endblocktrans %}' ) rendered = t.render(Context()) self.assertEqual(rendered, '2 Super-Ergebnisse') t = Template( '{% load i18n %}{% blocktrans context "other super search" count number=1 %}' '{{ number }} super result{% plural %}{{ number }} super results{% endblocktrans %}' ) rendered = t.render(Context()) self.assertEqual(rendered, '1 anderen Super-Ergebnis') t = Template( '{% load i18n %}{% blocktrans context "other super search" count number=2 %}' '{{ number }} super result{% plural %}{{ number }} super results{% endblocktrans %}' ) rendered = t.render(Context()) self.assertEqual(rendered, '2 andere Super-Ergebnisse')
t = Template( '{% load i18n %}{% blocktrans with num_comments=5 context "comment count" %}' 'There are {{ num_comments }} comments{% endblocktrans %}' ) rendered = t.render(Context()) self.assertEqual(rendered, 'Es gibt 5 Kommentare') t = Template( '{% load i18n %}{% blocktrans with num_comments=5 context "other comment count" %}' 'There are {{ num_comments }} comments{% endblocktrans %}' ) rendered = t.render(Context()) self.assertEqual(rendered, 'Andere: Es gibt 5 Kommentare')
t = Template( '{% load i18n %}{% blocktrans trimmed %}\n\nThere\n\t are 5 ' '\n\n comments\n{% endblocktrans %}' ) rendered = t.render(Context()) self.assertEqual(rendered, 'There are 5 comments') t = Template( '{% load i18n %}{% blocktrans with num_comments=5 context "comment count" trimmed %}\n\n' 'There are \t\n \t {{ num_comments }} comments\n\n{% endblocktrans %}' ) rendered = t.render(Context()) self.assertEqual(rendered, 'Es gibt 5 Kommentare') t = Template( '{% load i18n %}{% blocktrans context "other super search" count number=2 trimmed %}\n' '{{ number }} super \n result{% plural %}{{ number }} super results{% endblocktrans %}' ) rendered = t.render(Context()) self.assertEqual(rendered, '2 andere Super-Ergebnisse')
with self.assertRaises(TemplateSyntaxError): Template('{% load i18n %}{% blocktrans context with month="May" %}{{ month }}{% endblocktrans %}') with self.assertRaises(TemplateSyntaxError): Template('{% load i18n %}{% blocktrans context %}{% endblocktrans %}') with self.assertRaises(TemplateSyntaxError): Template( '{% load i18n %}{% blocktrans count number=2 context %}' '{{ number }} super result{% plural %}{{ number }}' ' super results{% endblocktrans %}' )
class sideeffect_str(str): def split(self, *args, **kwargs): res = str.split(self, *args, **kwargs) trans_real._translations['en-YY'] = None return res
self.assertLess(translation_count, len(trans_real._translations))
self.assertEqual('10000', nformat(self.l, decimal_sep='.', decimal_pos=0, grouping=0, force_grouping=True))
self.assertEqual('31.12.2009  20:50', Template('{{ dt|date:"d.m.Y  H:i" }}').render(self.ctxt)) self.assertEqual(' 10:15', Template('{{ t|time:" H:i" }}').render(self.ctxt))
with self.settings(USE_THOUSAND_SEPARATOR=True, NUMBER_GROUPING=1, THOUSAND_SEPARATOR='!'): self.assertEqual('66666.67', Template('{{ n|floatformat:2 }}').render(self.ctxt)) self.assertEqual('100000.0', Template('{{ f|floatformat }}').render(self.ctxt))
self.assertEqual('', get_format('THOUSAND_SEPARATOR'))
self.assertEqual(0, get_format('FIRST_DAY_OF_WEEK'))
with translation.override('ca', deactivate=True): self.assertEqual('j \d\e F \d\e Y', get_format('DATE_FORMAT')) self.assertEqual(1, get_format('FIRST_DAY_OF_WEEK')) self.assertEqual(',', get_format('DECIMAL_SEPARATOR')) self.assertEqual('10:15', time_format(self.t)) self.assertEqual('31 de desembre de 2009', date_format(self.d)) self.assertEqual('desembre del 2009', date_format(self.d, 'YEAR_MONTH_FORMAT')) self.assertEqual('31/12/2009 20:50', date_format(self.dt, 'SHORT_DATETIME_FORMAT')) self.assertEqual('No localizable', localize('No localizable'))
with translation.override('ru', deactivate=True): self.assertHTMLEqual( '<select name="mydate_day" id="id_mydate_day">' '<option value="0">---</option>' '<option value="1">1</option>' '<option value="2">2</option>' '<option value="3">3</option>' '<option value="4">4</option>' '<option value="5">5</option>' '<option value="6">6</option>' '<option value="7">7</option>' '<option value="8">8</option>' '<option value="9">9</option>' '<option value="10">10</option>' '<option value="11">11</option>' '<option value="12">12</option>' '<option value="13">13</option>' '<option value="14">14</option>' '<option value="15">15</option>' '<option value="16">16</option>' '<option value="17">17</option>' '<option value="18">18</option>' '<option value="19">19</option>' '<option value="20">20</option>' '<option value="21">21</option>' '<option value="22">22</option>' '<option value="23">23</option>' '<option value="24">24</option>' '<option value="25">25</option>' '<option value="26">26</option>' '<option value="27">27</option>' '<option value="28">28</option>' '<option value="29">29</option>' '<option value="30">30</option>' '<option value="31" selected="selected">31</option>' '</select>' '<select name="mydate_month" id="id_mydate_month">' '<option value="0">---</option>' '<option value="1">\u042f\u043d\u0432\u0430\u0440\u044c</option>' '<option value="2">\u0424\u0435\u0432\u0440\u0430\u043b\u044c</option>' '<option value="3">\u041c\u0430\u0440\u0442</option>' '<option value="4">\u0410\u043f\u0440\u0435\u043b\u044c</option>' '<option value="5">\u041c\u0430\u0439</option>' '<option value="6">\u0418\u044e\u043d\u044c</option>' '<option value="7">\u0418\u044e\u043b\u044c</option>' '<option value="8">\u0410\u0432\u0433\u0443\u0441\u0442</option>' '<option value="9">\u0421\u0435\u043d\u0442\u044f\u0431\u0440\u044c</option>' '<option value="10">\u041e\u043a\u0442\u044f\u0431\u0440\u044c</option>' '<option value="11">\u041d\u043e\u044f\u0431\u0440\u044c</option>' '<option value="12" selected="selected">\u0414\u0435\u043a\u0430\u0431\u0440\u044c</option>' '</select>' '<select name="mydate_year" id="id_mydate_year">' '<option value="0">---</option>' '<option value="2009" selected="selected">2009</option>' '<option value="2010">2010</option>' '<option value="2011">2011</option>' '<option value="2012">2012</option>' '<option value="2013">2013</option>' '<option value="2014">2014</option>' '<option value="2015">2015</option>' '<option value="2016">2016</option>' '<option value="2017">2017</option>' '<option value="2018">2018</option>' '</select>', forms.SelectDateWidget(years=range(2009, 2019)).render('mydate', datetime.date(2009, 12, 31)) )
with translation.override('en', deactivate=True): self.assertEqual('N j, Y', get_format('DATE_FORMAT')) self.assertEqual(0, get_format('FIRST_DAY_OF_WEEK')) self.assertEqual('.', get_format('DECIMAL_SEPARATOR')) self.assertEqual('Dec. 31, 2009', date_format(self.d)) self.assertEqual('December 2009', date_format(self.d, 'YEAR_MONTH_FORMAT')) self.assertEqual('12/31/2009 8:50 p.m.', date_format(self.dt, 'SHORT_DATETIME_FORMAT')) self.assertEqual('No localizable', localize('No localizable'))
self.assertInHTML( '<input type="text" name="products_delivered" ' 'value="12.000" id="id_products_delivered" required />', form6.as_ul() )
self.assertEqual(sanitize_separators(123), 123)
with self.settings(USE_THOUSAND_SEPARATOR=True): self.assertEqual(sanitize_separators('1\xa0234\xa0567'), '1234567') self.assertEqual(sanitize_separators('77\xa0777,777'), '77777.777') self.assertEqual(sanitize_separators('12 345'), '12345') self.assertEqual(sanitize_separators('77 777,777'), '77777.777') with self.settings(USE_THOUSAND_SEPARATOR=True, USE_L10N=False): self.assertEqual(sanitize_separators('12\xa0345'), '12\xa0345')
self.assertEqual(sanitize_separators('10.10'), '10.10')
default_mod = import_module('django.conf.locale.de.formats') test_mod = import_module('i18n.other.locale.de.formats') test_mod2 = import_module('i18n.other2.locale.de.formats')
self.assertEqual(list(iter_format_modules('de')), [default_mod])
self.assertEqual( list(iter_format_modules('de', 'i18n.other.locale')), [test_mod, default_mod])
self.assertEqual( list(iter_format_modules('de', ['i18n.other.locale', 'i18n.other2.locale'])), [test_mod, test_mod2, default_mod])
self.assertEqual([('de', 1.0)], p('de')) self.assertEqual([('en-au', 1.0)], p('en-AU')) self.assertEqual([('es-419', 1.0)], p('es-419')) self.assertEqual([('*', 1.0)], p('*;q=1.00')) self.assertEqual([('en-au', 0.123)], p('en-AU;q=0.123')) self.assertEqual([('en-au', 0.5)], p('en-au;q=0.5')) self.assertEqual([('en-au', 1.0)], p('en-au;q=1.0')) self.assertEqual([('da', 1.0), ('en', 0.5), ('en-gb', 0.25)], p('da, en-gb;q=0.25, en;q=0.5')) self.assertEqual([('en-au-xx', 1.0)], p('en-au-xx')) self.assertEqual( [('de', 1.0), ('en-au', 0.75), ('en-us', 0.5), ('en', 0.25), ('es', 0.125), ('fa', 0.125)], p('de,en-au;q=0.75,en-us;q=0.5,en;q=0.25,es;q=0.125,fa;q=0.125') ) self.assertEqual([('*', 1.0)], p('*')) self.assertEqual([('de', 1.0)], p('de;q=0.')) self.assertEqual([('en', 1.0), ('*', 0.5)], p('en; q=1.0, * ; q=0.5')) self.assertEqual([], p(''))
self.assertEqual([], p('en-gb;q=1.0000')) self.assertEqual([], p('en;q=0.1234')) self.assertEqual([], p('en;q=.2')) self.assertEqual([], p('abcdefghi-au')) self.assertEqual([], p('**')) self.assertEqual([], p('en,,gb')) self.assertEqual([], p('en-au;q=0.1.0')) self.assertEqual( [], p('XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXZ,en') ) self.assertEqual([], p('da, en-gb;q=0.8, en;q=0.7,#')) self.assertEqual([], p('de;q=2.0')) self.assertEqual([], p('de;q=0.a')) self.assertEqual([], p('12-345')) self.assertEqual([], p('')) self.assertEqual([], p('en; q=1,'))
r.META = {'HTTP_ACCEPT_LANGUAGE': 'es-us'} self.assertEqual(g(r), 'es')
r.META = {'HTTP_ACCEPT_LANGUAGE': 'zh-hans,de'} self.assertEqual(g(r), 'zh-hans')
r.COOKIES = {settings.LANGUAGE_COOKIE_NAME: 'es-us'} r.META = {} self.assertEqual(g(r), 'es')
r.COOKIES = {settings.LANGUAGE_COOKIE_NAME: 'zh-hans'} r.META = {'HTTP_ACCEPT_LANGUAGE': 'de'} self.assertEqual(g(r), 'zh-hans')
self.assertEqual(t_sing.render(Context({'num_comments': 42})), 'There are %(num_comments)s comments') self.assertEqual(t_plur.render(Context({'percent': 42, 'num': 1})), '%(percent)s% represents 1 object') self.assertEqual(t_plur.render(Context({'percent': 42, 'num': 4})), '%(percent)s% represents 4 objects')
self.assertUgettext('Date/time', 'Datum/Zeit')
with self.modify_settings(INSTALLED_APPS={'append': 'i18n.resolution'}): activate('de')
self.assertUgettext('Date/time', 'Datum/Zeit')
activate('de')
self.assertUgettext('Date/time', 'Datum/Zeit (APP)')
self.assertEqual(ugettext("Title"), "Title")
response = self.client.get('/fr/streaming/') self.assertContains(response, "Oui/Non") response = self.client.get('/en/streaming/') self.assertContains(response, "Yes/No")
self.client.get('/fr/simple/') self.assertNotIn(LANGUAGE_SESSION_KEY, self.client.session)
self.assertFalse(check_for_language('tr-TR.UTF-8')) self.assertFalse(check_for_language('tr-TR.UTF8')) self.assertFalse(check_for_language('de-DE.utf-8'))
r = self.rf.get('/') r.COOKIES = {} r.META = {'HTTP_ACCEPT_LANGUAGE': 'en-US,en;q=0.8,bg;q=0.6,ru;q=0.4'} lang = get_language_from_request(r) self.assertEqual('en-us', lang) r = self.rf.get('/') r.COOKIES = {} r.META = {'HTTP_ACCEPT_LANGUAGE': 'bg-bg,en-US;q=0.8,en;q=0.6,ru;q=0.4'} lang = get_language_from_request(r) self.assertEqual('bg', lang)
r = self.rf.get('/') r.COOKIES = {} r.META = {'HTTP_ACCEPT_LANGUAGE': 'pt,en-US;q=0.8,en;q=0.6,ru;q=0.4'} lang = get_language_from_request(r) self.assertEqual('pt-br', lang) r = self.rf.get('/') r.COOKIES = {} r.META = {'HTTP_ACCEPT_LANGUAGE': 'pt-pt,en-US;q=0.8,en;q=0.6,ru;q=0.4'} lang = get_language_from_request(r) self.assertEqual('pt-br', lang)
clear_url_caches()
clear_url_caches()
self.assertEqual(translate_url('/en/account/register/', 'nl'), '/nl/profiel/registeren/') self.assertEqual(translation.get_language(), 'en')
response = self.client.get('/account/register/', HTTP_ACCEPT_LANGUAGE='pl-pl') self.assertRedirects(response, '/en/account/register/')
self.assertListEqual(response.redirect_chain, [('/en/account/register/', 302)]) self.assertRedirects(response, '/en/account/register/', 302)
from __future__ import unicode_literals
expected = ('On dirait un spec str fmt %s mais ne devrait pas tre interprt comme plus disponible') trans_tpl = Template( '{% load i18n %}{% trans "Looks like a str fmt spec %s but ' 'should not be interpreted as such" %}' ) self.assertEqual(trans_tpl.render(Context({})), expected) block_tpl = Template( '{% load i18n %}{% blocktrans %}Looks like a str fmt spec %s but ' 'should not be interpreted as such{% endblocktrans %}' ) self.assertEqual(block_tpl.render(Context({})), expected)
expected = ('On dirait un spec str fmt % o mais ne devrait pas tre interprt comme plus disponible') trans_tpl = Template( '{% load i18n %}{% trans "Looks like a str fmt spec % o but should not be ' 'interpreted as such" %}' ) self.assertEqual(trans_tpl.render(Context({})), expected) block_tpl = Template( '{% load i18n %}{% blocktrans %}Looks like a str fmt spec % o but should not be ' 'interpreted as such{% endblocktrans %}' ) self.assertEqual(block_tpl.render(Context({})), expected)
pofile = os.path.join(proj_dir, 'locale', 'fr', 'LC_MESSAGES', 'django.po')
from django.utils.translation import ugettext as _
from __future__ import unicode_literals
from __future__ import unicode_literals
old_mode = os.stat(mo_file_en).st_mode os.chmod(mo_file_en, stat.S_IREAD) try: call_command('compilemessages', locale=['en'], stderr=err_buffer, verbosity=0) err = err_buffer.getvalue() self.assertIn("not writable location", force_text(err)) finally: os.chmod(mo_file_en, old_mode)
execute_from_command_line(['django-admin', 'help', 'compilemessages'])
mo_file = 'locale/ja/LC_MESSAGES/django.mo' self.addCleanup(self.rmfile, os.path.join(self.test_dir, mo_file)) with self.assertRaises(CommandError): call_command('compilemessages', locale=['ja'], verbosity=0)
mo_file = 'locale/ko/LC_MESSAGES/django.mo' self.addCleanup(self.rmfile, os.path.join(self.test_dir, mo_file)) env = os.environ.copy() env.update({str('LANG'): str('C')}) with mock.patch('django.core.management.utils.Popen', lambda *args, **kwargs: Popen(*args, env=env, **kwargs)): if six.PY2: try: call_command('compilemessages', locale=['ko'], verbosity=0) except CommandError as err: self.assertIn("'' cannot start a field name", six.text_type(err)) else: cmd = MakeMessagesCommand() if cmd.gettext_version < (0, 18, 3): raise unittest.SkipTest("python-brace-format is a recent gettext addition.") with self.assertRaisesMessage(CommandError, "'' cannot start a field name"): call_command('compilemessages', locale=['ko'], verbosity=0)
from __future__ import unicode_literals
lockfile = __file__
cwd_prefix = '%s%s' % (os.curdir, os.sep)
cwd_prefix = ''
self.assertIn('#. Translators: This comment should be extracted', po_contents) self.assertIn( "#. Translators: Django comment block for translators\n#. " "string's meaning unveiled", po_contents ) self.assertIn('#. Translators: One-line translator comment #1', po_contents) self.assertIn('#. Translators: Two-line translator comment #1\n#. continued here.', po_contents) self.assertIn('#. Translators: One-line translator comment #2', po_contents) self.assertIn('#. Translators: Two-line translator comment #2\n#. continued here.', po_contents) self.assertIn('#. Translators: One-line translator comment #3', po_contents) self.assertIn('#. Translators: Two-line translator comment #3\n#. continued here.', po_contents) self.assertIn('#. Translators: One-line translator comment #4', po_contents) self.assertIn('#. Translators: Two-line translator comment #4\n#. continued here.', po_contents) self.assertIn( '#. Translators: One-line translator comment #5 -- with ' 'non ASCII characters: ', po_contents ) self.assertIn( '#. Translators: Two-line translator comment #5 -- with ' 'non ASCII characters: \n#. continued here.', po_contents )
self.assertNotMsgId('Text with a few line breaks.', po_contents) self.assertMsgId("Again some text with a few line breaks, this time should be trimmed.", po_contents)
self.assertFalse(os.path.exists('./templates/template_with_error.tpl.py'))
self.assertIn('msgctxt "Special trans context #1"', po_contents) self.assertMsgId("Translatable literal #7a", po_contents) self.assertIn('msgctxt "Special trans context #2"', po_contents) self.assertMsgId("Translatable literal #7b", po_contents) self.assertIn('msgctxt "Special trans context #3"', po_contents) self.assertMsgId("Translatable literal #7c", po_contents)
self.assertIn('msgctxt "Special blocktrans context #1"', po_contents) self.assertMsgId("Translatable literal #8a", po_contents) self.assertIn('msgctxt "Special blocktrans context #2"', po_contents) self.assertMsgId("Translatable literal #8b-singular", po_contents) self.assertIn("Translatable literal #8b-plural", po_contents) self.assertIn('msgctxt "Special blocktrans context #3"', po_contents) self.assertMsgId("Translatable literal #8c-singular", po_contents) self.assertIn("Translatable literal #8c-plural", po_contents) self.assertIn('msgctxt "Special blocktrans context #4"', po_contents) self.assertMsgId("Translatable literal #8d %(a)s", po_contents)
self.assertIn('msgctxt "Context wrapped in double quotes"', po_contents) self.assertIn('msgctxt "Context wrapped in single quotes"', po_contents)
self.assertIn('msgctxt "Special blocktrans context wrapped in double quotes"', po_contents) self.assertIn('msgctxt "Special blocktrans context wrapped in single quotes"', po_contents)
with warnings.catch_warnings(record=True) as ws: warnings.simplefilter('always') management.call_command('makemessages', locale=[LOCALE], extensions=['thtml'], verbosity=0) self.assertEqual(len(ws), 3) for w in ws: self.assertTrue(issubclass(w.category, TranslatorCommentWarning)) six.assertRegex( self, str(ws[0].message), r"The translator-targeted comment 'Translators: ignored i18n " r"comment #1' \(file templates[/\\]comments.thtml, line 4\) " r"was ignored, because it wasn't the last item on the line\." ) six.assertRegex( self, str(ws[1].message), r"The translator-targeted comment 'Translators: ignored i18n " r"comment #3' \(file templates[/\\]comments.thtml, line 6\) " r"was ignored, because it wasn't the last item on the line\." ) six.assertRegex( self, str(ws[2].message), r"The translator-targeted comment 'Translators: ignored i18n " r"comment #4' \(file templates[/\\]comments.thtml, line 8\) " "was ignored, because it wasn't the last item on the line\." ) self.assertTrue(os.path.exists(self.PO_FILE)) with open(self.PO_FILE, 'r') as fp: po_contents = force_text(fp.read())
mocked_popen_wrapper.return_value = ( "xgettext (GNU gettext-tools) 0.18.1\n" "Copyright (C) 1995-1998, 2000-2010 Free Software Foundation, Inc.\n" "License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\n" "This is free software: you are free to change and redistribute it.\n" "There is NO WARRANTY, to the extent permitted by law.\n" "Written by Ulrich Drepper.\n", '', 0) cmd = MakeMessagesCommand() self.assertEqual(cmd.gettext_version, (0, 18, 1))
mocked_popen_wrapper.return_value = ( "xgettext (GNU gettext-tools) 0.17\n", '', 0) cmd = MakeMessagesCommand() self.assertEqual(cmd.gettext_version, (0, 17))
mocked_popen_wrapper.return_value = ( "any other return value\n", '', 0) cmd = MakeMessagesCommand() with six.assertRaisesRegex(self, CommandError, "Unable to get gettext version. Is it installed?"): cmd.gettext_version
if hasattr(os, 'symlink'): if os.path.exists(self.symlinked_dir): self.assertTrue(os.path.islink(self.symlinked_dir)) else: try: os.symlink(os.path.join(self.test_dir, 'templates'), self.symlinked_dir) except (OSError, NotImplementedError): raise SkipTest("os.symlink() is available on this OS but can't be used by this user.") os.chdir(self.test_dir) management.call_command('makemessages', locale=[LOCALE], verbosity=0, symlinks=True) self.assertTrue(os.path.exists(self.PO_FILE)) with open(self.PO_FILE, 'r') as fp: po_contents = force_text(fp.read()) self.assertMsgId('This literal should be included.', po_contents) self.assertLocationCommentPresent(self.PO_FILE, None, 'templates_symlinked', 'test.html') else: raise SkipTest("os.symlink() not available on this OS + Python version combination.")
self.assertLocationCommentPresent(self.PO_FILE, 'Translatable literal #6b', 'templates', 'test.html')
execute_from_command_line(['django-admin', 'help', 'makemessages'])
CUSTOM_DAY_FORMAT = 'd/m/Y CUSTOM'
dummy1 = _("This is a translatable string.")
dummy2 = _("This is another translatable string.")
dates = [] with self.assertNumQueries(0): article_datetimes_iterator = Article.objects.datetimes('pub_date', 'day', order='DESC').iterator()
from __future__ import unicode_literals
f = TypedMultipleChoiceField(choices=[(1, "+1"), (-1, "-1")], coerce=float) self.assertEqual([1.0], f.clean(['1']))
f = TypedMultipleChoiceField(choices=[(1, "+1"), (-1, "-1")], coerce=bool) self.assertEqual([True], f.clean(['-1']))
f = TypedMultipleChoiceField(choices=[('A', 'A'), ('B', 'B')], coerce=int) msg = "'Select a valid choice. B is not one of the available choices.'" with self.assertRaisesMessage(ValidationError, msg): f.clean(['B']) with self.assertRaisesMessage(ValidationError, "'This field is required.'"): f.clean([])
f = TypedMultipleChoiceField(choices=[(1, "+1"), (-1, "-1")], coerce=int, required=False) self.assertEqual([], f.clean([]))
f = TypedMultipleChoiceField(choices=[(1, "+1"), (-1, "-1")], coerce=int, required=False, empty_value=None) self.assertIsNone(f.clean([]))
f = TypedMultipleChoiceField(choices=[(1, "+1"), (-1, "-1")], coerce=int, required=True) self.assertFalse(f.has_changed(None, ''))
from __future__ import unicode_literals
with self.assertRaisesMessage(ValidationError, "'Enter a valid URL.'"): f.clean('http://%s' % ("X" * 200,))
with self.assertRaisesMessage(ValidationError, "'Enter a valid URL.'"): f.clean('http://%s' % ("X" * 60,))
self.assertEqual(url, f.clean(url))
from __future__ import unicode_literals
self.assertTrue(f.has_changed('False', 'on')) self.assertFalse(f.has_changed(False, 'False')) self.assertFalse(f.has_changed(True, 'True')) self.assertTrue(f.has_changed(False, 'True')) self.assertTrue(f.has_changed(True, 'False'))
f = GenericIPAddressField() with self.assertRaisesMessage(ValidationError, "'This field is required.'"): f.clean('') with self.assertRaisesMessage(ValidationError, "'This field is required.'"): f.clean(None) self.assertEqual(f.clean(' 127.0.0.1 '), '127.0.0.1') with self.assertRaisesMessage(ValidationError, "'Enter a valid IPv4 or IPv6 address.'"): f.clean('foo') with self.assertRaisesMessage(ValidationError, "'Enter a valid IPv4 or IPv6 address.'"): f.clean('127.0.0.') with self.assertRaisesMessage(ValidationError, "'Enter a valid IPv4 or IPv6 address.'"): f.clean('1.2.3.4.5') with self.assertRaisesMessage(ValidationError, "'Enter a valid IPv4 or IPv6 address.'"): f.clean('256.125.1.5') self.assertEqual(f.clean(' fe80::223:6cff:fe8a:2e8a '), 'fe80::223:6cff:fe8a:2e8a') self.assertEqual(f.clean(' 2a02::223:6cff:fe8a:2e8a '), '2a02::223:6cff:fe8a:2e8a') with self.assertRaisesMessage(ValidationError, "'This is not a valid IPv6 address.'"): f.clean('12345:2:3:4') with self.assertRaisesMessage(ValidationError, "'This is not a valid IPv6 address.'"): f.clean('1::2:3::4') with self.assertRaisesMessage(ValidationError, "'This is not a valid IPv6 address.'"): f.clean('foo::223:6cff:fe8a:2e8a') with self.assertRaisesMessage(ValidationError, "'This is not a valid IPv6 address.'"): f.clean('1::2:3:4:5:6:7:8') with self.assertRaisesMessage(ValidationError, "'This is not a valid IPv6 address.'"): f.clean('1:2')
f = GenericIPAddressField() self.assertEqual(f.clean(' ::ffff:0a0a:0a0a '), '::ffff:10.10.10.10') self.assertEqual(f.clean(' ::ffff:10.10.10.10 '), '::ffff:10.10.10.10') self.assertEqual(f.clean(' 2001:000:a:0000:0:fe:fe:beef '), '2001:0:a::fe:fe:beef') self.assertEqual(f.clean(' 2001::a:0000:0:fe:fe:beef '), '2001:0:a::fe:fe:beef')
from datetime import date, datetime
self.assertHTMLEqual( a['mydate'].as_hidden(), '<input type="hidden" name="mydate" value="2008-4-1" id="id_mydate" />', )
c = GetDate({'mydate_month': '2', 'mydate_day': '31', 'mydate_year': '2010'}) self.assertFalse(c.is_valid()) self.assertEqual(c.errors, {'mydate': ['Enter a valid date.']})
d = GetDate({'mydate_month': '1', 'mydate_day': '1', 'mydate_year': '2010'}) self.assertIn('<label for="id_mydate_month">', d.as_p())
b = GetDate({ 'mydate_year': '2008', 'mydate_month': '4', 'mydate_day': '1', }, initial={'mydate': date(2008, 4, 1)}) self.assertFalse(b.has_changed())
class GetDateShowHiddenInitial(Form): mydate = DateField(widget=SelectDateWidget, show_hidden_initial=True)
a = GetDate({'mydate_month': '2', 'mydate_day': '31', 'mydate_year': '2010'}) self.assertFalse(a.is_valid()) self.assertEqual(a.errors, {'mydate': ['Geef een geldige datum op.']})
a = GetDate({'mydate_month': '1', 'mydate_day': '1', 'mydate_year': '2010'}) self.assertIn('<label for="id_mydate_day">', a.as_p())
f = DateField() self.assertEqual(date(2006, 10, 25), f.clean(' 10/25/2006 ')) self.assertEqual(date(2006, 10, 25), f.clean(' 10/25/06 ')) self.assertEqual(date(2006, 10, 25), f.clean(' Oct 25 2006 ')) self.assertEqual(date(2006, 10, 25), f.clean(' October 25 2006 ')) self.assertEqual(date(2006, 10, 25), f.clean(' October 25, 2006 ')) self.assertEqual(date(2006, 10, 25), f.clean(' 25 October 2006 ')) with self.assertRaisesMessage(ValidationError, "'Enter a valid date.'"): f.clean(' ')
f = DateField() with self.assertRaisesMessage(ValidationError, "'Enter a valid date.'"): f.clean('a\x00b')
self.assertEqual(e.__class__, ValueError)
f = CharField() self.assertEqual(f.widget_attrs(TextInput()), {}) self.assertEqual(f.widget_attrs(Textarea()), {})
f = CharField(max_length=10) self.assertEqual(f.widget_attrs(TextInput()), {'maxlength': '10'}) self.assertEqual(f.widget_attrs(PasswordInput()), {'maxlength': '10'}) self.assertEqual(f.widget_attrs(Textarea()), {'maxlength': '10'})
f = CharField(min_length=5) self.assertEqual(f.widget_attrs(TextInput()), {'minlength': '5'}) self.assertEqual(f.widget_attrs(PasswordInput()), {'minlength': '5'}) self.assertEqual(f.widget_attrs(Textarea()), {'minlength': '5'})
f = CharField(max_length=10, min_length=5) self.assertEqual(f.widget_attrs(TextInput()), {'maxlength': '10', 'minlength': '5'}) self.assertEqual(f.widget_attrs(PasswordInput()), {'maxlength': '10', 'minlength': '5'}) self.assertEqual(f.widget_attrs(Textarea()), {'maxlength': '10', 'minlength': '5'})
from __future__ import unicode_literals
from __future__ import unicode_literals
f = TypedChoiceField(choices=[(1, "+1"), (-1, "-1")], coerce=float) self.assertEqual(1.0, f.clean('1'))
f = TypedChoiceField(choices=[(1, "+1"), (-1, "-1")], coerce=bool) self.assertTrue(f.clean('-1'))
f = TypedChoiceField(choices=[('A', 'A'), ('B', 'B')], coerce=int) msg = "'Select a valid choice. B is not one of the available choices.'" with self.assertRaisesMessage(ValidationError, msg): f.clean('B') with self.assertRaisesMessage(ValidationError, "'This field is required.'"): f.clean('')
f = TypedChoiceField(choices=[(1, "+1"), (-1, "-1")], coerce=int, required=False) self.assertEqual('', f.clean(''))
f = TypedChoiceField(choices=[(1, "+1"), (-1, "-1")], coerce=int, required=True) self.assertFalse(f.has_changed(None, '')) self.assertFalse(f.has_changed(1, '1')) self.assertFalse(f.has_changed('1', '1'))
self.assertEqual(datetime.time(14, 25), f.clean(' 14:25 ')) self.assertEqual(datetime.time(14, 25, 59), f.clean(' 14:25:59 ')) with self.assertRaisesMessage(ValidationError, "'Enter a valid time.'"): f.clean(' ')
from __future__ import unicode_literals
self.assertFalse(f.has_changed('', None))
self.assertTrue(f.has_changed('', {'filename': 'resume.txt', 'content': 'My resume'}))
self.assertFalse(f.has_changed('resume.txt', None))
self.assertTrue(f.has_changed('resume.txt', {'filename': 'resume.txt', 'content': 'My resume'}))
from __future__ import unicode_literals
self.assertEqual(f.clean('0000000.10'), decimal.Decimal("0.1")) self.assertEqual(f.clean('0000000.100'), decimal.Decimal("0.100")) self.assertEqual(f.clean('000000.02'), decimal.Decimal('0.02')) with self.assertRaisesMessage(ValidationError, "'Ensure that there are no more than 3 digits in total.'"): f.clean('000000.0002') self.assertEqual(f.clean('.002'), decimal.Decimal("0.002"))
self.assertEqual(datetime.datetime(2006, 10, 25, 14, 30, 45), f.clean(' 2006-10-25 14:30:45 ')) self.assertEqual(datetime.datetime(2006, 10, 25, 0, 0), f.clean(' 2006-10-25 ')) self.assertEqual(datetime.datetime(2006, 10, 25, 14, 30, 45), f.clean(' 10/25/2006 14:30:45 ')) self.assertEqual(datetime.datetime(2006, 10, 25, 14, 30), f.clean(' 10/25/2006 14:30 ')) self.assertEqual(datetime.datetime(2006, 10, 25, 0, 0), f.clean(' 10/25/2006 ')) self.assertEqual(datetime.datetime(2006, 10, 25, 14, 30, 45), f.clean(' 10/25/06 14:30:45 ')) self.assertEqual(datetime.datetime(2006, 10, 25, 0, 0), f.clean(' 10/25/06 ')) with self.assertRaisesMessage(ValidationError, "'Enter a valid date/time.'"): f.clean(' ')
from __future__ import unicode_literals
addr = 'viewx3dtextx26qx3d@yahoo.comx26latlngx3d15854521645943074058' self.assertEqual(addr, f.clean(addr))
class HiddenNullBooleanForm(Form): hidden_nullbool1 = NullBooleanField(widget=HiddenInput, initial=True) hidden_nullbool2 = NullBooleanField(widget=HiddenInput, initial=False) f = HiddenNullBooleanForm() self.assertHTMLEqual( '<input type="hidden" name="hidden_nullbool1" value="True" id="id_hidden_nullbool1" />' '<input type="hidden" name="hidden_nullbool2" value="False" id="id_hidden_nullbool2" />', str(f) )
NULLBOOL_CHOICES = (('1', 'Yes'), ('0', 'No'), ('', 'Unknown'))
self.assertFalse(f.has_changed(False, 'False')) self.assertFalse(f.has_changed(True, 'True')) self.assertFalse(f.has_changed(None, '')) self.assertTrue(f.has_changed(False, 'True')) self.assertTrue(f.has_changed(True, 'False')) self.assertTrue(f.has_changed(None, 'False'))
from __future__ import unicode_literals
self.assertInHTML('<option value="0">empty_label</option>', w.render('mydate', ''), count=3)
self.assertEqual(w.render('mydate', '2010-02-30').count('selected="selected"'), 3)
w = SelectDateWidget(years=('1899',)) self.assertEqual( w.value_from_datadict({'date_year': '1899', 'date_month': '8', 'date_day': '13'}, {}, 'date'), '13-08-1899', )
self.assertEqual(w1.choices, [1, 2, 3])
from __future__ import unicode_literals
from __future__ import unicode_literals
with self.assertNumQueries(1): field = ModelChoiceField(Group.objects.order_by('-name')) self.assertEqual('a', field.clean(self.groups[0].pk).name)
self.assertIsInstance(form.cleaned_data['multi_choice_optional'], models.query.QuerySet) self.assertIsInstance(form.cleaned_data['multi_choice'], models.query.QuerySet)
file1 = SimpleUploadedFile('.txt', '       '.encode('utf-8')) f = FileForm(data={}, files={'file1': file1}, auto_id=False) self.assertTrue(f.is_valid()) self.assertIn('file1', f.cleaned_data) m = FileModel.objects.create(file=f.cleaned_data['file1']) self.assertEqual(m.file.name, 'tests/\u6211\u96bb\u6c23\u588a\u8239\u88dd\u6eff\u6652\u9c54.txt') m.delete()
class BoundaryForm(ModelForm): class Meta: model = BoundaryModel fields = '__all__'
class DefaultsForm(ModelForm): class Meta: model = Defaults fields = '__all__'
foo_instance = Defaults(name='instance value', def_date=datetime.date(1969, 4, 4), value=12) instance_form = DefaultsForm(instance=foo_instance) self.assertEqual(instance_form.initial['name'], 'instance value') self.assertEqual(instance_form.initial['def_date'], datetime.date(1969, 4, 4)) self.assertEqual(instance_form.initial['value'], 12)
opt1 = ChoiceOptionModel.objects.create(id=1, name='default') opt2 = ChoiceOptionModel.objects.create(id=2, name='option 2') opt3 = ChoiceOptionModel.objects.create(id=3, name='option 3') initial = { 'choice': opt1, 'choice_int': opt1, } data = { 'choice': opt2.pk, 'choice_int': opt2.pk, 'multi_choice': 'string data!', 'multi_choice_int': [opt1.pk], } instance = ChoiceFieldModel.objects.create(**initial) instance.multi_choice.set([opt2, opt3]) instance.multi_choice_int.set([opt2, opt3]) form = ChoiceFieldExclusionForm(data=data, instance=instance) self.assertTrue(form.is_valid()) self.assertEqual(form.cleaned_data['multi_choice'], data['multi_choice']) form.save() self.assertEqual(form.instance.choice.pk, data['choice']) self.assertEqual(form.instance.choice_int.pk, data['choice_int']) self.assertEqual(list(form.instance.multi_choice.all()), [opt2, opt3]) self.assertEqual([obj.pk for obj in form.instance.multi_choice_int.all()], data['multi_choice_int'])
tests = [ (EmptyCharLabelNoneChoiceForm, 'choice_string_w_none', None), (EmptyIntegerLabelChoiceForm, 'choice_integer', None), (EmptyCharLabelChoiceForm, 'choice', ''), ]
activate('nl')
with self.assertRaises(forms.ValidationError): f.clean('1:30:05 PM')
result = f.clean('13:30:05') self.assertEqual(result, time(13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, '13:30:05')
result = f.clean('13:30') self.assertEqual(result, time(13, 30, 0))
text = f.widget.format_value(result) self.assertEqual(text, "13:30:00")
result = f.clean('13:30:05.000155') self.assertEqual(result, time(13, 30, 5, 155))
with self.assertRaises(forms.ValidationError): f.clean('1:30:05 PM')
result = f.clean('13:30:05') self.assertEqual(result, time(13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, '13:30:05')
result = f.clean('13:30') self.assertEqual(result, time(13, 30, 0))
text = f.widget.format_value(result) self.assertEqual(text, "13:30:00")
with self.assertRaises(forms.ValidationError): f.clean('1:30:05 PM') with self.assertRaises(forms.ValidationError): f.clean('13:30:05')
result = f.clean('13.30.05') self.assertEqual(result, time(13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, "13:30:05")
result = f.clean('13.30') self.assertEqual(result, time(13, 30, 0))
text = f.widget.format_value(result) self.assertEqual(text, "13:30:00")
with self.assertRaises(forms.ValidationError): f.clean('1:30:05 PM') with self.assertRaises(forms.ValidationError): f.clean('13:30:05')
result = f.clean('13.30.05') self.assertEqual(result, time(13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, "13:30:05")
result = f.clean('13.30') self.assertEqual(result, time(13, 30, 0))
text = f.widget.format_value(result) self.assertEqual(text, "13:30:00")
with self.assertRaises(forms.ValidationError): f.clean('13:30:05')
result = f.clean('1:30:05 PM') self.assertEqual(result, time(13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, '01:30:05 PM')
result = f.clean('1:30 PM') self.assertEqual(result, time(13, 30, 0))
text = f.widget.format_value(result) self.assertEqual(text, "01:30:00 PM")
with self.assertRaises(forms.ValidationError): f.clean('13:30:05')
result = f.clean('1:30:05 PM') self.assertEqual(result, time(13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, '01:30:05 PM')
result = f.clean('01:30 PM') self.assertEqual(result, time(13, 30, 0))
text = f.widget.format_value(result) self.assertEqual(text, "01:30:00 PM")
with self.assertRaises(forms.ValidationError): f.clean('1:30:05 PM') with self.assertRaises(forms.ValidationError): f.clean('13:30:05')
result = f.clean('13.30.05') self.assertEqual(result, time(13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, "01:30:05 PM")
result = f.clean('13.30') self.assertEqual(result, time(13, 30, 0))
text = f.widget.format_value(result) self.assertEqual(text, "01:30:00 PM")
with self.assertRaises(forms.ValidationError): f.clean('1:30:05 PM') with self.assertRaises(forms.ValidationError): f.clean('13:30:05')
result = f.clean('13.30.05') self.assertEqual(result, time(13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, "01:30:05 PM")
result = f.clean('13.30') self.assertEqual(result, time(13, 30, 0))
text = f.widget.format_value(result) self.assertEqual(text, "01:30:00 PM")
with self.assertRaises(forms.ValidationError): f.clean('1:30:05 PM')
result = f.clean('13:30:05') self.assertEqual(result, time(13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, "13:30:05")
result = f.clean('13:30') self.assertEqual(result, time(13, 30, 0))
text = f.widget.format_value(result) self.assertEqual(text, "13:30:00")
with self.assertRaises(forms.ValidationError): f.clean('1:30:05 PM')
result = f.clean('13:30:05') self.assertEqual(result, time(13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, "13:30:05")
result = f.clean('13:30') self.assertEqual(result, time(13, 30, 0))
text = f.widget.format_value(result) self.assertEqual(text, "13:30:00")
with self.assertRaises(forms.ValidationError): f.clean('13:30:05')
result = f.clean('1:30:05 PM') self.assertEqual(result, time(13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, "13:30:05")
result = f.clean('1:30 PM') self.assertEqual(result, time(13, 30, 0))
text = f.widget.format_value(result) self.assertEqual(text, "13:30:00")
with self.assertRaises(forms.ValidationError): f.clean('13:30:05')
result = f.clean('1:30:05 PM') self.assertEqual(result, time(13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, "13:30:05")
result = f.clean('1:30 PM') self.assertEqual(result, time(13, 30, 0))
text = f.widget.format_value(result) self.assertEqual(text, "13:30:00")
with self.assertRaises(forms.ValidationError): f.clean('21/12/2010')
self.assertEqual(f.clean('2010-12-21'), date(2010, 12, 21))
result = f.clean('21.12.2010') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, '21.12.2010')
result = f.clean('21.12.10') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, "21.12.2010")
with self.assertRaises(forms.ValidationError): f.clean('21/12/2010')
result = f.clean('21.12.2010') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, '21.12.2010')
result = f.clean('21.12.10') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, "21.12.2010")
with self.assertRaises(forms.ValidationError): f.clean('2010-12-21') with self.assertRaises(forms.ValidationError): f.clean('21/12/2010') with self.assertRaises(forms.ValidationError): f.clean('21.12.2010')
result = f.clean('12.21.2010') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, "21.12.2010")
result = f.clean('12-21-2010') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, "21.12.2010")
with self.assertRaises(forms.ValidationError): f.clean('2010-12-21') with self.assertRaises(forms.ValidationError): f.clean('21/12/2010') with self.assertRaises(forms.ValidationError): f.clean('21.12.2010')
result = f.clean('12.21.2010') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, "21.12.2010")
result = f.clean('12-21-2010') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, "21.12.2010")
with self.assertRaises(forms.ValidationError): f.clean('2010-12-21')
result = f.clean('21.12.2010') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, '21.12.2010')
result = f.clean('21-12-2010') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, "21.12.2010")
with self.assertRaises(forms.ValidationError): f.clean('2010-12-21')
result = f.clean('21.12.2010') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, '21.12.2010')
result = f.clean('21-12-2010') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, "21.12.2010")
with self.assertRaises(forms.ValidationError): f.clean('21.12.2010') with self.assertRaises(forms.ValidationError): f.clean('2010-12-21')
result = f.clean('12.21.2010') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, "21.12.2010")
result = f.clean('12-21-2010') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, "21.12.2010")
with self.assertRaises(forms.ValidationError): f.clean('21.12.2010') with self.assertRaises(forms.ValidationError): f.clean('2010-12-21')
result = f.clean('12.21.2010') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, "21.12.2010")
result = f.clean('12-21-2010') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, "21.12.2010")
with self.assertRaises(forms.ValidationError): f.clean('21.12.2010')
result = f.clean('2010-12-21') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, "2010-12-21")
result = f.clean('12/21/2010') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, "2010-12-21")
with self.assertRaises(forms.ValidationError): f.clean('21.12.2010')
result = f.clean('2010-12-21') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, "2010-12-21")
result = f.clean('12/21/2010') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, "2010-12-21")
with self.assertRaises(forms.ValidationError): f.clean('2010-12-21')
result = f.clean('21.12.2010') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, "2010-12-21")
result = f.clean('21-12-2010') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, "2010-12-21")
with self.assertRaises(forms.ValidationError): f.clean('2010-12-21')
result = f.clean('21.12.2010') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, "2010-12-21")
result = f.clean('21-12-2010') self.assertEqual(result, date(2010, 12, 21))
text = f.widget.format_value(result) self.assertEqual(text, "2010-12-21")
with self.assertRaises(forms.ValidationError): f.clean('1:30:05 PM 21/12/2010')
self.assertEqual(f.clean('2010-12-21 13:30:05'), datetime(2010, 12, 21, 13, 30, 5))
result = f.clean('21.12.2010 13:30:05') self.assertEqual(result, datetime(2010, 12, 21, 13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, '21.12.2010 13:30:05')
result = f.clean('21.12.2010 13:30') self.assertEqual(result, datetime(2010, 12, 21, 13, 30))
text = f.widget.format_value(result) self.assertEqual(text, "21.12.2010 13:30:00")
with self.assertRaises(forms.ValidationError): f.clean('1:30:05 PM 21/12/2010')
result = f.clean('21.12.2010 13:30:05') self.assertEqual(result, datetime(2010, 12, 21, 13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, '21.12.2010 13:30:05')
result = f.clean('21.12.2010 13:30') self.assertEqual(result, datetime(2010, 12, 21, 13, 30))
text = f.widget.format_value(result) self.assertEqual(text, "21.12.2010 13:30:00")
with self.assertRaises(forms.ValidationError): f.clean('2010-12-21 13:30:05 13:30:05') with self.assertRaises(forms.ValidationError): f.clean('1:30:05 PM 21/12/2010') with self.assertRaises(forms.ValidationError): f.clean('13:30:05 21.12.2010')
result = f.clean('13.30.05 12.21.2010') self.assertEqual(result, datetime(2010, 12, 21, 13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, "21.12.2010 13:30:05")
result = f.clean('13.30 12-21-2010') self.assertEqual(result, datetime(2010, 12, 21, 13, 30))
text = f.widget.format_value(result) self.assertEqual(text, "21.12.2010 13:30:00")
with self.assertRaises(forms.ValidationError): f.clean('2010-12-21 13:30:05') with self.assertRaises(forms.ValidationError): f.clean('1:30:05 PM 21/12/2010') with self.assertRaises(forms.ValidationError): f.clean('13:30:05 21.12.2010')
result = f.clean('13.30.05 12.21.2010') self.assertEqual(result, datetime(2010, 12, 21, 13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, "21.12.2010 13:30:05")
result = f.clean('13.30 12-21-2010') self.assertEqual(result, datetime(2010, 12, 21, 13, 30))
text = f.widget.format_value(result) self.assertEqual(text, "21.12.2010 13:30:00")
with self.assertRaises(forms.ValidationError): f.clean('2010-12-21 13:30:05')
result = f.clean('1:30:05 PM 21/12/2010') self.assertEqual(result, datetime(2010, 12, 21, 13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, '01:30:05 PM 21/12/2010')
result = f.clean('1:30 PM 21-12-2010') self.assertEqual(result, datetime(2010, 12, 21, 13, 30))
text = f.widget.format_value(result) self.assertEqual(text, "01:30:00 PM 21/12/2010")
with self.assertRaises(forms.ValidationError): f.clean('2010-12-21 13:30:05')
result = f.clean('1:30:05 PM 21/12/2010') self.assertEqual(result, datetime(2010, 12, 21, 13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, '01:30:05 PM 21/12/2010')
result = f.clean('1:30 PM 21-12-2010') self.assertEqual(result, datetime(2010, 12, 21, 13, 30))
text = f.widget.format_value(result) self.assertEqual(text, "01:30:00 PM 21/12/2010")
with self.assertRaises(forms.ValidationError): f.clean('13:30:05 21.12.2010') with self.assertRaises(forms.ValidationError): f.clean('2010-12-21 13:30:05')
result = f.clean('12.21.2010 13:30:05') self.assertEqual(result, datetime(2010, 12, 21, 13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, "01:30:05 PM 21/12/2010")
result = f.clean('12-21-2010 13:30') self.assertEqual(result, datetime(2010, 12, 21, 13, 30))
text = f.widget.format_value(result) self.assertEqual(text, "01:30:00 PM 21/12/2010")
with self.assertRaises(forms.ValidationError): f.clean('13:30:05 21.12.2010') with self.assertRaises(forms.ValidationError): f.clean('2010-12-21 13:30:05')
result = f.clean('12.21.2010 13:30:05') self.assertEqual(result, datetime(2010, 12, 21, 13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, "01:30:05 PM 21/12/2010")
result = f.clean('12-21-2010 13:30') self.assertEqual(result, datetime(2010, 12, 21, 13, 30))
text = f.widget.format_value(result) self.assertEqual(text, "01:30:00 PM 21/12/2010")
with self.assertRaises(forms.ValidationError): f.clean('13:30:05 21.12.2010')
result = f.clean('2010-12-21 13:30:05') self.assertEqual(result, datetime(2010, 12, 21, 13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, "2010-12-21 13:30:05")
result = f.clean('12/21/2010 13:30:05') self.assertEqual(result, datetime(2010, 12, 21, 13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, "2010-12-21 13:30:05")
with self.assertRaises(forms.ValidationError): f.clean('13:30:05 21.12.2010')
result = f.clean('2010-12-21 13:30:05') self.assertEqual(result, datetime(2010, 12, 21, 13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, "2010-12-21 13:30:05")
result = f.clean('12/21/2010 13:30:05') self.assertEqual(result, datetime(2010, 12, 21, 13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, "2010-12-21 13:30:05")
with self.assertRaises(forms.ValidationError): f.clean('2010-12-21 13:30:05')
result = f.clean('1:30:05 PM 21.12.2010') self.assertEqual(result, datetime(2010, 12, 21, 13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, "2010-12-21 13:30:05")
result = f.clean('1:30 PM 21-12-2010') self.assertEqual(result, datetime(2010, 12, 21, 13, 30))
text = f.widget.format_value(result) self.assertEqual(text, "2010-12-21 13:30:00")
with self.assertRaises(forms.ValidationError): f.clean('2010-12-21 13:30:05')
result = f.clean('1:30:05 PM 21.12.2010') self.assertEqual(result, datetime(2010, 12, 21, 13, 30, 5))
text = f.widget.format_value(result) self.assertEqual(text, "2010-12-21 13:30:05")
result = f.clean('1:30 PM 21-12-2010') self.assertEqual(result, datetime(2010, 12, 21, 13, 30))
text = f.widget.format_value(result) self.assertEqual(text, "2010-12-21 13:30:00")
from __future__ import unicode_literals
ChoiceFormSet = formset_factory(Choice)
FavoriteDrinksFormSet = formset_factory(FavoriteDrinkForm, formset=BaseFavoriteDrinksFormSet, extra=3)
class SplitDateTimeForm(Form): when = SplitDateTimeField(initial=datetime.datetime.now)
formset = self.make_choiceformset() self.assertFalse(formset.is_valid()) self.assertFalse(formset.has_changed())
formset = self.make_choiceformset([('Calexico', '')]) self.assertFalse(formset.is_valid()) self.assertEqual(formset.errors, [{'votes': ['This field is required.']}])
blank_formset = self.make_choiceformset([('', '')]) self.assertFalse(blank_formset.has_changed())
invalid_formset = self.make_choiceformset([('Calexico', '')]) self.assertFalse(invalid_formset.is_valid()) self.assertTrue(invalid_formset.has_changed())
valid_formset = self.make_choiceformset([('Calexico', '100')]) self.assertTrue(valid_formset.is_valid()) self.assertTrue(valid_formset.has_changed())
formset = self.make_choiceformset([('Calexico', '100'), ('', '')], initial_forms=1) self.assertTrue(formset.is_valid()) self.assertEqual([form.cleaned_data for form in formset.forms], [{'votes': 100, 'choice': 'Calexico'}, {}])
formset = self.make_choiceformset([('Calexico', '100'), ('The Decemberists', '')], initial_forms=1) self.assertFalse(formset.is_valid()) self.assertEqual(formset.errors, [{}, {'votes': ['This field is required.']}])
formset = self.make_choiceformset([('', ''), ('', '')], initial_forms=1) self.assertFalse(formset.is_valid()) self.assertEqual( formset.errors, [{'votes': ['This field is required.'], 'choice': ['This field is required.']}, {}] )
ChoiceFormSet = formset_factory(Choice, extra=3)
ChoiceFormSet = formset_factory(Choice, extra=1, min_num=1)
self.assertFalse(formset.forms[0].empty_permitted) self.assertTrue(formset.forms[1].empty_permitted)
ChoiceFormSet = formset_factory(Choice, extra=0, min_num=3)
initial = [{'choice': 'Calexico', 'votes': 100}] ChoiceFormSet = formset_factory(Choice, extra=3) formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices') form_output = []
data['check-1-DELETE'] = '' formset = CheckFormSet(data, prefix='check') self.assertFalse(formset.is_valid())
LimitedFavoriteDrinkFormSet = formset_factory(FavoriteDrinkForm, extra=3, max_num=0) formset = LimitedFavoriteDrinkFormSet() form_output = []
initial = [ {'name': 'Gin Tonic'}, ] LimitedFavoriteDrinkFormSet = formset_factory(FavoriteDrinkForm, extra=3, max_num=2) formset = LimitedFavoriteDrinkFormSet(initial=initial) form_output = []
ChoiceFormset = formset_factory(Choice, extra=3) formset = ChoiceFormset()
forms = list(formset) self.assertEqual(forms, formset.forms) self.assertEqual(len(formset), len(forms))
self.assertEqual(formset[0], forms[0]) try: formset[3] self.fail('Requesting an invalid formset index should raise an exception') except IndexError: pass
class BaseReverseFormSet(BaseFormSet): def __iter__(self): return reversed(self.forms)
self.assertEqual(str(reverse_formset[0]), str(forms[-1])) self.assertEqual(str(reverse_formset[1]), str(forms[-2])) self.assertEqual(len(reverse_formset), len(forms))
class CustomErrorList(ErrorList): pass
_old_DEFAULT_MAX_NUM = formsets.DEFAULT_MAX_NUM try: formsets.DEFAULT_MAX_NUM = 2 ChoiceFormSet = formset_factory(Choice, max_num=1) formset = ChoiceFormSet( { 'choices-TOTAL_FORMS': '4', 'choices-INITIAL_FORMS': '0',
self.assertEqual(len(formset.forms), 3) self.assertFalse(formset.is_valid())
_old_DEFAULT_MAX_NUM = formsets.DEFAULT_MAX_NUM try: formsets.DEFAULT_MAX_NUM = 3 ChoiceFormSet = formset_factory(Choice, max_num=4) formset = ChoiceFormSet( { 'choices-TOTAL_FORMS': '4', 'choices-INITIAL_FORMS': '0',
self.assertEqual(len(formset.forms), 4)
class BaseCustomFormSet(BaseFormSet): def clean(self): raise ValidationError("This is a non-form error")
class ArticleForm(Form): title = CharField() pub_date = DateField()
self.assertFalse(empty_forms[0].is_bound) self.assertFalse(empty_forms[1].is_bound)
self.assertHTMLEqual(empty_forms[0].as_p(), empty_forms[1].as_p())
from __future__ import unicode_literals
extra_attrs = {'class': 'special'}
with translation.override('de'): self.assertHTMLEqual( f.as_p(), '<p><label for="id_username">Benutzername:</label>' '<input id="id_username" type="text" name="username" maxlength="10" required /></p>' ) with translation.override('pl'): self.assertHTMLEqual( f.as_p(), '<p><label for="id_username">u\u017cytkownik:</label>' '<input id="id_username" type="text" name="username" maxlength="10" required /></p>' )
class SomeForm(Form): field_1 = CharField(max_length=10, label=ugettext_lazy('field_1')) field_2 = CharField( max_length=10, label=ugettext_lazy('field_2'), widget=TextInput(attrs={'id': 'field_2_id'}), )
GENDERS = (('\xc5', 'En tied\xe4'), ('\xf8', 'Mies'), ('\xdf', 'Nainen'))
with translation.override('ru'): f = SomeForm({}) self.assertHTMLEqual( f.as_p(), '<ul class="errorlist"><li>' '\u041e\u0431\u044f\u0437\u0430\u0442\u0435\u043b\u044c' '\u043d\u043e\u0435 \u043f\u043e\u043b\u0435.</li></ul>\n' '<p><label for="id_somechoice_0">\xc5\xf8\xdf:</label>' ' <ul id="id_somechoice">\n<li><label for="id_somechoice_0">' '<input type="radio" id="id_somechoice_0" value="\xc5" name="somechoice" required /> ' 'En tied\xe4</label></li>\n' '<li><label for="id_somechoice_1">' '<input type="radio" id="id_somechoice_1" value="\xf8" name="somechoice" required /> ' 'Mies</label></li>\n<li><label for="id_somechoice_2">' '<input type="radio" id="id_somechoice_2" value="\xdf" name="somechoice" required /> ' 'Nainen</label></li>\n</ul></p>' )
class CopyForm(Form): degree = IntegerField(widget=Select(choices=((1, gettext_lazy('test')),)))
UNITS = ((b'\xd0\xbc\xd0\xb5\xd1\x81.', b'\xd0\xbc\xd0\xb5\xd1\x81.'), (b'\xd1\x88\xd1\x82.', b'\xd1\x88\xd1\x82.')) f = ChoiceField(choices=UNITS) self.assertEqual(f.clean('\u0448\u0442.'), '\u0448\u0442.') self.assertEqual(f.clean(b'\xd1\x88\xd1\x82.'), '\u0448\u0442.')
class DataForm(Form): data = CharField(max_length=10)
class HiddenForm(Form): data = IntegerField(widget=HiddenInput)
from django.template import Template, Context t = Template('{{ form.errors }}')
from __future__ import unicode_literals
form1 = TestForm({'first_name': 'John'}) self.assertHTMLEqual( str(form1['last_name'].errors), '<ul class="errorlist"><li>This field is required.</li></ul>' ) self.assertHTMLEqual( str(form1.errors['__all__']), '<ul class="errorlist nonfield"><li>I like to be awkward.</li></ul>' )
form2 = TestForm({'first_name': 'John'}, error_class=CustomErrorList) self.assertHTMLEqual(str(form2['last_name'].errors), '<div class="error"><p>This field is required.</p></div>') self.assertHTMLEqual(str(form2.errors['__all__']), '<div class="error"><p>I like to be awkward.</p></div>')
from forms_tests.models import ChoiceModel ChoiceModel.objects.create(pk=1, name='a') ChoiceModel.objects.create(pk=2, name='b') ChoiceModel.objects.create(pk=3, name='c')
e = { 'required': 'REQUIRED', 'invalid_choice': 'INVALID CHOICE', } f = ModelChoiceField(queryset=ChoiceModel.objects.all(), error_messages=e) self.assertFormErrors(['REQUIRED'], f.clean, '') self.assertFormErrors(['INVALID CHOICE'], f.clean, '4')
e = { 'required': 'REQUIRED', 'invalid_choice': '%(value)s IS INVALID CHOICE', 'list': 'NOT A LIST OF VALUES', } f = ModelMultipleChoiceField(queryset=ChoiceModel.objects.all(), error_messages=e) self.assertFormErrors(['REQUIRED'], f.clean, '') self.assertFormErrors(['NOT A LIST OF VALUES'], f.clean, '3') self.assertFormErrors(['4 IS INVALID CHOICE'], f.clean, ['4'])
from __future__ import unicode_literals
w = RadioSelect(choices=(('J', 'John'), ('P', 'Paul'), ('G', 'George'), ('R', 'Ringo'))) r = w.get_renderer('beatle', 'J') inp_set1 = [] inp_set2 = [] inp_set3 = [] inp_set4 = []
w = RadioSelect(choices=(('J', 'John'), ('P', 'Paul'), ('G', 'George'), ('R', 'Ringo'))) r = w.get_renderer('beatle', 'J') self.assertHTMLEqual(str(r[1]), '<label><input type="radio" name="beatle" value="P" /> Paul</label>') self.assertHTMLEqual( str(r[0]), '<label><input checked="checked" type="radio" name="beatle" value="J" /> John</label>' ) self.assertTrue(r[0].is_checked()) self.assertFalse(r[1].is_checked()) self.assertEqual((r[1].name, r[1].value, r[1].choice_value, r[1].choice_label), ('beatle', 'J', 'P', 'Paul'))
self.assertHTMLEqual( r[1].render(attrs={'extra': 'value'}), '<label><input type="radio" extra="value" name="beatle" value="P" /> Paul</label>' )
self.assertEqual(article.content, "\r\nTst\r\n")
from __future__ import unicode_literals
p = Person({'first_name': 'John', 'last_name': 'Lennon', 'birthday': '1940-10-9'})
p = Person({ 'first_name': 'John', 'last_name': '\u0160\u0110\u0106\u017d\u0107\u017e\u0161\u0111', 'birthday': '1940-10-9' }) self.assertHTMLEqual( p.as_table(), '<tr><th><label for="id_first_name">First name:</label></th><td>' '<input type="text" name="first_name" value="John" id="id_first_name" required /></td></tr>\n' '<tr><th><label for="id_last_name">Last name:</label>' '</th><td><input type="text" name="last_name" ' 'value="\u0160\u0110\u0106\u017d\u0107\u017e\u0161\u0111"' 'id="id_last_name" required /></td></tr>\n' '<tr><th><label for="id_birthday">Birthday:</label></th><td>' '<input type="text" name="birthday" value="1940-10-9" id="id_birthday" required /></td></tr>' ) self.assertHTMLEqual( p.as_ul(), '<li><label for="id_first_name">First name:</label> ' '<input type="text" name="first_name" value="John" id="id_first_name" required /></li>\n' '<li><label for="id_last_name">Last name:</label> ' '<input type="text" name="last_name" ' 'value="\u0160\u0110\u0106\u017d\u0107\u017e\u0161\u0111" id="id_last_name" required /></li>\n' '<li><label for="id_birthday">Birthday:</label> ' '<input type="text" name="birthday" value="1940-10-9" id="id_birthday" required /></li>' ) self.assertHTMLEqual( p.as_p(), '<p><label for="id_first_name">First name:</label> ' '<input type="text" name="first_name" value="John" id="id_first_name" required /></p>\n' '<p><label for="id_last_name">Last name:</label> ' '<input type="text" name="last_name" ' 'value="\u0160\u0110\u0106\u017d\u0107\u017e\u0161\u0111" id="id_last_name" required /></p>\n' '<p><label for="id_birthday">Birthday:</label> ' '<input type="text" name="birthday" value="1940-10-9" id="id_birthday" required /></p>' )
data = { 'first_name': 'John', 'last_name': 'Lennon', 'birthday': '1940-10-9', 'extra1': 'hello', 'extra2': 'hello', } p = Person(data) self.assertTrue(p.is_valid()) self.assertEqual(p.cleaned_data['first_name'], 'John') self.assertEqual(p.cleaned_data['last_name'], 'Lennon') self.assertEqual(p.cleaned_data['birthday'], datetime.date(1940, 10, 9))
class OptionalPersonForm(Form): first_name = CharField() last_name = CharField() nick_name = CharField(required=False)
class OptionalPersonForm(Form): first_name = CharField() last_name = CharField() birth_date = DateField(required=False)
f = SignupForm({'email': 'test@example.com', 'get_spam': 'True'}, auto_id=False) self.assertHTMLEqual( str(f['get_spam']), '<input checked="checked" type="checkbox" name="get_spam" required />', )
f = SignupForm({'email': 'test@example.com', 'get_spam': 'False'}, auto_id=False) self.assertHTMLEqual(str(f['get_spam']), '<input type="checkbox" name="get_spam" required />')
f = SignupForm({'email': 'test@example.com', 'get_spam': '0'}) self.assertTrue(f.is_valid()) self.assertTrue(f.cleaned_data.get('get_spam'))
class ContactForm(Form): subject = CharField() message = CharField(widget=Textarea)
self.assertHTMLEqual( f['subject'].as_textarea(), '<textarea name="subject" rows="10" cols="40" required></textarea>', ) self.assertHTMLEqual(f['message'].as_text(), '<input type="text" name="message" required />') self.assertHTMLEqual(f['message'].as_hidden(), '<input type="hidden" name="message" />')
class ContactForm(Form): subject = CharField() message = CharField(widget=Textarea(attrs={'rows': 80, 'cols': 20}))
self.assertHTMLEqual(f['message'].as_text(), '<input type="text" name="message" required />') f = ContactForm({'subject': 'Hello', 'message': 'I love you.'}, auto_id=False) self.assertHTMLEqual( f['subject'].as_textarea(), '<textarea rows="10" cols="40" name="subject" required>Hello</textarea>' ) self.assertHTMLEqual( f['message'].as_text(), '<input type="text" name="message" value="I love you." required />', ) self.assertHTMLEqual(f['message'].as_hidden(), '<input type="hidden" name="message" value="I love you." />')
class FrameworkForm(Form): name = CharField() language = ChoiceField(choices=[('P', 'Python'), ('J', 'Java')])
class FrameworkForm(Form): name = CharField() language = ChoiceField(choices=[('', '------'), ('P', 'Python'), ('J', 'Java')])
class FrameworkForm(Form): name = CharField() language = ChoiceField(choices=[('P', 'Python'), ('J', 'Java')], widget=Select(attrs={'class': 'foo'}))
class FrameworkForm(Form): name = CharField() language = ChoiceField( choices=[('P', 'Python'), ('J', 'Java')], widget=Select(choices=[('R', 'Ruby'), ('P', 'Perl')], attrs={'class': 'foo'}), )
class FrameworkForm(Form): name = CharField() language = ChoiceField()
class FrameworkForm(Form): name = CharField() language = ChoiceField(choices=[('P', 'Python'), ('J', 'Java')], widget=RadioSelect)
class BeatleForm(Form): name = CharField()
class SongForm(Form): name = CharField() composers = MultipleChoiceField()
f1 = PersonForm({'name': 'John Doe'}, initial={'birthday': datetime.date(1974, 8, 16)}) f2 = PersonFormFieldInitial({'name': 'John Doe'}) for form in (f1, f2): self.assertTrue(form.is_valid()) self.assertEqual( form.cleaned_data, {'birthday': datetime.date(1974, 8, 16), 'name': 'John Doe'} )
data = {'name': 'John Doe', 'birthday': '1984-11-10'} f1 = PersonForm(data, initial={'birthday': datetime.date(1974, 8, 16)}) f2 = PersonFormFieldInitial(data) for form in (f1, f2): self.assertTrue(form.is_valid()) self.assertEqual( form.cleaned_data, {'birthday': datetime.date(1974, 8, 16), 'name': 'John Doe'} )
data = {} f1 = PersonForm(data, initial={'birthday': datetime.date(1974, 8, 16)}) f2 = PersonFormFieldInitial(data) for form in (f1, f2): self.assertFalse(form.is_valid()) self.assertEqual(form['birthday'].value(), datetime.date(1974, 8, 16))
class MessageForm(Form): when = SplitDateTimeField()
class SongForm(Form): name = CharField() composers = MultipleChoiceField( choices=[('J', 'John Lennon'), ('P', 'Paul McCartney')], widget=CheckboxSelectMultiple, )
class SongForm(Form): name = CharField() composers = MultipleChoiceField( choices=[('J', 'John Lennon'), ('P', 'Paul McCartney')], widget=CheckboxSelectMultiple, )
class SongForm(Form): name = CharField() composers = MultipleChoiceField( choices=[('J', 'John Lennon'), ('P', 'Paul McCartney')], widget=CheckboxSelectMultiple, )
class SongFormHidden(Form): name = CharField() composers = MultipleChoiceField( choices=[('J', 'John Lennon'), ('P', 'Paul McCartney')], widget=MultipleHiddenInput, )
f = SongForm({'name': 'Yesterday'}, auto_id=False) self.assertEqual(f.errors['composers'], ['This field is required.']) f = SongForm({'name': 'Yesterday', 'composers': ['J']}, auto_id=False) self.assertEqual(f.errors, {}) self.assertEqual(f.cleaned_data['composers'], ['J']) self.assertEqual(f.cleaned_data['name'], 'Yesterday') f = SongForm({'name': 'Yesterday', 'composers': ['J', 'P']}, auto_id=False) self.assertEqual(f.errors, {}) self.assertEqual(f.cleaned_data['composers'], ['J', 'P']) self.assertEqual(f.cleaned_data['name'], 'Yesterday')
class EscapingForm(Form): special_name = CharField(label="<em>Special</em> Field") special_safe_name = CharField(label=mark_safe("<em>Special</em> Field"))
class UserRegistration(Form): username = CharField(max_length=10) password1 = CharField(widget=PasswordInput) password2 = CharField(widget=PasswordInput)
class UserRegistration(Form): username = CharField(max_length=10) password1 = CharField(widget=PasswordInput) password2 = CharField(widget=PasswordInput)
if (self.cleaned_data.get('password1') and self.cleaned_data.get('password2') and self.cleaned_data['password1'] != self.cleaned_data['password2']): raise ValidationError('Please make sure your passwords match.')
errors = {} if self.cleaned_data.get('password1') == 'FORBIDDEN_VALUE': errors['password1'] = 'Forbidden value.' if self.cleaned_data.get('password2') == 'FORBIDDEN_VALUE': errors['password2'] = ['Forbidden value.'] if errors: raise ValidationError(errors)
if self.cleaned_data.get('password1') == 'FORBIDDEN_VALUE2': self.add_error(None, 'Non-field error 1.') self.add_error('password1', 'Forbidden value 2.') if self.cleaned_data.get('password2') == 'FORBIDDEN_VALUE2': self.add_error('password2', 'Forbidden value 2.') raise ValidationError('Non-field error 2.')
for field, error_list in self._errors.items(): if not isinstance(error_list, self.error_class): self._errors[field] = self.error_class(error_list)
self.assertFalse(form.is_valid())
self.assertIsInstance(form._errors, forms.ErrorDict)
class Person(Form): first_name = CharField() last_name = CharField()
class MyForm(Form): def __init__(self, data=None, auto_id=False, field_list=[]): Form.__init__(self, data, auto_id=auto_id)
class Person(Form): first_name = CharField(required=False) last_name = CharField(required=False)
class Person(Form): first_name = CharField(required=False) last_name = CharField(required=False) gender = ChoiceField(choices=(('f', 'Female'), ('m', 'Male')))
class Person(Form): first_name = CharField() last_name = CharField() hidden_text = CharField(widget=HiddenInput) birthday = DateField()
class TestForm(Form): foo = CharField(widget=HiddenInput) bar = CharField(widget=HiddenInput)
class TestForm(Form): field1 = CharField() field2 = CharField() field3 = CharField() field4 = CharField() field5 = CharField() field6 = CharField() field7 = CharField() field8 = CharField() field9 = CharField() field10 = CharField() field11 = CharField() field12 = CharField() field13 = CharField() field14 = CharField()
class UserRegistration(Form):
class UserRegistration(Form): username = CharField(max_length=10, widget=TextInput(attrs={'maxlength': 20})) password = CharField(max_length=10, widget=PasswordInput)
class UserRegistration(Form): username = CharField(max_length=10, label='Your username') password1 = CharField(widget=PasswordInput) password2 = CharField(widget=PasswordInput, label='Contrasea (de nuevo)')
class Questions(Form): q1 = CharField(label='The first question') q2 = CharField(label='What is your name?') q3 = CharField(label='The answer to life is:') q4 = CharField(label='Answer this question!') q5 = CharField(label='The last question. Period.')
class UserRegistration(Form): username = CharField(max_length=10, label='') password = CharField(widget=PasswordInput)
class UserRegistration(Form): username = CharField(max_length=10, label=None) password = CharField(widget=PasswordInput)
class FavoriteForm(Form): color = CharField(label='Favorite color?') animal = CharField(label='Favorite animal') answer = CharField(label='Secret answer', label_suffix=' =')
class UserRegistration(Form): username = CharField(max_length=10, initial='django') password = CharField(widget=PasswordInput)
p = UserRegistration({'password': 'secret'}) self.assertEqual(p.errors['username'], ['This field is required.']) self.assertFalse(p.is_valid())
class UserRegistration(Form): username = CharField(max_length=10) password = CharField(widget=PasswordInput)
p = UserRegistration({'password': 'secret'}, initial={'username': 'django'}) self.assertEqual(p.errors['username'], ['This field is required.']) self.assertFalse(p.is_valid())
class UserRegistration(Form): username = CharField(max_length=10, initial='django') password = CharField(widget=PasswordInput)
class UserRegistration(Form): username = CharField(max_length=10) password = CharField(widget=PasswordInput) options = MultipleChoiceField(choices=[('f', 'foo'), ('b', 'bar'), ('w', 'whiz')])
def initial_django(): return 'django'
p = UserRegistration({'password': 'secret'}, initial={'username': initial_django, 'options': initial_options}) self.assertEqual(p.errors['username'], ['This field is required.']) self.assertFalse(p.is_valid())
class UserRegistration(Form): username = CharField(max_length=10, initial=initial_django) password = CharField(widget=PasswordInput) options = MultipleChoiceField( choices=[('f', 'foo'), ('b', 'bar'), ('w', 'whiz')], initial=initial_other_options, )
class PedanticField(forms.Field): def to_python(self, value): raise ValidationError('Whatever')
self.assertIs(form['name'], name)
now_no_ms = now.replace(microsecond=0) if now == now_no_ms: now = now.replace(microsecond=1)
class UserRegistration(Form): username = CharField(max_length=10, help_text='e.g., user@example.com') password = CharField(widget=PasswordInput, help_text='Whlen Sie mit Bedacht.')
class UserRegistration(Form): username = CharField(max_length=10, help_text='e.g., user@example.com') password = CharField(widget=PasswordInput) next = CharField(widget=HiddenInput, initial='/', help_text='Redirect destination')
class Person(Form): first_name = CharField() last_name = CharField() birthday = DateField()
class Person(Form): first_name = CharField() last_name = CharField() birthday = DateField()
class Person(Form): first_name = CharField() last_name = CharField() birthday = DateField()
data = { 'person1-first_name': '', 'person1-last_name': '', 'person1-birthday': '' } p = Person(data, prefix='person1') self.assertEqual(p.errors['first_name'], ['This field is required.']) self.assertEqual(p.errors['last_name'], ['This field is required.']) self.assertEqual(p.errors['birthday'], ['This field is required.']) self.assertEqual(p['first_name'].errors, ['This field is required.']) try: p['person1-first_name'].errors self.fail('Attempts to access non-existent fields should fail.') except KeyError: pass
data = { 'first_name': 'John', 'last_name': 'Lennon', 'birthday': '1940-10-9' } p = Person(data, prefix='person1') self.assertEqual(p.errors['first_name'], ['This field is required.']) self.assertEqual(p.errors['last_name'], ['This field is required.']) self.assertEqual(p.errors['birthday'], ['This field is required.'])
data = { 'person1-first_name': 'John', 'person1-last_name': 'Lennon', 'person1-birthday': '1940-10-9', 'person2-first_name': 'Jim', 'person2-last_name': 'Morrison', 'person2-birthday': '1943-12-8' } p1 = Person(data, prefix='person1') self.assertTrue(p1.is_valid()) self.assertEqual(p1.cleaned_data['first_name'], 'John') self.assertEqual(p1.cleaned_data['last_name'], 'Lennon') self.assertEqual(p1.cleaned_data['birthday'], datetime.date(1940, 10, 9)) p2 = Person(data, prefix='person2') self.assertTrue(p2.is_valid()) self.assertEqual(p2.cleaned_data['first_name'], 'Jim') self.assertEqual(p2.cleaned_data['last_name'], 'Morrison') self.assertEqual(p2.cleaned_data['birthday'], datetime.date(1943, 12, 8))
class Person(Form): first_name = CharField() last_name = CharField() birthday = DateField()
class Person(Form): first_name = CharField() prefix = 'foo'
class Person(Form): name = CharField() is_cool = NullBooleanField()
class FileForm(Form): file1 = FileField()
self.assertEqual( my_function('POST', {'username': 'adrian', 'password1': 'secret', 'password2': 'secret'}), str_prefix( "VALID: [('password1', %(_)s'secret'), ('password2', %(_)s'secret'), ('username', %(_)s'adrian')]" ) )
class SongForm(Form): artist = CharField() name = CharField()
data = {'artist': '', 'song': ''} form = SongForm(data, empty_permitted=False) self.assertFalse(form.is_valid()) self.assertEqual(form.errors, {'name': ['This field is required.'], 'artist': ['This field is required.']}) self.assertEqual(form.cleaned_data, {})
form = SongForm(data, empty_permitted=True) self.assertTrue(form.is_valid()) self.assertEqual(form.errors, {}) self.assertEqual(form.cleaned_data, {})
data = {'artist': 'The Doors', 'song': ''} form = SongForm(data, empty_permitted=False) self.assertFalse(form.is_valid()) self.assertEqual(form.errors, {'name': ['This field is required.']}) self.assertEqual(form.cleaned_data, {'artist': 'The Doors'})
data = {'artist': None, 'song': ''} form = SongForm(data, empty_permitted=True) self.assertTrue(form.is_valid())
class PriceForm(Form): amount = FloatField() qty = IntegerField()
f = PhoneField() with self.assertRaisesMessage(ValidationError, "'This field is required.'"): f.clean('') with self.assertRaisesMessage(ValidationError, "'This field is required.'"): f.clean(None) with self.assertRaisesMessage(ValidationError, "'This field is required.'"): f.clean([]) with self.assertRaisesMessage(ValidationError, "'This field is required.'"): f.clean(['+61']) with self.assertRaisesMessage(ValidationError, "'This field is required.'"): f.clean(['+61', '287654321', '123']) self.assertEqual('+61.287654321 ext. 123 (label: Home)', f.clean(['+61', '287654321', '123', 'Home'])) with self.assertRaisesMessage(ValidationError, "'Enter a valid country code.'"): f.clean(['61', '287654321', '123', 'Home'])
f = PhoneField(required=False) self.assertIsNone(f.clean('')) self.assertIsNone(f.clean(None)) self.assertIsNone(f.clean([])) self.assertEqual('+61. ext. (label: )', f.clean(['+61'])) self.assertEqual('+61.287654321 ext. 123 (label: )', f.clean(['+61', '287654321', '123'])) self.assertEqual('+61.287654321 ext. 123 (label: Home)', f.clean(['+61', '287654321', '123', 'Home'])) with self.assertRaisesMessage(ValidationError, "'Enter a valid country code.'"): f.clean(['61', '287654321', '123', 'Home'])
f = PhoneField(require_all_fields=False) with self.assertRaisesMessage(ValidationError, "'This field is required.'"): f.clean('') with self.assertRaisesMessage(ValidationError, "'This field is required.'"): f.clean(None) with self.assertRaisesMessage(ValidationError, "'This field is required.'"): f.clean([]) with self.assertRaisesMessage(ValidationError, "'Enter a complete value.'"): f.clean(['+61']) self.assertEqual('+61.287654321 ext. 123 (label: )', f.clean(['+61', '287654321', '123'])) six.assertRaisesRegex( self, ValidationError, "'Enter a complete value\.', u?'Enter an extension\.'", f.clean, ['', '', '', 'Home'] ) with self.assertRaisesMessage(ValidationError, "'Enter a valid country code.'"): f.clean(['61', '287654321', '123', 'Home'])
f = PhoneField(required=False, require_all_fields=False) self.assertIsNone(f.clean('')) self.assertIsNone(f.clean(None)) self.assertIsNone(f.clean([])) with self.assertRaisesMessage(ValidationError, "'Enter a complete value.'"): f.clean(['+61']) self.assertEqual('+61.287654321 ext. 123 (label: )', f.clean(['+61', '287654321', '123'])) six.assertRaisesRegex( self, ValidationError, "'Enter a complete value\.', u?'Enter an extension\.'", f.clean, ['', '', '', 'Home'] ) with self.assertRaisesMessage(ValidationError, "'Enter a valid country code.'"): f.clean(['61', '287654321', '123', 'Home'])
if value == '{}': return {} return super(CustomJSONField, self).to_python(value)
((), {}, '<label for="id_field">Field:</label>'),
(('custom',), {}, '<label for="id_field">custom:</label>'),
(('custom&',), {}, '<label for="id_field">custom&amp;:</label>'), ((mark_safe('custom&'),), {}, '<label for="id_field">custom&:</label>'),
((), {'attrs': {'class': 'pretty'}}, '<label for="id_field" class="pretty">Field:</label>')
return { 'username': data['username'].lower(), 'password': 'this_is_not_a_secret', }
from __future__ import unicode_literals
self.assertHTMLEqual( str(ErrorList(ValidationError("There was an error.").messages)), '<ul class="errorlist"><li>There was an error.</li></ul>' ) self.assertHTMLEqual( six.text_type(ErrorList(ValidationError("Not \u03C0.").messages)), '<ul class="errorlist"><li>Not .</li></ul>' ) self.assertHTMLEqual( str(ErrorList(ValidationError(ugettext_lazy("Error.")).messages)), '<ul class="errorlist"><li>Error.</li></ul>' ) self.assertHTMLEqual( str(ErrorList(ValidationError(["Error one.", "Error two."]).messages)), '<ul class="errorlist"><li>Error one.</li><li>Error two.</li></ul>' ) self.assertHTMLEqual( str(ErrorList(sorted(ValidationError({'error_1': "1. Error one.", 'error_2': "2. Error two."}).messages))), '<ul class="errorlist"><li>1. Error one.</li><li>2. Error two.</li></ul>' ) self.assertHTMLEqual( str(ErrorList(sorted(ValidationError([ "1. First error.", "2. Not \u03C0.", ugettext_lazy("3. Error."), { 'error_1': "4. First dict error.", 'error_2': "5. Second dict error.", }, ]).messages))), '<ul class="errorlist">' '<li>1. First error.</li>' '<li>2. Not .</li>' '<li>3. Error.</li>' '<li>4. First dict error.</li>' '<li>5. Second dict error.</li>' '</ul>' )
self.assertHTMLEqual( str(ErrorList(ValidationError(VeryBadError()).messages)), '<ul class="errorlist"><li>A very bad error.</li></ul>' )
example = 'Example of link: <a href="http://www.example.com/">example</a>' self.assertHTMLEqual( str(ErrorList([example])), '<ul class="errorlist"><li>Example of link: ' '&lt;a href=&quot;http://www.example.com/&quot;&gt;example&lt;/a&gt;</li></ul>' ) self.assertHTMLEqual( str(ErrorList([mark_safe(example)])), '<ul class="errorlist"><li>Example of link: ' '<a href="http://www.example.com/">example</a></li></ul>' ) self.assertHTMLEqual( str(ErrorDict({'name': example})), '<ul class="errorlist"><li>nameExample of link: ' '&lt;a href=&quot;http://www.example.com/&quot;&gt;example&lt;/a&gt;</li></ul>' ) self.assertHTMLEqual( str(ErrorDict({'name': mark_safe(example)})), '<ul class="errorlist"><li>nameExample of link: ' '<a href="http://www.example.com/">example</a></li></ul>' )
from django.forms import CharField, Form, Media, MultiWidget, TextInput from django.template import Context, Template from django.test import SimpleTestCase, override_settings from django.utils.encoding import force_text
class MyWidget(TextInput): pass
class MyWidget1(TextInput): class Media: css = { 'all': ('path/to/css1', '/path/to/css2') } js = ('/path/to/js1', 'http://media.other.com/path/to/js2', 'https://secure.other.com/path/to/js3')
class MyWidget1(TextInput): class Media: css = { 'all': ('path/to/css1', '/path/to/css2') } js = ('/path/to/js1', 'http://media.other.com/path/to/js2', 'https://secure.other.com/path/to/js3')
class MyWidget4(TextInput): class Media: css = {'all': ('/path/to/css1', '/path/to/css1')} js = ('/path/to/js1', '/path/to/js1')
class MyWidget4(TextInput): def _media(self): return Media(css={'all': ('/some/path',)}, js=('/some/js',)) media = property(_media)
class MyWidget5(MyWidget4): def _media(self): return super(MyWidget5, self).media + Media(css={'all': ('/other/path',)}, js=('/other/js',)) media = property(_media)
class MyWidget1(TextInput): class Media: css = { 'all': ('path/to/css1', '/path/to/css2') } js = ('/path/to/js1', 'http://media.other.com/path/to/js2', 'https://secure.other.com/path/to/js3')
class MyWidget1(TextInput): class Media: css = { 'all': ('path/to/css1', '/path/to/css2') } js = ('/path/to/js1', 'http://media.other.com/path/to/js2', 'https://secure.other.com/path/to/js3')
class MyWidget8(MyWidget1): class Media: css = { 'all': ('/path/to/css3', 'path/to/css1') } js = ('/path/to/js1', '/path/to/js4')
class MyWidget1(TextInput): class Media: css = { 'all': ('path/to/css1', '/path/to/css2') } js = ('/path/to/js1', 'http://media.other.com/path/to/js2', 'https://secure.other.com/path/to/js3')
class MyWidget10(MyWidget1): class Media: extend = False css = { 'all': ('/path/to/css3', 'path/to/css1') } js = ('/path/to/js1', '/path/to/js4')
class MyWidget1(TextInput): class Media: css = { 'all': ('path/to/css1', '/path/to/css2') } js = ('/path/to/js1', 'http://media.other.com/path/to/js2', 'https://secure.other.com/path/to/js3')
class MyWidget1(TextInput): class Media: css = { 'all': ('path/to/css1', '/path/to/css2') } js = ('/path/to/js1', 'http://media.other.com/path/to/js2', 'https://secure.other.com/path/to/js3')
class MultimediaWidget(TextInput): class Media: css = { 'screen, print': ('/file1', '/file2'), 'screen': ('/file3',), 'print': ('/file4',) } js = ('/path/to/js1', '/path/to/js4')
class MyMultiWidget(MultiWidget): def __init__(self, attrs=None): widgets = [MyWidget1, MyWidget2, MyWidget3] super(MyMultiWidget, self).__init__(widgets, attrs)
class FormWithMedia(Form): field1 = CharField(max_length=20, widget=MyWidget1()) field2 = CharField(max_length=20, widget=MyWidget2())
manager1 = OnlyFred() manager2 = OnlyBarney() objects = models.Manager()
restricted = Value42()
class AbstractBase3(models.Model): comment = models.CharField(max_length=50)
@python_2_unicode_compatible class Child1(AbstractBase1): data = models.CharField(max_length=25)
default = models.Manager()
@python_2_unicode_compatible class RelatedModel(models.Model): test_gfk = GenericRelation('RelationModel', content_type_field='gfk_ctype', object_id_field='gfk_id') exact = models.NullBooleanField()
self.assertQuerysetEqual(Child4._default_manager.order_by('data'), [ "<Child4: d1>", "<Child4: d2>", "<Child4: f1>", "<Child4: f2>", ]) self.assertQuerysetEqual(Child4.manager1.all(), ["<Child4: d1>", "<Child4: f1>"], ordered=False) self.assertQuerysetEqual(Child5._default_manager.all(), ["<Child5: fred>"]) self.assertQuerysetEqual(Child6._default_manager.all(), ["<Child6: f1>", "<Child6: f2>"], ordered=False) self.assertQuerysetEqual( Child7._default_manager.order_by('name'), ["<Child7: barney>", "<Child7: fred>"] )
msg = "type object 'AbstractBase3' has no attribute 'objects'" with self.assertRaisesMessage(AttributeError, msg): AbstractBase3.objects.all()
msg = "Manager isn't available; AbstractBase2 is abstract" with self.assertRaisesMessage(AttributeError, msg): AbstractBase2.restricted.all()
msg = "Manager isn't available; AbstractBase1 is abstract" with self.assertRaisesMessage(AttributeError, msg): AbstractBase1.objects.all()
msg = ( "Manager isn't available; 'managers_regress.SwappableModel' " "has been swapped for 'managers_regress.Parent'" ) with self.assertRaisesMessage(AttributeError, msg): SwappableModel.objects.all()
msg = ( "Manager isn't available; 'managers_regress.SwappableModel' " "has been swapped for 'managers_regress.Parent'" ) with self.assertRaisesMessage(AttributeError, msg): SwappableModel.stuff.all()
msg = ( "Manager isn't available; 'managers_regress.SwappableModel' " "has been swapped for 'managers_regress.Parent'" ) with self.assertRaisesMessage(AttributeError, msg): SwappableModel.objects.all()
related = RelatedModel.objects.create(exact=False) relation = related.test_fk.create() self.assertEqual(related.test_fk.get(), relation)
with warnings.catch_warnings(record=True) as warns: warnings.simplefilter('always', RemovedInDjango20Warning) MyModel._base_manager self.assertEqual(len(warns), 0)
class MyModel2(models.Model): objects = MyManager()
class MyRelModel2(models.Model): objects = MyManager()
class MyRelModel2(models.Model): objects = MyManager()
with warnings.catch_warnings(record=True) as warns: warnings.simplefilter('always', RemovedInDjango20Warning)
with warnings.catch_warnings(record=True) as warns: warnings.simplefilter('always', RemovedInDjango20Warning)
class MyModel3(ConcreteParentWithManager): default = models.Manager() self.assertIs(MyModel3.default, MyModel3._default_manager) self.assertIsNone(getattr(MyModel3, 'objects', None))
class MyModel4(AbstractParent, ConcreteParentWithManager): pass self.assertIs(MyModel4.default, MyModel4._default_manager) self.assertIsNone(getattr(MyModel4, 'objects', None))
class MyModel5(ConcreteParentWithManager): class Meta: manager_inheritance_from_future = True self.assertIs(MyModel5.default, MyModel5._default_manager) self.assertIsNone(getattr(MyModel5, 'objects', None))
ver_string = get_version(ver_tuple) six.assertRegex(self, ver_string, r'1\.4(\.dev[0-9]+)?')
c.value = 2 c.save() c.value = 3 c.save(force_update=True)
c.value = 4 with self.assertRaises(ValueError): c.save(force_insert=True, force_update=True)
c1 = Counter(name="two", value=2) with self.assertRaises(ValueError): with transaction.atomic(): c1.save(force_update=True) c1.save(force_insert=True)
c.value = 5 with self.assertRaises(IntegrityError): with transaction.atomic(): c.save(force_insert=True)
obj = WithCustomPK(name=1, value=1) with self.assertRaises(DatabaseError): with transaction.atomic(): obj.save(force_update=True)
book, created = p.books.get_or_create(name="The Book of Ed & Fred") self.assertTrue(created) self.assertEqual(p.books.count(), 1)
book, created = p.books.get_or_create(name="The Book of Ed & Fred") self.assertFalse(created) self.assertEqual(p.books.count(), 1)
ed, created = book.authors.get_or_create(name="Ed") self.assertTrue(created) self.assertEqual(book.authors.count(), 1)
ed, created = book.authors.get_or_create(name="Ed") self.assertFalse(created) self.assertEqual(book.authors.count(), 1)
fred, created = book.authors.get_or_create(name="Fred") self.assertTrue(created)
self.assertEqual(book.authors.count(), 2)
Author.objects.create(name="Ted")
self.assertEqual(Author.objects.count(), 3) self.assertEqual(book.authors.count(), 2)
_, created = ed.books.get_or_create(name="Ed's Recipes", publisher=p) self.assertTrue(created)
self.assertEqual(ed.books.count(), 2) self.assertEqual(fred.books.count(), 1)
_, created = ed.books.get_or_create(name='The Great Book of Ed', publisher_id=p.id) self.assertTrue(created)
_, created = ed.books.get_or_create(name='The Great Book of Ed', publisher_id=p.id) self.assertFalse(created)
self.assertEqual(p.books.count(), 3)
p, created = Person.objects.update_or_create(**params) self.assertFalse(created)
url(r'^\$', include([ url(r'^bar/$', lambda x: x, name='bar'), ])),
from __future__ import unicode_literals
from __future__ import unicode_literals
registry = CheckRegistry() registry.register()(f) registry.register("tag1", "tag2")(f2) registry.register("tag2", deploy=True)(f3)
registry2 = CheckRegistry() registry2.register(f) registry2.register(f2, "tag1", "tag2") registry2.register(f3, "tag2", deploy=True)
errors = registry.run_checks() errors2 = registry2.run_checks() self.assertEqual(errors, errors2) self.assertEqual(sorted(errors), [1, 2, 3, 4]) self.assertEqual(calls[0], 2)
result = self.func(None) self.assertEqual(len(result), 2) self.assertEqual([r.id for r in result], ['mysql.W002', 'mysql.W002'])
result = check_url_config(None) self.assertEqual(len(result), 1) warning = result[0] self.assertEqual(warning.id, 'urls.W001')
from django.db import models from django.utils.encoding import python_2_unicode_compatible
self.assertEqual( Publisher.objects.aggregate(Avg('duration', output_field=DurationField())), {'duration__avg': datetime.timedelta(days=1, hours=12)} ) self.assertEqual( Publisher.objects.aggregate(Avg('duration')), {'duration__avg': datetime.timedelta(days=1, hours=12)} )
age_sum = distinct_authors.aggregate(Sum('age')) self.assertEqual(age_sum['age__sum'], 103)
max_rating = Book.objects.values('rating').aggregate(max_rating=Max('rating')) self.assertEqual(max_rating['max_rating'], 5) max_books_per_rating = Book.objects.values('rating').annotate( books_per_rating=Count('id') ).aggregate(Max('books_per_rating')) self.assertEqual( max_books_per_rating, {'books_per_rating__max': 3})
excluded_books = annotated_books.exclude(publisher__name="__UNLIKELY_VALUE__")
str(excluded_books.query)
self.assertIsNone(annotated_books.query.alias_map["aggregation_book"].join_type) self.assertIsNone(excluded_books.query.alias_map["aggregation_book"].join_type)
self.assertEqual( re.findall(r'order by (\w+)', qstr), [', '.join(f[1][0] for f in forced_ordering).lower()] )
qs = Author.objects.values('name').annotate(another_age=Sum('age') + F('age')) a = qs.get(name="Adrian Holovaty") self.assertEqual(a['another_age'], 68)
def lower_case_function_override(self, compiler, connection): sql, params = compiler.compile(self.source_expressions[0]) substitutions = dict(function=self.function.lower(), expressions=sql) substitutions.update(self.extra) return self.template % substitutions, params setattr(MySum, 'as_' + connection.vendor, lower_case_function_override)
def lower_case_function_super(self, compiler, connection): self.extra['function'] = self.function.lower() return super(MySum, self).as_sql(compiler, connection) setattr(MySum, 'as_' + connection.vendor, lower_case_function_super)
def be_evil(self, compiler, connection): substitutions = dict(function='MAX', expressions='2') substitutions.update(self.extra) return self.template % substitutions, () setattr(MySum, 'as_' + connection.vendor, be_evil)
class Greatest(Func): function = 'GREATEST'
form = Form() form_set = FormSet(instance=User())
data = { 'serial': '1', 'username': 'apollo13', 'usersite_set-TOTAL_FORMS': '1', 'usersite_set-INITIAL_FORMS': '0', 'usersite_set-MAX_NUM_FORMS': '0', 'usersite_set-0-data': '10', 'usersite_set-0-user': 'apollo13' } user = User() form = Form(data) if form.is_valid(): user = form.save() else: self.fail('Errors found on form:%s' % form_set)
data = { 'usersite_set-TOTAL_FORMS': '1', 'usersite_set-INITIAL_FORMS': '1', 'usersite_set-MAX_NUM_FORMS': '0', 'usersite_set-0-id': six.text_type(usersite[0]['id']), 'usersite_set-0-data': '11', 'usersite_set-0-user': 'apollo13' } form_set = FormSet(data, instance=user) if form_set.is_valid(): form_set.save() usersite = UserSite.objects.all().values() self.assertEqual(usersite[0]['data'], 11) self.assertEqual(usersite[0]['user_id'], 'apollo13') else: self.fail('Errors found on formset:%s' % form_set.errors)
data = { 'usersite_set-TOTAL_FORMS': '2', 'usersite_set-INITIAL_FORMS': '1', 'usersite_set-MAX_NUM_FORMS': '0', 'usersite_set-0-id': six.text_type(usersite[0]['id']), 'usersite_set-0-data': '11', 'usersite_set-0-user': 'apollo13', 'usersite_set-1-data': '42', 'usersite_set-1-user': 'apollo13' } form_set = FormSet(data, instance=user) if form_set.is_valid(): form_set.save() usersite = UserSite.objects.all().values().order_by('data') self.assertEqual(usersite[0]['data'], 11) self.assertEqual(usersite[0]['user_id'], 'apollo13') self.assertEqual(usersite[1]['data'], 42) self.assertEqual(usersite[1]['user_id'], 'apollo13') else: self.fail('Errors found on formset:%s' % form_set.errors)
form = Form() form_set = FormSet(instance=Restaurant())
data = { 'name': "Guido's House of Pasta", 'manager_set-TOTAL_FORMS': '1', 'manager_set-INITIAL_FORMS': '0', 'manager_set-MAX_NUM_FORMS': '0', 'manager_set-0-name': 'Guido Van Rossum' } restaurant = User() form = Form(data) if form.is_valid(): restaurant = form.save() else: self.fail('Errors found on form:%s' % form_set)
data = { 'manager_set-TOTAL_FORMS': '1', 'manager_set-INITIAL_FORMS': '1', 'manager_set-MAX_NUM_FORMS': '0', 'manager_set-0-id': six.text_type(manager[0]['id']), 'manager_set-0-name': 'Terry Gilliam' } form_set = FormSet(data, instance=restaurant) if form_set.is_valid(): form_set.save() manager = Manager.objects.all().values() self.assertEqual(manager[0]['name'], 'Terry Gilliam') else: self.fail('Errors found on formset:%s' % form_set.errors)
data = { 'manager_set-TOTAL_FORMS': '2', 'manager_set-INITIAL_FORMS': '1', 'manager_set-MAX_NUM_FORMS': '0', 'manager_set-0-id': six.text_type(manager[0]['id']), 'manager_set-0-name': 'Terry Gilliam', 'manager_set-1-name': 'John Cleese' } form_set = FormSet(data, instance=restaurant) if form_set.is_valid(): form_set.save() manager = Manager.objects.all().values().order_by('name') self.assertEqual(manager[0]['name'], 'John Cleese') self.assertEqual(manager[1]['name'], 'Terry Gilliam') else: self.fail('Errors found on formset:%s' % form_set.errors)
self.assertEqual(formset[0].instance.user_id, "guido")
self.assertEqual(formset[0].instance.profile_id, 1)
Form(instance=None) FormSet(instance=None)
data = { 'host_set-TOTAL_FORMS': '2', 'host_set-INITIAL_FORMS': '1', 'host_set-MAX_NUM_FORMS': '0', 'host_set-0-id': six.text_type(host1.id), 'host_set-0-hostname': 'tranquility.hub.dal.net', 'host_set-1-hostname': 'matrix.de.eu.dal.net' }
dalnet = Network.objects.create(name="DALnet") formset = HostFormSet(data, instance=dalnet, save_as_new=True)
self.assertIsInstance(formset.errors, list) self.assertIsInstance(formset.non_form_errors(), ErrorList) for form in formset.forms: self.assertIsInstance(form.errors, ErrorDict) self.assertIsInstance(form.non_field_errors(), ErrorList)
self.test_init_database()
data = dict(self.data) data['form-INITIAL_FORMS'] = 4 data.update({ 'form-%d-id' % i: user.pk for i, user in enumerate(User.objects.all()) }) formset = self.NormalFormset(data, queryset=User.objects.all()) self.assertTrue(formset.is_valid()) self.assertEqual(len(formset.save()), 0) self.assertEqual(len(User.objects.all()), 4)
self.test_init_database()
data = dict(self.data) data['form-INITIAL_FORMS'] = 4 data.update({ 'form-%d-id' % i: user.pk for i, user in enumerate(User.objects.all()) }) data.update(self.delete_all_ids) formset = self.NormalFormset(data, queryset=User.objects.all()) self.assertTrue(formset.is_valid()) self.assertEqual(len(formset.save()), 0) self.assertEqual(len(User.objects.all()), 0)
self.test_init_database()
data = dict(self.data) data['form-INITIAL_FORMS'] = 4 data.update({ 'form-%d-id' % i: user.pk for i, user in enumerate(User.objects.all()) }) data.update(self.delete_all_ids) formset = self.DeleteFormset(data, queryset=User.objects.all())
self.assertTrue(formset.is_valid()) self.assertEqual(len(formset.save()), 0) self.assertEqual(len(User.objects.all()), 2)
odd_ids = [user.pk for user in User.objects.all() if user.pk % 2] self.assertEqual(len(odd_ids), 0)
self.assertTrue(formset.is_valid()) formset.save() self.assertEqual(UserSite.objects.count(), 0)
self.assertEqual(signer.unsign(ts, max_age=datetime.timedelta(seconds=11)), value) with self.assertRaises(signing.SignatureExpired): signer.unsign(ts, max_age=10)
from __future__ import unicode_literals
file = SimpleUploadedFile("mode_test.txt", b"content") self.assertFalse(hasattr(file, 'mode')) gzip.GzipFile(fileobj=file)
f.DEFAULT_CHUNK_SIZE = 4 self.assertEqual(list(f), [b'one\n', b'two\n', b'three'])
f.DEFAULT_CHUNK_SIZE = 4 self.assertEqual(list(f), [b'one\r\n', b'two\r\n', b'three'])
f.DEFAULT_CHUNK_SIZE = 4 self.assertEqual(list(f), [b'one\r', b'two\r', b'three'])
wrapper.seek(0, 2) wrapper.write(content) wrapper.seek(0) self.assertEqual(wrapper.read(), content * 2) test_file = wrapper.detach() test_file.seek(0) self.assertEqual(test_file.read(), (content * 2).encode('utf-8'))
with self.assertRaises(IOError): file_move_safe(self.file_a, self.file_b, allow_overwrite=False)
self.assertIsNone(file_move_safe(self.file_a, self.file_b, allow_overwrite=True))
('2010-10-12 15:29:22.063202', datetime.datetime(2010, 10, 12, 15, 29, 22, 63202)), ('2010-10-12 15:29:22.063202-03', datetime.datetime(2010, 10, 12, 15, 29, 22, 63202)), ('2010-10-12 15:29:22.063202+04', datetime.datetime(2010, 10, 12, 15, 29, 22, 63202)), ('2010-10-12 15:29:22.0632021', datetime.datetime(2010, 10, 12, 15, 29, 22, 63202)), ('2010-10-12 15:29:22.0632029', datetime.datetime(2010, 10, 12, 15, 29, 22, 63202)),
response_gone_class = http.HttpResponseForbidden response_redirect_class = http.HttpResponseRedirect
class BinaryTree(models.Model): name = models.CharField(max_length=100) parent = models.ForeignKey('self', models.SET_NULL, null=True, blank=True)
class SomeParentModel(models.Model): name = models.CharField(max_length=1)
self.assertContains(response, '<h2>Author-book relationships</h2>') self.assertContains(response, 'Add another Author-book relationship') self.assertContains(response, 'id="id_Author_books-TOTAL_FORMS"')
data = { 'shoppingweakness_set-TOTAL_FORMS': 1, 'shoppingweakness_set-INITIAL_FORMS': 0, 'shoppingweakness_set-MAX_NUM_FORMS': 0, '_save': 'Save', 'person': person.id, 'max_weight': 0, 'shoppingweakness_set-0-item': item.id, } response = self.client.post(reverse('admin:admin_inlines_fashionista_add'), data) self.assertEqual(response.status_code, 302) self.assertEqual(len(Fashionista.objects.filter(person__firstname='Imelda')), 1)
self.assertContains( response, '<tr><td colspan="4"><ul class="errorlist nonfield">' '<li>The two titles must be the same</li></ul></td></tr>' )
response = self.client.get(reverse('admin:admin_inlines_novel_add')) self.assertEqual(response.status_code, 200) self.assertContains( response, '<div class="js-inline-admin-formset inline-group" id="chapter_set-group"' )
self.assertContains( response, '<div class="js-inline-admin-formset inline-group" id="question_set-group"' ) self.assertContains(response, '<p>Callable in QuestionInline</p>')
response = self.client.get(reverse('admin:admin_inlines_capofamiglia_add')) self.assertContains( response, '<img src="/static/admin/img/icon-unknown.svg" ' 'class="help help-tooltip" width="10" height="10" ' 'alt="(Help text for ReadOnlyInline)" ' 'title="Help text for ReadOnlyInline" />', 1 )
max_forms_input = ( '<input id="id_binarytree_set-MAX_NUM_FORMS" ' 'name="binarytree_set-MAX_NUM_FORMS" type="hidden" value="%d" />' ) total_forms_hidden = ( '<input id="id_binarytree_set-TOTAL_FORMS" ' 'name="binarytree_set-TOTAL_FORMS" type="hidden" value="2" />' ) response = self.client.get(reverse('admin:admin_inlines_binarytree_add')) self.assertContains(response, max_forms_input % 3) self.assertContains(response, total_forms_hidden)
permission = Permission.objects.get(codename='add_author', content_type=self.author_ct) self.user.user_permissions.add(permission) permission = Permission.objects.get(codename='change_author', content_type=self.author_ct) self.user.user_permissions.add(permission) permission = Permission.objects.get(codename='add_holder2', content_type=self.holder_ct) self.user.user_permissions.add(permission) permission = Permission.objects.get(codename='change_holder2', content_type=self.holder_ct) self.user.user_permissions.add(permission)
author_book_auto_m2m_intermediate = Author.books.through.objects.get(author=author, book=book) self.author_book_auto_m2m_intermediate_id = author_book_auto_m2m_intermediate.pk
self.assertNotContains(response, '<h2>Author-book relationships</h2>') self.assertNotContains(response, 'Add another Author-Book Relationship') self.assertNotContains(response, 'id="id_Author_books-TOTAL_FORMS"')
self.assertNotContains(response, '<h2>Inner2s</h2>') self.assertNotContains(response, 'Add another Inner2') self.assertNotContains(response, 'id="id_inner2_set-TOTAL_FORMS"')
self.assertNotContains(response, '<h2>Author-book relationships</h2>') self.assertNotContains(response, 'Add another Author-Book Relationship') self.assertNotContains(response, 'id="id_Author_books-TOTAL_FORMS"')
self.assertNotContains(response, '<h2>Inner2s</h2>') self.assertNotContains(response, 'Add another Inner2') self.assertNotContains(response, 'id="id_inner2_set-TOTAL_FORMS"')
self.assertNotContains(response, '<h2>Author-book relationships</h2>') self.assertNotContains(response, 'Add another Author-Book Relationship') self.assertNotContains(response, 'id="id_Author_books-TOTAL_FORMS"')
self.assertContains(response, '<h2>Inner2s</h2>') self.assertContains(response, 'Add another Inner2') self.assertContains(response, '<input type="hidden" id="id_inner2_set-TOTAL_FORMS" ' 'value="3" name="inner2_set-TOTAL_FORMS" />', html=True)
self.assertNotContains(response, '<h2>Author-book relationships</h2>') self.assertNotContains(response, 'Add another Author-Book Relationship') self.assertNotContains(response, 'id="id_Author_books-TOTAL_FORMS"') self.assertNotContains(response, 'id="id_Author_books-0-DELETE"')
self.assertContains(response, '<h2>Author-book relationships</h2>') self.assertContains(response, 'Add another Author-book relationship') self.assertContains(response, '<input type="hidden" id="id_Author_books-TOTAL_FORMS" ' 'value="4" name="Author_books-TOTAL_FORMS" />', html=True) self.assertContains( response, '<input type="hidden" id="id_Author_books-0-id" value="%i" ' 'name="Author_books-0-id" />' % self.author_book_auto_m2m_intermediate_id, html=True ) self.assertContains(response, 'id="id_Author_books-0-DELETE"')
self.assertContains(response, '<h2>Inner2s</h2>') self.assertContains(response, 'Add another Inner2') self.assertContains( response, '<input type="hidden" id="id_inner2_set-TOTAL_FORMS" value="3" ' 'name="inner2_set-TOTAL_FORMS" />', html=True ) self.assertNotContains( response, '<input type="hidden" id="id_inner2_set-0-id" value="%i" name="inner2_set-0-id" />' % self.inner2_id, html=True )
self.assertContains(response, '<h2>Inner2s</h2>') self.assertContains( response, '<input type="hidden" id="id_inner2_set-TOTAL_FORMS" value="1" name="inner2_set-TOTAL_FORMS" />', html=True ) self.assertContains( response, '<input type="hidden" id="id_inner2_set-0-id" value="%i" name="inner2_set-0-id" />' % self.inner2_id, html=True ) self.assertContains( response, '<input type="hidden" id="id_inner2_set-MAX_NUM_FORMS" value="0" name="inner2_set-MAX_NUM_FORMS" />', html=True )
self.assertContains(response, '<h2>Inner2s</h2>') self.assertContains( response, '<input type="hidden" id="id_inner2_set-TOTAL_FORMS" value="4" name="inner2_set-TOTAL_FORMS" />', html=True ) self.assertContains( response, '<input type="hidden" id="id_inner2_set-0-id" value="%i" name="inner2_set-0-id" />' % self.inner2_id, html=True )
self.assertContains(response, '<h2>Inner2s</h2>') self.assertContains( response, '<input type="hidden" id="id_inner2_set-TOTAL_FORMS" value="1" name="inner2_set-TOTAL_FORMS" />', html=True ) self.assertContains( response, '<input type="hidden" id="id_inner2_set-0-id" value="%i" name="inner2_set-0-id" />' % self.inner2_id, html=True ) self.assertContains(response, 'id="id_inner2_set-0-DELETE"')
self.assertContains(response, '<h2>Inner2s</h2>') self.assertContains( response, '<input type="hidden" id="id_inner2_set-TOTAL_FORMS" value="4" name="inner2_set-TOTAL_FORMS" />', html=True ) self.assertContains( response, '<input type="hidden" id="id_inner2_set-0-id" value="%i" name="inner2_set-0-id" />' % self.inner2_id, html=True ) self.assertContains(response, 'id="id_inner2_set-0-DELETE"')
self.assertEqual(len(self.selenium.find_elements_by_css_selector( '.dynamic-profile_set')), 1) self.assertEqual(self.selenium.find_elements_by_css_selector( '.dynamic-profile_set')[0].get_attribute('id'), 'profile_set-0') self.assertEqual(len(self.selenium.find_elements_by_css_selector( '.dynamic-profile_set#profile_set-0 input[name=profile_set-0-first_name]')), 1) self.assertEqual(len(self.selenium.find_elements_by_css_selector( '.dynamic-profile_set#profile_set-0 input[name=profile_set-0-last_name]')), 1)
self.selenium.find_element_by_link_text('Add another Profile').click()
self.assertEqual(len(self.selenium.find_elements_by_css_selector('.dynamic-profile_set')), 2) self.assertEqual(self.selenium.find_elements_by_css_selector( '.dynamic-profile_set')[1].get_attribute('id'), 'profile_set-1') self.assertEqual(len(self.selenium.find_elements_by_css_selector( '.dynamic-profile_set#profile_set-1 input[name=profile_set-1-first_name]')), 1) self.assertEqual(len(self.selenium.find_elements_by_css_selector( '.dynamic-profile_set#profile_set-1 input[name=profile_set-1-last_name]')), 1)
self.selenium.find_element_by_link_text('Add another Profile').click() self.assertEqual(len(self.selenium.find_elements_by_css_selector('.dynamic-profile_set')), 3) self.assertEqual(self.selenium.find_elements_by_css_selector( '.dynamic-profile_set')[2].get_attribute('id'), 'profile_set-2') self.assertEqual(len(self.selenium.find_elements_by_css_selector( '.dynamic-profile_set#profile_set-2 input[name=profile_set-2-first_name]')), 1) self.assertEqual(len(self.selenium.find_elements_by_css_selector( '.dynamic-profile_set#profile_set-2 input[name=profile_set-2-last_name]')), 1)
self.selenium.find_element_by_name('profile_set-0-first_name').send_keys('0 first name 1') self.selenium.find_element_by_name('profile_set-0-last_name').send_keys('0 last name 2') self.selenium.find_element_by_name('profile_set-1-first_name').send_keys('1 first name 1') self.selenium.find_element_by_name('profile_set-1-last_name').send_keys('1 last name 2') self.selenium.find_element_by_name('profile_set-2-first_name').send_keys('2 first name 1') self.selenium.find_element_by_name('profile_set-2-last_name').send_keys('2 last name 2')
self.assertEqual(ProfileCollection.objects.all().count(), 1) self.assertEqual(Profile.objects.all().count(), 3)
self.selenium.find_element_by_link_text('Add another Profile').click() self.selenium.find_element_by_link_text('Add another Profile').click() self.selenium.find_element_by_link_text('Add another Profile').click() self.selenium.find_element_by_link_text('Add another Profile').click() self.assertEqual(len(self.selenium.find_elements_by_css_selector( '#profile_set-group table tr.dynamic-profile_set')), 5) self.assertEqual(len(self.selenium.find_elements_by_css_selector( 'form#profilecollection_form tr.dynamic-profile_set#profile_set-0')), 1) self.assertEqual(len(self.selenium.find_elements_by_css_selector( 'form#profilecollection_form tr.dynamic-profile_set#profile_set-1')), 1) self.assertEqual(len(self.selenium.find_elements_by_css_selector( 'form#profilecollection_form tr.dynamic-profile_set#profile_set-2')), 1) self.assertEqual(len(self.selenium.find_elements_by_css_selector( 'form#profilecollection_form tr.dynamic-profile_set#profile_set-3')), 1) self.assertEqual(len(self.selenium.find_elements_by_css_selector( 'form#profilecollection_form tr.dynamic-profile_set#profile_set-4')), 1)
self.selenium.find_element_by_css_selector( 'form#profilecollection_form tr.dynamic-profile_set#profile_set-1 td.delete a').click() self.selenium.find_element_by_css_selector( 'form#profilecollection_form tr.dynamic-profile_set#profile_set-2 td.delete a').click() self.assertEqual(len(self.selenium.find_elements_by_css_selector( '#profile_set-group table tr.dynamic-profile_set')), 3) self.assertEqual(len(self.selenium.find_elements_by_css_selector( 'form#profilecollection_form tr.dynamic-profile_set#profile_set-0')), 1) self.assertEqual(len(self.selenium.find_elements_by_css_selector( 'form#profilecollection_form tr.dynamic-profile_set#profile_set-1')), 1) self.assertEqual(len(self.selenium.find_elements_by_css_selector( 'form#profilecollection_form tr.dynamic-profile_set#profile_set-2')), 1)
self.selenium.find_element_by_link_text('Add another Profile').click() self.selenium.find_element_by_link_text('Add another Profile').click()
self.admin_login(username='super', password='secret') self.selenium.get(self.live_server_url + reverse('admin:admin_inlines_author_add')) test_fields = ['#id_nonautopkbook_set-0-title', '#id_nonautopkbook_set-2-0-title'] show_links = self.selenium.find_elements_by_link_text('SHOW') self.assertEqual(len(show_links), 2) for show_index, field_name in enumerate(test_fields, 0): self.wait_until_invisible(field_name) show_links[show_index].click() self.wait_until_visible(field_name) hide_links = self.selenium.find_elements_by_link_text('HIDE') self.assertEqual(len(hide_links), 2) for hide_index, field_name in enumerate(test_fields, 0): self.wait_until_visible(field_name) hide_links[hide_index].click() self.wait_until_invisible(field_name)
class ChildModel1Inline(admin.TabularInline): model = ChildModel1
class BinaryTreeAdmin(admin.TabularInline): model = BinaryTree
class SightingInline(admin.TabularInline): model = Sighting
class SomeChildModelForm(forms.ModelForm):
site.register(Holder, HolderAdmin, inlines=[InnerInline]) site.register(Holder2, HolderAdmin, inlines=[InnerInline2]) site.register(Holder3, inlines=[InnerInline3])
('/normal/42/37/', 'normal-view', '', '', 'normal-view', views.empty_view, tuple(), {'arg1': '42', 'arg2': '37'}), ( '/view_class/42/37/', 'view-class', '', '', 'view-class', views.view_class_instance, tuple(), {'arg1': '42', 'arg2': '37'} ), ( '/included/normal/42/37/', 'inc-normal-view', '', '', 'inc-normal-view', views.empty_view, tuple(), {'arg1': '42', 'arg2': '37'} ), ( '/included/view_class/42/37/', 'inc-view-class', '', '', 'inc-view-class', views.view_class_instance, tuple(), {'arg1': '42', 'arg2': '37'} ),
('/mixed_args/42/37/', 'mixed-args', '', '', 'mixed-args', views.empty_view, tuple(), {'arg2': '37'}), ( '/included/mixed_args/42/37/', 'inc-mixed-args', '', '', 'inc-mixed-args', views.empty_view, tuple(), {'arg2': '37'} ), ( '/included/12/mixed_args/42/37/', 'inc-mixed-args', '', '', 'inc-mixed-args', views.empty_view, tuple(), {'arg2': '37'} ),
( '/unnamed/normal/42/37/', None, '', '', 'urlpatterns_reverse.views.empty_view', views.empty_view, tuple(), {'arg1': '42', 'arg2': '37'} ), ( '/unnamed/view_class/42/37/', None, '', '', 'urlpatterns_reverse.views.ViewClass', views.view_class_instance, tuple(), {'arg1': '42', 'arg2': '37'} ),
('/no_kwargs/42/37/', 'no-kwargs', '', '', 'no-kwargs', views.empty_view, ('42', '37'), {}), ('/included/no_kwargs/42/37/', 'inc-no-kwargs', '', '', 'inc-no-kwargs', views.empty_view, ('42', '37'), {}), ( '/included/12/no_kwargs/42/37/', 'inc-no-kwargs', '', '', 'inc-no-kwargs', views.empty_view, ('12', '42', '37'), {} ),
( '/test1/inner/42/37/', 'urlobject-view', 'testapp', 'test-ns1', 'test-ns1:urlobject-view', views.empty_view, tuple(), {'arg1': '42', 'arg2': '37'} ), ( '/included/test3/inner/42/37/', 'urlobject-view', 'testapp', 'test-ns3', 'test-ns3:urlobject-view', views.empty_view, tuple(), {'arg1': '42', 'arg2': '37'} ), ( '/ns-included1/normal/42/37/', 'inc-normal-view', '', 'inc-ns1', 'inc-ns1:inc-normal-view', views.empty_view, tuple(), {'arg1': '42', 'arg2': '37'} ), ( '/included/test3/inner/42/37/', 'urlobject-view', 'testapp', 'test-ns3', 'test-ns3:urlobject-view', views.empty_view, tuple(), {'arg1': '42', 'arg2': '37'} ), ( '/default/inner/42/37/', 'urlobject-view', 'testapp', 'testapp', 'testapp:urlobject-view', views.empty_view, tuple(), {'arg1': '42', 'arg2': '37'} ), ( '/other2/inner/42/37/', 'urlobject-view', 'nodefault', 'other-ns2', 'other-ns2:urlobject-view', views.empty_view, tuple(), {'arg1': '42', 'arg2': '37'} ), ( '/other1/inner/42/37/', 'urlobject-view', 'nodefault', 'other-ns1', 'other-ns1:urlobject-view', views.empty_view, tuple(), {'arg1': '42', 'arg2': '37'} ),
( '/ns-included1/test3/inner/42/37/', 'urlobject-view', 'testapp', 'inc-ns1:test-ns3', 'inc-ns1:test-ns3:urlobject-view', views.empty_view, tuple(), {'arg1': '42', 'arg2': '37'} ), ( '/ns-included1/ns-included4/ns-included2/test3/inner/42/37/', 'urlobject-view', 'testapp', 'inc-ns1:inc-ns4:inc-ns2:test-ns3', 'inc-ns1:inc-ns4:inc-ns2:test-ns3:urlobject-view', views.empty_view, tuple(), {'arg1': '42', 'arg2': '37'} ), ( '/app-included/test3/inner/42/37/', 'urlobject-view', 'inc-app:testapp', 'inc-app:test-ns3', 'inc-app:test-ns3:urlobject-view', views.empty_view, tuple(), {'arg1': '42', 'arg2': '37'} ), ( '/app-included/ns-included4/ns-included2/test3/inner/42/37/', 'urlobject-view', 'inc-app:testapp', 'inc-app:inc-ns4:inc-ns2:test-ns3', 'inc-app:inc-ns4:inc-ns2:test-ns3:urlobject-view', views.empty_view, tuple(), {'arg1': '42', 'arg2': '37'} ),
('/inc70/', 'inner-nothing', '', 'inc-ns5', 'inc-ns5:inner-nothing', views.empty_view, tuple(), {'outer': '70'}), ( '/inc78/extra/foobar/', 'inner-extra', '', 'inc-ns5', 'inc-ns5:inner-extra', views.empty_view, tuple(), {'outer': '78', 'extra': 'foobar'} ),
('nested-noncapture', '/nested/noncapture/opt', [], {'p': 'opt'}), ('nested-capture', '/nested/capture/opt/', ['opt/'], {}), ('nested-capture', NoReverseMatch, [], {'p': 'opt'}), ('nested-mixedcapture', '/nested/capture/mixed/opt', ['opt'], {}), ('nested-mixedcapture', NoReverseMatch, [], {'p': 'opt'}), ('nested-namedcapture', '/nested/capture/named/opt/', [], {'outer': 'opt/'}), ('nested-namedcapture', NoReverseMatch, [], {'outer': 'opt/', 'inner': 'opt'}), ('nested-namedcapture', NoReverseMatch, [], {'inner': 'opt'}),
('defaults', '/defaults_view1/3/', [], {'arg1': 3, 'arg2': 1}), ('defaults', '/defaults_view2/3/', [], {'arg1': 3, 'arg2': 2}), ('defaults', NoReverseMatch, [], {'arg1': 3, 'arg2': 3}), ('defaults', NoReverseMatch, [], {'arg2': 1}),
('security', '/%2Fexample.com/security/', ['/example.com'], {}),
with self.assertRaises(NoReverseMatch): reverse(None)
with override_script_prefix('/bogus)/'): self.assertEqual( '/bogus)/includes/non_path_include/', reverse('non_path_include') ) with override_script_prefix('/(bogus)/'): self.assertEqual( '/(bogus)/includes/non_path_include/', reverse('non_path_include') )
self.assertEqual('/%257Eme/places/1/', reverse('places', args=[1]))
try: reverse("people", args=[]) except NoReverseMatch as e: pattern_description = r"1 pattern(s) tried: ['people/(?P<name>\\w+)/$']" self.assertIn(pattern_description, str(e)) else: self.fail("Expected a NoReverseMatch, but none occurred.")
resolver = get_resolver('urlpatterns_reverse.namespace_urls') sub_resolver = resolver.namespace_dict['test-ns1'][1] self.assertIn('<RegexURLPattern list>', repr(sub_resolver))
url_types_names = [ [{'type': RegexURLPattern, 'name': 'named-url1'}], [{'type': RegexURLPattern, 'name': 'named-url2'}], [{'type': RegexURLPattern, 'name': None}], [{'type': RegexURLResolver}, {'type': RegexURLPattern, 'name': 'named-url3'}], [{'type': RegexURLResolver}, {'type': RegexURLPattern, 'name': 'named-url4'}], [{'type': RegexURLResolver}, {'type': RegexURLPattern, 'name': None}], [{'type': RegexURLResolver}, {'type': RegexURLResolver}], ] try: resolve('/included/non-existent-url', urlconf=urls) self.fail('resolve did not raise a 404') except Resolver404 as e: self.assertIn('tried', e.args[0]) tried = e.args[0]['tried'] self.assertEqual( len(e.args[0]['tried']), len(url_types_names), 'Wrong number of tried URLs returned. Expected %s, got %s.' % ( len(url_types_names), len(e.args[0]['tried']) ) ) for tried, expected in zip(e.args[0]['tried'], url_types_names): for t, e in zip(tried, expected): self.assertIsInstance(t, e['type']), str('%s is not an instance of %s') % (t, e['type']) if 'name' in e: if not e['name']: self.assertIsNone(t.name, 'Expected no URL name but found %s.' % t.name) else: self.assertEqual( t.name, e['name'], 'Wrong URL name. Expected "%s", got "%s".' % (e['name'], t.name) )
class FakeObj(object): def get_absolute_url(self): return "/hi-there/"
res = redirect('//abc/') self.assertEqual(res.url, '/%C3%A6%C3%B8%C3%A5/abc/') res = redirect('/.abc/') self.assertEqual(res.url, '/%C3%A6%C3%B8%C3%A5.abc/') res = redirect('os.path') self.assertEqual(res.url, 'os.path')
redirect("urlpatterns_reverse.nonimported_module.view") self.assertNotIn("urlpatterns_reverse.nonimported_module", sys.modules)
from .views import nested_view self.assertEqual(reverse(nested_view), '/includes/nested_path/')
match_func, match_args, match_kwargs = resolve(path) self.assertEqual(match_func, func) self.assertEqual(match_args, args) self.assertEqual(match_kwargs, kwargs)
match = resolve(path) self.assertEqual(match.__class__, ResolverMatch) self.assertEqual(match.url_name, url_name) self.assertEqual(match.app_name, app_name) self.assertEqual(match.namespace, namespace) self.assertEqual(match.view_name, view_name) self.assertEqual(match.func, func) self.assertEqual(match.args, args) self.assertEqual(match.kwargs, kwargs)
self.assertEqual(match[0], func) self.assertEqual(match[1], args) self.assertEqual(match[2], kwargs)
with self.assertRaisesMessage(TypeError, 'view must be a callable'): url(r'uncallable-object/$', views.uncallable)
msg = '(regex_error/$" is not a valid regular expression' with self.assertRaisesMessage(ImproperlyConfigured, msg): reverse(views.empty_view)
self.assertEqual(get_callable(empty_view), empty_view)
with six.assertRaisesRegex(self, ViewDoesNotExist, ".*View does not exist in.*"): get_callable('urlpatterns_reverse.views.i_should_not_exist') with self.assertRaises(AttributeError): get_callable('urlpatterns_reverse.views_broken.i_am_broken')
self.assertEqual(include(self.url_patterns, 'namespace'), (self.url_patterns, None, 'namespace'))
self.assertEqual( include(self.url_patterns, 'namespace', 'app_name'), (self.url_patterns, 'app_name', 'namespace') )
self.assertEqual( include((self.url_patterns, 'app_name', 'namespace')), (self.url_patterns, 'app_name', 'namespace') )
url(r'^partial/', empty_view_partial, name="partial"), url(r'^partial_nested/', empty_view_nested_partial, name="partial_nested"), url(r'^partial_wrapped/', empty_view_wrapped, name="partial_wrapped"),
url(r'^(?:foo|bar)(\w+)/$', empty_view, name="disjunction"),
url(r'defaults_view1/(?P<arg1>[0-9]+)/', defaults_view, {'arg2': 1}, name='defaults'), url(r'defaults_view2/(?P<arg1>[0-9]+)/', defaults_view, {'arg2': 2}, 'defaults'),
url('(.+)/security/$', empty_view, name='security'),
from django.conf.urls import url
raise AttributeError('I am here to confuse django.urls.get_callable')
from __future__ import unicode_literals
r['key'] = 'test' self.assertEqual(r['key'], str('test')) self.assertIsInstance(r['key'], str) r['key'] = 'test'.encode('ascii') self.assertEqual(r['key'], str('test')) self.assertIsInstance(r['key'], str) self.assertIn(b'test', r.serialize_headers())
r['key'] = 'caf' self.assertEqual(r['key'], force_str('caf', 'latin-1')) self.assertIsInstance(r['key'], str) r['key'] = 'caf'.encode('latin-1') self.assertEqual(r['key'], force_str('caf', 'latin-1')) self.assertIsInstance(r['key'], str) self.assertIn('caf'.encode('latin-1'), r.serialize_headers())
r['key'] = '' self.assertEqual(r['key'], str('=?utf-8?b?4oCg?=')) self.assertIsInstance(r['key'], str) self.assertIn(b'=?utf-8?b?4oCg?=', r.serialize_headers())
r = HttpResponse() del r['Content-Type'] r['foo'] = 'bar' l = list(r.items()) self.assertEqual(len(l), 1) self.assertEqual(l[0], ('foo', 'bar')) self.assertIsInstance(l[0][0], str)
h = HttpResponse() f = 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz a\xcc\x88'.encode('latin-1') f = f.decode('utf-8') h['Content-Disposition'] = 'attachment; filename="%s"' % f h['Content-Disposition'] = 'attachment; filename="EdelRot_Blu\u0308te (3)-0.JPG"'
r = HttpResponse() with self.assertRaises(BadHeaderError): r.__setitem__('test\rstr', 'test') with self.assertRaises(BadHeaderError): r.__setitem__('test\nstr', 'test')
r = HttpResponse(12345) self.assertEqual(r.content, b'12345')
r = HttpResponse() r.content = 12345 self.assertEqual(r.content, b'12345')
r = HttpResponse() r.content = ['idan', 'alex', 'jacob'] self.assertEqual(r.content, b'idanalexjacob')
r = HttpResponse() r.content = ['1', '2', 3, '\u079e'] self.assertEqual(r.content, b'123\xde\x9e')
r = HttpResponse(iter(['hello', 'world'])) self.assertEqual(r.content, r.content) self.assertEqual(r.content, b'helloworld') self.assertEqual(b''.join(r), b'helloworld') self.assertEqual(b''.join(r), b'helloworld') self.assertEqual(r.content, b'helloworld')
r = HttpResponse(iter(['hello', 'world'])) self.assertEqual(b''.join(r), b'helloworld') self.assertEqual(r.content, b'helloworld')
r = HttpResponse(iter(['hello', 'world'])) self.assertEqual(r.content, b'helloworld') r.write('!') self.assertEqual(r.content, b'helloworld!')
r = HttpResponse('abc') i = iter(r) self.assertEqual(list(i), [b'abc']) self.assertEqual(list(i), [])
r = HttpResponse() r['Content-Encoding'] = 'winning' r.write(b'abc') r.write(b'def') self.assertEqual(r.content, b'abcdef')
response = HttpResponseRedirect( '/redirected/', content='The resource has temporarily moved', content_type='text/html', ) self.assertContains(response, 'The resource has temporarily moved', status_code=302) self.assertEqual(response.url, response['Location'])
with self.assertRaises(AttributeError): response.content = "Hello dear" self.assertNotIn('content-type', response)
response = HttpResponseNotAllowed(['GET'], content='Only the GET method is allowed', content_type='text/html') self.assertContains(response, 'Only the GET method is allowed', status_code=405)
chunks = list(r) self.assertEqual(chunks, [b'hello', b'world']) for chunk in chunks: self.assertIsInstance(chunk, six.binary_type)
self.assertEqual(list(r), [])
r = StreamingHttpResponse(['abc', 'def']) self.assertEqual(list(r), [b'abc', b'def']) self.assertEqual(list(r), [])
r.streaming_content = iter(['hello', 'caf']) chunks = list(r) self.assertEqual(chunks, [b'hello', b'caf\xc3\xa9']) for chunk in chunks: self.assertIsInstance(chunk, six.binary_type)
self.assertFalse(hasattr(r, 'content'))
with self.assertRaises(AttributeError): r.content = 'xyz'
self.assertTrue(hasattr(r, 'streaming_content'))
r.streaming_content = iter(['abc', 'def']) r.streaming_content = (chunk.upper() for chunk in r.streaming_content) self.assertEqual(list(r), [b'ABC', b'DEF'])
r = StreamingHttpResponse(iter(['hello', 'world'])) self.assertEqual( six.binary_type(r), b'Content-Type: text/html; charset=utf-8')
self.assertEqual(list(r), [b'hello', b'world'])
r = StreamingHttpResponse(iter(['hello', 'world'])) with self.assertRaises(Exception): r.write('!')
with self.assertRaises(Exception): r.tell()
request_finished.disconnect(close_old_connections)
file1 = open(filename) r = HttpResponse(file1) self.assertTrue(file1.closed) r.close()
file1 = open(filename) file2 = open(filename) r = HttpResponse(file1) r.content = file2 self.assertTrue(file1.closed) self.assertTrue(file2.closed)
file1 = open(filename) r = StreamingHttpResponse(file1) self.assertFalse(file1.closed) r.close() self.assertTrue(file1.closed)
file1 = open(filename) file2 = open(filename) r = StreamingHttpResponse(file1) r.streaming_content = file2 self.assertFalse(file1.closed) self.assertFalse(file2.closed) r.close() self.assertTrue(file1.closed) self.assertTrue(file2.closed)
self.assertEqual( parse_cookie('keebler="E=mc2; L=\\"Loves\\"; fudge=\\012;"'), {'keebler': '"E=mc2', 'L': '\\"Loves\\"', 'fudge': '\\012', '': '"'} ) self.assertEqual(parse_cookie('keebler=E=mc2'), {'keebler': 'E=mc2'}) self.assertEqual(parse_cookie('key:term=value:term'), {'key:term': 'value:term'}) self.assertEqual(parse_cookie('a=b; c=[; d=r; f=h'), {'a': 'b', 'c': '[', 'd': 'r', 'f': 'h'})
self.assertEqual(parse_cookie('a=b; Domain=example.com'), {'a': 'b', 'Domain': 'example.com'}) self.assertEqual(parse_cookie('a=b; h=i; a=c'), {'a': 'c', 'h': 'i'})
self.assertIn('django_language', parse_cookie('abc=def; unnamed; django_language=en').keys()) self.assertEqual(parse_cookie('a=b; "; c=d'), {'a': 'b', '': '"', 'c': 'd'}) self.assertEqual(parse_cookie('a b c=d e = f; gh=i'), {'a b c': 'd e = f', 'gh': 'i'}) self.assertEqual(parse_cookie('a b,c<>@:/[]?{}=d " =e,f g'), {'a b,c<>@:/[]?{}': 'd " =e,f g'}) self.assertEqual(parse_cookie('saint=Andr Bessette'), {'saint': force_str('Andr Bessette')}) self.assertEqual(parse_cookie(' = b ; ; = ; c = ; '), {'': 'b', 'c': ''})
from app2.models import NiceModel
class First(models.Model): second = models.IntegerField()
class Third(models.Model): name = models.CharField(max_length=20) third = models.ForeignKey('self', models.SET_NULL, null=True, related_name='child_set')
@python_2_unicode_compatible class Category(models.Model): name = models.CharField(max_length=20)
class SchoolManager(models.Manager): def get_queryset(self): return super(SchoolManager, self).get_queryset().filter(is_public=True)
self.r = Reporter(first_name='John', last_name='Smith', email='john@example.com') self.r.save() self.r2 = Reporter(first_name='Paul', last_name='Jones', email='paul@example.com') self.r2.save() self.a = Article(headline="This is a test", pub_date=datetime.date(2005, 7, 27), reporter=self.r) self.a.save()
r = self.a.reporter self.assertEqual(r.id, self.r.id) self.assertEqual((r.first_name, self.r.last_name), ('John', 'Smith'))
a3 = Article(headline="Third article", pub_date=datetime.date(2005, 7, 27), reporter_id=self.r.id) a3.save() self.assertEqual(a3.reporter.id, self.r.id)
a4 = Article(headline="Fourth article", pub_date=datetime.date(2005, 7, 27), reporter_id=str(self.r.id)) a4.save() self.assertEqual(repr(a4.reporter), "<Reporter: John Smith>")
new_article = self.r.article_set.create(headline="John's second story", pub_date=datetime.date(2005, 7, 29)) self.assertEqual(repr(new_article), "<Article: John's second story>") self.assertEqual(new_article.reporter.id, self.r.id)
new_article2 = Article(headline="Paul's story", pub_date=datetime.date(2006, 1, 17)) msg = "<Article: Paul's story> instance isn't saved. Use bulk=False or save the object first." with self.assertRaisesMessage(ValueError, msg): self.r.article_set.add(new_article2)
self.r2.article_set.add(new_article2) self.assertEqual(new_article2.reporter.id, self.r2.id) self.assertQuerysetEqual(self.r2.article_set.all(), ["<Article: Paul's story>"])
with transaction.atomic(): with six.assertRaisesRegex(self, TypeError, "'Article' instance expected, got <Reporter.*"): self.r.article_set.add(self.r2) self.assertQuerysetEqual( self.r.article_set.all(), ["<Article: John's second story>", "<Article: This is a test>"] )
new_article2.reporter = self.r new_article2.save() self.assertEqual(repr(new_article2.reporter), "<Reporter: John Smith>") self.assertEqual(new_article2.reporter.id, self.r.id) self.assertQuerysetEqual(self.r.article_set.all(), [ "<Article: John's second story>", "<Article: Paul's story>", "<Article: This is a test>", ]) self.assertQuerysetEqual(self.r2.article_set.all(), [])
self.r2.article_set.set([new_article, new_article2]) self.assertQuerysetEqual(self.r.article_set.all(), ["<Article: This is a test>"]) self.assertQuerysetEqual( self.r2.article_set.all(), ["<Article: John's second story>", "<Article: Paul's story>"] )
self.r.article_set.set([new_article]) self.assertQuerysetEqual( self.r.article_set.all(), ["<Article: John's second story>", "<Article: This is a test>"] ) self.assertQuerysetEqual(self.r2.article_set.all(), ["<Article: Paul's story>"])
new_article2.reporter = self.r new_article2.save() self.assertEqual(repr(new_article2.reporter), "<Reporter: John Smith>") self.assertEqual(new_article2.reporter.id, self.r.id) self.assertQuerysetEqual(self.r.article_set.all(), [ "<Article: John's second story>", "<Article: Paul's story>", "<Article: This is a test>", ]) self.assertQuerysetEqual(self.r2.article_set.all(), [])
self.r2.article_set.set([new_article, new_article2]) self.assertQuerysetEqual(self.r.article_set.all(), ["<Article: This is a test>"]) self.assertQuerysetEqual( self.r2.article_set.all(), ["<Article: John's second story>", "<Article: Paul's story>"] )
self.r.article_set.set([new_article]) self.assertQuerysetEqual( self.r.article_set.all(), ["<Article: John's second story>", "<Article: This is a test>"] ) self.assertQuerysetEqual(self.r2.article_set.all(), ["<Article: Paul's story>"]) self.assertFalse(hasattr(self.r2.article_set, 'remove')) self.assertFalse(hasattr(self.r2.article_set, 'clear'))
self.assertQuerysetEqual(self.r.article_set.all(), [ "<Article: John's second story>", "<Article: This is a test>", ]) self.assertQuerysetEqual(self.r.article_set.filter(headline__startswith='This'), ["<Article: This is a test>"]) self.assertEqual(self.r.article_set.count(), 2) self.assertEqual(self.r2.article_set.count(), 1) self.assertQuerysetEqual(Article.objects.filter(id__exact=self.a.id), ["<Article: This is a test>"]) self.assertQuerysetEqual(Article.objects.filter(pk=self.a.id), ["<Article: This is a test>"]) self.assertQuerysetEqual(Article.objects.filter(headline__startswith='This'), ["<Article: This is a test>"]) self.assertQuerysetEqual( Article.objects.filter(reporter__first_name__exact='John'), ["<Article: John's second story>", "<Article: This is a test>"] ) self.assertQuerysetEqual( Article.objects.filter(reporter__first_name='John'), ["<Article: John's second story>", "<Article: This is a test>"] ) self.assertQuerysetEqual( Article.objects.filter(reporter__first_name__exact='John', reporter__last_name__exact='Smith'), ["<Article: John's second story>", "<Article: This is a test>"] ) queryset = Article.objects.filter(reporter__first_name__exact='John', reporter__last_name__exact='Smith') self.assertNumQueries(1, list, queryset) self.assertEqual(queryset.query.get_compiler(queryset.db).as_sql()[0].count('INNER JOIN'), 1)
self.assertQuerysetEqual( Article.objects.filter(reporter__first_name__exact='John').extra( where=["many_to_one_reporter.last_name='Smith'"]), ["<Article: John's second story>", "<Article: This is a test>"] ) self.assertQuerysetEqual( (Article.objects .filter(reporter__first_name__exact='John') .extra(where=["many_to_one_reporter.last_name='%s'" % 'Smith'])), ["<Article: John's second story>", "<Article: This is a test>"] ) self.assertQuerysetEqual( Article.objects.filter(reporter__id__exact=self.r.id), [ "<Article: John's second story>", "<Article: This is a test>", ]) self.assertQuerysetEqual( Article.objects.filter(reporter__pk=self.r.id), [ "<Article: John's second story>", "<Article: This is a test>", ]) self.assertQuerysetEqual( Article.objects.filter(reporter=self.r.id), [ "<Article: John's second story>", "<Article: This is a test>", ]) self.assertQuerysetEqual( Article.objects.filter(reporter=self.r), [ "<Article: John's second story>", "<Article: This is a test>", ]) self.assertQuerysetEqual( Article.objects.filter(reporter__in=[self.r.id, self.r2.id]).distinct(), [ "<Article: John's second story>", "<Article: Paul's story>", "<Article: This is a test>", ]) self.assertQuerysetEqual( Article.objects.filter(reporter__in=[self.r, self.r2]).distinct(), [ "<Article: John's second story>", "<Article: Paul's story>", "<Article: This is a test>", ]) self.assertQuerysetEqual( Article.objects.filter( reporter__in=Reporter.objects.filter(first_name='John').values('pk').query ).distinct(), [ "<Article: John's second story>", "<Article: This is a test>", ])
self.assertQuerysetEqual(Reporter.objects.filter(id__exact=self.r.id), john_smith) self.assertQuerysetEqual(Reporter.objects.filter(pk=self.r.id), john_smith) self.assertQuerysetEqual(Reporter.objects.filter(first_name__startswith='John'), john_smith) self.assertQuerysetEqual(Reporter.objects.filter(article__id__exact=self.a.id), john_smith) self.assertQuerysetEqual(Reporter.objects.filter(article__pk=self.a.id), john_smith) self.assertQuerysetEqual(Reporter.objects.filter(article=self.a.id), john_smith) self.assertQuerysetEqual(Reporter.objects.filter(article=self.a), john_smith) self.assertQuerysetEqual(Reporter.objects.filter(article__in=[self.a.id, a3.id]).distinct(), john_smith) self.assertQuerysetEqual(Reporter.objects.filter(article__in=[self.a.id, a3]).distinct(), john_smith) self.assertQuerysetEqual(Reporter.objects.filter(article__in=[self.a, a3]).distinct(), john_smith) self.assertQuerysetEqual( Reporter.objects.filter(article__headline__startswith='T'), ["<Reporter: John Smith>", "<Reporter: John Smith>"], ordered=False ) self.assertQuerysetEqual(Reporter.objects.filter(article__headline__startswith='T').distinct(), john_smith)
self.assertEqual(Reporter.objects.filter(article__headline__startswith='T').count(), 2) self.assertEqual(Reporter.objects.filter(article__headline__startswith='T').distinct().count(), 1)
self.assertQuerysetEqual( Reporter.objects.filter(article__reporter__first_name__startswith='John'), [ "<Reporter: John Smith>", "<Reporter: John Smith>", "<Reporter: John Smith>", ], ordered=False ) self.assertQuerysetEqual( Reporter.objects.filter(article__reporter__first_name__startswith='John').distinct(), john_smith ) self.assertQuerysetEqual(Reporter.objects.filter(article__reporter__exact=self.r).distinct(), john_smith)
self.assertQuerysetEqual(Reporter.objects.filter(article__reporter=self.r).distinct(), john_smith)
d = {'reporter__first_name': 'John', 'reporter__last_name': 'Smith'} qs = Article.objects.filter( reporter=self.r, ).distinct().order_by().values('reporter__first_name', 'reporter__last_name') self.assertEqual([d], list(qs))
r1 = Reporter.objects.create(first_name='Mike', last_name='Royko', email='royko@suntimes.com') r2 = Reporter.objects.create(first_name='John', last_name='Kass', email='jkass@tribune.com') Article.objects.create(headline='First', pub_date=datetime.date(1980, 4, 23), reporter=r1) Article.objects.create(headline='Second', pub_date=datetime.date(1980, 4, 23), reporter=r2) self.assertEqual( list(Article.objects.select_related().dates('pub_date', 'day')), [datetime.date(1980, 4, 23), datetime.date(2005, 7, 27)] ) self.assertEqual( list(Article.objects.select_related().dates('pub_date', 'month')), [datetime.date(1980, 4, 1), datetime.date(2005, 7, 1)] ) self.assertEqual( list(Article.objects.select_related().dates('pub_date', 'year')), [datetime.date(1980, 1, 1), datetime.date(2005, 1, 1)] )
self.assertQuerysetEqual( Article.objects.all(), [ "<Article: Fourth article>", "<Article: John's second story>", "<Article: Paul's story>", "<Article: Third article>", "<Article: This is a test>", ] ) self.assertQuerysetEqual( Reporter.objects.order_by('first_name'), ["<Reporter: John Smith>", "<Reporter: Paul Jones>"] ) self.r2.delete() self.assertQuerysetEqual( Article.objects.all(), [ "<Article: Fourth article>", "<Article: John's second story>", "<Article: Third article>", "<Article: This is a test>", ] ) self.assertQuerysetEqual(Reporter.objects.order_by('first_name'), ["<Reporter: John Smith>"]) Reporter.objects.filter(article__headline__startswith='This').delete() self.assertQuerysetEqual(Reporter.objects.all(), []) self.assertQuerysetEqual(Article.objects.all(), [])
a2, created = Article.objects.get_or_create( headline="John's second test", pub_date=datetime.date(2011, 5, 7), reporter_id=self.r.id, ) self.assertTrue(created) self.assertEqual(a2.reporter.id, self.r.id)
self.assertQuerysetEqual( Article.objects.filter(reporter_id__exact=self.r.id), ["<Article: John's second test>", "<Article: This is a test>"] )
a3 = Article.objects.create( headline="Paul's commentary", pub_date=datetime.date(2011, 5, 7), reporter_id=self.r2.id, ) self.assertEqual(a3.reporter.id, self.r2.id)
with self.assertRaises(MultipleObjectsReturned): Article.objects.get(reporter_id=self.r.id) self.assertEqual( repr(a3), repr(Article.objects.get(reporter_id=self.r2.id, pub_date=datetime.date(2011, 5, 7))) )
self.r.cached_query = Article.objects.filter(reporter=self.r) self.assertEqual(repr(deepcopy(self.r)), "<Reporter: John Smith>")
self.assertIs(r1.article_set.__class__, r1.article_set.__class__)
self.assertIs(r1.article_set.__class__, r2.article_set.__class__)
c = Child.objects.get(name="Child") p = c.parent
self.assertIs(c.parent, p)
del c._parent_cache self.assertIsNot(c.parent, p)
p2 = Parent.objects.create(name="Parent 2") c.parent = p2 self.assertIs(c.parent, p2)
p.bestchild = None self.assertIsNone(p.bestchild)
p.save() self.assertIsNone(p.bestchild)
p = Parent.objects.get(name="Parent") self.assertIsNone(p.bestchild)
setattr(c, "parent", None)
with self.assertRaises(ValueError): setattr(c, "parent", First(id=1, second=1))
Child(name='xyzzy', parent=None)
with self.assertRaises(IntegrityError), transaction.atomic(): Child.objects.create(name='xyzzy', parent=None)
p = Parent.objects.get(name="Parent") c = Child(parent=p) self.assertIs(c.parent, p)
p = Parent() msg = "save() prohibited to prevent data loss due to unsaved related object 'parent'." with self.assertRaisesMessage(ValueError, msg): Child.objects.create(parent=p)
p = Parent.objects.get(name="Parent") c = Child(parent_id=p.id) self.assertIsNot(c.parent, p) self.assertEqual(c.parent, p)
c1 = Category.objects.create(name='First') c2 = Category.objects.create(name='Second') c3 = Category.objects.create(name='Third') r1 = Record.objects.create(category=c1) r2 = Record.objects.create(category=c1) r3 = Record.objects.create(category=c2) r4 = Record.objects.create(category=c2) r5 = Record.objects.create(category=c3) Relation.objects.create(left=r1, right=r2) Relation.objects.create(left=r3, right=r4) Relation.objects.create(left=r1, right=r3) Relation.objects.create(left=r5, right=r2) Relation.objects.create(left=r3, right=r2)
cat = models.ForeignKey(Category, models.CASCADE) self.assertEqual('id', cat.remote_field.get_related_field().name)
Third.objects.create(name='Third 1') Third.objects.create(name='Third 2') th = Third(name="testing") with self.assertNumQueries(0): self.assertEqual(th.child_set.count(), 0) th.save() with self.assertNumQueries(1): self.assertEqual(th.child_set.count(), 0)
self.assertQuerysetEqual(School.objects.all(), ["<School: School object>"])
self.assertEqual(private_student.school, private_school)
School._default_manager.use_for_related_fields = True try: private_student = Student.objects.get(pk=private_student.pk) with self.assertRaises(School.DoesNotExist): private_student.school finally: School._default_manager.use_for_related_fields = False
self.assertFalse(hasattr(Article(), 'reporter'))
with self.assertRaises(Exception) as cm: admin.autodiscover() self.assertEqual(str(cm.exception), "Bad admin module")
with self.assertRaises(Exception) as cm: admin.autodiscover() self.assertEqual(str(cm.exception), "Bad admin module")
class TablespacesTests(TestCase):
self._old_models = apps.app_configs['model_options'].models.copy()
self.assertNumContains(sql, 'tbl_tbsp', 1) self.assertNumContains(sql, settings.DEFAULT_INDEX_TABLESPACE, 1)
self.assertNumContains(sql, 'tbl_tbsp', 2)
self.assertEqual(sql_for_table(Scientist), sql_for_table(ScientistRef))
self.assertNumContains(sql, 'tbl_tbsp', 1) self.assertNumContains(sql, settings.DEFAULT_INDEX_TABLESPACE, 2)
self.assertNumContains(sql, 'tbl_tbsp', 3)
self.assertNumContains(sql, 'idx_tbsp', 1)
self.assertEqual(sql_for_table(Article), sql_for_table(ArticleRef))
if settings.DEFAULT_INDEX_TABLESPACE: self.assertNumContains(sql, 'tbl_tbsp', 1) self.assertNumContains(sql, settings.DEFAULT_INDEX_TABLESPACE, 1) else: self.assertNumContains(sql, 'tbl_tbsp', 2) self.assertNumContains(sql, 'idx_tbsp', 0)
if settings.DEFAULT_INDEX_TABLESPACE: self.assertNumContains(sql, settings.DEFAULT_INDEX_TABLESPACE, 2) else: self.assertNumContains(sql, 'tbl_tbsp', 2) self.assertNumContains(sql, 'idx_tbsp', 0)
if settings.DEFAULT_INDEX_TABLESPACE: self.assertNumContains(sql, 'tbl_tbsp', 1) self.assertNumContains(sql, settings.DEFAULT_INDEX_TABLESPACE, 1) else: self.assertNumContains(sql, 'tbl_tbsp', 2) self.assertNumContains(sql, 'idx_tbsp', 0)
self.assertNumContains(sql, 'tbl_tbsp', 0) self.assertNumContains(sql, 'idx_tbsp', 2)
self.assertEqual(list(self.book.model_options_bookstores.all()), [])
from django.db import models from django.utils.encoding import python_2_unicode_compatible
first_name = models.CharField(max_length=20) manager = models.BooleanField(default=False) last_name = models.CharField(max_length=20) store = models.ForeignKey(Store, models.CASCADE) age = models.IntegerField() salary = models.DecimalField(max_digits=8, decimal_places=2)
qs = Book.objects.values('rating').annotate(other_rating=F('rating') - 1) book = qs.get(pk=self.b1.pk) self.assertEqual(book['rating'] - 1, book['other_rating'])
book = qs.get(other_rating=4) self.assertEqual(book['other_rating'], 4)
book = qs.annotate(other_isbn=F('isbn')).get(other_rating=4) self.assertEqual(book['other_rating'], 4) self.assertEqual(book['other_isbn'], '155860191')
self.assertQuerysetEqual( qs.defer('age').order_by('id'), rows, lambda e: ( e.id, e.first_name, e.manager, e.random_value, e.last_name, e.age, e.salary, e.store.name, e.annotated_value))
return None
from __future__ import unicode_literals
class Model(models.Model): field = models.AutoField(primary_key=False)
another = models.IntegerField(primary_key=True)
from __future__ import unicode_literals
return db == 'default'
from __future__ import unicode_literals
model = models.IntegerField()
class Model(models.Model): foreign_key = models.ForeignKey('Rel1', models.CASCADE)
first_person = models.ForeignKey(Person, models.CASCADE, related_name="first") second_person = models.ForeignKey(Person, models.CASCADE, related_name="second") second_model = models.ForeignKey(Group, models.CASCADE)
friends = models.ManyToManyField('self', through="Relationship")
friends = models.ManyToManyField('self', through="Relationship", symmetrical=True)
friends = models.ManyToManyField( 'self', symmetrical=True, through="Relationship", through_fields=('first', 'second'), )
country_id = models.IntegerField() city_id = models.IntegerField()
class Meta: swappable = 'TEST_SWAPPABLE_MODEL'
if six.PY3: invalid_related_names.append('')
if six.PY3: related_names.extend(['', '+'])
def test_complex_clash(self): class Target(models.Model): tgt_safe = models.CharField(max_length=10) clash = models.CharField(max_length=10) model = models.CharField(max_length=10)
from __future__ import unicode_literals
@isolate_apps('invalid_models_tests') class UniqueTogetherTests(SimpleTestCase):
unique_together = ('one', 'two')
class VeryLongModelNamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz(models.Model): title = models.CharField(max_length=11)
class ModelWithLongField(models.Model): m2m_field = models.ManyToManyField( VeryLongModelNamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz, related_name="rn1" ) m2m_field2 = models.ManyToManyField( VeryLongModelNamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz, related_name="rn2", through='m2msimple' ) m2m_field3 = models.ManyToManyField( VeryLongModelNamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz, related_name="rn3", through='m2mcomplex' ) fk = models.ForeignKey( VeryLongModelNamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz, models.CASCADE, related_name="rn4", )
class m2msimple(models.Model): id2 = models.ForeignKey(ModelWithLongField, models.CASCADE)
m2m_long_name = "verylongmodelnamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz_id" if self.max_column_name_length > len(m2m_long_name): expected = [] else: expected = [ Error( 'Autogenerated column name too long for M2M field "%s". ' 'Maximum length is "%s" for database "%s".' % (m2m_long_name, self.max_column_name_length, self.column_limit_db_alias), hint="Use 'through' to create a separate model for " "M2M and then set column_name using 'db_column'.", obj=ModelWithLongField, id='models.E019', ) ]
expected.append( Error( 'Autogenerated column name too long for M2M field "%s_id". ' 'Maximum length is "%s" for database "%s".' % (long_field_name, self.max_column_name_length, self.column_limit_db_alias), hint="Use 'through' to create a separate model for " "M2M and then set column_name using 'db_column'.", obj=ModelWithLongField, id='models.E019', ) )
expected = [ Error( 'Autogenerated column name too long for field "%s". ' 'Maximum length is "%s" for database "%s".' % (long_field_name, self.max_column_name_length, self.column_limit_db_alias), hint="Set the column name manually using 'db_column'.", obj=ModelWithLongField, id='models.E018', ) ]
pass
f_id = models.IntegerField()
f = models.ForeignKey(Target, models.CASCADE)
parent = models.OneToOneField(Place, models.CASCADE)
from __future__ import unicode_literals
from django.contrib.auth.models import User from django.db import models from django.utils.encoding import python_2_unicode_compatible
no = models.IntegerField(verbose_name="Number", blank=True, null=True)
ma = ModelAdmin(Band, self.site) self.assertEqual(ma.get_fieldsets(request), [(None, {'fields': ['name', 'bio', 'sign_date']})])
class BandAdmin(ModelAdmin): fields = ['name']
class BandAdmin(ModelAdmin): fields = ['name']
class BandAdmin(ModelAdmin): fieldsets = [(None, {'fields': ['name']})]
class BandAdmin(ModelAdmin): exclude = ['bio']
class BandAdmin(ModelAdmin): exclude = ('bio',)
class BandAdmin(ModelAdmin): fields = ['name', 'bio'] exclude = ['bio']
self.assertEqual( list(ma.get_form(request).base_fields), ['bio', 'sign_date'] ) self.assertEqual( list(ma.get_fields(request)), ['bio', 'sign_date', 'name'] ) self.assertEqual( list(ma.get_fieldsets(request)), [(None, {'fields': ['bio', 'sign_date', 'name']})] )
class TestMiddleware(MiddlewareMixin): def __init__(self, get_response=None): self.process_request_called = False self.process_view_called = False self.process_response_called = False self.process_template_response_called = False self.process_exception_called = False self.get_response = get_response
class RequestMiddleware(TestMiddleware): def process_request(self, request): super(RequestMiddleware, self).process_request(request) return HttpResponse('Request Middleware')
class BadRequestMiddleware(TestMiddleware): def process_request(self, request): super(BadRequestMiddleware, self).process_request(request) raise TestException('Test Request Exception')
class NoTemplateResponseMiddleware(TestMiddleware): def process_template_response(self, request, response): super(NoTemplateResponseMiddleware, self).process_template_response(request, response)
pass
self.assert_middleware_usage(pre_middleware, True, False, False, True, False) self.assert_middleware_usage(middleware, True, False, False, True, False) self.assert_middleware_usage(post_middleware, False, False, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(middleware, True, True, False, True, False) self.assert_middleware_usage(post_middleware, True, False, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(middleware, True, True, False, True, False) self.assert_middleware_usage(post_middleware, True, True, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, True, True, False) self.assert_middleware_usage(middleware, True, True, True, True, False) self.assert_middleware_usage(post_middleware, True, True, True, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(middleware, True, True, False, True, False) self.assert_middleware_usage(post_middleware, True, True, False, True, False)
self.assert_middleware_usage(pre_middleware, True, False, False, True, False) self.assert_middleware_usage(middleware, True, False, False, True, False) self.assert_middleware_usage(post_middleware, False, False, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(middleware, True, True, False, True, False) self.assert_middleware_usage(post_middleware, True, False, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, True, True) self.assert_middleware_usage(middleware, True, True, False, True, True) self.assert_middleware_usage(post_middleware, True, True, False, True, True)
self.assert_middleware_usage(pre_middleware, True, True, False, True, True) self.assert_middleware_usage(middleware, True, True, False, True, True) self.assert_middleware_usage(post_middleware, True, True, False, True, True)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(middleware, True, True, False, True, True) self.assert_middleware_usage(post_middleware, True, True, False, True, True)
self.assert_middleware_usage(pre_middleware, True, False, False, True, False) self.assert_middleware_usage(middleware, True, False, False, True, False) self.assert_middleware_usage(post_middleware, False, False, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(middleware, True, True, False, True, False) self.assert_middleware_usage(post_middleware, True, False, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, True, True) self.assert_middleware_usage(middleware, True, True, False, True, True) self.assert_middleware_usage(post_middleware, True, True, False, True, True)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(middleware, True, True, False, True, True) self.assert_middleware_usage(post_middleware, True, True, False, True, True)
self.assert_middleware_usage(pre_middleware, True, False, False, True, False) self.assert_middleware_usage(middleware, True, False, False, True, False) self.assert_middleware_usage(post_middleware, False, False, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(middleware, True, True, False, True, False) self.assert_middleware_usage(post_middleware, True, False, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(middleware, True, True, False, True, False) self.assert_middleware_usage(post_middleware, True, True, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(middleware, True, True, False, True, False) self.assert_middleware_usage(post_middleware, True, True, False, True, False)
self.assert_middleware_usage(pre_middleware, True, False, False, True, False) self.assert_middleware_usage(middleware, True, False, False, True, False) self.assert_middleware_usage(post_middleware, False, False, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(middleware, True, True, False, True, False) self.assert_middleware_usage(post_middleware, True, False, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, True, True) self.assert_middleware_usage(middleware, True, True, False, True, True) self.assert_middleware_usage(post_middleware, True, True, False, True, True)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(middleware, True, True, False, True, True) self.assert_middleware_usage(post_middleware, True, True, False, True, True)
self.assert_middleware_usage(middleware, True, True, True, True, False)
self.client.handler.load_middleware() response = self.client.get('/middleware_exceptions/exception_in_render/') self.assertEqual(response.content, b'Exception caught')
self.assert_middleware_usage(pre_middleware, True, False, False, True, False) self.assert_middleware_usage(bad_middleware, True, False, False, True, False) self.assert_middleware_usage(post_middleware, False, False, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(bad_middleware, True, True, False, True, False) self.assert_middleware_usage(post_middleware, True, False, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(bad_middleware, True, True, True, True, False) self.assert_middleware_usage(post_middleware, True, True, True, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, False, False) self.assert_middleware_usage(bad_middleware, True, True, False, True, False) self.assert_middleware_usage(post_middleware, True, True, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(bad_middleware, True, True, False, True, False) self.assert_middleware_usage(post_middleware, True, True, False, True, False)
self.assert_middleware_usage(pre_middleware, True, False, False, True, False) self.assert_middleware_usage(bad_middleware, True, False, False, True, False) self.assert_middleware_usage(post_middleware, False, False, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(bad_middleware, True, True, False, True, False) self.assert_middleware_usage(post_middleware, True, False, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, False, True) self.assert_middleware_usage(bad_middleware, True, True, False, True, True) self.assert_middleware_usage(post_middleware, True, True, False, True, True)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(bad_middleware, True, True, False, True, True) self.assert_middleware_usage(post_middleware, True, True, False, True, True)
self.assert_middleware_usage(pre_middleware, True, False, False, True, False) self.assert_middleware_usage(bad_middleware, True, False, False, True, False) self.assert_middleware_usage(post_middleware, False, False, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(bad_middleware, True, True, False, True, False) self.assert_middleware_usage(post_middleware, True, False, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, False, True) self.assert_middleware_usage(bad_middleware, True, True, False, True, True) self.assert_middleware_usage(post_middleware, True, True, False, True, True)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(bad_middleware, True, True, False, True, True) self.assert_middleware_usage(post_middleware, True, True, False, True, True)
self.assert_middleware_usage(pre_middleware, True, False, False, True, False) self.assert_middleware_usage(bad_middleware, True, False, False, True, False) self.assert_middleware_usage(post_middleware, False, False, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(bad_middleware, True, True, False, True, False) self.assert_middleware_usage(post_middleware, True, False, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, False, False) self.assert_middleware_usage(bad_middleware, True, True, False, True, False) self.assert_middleware_usage(post_middleware, True, True, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(bad_middleware, True, True, False, True, False) self.assert_middleware_usage(post_middleware, True, True, False, True, False)
self.assert_middleware_usage(pre_middleware, True, False, False, True, False) self.assert_middleware_usage(bad_middleware, True, False, False, True, False) self.assert_middleware_usage(post_middleware, False, False, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(bad_middleware, True, True, False, True, False) self.assert_middleware_usage(post_middleware, True, False, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, False, True) self.assert_middleware_usage(bad_middleware, True, True, False, True, True) self.assert_middleware_usage(post_middleware, True, True, False, True, True)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(bad_middleware, True, True, False, True, True) self.assert_middleware_usage(post_middleware, True, True, False, True, True)
self.assert_middleware_usage(pre_middleware, True, True, False, False, False) self.assert_middleware_usage(middleware, True, True, False, True, False) self.assert_middleware_usage(post_middleware, True, True, False, True, False)
self.assert_middleware_usage(pre_middleware, True, True, False, True, False) self.assert_middleware_usage(middleware, True, True, True, True, False) self.assert_middleware_usage(post_middleware, True, True, True, True, False)
del settings.ROOT_URLCONF with self.assertRaises(AttributeError): self.client.get("/middleware_exceptions/view/")
data_abstract = models.CharField(max_length=10) fk_abstract = models.ForeignKey(Relation, models.CASCADE, related_name='fk_abstract_rel')
m2m_abstract = models.ManyToManyField(Relation, related_name='m2m_abstract_rel') friends_abstract = models.ManyToManyField('self', related_name='friends_abstract', symmetrical=True) following_abstract = models.ManyToManyField('self', related_name='followers_abstract', symmetrical=False)
data_not_concrete_abstract = models.ForeignObject( Relation, on_delete=models.CASCADE, from_fields=['abstract_non_concrete_id'], to_fields=['id'], related_name='fo_abstract_rel', )
content_type_abstract = models.ForeignKey(ContentType, models.CASCADE, related_name='+') object_id_abstract = models.PositiveIntegerField() content_object_abstract = GenericForeignKey('content_type_abstract', 'object_id_abstract')
generic_relation_abstract = GenericRelation(Relation)
data_base = models.CharField(max_length=10) fk_base = models.ForeignKey(Relation, models.CASCADE, related_name='fk_base_rel')
m2m_base = models.ManyToManyField(Relation, related_name='m2m_base_rel') friends_base = models.ManyToManyField('self', related_name='friends_base', symmetrical=True) following_base = models.ManyToManyField('self', related_name='followers_base', symmetrical=False)
data_not_concrete_base = models.ForeignObject( Relation, on_delete=models.CASCADE, from_fields=['base_non_concrete_id'], to_fields=['id'], related_name='fo_base_rel', )
content_type_base = models.ForeignKey(ContentType, models.CASCADE, related_name='+') object_id_base = models.PositiveIntegerField() content_object_base = GenericForeignKey('content_type_base', 'object_id_base')
generic_relation_base = GenericRelation(Relation)
data_inherited = models.CharField(max_length=10) fk_inherited = models.ForeignKey(Relation, models.CASCADE, related_name='fk_concrete_rel')
m2m_inherited = models.ManyToManyField(Relation, related_name='m2m_concrete_rel') friends_inherited = models.ManyToManyField('self', related_name='friends_concrete', symmetrical=True) following_inherited = models.ManyToManyField('self', related_name='followers_concrete', symmetrical=False)
data_not_concrete_inherited = models.ForeignObject( Relation, on_delete=models.CASCADE, from_fields=['model_non_concrete_id'], to_fields=['id'], related_name='fo_concrete_rel', )
content_type_concrete = models.ForeignKey(ContentType, models.CASCADE, related_name='+') object_id_concrete = models.PositiveIntegerField() content_object_concrete = GenericForeignKey('content_type_concrete', 'object_id_concrete')
generic_relation_concrete = GenericRelation(Relation)
baseperson = models.ForeignKey(BasePerson, models.CASCADE, related_name='relating_baseperson') baseperson_hidden = models.ForeignKey(BasePerson, models.CASCADE, related_name='+')
person = models.ForeignKey(Person, models.CASCADE, related_name='relating_person') person_hidden = models.ForeignKey(Person, models.CASCADE, related_name='+')
proxyperson = models.ForeignKey(ProxyPerson, models.CASCADE, related_name='relating_proxyperson') proxyperson_hidden = models.ForeignKey(ProxyPerson, models.CASCADE, related_name='relating_proxyperson_hidden+')
basepeople = models.ManyToManyField(BasePerson, related_name='relating_basepeople') basepeople_hidden = models.ManyToManyField(BasePerson, related_name='+')
people = models.ManyToManyField(Person, related_name='relating_people') people_hidden = models.ManyToManyField(Person, related_name='+')
class CommonAncestor(models.Model): pass
fields = Person._meta.get_fields() with self.assertRaisesMessage(AttributeError, msg): fields += ["errors"]
opts.apps.models_ready = False try: self.assertTrue(opts.get_field('data_abstract')) msg = ( "Person has no field named 'relating_baseperson'. The app " "cache isn't ready yet, so if this is an auto-created related " "field, it won't be available yet." ) with self.assertRaisesMessage(FieldDoesNotExist, msg): opts.get_field('relating_baseperson') finally: opts.apps.models_ready = True
all_models_with_cache = (m for m in self.all_models if not m._meta.abstract) for m in all_models_with_cache: self.assertNotIn('_relation_tree', m._meta.__dict__)
self.assertTrue(self.all_models[0]._meta._relation_tree)
self.assertEqual(AbstractPerson._meta._relation_tree, EMPTY_RELATION_TREE)
all_models_but_abstractperson = (m for m in self.all_models if m is not AbstractPerson) for m in all_models_but_abstractperson: self.assertIn('_relation_tree', m._meta.__dict__)
self.assertEqual( sorted([field.related_query_name() for field in Relation._meta._relation_tree if not field.remote_field.field.remote_field.is_hidden()]), sorted([ 'fk_abstract_rel', 'fk_base_rel', 'fk_concrete_rel', 'fo_abstract_rel', 'fo_base_rel', 'fo_concrete_rel', 'm2m_abstract_rel', 'm2m_base_rel', 'm2m_concrete_rel' ]) ) self.assertEqual( sorted([field.related_query_name() for field in BasePerson._meta._relation_tree]), sorted([ '+', '_relating_basepeople_hidden_+', 'BasePerson_following_abstract+', 'BasePerson_following_abstract+', 'BasePerson_following_base+', 'BasePerson_following_base+', 'BasePerson_friends_abstract+', 'BasePerson_friends_abstract+', 'BasePerson_friends_base+', 'BasePerson_friends_base+', 'BasePerson_m2m_abstract+', 'BasePerson_m2m_base+', 'Relating_basepeople+', 'Relating_basepeople_hidden+', 'followers_abstract', 'followers_base', 'friends_abstract_rel_+', 'friends_base_rel_+', 'person', 'relating_basepeople', 'relating_baseperson', ]) ) self.assertEqual([field.related_query_name() for field in AbstractPerson._meta._relation_tree], [])
import argparse import atexit import copy import os import shutil import subprocess import sys import tempfile import warnings
warnings.simplefilter("error", RemovedInDjango20Warning) warnings.simplefilter("error", RuntimeWarning) warnings.filterwarnings("ignore", "'U' mode is deprecated", DeprecationWarning, module='docutils.io')
TMPDIR = tempfile.mkdtemp(prefix='django_') tempfile.tempdir = os.environ['TMPDIR'] = TMPDIR
atexit.register(shutil.rmtree, six.text_type(TMPDIR))
CONTRIB_TESTS_TO_APPS = { 'flatpages_tests': 'django.contrib.flatpages', 'redirects_tests': 'django.contrib.redirects', }
('gis_tests', os.path.join(RUNTESTS_DIR, 'gis_tests')),
def no_available_apps(self): raise Exception("Please define available_apps in TransactionTestCase " "and its subclasses.") TransactionTestCase.available_apps = property(no_available_apps) TestCase.available_apps = None
settings.INSTALLED_APPS = ALWAYS_INSTALLED_APPS settings.ROOT_URLCONF = 'urls' settings.STATIC_URL = '/static/' settings.STATIC_ROOT = os.path.join(TMPDIR, 'static') settings.TEMPLATES = [{ 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [TEMPLATE_DIR], 'APP_DIRS': True, 'OPTIONS': { 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], }, }] settings.LANGUAGE_CODE = 'en' settings.SITE_ID = 1 settings.MIDDLEWARE = ALWAYS_MIDDLEWARE settings.MIGRATION_MODULES = { 'auth': None, 'contenttypes': None, 'sessions': None, } log_config = copy.deepcopy(DEFAULT_LOGGING) log_config['loggers']['django']['level'] = 'ERROR' settings.LOGGING = log_config
django.setup()
test_modules = get_test_modules()
test_labels_set = set() for label in test_labels: bits = label.split('.')[:1] test_labels_set.add('.'.join(bits))
if not test_labels: module_found_in_labels = True else: module_found_in_labels = any( module_label == label or module_label.startswith(label + '.') for label in test_labels_set)
gis = 'django.contrib.gis' if connection.features.gis_enabled and gis not in settings.INSTALLED_APPS: if verbosity >= 2: print("Importing application %s" % gis) settings.INSTALLED_APPS.append(gis)
for key, value in state.items(): setattr(settings, key, value)
if all(conn.features.can_clone_databases for conn in connections.all()): return default_test_processes() else: return 1
if not hasattr(settings, 'TEST_RUNNER'): settings.TEST_RUNNER = 'django.test.runner.DiscoverRunner' TestRunner = get_runner(settings)
for label in [bisection_label, 'model_inheritance_same_model_name']: try: test_labels.remove(label) except ValueError: pass
for label in [paired_test, 'model_inheritance_same_model_name']: try: test_labels.remove(label) except ValueError: pass
try:
options.modules = [os.path.normpath(labels) for labels in options.modules]
request.process_response_content = response.content request.process_response_reached = True return response
self.assertFalse(getattr(request, 'process_template_response_reached', False)) self.assertTrue(getattr(request, 'process_response_reached', False))
self.assertFalse(response._is_rendered) self.assertFalse(getattr(request, 'process_response_reached', False)) response.render() self.assertTrue(getattr(request, 'process_response_reached', False)) self.assertEqual(request.process_response_content, b"Hello world")
from __future__ import unicode_literals
self.assertIn(npath(filename), autoreload.gen_filenames()) self.assertIn(npath(filename), autoreload.gen_filenames())
self.assertNotIn(npath(filename), autoreload.gen_filenames()) self.assertNotIn(npath(filename), autoreload.gen_filenames())
self.assertIn(npath(filename), autoreload.gen_filenames(only_new=True)) self.assertNotIn(npath(filename), autoreload.gen_filenames(only_new=True))
self.clear_autoreload_caches() filenames = set(autoreload.gen_filenames(only_new=True)) filenames_reference = set(autoreload.gen_filenames()) self.assertEqual(filenames, filenames_reference)
filenames = set(autoreload.gen_filenames(only_new=True)) self.assertEqual(filenames, set())
with extend_sys_path(dirname): import_module('test_only_new_module') filenames = set(autoreload.gen_filenames(only_new=True)) self.assertEqual(filenames, {npath(filename)})
from __future__ import unicode_literals
("a//b", ["id a", "linecomment //b"]), ("/****/a/=2//hello", ["comment /****/", "id a", "punct /=", "dnum 2", "linecomment //hello"]), ("/*\n * Header\n */\na=1;", ["comment /*\n * Header\n */", "id a", "punct =", "dnum 1", "punct ;"]), ("a+++b", ["id a", "punct ++", "punct +", "id b"]), (r"a=/a*/,1", ["id a", "punct =", "regex /a*/", "punct ,", "dnum 1"]), (r"a=/a*[^/]+/,1", ["id a", "punct =", "regex /a*[^/]+/", "punct ,", "dnum 1"]), (r"a=/a*\[^/,1", ["id a", "punct =", r"regex /a*\[^/", "punct ,", "dnum 1"]), (r"a=/\//,1", ["id a", "punct =", r"regex /\//", "punct ,", "dnum 1"]),
self.assertEqual(parse_date('2012-04-23'), date(2012, 4, 23)) self.assertEqual(parse_date('2012-4-9'), date(2012, 4, 9)) self.assertEqual(parse_date('20120423'), None) with self.assertRaises(ValueError): parse_date('2012-04-56')
self.assertEqual(parse_time('09:15:00'), time(9, 15)) self.assertEqual(parse_time('10:10'), time(10, 10)) self.assertEqual(parse_time('10:20:30.400'), time(10, 20, 30, 400000)) self.assertEqual(parse_time('4:8:16'), time(4, 8, 16)) self.assertEqual(parse_time('091500'), None) with self.assertRaises(ValueError): parse_time('09:15:90')
self.assertEqual( parse_datetime('2012-04-23T09:15:00'), datetime(2012, 4, 23, 9, 15) ) self.assertEqual( parse_datetime('2012-4-9 4:8:16'), datetime(2012, 4, 9, 4, 8, 16) ) self.assertEqual( parse_datetime('2012-04-23T09:15:00Z'), datetime(2012, 4, 23, 9, 15, 0, 0, get_fixed_timezone(0)) ) self.assertEqual( parse_datetime('2012-4-9 4:8:16-0320'), datetime(2012, 4, 9, 4, 8, 16, 0, get_fixed_timezone(-200)) ) self.assertEqual( parse_datetime('2012-04-23T10:20:30.400+02:30'), datetime(2012, 4, 23, 10, 20, 30, 400000, get_fixed_timezone(150)) ) self.assertEqual( parse_datetime('2012-04-23T10:20:30.400+02'), datetime(2012, 4, 23, 10, 20, 30, 400000, get_fixed_timezone(120)) ) self.assertEqual( parse_datetime('2012-04-23T10:20:30.400-02'), datetime(2012, 4, 23, 10, 20, 30, 400000, get_fixed_timezone(-120)) ) self.assertEqual(parse_datetime('20120423091500'), None) with self.assertRaises(ValueError): parse_datetime('2012-04-56T09:15:90')
return self.replace('<', '<<').replace('>', '>>')
ambiguous = datetime.datetime(2015, 10, 25, 2, 30)
non_existent = datetime.datetime(2015, 3, 29, 2, 30)
std = timezone.localtime(timezone.localtime(std, timezone.UTC()), CET) dst = timezone.localtime(timezone.localtime(dst, timezone.UTC()), CET) self.assertEqual((std.hour, std.minute), (3, 30)) self.assertEqual((dst.hour, dst.minute), (1, 30))
from __future__ import unicode_literals
exception = TypeError if six.PY3 else UnicodeError with self.assertRaises(exception): force_text(MyString())
('red%09ros#red', 'red%09ros%C3%A9#red'), ('/blog/for/Jrgen Mnster/', '/blog/for/J%C3%BCrgen%20M%C3%BCnster/'), ('locations/%s' % urlquote_plus('Paris & Orlans'), 'locations/Paris+%26+Orl%C3%A9ans'),
('%&', '%&'), ('red&ros%#red', 'red&%E2%99%A5ros%#red'),
self.assertEqual(iri_to_uri(iri_to_uri(iri)), uri)
('/%E2%99%A5%E2%99%A5/', '//'), ('/%E2%99%A5%E2%99%A5/?utf8=%E2%9C%93', '//?utf8='),
('/%AAd%AAj%AAa%AAn%AAg%AAo%AA/', '/%AAd%AAj%AAa%AAn%AAg%AAo%AA/'), ('/%E2%99%A5%E2%E2%99%A5/', '/%E2/'), ('/%E2%99%A5%E2%99%E2%99%A5/', '/%E2%99/'), ('/%E2%E2%99%A5%E2%99%A5%99/', '/%E2%99/'), ('/%E2%99%A5%E2%99%A5/?utf8=%9C%93%E2%9C%93%9C%93', '//?utf8=%9C%93%9C%93'),
self.assertEqual(uri_to_iri(uri_to_iri(uri)), iri)
self.assertTrue(constant_time_compare(b'spam', b'spam')) self.assertFalse(constant_time_compare(b'spam', b'eggs')) self.assertTrue(constant_time_compare('spam', 'spam')) self.assertFalse(constant_time_compare('spam', 'eggs'))
rfc_vectors = [ { "args": { "password": "password", "salt": "salt", "iterations": 1, "dklen": 20, "digest": hashlib.sha1, }, "result": "0c60c80f961f0e71f3a9b524af6012062fe037a6", }, { "args": { "password": "password", "salt": "salt", "iterations": 2, "dklen": 20, "digest": hashlib.sha1, }, "result": "ea6c014dc72d6f8ccd1ed92ace1d41f0d8de8957", }, { "args": { "password": "password", "salt": "salt", "iterations": 4096, "dklen": 20, "digest": hashlib.sha1, }, "result": "4b007901b765489abead49d926f721d065a429c1", }, { "args": { "password": "passwordPASSWORDpassword", "salt": "saltSALTsaltSALTsaltSALTsaltSALTsalt", "iterations": 4096, "dklen": 25, "digest": hashlib.sha1, }, "result": "3d2eec4fe41c849b80c8d83662c0e44a8b291a964cf2f07038", }, { "args": { "password": "pass\0word", "salt": "sa\0lt", "iterations": 4096, "dklen": 16, "digest": hashlib.sha1, }, "result": "56fa6aa75548099dcc37d7f03425e0c3", }, ]
{ "args": { "password": b'\xba', "salt": "salt", "iterations": 1, "dklen": 20, "digest": hashlib.sha1, }, "result": '0053d3b91a7f1e54effebd6d68771e8a6e0b2c5b', },
self.assertTrue(is_valid_ipv6_address('::254.42.16.14')) self.assertTrue(is_valid_ipv6_address('::0a0a:0a0a')) self.assertFalse(is_valid_ipv6_address('::999.42.16.14')) self.assertFalse(is_valid_ipv6_address('::zzzz:0a0a'))
def test_latest_post_date_returns_utc_time(self): for use_tz in (True, False): with self.settings(USE_TZ=use_tz): rss_feed = feedgenerator.Rss201rev2Feed('title', 'link', 'description') self.assertEqual(rss_feed.latest_post_date().tzinfo, utc)
user = User.objects.create_user('johndoe', 'john@example.com', 'pass') x = SimpleLazyObject(lambda: user)
pickle.dumps(x)
pickle.dumps(x, 0) pickle.dumps(x, 1) pickle.dumps(x, 2)
cPickle.dumps(x)
dt = datetime(2015, 10, 25, 2, 30, 0)
self.assertEqual(format(dt, 'I'), '0' if pytz is None else '') self.assertEqual(format(dt, 'O'), '+0100' if pytz is None else '') self.assertEqual(format(dt, 'T'), 'CET' if pytz is None else '') self.assertEqual(format(dt, 'Z'), '3600' if pytz is None else '')
self.assertEqual(datetime.fromtimestamp(int(format(dt, 'U'))), dt.astimezone(ltz).replace(tzinfo=None)) self.assertEqual(datetime.fromtimestamp(int(format(dt, 'U')), tz).utctimetuple(), dt.utctimetuple()) self.assertEqual(datetime.fromtimestamp(int(format(dt, 'U')), ltz).utctimetuple(), dt.utctimetuple())
dt = datetime(2009, 5, 16, microsecond=123) self.assertEqual(dateformat.format(dt, 'u'), '000123')
tz = get_fixed_timezone(-210) aware_dt = datetime(2009, 5, 16, 5, 30, 30, tzinfo=tz)
self.assertEqual(dateformat.format(aware_dt, 'O'), '-0330')
self.assertTrue(module_has_submodule(test_module, 'good_module')) mod = import_module('utils_tests.test_module.good_module') self.assertEqual(mod.content, 'Good Module')
self.assertTrue(module_has_submodule(test_module, 'bad_module')) with self.assertRaises(ImportError): import_module('utils_tests.test_module.bad_module')
self.assertFalse(module_has_submodule(test_module, 'no_such_module')) with self.assertRaises(ImportError): import_module('utils_tests.test_module.no_such_module')
self.assertFalse(module_has_submodule(test_module, 'django')) with self.assertRaises(ImportError): import_module('utils_tests.test_module.django')
self.assertFalse(module_has_submodule(test_no_submodule, 'anything')) with self.assertRaises(ImportError): import_module('utils_tests.test_no_submodule.anything')
self.assertTrue(module_has_submodule(egg_module, 'good_module')) mod = import_module('egg_module.good_module') self.assertEqual(mod.content, 'Good Module')
self.assertTrue(module_has_submodule(egg_module, 'bad_module')) with self.assertRaises(ImportError): import_module('egg_module.bad_module')
self.assertFalse(module_has_submodule(egg_module, 'no_such_module')) with self.assertRaises(ImportError): import_module('egg_module.no_such_module')
self.assertTrue(module_has_submodule(egg_module, 'good_module')) mod = import_module('egg_module.sub1.sub2.good_module') self.assertEqual(mod.content, 'Deep Good Module')
self.assertTrue(module_has_submodule(egg_module, 'bad_module')) with self.assertRaises(ImportError): import_module('egg_module.sub1.sub2.bad_module')
self.assertFalse(module_has_submodule(egg_module, 'no_such_module')) with self.assertRaises(ImportError): import_module('egg_module.sub1.sub2.no_such_module')
with self.assertRaises(ImportError): import_string('no_dots_in_path') msg = 'Module "utils_tests" does not define a "unexistent" attribute' with self.assertRaisesMessage(ImportError, msg): import_string('utils_tests.unexistent')
obj = self.lazy_wrap(Foo()) obj.bar = 'baz' obj.foo = 'BAR' self.assertEqual(obj.foo, 'BAR') self.assertEqual(obj.bar, 'baz')
for f in [False, 0, (), {}, [], None, set()]: self.assertFalse(self.lazy_wrap(f)) for t in [True, 1, (1,), {1: 2}, [1], object(), {1}]: self.assertTrue(t)
for needle_haystack in test_data[1:]: self.assertIn(self.lazy_wrap(needle), haystack) self.assertIn(self.lazy_wrap(needle), self.lazy_wrap(haystack))
obj = self.lazy_wrap(Foo()) pickled = pickle.dumps(obj) unpickled = pickle.loads(pickled) self.assertIsInstance(unpickled, Foo) self.assertEqual(unpickled, obj) self.assertEqual(unpickled.foo, obj.foo)
l = [1, 2, 3]
l = [1, 2, 3]
foo = Foo()
foo = Foo()
l = [1, 2, 3]
l = [1, 2, 3]
foo = Foo()
foo = Foo()
def lazy_wrap(self, wrapped_object): return SimpleLazyObject(lambda: wrapped_object)
obj = self.lazy_wrap(42) six.assertRegex(self, repr(obj), '^<SimpleLazyObject:')
old_trace_func = sys.gettrace() try: def trace_func(frame, event, arg): frame.f_locals['self'].__class__ if old_trace_func is not None: old_trace_func(frame, event, arg) sys.settrace(trace_func) self.lazy_wrap(None) finally: sys.settrace(old_trace_func)
lazydict = SimpleLazyObject(lambda: {'one': 1}) self.assertEqual(lazydict['one'], 1) lazydict['one'] = -1 self.assertEqual(lazydict['one'], -1) self.assertIn('one', lazydict) self.assertNotIn('two', lazydict) self.assertEqual(len(lazydict), 1) del lazydict['one'] with self.assertRaises(KeyError): lazydict['one']
for protocol in range(pickle.HIGHEST_PROTOCOL + 1): lazy_objs = [ SimpleLazyObject(lambda: BaseBaz()), SimpleLazyObject(lambda: Baz(1)), SimpleLazyObject(lambda: BazProxy(Baz(2))), ] for obj in lazy_objs: pickled = pickle.dumps(obj, protocol) unpickled = pickle.loads(pickled) self.assertEqual(unpickled, obj) self.assertEqual(unpickled.baz, 'right')
for protocol in range(pickle.HIGHEST_PROTOCOL + 1): lazy_category = SimpleLazyObject(lambda: category) lazy_category.categoryinfo lazy_category_2 = SimpleLazyObject(lambda: category) with warnings.catch_warnings(record=True) as recorded: self.assertEqual(pickle.loads(pickle.dumps(lazy_category, protocol)), category) self.assertEqual(pickle.loads(pickle.dumps(lazy_category_2, protocol)), category) self.assertEqual(len(recorded), 0)
from __future__ import unicode_literals
self.assertEqual(A.value.__doc__, "Here is the docstring...")
self.assertEqual(a.value, a.value)
self.assertEqual(a.value[0], 1)
a2 = A() self.assertNotEqual(a.value, a2.value)
self.assertIsInstance(A.value, cached_property)
self.assertEqual(a.other, 1) self.assertTrue(callable(a.other_value))
self.assertEqual(timesince(self.t, self.t), '0\xa0minutes')
self.assertEqual(date(*self.just_safe).strftime('%y'), '00') self.assertEqual(datetime(*self.just_safe).strftime('%y'), '00')
s = OrderedSet() self.assertFalse(s) s.add(1) self.assertTrue(s)
with self.assertRaisesMessage(AttributeError, 'ImmutableList object is immutable.'): d.sort()
with self.assertRaisesMessage(AttributeError, 'Object is immutable!'): d.__setitem__(1, 'test')
from __future__ import unicode_literals
patterns = ("%s", "asdf%sfdsa", "%s1", "1%sb") for value, output in items: for pattern in patterns: self.check_output(f, pattern % value, pattern % output) self.check_output(f, lazystr(pattern % value), pattern % output) self.check_output(f, value * 2, output * 2) self.check_output(f, '<&', '&lt;&amp;')
('&gotcha&#;<>', '&gotcha&#;<>'),
output = html.strip_tags('<sc<!-- -->ript>test<<!-- -->/script>') self.assertNotIn('<script>', output) self.assertIn('test', output) output = html.strip_tags('<script>alert()</script>&h') self.assertNotIn('<script>', output) self.assertIn('alert()', output)
for filename in ('strip_tags1.html', 'strip_tags2.txt'): path = os.path.join(os.path.dirname(upath(__file__)), 'files', filename) with open(path, 'r') as fp: content = force_text(fp.read()) start = datetime.now() stripped = html.strip_tags(content) elapsed = datetime.now() - start self.assertEqual(elapsed.seconds, 0) self.assertIn("Please try again.", stripped) self.assertNotIn('<', stripped)
items = (' <adf>', '<adf> ', ' </adf> ', ' <f> x</f>') for value in items: self.check_output(f, value) self.check_output(f, lazystr(value)) items = ( ('<d> </d>', '<d></d>'), ('<p>hello </p>\n<p> world</p>', '<p>hello </p><p> world</p>'), ('\n<p>\t</p>\n<p> </p>\n', '\n<p></p><p></p>\n'), ) for value, output in items: self.check_output(f, value, output) self.check_output(f, lazystr(value), output)
self.assertEqual(quote('http://.com/'), 'http://xn--4ca9at.com/') self.assertEqual(quote('http://.com//'), 'http://xn--4ca9at.com/%C3%B6%C3%A4%C3%BC/') self.assertEqual(quote('http://example.com/path//'), 'http://example.com/path/%C3%B6%C3%A4%C3%BC/') self.assertEqual(quote('http://example.com/%C3%B6//'), 'http://example.com/%C3%B6/%C3%A4/') self.assertEqual(quote('http://example.com/?x=1&y=2+3&z='), 'http://example.com/?x=1&y=2+3&z=') self.assertEqual(quote('http://example.com/?x=<>"\''), 'http://example.com/?x=%3C%3E%22%27') self.assertEqual(quote('http://example.com/?q=http://example.com/?x=1%26q=django'), 'http://example.com/?q=http%3A%2F%2Fexample.com%2F%3Fx%3D1%26q%3Ddjango') self.assertEqual(quote('http://example.com/?q=http%3A%2F%2Fexample.com%2F%3Fx%3D1%26q%3Ddjango'), 'http://example.com/?q=http%3A%2F%2Fexample.com%2F%3Fx%3D1%26q%3Ddjango')
return 'some html content'
return 'some html safe content'
return 'some html content'
return 'some html safe content'
from __future__ import unicode_literals
result = http.urlencode((('a', 1), ('b', 2), ('c', 3))) self.assertEqual(result, 'a=1&b=2&c=3')
result = http.urlencode({'a': 1, 'b': 2, 'c': 3}) acceptable_results = [ 'a=1&b=2&c=3', 'a=1&c=3&b=2', 'b=2&a=1&c=3', 'b=2&c=3&a=1', 'c=3&a=1&b=2', 'c=3&b=2&a=1' ] self.assertIn(result, acceptable_results) result = http.urlencode({'a': [1, 2]}, doseq=False) self.assertEqual(result, 'a=%5B%271%27%2C+%272%27%5D') result = http.urlencode({'a': [1, 2]}, doseq=True) self.assertEqual(result, 'a=1&a=2') result = http.urlencode({'a': []}, doseq=True) self.assertEqual(result, '')
result = http.urlencode(MultiValueDict({ 'name': ['Adrian', 'Simon'], 'position': ['Developer'] }), doseq=True) acceptable_results = [ 'name=Adrian&name=Simon&position=Developer', 'position=Developer&name=Adrian&name=Simon' ] self.assertIn(result, acceptable_results)
for n in [0, 1, 1000, 1000000]: self.assertEqual(n, http.base36_to_int(http.int_to_base36(n))) if six.PY2: self.assertEqual(sys.maxint, http.base36_to_int(http.int_to_base36(sys.maxint)))
with self.assertRaises(ValueError): http.int_to_base36(-1) if six.PY2: with self.assertRaises(ValueError): http.int_to_base36(sys.maxint + 1) for n in ['1', 'foo', {1: 2}, (1, 2, 3), 3.141]: with self.assertRaises(TypeError): http.int_to_base36(n)
for n, b36 in [(0, '0'), (1, '1'), (42, '16'), (818469960, 'django')]: self.assertEqual(http.int_to_base36(n), b36) self.assertEqual(http.base36_to_int(b36), n)
self.assertTrue( http.is_safe_url(b'https://testserver/', host='testserver'), "binary URLs should be allowed on Python 2" ) self.assertFalse(http.is_safe_url(b'\x08//example.com', host='testserver')) self.assertTrue(http.is_safe_url('view/'.encode('utf-8'), host='testserver')) self.assertFalse(http.is_safe_url('view'.encode('latin-1'), host='testserver'))
self.assertTrue(http.is_safe_url(r'http://user:pass@testserver/', host='user:pass@testserver')) self.assertTrue(http.is_safe_url('/confirm/me@example.com')) self.assertFalse(http.is_safe_url(r'http://testserver\@example.com'))
node3 = Node(self.node1_children) node3_added_child = ('c', 3) self.assertEqual(node3.add(node3_added_child, Node.default), node3_added_child) self.assertEqual(len(self.node1) + 1, len(node3)) self.assertEqual(str(node3), "(DEFAULT: ('a', 1), ('b', 2), ('c', 3))")
self.assertFalse(self.node1.negated) self.node1.negate() self.assertTrue(self.node1.negated) self.node1.negate() self.assertFalse(self.node1.negated)
from __future__ import unicode_literals
from __future__ import unicode_literals
nfc = text.Truncator('o\xfco\xfco\xfco\xfc') nfd = text.Truncator('ou\u0308ou\u0308ou\u0308ou\u0308') self.assertEqual('oooo', nfc.chars(8)) self.assertEqual('oooo', nfd.chars(8)) self.assertEqual('o...', nfc.chars(5)) self.assertEqual('o...', nfd.chars(5))
truncator = text.Truncator('-B\u030AB\u030A----8') self.assertEqual('-B\u030A...', truncator.chars(5)) self.assertEqual('-B\u030AB\u030A-...', truncator.chars(7)) self.assertEqual('-B\u030AB\u030A----8', truncator.chars(8))
truncator = text.Truncator('-----') self.assertEqual('---B\u030A', truncator.chars(4, 'B\u030A')) self.assertEqual('-----', truncator.chars(5, 'B\u030A'))
self.assertEqual('...', text.Truncator('asdf').chars(1)) self.assertEqual(text.Truncator(lazystr('The quick brown fox')).chars(12), 'The quick...')
truncator = text.Truncator(lazystr('The quick brown fox jumped over the lazy dog.')) self.assertEqual('The quick brown fox...', truncator.words(4))
truncator = text.Truncator( '<p>The quick <a href="xyz.html"\n id="mylink">brown fox</a> jumped over the lazy dog.</p>' ) self.assertEqual( '<p>The quick <a href="xyz.html"\n id="mylink">brown...</a></p>', truncator.words(3, '...', html=True) )
truncator = text.Truncator('<br/>The <hr />quick brown fox jumped over the lazy dog.') self.assertEqual('<br/>The <hr />quick brown...', truncator.words(3, '...', html=True)) truncator = text.Truncator('<br>The <hr/>quick <em>brown fox</em> jumped over the lazy dog.') self.assertEqual('<br>The <hr/>quick <em>brown...</em>', truncator.words(3, '...', html=True))
truncator = text.Truncator('<i>Buenos d&iacute;as! &#x00bf;C&oacute;mo est&aacute;?</i>') self.assertEqual('<i>Buenos d&iacute;as! &#x00bf;C&oacute;mo...</i>', truncator.words(3, '...', html=True)) truncator = text.Truncator('<p>I &lt;3 python, what about you?</p>') self.assertEqual('<p>I &lt;3 python...</p>', truncator.words(3, '...', html=True))
('Hello, World!', 'hello-world', False), ('spam & eggs', 'spam-eggs', False), ('spam & ', 'spam-', True), ('foo  bar', 'foo--bar', True), (' foo  bar', 'foo--bar', True), ('', '', True),
os.chdir(TEST_DIR)
s = Site.objects.get_current() self.assertIsInstance(s, Site) s.delete() with self.assertRaises(ObjectDoesNotExist): Site.objects.get_current()
site = Site.objects.get_current() self.assertEqual("example.com", site.name) s2 = Site.objects.get(id=settings.SITE_ID) s2.name = "Example site" s2.save() site = Site.objects.get_current() self.assertEqual("Example site", site.name)
self.assertIsInstance(Site.objects.get_current(), Site) Site.objects.all().delete() with self.assertRaises(Site.DoesNotExist): Site.objects.get_current()
request = HttpRequest() request.META = { "SERVER_NAME": "example.com", "SERVER_PORT": "80", } site = get_current_site(request) self.assertIsInstance(site, Site) self.assertEqual(site.id, settings.SITE_ID)
site.delete() with self.assertRaises(ObjectDoesNotExist): get_current_site(request)
with self.modify_settings(INSTALLED_APPS={'remove': 'django.contrib.sites'}): site = get_current_site(request) self.assertIsInstance(site, RequestSite) self.assertEqual(site.name, "example.com")
request.META = {'HTTP_HOST': 'example.com'} site = get_current_site(request) self.assertEqual(site, s1)
request.META = {'HTTP_HOST': 'example.com:80'} site = get_current_site(request) self.assertEqual(site, s2)
request.META = {'HTTP_HOST': 'example.com:81'} site = get_current_site(request) self.assertEqual(site, s1)
request.META = {'HTTP_HOST': 'example.net'} with self.assertRaises(ObjectDoesNotExist): get_current_site(request)
with self.modify_settings(INSTALLED_APPS={'remove': 'django.contrib.sites'}): request.META = {'HTTP_HOST': 'example.com'} site = get_current_site(request) self.assertEqual(site.name, 'example.com')
site = Site(name="test name", domain="test test") with self.assertRaises(ValidationError): site.full_clean() site.domain = "test\ttest" with self.assertRaises(ValidationError): site.full_clean() site.domain = "test\ntest" with self.assertRaises(ValidationError): site.full_clean()
clear_site_cache(Site, instance=site, using='other') self.assertEqual(models.SITE_CACHE, expected_cache) clear_site_cache(Site, instance=site, using='default') self.assertEqual(models.SITE_CACHE, {})
request = HttpRequest() request.META = { "HTTP_HOST": "example.com", } msg = 'RequestSite cannot be saved.' with self.assertRaisesMessage(NotImplementedError, msg): RequestSite(request).save()
request = HttpRequest() request.META = { "HTTP_HOST": "example.com", } msg = 'RequestSite cannot be deleted.' with self.assertRaisesMessage(NotImplementedError, msg): RequestSite(request).delete()
Site.objects.all().delete()
pass
Book._meta.apps.ready = False try: errors = BookAdminWithListFilter(Book, AdminSite()).check() self.assertEqual(errors, []) finally: Book._meta.apps.ready = True
data = {'var': '\xf2'} response = self.client.get('/get_view/', data)
self.assertContains(response, 'This is a test') self.assertEqual(response.context['var'], '\xf2') self.assertEqual(response.templates[0].name, 'GET Template')
self.assertEqual(response.status_code, 200) self.assertEqual(response.templates[0].name, 'Empty GET Template') self.assertTemplateUsed(response, 'Empty GET Template') self.assertTemplateNotUsed(response, 'Empty POST Template')
self.assertEqual(response.status_code, 200) self.assertEqual(response.templates[0].name, 'Empty POST Template') self.assertTemplateNotUsed(response, 'Empty GET Template') self.assertTemplateUsed(response, 'Empty POST Template')
self.assertEqual(response.status_code, 200) self.assertEqual(response.context['data'], '37') self.assertEqual(response.templates[0].name, 'POST Template') self.assertContains(response, 'Data received')
self.assertRedirects(response, '/get_view/')
self.assertRedirects(response, '/get_view/?var=value')
self.assertRedirects(response, '/get_view/', status_code=301)
self.assertRedirects(response, '/get_view/', status_code=302)
self.assertRedirects(response, '/permanent_redirect_view/', target_status_code=301)
self.assertContains(response, 'MAGIC', status_code=404)
self.assertContains(response, 'Select a valid choice.', 0)
self.assertEqual(response.status_code, 404)
self.assertEqual(response.request['PATH_INFO'], '/unknown_view/;some-parameter')
response = self.client.get('/login_protected_view/') self.assertRedirects(response, '/accounts/login/?next=/login_protected_view/')
login = self.client.login(username='testclient', password='password') self.assertTrue(login, 'Could not log in')
response = self.client.get('/login_protected_view/') self.assertEqual(response.status_code, 200) self.assertEqual(response.context['user'].username, 'testclient')
response = self.client.get('/login_protected_view/') self.assertRedirects(response, '/accounts/login/?next=/login_protected_view/')
self.client.force_login(self.u1)
response = self.client.get('/login_protected_view/') self.assertEqual(response.status_code, 200) self.assertEqual(response.context['user'].username, 'testclient')
response = self.client.get('/login_protected_method_view/') self.assertRedirects(response, '/accounts/login/?next=/login_protected_method_view/')
login = self.client.login(username='testclient', password='password') self.assertTrue(login, 'Could not log in')
response = self.client.get('/login_protected_method_view/') self.assertEqual(response.status_code, 200) self.assertEqual(response.context['user'].username, 'testclient')
response = self.client.get('/login_protected_method_view/') self.assertRedirects(response, '/accounts/login/?next=/login_protected_method_view/')
self.client.force_login(self.u1)
response = self.client.get('/login_protected_method_view/') self.assertEqual(response.status_code, 200) self.assertEqual(response.context['user'].username, 'testclient')
response = self.client.get('/login_protected_view_custom_redirect/') self.assertRedirects(response, '/accounts/login/?redirect_to=/login_protected_view_custom_redirect/')
login = self.client.login(username='testclient', password='password') self.assertTrue(login, 'Could not log in')
response = self.client.get('/login_protected_view_custom_redirect/') self.assertEqual(response.status_code, 200) self.assertEqual(response.context['user'].username, 'testclient')
response = self.client.get('/login_protected_view_custom_redirect/') self.assertRedirects(response, '/accounts/login/?redirect_to=/login_protected_view_custom_redirect/')
self.client.force_login(self.u1)
response = self.client.get('/login_protected_view_custom_redirect/') self.assertEqual(response.status_code, 200) self.assertEqual(response.context['user'].username, 'testclient')
response = self.client.get('/login_protected_view/') self.assertRedirects(response, '/accounts/login/?next=/login_protected_view/')
self.client.force_login(self.u2, backend='django.contrib.auth.backends.AllowAllUsersModelBackend')
response = self.client.get('/login_protected_view/') self.assertEqual(response.status_code, 200) self.assertEqual(response.context['user'].username, 'inactive')
self.client.login(username='testclient', password='password')
response = self.client.get('/login_protected_view/') self.assertEqual(response.status_code, 200) self.assertEqual(response.context['user'].username, 'testclient')
self.client.logout()
response = self.client.get('/login_protected_view/') self.assertRedirects(response, '/accounts/login/?next=/login_protected_view/')
self.client.force_login(self.u1)
response = self.client.get('/login_protected_view/') self.assertEqual(response.status_code, 200) self.assertEqual(response.context['user'].username, 'testclient')
self.client.logout()
response = self.client.get('/login_protected_view/') self.assertRedirects(response, '/accounts/login/?next=/login_protected_view/')
response = self.client.get('/login_protected_view/') self.assertRedirects(response, '/accounts/login/?next=/login_protected_view/')
self.client.force_login(self.u1, backend='test_client.auth_backends.TestClientBackend')
response = self.client.get('/login_protected_view/') self.assertEqual(response.status_code, 200) self.assertEqual(response.context['user'].username, 'testclient')
response = self.client.get('/permission_protected_view/') self.assertRedirects(response, '/accounts/login/?next=/permission_protected_view/')
login = self.client.login(username='testclient', password='password') self.assertTrue(login, 'Could not log in')
response = self.client.get('/permission_protected_view/') self.assertRedirects(response, '/accounts/login/?next=/permission_protected_view/')
response = self.client.get('/permission_protected_view_exception/') self.assertEqual(response.status_code, 403)
login = self.client.login(username='testclient', password='password') self.assertTrue(login, 'Could not log in')
response = self.client.get('/permission_protected_view_exception/') self.assertEqual(response.status_code, 403)
response = self.client.get('/permission_protected_method_view/') self.assertRedirects(response, '/accounts/login/?next=/permission_protected_method_view/')
login = self.client.login(username='testclient', password='password') self.assertTrue(login, 'Could not log in')
response = self.client.get('/permission_protected_method_view/') self.assertRedirects(response, '/accounts/login/?next=/permission_protected_method_view/')
try: self.client.session['tobacconist'] self.fail("Shouldn't have a session value") except KeyError: pass
self.assertEqual(self.client.session['tobacconist'], 'hovercraft')
try: self.client.get('/broken_view/') self.fail('Should raise an error') except KeyError: pass
self.assertContains(response, 'This is a test')
response = self.client.post('/post_view/', {}) self.assertEqual(response.status_code, 200)
response = csrf_client.post('/post_view/', {}) self.assertEqual(response.status_code, 403)
http_methods_and_views = ( ('get', get_view), ('post', post_view), ('put', _generic_view), ('patch', _generic_view), ('delete', _generic_view), ('head', _generic_view), ('options', _generic_view), ('trace', trace_view), )
def gzip_compress(data): buf = io.BytesIO() f = gzip.GzipFile(fileobj=buf, mode='wb', compresslevel=0) try: f.write(data) finally: f.close() return buf.getvalue()
res = HttpResponse('abc') conditional_content_removal(req, res) self.assertEqual(res.content, b'abc')
for status_code in (100, 150, 199, 204, 304): res = HttpResponse('abc', status=status_code) conditional_content_removal(req, res) self.assertEqual(res.content, b'')
abc = gzip_compress(b'abc') res = HttpResponse(abc, status=304) res['Content-Encoding'] = 'gzip' conditional_content_removal(req, res) self.assertEqual(res.content, b'')
req.method = 'HEAD'
return
@override_settings( INSTALLED_APPS=[ 'django.contrib.auth', 'django.contrib.contenttypes', 'user_commands', ], ) class CommandTests(SimpleTestCase): def test_command(self): out = StringIO() management.call_command('dance', stdout=out) self.assertIn("I don't feel like dancing Rock'n'Roll.\n", out.getvalue())
management.call_command('dance', '--style', 'Jive', stdout=out) self.assertIn("I don't feel like dancing Jive.\n", out.getvalue())
with translation.override('pl'): result = management.call_command('leave_locale_alone_false', stdout=StringIO()) self.assertIsNone(result)
with translation.override('pl'): result = management.call_command('leave_locale_alone_true', stdout=StringIO()) self.assertEqual(result, "pl")
for app_label in app_labels: if app_label.startswith('--'): raise CommandError("Sorry, Dave, I can't let you do that.")
bestchild = models.ForeignKey("Child", models.SET_NULL, null=True, related_name="favored_by")
parent = models.ForeignKey("mutually_referential.Parent", models.CASCADE)
q = Parent(name='Elizabeth') q.save()
c = q.child_set.create(name='Charles') q.child_set.create(name='Edward')
q.bestchild = c q.save() q.delete()
self.assertQuerysetEqual(Reporter.objects.all(), [])
self.assertFalse(transaction.get_rollback()) transaction.set_rollback(True)
with self.assertRaises(DatabaseError): with transaction.atomic(savepoint=False): with connection.cursor() as cursor: cursor.execute( "SELECT no_such_col FROM transactions_reporter") self.assertTrue(transaction.get_rollback()) transaction.set_rollback(False) transaction.savepoint_rollback(sid)
transaction.rollback() transaction.set_autocommit(True)
self.assertTrue(transaction.get_rollback()) transaction.set_rollback(False) self.assertEqual(Reporter.objects.count(), 3) transaction.set_rollback(True)
self.assertQuerysetEqual(Reporter.objects.all(), [])
self.assertTrue(transaction.get_rollback()) transaction.set_rollback(False) self.assertEqual(Reporter.objects.count(), 3) transaction.set_rollback(True)
self.assertEqual(connection.autocommit, autocommit)
with self.assertRaises(transaction.TransactionManagementError): r2.save(force_update=True)
transaction.set_rollback(False) r2.save(force_update=True)
with self.assertRaises(Error): Reporter.objects.create(first_name="Cuthbert", last_name="Calculus")
time.sleep(1) Reporter.objects.exclude(id=1).update(id=2)
connection.close()
with transaction.atomic(): with transaction.atomic(): Reporter.objects.create(id=1, first_name="Tintin")
transaction.atomic(Callable())
with self.assertRaises(Error):
with transaction.atomic():
with self.assertRaisesMessage(Exception, "Oops"):
with transaction.atomic(): sid = connection.savepoint_ids[-1] raise Exception("Oops")
connection.savepoint_rollback(sid)
project_dir = os.path.join( os.path.dirname(upath(conf.__file__)), 'project_template', 'project_name', ) template_settings_py = os.path.join(project_dir, 'settings.py-tpl') test_settings_py = os.path.join(project_dir, 'settings.py') shutil.copyfile(template_settings_py, test_settings_py) self.addCleanup(os.remove, test_settings_py)
perms = models.Permission.objects.filter(codename__in=('add_customuser', 'change_customuser')) self.user.user_permissions.add(*perms)
original_pk = request.user.pk request.user.pk = 1 super(CustomUserAdmin, self).log_change(request, object, message) request.user.pk = original_pk
from __future__ import unicode_literals
user = User.objects.create_user('comebackkid', 'test3@example.com', 'testpw') p0 = PasswordResetTokenGenerator() tk1 = p0.make_token(user) reload = User.objects.get(username='comebackkid') tk2 = p0.make_token(reload) self.assertEqual(tk1, tk2)
class Mocked(PasswordResetTokenGenerator): def __init__(self, today): self._today_val = today
with self.assertRaises(ValueError): p0._make_token_with_timestamp(user, 175455491841851871349)
known_user = 'knownuser' known_user2 = 'knownuser2'
response = self.client.get('/remote_user/', **{self.header: 'newuser'}) self.assertEqual(User.objects.count(), num_users + 1)
response = self.client.get('/remote_user/', **{self.header: self.known_user2}) self.assertEqual(response.context['user'].username, 'knownuser2') self.assertEqual(User.objects.count(), num_users)
default_login = datetime(2000, 1, 1) if settings.USE_TZ: default_login = default_login.replace(tzinfo=timezone.utc) user.last_login = default_login user.save()
response = self.client.get('/remote_user/', **{self.header: self.known_user}) self.assertEqual(response.context['user'].username, 'knownuser') response = self.client.get('/remote_user/') self.assertTrue(response.context['user'].is_anonymous) User.objects.create_user(username='modeluser', password='foo') self.client.login(username='modeluser', password='foo') authenticate(username='modeluser', password='foo') response = self.client.get('/remote_user/') self.assertEqual(response.context['user'].username, 'modeluser')
response = self.client.get('/remote_user/', **{self.header: self.known_user}) self.assertEqual(response.context['user'].username, 'knownuser') response = self.client.get('/remote_user/', **{self.header: "newnewuser"}) self.assertNotEqual(response.context['user'].username, 'knownuser')
known_user = 'knownuser@example.com' known_user2 = 'knownuser2@example.com'
response = self.client.get('/remote_user/', **{self.header: self.known_user}) self.assertEqual(response.context['user'].username, 'knownuser') response = self.client.get('/remote_user/') self.assertFalse(response.context['user'].is_anonymous) self.assertEqual(response.context['user'].username, 'knownuser')
ContentType.objects.clear_cache()
user = self.UserModel._default_manager.get(pk=self.user.pk) self.assertEqual(user.get_all_permissions() == {'auth.test'}, True) self.assertEqual(user.get_group_permissions(), set()) self.assertEqual(user.has_module_perms('Group'), False) self.assertEqual(user.has_module_perms('auth'), True)
self.user.set_password('test') self.user.save()
ContentType.objects.clear_cache()
self.assertEqual(self.user_login_failed, [{'password': '********************', 'username': 'test'}])
self.assertTrue(self.client.login( username=self.TEST_USERNAME, password=self.TEST_PASSWORD) )
request = HttpRequest() request.session = self.client.session
with self.settings(AUTHENTICATION_BACKENDS=[ 'django.contrib.auth.backends.ModelBackend']): user = get_user(request)
self.assertIsNotNone(user) self.assertTrue(user.is_anonymous)
request = HttpRequest() request.session = self.client.session
return render(request, 'context_processors/auth_attrs_test_access.html', {'session_accessed': request.session.accessed})
urlpatterns = auth_urlpatterns + [ url(r'^logout/custom_query/$', views.logout, dict(redirect_field_name='follow')), url(r'^logout/next_page/$', views.logout, dict(next_page='/somewhere/')), url(r'^logout/next_page/named/$', views.logout, dict(next_page='password_reset')), url(r'^remote_user/$', remote_user_auth_view), url(r'^password_reset_from_email/$', views.password_reset, dict(from_email='staffmember@example.com')), url(r'^password_reset_extra_email_context/$', views.password_reset, dict(extra_email_context=dict(greeting='Hello!'))), url(r'^password_reset/custom_redirect/$', views.password_reset, dict(post_reset_redirect='/custom/')), url(r'^password_reset/custom_redirect/named/$', views.password_reset, dict(post_reset_redirect='password_reset')), url(r'^password_reset/html_email_template/$', views.password_reset, dict(html_email_template_name='registration/html_password_reset_email.html')), url(r'^reset/custom/(?P<uidb64>[0-9A-Za-z_\-]+)/(?P<token>[0-9A-Za-z]{1,13}-[0-9A-Za-z]{1,20})/$', views.password_reset_confirm, dict(post_reset_redirect='/custom/')), url(r'^reset/custom/named/(?P<uidb64>[0-9A-Za-z_\-]+)/(?P<token>[0-9A-Za-z]{1,13}-[0-9A-Za-z]{1,20})/$', views.password_reset_confirm, dict(post_reset_redirect='password_reset')), url(r'^password_change/custom/$', views.password_change, dict(post_change_redirect='/custom/')), url(r'^password_change/custom/named/$', views.password_change, dict(post_change_redirect='password_reset')), url(r'^login_required/$', login_required(views.password_reset)), url(r'^login_required_login_url/$', login_required(views.password_reset, login_url='/somewhere/')),
url(r'^admin/', admin.site.urls),
response = password_reset_confirm(request, uidb64='Bad', token='Bad', post_reset_redirect='dummy/') self.assertContains(response, '<title>Password reset unsuccessful</title>') self.assertContains(response, '<h1>Password reset unsuccessful</h1>')
default_token_generator = PasswordResetTokenGenerator() token = default_token_generator.make_token(user) uidb64 = force_text(urlsafe_base64_encode(force_bytes(user.pk))) response = password_reset_confirm(request, uidb64, token, post_reset_redirect='dummy/') self.assertContains(response, '<title>Enter new password</title>') self.assertContains(response, '<h1>Enter new password</h1>')
from .test_auth_backends import ImportedModelBackend
from __future__ import unicode_literals
data = { 'username': 'jsmith', 'password1': 'test123', 'password2': 'test', } form = UserCreationForm(data) self.assertFalse(form.is_valid()) self.assertEqual(form["password2"].errors, [force_text(form.error_messages['password_mismatch'])])
data = {'username': 'jsmith'} form = UserCreationForm(data) required_error = [force_text(Field.default_error_messages['required'])] self.assertFalse(form.is_valid()) self.assertEqual(form['password1'].errors, required_error) self.assertEqual(form['password2'].errors, required_error)
data = { 'username': 'jsmith@example.com', 'password1': 'test123', 'password2': 'test123', } form = UserCreationForm(data) self.assertTrue(form.is_valid()) form.save(commit=False) self.assertEqual(password_changed.call_count, 0) u = form.save() self.assertEqual(password_changed.call_count, 1) self.assertEqual(repr(u), '<User: jsmith@example.com>')
@override_settings(AUTHENTICATION_BACKENDS=['django.contrib.auth.backends.AllowAllUsersModelBackend']) class AuthenticationFormTest(TestDataMixin, TestCase):
data = { 'username': 'inactive', 'password': 'password', } form = AuthenticationForm(None, data) self.assertFalse(form.is_valid()) self.assertEqual(form.non_field_errors(), [force_text(form.error_messages['inactive'])])
data = { 'username': 'inactive', 'password': 'password', } form = AuthenticationForm(None, data) self.assertFalse(form.is_valid()) self.assertEqual(form.non_field_errors(), [force_text(form.error_messages['inactive'])])
data = { 'username': 'inactive', 'password': 'password', }
class PickyAuthenticationForm(AuthenticationForm): def confirm_login_allowed(self, user): if user.username == "inactive": raise forms.ValidationError("This user is disallowed.") raise forms.ValidationError("Sorry, nobody's allowed in.")
data = { 'username': 'testclient', 'password': 'password', } form = AuthenticationForm(None, data) self.assertTrue(form.is_valid()) self.assertEqual(form.non_field_errors(), [])
user = User.objects.get(username='testclient') data = { 'new_password1': 'abc123', 'new_password2': 'abc', } form = SetPasswordForm(user, data) self.assertFalse(form.is_valid()) self.assertEqual( form["new_password2"].errors, [force_text(form.error_messages['password_mismatch'])] )
user = User.objects.get(username='testclient') data = { 'old_password': 'password', 'new_password1': 'abc123', 'new_password2': 'abc', } form = PasswordChangeForm(user, data) self.assertFalse(form.is_valid()) self.assertEqual(form["new_password2"].errors, [force_text(form.error_messages['password_mismatch'])])
user = User.objects.get(username='testclient') data = { 'old_password': 'password', 'new_password1': 'abc123', 'new_password2': 'abc123', } form = PasswordChangeForm(user, data) self.assertTrue(form.is_valid()) form.save(commit=False) self.assertEqual(password_changed.call_count, 0) form.save() self.assertEqual(password_changed.call_count, 1)
user = User.objects.get(username='testclient') self.assertEqual(list(PasswordChangeForm(user, {}).fields), ['old_password', 'new_password1', 'new_password2'])
MyUserForm({})
user = User.objects.get(username='testclient') form_for_data = UserChangeForm(instance=user) post_data = form_for_data.initial
post_data['password'] = 'new password' form = UserChangeForm(instance=user, data=post_data)
self.assertIn('$', form.cleaned_data['password'])
self.assertEqual(form.initial['password'], form['password'].value())
Site.objects.clear_cache()
form.save(domain_override='example.com') self.assertEqual(len(mail.outbox), 1) self.assertEqual(mail.outbox[0].subject, 'Custom password reset on example.com')
form.save(domain_override='example.com') self.assertEqual(len(mail.outbox), 1) self.assertEqual(mail.outbox[0].subject, 'Forgot your password?') self.assertEqual(mail.outbox[0].bcc, ['site_monitor@example.com']) self.assertEqual(mail.outbox[0].content_subtype, "plain")
self.assertTrue(form.is_valid()) form.save() self.assertEqual(len(mail.outbox), 0)
widget = ReadOnlyPasswordHashWidget() html = widget.render(name='password', value=None, attrs={}) self.assertIn(_("No password set."), html)
from __future__ import unicode_literals
if crypt.crypt('', '') is None: crypt = None
blank_encoded = make_password('') self.assertTrue(blank_encoded.startswith('pbkdf2_sha256$')) self.assertTrue(is_password_usable(blank_encoded)) self.assertTrue(check_password('', blank_encoded)) self.assertFalse(check_password(' ', blank_encoded))
blank_encoded = make_password('', 'seasalt', 'pbkdf2_sha256') self.assertTrue(blank_encoded.startswith('pbkdf2_sha256$')) self.assertTrue(is_password_usable(blank_encoded)) self.assertTrue(check_password('', blank_encoded)) self.assertFalse(check_password(' ', blank_encoded))
blank_encoded = make_password('', 'seasalt', 'sha1') self.assertTrue(blank_encoded.startswith('sha1$')) self.assertTrue(is_password_usable(blank_encoded)) self.assertTrue(check_password('', blank_encoded)) self.assertFalse(check_password(' ', blank_encoded))
blank_encoded = make_password('', 'seasalt', 'md5') self.assertTrue(blank_encoded.startswith('md5$')) self.assertTrue(is_password_usable(blank_encoded)) self.assertTrue(check_password('', blank_encoded)) self.assertFalse(check_password(' ', blank_encoded))
alt_encoded = "md5$$%s" % encoded self.assertTrue(is_password_usable(alt_encoded)) self.assertTrue(check_password('ltmein', alt_encoded)) self.assertFalse(check_password('ltmeinz', alt_encoded)) blank_encoded = make_password('', '', 'unsalted_md5') self.assertTrue(is_password_usable(blank_encoded)) self.assertTrue(check_password('', blank_encoded)) self.assertFalse(check_password(' ', blank_encoded))
alt_encoded = encoded[6:] self.assertFalse(check_password('ltmein', alt_encoded)) blank_encoded = make_password('', '', 'unsalted_sha1') self.assertTrue(blank_encoded.startswith('sha1$')) self.assertTrue(is_password_usable(blank_encoded)) self.assertTrue(check_password('', blank_encoded)) self.assertFalse(check_password(' ', blank_encoded))
blank_encoded = make_password('', 'ab', 'crypt') self.assertTrue(blank_encoded.startswith('crypt$')) self.assertTrue(is_password_usable(blank_encoded)) self.assertTrue(check_password('', blank_encoded)) self.assertFalse(check_password(' ', blank_encoded))
password = ( 'VSK0UYV6FFQVZ0KG88DYN9WADAADZO1CTSIVDJUNZSUML6IBX7LN7ZS3R5' 'JGB3RGZ7VI7G7DJQ9NI8BQFSRPTG6UWTTVESA5ZPUN' ) encoded = make_password(password, hasher='bcrypt_sha256') self.assertTrue(check_password(password, encoded)) self.assertFalse(check_password(password[:72], encoded)) blank_encoded = make_password('', hasher='bcrypt_sha256') self.assertTrue(blank_encoded.startswith('bcrypt_sha256$')) self.assertTrue(is_password_usable(blank_encoded)) self.assertTrue(check_password('', blank_encoded)) self.assertFalse(check_password(' ', blank_encoded))
blank_encoded = make_password('', hasher='bcrypt') self.assertTrue(blank_encoded.startswith('bcrypt$')) self.assertTrue(is_password_usable(blank_encoded)) self.assertTrue(check_password('', blank_encoded)) self.assertFalse(check_password(' ', blank_encoded))
hasher.rounds = 4 encoded = make_password('letmein', hasher='bcrypt') rounds = hasher.safe_summary(encoded)['work factor'] self.assertEqual(rounds, '04')
self.assertTrue(check_password('letmein', encoded, setter, 'bcrypt')) self.assertFalse(state['upgraded'])
hasher.rounds = old_rounds
self.assertTrue(check_password('letmein', encoded, setter, 'bcrypt')) self.assertTrue(state['upgraded'])
self.assertEqual(hasher.encode.call_count, 3)
algorithm, data = encoded.split('$', 1) expected_call = (('wrong_password', force_bytes(data[:29])),) self.assertEqual(hasher.encode.call_args_list, [expected_call] * 3)
self.assertNotEqual(encoded, make_password(None), "Random password collision?")
hasher.iterations = 1 encoded = make_password('letmein') algo, iterations, salt, hash = encoded.split('$', 3) self.assertEqual(iterations, '1')
self.assertTrue(check_password('letmein', encoded, setter)) self.assertFalse(state['upgraded'])
hasher.iterations = old_iterations
self.assertTrue(check_password('letmein', encoded, setter)) self.assertTrue(state['upgraded'])
self.assertEqual(hasher.encode.call_count, 1)
algorithm, iterations, salt, hash = encoded.split('$', 3) expected_call = (('wrong_password', salt, 5),) self.assertEqual(hasher.encode.call_args, expected_call)
self.assertTrue(check_password('letmein', encoded, setter)) self.assertFalse(state['upgraded'])
with self.settings(PASSWORD_HASHERS=[ 'django.contrib.auth.hashers.PBKDF2PasswordHasher', 'auth_tests.test_hashers.PBKDF2SingleIterationHasher']): self.assertTrue(check_password('letmein', encoded, setter)) self.assertTrue(state['upgraded'])
check_password('letmein', encoded) self.assertEqual(hasher.harden_runtime.call_count, 0)
check_password('wrong_password', encoded) self.assertEqual(hasher.harden_runtime.call_count, 1)
msg = "Couldn't load 'PlainHasher' algorithm library: No module named '?plain'?" with six.assertRaisesRegex(self, ValueError, msg): PlainHasher()._load_library()
blank_encoded = make_password('', hasher='argon2') self.assertTrue(blank_encoded.startswith('argon2$')) self.assertTrue(is_password_usable(blank_encoded)) self.assertTrue(check_password('', blank_encoded)) self.assertFalse(check_password(' ', blank_encoded)) encoded = ( 'argon2$argon2i$m=8,t=1,p=1$c29tZXNhbHQ$gwQOXSNhxiOxPOA0+PY10P9QFO' '4NAYysnqRt1GSQLE55m+2GYDt9FEjPMHhP2Cuf0nOEXXMocVrsJAtNSsKyfg' ) self.assertTrue(check_password('secret', encoded)) self.assertFalse(check_password('wrong', encoded))
setattr(hasher, attr, new_value) encoded = make_password('letmein', hasher='argon2') attr_value = hasher.safe_summary(encoded)[summary_key] self.assertEqual(attr_value, new_value)
self.assertTrue(check_password('letmein', encoded, setter, 'argon2')) self.assertFalse(state['upgraded'])
setattr(hasher, attr, old_value)
self.assertTrue(check_password('letmein', encoded, setter, 'argon2')) self.assertTrue(state['upgraded'])
from django.contrib.auth.models import AbstractBaseUser, BaseUserManager from django.db import models
def get_group_permissions(self, obj=None): return set()
@property def is_staff(self): return self.is_admin
with RemoveGroupsAndPermissions(): class ExtensionUser(AbstractUser): date_of_birth = models.DateField()
from __future__ import unicode_literals
self.assertFalse(mail.outbox[0].message().is_multipart())
@override_settings(DEBUG_PROPAGATE_EXCEPTIONS=True) def test_poisoned_http_host(self): "Poisoned HTTP_HOST headers can't be used for reset emails" with patch_logger('django.security.DisallowedHost', 'error') as logger_calls: response = self.client.post( '/password_reset/', {'email': 'staffmember@example.com'}, HTTP_HOST='www.example:dr.frankenstein@evil.tld' ) self.assertEqual(response.status_code, 400) self.assertEqual(len(mail.outbox), 0) self.assertEqual(len(logger_calls), 1)
@override_settings(DEBUG_PROPAGATE_EXCEPTIONS=True) def test_poisoned_http_host_admin_site(self): "Poisoned HTTP_HOST headers can't be used for reset emails on admin views" with patch_logger('django.security.DisallowedHost', 'error') as logger_calls: response = self.client.post( '/admin_password_reset/', {'email': 'staffmember@example.com'}, HTTP_HOST='www.example:dr.frankenstein@evil.tld' ) self.assertEqual(response.status_code, 400) self.assertEqual(len(mail.outbox), 0) self.assertEqual(len(logger_calls), 1)
self.client.post('/password_reset/', {'email': 'staffmember@example.com'}) self.assertEqual(len(mail.outbox), 1) return self._read_signup_email(mail.outbox[0])
self.assertContains(response, "Please enter your new password")
path = path[:-5] + ("0" * 4) + path[-1]
response = self.client.get('/reset/123456/1-1/') self.assertContains(response, "The password reset link was invalid")
response = self.client.get('/reset/zzzzzzzzzzzzz/1-1/') self.assertContains(response, "The password reset link was invalid")
url, path = self._test_confirm_start() path = path[:-5] + ("0" * 4) + path[-1]
u = User.objects.get(email='staffmember@example.com') self.assertTrue(not u.check_password("anewpassword"))
u = User.objects.get(email='staffmember@example.com') self.assertTrue(u.check_password("anewpassword"))
response = self.client.get(path) self.assertContains(response, "The password reset link was invalid")
username = User.objects.get(email='staffmember@example.com').username self.assertContains(response, "Hello, %s." % username)
response = self.client.get('/reset/zzzzzzzzzzzzz/1-1/') self.assertContains(response, "Hello, .")
response = self.client.post('/password_reset/', {'email': self.user_email}) self.assertEqual(response.status_code, 302) self.assertEqual(len(mail.outbox), 1) return self._read_signup_email(mail.outbox[0])
self.assertContains(response, "Please enter your new password") response = self.client.post(path, { 'new_password1': 'anewpassword', 'new_password2': 'anewpassword', }) self.assertRedirects(response, '/reset/done/')
UUIDUser.objects.create_user( email=self.user_email, username='foo', password='foo', ) return super(UUIDUserPasswordResetTest, self)._test_confirm_start()
self.assertRedirects(response, '/password_change/done/')
for bad_url in ('http://example.com', 'http:///example.com', 'https://example.com', 'ftp://example.com', '///example.com', '//example.com', 'javascript:alert("XSS")'):
for good_url in ('/view/?param=http://example.com', '/view/?param=https://example.com', '/view?param=ftp://example.com', 'view/?param=//example.com', 'https://testserver/', 'HTTPS://testserver/', '//testserver/',
self.client.post('/custom_requestauth_login/', { 'username': 'testclient', 'password': 'password', }, follow=True)
req = HttpRequest() CsrfViewMiddleware().process_view(req, login_view, (), {}) get_token(req) resp = login_view(req) resp2 = CsrfViewMiddleware().process_response(req, resp) csrf_cookie = resp2.cookies.get(settings.CSRF_COOKIE_NAME, None) token1 = csrf_cookie.coded_value
req = HttpRequest() req.COOKIES[settings.CSRF_COOKIE_NAME] = token1 req.method = "POST" req.POST = {'username': 'testclient', 'password': password, 'csrfmiddlewaretoken': token1}
SessionMiddleware().process_request(req) CsrfViewMiddleware().process_view(req, login_view, (), {})
self.assertNotEqual(token1, token2)
self.login() self.assertEqual(original_session_key, self.client.session.session_key)
self.login() response = self.client.get('/logout/') self.assertIn('site', response.context)
self.login() response = self.client.get('/logout/next_page/') self.assertEqual(response.status_code, 302) self.assertURLEqual(response.url, '/somewhere/')
for bad_url in ('http://example.com', 'http:///example.com', 'https://example.com', 'ftp://example.com', '///example.com', '//example.com', 'javascript:alert("XSS")'): nasty_url = '%(url)s?%(next)s=%(bad_url)s' % { 'url': logout_url, 'next': REDIRECT_FIELD_NAME, 'bad_url': urlquote(bad_url), } self.login() response = self.client.get(nasty_url) self.assertEqual(response.status_code, 302) self.assertNotIn(bad_url, response.url, "%s should be blocked" % bad_url) self.confirm_logged_out()
for good_url in ('/view/?param=http://example.com', '/view/?param=https://example.com', '/view?param=ftp://example.com', 'view/?param=//example.com', 'https://testserver/', 'HTTPS://testserver/', '//testserver/',
engine = import_module(settings.SESSION_ENGINE) session = engine.SessionStore() session[LANGUAGE_SESSION_KEY] = 'pl' session.save() self.client.cookies[settings.SESSION_COOKIE_NAME] = session.session_key
@override_settings(ROOT_URLCONF='auth_tests.urls_admin') class ChangelistTests(AuthViewsTestCase):
User.objects.filter(username='testclient').update(is_staff=True, is_superuser=True) self.login() self.admin = User.objects.get(pk=self.u1.pk)
def test_changelist_disallows_password_lookups(self): with patch_logger('django.security.DisallowedModelAdminLookup', 'error') as logger_calls: response = self.client.get(reverse('auth_test_admin:auth_user_changelist') + '?password__startswith=sha1$') self.assertEqual(response.status_code, 400) self.assertEqual(len(logger_calls), 1)
rel_link = re.search( r'you can change the password using <a href="([^"]*)">this form</a>', force_text(response.content) ).groups()[0] self.assertEqual( os.path.normpath(user_change_url + rel_link), os.path.normpath(password_change_url) )
with connection.constraint_checks_disabled(): response = self.client.post(password_change_url, { 'password1': 'password1', 'password2': 'password1', }) self.assertRedirects(response, user_change_url) row = LogEntry.objects.latest('id')
row.delete()
assert isinstance(prompt, six.binary_type)
prompt = str(prompt) assert str('__proxy__') not in prompt response = '' for key, val in inputs.items(): if force_str(key) in prompt.lower(): response = val break return response
management.get_system_username = lambda: 'J\xfalia' self.assertEqual(management.get_default_username(), 'julia')
User.objects.create_user(username='J\xfalia', password='qwerty') call_command('changepassword', username='J\xfalia', stdout=self.stdout)
new_io = six.StringIO() call_command( "createsuperuser", interactive=False, username="joe", email="joe@somewhere.org", stdout=new_io ) command_output = new_io.getvalue().strip() self.assertEqual(command_output, 'Superuser created successfully.') u = User.objects.get(username="joe") self.assertEqual(u.email, 'joe@somewhere.org')
self.assertFalse(u.has_usable_password())
new_io = six.StringIO() call_command( "createsuperuser", interactive=False, username="joe2", email="joe2@somewhere.org", verbosity=0, stdout=new_io ) command_output = new_io.getvalue().strip() self.assertEqual(command_output, '') u = User.objects.get(username="joe2") self.assertEqual(u.email, 'joe2@somewhere.org') self.assertFalse(u.has_usable_password())
new_io = six.StringIO() call_command( "createsuperuser", interactive=False, email="joe@somewhere.org", date_of_birth="1976-04-01", stdout=new_io, ) command_output = new_io.getvalue().strip() self.assertEqual(command_output, 'Superuser created successfully.') u = CustomUser._default_manager.get(email="joe@somewhere.org") self.assertEqual(u.date_of_birth, date(1976, 4, 1))
self.assertFalse(u.has_usable_password())
new_io = six.StringIO() with self.assertRaises(CommandError): call_command( "createsuperuser", interactive=False, username="joe@somewhere.org", stdout=new_io, stderr=new_io, )
def bad_then_good_password(index=[0]): index[0] += 1 if index[0] <= 2: return '1234567890' return 'password'
entered_passwords = ["password", "not password", "password2", "password2"]
entered_passwords = ["", "", "password2", "password2"]
self.assertEqual(Permission.objects.filter( content_type=permission_content_type, ).count(), 4)
self.assertEqual(Permission.objects.filter( content_type=permission_content_type, ).count(), 1)
with self.assertNumQueries(0): create_permissions(self.app_config, verbosity=0, apps=state.apps) state = migrations.state.ProjectState(real_apps=['contenttypes']) with self.assertNumQueries(0): create_permissions(self.app_config, verbosity=0, apps=state.apps)
self.assertIsNone(check_password({}, 'unknown', ''))
self.assertTrue(check_password({}, 'test', 'test'))
User.objects.filter(username='test').update(is_active=False) self.assertFalse(check_password({}, 'test', 'test'))
self.assertFalse(check_password({}, 'test', 'incorrect'))
self.assertIsNone(check_password({}, 'unknown', ''))
self.assertTrue(check_password({}, 'test@example.com', 'test'))
self.assertFalse(check_password({}, 'test@example.com', 'incorrect'))
self.assertEqual(groups_for_user({}, 'unknown'), [])
site = admin.AdminSite(name='auth_test_admin') site.register(User, UserAdmin) site.register(Group, GroupAdmin)
default_objects = [ ContentType.objects.db_manager('default').create( model='examplemodela', app_label='app_a', ), ContentType.objects.db_manager('default').create( model='examplemodelb', app_label='app_b', ), ] other_objects = [ ContentType.objects.db_manager('other').create( model='examplemodelb', app_label='app_b', ), ContentType.objects.db_manager('other').create( model='examplemodela', app_label='app_a', ), ]
Permission.objects.db_manager("default").create( name="Can delete example model b", codename="delete_examplemodelb", content_type=default_objects[1], ) Permission.objects.db_manager("other").create( name="Can delete example model b", codename="delete_examplemodelb", content_type=other_objects[0], )
returned = UserManager.normalize_email(r'Abc\@DEF@EXAMPLE.com') self.assertEqual(returned, r'Abc\@DEF@example.com')
kwargs = { "fail_silently": False, "auth_user": None, "auth_password": None, "connection": None, "html_message": None, } abstract_user = AbstractUser(email='foo@bar.com') abstract_user.email_user( subject="Subject here", message="This is a message", from_email="from@domain.com", **kwargs ) self.assertEqual(len(mail.outbox), 1) message = mail.outbox[0] self.assertEqual(message.subject, "Subject here") self.assertEqual(message.body, "This is a message") self.assertEqual(message.from_email, "from@domain.com") self.assertEqual(message.to, [abstract_user.email])
hasher.iterations = old_iterations + 1 with mock.patch('django.contrib.auth.password_validation.password_changed') as pw_changed: user.check_password('foo') self.assertEqual(pw_changed.call_count, 0) self.assertNotEqual(initial_password, user.password)
self.assertEqual(user.is_active, True) user.is_active = False user.save() user_fetched = User.objects.get(pk=user.pk) self.assertFalse(user_fetched.is_active)
user.is_active = False user.save() user_fetched = UserModel._default_manager.get(pk=user.pk) self.assertEqual(user_fetched.is_active, True)
self.assertIn('mockapp', perms) self.assertNotIn('nonexisting', perms) self.assertIn('mockapp.someperm', perms) self.assertNotIn('mockapp.nonexisting', perms)
self.client.login(username='super', password='secret') user = authenticate(username='super', password='secret') response = self.client.get('/auth_processor_user/') self.assertContains(response, "unicode: super") self.assertContains(response, "id: %d" % self.superuser.pk) self.assertContains(response, "username: super") self.assertContains(response, "url: /userpage/super/")
Q(user=response.context['user']) & Q(someflag=True)
self.assertEqual(response.context['user'], user) self.assertEqual(user, response.context['user'])
self.user.set_password('new_password') self.user.save() self.middleware.process_request(self.request) self.assertIsNotNone(self.request.user) self.assertTrue(self.request.user.is_anonymous) self.assertIsNone(self.request.session.session_key)
from __future__ import unicode_literals
u.set_unusable_password() u.save() self.assertFalse(u.check_password('testpw')) self.assertFalse(u.has_usable_password()) u.set_password('testpw') self.assertTrue(u.check_password('testpw')) u.set_password(None) self.assertFalse(u.has_usable_password())
self.assertEqual(u.get_username(), 'testuser')
self.assertFalse(u.is_anonymous) self.assertTrue(u.is_authenticated) self.assertFalse(u.is_staff) self.assertTrue(u.is_active) self.assertFalse(u.is_superuser)
u2 = User.objects.create_user('testuser2', 'test2@example.com') self.assertFalse(u2.has_usable_password())
with warnings.catch_warnings(record=True) as warns: warnings.simplefilter('always') self.assertFalse(u.is_anonymous()) self.assertEqual(len(warns), 1) self.assertEqual(str(warns[0].message), deprecation_message)
with warnings.catch_warnings(record=True) as warns:
self.client.login(username='testclient', password='bad') self.assertEqual(len(self.logged_in), 0) self.assertEqual(len(self.login_failed), 1) self.assertEqual(self.login_failed[0]['username'], 'testclient') self.assertIn('***', self.login_failed[0]['password'])
self.client.login(username='testclient', password='password') self.assertEqual(len(self.logged_in), 1) self.assertEqual(self.logged_in[0].username, 'testclient')
self.assertEqual(len(self.login_failed), 1)
self.client.get('/logout/next_page/') self.assertEqual(len(self.logged_out), 1) self.assertEqual(self.logged_out[0], None)
tl = connection.introspection.django_table_names(only_existing=True) self.assertIs(type(tl), list) tl = connection.introspection.django_table_names(only_existing=False) self.assertIs(type(tl), list)
@skipUnlessDBFeature('can_introspect_max_length') def test_get_table_description_col_lengths(self): with connection.cursor() as cursor: desc = connection.introspection.get_table_description(cursor, Reporter._meta.db_table) self.assertEqual( [r[3] for r in desc if datatype(r[1], r) == 'CharField'], [30, 30, 254] )
@skipUnlessDBFeature('has_real_datatype') def test_postgresql_real_type(self): with connection.cursor() as cursor: cursor.execute("CREATE TABLE django_ixn_real_test_table (number REAL);") desc = connection.introspection.get_table_description(cursor, 'django_ixn_real_test_table') cursor.execute('DROP TABLE django_ixn_real_test_table;') self.assertEqual(datatype(desc[0][1], desc[0]), 'FloatField')
expected_relations = { 'reporter_id': ('id', Reporter._meta.db_table), 'response_to_id': ('id', Article._meta.db_table), } self.assertEqual(relations, expected_relations)
body = Article._meta.get_field('body') with connection.schema_editor() as editor: editor.remove_field(Article, body) with connection.cursor() as cursor: relations = connection.introspection.get_relations(cursor, Article._meta.db_table) with connection.schema_editor() as editor: editor.add_field(Article, body) self.assertEqual(relations, expected_relations)
from __future__ import unicode_literals
OLD_LOGGING = { 'version': 1, 'disable_existing_loggers': False, 'handlers': { 'mail_admins': { 'level': 'ERROR', 'class': 'django.utils.log.AdminEmailHandler' } }, 'loggers': { 'django.request': { 'handlers': ['mail_admins'], 'level': 'ERROR', 'propagate': True, }, } }
self._old_capture_state = bool(getattr(logging, '_warnings_showwarning', False)) logging.captureWarnings(True)
logging.captureWarnings(self._old_capture_state)
admin_email_handler = [ h for h in logger.handlers if h.__class__.__name__ == "AdminEmailHandler" ][0] return admin_email_handler
orig_filters = admin_email_handler.filters try: admin_email_handler.filters = []
admin_email_handler.filters = orig_filters
orig_filters = admin_email_handler.filters try: admin_email_handler.filters = [] rf = RequestFactory() request = rf.get('/') self.logger.error( message, token1, token2, extra={ 'status_code': 403, 'request': request, } ) self.assertEqual(len(mail.outbox), 1) self.assertEqual(mail.outbox[0].to, ['admin@example.com']) self.assertEqual(mail.outbox[0].subject, "-SuperAwesomeSubject-ERROR (internal IP): Custom message that says 'ping' and 'pong'") finally: admin_email_handler.filters = orig_filters
orig_mail_admins = mail.mail_admins orig_email_backend = admin_email_handler.email_backend mail.mail_admins = my_mail_admins admin_email_handler.email_backend = ( 'logging_tests.logconfig.MyEmailBackend')
mail.mail_admins = orig_mail_admins admin_email_handler.email_backend = orig_email_backend
admin_email_handler.include_html = False try: self.client.get('/', HTTP_HOST='evil.com') finally: admin_email_handler.include_html = old_include_html
admin_email_handler.include_html = True try: self.client.get('/', HTTP_HOST='evil.com') finally: admin_email_handler.include_html = old_include_html
out, err = self.run_manage(['check']) self.assertNoOutput(err) self.assertOutput(out, "System check identified no issues (0 silenced).")
self.assertQuerysetEqual( Issue.objects.filter(Q(cc__id__exact=r.id) | Q(client=r.id)), [ 1, 2, 3, ], lambda i: i.num ) self.assertQuerysetEqual( Issue.objects.filter(cc__id__exact=r.id) | Issue.objects.filter(client=r.id), [ 1, 2, 3, ], lambda i: i.num ) self.assertQuerysetEqual( Issue.objects.filter(Q(client=r.id) | Q(cc__id__exact=r.id)), [ 1, 2, 3, ], lambda i: i.num )
parent = models.OneToOneField(Place, models.CASCADE, primary_key=True, parent_link=True) capacity = models.IntegerField()
primary_key = models.AutoField(primary_key=True) parent = models.OneToOneField(Place, models.CASCADE, parent_link=True)
parent = models.OneToOneField(Place, models.CASCADE, parent_link=True)
@python_2_unicode_compatible class Person(models.Model): name = models.CharField(max_length=100)
class SearchableLocation(models.Model): keywords = models.CharField(max_length=256)
class Politician(models.Model): politician_id = models.AutoField(primary_key=True) title = models.CharField(max_length=50)
place1 = Place( name="Guido's House of Pasta", address='944 W. Fullerton') place1.save_base(raw=True) restaurant = Restaurant( place_ptr=place1, serves_hot_dogs=True, serves_pizza=False) restaurant.save_base(raw=True) italian_restaurant = ItalianRestaurant( restaurant_ptr=restaurant, serves_gnocchi=True) italian_restaurant.save_base(raw=True)
place2 = Place(name='Main St', address='111 Main St') place2.save_base(raw=True) park = ParkingLot(parent=place2, capacity=100) park.save_base(raw=True)
places = list(Place.objects.all()) self.assertEqual(places, [place1, place2])
place1.name = "Guido's All New House of Pasta" place1.save_base(raw=True)
places = list(Place.objects.all()) self.assertEqual(places, [place2, place1]) self.assertEqual(places[0].name, 'Derelict lot') self.assertEqual(places[1].name, "Guido's All New House of Pasta")
dicts = list(ItalianRestaurant.objects.values( 'name', 'serves_hot_dogs', 'serves_gnocchi')) self.assertEqual(dicts, [{ 'name': "Guido's All New House of Pasta", 'serves_gnocchi': False, 'serves_hot_dogs': False, }])
Child.objects.create( name='child', created=datetime.datetime(2008, 6, 26, 17, 0, 0)) datetimes = list(Child.objects.datetimes('created', 'month')) self.assertEqual(datetimes, [datetime.datetime(2008, 6, 1, 0, 0)])
place1 = Place( name="Guido's House of Pasta", address='944 W. Fullerton') place1.save_base(raw=True) restaurant = Restaurant( place_ptr=place1, serves_hot_dogs=True, serves_pizza=False) restaurant.save_base(raw=True) italian_restaurant = ItalianRestaurant( restaurant_ptr=restaurant, serves_gnocchi=True) italian_restaurant.save_base(raw=True)
Restaurant.objects.all().delete()
suppliers = Supplier.objects.filter( restaurant=Restaurant(name='xx', address='yy')) suppliers = list(suppliers) self.assertEqual(suppliers, [])
qs = ArticleWithAuthor.objects.order_by('pub_date', 'pk') sql = qs.query.get_compiler(qs.db).as_sql()[0] fragment = sql[sql.find('ORDER BY'):] pos = fragment.find('pub_date') self.assertEqual(fragment.find('pub_date', pos + 1), -1)
self.assertEqual(ParkingLot3._meta.get_ancestor_link(Place).name, "parent")
QualityControl.objects.create( headline="Problems in Django", pub_date=datetime.datetime.now(), quality=10, assignee="adrian")
p1 = Person.objects.create(name='Alice') p2 = Person.objects.create(name='Bob') p3 = Person.objects.create(name='Carol') p4 = Person.objects.create(name='Dave')
self.assertFalse(hasattr(p2, 'messybachelorparty_set'))
messy = MessyBachelorParty.objects.create( name='Bachelor party for Dave') messy.attendees.set([p4]) messy_parent = messy.bachelorparty_ptr
self.assertEqual( InternalCertificationAudit._meta.verbose_name_plural, 'Audits' )
self.assertEqual( len([field for field in BusStation._meta.local_fields if field.primary_key]), 1 ) self.assertEqual( len([field for field in TrainStation._meta.local_fields if field.primary_key]), 1 ) self.assertIs(BusStation._meta.pk.model, BusStation) self.assertIs(TrainStation._meta.pk.model, TrainStation)
qs = ItalianRestaurant.objects.all() self.assertEqual(str(qs.query).count('JOIN'), 2) qs = ItalianRestaurant.objects.filter(name='foo') self.assertEqual(str(qs.query).count('JOIN'), 2)
qs = ItalianRestaurant.objects.values_list('serves_gnocchi').filter(name='foo') self.assertEqual(str(qs.query).count('JOIN'), 1)
r1 = Restaurant.objects.create( name="Nobu", serves_hot_dogs=True, serves_pizza=False ) r2 = Restaurant.objects.create( name="Craft", serves_hot_dogs=False, serves_pizza=True ) Supplier.objects.create(name="John", restaurant=r1) Supplier.objects.create(name="Jane", restaurant=r2)
from __future__ import unicode_literals
self.assertEqual(request.GET.urlencode(), '') self.assertEqual(request.POST.urlencode(), '')
self.assertEqual(request.FILES.getlist('foo'), [])
request = WSGIRequest({ 'PATH_INFO': '/somepath/', 'SCRIPT_NAME': '/PREFIX/', 'REQUEST_METHOD': 'get', 'wsgi.input': BytesIO(b''), }) self.assertEqual(request.path, '/PREFIX/somepath/') request = WSGIRequest({ 'PATH_INFO': '/somepath/', 'SCRIPT_NAME': '/PREFIX', 'REQUEST_METHOD': 'get', 'wsgi.input': BytesIO(b''), }) self.assertEqual(request.path, '/PREFIX/somepath/')
with override_settings(FORCE_SCRIPT_NAME='/FORCED_PREFIX/'): request = WSGIRequest({'PATH_INFO': '/somepath/', 'REQUEST_METHOD': 'get', 'wsgi.input': BytesIO(b'')}) self.assertEqual(request.path, '/FORCED_PREFIX/somepath/') with override_settings(FORCE_SCRIPT_NAME='/FORCED_PREFIX'): request = WSGIRequest({'PATH_INFO': '/somepath/', 'REQUEST_METHOD': 'get', 'wsgi.input': BytesIO(b'')}) self.assertEqual(request.path, '/FORCED_PREFIX/somepath/')
request = WSGIRequest({'PATH_INFO': wsgi_str("//"), 'REQUEST_METHOD': 'get', 'wsgi.input': BytesIO(b'')}) self.assertEqual(request.path, "//")
expires = datetime.utcnow() + timedelta(seconds=10) time.sleep(0.001) response.set_cookie('datetime', expires=expires) datetime_cookie = response.cookies['datetime'] self.assertEqual(datetime_cookie['max-age'], 10)
('Sat, 01-Jan-2028 04:05:06 GMT', 'Sat, 01-Jan-2028 04:05:07 GMT')
self.assertIn('; %s' % http_cookies.Morsel._reserved['httponly'], str(example_cookie)) self.assertTrue(example_cookie['httponly'])
stream = LimitedStream(BytesIO(b'test'), 2) self.assertEqual(stream.read(), b'te') self.assertEqual(stream.read(), b'')
stream = LimitedStream(BytesIO(b'test'), 2) self.assertEqual(stream.read(5), b'te') self.assertEqual(stream.readline(5), b'')
stream = LimitedStream(BytesIO(b'12345678'), 8) self.assertEqual(stream.read(5), b'12345') self.assertEqual(stream.read(5), b'678') self.assertEqual(stream.readline(5), b'')
stream = LimitedStream(BytesIO(b'1234\n5678\nabcd\nefgh\nijkl'), 24) self.assertEqual(stream.readline(), b'1234\n') self.assertEqual(stream.readline(2), b'56') self.assertEqual(stream.readline(), b'78\n') self.assertEqual(stream.readline(6), b'abcd\n') self.assertEqual(stream.readline(4), b'efgh') self.assertEqual(stream.readline(), b'\n') self.assertEqual(stream.readline(), b'ijkl')
stream = LimitedStream(BytesIO(b'1234\nabcdef'), 9) self.assertEqual(stream.readline(10), b'1234\n') self.assertEqual(stream.readline(3), b'abc') self.assertEqual(stream.readline(3), b'd') self.assertEqual(stream.readline(2), b'')
stream = LimitedStream(BytesIO(b'1234\nabcdef'), 9) self.assertEqual(stream.read(6), b'1234\na') self.assertEqual(stream.read(2), b'bc') self.assertEqual(stream.read(2), b'd') self.assertEqual(stream.read(2), b'') self.assertEqual(stream.read(), b'')
payload = FakePayload("\r\n".join([ '--boundary', 'Content-Disposition: form-data; name="name"', '', 'value', '--boundary--' ''])) request = WSGIRequest({'REQUEST_METHOD': 'POST', 'CONTENT_TYPE': 'multipart/form-data; boundary=boundary', 'CONTENT_LENGTH': len(payload), 'wsgi.input': payload}) self.assertEqual(request.POST, {'name': ['value']}) with self.assertRaises(RawPostDataException): request.body
payload_data = b"\r\n".join([ b'--boundary', b'Content-ID: id; name="name"', b'', b'value', b'--boundary--' b'']) payload = FakePayload(payload_data) request = WSGIRequest({'REQUEST_METHOD': 'POST', 'CONTENT_TYPE': 'multipart/related; boundary=boundary', 'CONTENT_LENGTH': len(payload), 'wsgi.input': payload}) self.assertEqual(request.POST, {}) self.assertEqual(request.body, payload_data)
payload = FakePayload("\r\n".join([ '--boundary', 'Content-Disposition: form-data; name="name"', '', 'value', '--boundary--' ''])) request = WSGIRequest({'REQUEST_METHOD': 'POST', 'CONTENT_TYPE': 'multipart/form-data; boundary=boundary', 'CONTENT_LENGTH': 0, 'wsgi.input': payload}) self.assertEqual(request.POST, {})
environ.update({'CONTENT_TYPE': '', 'wsgi.input': BytesIO(payload)}) request = WSGIRequest(environ) self.assertEqual(request.POST, {}) self.assertEqual(request.FILES, {}) self.assertEqual(request.body, payload)
self.assertEqual(request.read(13), b'--boundary\r\nC') self.assertEqual(request.POST, {'name': ['value']})
request = HttpRequest() request.META = { 'HTTP_X_FORWARDED_HOST': 'forward.com', 'HTTP_HOST': 'example.com', 'SERVER_NAME': 'internal.com', 'SERVER_PORT': 80, } self.assertEqual(request.get_host(), 'example.com')
request = HttpRequest() request.META = { 'HTTP_HOST': 'example.com', 'SERVER_NAME': 'internal.com', 'SERVER_PORT': 80, } self.assertEqual(request.get_host(), 'example.com')
request = HttpRequest() request.META = { 'SERVER_NAME': 'internal.com', 'SERVER_PORT': 80, } self.assertEqual(request.get_host(), 'internal.com')
request = HttpRequest() request.META = { 'SERVER_NAME': 'internal.com', 'SERVER_PORT': 8042, } self.assertEqual(request.get_host(), 'internal.com:8042')
for host in chain(self.poisoned_hosts, ['other.com', 'example.com..']): with self.assertRaises(SuspiciousOperation): request = HttpRequest() request.META = { 'HTTP_HOST': host, } request.get_host()
request = HttpRequest() request.META = { 'HTTP_X_FORWARDED_HOST': 'forward.com', 'HTTP_HOST': 'example.com', 'SERVER_NAME': 'internal.com', 'SERVER_PORT': 80, } self.assertEqual(request.get_host(), 'forward.com')
request = HttpRequest() request.META = { 'HTTP_HOST': 'example.com', 'SERVER_NAME': 'internal.com', 'SERVER_PORT': 80, } self.assertEqual(request.get_host(), 'example.com')
request = HttpRequest() request.META = { 'SERVER_NAME': 'internal.com', 'SERVER_PORT': 80, } self.assertEqual(request.get_host(), 'internal.com')
request = HttpRequest() request.META = { 'SERVER_NAME': 'internal.com', 'SERVER_PORT': 8042, } self.assertEqual(request.get_host(), 'internal.com:8042')
legit_hosts = [ 'example.com', 'example.com:80', '12.34.56.78', '12.34.56.78:443', '[2001:19f0:feee::dead:beef:cafe]', '[2001:19f0:feee::dead:beef:cafe]:8080',
self.assertEqual(request.get_port(), '8080')
self.assertEqual(request.get_port(), '80')
request = HttpRequest() request.META = { 'HTTP_HOST': "invalid_hostname.com", } self.assertEqual(request.get_host(), "invalid_hostname.com")
request = self.factory.get('////absolute-uri') self.assertEqual( request.build_absolute_uri(), 'http://testserver//absolute-uri' )
request = self.factory.get('////absolute-uri') self.assertEqual( request.build_absolute_uri(location='http://example.com/?foo=bar'), 'http://example.com/?foo=bar' )
request = self.factory.get('////absolute-uri') self.assertEqual( request.build_absolute_uri(location='//example.com/?foo=bar'), 'http://example.com/?foo=bar' )
request = self.factory.get('////absolute-uri') self.assertEqual( request.build_absolute_uri(location='/foo/bar/'), 'http://testserver/foo/bar/' )
publications = models.ManyToManyField(Publication, name='publications') tags = models.ManyToManyField(Tag, related_name='tags')
class AbstractArticle(models.Model): class Meta: abstract = True ordering = ('title',)
self.p1 = Publication.objects.create(title='The Python Journal') self.p2 = Publication.objects.create(title='Science News') self.p3 = Publication.objects.create(title='Science Weekly') self.p4 = Publication.objects.create(title='Highlights for Children')
a5 = Article(headline='Django lets you reate Web apps easily') with self.assertRaises(ValueError): getattr(a5, 'publications') a5.save() a5.publications.add(self.p1) self.assertQuerysetEqual(a5.publications.all(), ['<Publication: The Python Journal>']) a6 = Article(headline='ESA uses Python') a6.save() a6.publications.add(self.p1, self.p2) a6.publications.add(self.p3) a6.publications.add(self.p3) self.assertQuerysetEqual( a6.publications.all(), [ '<Publication: Science News>', '<Publication: Science Weekly>', '<Publication: The Python Journal>', ] )
with self.assertRaisesMessage(TypeError, "'Publication' instance expected, got <Article"): with transaction.atomic(): a6.publications.add(a5)
a6.publications.create(title='Highlights for Adults') self.assertQuerysetEqual( a6.publications.all(), [ '<Publication: Highlights for Adults>', '<Publication: Science News>', '<Publication: Science Weekly>', '<Publication: The Python Journal>', ] )
a5 = Article(headline='NASA finds intelligent life on Mars') a5.save() self.p2.article_set.add(a5) self.assertQuerysetEqual( self.p2.article_set.all(), [ '<Article: NASA finds intelligent life on Earth>', '<Article: NASA finds intelligent life on Mars>', '<Article: NASA uses Python>', '<Article: Oxygen-free diet works wonders>', ] ) self.assertQuerysetEqual(a5.publications.all(), ['<Publication: Science News>'])
self.p2.article_set.create(headline='Carbon-free diet works wonders') self.assertQuerysetEqual( self.p2.article_set.all(), [ '<Article: Carbon-free diet works wonders>', '<Article: NASA finds intelligent life on Earth>', '<Article: NASA finds intelligent life on Mars>', '<Article: NASA uses Python>', '<Article: Oxygen-free diet works wonders>', ]) a6 = self.p2.article_set.all()[3] self.assertQuerysetEqual( a6.publications.all(), [ '<Publication: Highlights for Children>', '<Publication: Science News>', '<Publication: Science Weekly>', '<Publication: The Python Journal>', ] )
self.assertQuerysetEqual(self.a1.publications.all(), ['<Publication: The Python Journal>']) self.assertQuerysetEqual( self.a2.publications.all(), [ '<Publication: Highlights for Children>', '<Publication: Science News>', '<Publication: Science Weekly>', '<Publication: The Python Journal>', ] ) self.assertQuerysetEqual( self.p2.article_set.all(), [ '<Article: NASA finds intelligent life on Earth>', '<Article: NASA uses Python>', '<Article: Oxygen-free diet works wonders>', ] ) self.assertQuerysetEqual( self.p1.article_set.all(), [ '<Article: Django lets you build Web apps easily>', '<Article: NASA uses Python>', ] ) self.assertQuerysetEqual( Publication.objects.get(id=self.p4.id).article_set.all(), ['<Article: NASA uses Python>'] )
self.assertQuerysetEqual( Article.objects.filter(publications__id__exact=self.p1.id), [ '<Article: Django lets you build Web apps easily>', '<Article: NASA uses Python>', ]) self.assertQuerysetEqual( Article.objects.filter(publications__pk=self.p1.id), [ '<Article: Django lets you build Web apps easily>', '<Article: NASA uses Python>', ] ) self.assertQuerysetEqual( Article.objects.filter(publications=self.p1.id), [ '<Article: Django lets you build Web apps easily>', '<Article: NASA uses Python>', ] ) self.assertQuerysetEqual( Article.objects.filter(publications=self.p1), [ '<Article: Django lets you build Web apps easily>', '<Article: NASA uses Python>', ] ) self.assertQuerysetEqual( Article.objects.filter(publications__title__startswith="Science"), [ '<Article: NASA finds intelligent life on Earth>', '<Article: NASA uses Python>', '<Article: NASA uses Python>', '<Article: Oxygen-free diet works wonders>', ] ) self.assertQuerysetEqual( Article.objects.filter(publications__title__startswith="Science").distinct(), [ '<Article: NASA finds intelligent life on Earth>', '<Article: NASA uses Python>', '<Article: Oxygen-free diet works wonders>', ] )
self.assertEqual(Article.objects.filter(publications__title__startswith="Science").count(), 4) self.assertEqual(Article.objects.filter(publications__title__startswith="Science").distinct().count(), 3) self.assertQuerysetEqual( Article.objects.filter(publications__in=[self.p1.id, self.p2.id]).distinct(), [ '<Article: Django lets you build Web apps easily>', '<Article: NASA finds intelligent life on Earth>', '<Article: NASA uses Python>', '<Article: Oxygen-free diet works wonders>', ]) self.assertQuerysetEqual( Article.objects.filter(publications__in=[self.p1.id, self.p2]).distinct(), [ '<Article: Django lets you build Web apps easily>', '<Article: NASA finds intelligent life on Earth>', '<Article: NASA uses Python>', '<Article: Oxygen-free diet works wonders>', ] ) self.assertQuerysetEqual( Article.objects.filter(publications__in=[self.p1, self.p2]).distinct(), [ '<Article: Django lets you build Web apps easily>', '<Article: NASA finds intelligent life on Earth>', '<Article: NASA uses Python>', '<Article: Oxygen-free diet works wonders>', ] )
self.assertQuerysetEqual( Article.objects.exclude(publications=self.p2), ['<Article: Django lets you build Web apps easily>'] )
python_journal = ['<Publication: The Python Journal>'] self.assertQuerysetEqual(Publication.objects.filter(id__exact=self.p1.id), python_journal) self.assertQuerysetEqual(Publication.objects.filter(pk=self.p1.id), python_journal) self.assertQuerysetEqual( Publication.objects.filter(article__headline__startswith="NASA"), [ '<Publication: Highlights for Children>', '<Publication: Science News>', '<Publication: Science News>', '<Publication: Science Weekly>', '<Publication: The Python Journal>', ])
self.p1.delete() self.assertQuerysetEqual( Publication.objects.all(), [ '<Publication: Highlights for Children>', '<Publication: Science News>', '<Publication: Science Weekly>', ] ) self.assertQuerysetEqual(self.a1.publications.all(), []) self.a2.delete() self.assertQuerysetEqual( Article.objects.all(), [ '<Article: Django lets you build Web apps easily>', '<Article: NASA finds intelligent life on Earth>', '<Article: Oxygen-free diet works wonders>', ] ) self.assertQuerysetEqual( self.p2.article_set.all(), [ '<Article: NASA finds intelligent life on Earth>', '<Article: Oxygen-free diet works wonders>', ] )
Publication.objects.filter(title__startswith='Science').delete() self.assertQuerysetEqual( Publication.objects.all(), [ '<Publication: Highlights for Children>', '<Publication: The Python Journal>', ] ) self.assertQuerysetEqual( Article.objects.all(), [ '<Article: Django lets you build Web apps easily>', '<Article: NASA finds intelligent life on Earth>', '<Article: NASA uses Python>', '<Article: Oxygen-free diet works wonders>', ] ) self.assertQuerysetEqual( self.a2.publications.all(), [ '<Publication: Highlights for Children>', '<Publication: The Python Journal>', ] )
q = Article.objects.filter(headline__startswith='Django') self.assertQuerysetEqual(q, ['<Article: Django lets you build Web apps easily>']) q.delete() self.assertQuerysetEqual(q, []) self.assertQuerysetEqual(self.p1.article_set.all(), ['<Article: NASA uses Python>'])
self.assertQuerysetEqual( self.p2.article_set.all(), [ '<Article: NASA finds intelligent life on Earth>', '<Article: NASA uses Python>', '<Article: Oxygen-free diet works wonders>', ] ) self.a4.publications.remove(self.p2) self.assertQuerysetEqual( self.p2.article_set.all(), [ '<Article: NASA finds intelligent life on Earth>', '<Article: NASA uses Python>', ] ) self.assertQuerysetEqual(self.a4.publications.all(), []) self.p2.article_set.remove(self.a3) self.assertQuerysetEqual(self.p2.article_set.all(), ['<Article: NASA uses Python>']) self.assertQuerysetEqual(self.a3.publications.all(), [])
self.p2.article_set = [] self.assertQuerysetEqual(self.p2.article_set.all(), []) self.a4.publications = [] self.assertQuerysetEqual(self.a4.publications.all(), [])
self.p2.article_set.set([self.a4, self.a3]) self.assertQuerysetEqual( self.p2.article_set.all(), [ '<Article: NASA finds intelligent life on Earth>', '<Article: Oxygen-free diet works wonders>', ] ) self.assertQuerysetEqual(self.a4.publications.all(), ['<Publication: Science News>']) self.a4.publications.set([self.p3.id]) self.assertQuerysetEqual(self.p2.article_set.all(), ['<Article: NASA finds intelligent life on Earth>']) self.assertQuerysetEqual(self.a4.publications.all(), ['<Publication: Science Weekly>'])
self.p2.article_set.set([]) self.assertQuerysetEqual(self.p2.article_set.all(), []) self.a4.publications.set([]) self.assertQuerysetEqual(self.a4.publications.all(), [])
self.p2.article_set.set([self.a4.id, self.a3.id]) self.assertQuerysetEqual( self.p2.article_set.all(), [ '<Article: NASA finds intelligent life on Earth>', '<Article: Oxygen-free diet works wonders>', ] ) self.assertQuerysetEqual(self.a4.publications.all(), ['<Publication: Science News>']) self.a4.publications.set([self.p3.id]) self.assertQuerysetEqual(self.p2.article_set.all(), ['<Article: NASA finds intelligent life on Earth>']) self.assertQuerysetEqual(self.a4.publications.all(), ['<Publication: Science Weekly>'])
self.a1.publications.set([self.p1, self.p2])
self.p1.article_set.set([self.a1, self.a2])
self.p2.article_set.clear() self.assertQuerysetEqual(self.p2.article_set.all(), []) self.assertQuerysetEqual(self.a4.publications.all(), [])
self.p2.article_set.add(self.a3, self.a4) self.assertQuerysetEqual( self.p2.article_set.all(), [ '<Article: NASA finds intelligent life on Earth>', '<Article: Oxygen-free diet works wonders>', ] ) self.assertQuerysetEqual(self.a4.publications.all(), ['<Publication: Science News>']) self.a4.publications.clear() self.assertQuerysetEqual(self.a4.publications.all(), []) self.assertQuerysetEqual(self.p2.article_set.all(), ['<Article: NASA finds intelligent life on Earth>'])
requires_unique_target = False
kwargs['related_name'] = '+' kwargs['unique'] = True super(CurrentTranslation, self).__init__(to, on_delete, from_fields, to_fields, **kwargs)
translation = CurrentTranslation(ArticleTranslation, models.CASCADE, ['id'], ['article'])
class IndexTogetherSingleList(models.Model): headline = models.CharField(max_length=100) pub_date = models.DateTimeField()
if connection.vendor == 'postgresql': class IndexedArticle(models.Model): headline = models.CharField(max_length=100, db_index=True) body = models.TextField(db_index=True) slug = models.CharField(max_length=40, unique=True)
self.assertIn( connection.ops.quote_name( editor._create_index_name(Article, ['headline', 'pub_date'], suffix='_idx') ), index_sql[0] )
index_sql = connection.schema_editor()._model_indexes_sql(IndexTogetherSingleList) self.assertEqual(len(index_sql), 1)
self.assertIn('("slug" varchar_pattern_ops)', index_sql[4])
from __future__ import unicode_literals
self.patched_settings = self.settings(STATIC_ROOT=temp_dir) self.patched_settings.enable() self.run_collectstatic() self.addCleanup(shutil.rmtree, six.text_type(temp_dir))
cls.settings_override = override_settings(**TEST_SETTINGS) cls.settings_override.enable() super(LiveServerBase, cls).setUpClass()
cls.settings_override.disable() super(LiveServerBase, cls).tearDownClass()
address_predefined = 'DJANGO_LIVE_TEST_SERVER_ADDRESS' in os.environ old_address = os.environ.get('DJANGO_LIVE_TEST_SERVER_ADDRESS')
old_STATIC_URL = TEST_SETTINGS['STATIC_URL'] TEST_SETTINGS['STATIC_URL'] = None cls.raises_exception('localhost:8081', ImproperlyConfigured) TEST_SETTINGS['STATIC_URL'] = old_STATIC_URL
if address_predefined: os.environ['DJANGO_LIVE_TEST_SERVER_ADDRESS'] = old_address else: del os.environ['DJANGO_LIVE_TEST_SERVER_ADDRESS']
pass
pass
self.assertIn(os.path.join('staticfiles_tests', 'apps', 'test', 'static'), searched_locations) self.assertIn(os.path.join('staticfiles_tests', 'apps', 'no_label', 'static'), searched_locations) self.assertIn(TEST_SETTINGS['STATICFILES_DIRS'][1][1], searched_locations) self.assertIn(TEST_SETTINGS['STATICFILES_DIRS'][0], searched_locations) self.assertIn( os.path.join('staticfiles_tests', 'project', 'site_media', 'media'), searched_locations )
self.orig_path = os.path.join(TEST_ROOT, 'apps', 'no_label', 'static', 'file2.txt') self.orig_mtime = os.path.getmtime(self.orig_path) self.orig_atime = os.path.getatime(self.orig_path)
self.temp_app_path = os.path.join(self.temp_dir, 'staticfiles_test_app') self.testfile_path = os.path.join(self.temp_app_path, 'static', 'file2.txt')
self.run_collectstatic()
warning_string = 'Found another file'
with self.settings(STATICFILES_DIRS=[static_dir]): output = self._collectstatic_output(clear=True) self.assertNotIn(self.warning_string, output)
storage.staticfiles_storage.hashed_files.clear()
cache_key = storage.staticfiles_storage.hash_key(name) cached_name = storage.staticfiles_storage.hashed_files.get(cache_key) self.assertEqual(self.hashed_file_path(name), cached_name) storage.staticfiles_storage.hashed_files.clear() cached_name = storage.staticfiles_storage.hashed_files.get(cache_key) self.assertEqual(cached_name, None) self.assertEqual(self.hashed_file_path(name), hashed_name) cached_name = storage.staticfiles_storage.hashed_files.get(cache_key) self.assertEqual(cached_name, hashed_name)
relpath = self.cached_file_path("cached/import.css") self.assertEqual(relpath, "cached/import.2b1d40b0bbd4.css") with storage.staticfiles_storage.open(relpath) as relfile: self.assertIn(b'import url("styles.bb84a0240107.css")', relfile.read())
relpath = self.cached_file_path("cached/test.js") self.assertEqual(relpath, "cached/test.62789ffcd280.js") with storage.staticfiles_storage.open(relpath) as relfile: self.assertIn(b'JS_URL("import.2b1d40b0bbd4.css")', relfile.read())
self.run_collectstatic()
os.unlink(self._clear_filename) self.run_collectstatic(clear=True)
def run_collectstatic(self, **kwargs): pass
models.OriginalRasterField = models.RasterField
if e.args and e.args[0].startswith('Could not import user-defined GEOMETRY_BACKEND'): HAS_POSTGRES = False else: six.reraise(*sys.exc_info())
if hasattr(self, 'current_state'): self.apply_operations('gis', self.current_state, [migrations.DeleteModel('Neighborhood')]) super(OperationTests, self).tearDown()
if HAS_GEOMETRY_COLUMNS: self.assertGeometryColumnsCount(2)
if self.has_spatial_indexes: self.assertSpatialIndexExists('gis_neighborhood', 'path')
if self.has_spatial_indexes: self.assertSpatialIndexExists('gis_neighborhood', 'heatmap')
if HAS_GEOMETRY_COLUMNS: self.assertGeometryColumnsCount(2)
if self.has_spatial_indexes: self.assertSpatialIndexExists('gis_neighborhood', 'path')
if self.has_spatial_indexes: self.assertSpatialIndexExists('gis_neighborhood', 'heatmap')
if HAS_GEOMETRY_COLUMNS: self.assertGeometryColumnsCount(0)
self.assertTableExists("gis_migrations_neighborhood") self.assertTableExists("gis_migrations_household") self.assertTableExists("gis_migrations_family") if connection.features.supports_raster: self.assertTableExists("gis_migrations_heatmap") call_command("migrate", "gis_migrations", "zero", verbosity=0) self.assertTableNotExists("gis_migrations_neighborhood") self.assertTableNotExists("gis_migrations_household") self.assertTableNotExists("gis_migrations_family") if connection.features.supports_raster: self.assertTableNotExists("gis_migrations_heatmap") try: GeoColumn = connection.ops.geometry_columns() except NotImplementedError: pass else: qs = GeoColumn.objects.filter( **{'%s__in' % GeoColumn.table_name_col(): ["gis_neighborhood", "gis_household"]} ) self.assertEqual(qs.count(), 0) call_command("migrate", "gis_migrations", verbosity=0)
center2 = models.PointField(srid=2276, db_column='mycenter') border1 = models.PolygonField() border2 = models.PolygonField(srid=2276)
from __future__ import unicode_literals
cities = ( ('Aurora', 'TX', -97.516111, 33.058333), ('Roswell', 'NM', -104.528056, 33.387222), ('Kecksburg', 'PA', -79.460734, 40.18476), )
tol = 0
transformed = (('Kecksburg', 2272, 'POINT(1490553.98959621 314792.131023984)'), ('Roswell', 2257, 'POINT(481902.189077221 868477.766629735)'), ('Aurora', 2276, 'POINT(2269923.2484839 7069381.28722222)'), )
qs = list(City.objects.filter(name=name).transform(srid, field_name='location__point')) check_pnt(GEOSGeometry(wkt, srid), qs[0].location.point)
self.assertEqual(list(Parcel.objects.transform(srid, field_name='city__location__point')), [])
aggs = City.objects.aggregate(Extent('location__point'))
all_extent = (-104.528056, 29.763374, -79.460734, 40.18476) txpa_extent = (-97.516111, 29.763374, -79.460734, 40.18476) e1 = City.objects.aggregate(Extent('location__point'))['location__point__extent'] e2 = City.objects.exclude(state='NM').aggregate(Extent('location__point'))['location__point__extent'] e3 = aggs['location__point__extent']
tol = 4 for ref, e in [(all_extent, e1), (txpa_extent, e2), (all_extent, e3)]: for ref_val, e_val in zip(ref, e): self.assertAlmostEqual(ref_val, e_val, tol)
aggs = City.objects.aggregate(Union('location__point'))
p1 = Point(-104.528056, 33.387222) p2 = Point(-97.516111, 33.058333) p3 = Point(-79.460734, 40.18476) p4 = Point(-96.801611, 32.782057) p5 = Point(-95.363151, 29.763374)
ref_u1 = MultiPoint(p1, p2, p4, p5, p3, srid=4326) ref_u2 = MultiPoint(p2, p3, srid=4326)
self.assertSetEqual({p.ewkt for p in ref_u1}, {p.ewkt for p in u1}) self.assertSetEqual({p.ewkt for p in ref_u2}, {p.ewkt for p in u2}) self.assertSetEqual({p.ewkt for p in ref_u1}, {p.ewkt for p in u3})
list(DirectoryEntry.objects.all().select_related())
b1 = GEOSGeometry( 'POLYGON((-97.501205 33.052520,-97.501205 33.052576,' '-97.501150 33.052576,-97.501150 33.052520,-97.501205 33.052520))', srid=4326 ) pcity = City.objects.get(name='Aurora')
c1 = pcity.location.point c2 = c1.transform(2276, clone=True) b2 = c2.buffer(100) Parcel.objects.create(name='P1', city=pcity, center1=c1, center2=c2, border1=b1, border2=b2)
c1 = b1.centroid c2 = c1.transform(2276, clone=True) Parcel.objects.create(name='P2', city=pcity, center1=c1, center2=c2, border1=b1, border2=b1)
qs = Parcel.objects.filter(center1__within=F('border1')) self.assertEqual(1, len(qs)) self.assertEqual('P2', qs[0].name)
qs = Parcel.objects.filter(center2__within=F('border1')) self.assertEqual(1, len(qs)) self.assertEqual('P2', qs[0].name)
qs = Parcel.objects.filter(center1=F('city__location__point')) self.assertEqual(1, len(qs)) self.assertEqual('P1', qs[0].name)
qs = Parcel.objects.filter(border2__contains=F('city__location__point')) self.assertEqual(1, len(qs)) self.assertEqual('P1', qs[0].name)
for m, d, t in zip(gqs, gvqs, gvlqs): self.assertIsInstance(d['point'], Geometry) self.assertIsInstance(t[1], Geometry) self.assertEqual(m.point, d['point']) self.assertEqual(m.point, t[1])
city_ids = (1, 2, 3, 4, 5) loc_ids = (1, 2, 3, 5, 4) ids_qs = City.objects.order_by('id').values('id', 'location__id') for val_dict, c_id, l_id in zip(ids_qs, city_ids, loc_ids): self.assertEqual(val_dict['id'], c_id) self.assertEqual(val_dict['location__id'], l_id)
@no_oracle def test10_combine(self): "Testing the combination of two GeoQuerySets. See #10807." buf1 = City.objects.get(name='Aurora').location.point.buffer(0.1) buf2 = City.objects.get(name='Kecksburg').location.point.buffer(0.1) qs1 = City.objects.filter(location__point__within=buf1) qs2 = City.objects.filter(location__point__within=buf2) combined = qs1 | qs2 names = [c.name for c in combined] self.assertEqual(2, len(names)) self.assertIn('Aurora', names) self.assertIn('Kecksburg', names)
@no_oracle def test12a_count(self): "Testing `Count` aggregate on geo-fields." dallas = City.objects.get(name='Dallas')
loc = Location.objects.annotate(num_cities=Count('city')).get(id=dallas.location.id) self.assertEqual(2, loc.num_cities)
qs = Author.objects.annotate(num_books=Count('books')).filter(num_books__gt=1) vqs = Author.objects.values('name').annotate(num_books=Count('books')).filter(num_books__gt=1) self.assertEqual(1, len(qs)) self.assertEqual(3, qs[0].num_books) self.assertEqual(1, len(vqs)) self.assertEqual(3, vqs[0]['num_books'])
@no_oracle def test13c_count(self): "Testing `Count` aggregate with `.values()`. See #15305." qs = Location.objects.filter(id=5).annotate(num_cities=Count('city')).values('id', 'point', 'num_cities') self.assertEqual(1, len(qs)) self.assertEqual(2, qs[0]['num_cities']) self.assertIsInstance(qs[0]['point'], GEOSGeometry)
@no_oracle def test13_select_related_null_fk(self): "Testing `select_related` on a nullable ForeignKey." Book.objects.create(title='Without Author') b = Book.objects.select_related('author').get(title='Without Author') self.assertIsNone(b.author)
ref_geom = GEOSGeometry( 'MULTIPOINT(-97.516111 33.058333,-96.801611 32.782057,' '-95.363151 29.763374,-96.801611 32.782057)' )
self.assertEqual(4, len(coll)) self.assertTrue(ref_geom.equals(coll))
str(qs.query)
city_data = ( ('Houston', (-95.363151, 29.763374, 18)), ('Dallas', (-96.801611, 32.782057, 147)), ('Oklahoma City', (-97.521157, 34.464642, 380)), ('Wellington', (174.783117, -41.315268, 14)), ('Pueblo', (-104.609252, 38.255001, 1433)), ('Lawrence', (-95.235060, 38.971823, 251)), ('Chicago', (-87.650175, 41.850385, 181)), ('Victoria', (-123.305196, 48.462611, 15)), )
city_dict = {name: coords for name, coords in city_data}
interstate_data = ( ('I-45', 'LINESTRING(-95.3708481 29.7765870 11.339,-95.3694580 29.7787980 4.536,' '-95.3690305 29.7797359 9.762,-95.3691886 29.7812450 12.448,' '-95.3696447 29.7850144 10.457,-95.3702511 29.7868518 9.418,' '-95.3706724 29.7881286 14.858,-95.3711632 29.7896157 15.386,' '-95.3714525 29.7936267 13.168,-95.3717848 29.7955007 15.104,' '-95.3717719 29.7969804 16.516,-95.3717305 29.7982117 13.923,' '-95.3717254 29.8000778 14.385,-95.3719875 29.8013539 15.160,' '-95.3720575 29.8026785 15.544,-95.3721321 29.8040912 14.975,' '-95.3722074 29.8050998 15.688,-95.3722779 29.8060430 16.099,' '-95.3733818 29.8076750 15.197,-95.3741563 29.8103686 17.268,' '-95.3749458 29.8129927 19.857,-95.3763564 29.8144557 15.435)', (11.339, 4.536, 9.762, 12.448, 10.457, 9.418, 14.858, 15.386, 13.168, 15.104, 16.516, 13.923, 14.385, 15.16, 15.544, 14.975, 15.688, 16.099, 15.197, 17.268, 19.857, 15.435), ), )
bbox_data = ( 'POLYGON((941527.97 4225693.20,962596.48 4226349.75,963152.57 4209023.95,' '942051.75 4208366.38,941527.97 4225693.20))', (21.71, 13.21, 9.12, 16.40, 21.71) )
for name, line, exp_z in interstate_data: line_3d = GEOSGeometry(line, srid=4269) line_2d = LineString([l[:2] for l in line_3d.coords], srid=4269)
Interstate3D.objects.create(name=name, line=line_3d) InterstateProj3D.objects.create(name=name, line=line_3d) Interstate2D.objects.create(name=name, line=line_2d) InterstateProj2D.objects.create(name=name, line=line_2d)
lm = LayerMapping(Point2D, vrt_file, point_mapping, transform=False) lm.save() self.assertEqual(3, Point2D.objects.count())
with self.assertRaises(LayerMapError): LayerMapping(Point3D, city_file, point_mapping, transform=False)
lm = LayerMapping(Point3D, vrt_file, point_mapping, transform=False) lm.save() self.assertEqual(3, Point3D.objects.count())
lm = LayerMapping(MultiPoint3D, vrt_file, mpoint_mapping, transform=False) lm.save() self.assertEqual(3, MultiPoint3D.objects.count())
ref_kml_regex = re.compile(r'^<Point><coordinates>-95.363\d+,29.763\d+,18</coordinates></Point>$') self.assertTrue(ref_kml_regex.match(h.kml))
ref_json_regex = re.compile(r'^{"type":"Point","coordinates":\[-95.363151,29.763374,18(\.0+)?\]}$') self.assertTrue(ref_json_regex.match(h.geojson))
self._load_city_data() ref_ewkt = ( 'SRID=4326;MULTIPOINT(-123.305196 48.462611 15,-104.609252 38.255001 1433,' '-97.521157 34.464642 380,-96.801611 32.782057 147,-95.363151 29.763374 18,' '-95.23506 38.971823 251,-87.650175 41.850385 181,174.783117 -41.315268 14)' ) ref_union = GEOSGeometry(ref_ewkt) union = City3D.objects.aggregate(Union('point'))['point__union'] self.assertTrue(union.hasz) self.assertSetEqual({p.ewkt for p in ref_union}, {p.ewkt for p in union})
ref_extent3d = (-123.305196, -41.315268, 14, 174.783117, 48.462611, 1433) extent = City3D.objects.aggregate(Extent3D('point'))['point__extent3d']
ref_perim_3d = 76859.2620451 ref_perim_2d = 76859.2577803 tol = 6 self.assertAlmostEqual(ref_perim_2d, Polygon2D.objects.perimeter().get(name='2D BBox').perimeter.m, tol) self.assertAlmostEqual(ref_perim_3d, Polygon3D.objects.perimeter().get(name='3D BBox').perimeter.m, tol)
self._load_interstate_data() tol = 3 ref_length_2d = 4368.1721949481 ref_length_3d = 4368.62547052088 self.assertAlmostEqual(ref_length_2d, Interstate2D.objects.length().get(name='I-45').length.m, tol) self.assertAlmostEqual(ref_length_3d, Interstate3D.objects.length().get(name='I-45').length.m, tol)
ref_length_2d = 4367.71564892392 ref_length_3d = 4368.16897234101 self.assertAlmostEqual(ref_length_2d, InterstateProj2D.objects.length().get(name='I-45').length.m, tol) self.assertAlmostEqual(ref_length_3d, InterstateProj3D.objects.length().get(name='I-45').length.m, tol)
zscales = (-3, 4, 23) for zscale in zscales: for city in City3D.objects.scale(1.0, 1.0, zscale): self.assertEqual(city_dict[city.name][2] * zscale, city.scale.z)
ref_kml_regex = re.compile(r'^<Point><coordinates>-95.363\d+,29.763\d+,18</coordinates></Point>$') self.assertTrue(ref_kml_regex.match(h.kml))
ref_json_regex = re.compile(r'^{"type":"Point","coordinates":\[-95.363151,29.763374,18(\.0+)?\]}$') self.assertTrue(ref_json_regex.match(h.geojson))
ref_perim_3d = 76859.2620451 ref_perim_2d = 76859.2577803 tol = 6 poly2d = Polygon2D.objects.annotate(perimeter=Perimeter('poly')).get(name='2D BBox') self.assertAlmostEqual(ref_perim_2d, poly2d.perimeter.m, tol) poly3d = Polygon3D.objects.annotate(perimeter=Perimeter('poly')).get(name='3D BBox') self.assertAlmostEqual(ref_perim_3d, poly3d.perimeter.m, tol)
self._load_interstate_data() tol = 3 ref_length_2d = 4368.1721949481 ref_length_3d = 4368.62547052088 inter2d = Interstate2D.objects.annotate(length=Length('line')).get(name='I-45') self.assertAlmostEqual(ref_length_2d, inter2d.length.m, tol) inter3d = Interstate3D.objects.annotate(length=Length('line')).get(name='I-45') self.assertAlmostEqual(ref_length_3d, inter3d.length.m, tol)
ref_length_2d = 4367.71564892392 ref_length_3d = 4368.16897234101 inter2d = InterstateProj2D.objects.annotate(length=Length('line')).get(name='I-45') self.assertAlmostEqual(ref_length_2d, inter2d.length.m, tol) inter3d = InterstateProj3D.objects.annotate(length=Length('line')).get(name='I-45') self.assertAlmostEqual(ref_length_3d, inter3d.length.m, tol)
zscales = (-3, 4, 23) for zscale in zscales: for city in City3D.objects.annotate(scale=Scale('point', 1.0, 1.0, zscale)): self.assertEqual(city_dict[city.name][2] * zscale, city.scale.z)
TEST_DATA = os.path.join(os.path.dirname(upath(__file__)), 'data')
ext = kwargs.pop('ext', 'shp') self.ds = get_ds_file(name, ext) super(TestDS, self).__init__(**kwargs)
coords = kwargs.pop('coords', None) if coords: self.coords = tuplize(coords)
with open(os.path.join(TEST_DATA, 'geometries.json')) as f: geometries = json.load(f) return TestGeomSet(**strconvert(geometries))
self.assertEqual( self.rs.geotransform, [511700.4680706557, 100.0, 0.0, 435103.3771231986, 0.0, -100.0] ) self.assertEqual(self.rs.origin, [511700.4680706557, 435103.3771231986]) self.assertEqual(self.rs.origin.x, 511700.4680706557) self.assertEqual(self.rs.origin.y, 435103.3771231986) self.assertEqual(self.rs.scale, [100.0, -100.0]) self.assertEqual(self.rs.scale.x, 100.0) self.assertEqual(self.rs.scale.y, -100.0) self.assertEqual(self.rs.skew, [0, 0]) self.assertEqual(self.rs.skew.x, 0) self.assertEqual(self.rs.skew.y, 0) rsmem = GDALRaster(JSON_RASTER) rsmem.geotransform = range(6) self.assertEqual(rsmem.geotransform, [float(x) for x in range(6)]) self.assertEqual(rsmem.origin, [0, 3]) self.assertEqual(rsmem.origin.x, 0) self.assertEqual(rsmem.origin.y, 3) self.assertEqual(rsmem.scale, [1, 5]) self.assertEqual(rsmem.scale.x, 1) self.assertEqual(rsmem.scale.y, 5) self.assertEqual(rsmem.skew, [2, 4]) self.assertEqual(rsmem.skew.x, 2) self.assertEqual(rsmem.skew.y, 4) self.assertEqual(rsmem.width, 5) self.assertEqual(rsmem.height, 5)
rast = GDALRaster({ 'datatype': 1, 'width': 16, 'height': 16, 'srid': 4326, 'bands': [{ 'data': range(256), 'nodata_value': 255, }], })
result = rast.bands[0].data() if numpy: result = result.flatten().tolist()
self.assertEqual(result, list(range(256)))
rstfile = tempfile.NamedTemporaryFile(suffix='.tif')
GDALRaster({ 'datatype': self.rs.bands[0].datatype(), 'driver': 'tif', 'name': rstfile.name, 'width': 163, 'height': 174, 'nr_of_bands': 1, 'srid': self.rs.srs.wkt, 'origin': (self.rs.origin.x, self.rs.origin.y), 'scale': (self.rs.scale.x, self.rs.scale.y), 'skew': (self.rs.skew.x, self.rs.skew.y), 'bands': [{ 'data': self.rs.bands[0].data(), 'nodata_value': self.rs.bands[0].nodata_value, }], })
restored_raster = GDALRaster(rstfile.name) self.assertEqual(restored_raster.srs.wkt, self.rs.srs.wkt) self.assertEqual(restored_raster.geotransform, self.rs.geotransform) if numpy: numpy.testing.assert_equal( restored_raster.bands[0].data(), self.rs.bands[0].data() ) else: self.assertEqual(restored_raster.bands[0].data(), self.rs.bands[0].data())
source = GDALRaster({ 'datatype': 1, 'driver': 'MEM', 'name': 'sourceraster', 'width': 4, 'height': 4, 'nr_of_bands': 1, 'srid': 3086, 'origin': (500000, 400000), 'scale': (100, -100), 'skew': (0, 0), 'bands': [{ 'data': range(16), 'nodata_value': 255, }], })
data = { 'scale': [200, -200], 'width': 2, 'height': 2, } target = source.warp(data) self.assertEqual(target.width, data['width']) self.assertEqual(target.height, data['height']) self.assertEqual(target.scale, data['scale']) self.assertEqual(target.bands[0].datatype(), source.bands[0].datatype()) self.assertEqual(target.name, 'sourceraster_copy.MEM') result = target.bands[0].data() if numpy: result = result.flatten().tolist() self.assertEqual(result, [5, 7, 13, 15])
data = { 'name': '/path/to/targetraster.tif', 'datatype': 6, } target = source.warp(data) self.assertEqual(target.bands[0].datatype(), 6) self.assertEqual(target.name, '/path/to/targetraster.tif') self.assertEqual(target.driver.name, 'MEM') result = target.bands[0].data() if numpy: result = result.flatten().tolist() self.assertEqual( result, [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0] )
rstfile = tempfile.NamedTemporaryFile(suffix='.tif') ndv = 99
source = GDALRaster({ 'datatype': 1, 'driver': 'tif', 'name': rstfile.name, 'width': 5, 'height': 5, 'nr_of_bands': 1, 'srid': 4326, 'origin': (-5, 5), 'scale': (2, -2), 'skew': (0, 0), 'bands': [{ 'data': range(25), 'nodata_value': ndv, }], })
target = source.transform(3086)
target = GDALRaster(target.name)
self.assertEqual( result, [ ndv, ndv, ndv, ndv, 4, ndv, ndv, ndv, ndv, 2, 3, 9, ndv, ndv, ndv, 1, 2, 8, 13, 19, ndv, 0, 6, 6, 12, 18, 18, 24, ndv, 10, 11, 16, 22, 23, ndv, ndv, ndv, 15, 21, 22, ndv, ndv, ndv, ndv, 20, ndv, ndv, ndv, ndv, ] )
self.band = None self.assertTrue(os.path.isfile(pam_file))
self.band = None if os.path.isfile(pam_file): os.remove(pam_file)
rs = GDALRaster(self.rs_path, write=False) band = rs.bands[0]
with self.assertRaises(GDALException): setattr(band, 'nodata_value', 10)
rsmem = GDALRaster({ 'datatype': 1, 'driver': 'MEM', 'name': 'mem_rst', 'width': 10, 'height': 10, 'nr_of_bands': 1, 'srid': 4326, }) bandmem = rsmem.bands[0]
bandmem.nodata_value = 99 self.assertEqual(bandmem.nodata_value, 99)
bandmem.data(range(100)) if numpy: numpy.testing.assert_equal(bandmem.data(), numpy.arange(100).reshape(10, 10)) else: self.assertEqual(bandmem.data(), list(range(100)))
block = list(range(100, 104)) packed_block = struct.pack('<' + 'B B B B', *block)
bandmem.data(block, (1, 1), (2, 2)) result = bandmem.data(offset=(1, 1), size=(2, 2)) if numpy: numpy.testing.assert_equal(result, numpy.array(block).reshape(2, 2)) else: self.assertEqual(result, block)
bandmem.data(packed_block, (1, 1), (2, 2)) result = bandmem.data(offset=(1, 1), size=(2, 2)) if numpy: numpy.testing.assert_equal(result, numpy.array(block).reshape(2, 2)) else: self.assertEqual(result, block)
bandmem.data(bytes(packed_block), (1, 1), (2, 2)) result = bandmem.data(offset=(1, 1), size=(2, 2)) if numpy: numpy.testing.assert_equal(result, numpy.array(block).reshape(2, 2)) else: self.assertEqual(result, block)
bandmem.data(bytearray(packed_block), (1, 1), (2, 2)) result = bandmem.data(offset=(1, 1), size=(2, 2)) if numpy: numpy.testing.assert_equal(result, numpy.array(block).reshape(2, 2)) else: self.assertEqual(result, block)
bandmem.data(six.memoryview(packed_block), (1, 1), (2, 2)) result = bandmem.data(offset=(1, 1), size=(2, 2)) if numpy: numpy.testing.assert_equal(result, numpy.array(block).reshape(2, 2)) else: self.assertEqual(result, block)
if numpy: bandmem.data(numpy.array(block, dtype='int8').reshape(2, 2), (1, 1), (2, 2)) numpy.testing.assert_equal( bandmem.data(offset=(1, 1), size=(2, 2)), numpy.array(block).reshape(2, 2) )
rsmemjson = GDALRaster(JSON_RASTER) bandmemjson = rsmemjson.bands[0] if numpy: numpy.testing.assert_equal( bandmemjson.data(), numpy.array(range(25)).reshape(5, 5) ) else: self.assertEqual(bandmemjson.data(), list(range(25)))
self.assertEqual(band.statistics(), (0, 0, 0, 0)) band.data([1, 1, 0, 0]) self.assertEqual(band.statistics(), (0.0, 1.0, 0.5, 0.5)) band.nodata_value = 0 self.assertEqual(band.statistics(), (1.0, 1.0, 1.0, 0.0))
combos = ( ([1], (1, 1), [1] * 9), (range(3), (1, 3), [0, 0, 0, 1, 1, 1, 2, 2, 2]), (range(3), (3, 1), [0, 1, 2, 0, 1, 2, 0, 1, 2]), ) for combo in combos: band.data(combo[0], shape=combo[1]) if numpy: numpy.testing.assert_equal(band.data(), numpy.array(combo[2]).reshape(3, 3)) else: self.assertEqual(band.data(), list(combo[2]))
ds_list = ( TestDS( 'test_point', nfeat=5, nfld=3, geom='POINT', gtype=1, driver='ESRI Shapefile', fields={'dbl': OFTReal, 'int': OFTInteger, 'str': OFTString},
ds = DataSource(source.ds)
self.assertEqual(1, len(ds))
self.assertEqual(source.ds, ds.name)
self.assertEqual(source.driver, str(ds.driver))
try: ds[len(ds)] except OGRIndexError: pass else: self.fail('Expected an IndexError!')
for layer in ds: self.assertEqual(len(layer), source.nfeat)
self.assertEqual(source.nfld, layer.num_fields) self.assertEqual(source.nfld, len(layer.fields))
if source.driver == 'VRT' and (GDAL_VERSION >= (1, 7, 0) and GDAL_VERSION < (1, 7, 3)): pass else: self.assertIsInstance(layer.extent, Envelope) self.assertAlmostEqual(source.extent[0], layer.extent.min_x, 5) self.assertAlmostEqual(source.extent[1], layer.extent.min_y, 5) self.assertAlmostEqual(source.extent[2], layer.extent.max_x, 5) self.assertAlmostEqual(source.extent[3], layer.extent.max_y, 5)
flds = layer.fields for f in flds: self.assertIn(f, source.fields)
with self.assertRaises(OGRIndexError): layer.__getitem__(-1) with self.assertRaises(OGRIndexError): layer.__getitem__(50000)
for fld_name in fld_names: self.assertEqual(source.field_values[fld_name], layer.get_fields(fld_name))
for i, fid in enumerate(source.fids): feat = layer[fid] self.assertEqual(fid, feat.fid) for fld_name in fld_names: self.assertEqual(source.field_values[fld_name][i], feat.get(fld_name))
source = ds_list[0] ds = DataSource(source.ds)
def get_layer(): ds = DataSource(source.ds) return ds[0]
lyr = get_layer() self.assertEqual(source.nfeat, len(lyr)) self.assertEqual(source.gtype, lyr.geom_type.num)
self.assertEqual(str(lyr[0]['str']), "1")
for layer in ds: for feat in layer: self.assertEqual(source.nfld, len(list(feat))) self.assertEqual(source.gtype, feat.geom_type)
for k, v in source.fields.items(): self.assertIsInstance(feat[k], v)
for fld in feat: self.assertIn(fld.name, source.fields.keys())
for layer in ds: for feat in layer: g = feat.geom
self.assertEqual(source.geom, g.geom_name) self.assertEqual(source.gtype, g.geom_type)
if hasattr(source, 'srs_wkt'): self.assertEqual( source.srs_wkt, g.srs.wkt.replace('SPHEROID["WGS_84"', 'SPHEROID["WGS_1984"') )
self.assertIsNone(lyr.spatial_filter)
with self.assertRaises(TypeError): lyr._set_spatial_filter('foo')
with self.assertRaises(ValueError): lyr._set_spatial_filter(list(range(5))) filter_extent = (-105.609252, 37.255001, -103.609252, 39.255001) lyr.spatial_filter = (-105.609252, 37.255001, -103.609252, 39.255001) self.assertEqual(OGRGeometry.from_bbox(filter_extent), lyr.spatial_filter) feats = [feat for feat in lyr] self.assertEqual(1, len(feats)) self.assertEqual('Pueblo', feats[0].get('Name'))
filter_geom = OGRGeometry( 'POLYGON((-96.363151 28.763374,-94.363151 28.763374,' '-94.363151 30.763374,-96.363151 30.763374,-96.363151 28.763374))' ) lyr.spatial_filter = filter_geom self.assertEqual(filter_geom, lyr.spatial_filter) feats = [feat for feat in lyr] self.assertEqual(1, len(feats)) self.assertEqual('Houston', feats[0].get('Name'))
lyr.spatial_filter = None self.assertEqual(3, len(lyr))
ds = DataSource(os.path.join(TEST_DATA, 'texas.dbf')) feat = ds[0][0] self.assertEqual(676586997978, feat.get('ALAND10'))
srlist = ( TestSRS( 'GEOGCS["WGS 84",DATUM["WGS_1984",SPHEROID["WGS 84",6378137,298.257223563,' 'AUTHORITY["EPSG","7030"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY["EPSG","6326"]],' 'PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],UNIT["degree",' '0.01745329251994328,AUTHORITY["EPSG","9122"]],AUTHORITY["EPSG","4326"]]', epsg=4326, projected=False, geographic=True, local=False, lin_name='unknown', ang_name='degree', lin_units=1.0, ang_units=0.0174532925199, auth={'GEOGCS': ('EPSG', '4326'), 'spheroid': ('EPSG', '7030')}, attr=(('DATUM', 'WGS_1984'), (('SPHEROID', 1), '6378137'), ('primem|authority', 'EPSG'),), ), TestSRS( 'PROJCS["NAD83 / Texas South Central",GEOGCS["NAD83",DATUM["North_American_Datum_1983",' 'SPHEROID["GRS 1980",6378137,298.257222101,AUTHORITY["EPSG","7019"]],' 'AUTHORITY["EPSG","6269"]],PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],' 'UNIT["degree",0.01745329251994328,AUTHORITY["EPSG","9122"]],' 'AUTHORITY["EPSG","4269"]],PROJECTION["Lambert_Conformal_Conic_2SP"],' 'PARAMETER["standard_parallel_1",30.28333333333333],' 'PARAMETER["standard_parallel_2",28.38333333333333],' 'PARAMETER["latitude_of_origin",27.83333333333333],' 'PARAMETER["central_meridian",-99],PARAMETER["false_easting",600000],' 'PARAMETER["false_northing",4000000],UNIT["metre",1,AUTHORITY["EPSG","9001"]],' 'AUTHORITY["EPSG","32140"]]', epsg=32140, projected=True, geographic=False, local=False, lin_name='metre', ang_name='degree', lin_units=1.0, ang_units=0.0174532925199, auth={'PROJCS': ('EPSG', '32140'), 'spheroid': ('EPSG', '7019'), 'unit': ('EPSG', '9001')}, attr=( ('DATUM', 'North_American_Datum_1983'), (('SPHEROID', 2), '298.257222101'), ('PROJECTION', 'Lambert_Conformal_Conic_2SP'), ), ), TestSRS( 'PROJCS["NAD_1983_StatePlane_Texas_South_Central_FIPS_4204_Feet",' 'GEOGCS["GCS_North_American_1983",DATUM["North_American_Datum_1983",' 'SPHEROID["GRS_1980",6378137.0,298.257222101]],PRIMEM["Greenwich",0.0],' 'UNIT["Degree",0.0174532925199433]],PROJECTION["Lambert_Conformal_Conic_2SP"],' 'PARAMETER["False_Easting",1968500.0],PARAMETER["False_Northing",13123333.33333333],' 'PARAMETER["Central_Meridian",-99.0],PARAMETER["Standard_Parallel_1",28.38333333333333],' 'PARAMETER["Standard_Parallel_2",30.28333333333334],PARAMETER["Latitude_Of_Origin",27.83333333333333],' 'UNIT["Foot_US",0.3048006096012192]]', epsg=None, projected=True, geographic=False, local=False, lin_name='Foot_US', ang_name='Degree', lin_units=0.3048006096012192, ang_units=0.0174532925199, auth={'PROJCS': (None, None)}, attr=(('PROJCS|GeOgCs|spheroid', 'GRS_1980'), (('projcs', 9), 'UNIT'), (('projcs', 11), None),), ), TestSRS( 'LOCAL_CS["Non-Earth (Meter)",LOCAL_DATUM["Local Datum",0],UNIT["Meter",1.0],AXIS["X",EAST],AXIS["Y",NORTH]]', esri=True, epsg=None, projected=False, geographic=False, local=True, lin_name='Meter', ang_name='degree', lin_units=1.0, ang_units=0.0174532925199, attr=(('LOCAL_DATUM', 'Local Datum'), ('unit', 'Meter')), ), )
well_known = ( TestSRS( 'GEOGCS["WGS 84",DATUM["WGS_1984",SPHEROID["WGS 84",6378137,298.257223563,' 'AUTHORITY["EPSG","7030"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY["EPSG","6326"]],' 'PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],UNIT["degree",0.01745329251994328,' 'AUTHORITY["EPSG","9122"]],AUTHORITY["EPSG","4326"]]', wk='WGS84', name='WGS 84', attrs=(('GEOGCS|AUTHORITY', 1, '4326'), ('SPHEROID', 'WGS 84')), ), TestSRS( 'GEOGCS["WGS 72",DATUM["WGS_1972",SPHEROID["WGS 72",6378135,298.26,' 'AUTHORITY["EPSG","7043"]],AUTHORITY["EPSG","6322"]],' 'PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],' 'UNIT["degree",0.01745329251994328,AUTHORITY["EPSG","9122"]],' 'AUTHORITY["EPSG","4322"]]', wk='WGS72', name='WGS 72', attrs=(('GEOGCS|AUTHORITY', 1, '4322'), ('SPHEROID', 'WGS 72')), ), TestSRS( 'GEOGCS["NAD27",DATUM["North_American_Datum_1927",' 'SPHEROID["Clarke 1866",6378206.4,294.9786982138982,' 'AUTHORITY["EPSG","7008"]],AUTHORITY["EPSG","6267"]],' 'PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],' 'UNIT["degree",0.01745329251994328,AUTHORITY["EPSG","9122"]],' 'AUTHORITY["EPSG","4267"]]', wk='NAD27', name='NAD27', attrs=(('GEOGCS|AUTHORITY', 1, '4267'), ('SPHEROID', 'Clarke 1866')) ), TestSRS( 'GEOGCS["NAD83",DATUM["North_American_Datum_1983",' 'SPHEROID["GRS 1980",6378137,298.257222101,' 'AUTHORITY["EPSG","7019"]],AUTHORITY["EPSG","6269"]],' 'PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],' 'UNIT["degree",0.01745329251994328,AUTHORITY["EPSG","9122"]],' 'AUTHORITY["EPSG","4269"]]', wk='NAD83', name='NAD83', attrs=(('GEOGCS|AUTHORITY', 1, '4269'), ('SPHEROID', 'GRS 1980')), ), TestSRS( 'PROJCS["NZGD49 / Karamea Circuit",GEOGCS["NZGD49",' 'DATUM["New_Zealand_Geodetic_Datum_1949",' 'SPHEROID["International 1924",6378388,297,' 'AUTHORITY["EPSG","7022"]],' 'TOWGS84[59.47,-5.04,187.44,0.47,-0.1,1.024,-4.5993],' 'AUTHORITY["EPSG","6272"]],PRIMEM["Greenwich",0,' 'AUTHORITY["EPSG","8901"]],UNIT["degree",0.01745329251994328,' 'AUTHORITY["EPSG","9122"]],AUTHORITY["EPSG","4272"]],' 'PROJECTION["Transverse_Mercator"],' 'PARAMETER["latitude_of_origin",-41.28991152777778],' 'PARAMETER["central_meridian",172.1090281944444],' 'PARAMETER["scale_factor",1],PARAMETER["false_easting",300000],' 'PARAMETER["false_northing",700000],' 'UNIT["metre",1,AUTHORITY["EPSG","9001"]],AUTHORITY["EPSG","27216"]]', wk='EPSG:27216', name='NZGD49 / Karamea Circuit', attrs=(('PROJECTION', 'Transverse_Mercator'), ('SPHEROID', 'International 1924')), ), )
OGRGeomType(1) OGRGeomType(7) OGRGeomType('point') OGRGeomType('GeometrycollectioN') OGRGeomType('LINearrING') OGRGeomType('Unknown')
with self.assertRaises(GDALException): OGRGeomType(23) with self.assertRaises(GDALException): OGRGeomType('fooD') with self.assertRaises(GDALException): OGRGeomType(9)
self.assertEqual(OGRGeomType(1), OGRGeomType(1)) self.assertEqual(OGRGeomType(7), 'GeometryCollection') self.assertEqual(OGRGeomType('point'), 'POINT') self.assertNotEqual(OGRGeomType('point'), 2) self.assertEqual(OGRGeomType('unknown'), 0) self.assertEqual(OGRGeomType(6), 'MULtiPolyGON') self.assertEqual(OGRGeomType(1), OGRGeomType('point')) self.assertNotEqual(OGRGeomType('POINT'), OGRGeomType(6))
self.assertEqual('PointField', OGRGeomType('Point').django) self.assertEqual('GeometryField', OGRGeomType('Geometry').django) self.assertEqual('GeometryField', OGRGeomType('Unknown').django) self.assertIsNone(OGRGeomType('none').django)
gt = OGRGeomType('Geometry') self.assertEqual(0, gt.num) self.assertEqual('Unknown', gt.name)
self.assertEqual(ewkt_val, OGRGeometry(ewkt_val).ewkt) ewkt_val = 'SRID=4326;%s' % ewkt_val geom = OGRGeometry(ewkt_val) self.assertEqual(ewkt_val, geom.ewkt) self.assertEqual(4326, geom.srs.srid)
exp_gml = exp_gml.replace('GeometryCollection', 'MultiGeometry')
geom2 = OGRGeometry(g.hex) self.assertEqual(geom1, geom2)
geom2 = OGRGeometry(wkb) self.assertEqual(geom1, geom2)
self.assertEqual(json.loads(g.json), json.loads(geom.json)) self.assertEqual(json.loads(g.json), json.loads(geom.geojson))
geom = OGRGeometry('{"type": "Point", "coordinates": [ 100.0, 0.0 ], "other": "<test>"}') self.assertIsInstance(geom, OGRGeometry)
x = [tmpx for tmpx, tmpy in ls.coords] y = [tmpy for tmpx, tmpy in ls.coords] self.assertEqual(x, linestr.x) self.assertEqual(y, linestr.y)
self.assertEqual('LINEARRING', lr.geom_name) self.assertEqual(rr.n_p, len(lr)) self.assertEqual(lr, OGRGeometry(rr.wkt)) self.assertNotEqual(lr, prev) prev = lr
bbox = (-180, -90, 180, 90) p = OGRGeometry.from_bbox(bbox) self.assertEqual(bbox, p.extent)
self.assertAlmostEqual(p.area, poly.area, 9) x, y = poly.centroid.tuple self.assertAlmostEqual(p.centroid[0], x, 9) self.assertAlmostEqual(p.centroid[1], y, 9)
self.assertEqual(poly, OGRGeometry(p.wkt)) self.assertNotEqual(poly, prev)
poly = OGRGeometry('POLYGON((0 0, 5 0, 5 5, 0 5), (1 1, 2 1, 2 2, 2 1))') self.assertEqual(8, poly.point_count) with self.assertRaises(GDALException): poly.centroid
sr = SpatialReference('WGS84') mpoly = OGRGeometry(mp.wkt, sr) self.assertEqual(sr.wkt, mpoly.srs.wkt)
klone = mpoly.clone() self.assertEqual(sr.wkt, klone.srs.wkt)
for poly in mpoly: self.assertEqual(sr.wkt, poly.srs.wkt) for ring in poly: self.assertEqual(sr.wkt, ring.srs.wkt)
a = OGRGeometry(self.geometries.topology_geoms[0].wkt_a, sr) b = OGRGeometry(self.geometries.topology_geoms[0].wkt_b, sr) diff = a.difference(b) union = a.union(b) self.assertEqual(sr.wkt, diff.srs.wkt) self.assertEqual(sr.srid, union.srs.srid)
mpoly = OGRGeometry(mp.wkt, 4326) self.assertEqual(4326, mpoly.srid) mpoly.srs = SpatialReference(4269) self.assertEqual(4269, mpoly.srid) self.assertEqual('NAD83', mpoly.srs.name)
for poly in mpoly: self.assertEqual(mpoly.srs.wkt, poly.srs.wkt) poly.srs = 32140 for ring in poly: self.assertEqual(32140, ring.srs.srid) self.assertEqual('NAD83 / Texas South Central', ring.srs.name)
ring.srid = 4322 self.assertEqual('WGS 72', ring.srs.name) self.assertEqual(4322, ring.srid)
mpoly = OGRGeometry(mp.wkt, srs=None) mpoly.srs = mpoly.srs mpoly.srid = mpoly.srid
t1, t2, t3 = orig.clone(), orig.clone(), orig.clone() t1.transform(trans.srid) t2.transform(SpatialReference('EPSG:2774')) ct = CoordTransform(SpatialReference('WGS84'), SpatialReference(2774)) t3.transform(ct)
k1 = orig.clone() k2 = k1.transform(trans.srid, clone=True) self.assertEqual(k1, orig) self.assertNotEqual(k1, k2)
self.assertEqual(2, ls_orig.coord_dim) self.assertAlmostEqual(ls_trans.x[0], ls_orig.x[0], prec) self.assertAlmostEqual(ls_trans.y[0], ls_orig.y[0], prec)
mp = OGRGeometry('MultiPolygon') pnt = OGRGeometry('POINT(5 23)') with self.assertRaises(GDALException): mp.add(pnt)
for mp in self.geometries.multipolygons: mpoly = OGRGeometry(mp.wkt) mp1 = OGRGeometry('MultiPolygon') mp2 = OGRGeometry('MultiPolygon') mp3 = OGRGeometry('MultiPolygon')
mp = OGRGeometry('MULTIPOINT(5 23, 0 0, 10 50)') self.assertEqual((0.0, 0.0, 10.0, 50.0), mp.extent) poly = OGRGeometry(self.geometries.polygons[3].wkt) ring = poly.shell x, y = ring.x, ring.y xmin, ymin = min(x), min(y) xmax, ymax = max(x), max(y) self.assertEqual((xmin, ymin, xmax, ymax), poly.extent)
wkt_2d = "MULTILINESTRING ((0 0,1 1,2 2))" wkt_3d = "MULTILINESTRING ((0 0 0,1 1 1,2 2 2))" srid = 4326
geom = OGRGeometry(wkt_2d, srid) geom.transform(srid) self.assertEqual(2, geom.coord_dim) self.assertEqual(2, geom[0].coord_dim) self.assertEqual(wkt_2d, geom.wkt)
'ESRI Shapefile', 'MapInfo File', 'TIGER', 'S57', 'DGN', 'Memory', 'CSV', 'GML', 'KML', 'GTiff', 'JPEG', 'MEM', 'PNG',
class CityBase(NamedModel): population = models.IntegerField() density = models.DecimalField(max_digits=7, decimal_places=1) point = models.PointField()
co_mapping = { 'name': 'Name', 'state': {'name': 'State'},
from __future__ import unicode_literals
NAMES = ['Bexar', 'Galveston', 'Harris', 'Honolulu', 'Pueblo']
bad1 = copy(city_mapping) bad1['foobar'] = 'FooField'
bad2 = copy(city_mapping) bad2['name'] = 'Nombre'
bad3 = copy(city_mapping) bad3['point'] = 'CURVE'
for bad_map in (bad1, bad2, bad3): with self.assertRaises(LayerMapError): LayerMapping(City, city_shp, bad_map)
with self.assertRaises(LookupError): LayerMapping(City, city_shp, city_mapping, encoding='foobar')
lm = LayerMapping(City, city_shp, city_mapping) lm.save()
self.assertEqual(3, City.objects.count())
ds = DataSource(city_shp) layer = ds[0] for feat in layer: city = City.objects.get(name=feat['Name'].value) self.assertEqual(feat['Population'].value, city.population) self.assertEqual(Decimal(str(feat['Density'])), city.density) self.assertEqual(feat['Created'].value, city.dt)
pnt1, pnt2 = feat.geom, city.point self.assertAlmostEqual(pnt1.x, pnt2.x, 5) self.assertAlmostEqual(pnt1.y, pnt2.y, 5)
with self.assertRaises(InvalidDecimal): lm = LayerMapping(Interstate, inter_shp, inter_mapping) lm.save(silent=True, strict=True) Interstate.objects.all().delete()
lm = LayerMapping(Interstate, inter_shp, inter_mapping) lm.save(silent=True)
self.assertEqual(2, Interstate.objects.count())
ds = DataSource(inter_shp)
valid_feats = ds[0][:2] for feat in valid_feats: istate = Interstate.objects.get(name=feat['Name'].value)
self.assertAlmostEqual(feat.get('Length'), float(istate.length), 2)
c = County.objects.get(name=name) self.assertEqual(n, len(c.mpoly))
if county_feat: qs = CountyFeat.objects.filter(name=name) self.assertEqual(n, qs.count())
lm = LayerMapping(County, co_shp, co_mapping, transform=False)
lm = LayerMapping(County, co_shp, co_mapping, source_srs=4269) lm = LayerMapping(County, co_shp, co_mapping, source_srs='NAD83')
for arg in ('name', ('name', 'mpoly')): lm = LayerMapping(County, co_shp, co_mapping, transform=False, unique=arg)
for e, arg in ((TypeError, 5.0), (ValueError, 'foobar'), (ValueError, ('name', 'mpolygon'))): with self.assertRaises(e): LayerMapping(County, co_shp, co_mapping, transform=False, unique=arg)
if connection.features.supports_transform: with self.assertRaises(LayerMapError): LayerMapping(County, co_shp, co_mapping)
bad_fk_map1 = copy(co_mapping) bad_fk_map1['state'] = 'name' bad_fk_map2 = copy(co_mapping) bad_fk_map2['state'] = {'nombre': 'State'} with self.assertRaises(TypeError): LayerMapping(County, co_shp, bad_fk_map1, transform=False) with self.assertRaises(LayerMapError): LayerMapping(County, co_shp, bad_fk_map2, transform=False)
lm = LayerMapping(County, co_shp, co_mapping, transform=False, unique='name') with self.assertRaises(MissingForeignKey): lm.save(silent=True, strict=True)
State.objects.bulk_create([ State(name='Colorado'), State(name='Hawaii'), State(name='Texas') ])
lm = LayerMapping(County, co_shp, co_mapping, transform=False, unique='name') lm.save(silent=True, strict=True)
lm = LayerMapping(CountyFeat, co_shp, cofeat_mapping, transform=False) lm.save(silent=True, strict=True)
self.county_helper()
def clear_counties(): County.objects.all().delete()
lm = LayerMapping(County, co_shp, co_mapping, transform=False, unique='name')
bad_ranges = (5.0, 'foo', co_shp) for bad in bad_ranges: with self.assertRaises(TypeError): lm.save(fid_range=bad)
qs = County.objects.all() self.assertEqual(1, qs.count()) self.assertEqual('Galveston', qs[0].name)
clear_counties()
qs = County.objects.order_by('name') self.assertEqual(2, qs.count()) hi, co = tuple(qs) hi_idx, co_idx = tuple(map(NAMES.index, ('Honolulu', 'Pueblo'))) self.assertEqual('Pueblo', co.name) self.assertEqual(NUMS[co_idx], len(co.mpoly)) self.assertEqual('Honolulu', hi.name) self.assertEqual(NUMS[hi_idx], len(hi.mpoly))
for st in (4, 7, 1000): clear_counties() lm.save(step=st, strict=True) self.county_helper(county_feat=False)
lm1 = LayerMapping(ICity1, city_shp, icity_mapping) lm1.save()
lm2 = LayerMapping(ICity2, city_shp, icity_mapping) lm2.save()
from __future__ import unicode_literals
@skipUnless( HAS_GEOIP2 and getattr(settings, "GEOIP_PATH", None), "GeoIP is required along with the GEOIP_PATH setting." ) class GeoIPTest(unittest.TestCase): addr = '128.249.1.1' fqdn = 'tmc.edu'
city = os.path.join(path, 'GeoLite2-City.mmdb') cntry = os.path.join(path, 'GeoLite2-Country.mmdb') g4 = GeoIP2(city, country='') self.assertIsNone(g4._country) g5 = GeoIP2(cntry, city='') self.assertIsNone(g5._city)
bad_params = (23, 'foo', 15.23) for bad in bad_params: with self.assertRaises(GeoIP2Exception): GeoIP2(cache=bad) if isinstance(bad, six.string_types): e = GeoIP2Exception else: e = TypeError with self.assertRaises(e): GeoIP2(bad, 0)
with self.assertRaises(GeoIP2Exception): cntry_g.city('tmc.edu') with self.assertRaises(GeoIP2Exception): cntry_g.coords('tmc.edu')
with self.assertRaises(TypeError): cntry_g.country_code(17) with self.assertRaises(TypeError): cntry_g.country_name(GeoIP2)
self.assertEqual( 'US', g.country_code(query), 'Failed for func country_code and query %s' % query ) self.assertEqual( 'United States', g.country_name(query), 'Failed for func country_name and query %s' % query ) self.assertEqual( {'country_code': 'US', 'country_name': 'United States'}, g.country(query) )
d = g.city(query) self.assertEqual('US', d['country_code']) self.assertEqual('Houston', d['city']) self.assertEqual('TX', d['region'])
self.assertIn(d['country_name'], ('Curaao', 'Curacao'))
shp_file = os.path.join(TEST_DATA, 'gas_lines', 'gas_leitung.shp') model_def = ogrinspect(shp_file, 'MyModel', multi_geom=True) self.assertIn('geom = models.MultiLineStringField(srid=-1)', model_def)
ogr_db = get_ogr_db_string() if not ogr_db: self.skipTest("Unable to setup an OGR connection to your database")
model_def = ogrinspect(ogr_db, 'Measurement', layer_key=AllOGRFields._meta.db_table, decimal=['f_decimal'])
self.assertIn(' f_decimal = models.DecimalField(max_digits=0, decimal_places=0)', model_def) self.assertIn(' f_int = models.IntegerField()', model_def) self.assertIn(' f_datetime = models.DateTimeField()', model_def) self.assertIn(' f_time = models.TimeField()', model_def) self.assertIn(' f_float = models.FloatField()', model_def) self.assertIn(' f_char = models.CharField(max_length=10)', model_def) self.assertIn(' f_date = models.DateField()', model_def)
self.assertIsNotNone(re.search(r' geom = models.PolygonField\(([^\)])*\)', model_def))
drivers = { 'django.contrib.gis.db.backends.postgis': ('PostgreSQL', "PG:dbname='%(db_name)s'", ' '), 'django.contrib.gis.db.backends.mysql': ('MySQL', 'MYSQL:"%(db_name)s"', ','), 'django.contrib.gis.db.backends.spatialite': ('SQLite', '%(db_name)s', '') }
try: Driver(drv_name) except GDALException: return None
if db['NAME'] == ":memory:": return None
params = [db_str % {'db_name': db['NAME']}]
if value: params.append(template % value)
class PennsylvaniaCity(City): county = models.CharField(max_length=30) founded = models.DateTimeField(null=True)
self.assertEqual(2, Country.objects.count()) self.assertEqual(8, City.objects.count()) self.assertEqual(2, State.objects.count())
pnt = Point(0, 0) nullcity = City(name='NullCity', point=pnt) nullcity.save()
for bad in [5, 2.0, LineString((0, 0), (1, 1))]: try: nullcity.point = bad except TypeError: pass else: self.fail('Should throw a TypeError')
new = Point(5, 23) nullcity.point = new
self.assertEqual(4326, nullcity.point.srid) nullcity.save()
self.assertEqual(new, City.objects.get(name='NullCity').point)
nullcity.point.x = 23 nullcity.point.y = 5 self.assertNotEqual(Point(23, 5), City.objects.get(name='NullCity').point) nullcity.save() self.assertEqual(Point(23, 5), City.objects.get(name='NullCity').point) nullcity.delete()
shell = LinearRing((0, 0), (0, 100), (100, 100), (100, 0), (0, 0)) inner = LinearRing((40, 40), (40, 60), (60, 60), (60, 40), (40, 40))
ply = Polygon(shell, inner) nullstate = State(name='NullState', poly=ply)
if gdal.HAS_GDAL: self.assertIsInstance(ns.poly.ogr, gdal.OGRGeometry) self.assertEqual(ns.poly.wkb, ns.poly.ogr.wkb) self.assertIsInstance(ns.poly.srs, gdal.SpatialReference) self.assertEqual('WGS 84', ns.poly.srs.name)
new_inner = LinearRing((30, 30), (30, 70), (70, 70), (70, 30), (30, 30)) ns.poly[1] = new_inner ply[1] = new_inner self.assertEqual(4326, ns.poly.srid) ns.save() self.assertEqual(ply, State.objects.get(name='NullState').poly) ns.delete()
sa_4326 = 'POINT (-98.493183 29.424170)'
if oracle: nad_wkt = 'POINT (300662.034646583 5416427.45974934)' nad_srid = 41157 else: nad_wkt = 'POINT (1645978.362408288754523 6276356.025927528738976)' nad_srid = 3084
nad_pnt = fromstr(nad_wkt, srid=nad_srid) if oracle: tx = Country.objects.get(mpoly__contains=nad_pnt) else: tx = Country.objects.get(mpoly__intersects=nad_pnt) self.assertEqual('Texas', tx.name)
sa = City.objects.create(name='San Antonio', point=nad_pnt)
sa = City.objects.get(name='San Antonio') self.assertAlmostEqual(wgs_pnt.x, sa.point.x, 6) self.assertAlmostEqual(wgs_pnt.y, sa.point.y, 6)
m1 = MinusOneSRID(geom=Point(17, 23, srid=4326)) m1.save() self.assertEqual(-1, m1.geom.srid)
PennsylvaniaCity.objects.create(name='Mansfield', county='Tioga', point='POINT(-77.071445 41.823881)')
qs = PennsylvaniaCity.objects.transform(32128)
as_text = 'ST_AsText(%s)' if postgis else connection.ops.select cities2 = City.objects.raw( 'select id, name, %s from geoapp_city' % as_text % 'point' ) self.assertEqual(len(cities1), len(list(cities2))) self.assertIsInstance(cities2[0].point, Point)
with tempfile.NamedTemporaryFile(mode='w', suffix='.json') as tmp: tmp.write(result) tmp.seek(0) call_command('loaddata', tmp.name, verbosity=0) self.assertListEqual(original_data, list(City.objects.all().order_by('name')))
texas = Country.objects.get(name='Texas')
if connection.features.supports_contained_lookup: qs = City.objects.filter(point__contained=texas.mpoly) self.assertEqual(3, qs.count()) cities = ['Houston', 'Dallas', 'Oklahoma City'] for c in qs: self.assertIn(c.name, cities)
houston = City.objects.get(name='Houston') wellington = City.objects.get(name='Wellington') pueblo = City.objects.get(name='Pueblo') okcity = City.objects.get(name='Oklahoma City') lawrence = City.objects.get(name='Lawrence')
ks = State.objects.get(poly__contains=lawrence.point) self.assertEqual('Kansas', ks.name)
if connection.features.supports_bbcontains_lookup: qs = Country.objects.filter(mpoly__bbcontains=okcity.point) self.assertEqual(1, len(qs)) self.assertEqual('Texas', qs[0].name)
co_border = State.objects.get(name='Colorado').poly ks_border = State.objects.get(name='Kansas').poly
cities = ['Houston', 'Dallas', 'Oklahoma City', 'Lawrence', 'Chicago', 'Wellington'] qs = City.objects.filter(point__right=co_border) self.assertEqual(6, len(qs)) for c in qs: self.assertIn(c.name, cities)
cities = ['Chicago', 'Wellington'] qs = City.objects.filter(point__right=ks_border) self.assertEqual(2, len(qs)) for c in qs: self.assertIn(c.name, cities)
vic = City.objects.get(point__left=co_border) self.assertEqual('Victoria', vic.name)
State.objects.create(name='Puerto Rico')
nullqs = State.objects.filter(poly__isnull=True) validqs = State.objects.filter(poly__isnull=False)
self.assertEqual(1, len(nullqs)) self.assertEqual('Puerto Rico', nullqs[0].name)
self.assertEqual(2, len(validqs)) state_names = [s.name for s in validqs] self.assertIn('Colorado', state_names) self.assertIn('Kansas', state_names)
nmi = State.objects.create(name='Northern Mariana Islands', poly=None) self.assertEqual(nmi.poly, None)
nmi.poly = 'POLYGON((0 0,1 0,1 1,1 0,0 0))' nmi.save() State.objects.filter(name='Northern Mariana Islands').update(poly=None) self.assertIsNone(State.objects.get(name='Northern Mariana Islands').poly)
pnt1 = fromstr('POINT (649287.0363174 4177429.4494686)', srid=2847) pnt2 = fromstr('POINT(-98.4919715741052 29.4333344025053)', srid=4326)
with self.assertRaises(ValueError): Country.objects.filter(mpoly__relate=(23, 'foo'))
for bad_args, e in [((pnt1, 0), ValueError), ((pnt2, 'T*T***FF*', 0), ValueError)]: qs = Country.objects.filter(mpoly__relate=bad_args) with self.assertRaises(e): qs.count()
if postgis or spatialite: contains_mask = 'T*T***FF*' within_mask = 'T*F**F***' intersects_mask = 'T********' elif oracle: contains_mask = 'contains' within_mask = 'inside' intersects_mask = 'overlapbdyintersect'
self.assertEqual('Texas', Country.objects.get(mpoly__relate=(pnt1, contains_mask)).name) self.assertEqual('Texas', Country.objects.get(mpoly__relate=(pnt2, contains_mask)).name)
ks = State.objects.get(name='Kansas') self.assertEqual('Lawrence', City.objects.get(point__relate=(ks.poly, within_mask)).name)
if not oracle: self.assertEqual('Texas', Country.objects.get(mpoly__relate=(pnt1, intersects_mask)).name) self.assertEqual('Texas', Country.objects.get(mpoly__relate=(pnt2, intersects_mask)).name) self.assertEqual('Lawrence', City.objects.get(point__relate=(ks.poly, intersects_mask)).name)
if spatialite: qs = qs.exclude(name='Texas') else: qs = qs.intersection(geom)
pass
self.assertSetEqual(set(g.wkt for g in c.mpoly.sym_difference(geom)), set(g.wkt for g in c.sym_difference)) self.assertSetEqual(set(g.wkt for g in c.mpoly.union(geom)), set(g.wkt for g in c.union))
expected = (-96.8016128540039, 29.7633724212646, -95.3631439208984, 32.782058715820)
ref_hash = '9vk1mfq8jx0c8e0386z6' h1 = City.objects.geohash().get(name='Houston') h2 = City.objects.geohash(precision=5).get(name='Houston') self.assertEqual(ref_hash, h1.geohash) self.assertEqual(ref_hash[:5], h2.geohash)
if not connection.ops.geojson: with self.assertRaises(NotImplementedError): Country.objects.all().geojson(field_name='mpoly') return
with self.assertRaises(TypeError): City.objects.geojson(precision='foo')
self.assertEqual(pueblo_json, City.objects.geojson().get(name='Pueblo').geojson)
self.assertEqual(houston_json, City.objects.geojson(crs=True, model_att='json').get(name='Houston').json)
self.assertEqual(victoria_json, City.objects.geojson(bbox=True).get(name='Victoria').geojson)
self.assertEqual( chicago_json, City.objects.geojson(bbox=True, crs=True, precision=5).get(name='Chicago').geojson )
qs = City.objects.all() with self.assertRaises(TypeError): qs.gml(field_name='name') ptown1 = City.objects.gml(field_name='point', precision=9).get(name='Pueblo') ptown2 = City.objects.gml(precision=9).get(name='Pueblo')
gml_regex = re.compile( r'^<gml:Point srsName="EPSG:4326" xmlns:gml="http://www.opengis.net/gml">' r'<gml:coordinates decimal="\." cs="," ts=" ">-104.60925\d+,38.25500\d+ ' r'</gml:coordinates></gml:Point>' )
qs = City.objects.all() with self.assertRaises(TypeError): qs.kml('name')
ptown1 = City.objects.kml(field_name='point', precision=9).get(name='Pueblo') ptown2 = City.objects.kml(precision=9).get(name='Pueblo') for ptown in [ptown1, ptown2]: self.assertEqual('<Point><coordinates>-104.609252,38.255001</coordinates></Point>', ptown.kml)
self.assertIsNone(State.objects.aggregate(MakeLine('poly'))['poly__makeline']) ref_line = GEOSGeometry( 'LINESTRING(-95.363151 29.763374,-96.801611 32.782057,' '-97.521157 34.464642,174.783117 -41.315268,-104.609252 38.255001,' '-95.23506 38.971823,-87.650175 41.850385,-123.305196 48.462611)', srid=4326 ) line = City.objects.aggregate(MakeLine('point'))['point__makeline'] self.assertTrue( ref_line.equals_exact(line, tolerance=10e-5), "%s != %s" % (ref_line, line) )
for c in Country.objects.num_geom(): self.assertEqual(2, c.num_geom)
self.assertEqual(1, c.num_geom)
for c in City.objects.num_points(): self.assertEqual(1, c.num_points)
if oracle: ref = {'New Zealand': fromstr('POINT (174.616364 -36.100861)', srid=4326), 'Texas': fromstr('POINT (-103.002434 36.500397)', srid=4326), }
ref = {'New Zealand': Country.objects.get(name='New Zealand').mpoly.point_on_surface, 'Texas': Country.objects.get(name='Texas').mpoly.point_on_surface }
tol = 0.00001
for bad_args in ((), range(3), range(5)): with self.assertRaises(ValueError): Country.objects.snap_to_grid(*bad_args) for bad_args in (('1.0',), (1.0, None), tuple(map(six.text_type, range(4)))): with self.assertRaises(TypeError): Country.objects.snap_to_grid(*bad_args)
wkt = ('MULTIPOLYGON(((12.41580 43.95795,12.45055 43.97972,12.45389 43.98167,' '12.46250 43.98472,12.47167 43.98694,12.49278 43.98917,' '12.50555 43.98861,12.51000 43.98694,12.51028 43.98277,' '12.51167 43.94333,12.51056 43.93916,12.49639 43.92333,' '12.49500 43.91472,12.48778 43.90583,12.47444 43.89722,' '12.46472 43.89555,12.45917 43.89611,12.41639 43.90472,' '12.41222 43.90610,12.40782 43.91366,12.40389 43.92667,' '12.40500 43.94833,12.40889 43.95499,12.41580 43.95795)))') Country.objects.create(name='San Marino', mpoly=fromstr(wkt))
tol = 0.000000001
ref = fromstr('MULTIPOLYGON(((12.4 44,12.5 44,12.5 43.9,12.4 43.9,12.4 44)))') self.assertTrue(ref.equals_exact(Country.objects.snap_to_grid(0.1).get(name='San Marino').snap_to_grid, tol))
ref = fromstr('MULTIPOLYGON(((12.4 43.93,12.45 43.93,12.5 43.93,12.45 43.93,12.4 43.93)))') self.assertTrue( ref.equals_exact(Country.objects.snap_to_grid(0.05, 0.23).get(name='San Marino').snap_to_grid, tol) )
ref = fromstr( 'MULTIPOLYGON(((12.4 43.87,12.45 43.87,12.45 44.1,12.5 44.1,12.5 43.87,12.45 43.87,12.4 43.87)))' ) self.assertTrue( ref.equals_exact( Country.objects.snap_to_grid(0.05, 0.23, 0.5, 0.17).get(name='San Marino').snap_to_grid, tol ) )
svg1 = 'cx="-104.609252" cy="-38.255001"' svg2 = svg1.replace('c', '') self.assertEqual(svg1, City.objects.svg().get(name='Pueblo').svg) self.assertEqual(svg2, City.objects.svg(relative=5).get(name='Pueblo').svg)
htown = fromstr('POINT(1947516.83115183 6322297.06040572)', srid=3084) ptown = fromstr('POINT(992363.390841912 481455.395105533)', srid=2774)
if not oracle: h = City.objects.transform(htown.srid).get(name='Houston') self.assertEqual(3084, h.point.srid) self.assertAlmostEqual(htown.x, h.point.x, prec) self.assertAlmostEqual(htown.y, h.point.y, prec)
self.assertAlmostEqual(c1[0] + xfac, c2[0], 5) self.assertAlmostEqual(c1[1] + yfac, c2[1], 5)
union1 = fromstr('MULTIPOINT(-96.801611 32.782057,-95.363151 29.763374)') union2 = fromstr('MULTIPOINT(-95.363151 29.763374,-96.801611 32.782057)') qs = City.objects.filter(point__within=tx) with self.assertRaises(ValueError): qs.aggregate(Union('name')) u1 = qs.aggregate(Union('point'))['point__union'] u2 = qs.order_by('name').aggregate(Union('point'))['point__union'] tol = 0.00001 self.assertTrue(union1.equals_exact(u1, tol) or union2.equals_exact(u1, tol)) self.assertTrue(union1.equals_exact(u2, tol) or union2.equals_exact(u2, tol)) qs = City.objects.filter(name='NotACity') self.assertIsNone(qs.aggregate(Union('point'))['point__union'])
doc1 = minidom.parseString(self.client.get('/feeds/rss1/').content) doc2 = minidom.parseString(self.client.get('/feeds/rss2/').content) feed1, feed2 = doc1.firstChild, doc2.firstChild
self.assertChildNodes(feed2.getElementsByTagName('channel')[0], ['title', 'link', 'description', 'language', 'lastBuildDate', 'item', 'georss:box', 'atom:link'] )
for feed in [feed1, feed2]: self.assertEqual(feed.getAttribute('xmlns:georss'), 'http://www.georss.org/georss') chan = feed.getElementsByTagName('channel')[0] items = chan.getElementsByTagName('item') self.assertEqual(len(items), City.objects.count())
for item in items: self.assertChildNodes(item, ['title', 'link', 'description', 'guid', 'georss:point'])
self.assertChildNodes(feed2, ['title', 'link', 'id', 'updated', 'entry', 'georss:box'])
self.assertEqual(feed.getAttribute('xmlns:georss'), 'http://www.georss.org/georss') entries = feed.getElementsByTagName('entry') self.assertEqual(len(entries), City.objects.count())
for entry in entries: self.assertChildNodes(entry, ['title', 'link', 'id', 'summary', 'georss:point'])
self.assertEqual(feed.getAttribute('xmlns:geo'), 'http://www.w3.org/2003/01/geo/wgs84_pos#') chan = feed.getElementsByTagName('channel')[0] items = chan.getElementsByTagName('item') self.assertEqual(len(items), City.objects.count())
for item in items: self.assertChildNodes(item, ['title', 'link', 'description', 'guid', 'geo:lat', 'geo:lon'])
geojson = serializers.serialize( 'geojson', MultiFields.objects.all(), geometry_field='poly', fields=('city',) ) geodata = json.loads(geojson) self.assertEqual(geodata['features'][0]['geometry']['type'], 'Polygon')
serializers.serialize('geojson', City.objects.all()) with six.assertRaisesRegex(self, serializers.base.SerializationError, '.*GDAL is not installed'): serializers.serialize('geojson', City.objects.all(), srid=2847)
from __future__ import unicode_literals
pueblo = City.objects.get(name='Pueblo') state = State.objects.filter(poly__contains=pueblo.point) cities_within_state = City.objects.filter(id__in=state)
self.assertEqual(cities_within_state.count(), 1)
@no_oracle def test_defer_or_only_with_annotate(self): "Regression for #16409. Make sure defer() and only() work with annotate()" self.assertIsInstance(list(City.objects.annotate(Count('point')).defer('name')), list) self.assertIsInstance(list(City.objects.annotate(Count('point')).only('name')), list)
self.assertIsInstance(val1, bool) self.assertIsInstance(val2, bool) self.assertEqual(val1, True) self.assertEqual(val2, False)
if not connection.ops.geojson: with self.assertRaises(NotImplementedError): list(Country.objects.annotate(json=functions.AsGeoJSON('mpoly'))) return
with self.assertRaises(TypeError): City.objects.annotate(geojson=functions.AsGeoJSON('point', precision='foo'))
self.assertEqual( pueblo_json, City.objects.annotate(geojson=functions.AsGeoJSON('point')).get(name='Pueblo').geojson )
self.assertEqual( houston_json, City.objects.annotate(json=functions.AsGeoJSON('point', crs=True)).get(name='Houston').json )
self.assertEqual( victoria_json, City.objects.annotate( geojson=functions.AsGeoJSON('point', bbox=True) ).get(name='Victoria').geojson )
self.assertEqual( chicago_json, City.objects.annotate( geojson=functions.AsGeoJSON('point', bbox=True, crs=True, precision=5) ).get(name='Chicago').geojson )
qs = City.objects.all() with self.assertRaises(TypeError): qs.annotate(gml=functions.AsGML('name')) ptown = City.objects.annotate(gml=functions.AsGML('point', precision=9)).get(name='Pueblo')
gml_regex = re.compile( r'^<gml:Point srsName="SDO:4326" xmlns:gml="http://www.opengis.net/gml">' r'<gml:coordinates decimal="\." cs="," ts=" ">-104.60925\d+,38.25500\d+ ' r'</gml:coordinates></gml:Point>' )
with self.assertRaises(TypeError): City.objects.annotate(kml=functions.AsKML('name'))
ptown = City.objects.annotate(kml=functions.AsKML('point', precision=9)).get(name='Pueblo') self.assertEqual('<Point><coordinates>-104.609252,38.255001</coordinates></Point>', ptown.kml)
svg1 = 'cx="-104.609252" cy="-38.255001"' svg2 = svg1.replace('c', '') self.assertEqual(svg1, City.objects.annotate(svg=functions.AsSVG('point')).get(name='Pueblo').svg) self.assertEqual(svg2, City.objects.annotate(svg=functions.AsSVG('point', relative=5)).get(name='Pueblo').svg)
if spatialite or oracle: qs = qs.exclude(name='Texas')
if spatialite or oracle: qs = qs.exclude(name='Texas') for c in qs: self.assertTrue(c.mpoly.difference(geom).equals(c.difference))
ref_hash = '9vk1mfq8jx0c8e0386z6' h1 = City.objects.annotate(geohash=functions.GeoHash('point')).get(name='Houston') h2 = City.objects.annotate(geohash=functions.GeoHash('point', precision=5)).get(name='Houston') self.assertEqual(ref_hash, h1.geohash) self.assertEqual(ref_hash[:5], h2.geohash)
expected = None
expected = ''
for c in Country.objects.all(): CountryWebMercator.objects.create(name=c.name, mpoly=c.mpoly) qs = CountryWebMercator.objects.annotate(area_sum=Sum(functions.Area('mpoly'))) for c in qs.defer('mpoly'): result = c.area_sum if isinstance(result, Area): result = result.sq_m self.assertAlmostEqual((result - c.mpoly.area) / c.mpoly.area, 0)
for c in Country.objects.annotate(num_geom=functions.NumGeometries('mpoly')): self.assertEqual(2, c.num_geom)
if mysql: self.assertIsNone(city.num_geom) else: self.assertEqual(1, city.num_geom)
return
for c in City.objects.annotate(num_points=functions.NumPoints('point')): self.assertEqual(1, c.num_points)
if oracle: ref = {'New Zealand': fromstr('POINT (174.616364 -36.100861)', srid=4326), 'Texas': fromstr('POINT (-103.002434 36.500397)', srid=4326), } else: ref = {'New Zealand': Country.objects.get(name='New Zealand').mpoly.point_on_surface, 'Texas': Country.objects.get(name='Texas').mpoly.point_on_surface }
qs = Country.objects.annotate(scaled=functions.Scale('mpoly', 1.5, Decimal('2.5'))) self.assertGreater(qs[0].scaled.area, qs[0].mpoly.area)
for bad_args in ((), range(3), range(5)): with self.assertRaises(ValueError): Country.objects.annotate(snap=functions.SnapToGrid('mpoly', *bad_args)) for bad_args in (('1.0',), (1.0, None), tuple(map(six.text_type, range(4)))): with self.assertRaises(TypeError): Country.objects.annotate(snap=functions.SnapToGrid('mpoly', *bad_args))
wkt = ('MULTIPOLYGON(((12.41580 43.95795,12.45055 43.97972,12.45389 43.98167,' '12.46250 43.98472,12.47167 43.98694,12.49278 43.98917,' '12.50555 43.98861,12.51000 43.98694,12.51028 43.98277,' '12.51167 43.94333,12.51056 43.93916,12.49639 43.92333,' '12.49500 43.91472,12.48778 43.90583,12.47444 43.89722,' '12.46472 43.89555,12.45917 43.89611,12.41639 43.90472,' '12.41222 43.90610,12.40782 43.91366,12.40389 43.92667,' '12.40500 43.94833,12.40889 43.95499,12.41580 43.95795)))') Country.objects.create(name='San Marino', mpoly=fromstr(wkt))
tol = 0.000000001
ref = fromstr('MULTIPOLYGON(((12.4 44,12.5 44,12.5 43.9,12.4 43.9,12.4 44)))') self.assertTrue( ref.equals_exact( Country.objects.annotate( snap=functions.SnapToGrid('mpoly', 0.1) ).get(name='San Marino').snap, tol ) )
ref = fromstr('MULTIPOLYGON(((12.4 43.93,12.45 43.93,12.5 43.93,12.45 43.93,12.4 43.93)))') self.assertTrue( ref.equals_exact( Country.objects.annotate( snap=functions.SnapToGrid('mpoly', 0.05, 0.23) ).get(name='San Marino').snap, tol ) )
ref = fromstr( 'MULTIPOLYGON(((12.4 43.87,12.45 43.87,12.45 44.1,12.5 44.1,12.5 43.87,12.45 43.87,12.4 43.87)))' ) self.assertTrue( ref.equals_exact( Country.objects.annotate( snap=functions.SnapToGrid('mpoly', 0.05, 0.23, 0.5, 0.17) ).get(name='San Marino').snap, tol ) )
if oracle: qs = qs.exclude(name='Texas') for country in qs: self.assertTrue(country.mpoly.sym_difference(geom).equals(country.sym_difference))
ptown = fromstr('POINT(992363.390841912 481455.395105533)', srid=2774)
h = City.objects.annotate(pt=functions.Transform('point', ptown.srid)).get(name='Pueblo') self.assertEqual(2774, h.pt.srid) self.assertAlmostEqual(ptown.x, h.pt.x, prec) self.assertAlmostEqual(ptown.y, h.pt.y, prec)
self.assertAlmostEqual(c1[0] + xfac, c2[0], 5) self.assertAlmostEqual(c1[1] + yfac, c2[1], 5)
@skipUnlessDBFeature( "has_Difference_function", "has_Intersection_function", "has_SymDifference_function", "has_Union_function") def test_diff_intersection_union(self): "Testing the `difference`, `intersection`, `sym_difference`, and `union` GeoQuerySet methods." geom = Point(5, 23, srid=4326) qs = Country.objects.all().annotate( difference=functions.Difference('mpoly', geom), sym_difference=functions.SymDifference('mpoly', geom), union=functions.Union('mpoly', geom), )
if spatialite: qs = qs.exclude(name='Texas') else: qs = qs.annotate(intersection=functions.Intersection('mpoly', geom))
return
expected1 = fromstr('MULTIPOINT(-96.801611 32.782057,-95.363151 29.763374)', srid=4326) expected2 = fromstr('MULTIPOINT(-95.363151 29.763374,-96.801611 32.782057)', srid=4326) self.assertTrue(expected1.equals_exact(ptown.union, tol) or expected2.equals_exact(ptown.union, tol))
return (-123.30, -41.32, 174.78, 48.46)
return item.point.x, item.point.y
return ((-123.30, -41.32), (174.78, 48.46))
class TestW3CGeo2(TestGeoRSS2): feed_type = feeds.W3CGeoFeed
feed_dict = { 'rss1': TestGeoRSS1, 'rss2': TestGeoRSS2, 'atom1': TestGeoAtom1, 'atom2': TestGeoAtom2, 'w3cgeo1': TestW3CGeo1, 'w3cgeo2': TestW3CGeo2, 'w3cgeo3': TestW3CGeo3, }
urlset = doc.firstChild self.assertEqual(urlset.getAttribute('xmlns'), 'http://www.sitemaps.org/schemas/sitemap/0.9')
kml_url = url.getElementsByTagName('loc')[0].childNodes[0].data.split('http://example.com')[1]
buf = BytesIO(self.client.get(kml_url).content) with zipfile.ZipFile(buf) as zf: self.assertEqual(1, len(zf.filelist)) self.assertEqual('doc.kml', zf.filelist[0].filename) kml_doc = minidom.parseString(zf.read('doc.kml'))
if 'city' in kml_url: model = City elif 'country' in kml_url: model = Country self.assertEqual(model.objects.count(), len(kml_doc.getElementsByTagName('Placemark')))
from __future__ import unicode_literals
ErrClass = socket.error if six.PY2 else OSError try: socket.gethostbyname(domain) return True except ErrClass: return False
city = os.path.join(path, 'GeoLiteCity.dat') cntry = os.path.join(path, 'GeoIP.dat') g4 = GeoIP(city, country='') self.assertIsNone(g4._country) g5 = GeoIP(cntry, city='') self.assertIsNone(g5._city)
bad_params = (23, 'foo', 15.23) for bad in bad_params: with self.assertRaises(GeoIPException): GeoIP(cache=bad) if isinstance(bad, six.string_types): e = GeoIPException else: e = TypeError with self.assertRaises(e): GeoIP(bad, 0)
with self.assertRaises(GeoIPException): cntry_g.city('google.com') with self.assertRaises(GeoIPException): cntry_g.coords('yahoo.com')
with self.assertRaises(TypeError): cntry_g.country_code(17) with self.assertRaises(TypeError): cntry_g.country_name(GeoIP)
for func in (g.country_code, g.country_code_by_addr, g.country_code_by_name): self.assertEqual('US', func(query)) for func in (g.country_name, g.country_name_by_addr, g.country_name_by_name): self.assertEqual('United States', func(query)) self.assertEqual({'country_code': 'US', 'country_name': 'United States'}, g.country(query))
d = g.city(query) self.assertEqual('USA', d['country_code3']) self.assertEqual('Houston', d['city']) self.assertEqual('TX', d['region']) self.assertEqual(713, d['area_code']) geom = g.geos(query) self.assertIsInstance(geom, GEOSGeometry) lon, lat = (-95.4010, 29.7079) lat_lon = g.lat_lon(query) lat_lon = (lat_lon[1], lat_lon[0]) for tup in (geom.tuple, g.coords(query), g.lon_lat(query), lat_lon): self.assertAlmostEqual(lon, tup[0], 4) self.assertAlmostEqual(lat, tup[1], 4)
self.assertIn(d['country_name'], ('Curaao', 'Curacao'))
from __future__ import unicode_literals
itemList = ['x'] * length for i, v in enumerate(items): itemList[i] = v
ul_longer = ul + [2] ul_longer._IndexError = TypeError ul._IndexError = TypeError self.assertNotEqual(ul_longer, pl) self.assertGreater(ul_longer, ul)
wkt_r = WKTReader() wkt = 'POINT (5 23)'
ref = GEOSGeometry(wkt) g1 = wkt_r.read(wkt.encode()) g2 = wkt_r.read(wkt)
with self.assertRaises(TypeError): wkt_r.read(1) with self.assertRaises(TypeError): wkt_r.read(memoryview(b'foo'))
wkt_w = WKTWriter() with self.assertRaises(TypeError): wkt_w._set_ptr(WKTReader.ptr_type())
wkb_r = WKBReader()
g1 = wkb_r.read(wkb) g2 = wkb_r.read(hex) for geom in (g1, g2): self.assertEqual(ref, geom)
g = GEOSGeometry('POINT (5 23)') hex1 = b'010100000000000000000014400000000000003740' wkb1 = memoryview(binascii.a2b_hex(hex1)) hex2 = b'000000000140140000000000004037000000000000' wkb2 = memoryview(binascii.a2b_hex(hex2))
for bad_byteorder in (-1, 2, 523, 'foo', None): with self.assertRaises(ValueError): wkb_w._set_byteorder(bad_byteorder)
wkb_w.byteorder = 0 self.assertEqual(hex2, wkb_w.write_hex(g)) self.assertEqual(wkb2, wkb_w.write(g))
wkb_w.byteorder = 1
g = GEOSGeometry('POINT (5 23 17)') g.srid = 4326
for bad_outdim in (-1, 0, 1, 4, 423, 'foo', None): with self.assertRaisesMessage(ValueError, 'WKB output dimension must be 2 or 3'): wkb_w.outdim = bad_outdim
wkb_w.outdim = 3
wkb_w.srid = True self.assertEqual(hex3d_srid, wkb_w.write_hex(g)) self.assertEqual(wkb3d_srid, wkb_w.write(g))
class FakeGeom1(GEOSBase): pass
c_float_p = ctypes.POINTER(ctypes.c_float)
fg1 = FakeGeom1() fg2 = FakeGeom2()
fg1.ptr = ctypes.c_void_p() fg1.ptr = None fg2.ptr = c_float_p(ctypes.c_float(5.23)) fg2.ptr = None
for fg in (fg1, fg2): with self.assertRaises(GEOSException): fg._get_ptr()
bad_ptrs = (5, ctypes.c_char_p(b'foobar')) for bad_ptr in bad_ptrs: with self.assertRaises(TypeError): fg1._set_ptr(bad_ptr) with self.assertRaises(TypeError): fg2._set_ptr(bad_ptr)
ogc_hex = b'01010000000000000000000000000000000000F03F' ogc_hex_3d = b'01010000800000000000000000000000000000F03F0000000000000040' hexewkb_2d = b'0101000020E61000000000000000000000000000000000F03F' hexewkb_3d = b'01010000A0E61000000000000000000000000000000000F03F0000000000000040'
self.assertEqual(ogc_hex, pnt_2d.hex) self.assertEqual(ogc_hex_3d, pnt_3d.hex)
self.assertEqual(hexewkb_2d, pnt_2d.hexewkb) self.assertEqual(hexewkb_3d, pnt_3d.hexewkb) self.assertEqual(True, GEOSGeometry(hexewkb_3d).hasz)
self.assertEqual(six.memoryview(a2b_hex(hexewkb_2d)), pnt_2d.ewkb) self.assertEqual(six.memoryview(a2b_hex(hexewkb_3d)), pnt_3d.ewkb)
self.assertEqual(4326, GEOSGeometry(hexewkb_2d).srid)
for err in self.geometries.errors: with self.assertRaises((GEOSException, ValueError)): fromstr(err.wkt)
with self.assertRaises(GEOSException): GEOSGeometry(six.memoryview(b'0'))
with self.assertRaises(TypeError): GEOSGeometry(NotAGeometry()) with self.assertRaises(TypeError): GEOSGeometry(None)
geom_t = fromstr(g.wkt) self.assertEqual(geom_t.wkt, geom_h.wkt)
geom_t = fromstr(g.wkt) self.assertEqual(geom_t.wkt, geom_h.wkt)
self.assertEqual(json.loads(g.json), json.loads(geom.json)) self.assertEqual(json.loads(g.json), json.loads(geom.geojson))
for fh in (wkt_f, wkb_f): fh.seek(0) pnt = fromfile(fh) self.assertEqual(ref_pnt, pnt)
for g in (p, ls): self.assertNotEqual(g, None) self.assertNotEqual(g, {'foo': 'bar'}) self.assertNotEqual(g, False)
pnt = fromstr(p.wkt) self.assertEqual(pnt.geom_type, 'Point') self.assertEqual(pnt.geom_typeid, 0) self.assertEqual(pnt.dims, 0) self.assertEqual(p.x, pnt.x) self.assertEqual(p.y, pnt.y) self.assertEqual(pnt, fromstr(p.wkt))
self.assertAlmostEqual(p.x, pnt.tuple[0], 9) self.assertAlmostEqual(p.y, pnt.tuple[1], 9)
if hasattr(p, 'z'): self.assertEqual(True, pnt.hasz) self.assertEqual(p.z, pnt.z) self.assertEqual(p.z, pnt.tuple[2], 9) tup_args = (p.x, p.y, p.z) set_tup1 = (2.71, 3.14, 5.23) set_tup2 = (5.23, 2.71, 3.14) else: self.assertEqual(False, pnt.hasz) self.assertIsNone(pnt.z) tup_args = (p.x, p.y) set_tup1 = (2.71, 3.14) set_tup2 = (3.14, 2.71)
self.assertEqual(p.centroid, pnt.centroid.tuple)
pnt.y = 3.14 pnt.x = 2.71 self.assertEqual(3.14, pnt.y) self.assertEqual(2.71, pnt.x)
pnt.tuple = set_tup1 self.assertEqual(set_tup1, pnt.tuple) pnt.coords = set_tup2 self.assertEqual(set_tup2, pnt.coords)
self.assertEqual(ls.wkt, LineString(*tuple(Point(tup) for tup in ls.tuple)).wkt) if numpy:
self.assertEqual(lr, LinearRing(lr.tuple)) self.assertEqual(lr, LinearRing(*lr.tuple)) self.assertEqual(lr, LinearRing([list(tup) for tup in lr.tuple])) if numpy: self.assertEqual(lr, LinearRing(numpy.array(lr.tuple)))
x = 3.14159265358979323 bbox = (0, 0, 1, x) p = Polygon.from_bbox(bbox) y = p.extent[-1] self.assertEqual(format(x, '.13f'), format(y, '.13f'))
poly = fromstr(p.wkt) self.assertEqual(poly.geom_type, 'Polygon') self.assertEqual(poly.geom_typeid, 3) self.assertEqual(poly.dims, 2) self.assertEqual(poly.empty, False) self.assertEqual(poly.ring, False) self.assertEqual(p.n_i, poly.num_interior_rings)
self.assertAlmostEqual(p.area, poly.area, 9) self.assertAlmostEqual(p.centroid[0], poly.centroid.tuple[0], 9) self.assertAlmostEqual(p.centroid[1], poly.centroid.tuple[1], 9)
self.assertEqual(poly, fromstr(p.wkt))
ring = poly.exterior_ring self.assertEqual(ring.geom_type, 'LinearRing') self.assertEqual(ring.geom_typeid, 2) if p.ext_ring_cs: self.assertEqual(p.ext_ring_cs, ring.tuple)
with self.assertRaises(IndexError): poly.__getitem__(len(poly)) with self.assertRaises(IndexError): poly.__setitem__(len(poly), False) with self.assertRaises(IndexError): poly.__getitem__(-1 * len(poly) - 1)
for r in poly: self.assertEqual(r.geom_type, 'LinearRing') self.assertEqual(r.geom_typeid, 2)
with self.assertRaises(TypeError): Polygon(0, [1, 2, 3]) with self.assertRaises(TypeError): Polygon('foo')
rings = tuple(r for r in poly) self.assertEqual(poly, Polygon(rings[0], rings[1:]))
ring_tuples = tuple(r.tuple for r in poly) self.assertEqual(poly, Polygon(*ring_tuples))
self.assertEqual(poly.wkt, Polygon(*tuple(r for r in poly)).wkt) self.assertEqual(poly.wkt, Polygon(*tuple(LinearRing(r.tuple) for r in poly)).wkt)
engine = Engine() template = engine.from_string('{{ polygons.0.wkt }}') polygons = [fromstr(p.wkt) for p in self.geometries.multipolygons[:2]] content = template.render(Context({'polygons': polygons})) self.assertIn('MULTIPOLYGON (((100', content)
poly = fromstr(self.geometries.polygons[1].wkt) ring1 = poly[0] ring2 = poly[1]
del ring1 del ring2 ring1 = poly[0] ring2 = poly[1]
del poly
str(ring1) str(ring2)
poly = fromstr(p.wkt) cs = poly.exterior_ring.coord_seq
for i in range(len(p.ext_ring_cs)):
if len(c1) == 2: tset = (5, 23) else: tset = (5, 23, 8) cs[i] = tset
for j in range(len(tset)): cs[i] = tset self.assertEqual(tset[j], cs[i][j])
exp_buf = fromstr(bg.buffer_wkt) quadsegs = bg.quadsegs width = bg.width
with self.assertRaises(ctypes.ArgumentError): g.buffer(width, float(quadsegs))
buf = g.buffer(width, quadsegs) self.assertEqual(exp_buf.num_coords, buf.num_coords) self.assertEqual(len(exp_buf), len(buf))
for j in range(len(exp_buf)): exp_ring = exp_buf[j] buf_ring = buf[j] self.assertEqual(len(exp_ring), len(buf_ring)) for k in range(len(exp_ring)): self.assertAlmostEqual(exp_ring[k][0], buf_ring[k][0], 9) self.assertAlmostEqual(exp_ring[k][1], buf_ring[k][1], 9)
pnt = Point(5, 23, srid=4326) self.assertEqual(4326, pnt.srid) pnt.srid = 3084 self.assertEqual(3084, pnt.srid) with self.assertRaises(ctypes.ArgumentError): pnt.srid = '4326'
poly = fromstr(self.geometries.polygons[1].wkt, srid=4269) self.assertEqual(4269, poly.srid) for ring in poly: self.assertEqual(4269, ring.srid) poly.srid = 4326 self.assertEqual(4326, poly.shell.srid)
gc = GeometryCollection(Point(5, 23), LineString((0, 0), (1.5, 1.5), (3, 3)), srid=32021) self.assertEqual(32021, gc.srid) for i in range(len(gc)): self.assertEqual(32021, gc[i].srid)
hex = '0101000020E610000000000000000014400000000000003740' p1 = fromstr(hex) self.assertEqual(4326, p1.srid)
pnt_wo_srid = Point(1, 1) pnt_wo_srid.srid = pnt_wo_srid.srid
c2w = gdal.CoordTransform( gdal.SpatialReference( '+proj=mill +lat_0=0 +lon_0=0 +x_0=0 +y_0=0 +R_A +ellps=WGS84 ' '+datum=WGS84 +units=m +no_defs' ), gdal.SpatialReference(4326)) new_pnt = pnt.transform(c2w, clone=True) self.assertEqual(new_pnt.srid, 4326) self.assertAlmostEqual(new_pnt.x, 1, 3) self.assertAlmostEqual(new_pnt.y, 2, 3)
for p in self.geometries.polygons: poly = fromstr(p.wkt)
with self.assertRaises(TypeError): poly.__setitem__(0, LineString((1, 1), (2, 2)))
shell_tup = poly.shell.tuple new_coords = [] for point in shell_tup: new_coords.append((point[0] + 500., point[1] + 500.)) new_shell = LinearRing(*tuple(new_coords))
poly.exterior_ring = new_shell
for tg in self.geometries.multipoints: mp = fromstr(tg.wkt) for i in range(len(mp)): pnt = mp[i] new = Point(random.randint(21, 100), random.randint(21, 100)) mp[i] = new
for tg in self.geometries.multipolygons: mpoly = fromstr(tg.wkt) for i in range(len(mpoly)): poly = mpoly[i] old_poly = mpoly[i] for j in range(len(poly)): r = poly[j] for k in range(len(r)): r[k] = (r[k][0] + 500., r[k][1] + 500.) poly[j] = r
mpoly[i] = poly
pnt = Point(2, 3, 8) self.assertEqual((2., 3., 8.), pnt.coords) with self.assertRaises(TypeError): pnt.tuple = (1., 2.) pnt.coords = (1., 2., 3.) self.assertEqual((1., 2., 3.), pnt.coords)
ls = LineString((2., 3., 8.), (50., 250., -117.)) self.assertEqual(((2., 3., 8.), (50., 250., -117.)), ls.tuple) with self.assertRaises(TypeError): ls.__setitem__(0, (1., 2.)) ls[0] = (1., 2., 3.) self.assertEqual((1., 2., 3.), ls[0])
pnt = Point(0, 0) self.assertEqual(0.0, pnt.distance(Point(0, 0)))
self.assertEqual(1.0, pnt.distance(Point(0, 1)))
self.assertAlmostEqual(1.41421356237, pnt.distance(Point(1, 1)), 11)
ls1 = LineString((0, 0), (1, 1), (2, 2)) ls2 = LineString((5, 2), (6, 1), (7, 0)) self.assertEqual(3, ls1.distance(ls2))
pnt = Point(0, 0) self.assertEqual(0.0, pnt.length)
ls = LineString((0, 0), (1, 1)) self.assertAlmostEqual(1.41421356237, ls.length, 11)
poly = Polygon(LinearRing((0, 0), (0, 1), (1, 1), (1, 0), (0, 0))) self.assertEqual(4.0, poly.length)
mpoly = MultiPolygon(poly.clone(), poly) self.assertEqual(8.0, mpoly.length)
if isinstance(g, Polygon):
if isinstance(g, Point): with self.assertRaises(IndexError): g.x elif isinstance(g, Polygon): lr = g.shell self.assertEqual('LINEARRING EMPTY', lr.wkt) self.assertEqual(0, len(lr)) self.assertEqual(True, lr.empty) with self.assertRaises(IndexError): lr.__getitem__(0) else: with self.assertRaises(IndexError): g.__getitem__(0)
coll = [mp.wkt for mp in self.geometries.multipolygons if mp.valid] coll.extend(mls.wkt for mls in self.geometries.multilinestrings) coll.extend(p.wkt for p in self.geometries.polygons) coll.extend(mp.wkt for mp in self.geometries.multipoints) gc_wkt = 'GEOMETRYCOLLECTION(%s)' % ','.join(coll)
gc1 = GEOSGeometry(gc_wkt)
gc2 = GeometryCollection(*tuple(g for g in gc1))
self.assertEqual(gc1, gc2)
t1, t2, t3 = orig.clone(), orig.clone(), orig.clone() t1.transform(trans.srid) t2.transform(gdal.SpatialReference('EPSG:2774')) ct = gdal.CoordTransform(gdal.SpatialReference('WGS84'), gdal.SpatialReference(2774)) t3.transform(ct)
k1 = orig.clone() k2 = k1.transform(trans.srid, clone=True) self.assertEqual(k1, orig) self.assertNotEqual(k1, k2)
g = GEOSGeometry('POINT (-104.609 38.255)', 4326) gt = g.tuple g.transform(4326) self.assertEqual(g.tuple, gt) self.assertEqual(g.srid, 4326)
mp = MultiPoint(Point(5, 23), Point(0, 0), Point(10, 50)) self.assertEqual((0.0, 0.0, 10.0, 50.0), mp.extent) pnt = Point(5.23, 17.8) self.assertEqual((5.23, 17.8, 5.23, 17.8), pnt.extent) poly = fromstr(self.geometries.polygons[3].wkt) ring = poly.shell x, y = ring.x, ring.y xmin, ymin = min(x), min(y) xmax, ymax = max(x), max(y) self.assertEqual((xmin, ymin, xmax, ymax), poly.extent)
from django.utils.six.moves import cPickle import pickle
def get_geoms(lst, srid=None): return [GEOSGeometry(tg.wkt, srid) for tg in lst] tgeoms = get_geoms(self.geometries.points) tgeoms.extend(get_geoms(self.geometries.multilinestrings, 4326)) tgeoms.extend(get_geoms(self.geometries.polygons, 3084)) tgeoms.extend(get_geoms(self.geometries.multipolygons, 3857))
mpoly = GEOSGeometry('MULTIPOLYGON(((0 0,0 5,5 5,5 0,0 0)),((5 5,5 10,10 10,10 5,5 5)))') prep = mpoly.prepared
pnts = [Point(5, 5), Point(7.5, 7.5), Point(2.5, 7.5)] for pnt in pnts: self.assertEqual(mpoly.contains(pnt), prep.contains(pnt)) self.assertEqual(mpoly.intersects(pnt), prep.intersects(pnt)) self.assertEqual(mpoly.covers(pnt), prep.covers(pnt))
del mpoly self.assertTrue(prep.covers(Point(5, 5)))
p._set_single(0, 100) self.assertEqual(p.coords, (100.0, 2.0, 3.0), 'Point _set_single')
p._set_list(2, (50, 3141)) self.assertEqual(p.coords, (50.0, 3141.0), 'Point _set_list')
ls._set_single(0, (-50, 25)) self.assertEqual(ls.coords, ((-50.0, 25.0), (4.0, 1.0), (6.0, -1.0)), 'LineString _set_single')
ls._set_list(2, ((-50.0, 25.0), (6.0, -1.0))) self.assertEqual(ls.coords, ((-50.0, 25.0), (6.0, -1.0)), 'LineString _set_list')
pg._set_list(2, (((1, 2), (10, 0), (12, 9), (-1, 15), (1, 2)), ((4, 2), (5, 2), (5, 3), (4, 2)))) self.assertEqual( pg.coords, (((1.0, 2.0), (10.0, 0.0), (12.0, 9.0), (-1.0, 15.0), (1.0, 2.0)), ((4.0, 2.0), (5.0, 2.0), (5.0, 3.0), (4.0, 2.0))), 'Polygon _set_list')
r = RasterModel.objects.create(rast=JSON_RASTER) r.refresh_from_db() self.assertEqual((5, 5), (r.rast.width, r.rast.height)) self.assertEqual([0.0, -1.0, 0.0, 0.0, 0.0, 1.0], r.rast.geotransform) self.assertIsNone(r.rast.bands[0].nodata_value) self.assertEqual(r.rast.srs.srid, 4326) band = r.rast.bands[0].data() if numpy: band = band.flatten().tolist() self.assertEqual( [ 0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0 ], band )
rast = json.loads(JSON_RASTER) rast['srid'] = 3086 r = RasterModel.objects.create(rast=rast) r.refresh_from_db() self.assertEqual(r.rast.srs.srid, 4326) self.assertEqual( r.rast.geotransform, [-87.9298551266551, 9.459646421449934e-06, 0.0, 23.94249275457565, 0.0, -9.459646421449934e-06] )
rast = GDALRaster(json.loads(JSON_RASTER)) stx_pnt = GEOSGeometry('POINT (-95.370401017314293 29.704867409475465)', 4326) stx_pnt.transform(3086)
for name, lookup in gis_lookups.items(): combo_keys = [ field + name for field in [ 'rast__', 'rast__', 'rastprojected__0__', 'rast__', 'rastprojected__', 'geom__', 'rast__', ] ] if issubclass(lookup, DistanceLookupBase): combo_values = [ (rast, 50, 'spheroid'), (rast, 0, 50, 'spheroid'), (rast, 0, D(km=1)), (stx_pnt, 0, 500), (stx_pnt, D(km=1000)), (rast, 500), (json.loads(JSON_RASTER), 500), ] elif name == 'relate': combo_values = [ (rast, 'T*T***FF*'), (rast, 0, 'T*T***FF*'), (rast, 0, 'T*T***FF*'), (stx_pnt, 0, 'T*T***FF*'), (stx_pnt, 'T*T***FF*'), (rast, 'T*T***FF*'), (json.loads(JSON_RASTER), 'T*T***FF*'), ] elif name == 'isvalid': continue elif PostGISOperations.gis_operators[name].func: combo_values = [ rast, (rast, 0), (rast, 0), (stx_pnt, 0), stx_pnt, rast, rast, json.loads(JSON_RASTER) ] else: combo_keys[2] = 'rastprojected__' + name combo_values = [rast, rast, rast, stx_pnt, stx_pnt, rast, rast, json.loads(JSON_RASTER)]
combos = [{x[0]: x[1]} for x in zip(combo_keys, combo_values)]
qs = RasterModel.objects.filter(**combo)
self.assertTrue(qs.count() in [0, 1])
qs = RasterModel.objects.filter(Q(**combos[0]) & Q(**combos[1])) self.assertTrue(qs.count() in [0, 1])
rast = GDALRaster(json.loads(JSON_RASTER)) stx_pnt = GEOSGeometry('POINT (-95.370401017314293 29.704867409475465)', 4326) stx_pnt.transform(3086)
qs = RasterModel.objects.filter(rastprojected__dwithin=(rast, D(km=1))) self.assertEqual(qs.count(), 1)
qs = RasterModel.objects.filter(rast__dwithin=(rast, 40)) self.assertEqual(qs.count(), 1)
qs = RasterModel.objects.filter(rast__1__dwithin=(rast, 1, 40)) self.assertEqual(qs.count(), 1) qs = RasterModel.objects.filter(rast__1__dwithin=(rast, 40)) self.assertEqual(qs.count(), 1) qs = RasterModel.objects.filter(rast__dwithin=(rast, 1, 40)) self.assertEqual(qs.count(), 1)
qs = RasterModel.objects.filter(rast__dwithin=(stx_pnt, 500)) self.assertEqual(qs.count(), 1)
qs = RasterModel.objects.filter(geom__dwithin=(rast, 500)) self.assertEqual(qs.count(), 1)
qs = RasterRelatedModel.objects.filter(rastermodel__rast__dwithin=(rast, 40)) self.assertEqual(qs.count(), 1)
qs = RasterRelatedModel.objects.filter(rastermodel__rast__1__dwithin=(rast, 40)) self.assertEqual(qs.count(), 1)
qs = RasterModel.objects.filter(Q(rast__dwithin=(rast, 40)) & Q(rastprojected__dwithin=(stx_pnt, D(km=10000)))) self.assertEqual(qs.count(), 1)
qs = RasterModel.objects.filter(rastprojected__bbcontains=rast) self.assertEqual(qs.count(), 1)
qs = RasterModel.objects.filter(rast__contains=GEOSGeometry('POINT (-0.5 0.5)', 4326)) self.assertEqual(qs.count(), 1) qs = RasterModel.objects.filter(rast__contains=GEOSGeometry('POINT (0.5 0.5)', 4326)) self.assertEqual(qs.count(), 0) qs = RasterModel.objects.filter(rast__contains_properly=GEOSGeometry('POINT (0 0)', 4326)) self.assertEqual(qs.count(), 0) qs = RasterModel.objects.filter(rast__left=GEOSGeometry('POINT (1 0)', 4326)) self.assertEqual(qs.count(), 1)
rast.origin.y = 2 qs = RasterModel.objects.filter(rast__strictly_below=rast) self.assertEqual(qs.count(), 0) rast.origin.y = 6 qs = RasterModel.objects.filter(rast__strictly_below=rast) self.assertEqual(qs.count(), 1)
rast.origin.x = -95.37040 + 1 rast.origin.y = 29.70486 qs = RasterModel.objects.filter(geom__intersects=rast) self.assertEqual(qs.count(), 1) rast.bands[0].data(data=[0, 0, 0, 1, 1], shape=(5, 1)) rast.bands[0].nodata_value = 0 qs = RasterModel.objects.filter(geom__intersects=rast) self.assertEqual(qs.count(), 0)
obj = dict() msg = "Couldn't create spatial object from lookup value '%s'." % obj with self.assertRaisesMessage(ValueError, msg): RasterModel.objects.filter(geom__intersects=obj) obj = '00000' msg = "Couldn't create spatial object from lookup value '%s'." % obj with self.assertRaisesMessage(ValueError, msg): RasterModel.objects.filter(geom__intersects=obj)
'ellipsoid': (6378137.0, 6356752.31414, 298.257222101), 'eprec': (1, 5, 10),
auth_name, oracle_flag = sd['auth_name'] if postgis or (oracle and oracle_flag): self.assertTrue(srs.auth_name.startswith(auth_name))
if postgis: self.assertTrue(srs.wkt.startswith(sd['srtext'])) six.assertRegex(self, srs.proj4text, sd['proj4_re'])
self.assertTrue(sr.name.startswith(sd['name']))
if postgis or spatialite: srs = sr.srs six.assertRegex(self, srs.proj4, sd['proj4_re']) self.assertTrue(srs.wkt.startswith(sd['srtext']))
ellps1 = sd['ellipsoid'] prec = sd['eprec']
srs = SpatialRefSys.objects.get(srid=sd['srid']) ellps2 = srs.ellipsoid
htown = City.objects.get(name='Houston') Zipcode.objects.distance(htown.point)
z = Zipcode.objects.get(code='77002') with self.assertRaises(ValueError): City.objects.filter(point__within=z.poly).count() with self.assertRaises(ValueError): City.objects.filter(point__contained=z.poly).count()
htown = City.objects.get(name='Houston') with self.assertRaises(ValueError): City.objects.get(point__exact=htown.point)
from django.contrib.gis.utils import LayerMapping
shp_path = os.path.realpath(os.path.join(os.path.dirname(upath(__file__)), '..', 'data')) co_shp = os.path.join(shp_path, 'counties', 'counties.shp') co_mapping = {'name': 'Name', 'state': 'State', 'mpoly': 'MULTIPOLYGON', }
names = ['Bexar', 'Galveston', 'Harris', 'Honolulu', 'Pueblo']
z = Zipcode.objects.area().get(code='77002') rounded_value = z.area.sq_m rounded_value -= z.area.sq_m % 1000 self.assertEqual(rounded_value, 5439000)
z = Zipcode.objects.annotate(area=Area('poly')).get(code='77002') rounded_value = z.area.sq_m rounded_value -= z.area.sq_m % 1000 self.assertEqual(rounded_value, 5439000)
def no_oracle(func): return no_backend(func, 'oracle')
_default_db = settings.DATABASES[DEFAULT_DB_ALIAS]['ENGINE'].rsplit('.')[-1] oracle = _default_db == 'oracle' postgis = _default_db == 'postgis' mysql = _default_db == 'mysql' spatialite = _default_db == 'spatialite'
gisfield_may_be_null = not mysql
self.stx_pnt = GEOSGeometry('POINT (-95.370401017314293 29.704867409475465)', 4326) self.au_pnt = GEOSGeometry('POINT (150.791 -34.4919)', 4326)
tx_dists = [(7000, 22965.83), D(km=7), D(mi=4.349)] au_dists = [(0.5, 32000), D(km=32), D(mi=19.884)]
tx_cities = ['Downtown Houston', 'Southside Place'] au_cities = ['Mittagong', 'Shellharbour', 'Thirroul', 'Wollongong']
for dist in tx_dists: if isinstance(dist, tuple): dist1, dist2 = dist else: dist1 = dist2 = dist qs1 = SouthTexasCity.objects.filter(point__dwithin=(self.stx_pnt, dist1)) qs2 = SouthTexasCityFt.objects.filter(point__dwithin=(self.stx_pnt, dist2)) for qs in qs1, qs2: self.assertEqual(tx_cities, self.get_names(qs))
for dist in au_dists: if isinstance(dist, D) and not oracle: type_error = True else: type_error = False
qs = AustraliaCity.objects.order_by('name') if type_error: with self.assertRaises(ValueError): AustraliaCity.objects.filter(point__dwithin=(self.au_pnt, dist)).count() else: self.assertListEqual(au_cities, self.get_names(qs.filter(point__dwithin=(self.au_pnt, dist))))
lagrange = GEOSGeometry('POINT(-96.876369 29.905320)', 4326) m_distances = [147075.069813, 139630.198056, 140888.552826, 138809.684197, 158309.246259, 212183.594374, 70870.188967, 165337.758878, 139196.085105] ft_distances = [482528.79154625, 458103.408123001, 462231.860397575, 455411.438904354, 519386.252102563, 696139.009211594, 232513.278304279, 542445.630586414, 456679.155883207]
dist1 = SouthTexasCity.objects.distance(lagrange, field_name='point').order_by('id')
tol = 2 if oracle else 5
for qs in dist_qs: for i, c in enumerate(qs): self.assertAlmostEqual(m_distances[i], c.distance.m, tol) self.assertAlmostEqual(ft_distances[i], c.distance.survey_ft, tol)
ls = LineString(((150.902, -34.4245), (150.87, -34.5789)))
distances = [1120954.92533513, 140575.720018241, 640396.662906304, 60580.9693849269, 972807.955955075, 568451.8357838, 40435.4335201384, 0, 68272.3896586844, 12375.0643697706, 0] qs = AustraliaCity.objects.distance(ls).order_by('name') for city, distance in zip(qs, distances): self.assertAlmostEqual(distance, city.distance.m, 0)
if connection.ops.postgis and connection.ops.proj_version_tuple() >= (4, 7, 0): spheroid_distances = [60504.0628957201, 77023.9489850262, 49154.8867574404, 90847.4358768573, 217402.811919332, 709599.234564757, 640011.483550888, 7772.00667991925, 1047861.78619339, 1165126.55236034] sphere_distances = [60580.9693849267, 77144.0435286473, 49199.4415344719, 90804.7533823494, 217713.384600405, 709134.127242793, 639828.157159169, 7786.82949717788, 1049204.06569028, 1162623.7238134]
hillsdale = AustraliaCity.objects.get(name='Hillsdale') qs = AustraliaCity.objects.exclude(id=hillsdale.id).distance(hillsdale.point, spheroid=True).order_by('id') for i, c in enumerate(qs): self.assertAlmostEqual(spheroid_distances[i], c.distance.m, tol) if postgis: qs = AustraliaCity.objects.exclude(id=hillsdale.id).distance(hillsdale.point).order_by('id') for i, c in enumerate(qs): self.assertAlmostEqual(sphere_distances[i], c.distance.m, tol)
z = SouthTexasZipcode.objects.get(name='77005')
dists_m = [3553.30384972258, 1243.18391525602, 2186.15439472242]
buf1 = z.poly.centroid.buffer(100) buf2 = buf1.transform(4269, clone=True) ref_zips = ['77002', '77025', '77401']
qs1 = SouthTexasCity.objects.filter(point__distance_gte=(self.stx_pnt, D(km=7))).filter( point__distance_lte=(self.stx_pnt, D(km=20)), )
if oracle: dist_qs = (qs1,) else: qs2 = SouthTexasCityFt.objects.filter(point__distance_gte=(self.stx_pnt, D(km=7))).filter( point__distance_lte=(self.stx_pnt, D(km=20)), ) dist_qs = (qs1, qs2)
z = SouthTexasZipcode.objects.get(name='77005') qs = SouthTexasZipcode.objects.exclude(name='77005').filter(poly__distance_lte=(z.poly, D(m=275))) self.assertEqual(['77025', '77401'], self.get_names(qs)) qs = SouthTexasZipcode.objects.exclude(name='77005').filter(poly__distance_lte=(z.poly, D(m=300))) self.assertEqual(['77002', '77025', '77401'], self.get_names(qs))
line = GEOSGeometry('LINESTRING(144.9630 -37.8143,151.2607 -33.8870)', 4326) dist_qs = AustraliaCity.objects.filter(point__distance_lte=(line, D(km=100)))
queryset = AustraliaCity.objects.filter(point__distance_lte=('POINT(5 23)', D(km=100), 'spheroid', '4')) with self.assertRaises(ValueError): len(queryset)
with self.assertRaises(ValueError): len(AustraliaCity.objects.filter(point__distance_lte=('POINT(5 23)',)))
hobart = AustraliaCity.objects.get(name='Hobart') qs = AustraliaCity.objects.exclude(name='Hobart').filter(point__distance_lte=(hobart.point, D(mi=550))) cities = self.get_names(qs) self.assertEqual(cities, ['Batemans Bay', 'Canberra', 'Melbourne'])
wollongong = AustraliaCity.objects.get(name='Wollongong')
gq1 = Q(point__distance_lte=(wollongong.point, d1)) gq2 = Q(point__distance_gte=(wollongong.point, d2)) qs1 = AustraliaCity.objects.exclude(name='Wollongong').filter(gq1 | gq2)
querysets = [qs1] if connection.features.has_distance_spheroid_method: gq3 = Q(point__distance_lte=(wollongong.point, d1, 'spheroid')) gq4 = Q(point__distance_gte=(wollongong.point, d2, 'spheroid')) qs2 = AustraliaCity.objects.exclude(name='Wollongong').filter(gq3 | gq4) querysets.append(qs2)
qs = SouthTexasCity.objects.filter( point__distance_lte=(self.stx_pnt, F('radius') * 2), ).order_by('name') self.assertEqual(len(qs), 5) self.assertIn('Pearland', self.get_names(qs))
if connection.features.supports_distance_geodetic: hobart = AustraliaCity.objects.get(name='Hobart') qs = AustraliaCity.objects.filter( point__distance_lte=(hobart.point, F('radius') * 70, 'spheroid'), ).order_by('name') self.assertEqual(self.get_names(qs), ['Canberra', 'Hobart', 'Melbourne'])
area_sq_m = [5437908.90234375, 10183031.4389648, 11254471.0073242, 9881708.91772461] tol = 2 for i, z in enumerate(SouthTexasZipcode.objects.order_by('name').area()): self.assertAlmostEqual(area_sq_m[i], z.area.sq_m, tol)
len_m1 = 473504.769553813 len_m2 = 4617.668
with self.assertRaises(ValueError): Interstate.objects.length()
i10 = SouthTexasInterstate.objects.length().get(name='I-10') self.assertAlmostEqual(len_m2, i10.length.m, 2)
perim_m = [18404.3550889361, 15627.2108551001, 20632.5588368978, 17094.5996143697] tol = 2 if oracle else 7 for i, z in enumerate(SouthTexasZipcode.objects.order_by('name').perimeter()): self.assertAlmostEqual(perim_m[i], z.perimeter.m, tol)
for i, c in enumerate(SouthTexasCity.objects.perimeter(model_att='perim')): self.assertEqual(0, c.perim.m)
SouthTexasZipcode.objects.create(name='78212') htown = SouthTexasCity.objects.get(name='Downtown Houston') z = SouthTexasZipcode.objects.distance(htown.point).area().get(name='78212') self.assertIsNone(z.distance) self.assertIsNone(z.area)
area_sq_m = [5437908.90234375, 10183031.4389648, 11254471.0073242, 9881708.91772461] tol = 2 for i, z in enumerate(SouthTexasZipcode.objects.annotate(area=Area('poly')).order_by('name')): self.assertAlmostEqual(area_sq_m[i], z.area.sq_m if hasattr(z.area, 'sq_m') else z.area, tol)
lagrange = GEOSGeometry('POINT(-96.876369 29.905320)', 4326) m_distances = [147075.069813, 139630.198056, 140888.552826, 138809.684197, 158309.246259, 212183.594374, 70870.188967, 165337.758878, 139196.085105] ft_distances = [482528.79154625, 458103.408123001, 462231.860397575, 455411.438904354, 519386.252102563, 696139.009211594, 232513.278304279, 542445.630586414, 456679.155883207]
dist1 = SouthTexasCity.objects.annotate(distance=Distance('point', lagrange)).order_by('id') if oracle: dist_qs = [dist1] else: dist2 = SouthTexasCityFt.objects.annotate(distance=Distance('point', lagrange)).order_by('id') dist_qs = [dist1, dist2]
tol = 2 if oracle else 5
for qs in dist_qs: for i, c in enumerate(qs): self.assertAlmostEqual(m_distances[i], c.distance.m, tol) self.assertAlmostEqual(ft_distances[i], c.distance.survey_ft, tol)
ls = LineString(((150.902, -34.4245), (150.87, -34.5789)), srid=4326)
distances = [1120954.92533513, 140575.720018241, 640396.662906304, 60580.9693849269, 972807.955955075, 568451.8357838, 40435.4335201384, 0, 68272.3896586844, 12375.0643697706, 0] qs = AustraliaCity.objects.annotate(distance=Distance('point', ls)).order_by('name') for city, distance in zip(qs, distances): self.assertAlmostEqual(distance, city.distance.m, 0)
if connection.ops.postgis and connection.ops.proj_version_tuple() >= (4, 7, 0): spheroid_distances = [60504.0628957201, 77023.9489850262, 49154.8867574404, 90847.4358768573, 217402.811919332, 709599.234564757, 640011.483550888, 7772.00667991925, 1047861.78619339, 1165126.55236034] sphere_distances = [60580.9693849267, 77144.0435286473, 49199.4415344719, 90804.7533823494, 217713.384600405, 709134.127242793, 639828.157159169, 7786.82949717788, 1049204.06569028, 1162623.7238134]
hillsdale = AustraliaCity.objects.get(name='Hillsdale') qs = AustraliaCity.objects.exclude(id=hillsdale.id).annotate( distance=Distance('point', hillsdale.point, spheroid=True) ).order_by('id') for i, c in enumerate(qs): self.assertAlmostEqual(spheroid_distances[i], c.distance.m, tol) if postgis: qs = AustraliaCity.objects.exclude(id=hillsdale.id).annotate( distance=Distance('point', hillsdale.point) ).order_by('id') for i, c in enumerate(qs): self.assertAlmostEqual(sphere_distances[i], c.distance.m, tol)
z = SouthTexasZipcode.objects.get(name='77005')
dists_m = [3553.30384972258, 1243.18391525602, 2186.15439472242]
buf1 = z.poly.centroid.buffer(100) buf2 = buf1.transform(4269, clone=True) ref_zips = ['77002', '77025', '77401']
len_m1 = 473504.769553813 len_m2 = 4617.668
else: with self.assertRaises(NotImplementedError): list(Interstate.objects.annotate(length=Length('path')))
i10 = SouthTexasInterstate.objects.annotate(length=Length('path')).get(name='I-10') self.assertAlmostEqual(len_m2, i10.length.m if isinstance(i10.length, D) else i10.length, 2) self.assertTrue( SouthTexasInterstate.objects.annotate(length=Length('path')).filter(length__gt=4000).exists() )
perim_m = [18404.3550889361, 15627.2108551001, 20632.5588368978, 17094.5996143697] tol = 2 if oracle else 7 qs = SouthTexasZipcode.objects.annotate(perimeter=Perimeter('poly')).order_by('name') for i, z in enumerate(qs): self.assertAlmostEqual(perim_m[i], z.perimeter.m, tol)
qs = SouthTexasCity.objects.annotate(perim=Perimeter('point')) for city in qs: self.assertEqual(0, city.perim.m)
qs1 = CensusZipcode.objects.annotate(perim=Perimeter('poly')) if connection.features.supports_perimeter_geodetic: self.assertAlmostEqual(qs1[0].perim.m, 18406.3818954314, 3) else: with self.assertRaises(NotImplementedError): list(qs1) qs2 = CensusZipcode.objects.annotate(perim=Perimeter(Transform('poly', 32140))).filter(name='77002') self.assertAlmostEqual(qs2[0].perim.m, 18404.355, 3)
SouthTexasZipcode.objects.create(name='78212') htown = SouthTexasCity.objects.get(name='Downtown Houston') z = SouthTexasZipcode.objects.annotate( distance=Distance('poly', htown.point), area=Area('poly') ).get(name='78212') self.assertIsNone(z.distance) self.assertIsNone(z.area)
fld = forms.GeometryField(srid=4326) geom = fld.clean('POINT(5 23)') self.assertEqual(4326, geom.srid) fld = forms.GeometryField(srid=32140) tol = 0.0000001 xform_geom = GEOSGeometry('POINT (951640.547328465 4219369.26171664)', srid=32140) cleaned_geom = fld.clean('SRID=4326;POINT (-95.363151 29.763374)') self.assertTrue(xform_geom.equals_exact(cleaned_geom, tol))
fld = forms.GeometryField() with self.assertRaisesMessage(forms.ValidationError, "No geometry value provided."): fld.clean(None)
fld = forms.GeometryField(required=False) self.assertIsNone(fld.clean(None))
fld = forms.GeometryField() for wkt in ('POINT(5 23)', 'MULTIPOLYGON(((0 0, 0 1, 1 1, 1 0, 0 0)))', 'LINESTRING(0 0, 1 1)'): self.assertEqual(GEOSGeometry(wkt), fld.clean(wkt))
self.assertEqual(GEOSGeometry('LINESTRING(0 0, 1 1)'), pnt_fld.to_python('LINESTRING(0 0, 1 1)')) with self.assertRaises(forms.ValidationError): pnt_fld.clean('LINESTRING(0 0, 1 1)')
for wkt in ('POINT(5 23)', 'MULTIPOLYGON(((0 0, 0 1, 1 1, 1 0, 0 0)))', 'LINESTRING(0 0, 1 1)'): self.assertEqual(GEOSGeometry(wkt), fld.to_python(wkt)) for wkt in ('POINT(5)', 'MULTI POLYGON(((0 0, 0 1, 1 1, 1 0, 0 0)))', 'BLAH(0 0, 1 1)'): with self.assertRaises(forms.ValidationError): fld.to_python(wkt)
@override_settings(USE_L10N=True, USE_THOUSAND_SEPARATOR=True) def test_pointfield(self): class PointForm(forms.Form): p = forms.PointField()
self.assertIn(escape(point.json), widget.render('p', point.json)) self.assertEqual(widget.deserialize_called, 1)
self.assertEqual(form.cleaned_data['p'].srid, 4326)
return name + '_valid'
return '%s/%s' % (random.randint(100, 999), filename)
from __future__ import unicode_literals
with six.assertRaisesRegex(self, ImportError, "No module named '?(django.core.files.)?non_existing_storage'?"): get_storage_class('django.core.files.non_existing_storage.NonExistingStorage')
requires_pytz = unittest.skipIf(pytz is None, "this test requires pytz")
storage_class = FileSystemStorage
self.temp_dir2 = tempfile.mkdtemp(suffix='aBc')
self._test_file_time_getter_tz_handling_on(getter) self._test_file_time_getter_tz_handling_off(getter)
now_in_algiers = timezone.make_aware(datetime.now())
with timezone.override(timezone.get_fixed_timezone(-300)): now = timezone.now() self.assertFalse(self.storage.exists('test.file.tz.on'))
self.assertTrue(timezone.is_aware(dt)) self.assertEqual(now.tzname(), dt.tzname())
naive_now = datetime.now() algiers_offset = now_in_algiers.tzinfo.utcoffset(naive_now) django_offset = timezone.get_current_timezone().utcoffset(naive_now) utc_offset = timezone.utc.utcoffset(naive_now) self.assertGreater(algiers_offset, utc_offset) self.assertLess(django_offset, utc_offset)
self.assertLess(abs(dt - now), timedelta(seconds=2))
now_in_algiers = timezone.make_aware(datetime.now())
with timezone.override(timezone.get_fixed_timezone(-300)): self.assertFalse(self.storage.exists('test.file.tz.off'))
self.assertTrue(timezone.is_naive(dt))
naive_now = datetime.now() algiers_offset = now_in_algiers.tzinfo.utcoffset(naive_now) django_offset = timezone.get_current_timezone().utcoffset(naive_now) utc_offset = timezone.utc.utcoffset(naive_now) self.assertGreater(algiers_offset, utc_offset) self.assertLess(django_offset, utc_offset)
self.assertLess(abs(dt - naive_now), timedelta(seconds=2)) _dt = timezone.make_aware(dt, now_in_algiers.tzinfo) self.assertLess(abs(_dt - now_in_algiers), timedelta(seconds=2))
self.assertEqual( self.storage.url(r"~!*()'@#$%^&*abc`+ =.file"), "/test_media_url/~!*()'%40%23%24%25%5E%26*abc%60%2B%20%3D.file" ) self.assertEqual(self.storage.url("ab\0c"), "/test_media_url/ab%00c")
self.assertEqual(self.storage.url("/evil.com"), "/test_media_url/evil.com") self.assertEqual(self.storage.url(r"\evil.com"), "/test_media_url/evil.com") self.assertEqual(self.storage.url("///evil.com"), "/test_media_url/evil.com") self.assertEqual(self.storage.url(r"\\\evil.com"), "/test_media_url/evil.com")
storage = self.storage_class(location=self.temp_dir, base_url='/no_ending_slash') self.assertEqual( storage.url('test.file'), '%s%s' % (storage.base_url, 'test.file') )
other_temp_storage = self.storage_class(location=self.temp_dir2) mixed_case = 'CaSe_SeNsItIvE' file = other_temp_storage.open(mixed_case, 'w') file.write('storage contents') file.close() self.assertEqual(os.path.join(self.temp_dir2, mixed_case), other_temp_storage.path(mixed_case)) other_temp_storage.delete(mixed_case)
def fake_makedirs(path): if path == os.path.join(self.temp_dir, 'normal'): real_makedirs(path) elif path == os.path.join(self.temp_dir, 'raced'): real_makedirs(path) raise OSError(errno.EEXIST, 'simulated EEXIST') elif path == os.path.join(self.temp_dir, 'error'): raise OSError(errno.EACCES, 'simulated EACCES') else: self.fail('unexpected argument %r' % path)
with self.assertRaises(OSError): self.storage.save('error/test.file', ContentFile('not saved'))
def fake_remove(path): if path == os.path.join(self.temp_dir, 'normal.file'): real_remove(path) elif path == os.path.join(self.temp_dir, 'raced.file'): real_remove(path) raise OSError(errno.ENOENT, 'simulated ENOENT') elif path == os.path.join(self.temp_dir, 'error.file'): raise OSError(errno.EACCES, 'simulated EACCES') else: self.fail('unexpected argument %r' % path)
self.storage.save('error.file', ContentFile('delete with error')) with self.assertRaises(OSError): self.storage.delete('error.file')
obj1 = Storage() self.assertEqual(obj1.normal.name, "") with self.assertRaises(ValueError): obj1.normal.size
obj1.normal.save("django_test.txt", ContentFile("content")) self.assertEqual(obj1.normal.name, "tests/django_test.txt") self.assertEqual(obj1.normal.size, 7) self.assertEqual(obj1.normal.read(), b"content") obj1.normal.close()
obj1.normal = SimpleUploadedFile("assignment.txt", b"content") dirs, files = temp_storage.listdir("tests") self.assertEqual(dirs, []) self.assertNotIn("assignment.txt", files)
obj2 = Storage() obj2.normal.save("django_test.txt", ContentFile("more content")) obj2_name = obj2.normal.name six.assertRegex(self, obj2_name, "tests/django_test_%s.txt" % FILE_SUFFIX_REGEX) self.assertEqual(obj2.normal.size, 12) obj2.normal.close()
obj2.delete() obj2.normal.save("django_test.txt", ContentFile("more content")) self.assertNotEqual(obj2_name, obj2.normal.name) six.assertRegex(self, obj2.normal.name, "tests/django_test_%s.txt" % FILE_SUFFIX_REGEX) obj2.normal.close()
obj = Storage.objects.create( normal=SimpleUploadedFile("assignment.txt", b"content")) obj.normal.open() self.assertEqual(obj.normal.read(3), b"con") self.assertEqual(obj.normal.read(), b"tent") self.assertEqual(list(obj.normal.chunks(chunk_size=2)), [b"co", b"nt", b"en", b"t"]) obj.normal.close()
obj = Storage.objects.create(normal=SimpleUploadedFile('rewritten.txt', b'content')) with obj.normal as normal: normal.open('wb') normal.write(b'updated') obj.refresh_from_db() self.assertEqual(obj.normal.read(), b'updated') obj.normal.close()
objs = [Storage() for i in range(2)] for o in objs: o.normal.save("multiple_files.txt", ContentFile("Same Content")) try: names = [o.normal.name for o in objs] self.assertEqual(names[0], "tests/multiple_files.txt") six.assertRegex(self, names[1], "tests/multiple_files_%s.txt" % FILE_SUFFIX_REGEX) finally: for o in objs: o.delete()
objs = [Storage() for i in range(2)] filename = 'filename.ext'
names = [o.limited_length.name for o in objs] self.assertEqual(names[0], 'tests/%s' % filename) six.assertRegex(self, names[1], 'tests/fi_%s.ext' % FILE_SUFFIX_REGEX)
filename = 'short.longext' objs[0].limited_length.save(filename, ContentFile('Same Content')) with self.assertRaisesMessage(SuspiciousFileOperation, 'Storage can not find an available filename'): objs[1].limited_length.save(*(filename, ContentFile('Same Content')))
temp_storage.save('tests/default.txt', ContentFile('default content')) obj = Storage.objects.create() self.assertEqual(obj.default.name, "tests/default.txt") self.assertEqual(obj.default.read(), b"default content") obj.default.close()
obj.delete() obj = Storage() self.assertEqual(obj.default.read(), b"default content") obj.default.close()
obj = Storage() obj.empty.save('django_test.txt', ContentFile('more content')) self.assertEqual(obj.empty.name, "django_test.txt") self.assertEqual(obj.empty.read(), b"more content") obj.empty.close()
obj = Storage() obj.random.save("random_file", ContentFile("random content")) self.assertTrue(obj.random.name.endswith("/random_file")) obj.random.close()
self.assertTrue(obj.custom_valid_name.name.endswith("/random_file_valid")) obj.custom_valid_name.close()
obj = Storage() obj.normal.save("django_test.txt", ContentFile("more content")) obj.normal.close() cache.set("obj", obj) self.assertEqual(cache.get("obj").normal.name, "tests/django_test.txt")
temp_storage.save('tests/example.txt', ContentFile('some content'))
with open(temp_storage.path('tests/example.txt')) as file_obj: temp_storage.save('tests/file_obj', file_obj) self.assertTrue(temp_storage.exists('tests/file_obj')) with temp_storage.open('tests/file_obj') as f: self.assertEqual(f.read(), b'some content')
output = six.StringIO() output.write('content') output.seek(0)
temp_storage.save('tests/stringio', output) self.assertTrue(temp_storage.exists('tests/stringio')) with temp_storage.open('tests/stringio') as f: self.assertEqual(f.read(), b'content')
result_key = f.generate_filename(None, key) self.assertEqual(result_key, expected_key)
def upload_to(instance, filename): return folder + filename
result_key = f.generate_filename(None, key) self.assertEqual(result_key, expected_key)
self.usa = Country.objects.create(name="United States of America") self.soviet_union = Country.objects.create(name="Soviet Union") Person() self.bob = Person() self.bob.name = 'Bob' self.bob.person_country = self.usa self.bob.save() self.jim = Person.objects.create(name='Jim', person_country=self.usa) self.george = Person.objects.create(name='George', person_country=self.usa)
self.kgb = Group.objects.create(name='KGB', group_country=self.soviet_union) self.cia = Group.objects.create(name='CIA', group_country=self.usa) self.republican = Group.objects.create(name='Republican', group_country=self.usa) self.democrat = Group.objects.create(name='Democrat', group_country=self.usa)
membership = Membership.objects.create( membership_country_id=self.usa.id, person_id=self.bob.id, group_id=self.cia.id)
membership = Membership.objects.create( membership_country_id=self.usa.id, person_id=self.jane.id, group_id=self.cia.id)
Membership.objects.create( membership_country_id=self.usa.id, person_id=self.bob.id, group_id=self.cia.id)
Membership.objects.create( membership_country_id=self.soviet_union.id, person_id=self.bob.id, group_id=self.republican.id)
Membership.objects.create( membership_country_id=self.usa.id, person_id=self.bob.id, group_id=self.cia.id) Membership.objects.create( membership_country_id=self.usa.id, person_id=self.jim.id, group_id=self.cia.id)
Membership.objects.create(membership_country_id=self.soviet_union.id, person_id=self.george.id, group_id=self.cia.id)
Membership.objects.create( membership_country_id=self.usa.id, person_id=self.bob.id, group_id=self.cia.id, date_joined=timemark - timedelta) Membership.objects.create( membership_country_id=self.usa.id, person_id=self.jim.id, group_id=self.cia.id, date_joined=timemark + timedelta)
Membership.objects.create( membership_country_id=self.soviet_union.id, person_id=self.george.id, group_id=self.cia.id, date_joined=timemark + timedelta)
Membership.objects.create( membership_country_id=self.soviet_union.id, person_id=self.george.id, group_id=self.cia.id)
self.assertQuerysetEqual( self.cia.members.all(), [] )
self.assertQuerysetEqual( self.bob.groups.all(), [] )
self.assertQuerysetEqual( self.bob.groups.all(), [ 'CIA', 'Republican' ], attrgetter("name") )
self.assertQuerysetEqual( self.cia.members.all(), [] )
Membership.objects.create(membership_country=self.usa, person=self.jane, group=self.cia)
self.assertQuerysetEqual( self.cia.members.all(), [] )
self.assertQuerysetEqual( self.jane.groups.all(), [] )
Membership.objects.create(membership_country=self.usa, person=self.jane, group=self.cia)
self.assertQuerysetEqual( self.jane.groups.all(), [] )
Friendship.objects.create( from_friend_id=self.jane.id, to_friend_id=self.george.id, to_friend_country_id=self.jane.person_country_id, from_friend_country_id=self.george.person_country_id)
a3 = Article(id=a3.id, pub_date=a3.pub_date, active_translation=at3_en) a3.save() self.assertEqual( list(Article.objects.filter(active_translation__abstract=None)), [a1, a3]) self.assertEqual( list(Article.objects.filter(active_translation__abstract=None, active_translation__pk__isnull=False)), [a1])
class ArticleForm(forms.ModelForm): class Meta: model = Article fields = '__all__'
form = FormsTests.ArticleForm() self.assertIn('id_pub_date', form.as_table()) self.assertNotIn('active_translation', form.as_table()) form = FormsTests.ArticleForm(data={'pub_date': str(datetime.date.today())}) self.assertTrue(form.is_valid()) a = form.save() self.assertEqual(a.pub_date, datetime.date.today()) form = FormsTests.ArticleForm(instance=a, data={'pub_date': '2013-01-01'}) a2 = form.save() self.assertEqual(a.pk, a2.pk) self.assertEqual(a2.pub_date, datetime.date(2013, 1, 1))
from_fields=['company', 'customer_id'], to_fields=['company', 'customer_id'],
def __init__(self, alias, col, value): self.alias, self.col, self.value = alias, col, value
name = models.CharField(max_length=50)
name = models.CharField(max_length=128) person_country_id = models.IntegerField()
person_country = models.ForeignObject( Country, from_fields=['person_country_id'], to_fields=['id'], on_delete=models.CASCADE, ) friends = models.ManyToManyField('self', through='Friendship', symmetrical=False)
name = models.CharField(max_length=128) group_country = models.ForeignKey(Country, models.CASCADE) members = models.ManyToManyField(Person, related_name='groups', through='Membership')
membership_country = models.ForeignKey(Country, models.CASCADE) date_joined = models.DateTimeField(default=datetime.datetime.now) invite_reason = models.CharField(max_length=64, null=True) person_id = models.IntegerField() group_id = models.IntegerField(blank=True, null=True)
person = models.ForeignObject( Person, from_fields=['person_id', 'membership_country'], to_fields=['id', 'person_country_id'], on_delete=models.CASCADE, ) group = models.ForeignObject( Group, from_fields=['group_id', 'membership_country'], to_fields=['id', 'group_country'], on_delete=models.CASCADE, )
from_friend_country = models.ForeignKey(Country, models.CASCADE, related_name="from_friend_country") from_friend_id = models.IntegerField() to_friend_country_id = models.IntegerField() to_friend_id = models.IntegerField()
from_friend = models.ForeignObject( Person, on_delete=models.CASCADE, from_fields=['from_friend_country', 'from_friend_id'], to_fields=['person_country_id', 'id'], related_name='from_friend')
class MyISAMArticle(models.Model): headline = models.CharField(max_length=100)
self.au1 = Author.objects.create(name='Author 1') self.au2 = Author.objects.create(name='Author 2') self.a1 = Article.objects.create(headline='Article 1', pub_date=datetime(2005, 7, 26), author=self.au1) self.a2 = Article.objects.create(headline='Article 2', pub_date=datetime(2005, 7, 27), author=self.au1) self.a3 = Article.objects.create(headline='Article 3', pub_date=datetime(2005, 7, 27), author=self.au1) self.a4 = Article.objects.create(headline='Article 4', pub_date=datetime(2005, 7, 28), author=self.au1) self.a5 = Article.objects.create(headline='Article 5', pub_date=datetime(2005, 8, 1, 9, 0), author=self.au2) self.a6 = Article.objects.create(headline='Article 6', pub_date=datetime(2005, 8, 1, 8, 0), author=self.au2) self.a7 = Article.objects.create(headline='Article 7', pub_date=datetime(2005, 7, 27), author=self.au2) self.t1 = Tag.objects.create(name='Tag 1') self.t1.articles.add(self.a1, self.a2, self.a3) self.t2 = Tag.objects.create(name='Tag 2') self.t2.articles.add(self.a3, self.a4, self.a5) self.t3 = Tag.objects.create(name='Tag 3') self.t3.articles.add(self.a5, self.a6, self.a7)
self.assertTrue(Article.objects.exists()) for a in Article.objects.all(): a.delete() self.assertFalse(Article.objects.exists())
self.assertQuerysetEqual(Article.objects.filter(id__iexact=str(self.a1.id)), ['<Article: Article 1>'])
self.assertQuerysetEqual( Article.objects.filter(pub_date__startswith='2005'), [ '<Article: Article 5>', '<Article: Article 6>', '<Article: Article 4>', '<Article: Article 2>', '<Article: Article 3>', '<Article: Article 7>', '<Article: Article 1>', ] )
self.assertIsInstance(Article.objects.iterator(), collections.Iterator)
self.assertQuerysetEqual( Article.objects.filter(headline__endswith='4').iterator(), ['Article 4'], transform=attrgetter('headline'))
self.assertEqual(Article.objects.count(), 7) self.assertEqual(Article.objects.filter(pub_date__exact=datetime(2005, 7, 27)).count(), 3) self.assertEqual(Article.objects.filter(headline__startswith='Blah blah').count(), 0)
articles = Article.objects.all() self.assertEqual(articles.count(), 7) self.assertEqual(articles[:4].count(), 4) self.assertEqual(articles[1:100].count(), 6) self.assertEqual(articles[10:100].count(), 0)
self.assertEqual(Article.objects.filter(pub_date__exact='2005-07-27 00:00:00').count(), 3)
arts = Article.objects.in_bulk([self.a1.id, self.a2.id]) self.assertEqual(arts[self.a1.id], self.a1) self.assertEqual(arts[self.a2.id], self.a2) self.assertEqual( Article.objects.in_bulk(), { self.a1.id: self.a1, self.a2.id: self.a2, self.a3.id: self.a3, self.a4.id: self.a4, self.a5.id: self.a5, self.a6.id: self.a6, self.a7.id: self.a7, } ) self.assertEqual(Article.objects.in_bulk([self.a3.id]), {self.a3.id: self.a3}) self.assertEqual(Article.objects.in_bulk({self.a3.id}), {self.a3.id: self.a3}) self.assertEqual(Article.objects.in_bulk(frozenset([self.a3.id])), {self.a3.id: self.a3}) self.assertEqual(Article.objects.in_bulk((self.a3.id,)), {self.a3.id: self.a3}) self.assertEqual(Article.objects.in_bulk([1000]), {}) self.assertEqual(Article.objects.in_bulk([]), {}) self.assertEqual(Article.objects.in_bulk(iter([self.a1.id])), {self.a1.id: self.a1}) self.assertEqual(Article.objects.in_bulk(iter([])), {}) with self.assertRaises(TypeError): Article.objects.in_bulk(headline__startswith='Blah')
def identity(x): return x self.assertQuerysetEqual( Article.objects.values('headline'), [ {'headline': 'Article 5'}, {'headline': 'Article 6'}, {'headline': 'Article 4'}, {'headline': 'Article 2'}, {'headline': 'Article 3'}, {'headline': 'Article 7'}, {'headline': 'Article 1'}, ], transform=identity ) self.assertQuerysetEqual( Article.objects.filter(pub_date__exact=datetime(2005, 7, 27)).values('id'), [{'id': self.a2.id}, {'id': self.a3.id}, {'id': self.a7.id}], transform=identity ) self.assertQuerysetEqual( Article.objects.values('id', 'headline'), [ {'id': self.a5.id, 'headline': 'Article 5'}, {'id': self.a6.id, 'headline': 'Article 6'}, {'id': self.a4.id, 'headline': 'Article 4'}, {'id': self.a2.id, 'headline': 'Article 2'}, {'id': self.a3.id, 'headline': 'Article 3'}, {'id': self.a7.id, 'headline': 'Article 7'}, {'id': self.a1.id, 'headline': 'Article 1'}, ], transform=identity ) self.assertQuerysetEqual( Article.objects.values('id', 'headline').iterator(), [ {'headline': 'Article 5', 'id': self.a5.id}, {'headline': 'Article 6', 'id': self.a6.id}, {'headline': 'Article 4', 'id': self.a4.id}, {'headline': 'Article 2', 'id': self.a2.id}, {'headline': 'Article 3', 'id': self.a3.id}, {'headline': 'Article 7', 'id': self.a7.id}, {'headline': 'Article 1', 'id': self.a1.id}, ], transform=identity ) self.assertQuerysetEqual( Article.objects.extra(select={'id_plus_one': 'id + 1'}).values('id', 'id_plus_one'), [ {'id': self.a5.id, 'id_plus_one': self.a5.id + 1}, {'id': self.a6.id, 'id_plus_one': self.a6.id + 1}, {'id': self.a4.id, 'id_plus_one': self.a4.id + 1}, {'id': self.a2.id, 'id_plus_one': self.a2.id + 1}, {'id': self.a3.id, 'id_plus_one': self.a3.id + 1}, {'id': self.a7.id, 'id_plus_one': self.a7.id + 1}, {'id': self.a1.id, 'id_plus_one': self.a1.id + 1}, ], transform=identity ) data = { 'id_plus_one': 'id+1', 'id_plus_two': 'id+2', 'id_plus_three': 'id+3', 'id_plus_four': 'id+4', 'id_plus_five': 'id+5', 'id_plus_six': 'id+6', 'id_plus_seven': 'id+7', 'id_plus_eight': 'id+8', } self.assertQuerysetEqual( Article.objects.filter(id=self.a1.id).extra(select=data).values(*data.keys()), [{ 'id_plus_one': self.a1.id + 1, 'id_plus_two': self.a1.id + 2, 'id_plus_three': self.a1.id + 3, 'id_plus_four': self.a1.id + 4, 'id_plus_five': self.a1.id + 5, 'id_plus_six': self.a1.id + 6, 'id_plus_seven': self.a1.id + 7, 'id_plus_eight': self.a1.id + 8, }], transform=identity ) self.assertQuerysetEqual( Article.objects.values('headline', 'author__name'), [ {'headline': self.a5.headline, 'author__name': self.au2.name}, {'headline': self.a6.headline, 'author__name': self.au2.name}, {'headline': self.a4.headline, 'author__name': self.au1.name}, {'headline': self.a2.headline, 'author__name': self.au1.name}, {'headline': self.a3.headline, 'author__name': self.au1.name}, {'headline': self.a7.headline, 'author__name': self.au2.name}, {'headline': self.a1.headline, 'author__name': self.au1.name}, ], transform=identity ) self.assertQuerysetEqual( Author.objects.values('name', 'article__headline').order_by('name', 'article__headline'), [ {'name': self.au1.name, 'article__headline': self.a1.headline}, {'name': self.au1.name, 'article__headline': self.a2.headline}, {'name': self.au1.name, 'article__headline': self.a3.headline}, {'name': self.au1.name, 'article__headline': self.a4.headline}, {'name': self.au2.name, 'article__headline': self.a5.headline}, {'name': self.au2.name, 'article__headline': self.a6.headline}, {'name': self.au2.name, 'article__headline': self.a7.headline}, ], transform=identity ) self.assertQuerysetEqual( ( Author.objects .values('name', 'article__headline', 'article__tag__name') .order_by('name', 'article__headline', 'article__tag__name') ), [ {'name': self.au1.name, 'article__headline': self.a1.headline, 'article__tag__name': self.t1.name}, {'name': self.au1.name, 'article__headline': self.a2.headline, 'article__tag__name': self.t1.name}, {'name': self.au1.name, 'article__headline': self.a3.headline, 'article__tag__name': self.t1.name}, {'name': self.au1.name, 'article__headline': self.a3.headline, 'article__tag__name': self.t2.name}, {'name': self.au1.name, 'article__headline': self.a4.headline, 'article__tag__name': self.t2.name}, {'name': self.au2.name, 'article__headline': self.a5.headline, 'article__tag__name': self.t2.name}, {'name': self.au2.name, 'article__headline': self.a5.headline, 'article__tag__name': self.t3.name}, {'name': self.au2.name, 'article__headline': self.a6.headline, 'article__tag__name': self.t3.name}, {'name': self.au2.name, 'article__headline': self.a7.headline, 'article__tag__name': self.t3.name}, ], transform=identity ) with self.assertRaises(FieldError): Article.objects.extra(select={'id_plus_one': 'id + 1'}).values('id', 'id_plus_two') self.assertQuerysetEqual( Article.objects.filter(id=self.a5.id).values(), [{ 'id': self.a5.id, 'author_id': self.au2.id, 'headline': 'Article 5', 'pub_date': datetime(2005, 8, 1, 9, 0) }], transform=identity )
def identity(x): return x self.assertQuerysetEqual( Article.objects.values_list('headline'), [ ('Article 5',), ('Article 6',), ('Article 4',), ('Article 2',), ('Article 3',), ('Article 7',), ('Article 1',), ], transform=identity ) self.assertQuerysetEqual( Article.objects.values_list('id').order_by('id'), [(self.a1.id,), (self.a2.id,), (self.a3.id,), (self.a4.id,), (self.a5.id,), (self.a6.id,), (self.a7.id,)], transform=identity ) self.assertQuerysetEqual( Article.objects.values_list('id', flat=True).order_by('id'), [self.a1.id, self.a2.id, self.a3.id, self.a4.id, self.a5.id, self.a6.id, self.a7.id], transform=identity ) self.assertQuerysetEqual( Article.objects.extra(select={'id_plus_one': 'id+1'}).order_by('id').values_list('id'), [(self.a1.id,), (self.a2.id,), (self.a3.id,), (self.a4.id,), (self.a5.id,), (self.a6.id,), (self.a7.id,)], transform=identity ) self.assertQuerysetEqual( Article.objects.extra(select={'id_plus_one': 'id+1'}).order_by('id').values_list('id_plus_one', 'id'), [ (self.a1.id + 1, self.a1.id), (self.a2.id + 1, self.a2.id), (self.a3.id + 1, self.a3.id), (self.a4.id + 1, self.a4.id), (self.a5.id + 1, self.a5.id), (self.a6.id + 1, self.a6.id), (self.a7.id + 1, self.a7.id) ], transform=identity ) self.assertQuerysetEqual( Article.objects.extra(select={'id_plus_one': 'id+1'}).order_by('id').values_list('id', 'id_plus_one'), [ (self.a1.id, self.a1.id + 1), (self.a2.id, self.a2.id + 1), (self.a3.id, self.a3.id + 1), (self.a4.id, self.a4.id + 1), (self.a5.id, self.a5.id + 1), (self.a6.id, self.a6.id + 1), (self.a7.id, self.a7.id + 1) ], transform=identity ) args = ('name', 'article__headline', 'article__tag__name') self.assertQuerysetEqual( Author.objects.values_list(*args).order_by(*args), [ (self.au1.name, self.a1.headline, self.t1.name), (self.au1.name, self.a2.headline, self.t1.name), (self.au1.name, self.a3.headline, self.t1.name), (self.au1.name, self.a3.headline, self.t2.name), (self.au1.name, self.a4.headline, self.t2.name), (self.au2.name, self.a5.headline, self.t2.name), (self.au2.name, self.a5.headline, self.t3.name), (self.au2.name, self.a6.headline, self.t3.name), (self.au2.name, self.a7.headline, self.t3.name), ], transform=identity ) with self.assertRaises(TypeError): Article.objects.values_list('id', 'headline', flat=True)
self.assertEqual(repr(self.a1.get_next_by_pub_date()), '<Article: Article 2>') self.assertEqual(repr(self.a2.get_next_by_pub_date()), '<Article: Article 3>') self.assertEqual(repr(self.a2.get_next_by_pub_date(headline__endswith='6')), '<Article: Article 6>') self.assertEqual(repr(self.a3.get_next_by_pub_date()), '<Article: Article 7>') self.assertEqual(repr(self.a4.get_next_by_pub_date()), '<Article: Article 6>') with self.assertRaises(Article.DoesNotExist): self.a5.get_next_by_pub_date() self.assertEqual(repr(self.a6.get_next_by_pub_date()), '<Article: Article 5>') self.assertEqual(repr(self.a7.get_next_by_pub_date()), '<Article: Article 4>')
Article.objects.create(headline='Article_ with underscore', pub_date=datetime(2005, 11, 20))
self.assertQuerysetEqual( Article.objects.filter(headline__contains='Article').exclude(headline__contains='with'), [ '<Article: Article 5>', '<Article: Article 6>', '<Article: Article 4>', '<Article: Article 2>', '<Article: Article 3>', '<Article: Article 7>', '<Article: Article 1>', ] ) self.assertQuerysetEqual( Article.objects.exclude(headline__startswith="Article_"), [ '<Article: Article with \\ backslash>', '<Article: Article% with percent sign>', '<Article: Article 5>', '<Article: Article 6>', '<Article: Article 4>', '<Article: Article 2>', '<Article: Article 3>', '<Article: Article 7>', '<Article: Article 1>', ] ) self.assertQuerysetEqual( Article.objects.exclude(headline="Article 7"), [ '<Article: Article with \\ backslash>', '<Article: Article% with percent sign>', '<Article: Article_ with underscore>', '<Article: Article 5>', '<Article: Article 6>', '<Article: Article 4>', '<Article: Article 2>', '<Article: Article 3>', '<Article: Article 1>', ] )
self.assertQuerysetEqual(Article.objects.none(), []) self.assertQuerysetEqual(Article.objects.none().filter(headline__startswith='Article'), []) self.assertQuerysetEqual(Article.objects.filter(headline__startswith='Article').none(), []) self.assertEqual(Article.objects.none().count(), 0) self.assertEqual(Article.objects.none().update(headline="This should not take effect"), 0) self.assertQuerysetEqual([article for article in Article.objects.none().iterator()], [])
self.assertQuerysetEqual(Article.objects.filter(id__in=[]), []) self.assertQuerysetEqual( Article.objects.exclude(id__in=[]), [ '<Article: Article 5>', '<Article: Article 6>', '<Article: Article 4>', '<Article: Article 2>', '<Article: Article 3>', '<Article: Article 7>', '<Article: Article 1>', ] )
with self.assertRaisesMessage( FieldError, "Cannot resolve keyword 'pub_date_year' into field. Choices are: " "author, author_id, headline, id, pub_date, tag" ): Article.objects.filter(pub_date_year='2005').count()
msg = 'Related Field got invalid lookup: editor' with self.assertRaisesMessage(FieldError, msg): Article.objects.filter(author__editor__name='James')
for a in Article.objects.all(): a.delete() now = datetime.now() Article.objects.create(pub_date=now, headline='f') Article.objects.create(pub_date=now, headline='fo') Article.objects.create(pub_date=now, headline='foo') Article.objects.create(pub_date=now, headline='fooo') Article.objects.create(pub_date=now, headline='hey-Foo') Article.objects.create(pub_date=now, headline='bar') Article.objects.create(pub_date=now, headline='AbBa') Article.objects.create(pub_date=now, headline='baz') Article.objects.create(pub_date=now, headline='baxZ') self.assertQuerysetEqual( Article.objects.filter(headline__regex=r'fo*'), ['<Article: f>', '<Article: fo>', '<Article: foo>', '<Article: fooo>'] ) self.assertQuerysetEqual( Article.objects.filter(headline__iregex=r'fo*'), [ '<Article: f>', '<Article: fo>', '<Article: foo>', '<Article: fooo>', '<Article: hey-Foo>', ] ) self.assertQuerysetEqual( Article.objects.filter(headline__regex=r'fo+'), ['<Article: fo>', '<Article: foo>', '<Article: fooo>'] ) self.assertQuerysetEqual( Article.objects.filter(headline__regex=r'fooo?'), ['<Article: foo>', '<Article: fooo>'] ) self.assertQuerysetEqual( Article.objects.filter(headline__regex=r'^b'), ['<Article: bar>', '<Article: baxZ>', '<Article: baz>'] ) self.assertQuerysetEqual(Article.objects.filter(headline__iregex=r'^a'), ['<Article: AbBa>']) self.assertQuerysetEqual(Article.objects.filter(headline__regex=r'z$'), ['<Article: baz>']) self.assertQuerysetEqual( Article.objects.filter(headline__iregex=r'z$'), ['<Article: baxZ>', '<Article: baz>'] ) self.assertQuerysetEqual( Article.objects.filter(headline__regex=r'ba[rz]'), ['<Article: bar>', '<Article: baz>'] ) self.assertQuerysetEqual(Article.objects.filter(headline__regex=r'ba.[RxZ]'), ['<Article: baxZ>']) self.assertQuerysetEqual( Article.objects.filter(headline__iregex=r'ba[RxZ]'), ['<Article: bar>', '<Article: baxZ>', '<Article: baz>'] )
Article.objects.create(pub_date=now, headline='foobar') Article.objects.create(pub_date=now, headline='foobaz') Article.objects.create(pub_date=now, headline='ooF') Article.objects.create(pub_date=now, headline='foobarbaz') Article.objects.create(pub_date=now, headline='zoocarfaz') Article.objects.create(pub_date=now, headline='barfoobaz') Article.objects.create(pub_date=now, headline='bazbaRFOO')
self.assertQuerysetEqual( Article.objects.filter(headline__regex=r'oo(f|b)'), [ '<Article: barfoobaz>', '<Article: foobar>', '<Article: foobarbaz>', '<Article: foobaz>', ] ) self.assertQuerysetEqual( Article.objects.filter(headline__iregex=r'oo(f|b)'), [ '<Article: barfoobaz>', '<Article: foobar>', '<Article: foobarbaz>', '<Article: foobaz>', '<Article: ooF>', ] ) self.assertQuerysetEqual( Article.objects.filter(headline__regex=r'^foo(f|b)'), ['<Article: foobar>', '<Article: foobarbaz>', '<Article: foobaz>'] )
self.assertQuerysetEqual( Article.objects.filter(headline__regex=r'b.*az'), [ '<Article: barfoobaz>', '<Article: baz>', '<Article: bazbaRFOO>', '<Article: foobarbaz>', '<Article: foobaz>', ] ) self.assertQuerysetEqual( Article.objects.filter(headline__iregex=r'b.*ar'), [ '<Article: bar>', '<Article: barfoobaz>', '<Article: bazbaRFOO>', '<Article: foobar>', '<Article: foobarbaz>', ] )
now = datetime.now() Article.objects.create(pub_date=now, headline='foobar') Article.objects.create(pub_date=now, headline='foobaz') Article.objects.create(pub_date=now, headline='ooF') Article.objects.create(pub_date=now, headline='foobarbaz') Article.objects.create(pub_date=now, headline='zoocarfaz') Article.objects.create(pub_date=now, headline='barfoobaz') Article.objects.create(pub_date=now, headline='bazbaRFOO') self.assertQuerysetEqual( Article.objects.filter(headline__regex=r'b(.).*b\1'), ['<Article: barfoobaz>', '<Article: bazbaRFOO>', '<Article: foobarbaz>'] )
season_2009 = Season.objects.create(year=2009, gt=111) season_2009.games.create(home="Houston Astros", away="St. Louis Cardinals") season_2010 = Season.objects.create(year=2010, gt=222) season_2010.games.create(home="Houston Astros", away="Chicago Cubs") season_2010.games.create(home="Houston Astros", away="Milwaukee Brewers") season_2010.games.create(home="Houston Astros", away="St. Louis Cardinals") season_2011 = Season.objects.create(year=2011, gt=333) season_2011.games.create(home="Houston Astros", away="St. Louis Cardinals") season_2011.games.create(home="Houston Astros", away="Milwaukee Brewers") hunter_pence = Player.objects.create(name="Hunter Pence") hunter_pence.games.set(Game.objects.filter(season__year__in=[2009, 2010])) pudge = Player.objects.create(name="Ivan Rodriquez") pudge.games.set(Game.objects.filter(season__year=2009)) pedro_feliz = Player.objects.create(name="Pedro Feliz") pedro_feliz.games.set(Game.objects.filter(season__year__in=[2011])) johnson = Player.objects.create(name="Johnson") johnson.games.set(Game.objects.filter(season__year__in=[2011]))
self.assertEqual(Game.objects.filter(season__year=2010).count(), 3) self.assertEqual(Game.objects.filter(season__year__exact=2010).count(), 3) self.assertEqual(Game.objects.filter(season__gt=222).count(), 3) self.assertEqual(Game.objects.filter(season__gt__exact=222).count(), 3)
self.assertEqual(Game.objects.filter(season__year=2011).count(), 2) self.assertEqual(Game.objects.filter(season__year__exact=2011).count(), 2) self.assertEqual(Game.objects.filter(season__gt=333).count(), 2) self.assertEqual(Game.objects.filter(season__gt__exact=333).count(), 2) self.assertEqual(Game.objects.filter(season__year__gt=2010).count(), 2) self.assertEqual(Game.objects.filter(season__gt__gt=222).count(), 2)
self.assertEqual(Game.objects.filter(season__year__in=[2010, 2011]).count(), 5) self.assertEqual(Game.objects.filter(season__year__gt=2009).count(), 5) self.assertEqual(Game.objects.filter(season__gt__in=[222, 333]).count(), 5) self.assertEqual(Game.objects.filter(season__gt__gt=111).count(), 5)
self.assertEqual(Player.objects.filter(games__season__year=2009).distinct().count(), 2) self.assertEqual(Player.objects.filter(games__season__year__exact=2009).distinct().count(), 2) self.assertEqual(Player.objects.filter(games__season__gt=111).distinct().count(), 2) self.assertEqual(Player.objects.filter(games__season__gt__exact=111).distinct().count(), 2)
self.assertEqual(Player.objects.filter(games__season__year=2010).distinct().count(), 1) self.assertEqual(Player.objects.filter(games__season__year__exact=2010).distinct().count(), 1) self.assertEqual(Player.objects.filter(games__season__gt=222).distinct().count(), 1) self.assertEqual(Player.objects.filter(games__season__gt__exact=222).distinct().count(), 1)
self.assertEqual(Player.objects.filter(games__season__year=2011).distinct().count(), 2) self.assertEqual(Player.objects.filter(games__season__year__exact=2011).distinct().count(), 2) self.assertEqual(Player.objects.filter(games__season__gt=333).distinct().count(), 2) self.assertEqual(Player.objects.filter(games__season__year__gt=2010).distinct().count(), 2) self.assertEqual(Player.objects.filter(games__season__gt__gt=222).distinct().count(), 2)
with connection.cursor() as cursor: cursor.execute( "CREATE TEMPORARY TABLE myisam_article (" " id INTEGER PRIMARY KEY AUTO_INCREMENT, " " headline VARCHAR(100) NOT NULL " ") ENGINE MYISAM") dr = MyISAMArticle.objects.create(headline='Django Reinhardt') MyISAMArticle.objects.create(headline='Ringo Star') cursor.execute( 'CREATE FULLTEXT INDEX myisam_article_ft ON myisam_article (headline)') self.assertQuerysetEqual( MyISAMArticle.objects.filter(headline__search='Reinhardt'), [dr], lambda x: x)
self.al1 = Alarm.objects.create(desc='Early', time='05:30') self.al2 = Alarm.objects.create(desc='Late', time='10:00') self.al3 = Alarm.objects.create(desc='Precise', time='12:34:56')
from __future__ import unicode_literals
with warnings.catch_warnings(): warnings.filterwarnings("ignore", category=UnicodeWarning) CsrfViewMiddleware().process_view(req, token_view, (), {}) resp = token_view(req) resp2 = CsrfViewMiddleware().process_response(req, resp) csrf_cookie = resp2.cookies.get(settings.CSRF_COOKIE_NAME, False) self.assertEqual(len(csrf_cookie.value), CSRF_TOKEN_LENGTH) self.assertNotEqual(csrf_cookie.value, token)
with self.settings(CSRF_COOKIE_NAME='myname', CSRF_COOKIE_DOMAIN='.example.com', CSRF_COOKIE_PATH='/test/', CSRF_COOKIE_SECURE=True, CSRF_COOKIE_HTTPONLY=True): CsrfViewMiddleware().process_view(req, token_view, (), {}) resp = token_view(req) resp2 = CsrfViewMiddleware().process_response(req, resp) csrf_cookie = resp2.cookies.get('myname', False) self.assertNotEqual(csrf_cookie, False) self.assertEqual(csrf_cookie['domain'], '.example.com') self.assertEqual(csrf_cookie['secure'], True) self.assertEqual(csrf_cookie['httponly'], True) self.assertEqual(csrf_cookie['path'], '/test/') self.assertIn('Cookie', resp2.get('Vary', ''))
req = self._get_GET_no_csrf_cookie_request() CsrfViewMiddleware().process_view(req, non_token_view_using_request_processor, (), {}) resp = non_token_view_using_request_processor(req) resp2 = CsrfViewMiddleware().process_response(req, resp)
req.META['HTTP_REFERER'] = '' response = CsrfViewMiddleware().process_view(req, post_form_view, (), {}) self.assertContains(response, malformed_referer_msg, status_code=403) req.META['HTTP_REFERER'] = b'\xd8B\xf6I\xdf' response = CsrfViewMiddleware().process_view(req, post_form_view, (), {}) self.assertContains(response, malformed_referer_msg, status_code=403) req.META['HTTP_REFERER'] = '//example.com/' response = CsrfViewMiddleware().process_view(req, post_form_view, (), {}) self.assertContains(response, malformed_referer_msg, status_code=403) req.META['HTTP_REFERER'] = 'https://' response = CsrfViewMiddleware().process_view(req, post_form_view, (), {}) self.assertContains(response, malformed_referer_msg, status_code=403)
req = self._get_POST_request_with_token() req._is_secure_override = True req.META['HTTP_HOST'] = 'www.example.com' req.META['HTTP_REFERER'] = 'https://www.example.com' req2 = CsrfViewMiddleware().process_view(req, post_form_view, (), {}) self.assertIsNone(req2)
return HttpResponse(content="")
return HttpResponse(content="")
return HttpResponse(content="")
CsrfViewMiddleware().process_view(req, token_view, (), {}) resp = token_view(req)
CsrfViewMiddleware().process_view(req, token_view, (), {}) resp = token_view(req)
class NestedForeignKeysTests(TestCase): def setUp(self): self.director = Person.objects.create(name='Terry Gilliam / Terry Jones') self.movie = Movie.objects.create(title='Monty Python and the Holy Grail', director=self.director)
def test_inheritance(self): Event.objects.create() Screening.objects.create(movie=self.movie)
self.assertEqual(len(Event.objects.select_related('screening__movie')), 2)
self.assertEqual(len(Event.objects.values('screening__movie__pk', 'screening__movie__title')), 2)
self.assertEqual(Event.objects.filter(screening__movie=self.movie).count(), 1) self.assertEqual(Event.objects.exclude(screening__movie=self.movie).count(), 1)
def test_inheritance_null_FK(self): Event.objects.create() ScreeningNullFK.objects.create(movie=None) ScreeningNullFK.objects.create(movie=self.movie)
def test_explicit_ForeignKey(self): Package.objects.create() screening = Screening.objects.create(movie=self.movie) Package.objects.create(screening=screening)
self.assertEqual(len(Package.objects.values('screening__movie__pk', 'screening__movie__title')), 2)
def test_explicit_ForeignKey_NullFK(self): PackageNullFK.objects.create() screening = ScreeningNullFK.objects.create(movie=None) screening_with_movie = ScreeningNullFK.objects.create(movie=self.movie) PackageNullFK.objects.create(screening=screening) PackageNullFK.objects.create(screening=screening_with_movie)
class DeeplyNestedForeignKeysTests(TestCase): def setUp(self): self.director = Person.objects.create(name='Terry Gilliam / Terry Jones') self.movie = Movie.objects.create(title='Monty Python and the Holy Grail', director=self.director)
from __future__ import unicode_literals
try: func() except expected_exc: pass except Exception as e: self.fail("No %s exception should have been raised for %s." % ( e.__class__.__name__, func.__name__))
@skipUnlessDBFeature("__class__") def test_func(): raise ValueError
with self.assertRaises(ValueError): self.assertQuerysetEqual( Person.objects.all(), [repr(self.p1), repr(self.p2)] ) self.assertQuerysetEqual( Person.objects.filter(name='p1'), [repr(self.p1)] )
dom1 = parse_html('<p>foo') dom2 = parse_html('<p>foo</p>') self.assertIn(dom1, dom2) self.assertIn(dom2, dom1)
dom1 = parse_html('<p>foo</p><p>bar</p>') dom2 = parse_html('<p>foo</p><p>bar</p>') self.assertIn(dom1, dom2) dom1 = parse_html('<p>foo</p>') self.assertIn(dom1, dom2) dom1 = parse_html('<p>bar</p>') self.assertIn(dom1, dom2)
dom1 = parse_html('<p>foo') dom2 = parse_html('<p>foo</p>') self.assertEqual(dom1.count(dom2), 1) self.assertEqual(dom2.count(dom1), 1)
def __call__(self, result=None): with self.assertNumQueries(0): super(SkippingExtraTests, self).__call__(result)
with self.assertRaisesMessage(AssertionError, msg): with self.assertRaisesMessage(ValueError, "Expected message"): raise ValueError("Unexpected message")
def func(): raise ValueError("Unexpected message")
def func1(): raise ValueError("[.*x+]y?")
pass
raise cls.MyException()
self.assertFalse(self._in_atomic_block)
self.available_apps = None
self._fixture_teardown() call_command.assert_called_with( 'flush', interactive=False, allow_cascade=False, reset_sequences=False, inhibit_post_migrate=True, database='default', verbosity=0, )
self.assertLess(ordered_sigs.index('s2'), ordered_sigs.index('s1')) self.assertLess(ordered_sigs.index('s3'), ordered_sigs.index('s2'))
self.assertLess(ordered_sigs.index('s3'), ordered_sigs.index('s1'))
self.assertLess(ordered_sigs.index('s2'), ordered_sigs.index('s1')) self.assertLess(ordered_sigs.index('s4'), ordered_sigs.index('s1')) self.assertLess(ordered_sigs.index('s3'), ordered_sigs.index('s2')) self.assertLess(ordered_sigs.index('s3'), ordered_sigs.index('s4'))
self.assertLess(ordered_sigs.index('s3'), ordered_sigs.index('s1'))
raw = [ ('s1', ('s1_db', ['bravo', 'alpha'])) ]
self.assertTrue(other.features.supports_transactions, msg) self.assertTrue(connections_support_transactions(), msg)
old_name = settings.DATABASES[db.DEFAULT_DB_ALIAS]["NAME"] with mock.patch('django.db.connections', new=tested_connections): tested_connections['default'].creation.destroy_test_db(old_name, verbosity=0, keepdb=True) self.assertEqual(tested_connections['default'].settings_dict["NAME"], old_name)
x.format('' if sys.version_info < (3, 5) else 'TestDebugSQL.') for x in [ 'runTest (test_runner.test_debug_sql.{}FailingTest) ... FAIL', 'runTest (test_runner.test_debug_sql.{}ErrorTest) ... ERROR', 'runTest (test_runner.test_debug_sql.{}PassingTest) ... ok', ]
self.assertIn('DocTestCase', [t.__class__.__name__ for t in suite._tests[2:]])
from .article import Article from .publication import Publication
class Category(models.Model): name = models.CharField(max_length=50)
class EpisodePermanent(Episode): pass
from __future__ import unicode_literals
@override_settings(DEBUG=True, ROOT_URLCONF='generic_inline_admin.urls') class GenericAdminViewTest(TestDataMixin, TestCase):
"generic_inline_admin-media-content_type-object_id-TOTAL_FORMS": "1", "generic_inline_admin-media-content_type-object_id-INITIAL_FORMS": "0", "generic_inline_admin-media-content_type-object_id-MAX_NUM_FORMS": "0",
"generic_inline_admin-media-content_type-object_id-TOTAL_FORMS": "3", "generic_inline_admin-media-content_type-object_id-INITIAL_FORMS": "2", "generic_inline_admin-media-content_type-object_id-MAX_NUM_FORMS": "0", "generic_inline_admin-media-content_type-object_id-0-id": "%d" % self.mp3_media_pk, "generic_inline_admin-media-content_type-object_id-0-url": "http://example.com/podcast.mp3", "generic_inline_admin-media-content_type-object_id-1-id": "%d" % self.png_media_pk, "generic_inline_admin-media-content_type-object_id-1-url": "http://example.com/logo.png", "generic_inline_admin-media-content_type-object_id-2-id": "", "generic_inline_admin-media-content_type-object_id-2-url": "",
formset = EpisodeMediaFormSet(instance=e) self.assertEqual(len(formset.forms), 5) self.assertHTMLEqual( formset.forms[0].as_p(), '<p><label for="id_generic_inline_admin-media-content_type-object_id-0-url">' 'Url:</label> <input id="id_generic_inline_admin-media-content_type-object_id-0-url" ' 'type="url" name="generic_inline_admin-media-content_type-object_id-0-url" ' 'value="http://example.com/podcast.mp3" maxlength="200" />' '<input type="hidden" name="generic_inline_admin-media-content_type-object_id-0-id" ' 'value="%s" id="id_generic_inline_admin-media-content_type-object_id-0-id" /></p>' % self.mp3_media_pk ) self.assertHTMLEqual( formset.forms[1].as_p(), '<p><label for="id_generic_inline_admin-media-content_type-object_id-1-url">' 'Url:</label> <input id="id_generic_inline_admin-media-content_type-object_id-1-url" ' 'type="url" name="generic_inline_admin-media-content_type-object_id-1-url" ' 'value="http://example.com/logo.png" maxlength="200" />' '<input type="hidden" name="generic_inline_admin-media-content_type-object_id-1-id" ' 'value="%s" id="id_generic_inline_admin-media-content_type-object_id-1-id" /></p>' % self.png_media_pk ) self.assertHTMLEqual( formset.forms[2].as_p(), '<p><label for="id_generic_inline_admin-media-content_type-object_id-2-url">Url:</label>' '<input id="id_generic_inline_admin-media-content_type-object_id-2-url" type="url" ' 'name="generic_inline_admin-media-content_type-object_id-2-url" maxlength="200" />' '<input type="hidden" name="generic_inline_admin-media-content_type-object_id-2-id" ' 'id="id_generic_inline_admin-media-content_type-object_id-2-id" /></p>' )
formset = EpisodeMediaFormSet(instance=e, queryset=Media.objects.order_by('url')) self.assertEqual(len(formset.forms), 5) self.assertHTMLEqual( formset.forms[0].as_p(), '<p><label for="id_generic_inline_admin-media-content_type-object_id-0-url">Url:</label>' '<input id="id_generic_inline_admin-media-content_type-object_id-0-url" type="url" ' 'name="generic_inline_admin-media-content_type-object_id-0-url"' 'value="http://example.com/logo.png" maxlength="200" />' '<input type="hidden" name="generic_inline_admin-media-content_type-object_id-0-id" ' 'value="%s" id="id_generic_inline_admin-media-content_type-object_id-0-id" /></p>' % self.png_media_pk ) self.assertHTMLEqual( formset.forms[1].as_p(), '<p><label for="id_generic_inline_admin-media-content_type-object_id-1-url">Url:</label>' '<input id="id_generic_inline_admin-media-content_type-object_id-1-url" type="url" ' 'name="generic_inline_admin-media-content_type-object_id-1-url" ' 'value="http://example.com/podcast.mp3" maxlength="200" />' '<input type="hidden" name="generic_inline_admin-media-content_type-object_id-1-id" ' 'value="%s" id="id_generic_inline_admin-media-content_type-object_id-1-id" /></p>' % self.mp3_media_pk ) self.assertHTMLEqual( formset.forms[2].as_p(), '<p><label for="id_generic_inline_admin-media-content_type-object_id-2-url">' 'Url:</label> <input id="id_generic_inline_admin-media-content_type-object_id-2-url" ' 'type="url" name="generic_inline_admin-media-content_type-object_id-2-url" maxlength="200" />' '<input type="hidden" name="generic_inline_admin-media-content_type-object_id-2-id" ' 'id="id_generic_inline_admin-media-content_type-object_id-2-id" /></p>' )
formset = EpisodeMediaFormSet(instance=e, queryset=Media.objects.filter(url__endswith=".png")) self.assertEqual(len(formset.forms), 4) self.assertHTMLEqual( formset.forms[0].as_p(), '<p><label for="id_generic_inline_admin-media-content_type-object_id-0-url">Url:</label>' ' <input id="id_generic_inline_admin-media-content_type-object_id-0-url" type="url" ' 'name="generic_inline_admin-media-content_type-object_id-0-url" ' 'value="http://example.com/logo.png" maxlength="200" />' '<input type="hidden" name="generic_inline_admin-media-content_type-object_id-0-id" ' 'value="%s" id="id_generic_inline_admin-media-content_type-object_id-0-id" /></p>' % self.png_media_pk ) self.assertHTMLEqual( formset.forms[1].as_p(), '<p><label for="id_generic_inline_admin-media-content_type-object_id-1-url">' 'Url:</label> <input id="id_generic_inline_admin-media-content_type-object_id-1-url" ' 'type="url" name="generic_inline_admin-media-content_type-object_id-1-url" maxlength="200" />' '<input type="hidden" name="generic_inline_admin-media-content_type-object_id-1-id" ' 'id="id_generic_inline_admin-media-content_type-object_id-1-id" /></p>' )
inline_formset = generic_inlineformset_factory(Media, exclude=('url',))
e = Episode.objects.get(name='This Week in Django') formset = inline_formset(instance=e) self.assertTrue(formset.get_queryset().ordered)
"generic_inline_admin-phonenumber-content_type-object_id-TOTAL_FORMS": "1", "generic_inline_admin-phonenumber-content_type-object_id-INITIAL_FORMS": "0", "generic_inline_admin-phonenumber-content_type-object_id-MAX_NUM_FORMS": "0", "generic_inline_admin-phonenumber-content_type-object_id-0-id": "", "generic_inline_admin-phonenumber-content_type-object_id-0-phone_number": "555-555-5555", "generic_inline_admin-phonenumber-content_type-object_id-0-category": "%s" % category_id,
formset = media_inline.get_formset(request) self.assertEqual(formset.max_num, DEFAULT_MAX_NUM) self.assertEqual(formset.can_order, False)
formset = media_inline.get_formset(request, max_num=100, can_order=True) self.assertEqual(formset.max_num, 100) self.assertEqual(formset.can_order, True)
class MediaForm(ModelForm): class Meta: model = Media fields = '__all__'
assert self.author.name is not None
alt_editor = models.ForeignKey(Editor, models.SET_NULL, blank=True, null=True) title = models.CharField(max_length=100)
lat = models.CharField(max_length=100) lon = models.CharField(max_length=100)
@python_2_unicode_compatible class Repository(models.Model): name = models.CharField(max_length=25)
class Person(models.Model): name = models.CharField(max_length=128)
class Team(models.Model): name = models.CharField(max_length=100)
@python_2_unicode_compatible class Poet(models.Model): name = models.CharField(max_length=100)
class UUIDPKParent(models.Model): uuid = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False) name = models.CharField(max_length=255)
data = { 'form-TOTAL_FORMS': '3', 'form-INITIAL_FORMS': '1', 'form-MAX_NUM_FORMS': '0', 'form-0-id': six.text_type(poet.id), 'form-0-name': 'test', 'form-1-id': '',
self.assertEqual(formset.is_valid(), False) self.assertEqual(Poet.objects.count(), 1)
data['form-0-DELETE'] = 'on' data['form-1-DELETE'] = 'on' data['form-2-DELETE'] = 'on' formset = PoetFormSet(data, queryset=Poet.objects.all()) self.assertEqual(formset.is_valid(), True) formset.save() self.assertEqual(Poet.objects.count(), 0)
self.assertEqual(formset.is_valid(), False) self.assertEqual(Poet.objects.count(), 1)
data['form-0-DELETE'] = 'on' formset = PoetFormSet(data, queryset=Poet.objects.all()) self.assertEqual(formset.is_valid(), True) formset.save() self.assertEqual(Poet.objects.count(), 0)
data = { 'form-TOTAL_FORMS': '2', 'form-INITIAL_FORMS': '2', 'form-0-id': str(poem.pk), 'form-0-name': 'foo',
self.assertTrue(formset.is_valid())
self.assertEqual(Poem.objects.get(pk=poem.pk).name, "foo") self.assertEqual(poet.poem_set.count(), 1) self.assertFalse(Poem.objects.filter(pk=poem.pk + 1).exists())
saved = formset.save() self.assertEqual(len(saved), 1) author3 = saved[0] self.assertEqual(author3, Author.objects.get(name='Paul Verlaine'))
qs = Author.objects.none()
Author.objects.create(name='Charles Baudelaire') qs = Author.objects.all()
author = super(PoetForm, self).save(commit=False) author.name = "Vladimir Mayakovsky" if commit: author.save() return author
self.assertQuerysetEqual(author.book_set.order_by('title'), [ '<Book: Les Fleurs du Mal>', '<Book: Les Paradis Artificiels>', ])
AuthorBooksFormSet = inlineformset_factory(Author, Book, can_delete=False, extra=2, fields="__all__") Author.objects.create(name='Charles Baudelaire')
self.maxDiff = 1024
poem = super(PoemForm, self).save(commit=False) poem.name = "Brooklyn Bridge" if commit: poem.save() return poem
poet.name = 'Lamartine' poet.save() poem = formset.save()[0] self.assertEqual(poem.name, 'Le Lac by Lamartine')
FormSet = modelformset_factory(Price, fields="__all__", extra=1, max_num=1) formset = FormSet(data) self.assertTrue(formset.is_valid())
data = { 'revision_set-TOTAL_FORMS': '1', 'revision_set-INITIAL_FORMS': '0', 'revision_set-MAX_NUM_FORMS': '', 'revision_set-0-repository': repository.pk, 'revision_set-0-revision': '146239817507f148d448db38840db7c3cbf47c76', 'revision_set-0-DELETE': '', } formset = FormSet(data, instance=repository) self.assertFalse(formset.is_valid()) self.assertEqual(formset.errors, [{'__all__': ['Revision with this Repository and Revision already exists.']}])
team = Team.objects.create(name="Red Vipers") Player(name="Timmy").save() Player(name="Bobby", team=team).save()
FormSet = modelformset_factory(ClassyMexicanRestaurant, fields=["tacos_are_yummy"]) self.assertEqual(sorted(FormSet().forms[0].fields.keys()), ['restaurant', 'tacos_are_yummy'])
FormSet = modelformset_factory(Poem, fields='__all__') john_milton = Poet(name="John Milton") john_milton.save() data = { 'form-TOTAL_FORMS': 1, 'form-INITIAL_FORMS': 0, 'form-MAX_NUM_FORMS': '', 'form-0-name': '', 'form-0-poet': str(john_milton.id), } formset = FormSet(initial=[{'poet': john_milton}], data=data) self.assertFalse(formset.extra_forms[0].has_changed())
FormSet = modelformset_factory(AuthorMeeting, fields='__all__') Author.objects.create(pk=1, name='Charles Baudelaire') data = { 'form-TOTAL_FORMS': 1, 'form-INITIAL_FORMS': 0, 'form-MAX_NUM_FORMS': '', 'form-0-name': '', 'form-0-created': '', 'form-0-authors': list(Author.objects.values_list('id', flat=True)), } formset = FormSet(initial=[{'authors': Author.objects.all()}], data=data) self.assertFalse(formset.extra_forms[0].has_changed())
FormSet = modelformset_factory(Price, fields=("price",), extra=2) data = { 'form-TOTAL_FORMS': '2', 'form-INITIAL_FORMS': '0', 'form-MAX_NUM_FORMS': '', 'form-0-price': '24', 'form-1-price': '24', } formset = FormSet(data) self.assertTrue(formset.is_valid())
from __future__ import unicode_literals
field_field_0 = models.IntegerField(db_column='Field_') field_field_1 = models.IntegerField(db_column='Field__') field_field_2 = models.IntegerField(db_column='__field') prc_x = models.IntegerField(db_column='prc(%) x') non_ascii = models.IntegerField(db_column='tamao')
from __future__ import unicode_literals
call_command('inspectdb', table_name_filter=lambda tn: tn.startswith('inspectdb_'), stdout=out) error_message = "inspectdb has examined a table that should have been filtered out." self.assertNotIn("class DjangoContentType(models.Model):", out.getvalue(), msg=error_message)
if (connection.features.can_introspect_max_length and not connection.features.interprets_empty_strings_as_nulls): assertFieldType('char_field', "models.CharField(max_length=10)") assertFieldType('null_char_field', "models.CharField(max_length=10, blank=True, null=True)") assertFieldType('comma_separated_int_field', "models.CharField(max_length=99)") assertFieldType('date_field', "models.DateField()") assertFieldType('date_time_field', "models.DateTimeField()") if (connection.features.can_introspect_max_length and not connection.features.interprets_empty_strings_as_nulls): assertFieldType('email_field', "models.CharField(max_length=254)") assertFieldType('file_field', "models.CharField(max_length=100)") assertFieldType('file_path_field', "models.CharField(max_length=100)") if connection.features.can_introspect_ip_address_field: assertFieldType('gen_ip_adress_field', "models.GenericIPAddressField()") elif (connection.features.can_introspect_max_length and not connection.features.interprets_empty_strings_as_nulls): assertFieldType('gen_ip_adress_field', "models.CharField(max_length=39)") if (connection.features.can_introspect_max_length and not connection.features.interprets_empty_strings_as_nulls): assertFieldType('slug_field', "models.CharField(max_length=50)") if not connection.features.interprets_empty_strings_as_nulls: assertFieldType('text_field', "models.TextField()") if connection.features.can_introspect_time_field: assertFieldType('time_field', "models.TimeField()") if (connection.features.can_introspect_max_length and not connection.features.interprets_empty_strings_as_nulls): assertFieldType('url_field', "models.CharField(max_length=200)")
call_command('inspectdb', table_name_filter=lambda tn: tn.startswith('inspectdb_'), stdout=out) output = out.getvalue() error_message = "inspectdb generated an attribute name which is a python keyword" self.assertIn("parent = models.ForeignKey('self', models.DO_NOTHING)", output) self.assertNotIn( "from = models.ForeignKey(InspectdbPeople, models.DO_NOTHING)", output, msg=error_message, ) self.assertIn( "from_field = models.ForeignKey('InspectdbPeople', models.DO_NOTHING, db_column='from_id')", output, ) self.assertIn( "people_pk = models.ForeignKey(InspectdbPeople, models.DO_NOTHING, primary_key=True)", output, ) self.assertIn( "people_unique = models.ForeignKey(InspectdbPeople, models.DO_NOTHING, unique=True)", output, )
call_command('inspectdb', table_name_filter=lambda tn: tn.startswith('inspectdb_'), stdout=out) output = out.getvalue() error_message = "inspectdb generated a model field name which is a number" self.assertNotIn(" 123 = models.CharField", output, msg=error_message) self.assertIn("number_123 = models.CharField", output)
self.assertIn("tamao = models.IntegerField()", output)
self.assertEqual(len(unique_together_match), 1) fields = unique_together_match[0] self.assertIn("('field1', 'field2')", fields) self.assertIn("('field1', 'field2')", fields) self.assertIn("('non_unique_column', 'non_unique_column_0')", fields)
qsets = ( ( Staff.objects.distinct().order_by('name'), ['<Staff: p1>', '<Staff: p1>', '<Staff: p2>', '<Staff: p3>'], ), ( Staff.objects.distinct('name').order_by('name'), ['<Staff: p1>', '<Staff: p2>', '<Staff: p3>'], ), ( Staff.objects.distinct('organisation').order_by('organisation', 'name'), ['<Staff: p1>', '<Staff: p1>'], ), ( Staff.objects.distinct('name', 'organisation').order_by('name', 'organisation'), ['<Staff: p1>', '<Staff: p1>', '<Staff: p2>', '<Staff: p3>'], ), ( Celebrity.objects.filter(fan__in=[self.fan1, self.fan2, self.fan3]).distinct('name').order_by('name'), ['<Celebrity: c1>', '<Celebrity: c2>'], ), ( (Celebrity.objects.filter(fan__in=[self.fan1, self.fan2]). distinct('name').order_by('name') | Celebrity.objects.filter(fan__in=[self.fan3]). distinct('name').order_by('name')), ['<Celebrity: c1>', '<Celebrity: c2>'], ), ( StaffTag.objects.distinct('staff', 'tag'), ['<StaffTag: t1 -> p1>'], ), ( Tag.objects.order_by('parent__pk', 'pk').distinct('parent'), ['<Tag: t2>', '<Tag: t4>', '<Tag: t1>'], ), ( StaffTag.objects.select_related('staff').distinct('staff__name').order_by('staff__name'), ['<StaffTag: t1 -> p1>'], ), ( (Staff.objects.distinct('id').order_by('id', 'coworkers__name'). values_list('id', 'coworkers__name')), [str_prefix("(1, %(_)s'p2')"), str_prefix("(2, %(_)s'p1')"), str_prefix("(3, %(_)s'p1')"), "(4, None)"] ), ) for qset, expected in qsets: self.assertQuerysetEqual(qset, expected) self.assertEqual(qset.count(), len(expected))
base_qs = Celebrity.objects.all() with self.assertRaisesMessage(AssertionError, "Cannot combine queries with different distinct fields."): base_qs.distinct('id') & base_qs.distinct('name')
c1 = Celebrity.objects.distinct('greatest_fan__id', 'greatest_fan__fan_of') self.assertIn('OUTER JOIN', str(c1.query)) c2 = c1.distinct('pk') self.assertNotIn('OUTER JOIN', str(c2.query))
with self.assertRaises(NotImplementedError): Celebrity.objects.annotate(Max('id')).distinct('id')[0] with self.assertRaises(NotImplementedError): Celebrity.objects.distinct('id').annotate(Max('id'))[0]
Celebrity.objects.distinct('id').annotate(Max('id')).distinct()[0] with self.assertRaises(NotImplementedError): Celebrity.objects.distinct('id').aggregate(Max('id'))
from __future__ import unicode_literals
name = '"SOME%NAME"' quoted_name = connection.ops.quote_name(name) self.assertEqual(quoted_name % (), name)
from django.db.backends.oracle.base import convert_unicode
from django.db.backends.oracle.base import Database
with connection.cursor() as cursor: cursor.execute('CREATE TABLE ltext ("TEXT" NCLOB)') long_str = ''.join(six.text_type(x) for x in range(4000)) cursor.execute('INSERT INTO ltext VALUES (%s)', [long_str]) cursor.execute('SELECT text FROM ltext') row = cursor.fetchone() self.assertEqual(long_str, row[0].read()) cursor.execute('DROP TABLE ltext')
connection.ensure_connection() self.assertEqual(connection.connection.encoding, "UTF-8") self.assertEqual(connection.connection.nencoding, "UTF-8")
with connection.cursor() as cursor: query = "select 1 from dual where '1936-12-29 00:00' < sysdate" cursor.execute(query) self.assertEqual(cursor.fetchone()[0], 1)
with warnings.catch_warnings(record=True) as w: with mock.patch('django.db.backends.base.base.BaseDatabaseWrapper.connect', side_effect=mocked_connect, autospec=True): warnings.simplefilter('always', RuntimeWarning) nodb_conn = connection._nodb_connection self.assertIsNotNone(nodb_conn.settings_dict['NAME']) self.assertEqual(nodb_conn.settings_dict['NAME'], connection.settings_dict['NAME']) self.assertEqual(len(w), 1) self.assertEqual(w[0].message.__class__, RuntimeWarning)
class CursorMock(object): "Very simple mock of DB-API cursor" def execute(self, arg): pass
conn = OlderConnectionMock() self.assertEqual(pg_version.get_version(conn), 90300)
cursor = new_connection.cursor() cursor.execute("RESET TIMEZONE") cursor.execute("SHOW TIMEZONE") db_default_tz = cursor.fetchone()[0] new_tz = 'Europe/Paris' if db_default_tz == 'UTC' else 'UTC' new_connection.close()
del new_connection.timezone_name
with self.settings(TIME_ZONE=new_tz): new_connection.set_autocommit(False) cursor = new_connection.cursor() new_connection.rollback()
cursor.execute("SHOW TIMEZONE") tz = cursor.fetchone()[0] self.assertEqual(new_tz, tz)
new_connection.cursor() self.assertFalse(new_connection.get_autocommit())
self.assertEqual(connection.connection.isolation_level, read_committed)
new_connection.set_autocommit(False) self.assertEqual(new_connection.connection.isolation_level, serializable)
query = "SELECT strftime('%Y', 'now');" connection.cursor().execute(query) self.assertEqual(connection.queries[-1]['sql'], query)
query = "SELECT %s" params = ["\"'\\"] connection.cursor().execute(query, params) substituted = "SELECT '\"''\\'" self.assertEqual(connection.queries[-1]['sql'], substituted)
cursor = connection.cursor() sql = "SELECT MAX(%s)" % ", ".join(["%s"] * 2001) params = list(range(2001)) cursor.db.ops.last_executed_query(cursor.cursor, sql, params)
VLM = models.VeryLongModelNameZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZ VLM_m2m = VLM.m2m_also_quite_long_zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz.through tables = [ VLM._meta.db_table, VLM_m2m._meta.db_table, ] sequences = [ { 'column': VLM._meta.pk.column, 'table': VLM._meta.db_table }, ] cursor = connection.cursor() for statement in connection.ops.sql_flush(no_style(), tables, sequences): cursor.execute(statement)
models.Post.objects.create(id=10, name='1st post', text='hello world')
cursor = connection.cursor() commands = connections[DEFAULT_DB_ALIAS].ops.sequence_reset_sql(no_style(), [models.Post]) for sql in commands: cursor.execute(sql)
obj = models.Post.objects.create(name='New post', text='goodbye world') self.assertGreater(obj.pk, 10)
class ConnectionCreatedSignalTest(TransactionTestCase):
@skipUnlessDBFeature('test_db_allows_multiple_connections') def test_signal(self): data = {}
cursor = connection.cursor() cursor.execute("select strftime('%s', date('now'))") response = cursor.fetchall()[0][0] self.assertTrue(int(response))
args = [(i, i ** 2) for i in range(-5, 6)] self.create_squares_with_executemany(args) self.assertEqual(models.Square.objects.count(), 11) for i in range(-5, 6): square = models.Square.objects.get(root=i) self.assertEqual(square.square, i ** 2)
args = [] self.create_squares_with_executemany(args) self.assertEqual(models.Square.objects.count(), 0)
args = iter((i, i ** 2) for i in range(-3, 2)) self.create_squares_with_executemany(args) self.assertEqual(models.Square.objects.count(), 5)
self.create_squares_with_executemany(args)
args = {'root': 3, 'square': 9} self.create_squares(args, 'pyformat', multiple=False) self.assertEqual(models.Square.objects.count(), 1)
args = [{'root': i, 'square': i ** 2} for i in range(-5, 6)] self.create_squares(args, 'pyformat', multiple=True) self.assertEqual(models.Square.objects.count(), 11) for i in range(-5, 6): square = models.Square.objects.get(root=i) self.assertEqual(square.square, i ** 2)
self.create_squares(args, 'pyformat', multiple=True)
qn = connection.ops.quote_name models.Person(first_name="John", last_name="Doe").save() models.Person(first_name="Jane", last_name="Doe").save() models.Person(first_name="Mary", last_name="Agnelline").save() models.Person(first_name="Peter", last_name="Parker").save() models.Person(first_name="Clark", last_name="Kent").save() opts2 = models.Person._meta f3, f4 = opts2.get_field('first_name'), opts2.get_field('last_name') cursor = connection.cursor() cursor.execute( 'SELECT %s, %s FROM %s ORDER BY %s' % ( qn(f3.column), qn(f4.column), connection.introspection.table_name_converter(opts2.db_table), qn(f3.column), ) ) self.assertEqual(cursor.fetchone(), ('Clark', 'Kent')) self.assertEqual(list(cursor.fetchmany(2)), [('Jane', 'Doe'), ('John', 'Doe')]) self.assertEqual(list(cursor.fetchall()), [('Mary', 'Agnelline'), ('Peter', 'Parker')])
pass
self.assertTrue(hasattr(connection, 'ops')) self.assertTrue(hasattr(connection.ops, 'connection')) self.assertEqual(connection, connection.ops.connection)
with self.assertRaises(connection.features.closed_cursor_error_class): cursor.execute("SELECT 1" + connection.features.bare_select_suffix)
with connection.cursor() as cursor: self.assertIsInstance(cursor, CursorWrapper) self.assertTrue(cursor.closed)
with connection.cursor(): pass connection._close() try: self.assertFalse(connection.is_usable()) finally: try: connection.close() except Exception: pass
with new_connection.cursor(): pass new_connection.queries_log.clear()
class FkConstraintsTests(TransactionTestCase):
self.r = models.Reporter.objects.create(first_name='John', last_name='Smith')
a2 = models.Article(headline='This is another test', reporter=self.r, pub_date=datetime.datetime(2012, 8, 3), reporter_proxy_id=30) with self.assertRaises(IntegrityError): a2.save()
models.Article.objects.create(headline="Test article", pub_date=datetime.datetime(2010, 9, 4), reporter=self.r) a1 = models.Article.objects.get(headline="Test article") a1.reporter_id = 30 try: a1.save() except IntegrityError: pass else: self.skipTest("This backend does not support integrity checks.") r_proxy = models.ReporterProxy.objects.get(pk=self.r.pk) models.Article.objects.create(headline='Another article', pub_date=datetime.datetime(1988, 5, 15), reporter=self.r, reporter_proxy=r_proxy) a2 = models.Article.objects.get(headline='Another article') a2.reporter_proxy_id = 30 with self.assertRaises(IntegrityError): a2.save()
models.Article.objects.create( headline="Test article", pub_date=datetime.datetime(2010, 9, 4), reporter=self.r, ) a = models.Article.objects.get(headline="Test article") a.reporter_id = 30 try: connection.disable_constraint_checking() a.save() connection.enable_constraint_checking() except IntegrityError: self.fail("IntegrityError should not have occurred.") transaction.set_rollback(True)
models.Article.objects.create( headline="Test article", pub_date=datetime.datetime(2010, 9, 4), reporter=self.r, ) a = models.Article.objects.get(headline="Test article") a.reporter_id = 30 try: with connection.constraint_checks_disabled(): a.save() except IntegrityError: self.fail("IntegrityError should not have occurred.") transaction.set_rollback(True)
models.Article.objects.create( headline="Test article", pub_date=datetime.datetime(2010, 9, 4), reporter=self.r, ) a = models.Article.objects.get(headline="Test article") a.reporter_id = 30 with connection.constraint_checks_disabled(): a.save() with self.assertRaises(IntegrityError): connection.check_constraints() transaction.set_rollback(True)
connections_dict = {} connection.cursor() connections_dict[id(connection)] = connection
from django.db import connections connection = connections[DEFAULT_DB_ALIAS] connection.allow_thread_sharing = True connection.cursor() connections_dict[id(connection)] = connection
self.assertEqual( len(set(conn.connection for conn in connections_dict.values())), 3) for conn in connections_dict.values(): if conn is not connection: conn.close()
connections_dict = {} for conn in connections.all(): connections_dict[id(conn)] = conn
conn.allow_thread_sharing = True connections_dict[id(conn)] = conn
for conn in connections_dict.values(): if conn is not connection: conn.close()
exceptions = [] do_thread() self.assertIsInstance(exceptions[0], DatabaseError)
connections['default'].allow_thread_sharing = False exceptions = [] do_thread() self.assertIsInstance(exceptions[0], DatabaseError)
connections['default'].allow_thread_sharing = True exceptions = [] do_thread() self.assertEqual(exceptions, [])
exceptions = set()
self.assertEqual(len(exceptions), 1)
exceptions = set()
connections['default'].allow_thread_sharing = True t2 = threading.Thread(target=runner2, args=[connections['default']]) t2.start() t2.join()
self.assertEqual(len(exceptions), 0)
test_connection = copy.copy(connections[DEFAULT_DB_ALIAS]) test_connection.settings_dict = copy.copy(connections[DEFAULT_DB_ALIAS].settings_dict) return test_connection
prod_name = 'hodor' test_connection = self.get_connection_copy() test_connection.settings_dict['NAME'] = prod_name test_connection.settings_dict['TEST'] = {'NAME': None} signature = BaseDatabaseCreation(test_connection).test_db_signature() self.assertEqual(signature[3], TEST_DATABASE_PREFIX + prod_name)
test_name = 'hodor' test_connection = self.get_connection_copy() test_connection.settings_dict['TEST'] = {'NAME': test_name} signature = BaseDatabaseCreation(test_connection).test_db_signature() self.assertEqual(signature[3], test_name)
test_name = TEST_DATABASE_PREFIX + 'hodor' test_connection = self.get_connection_copy() test_connection.settings_dict['TEST'] = {'NAME': test_name} signature = BaseDatabaseCreation(test_connection).test_db_signature() self.assertEqual(signature[3], test_name)
class BookManager(models.Manager): def create(self, *args, **kwargs): kwargs.pop('extra_arg', None) return super(BookManager, self).create(*args, **kwargs)
Book.objects.create(title="Pro Django", published=datetime.date(2008, 12, 16))
dive = Book() dive.title = "Dive into Python" dive.published = datetime.date(2009, 5, 4) dive.save()
try: Book.objects.get(title="Pro Django") Book.objects.using('default').get(title="Pro Django") except Book.DoesNotExist: self.fail('"Pro Django" should exist on default database')
Book.objects.using('other').create(title="Pro Django", published=datetime.date(2008, 12, 16))
dive = Book() dive.title = "Dive into Python" dive.published = datetime.date(2009, 5, 4) dive.save(using='other')
try: Book.objects.using('other').get(title="Pro Django") except Book.DoesNotExist: self.fail('"Pro Django" should exist on other database')
pro = Book.objects.create(title="Pro Django", published=datetime.date(2008, 12, 16))
dive = Book.objects.using('other').create(title="Dive into Python", published=datetime.date(2009, 5, 4))
pro.authors.set([marty]) dive.authors.set([mark])
self.assertEqual(Book.authors.through.objects.using('default').count(), 1) self.assertEqual(Book.authors.through.objects.using('other').count(), 1)
self.assertEqual( list(Book.objects.using('default').filter(authors__name='Marty Alchin').values_list('title', flat=True)), ['Pro Django'] ) self.assertEqual( list(Book.objects.using('other').filter(authors__name='Marty Alchin').values_list('title', flat=True)), [] )
dive = Book.objects.using('other').get(title="Dive into Python") mark = Person.objects.using('other').get(name="Mark Pilgrim")
self.assertEqual(list(dive.authors.all().values_list('name', flat=True)), ['Mark Pilgrim'])
dive = Book.objects.using('other').create(title="Dive into Python", published=datetime.date(2009, 5, 4)) mark = Person.objects.using('other').create(name="Mark Pilgrim")
dive.authors.set([mark])
john = Person.objects.using('other').create(name="John Smith") self.assertEqual( list(Book.objects.using('other').filter(authors__name='John Smith').values_list('title', flat=True)), [] )
dive.authors.remove(john) self.assertEqual( list(Book.objects.using('other').filter(authors__name='Mark Pilgrim').values_list('title', flat=True)), ['Dive into Python'] ) self.assertEqual( list(Book.objects.using('other').filter(authors__name='John Smith').values_list('title', flat=True)), [] )
dive.authors.clear() self.assertEqual( list(Book.objects.using('other').filter(authors__name='Mark Pilgrim').values_list('title', flat=True)), [] ) self.assertEqual( list(Book.objects.using('other').filter(authors__name='John Smith').values_list('title', flat=True)), [] )
dive.authors.create(name='Jane Brown') self.assertEqual( list(Book.objects.using('other').filter(authors__name='Mark Pilgrim').values_list('title', flat=True)), [] ) self.assertEqual( list(Book.objects.using('other').filter(authors__name='Jane Brown').values_list('title', flat=True)), ['Dive into Python'] )
dive = Book.objects.using('other').create(title="Dive into Python", published=datetime.date(2009, 5, 4)) mark = Person.objects.using('other').create(name="Mark Pilgrim")
dive.authors.set([mark])
grease = Book.objects.using('other').create(title="Greasemonkey Hacks", published=datetime.date(2005, 11, 1))
mark.book_set.add(grease) self.assertEqual( list(Person.objects.using('other').filter(book__title='Dive into Python').values_list('name', flat=True)), ['Mark Pilgrim'] ) self.assertEqual( list( Person.objects.using('other').filter(book__title='Greasemonkey Hacks').values_list('name', flat=True) ), ['Mark Pilgrim'] )
mark.book_set.remove(grease) self.assertEqual( list(Person.objects.using('other').filter(book__title='Dive into Python').values_list('name', flat=True)), ['Mark Pilgrim'] ) self.assertEqual( list( Person.objects.using('other').filter(book__title='Greasemonkey Hacks').values_list('name', flat=True) ), [] )
mark.book_set.clear() self.assertEqual( list(Person.objects.using('other').filter(book__title='Dive into Python').values_list('name', flat=True)), [] ) self.assertEqual( list( Person.objects.using('other').filter(book__title='Greasemonkey Hacks').values_list('name', flat=True) ), [] )
mark.book_set.create(title="Dive into HTML5", published=datetime.date(2020, 1, 1)) self.assertEqual( list(Person.objects.using('other').filter(book__title='Dive into Python').values_list('name', flat=True)), [] ) self.assertEqual( list(Person.objects.using('other').filter(book__title='Dive into HTML5').values_list('name', flat=True)), ['Mark Pilgrim'] )
pro = Book.objects.create(title="Pro Django", published=datetime.date(2008, 12, 16))
dive = Book.objects.using('other').create(title="Dive into Python", published=datetime.date(2009, 5, 4))
with self.assertRaises(ValueError): with transaction.atomic(using='default'): marty.edited.set([pro, dive])
with self.assertRaises(ValueError): with transaction.atomic(using='default'): marty.book_set.add(dive)
with self.assertRaises(ValueError): with transaction.atomic(using='default'): marty.book_set.set([pro, dive])
with self.assertRaises(ValueError): with transaction.atomic(using='other'): dive.authors.add(marty)
with self.assertRaises(ValueError): with transaction.atomic(using='other'): dive.authors.set([mark, marty])
dive = Book.objects.using('other').create(title="Dive into Python", published=datetime.date(2009, 5, 4)) mark = Person.objects.using('other').create(name="Mark Pilgrim") dive.authors.set([mark])
self.assertEqual(Person.objects.using('default').count(), 0) self.assertEqual(Book.objects.using('default').count(), 0) self.assertEqual(Book.authors.through.objects.using('default').count(), 0)
dive.delete(using='other')
self.assertEqual(Person.objects.using('other').count(), 1) self.assertEqual(Book.objects.using('other').count(), 0) self.assertEqual(Book.authors.through.objects.using('other').count(), 0)
dive = Book.objects.using('other').create(title="Dive into Python", published=datetime.date(2009, 5, 4)) dive.authors.set([mark])
self.assertEqual(Person.objects.using('default').count(), 0) self.assertEqual(Book.objects.using('default').count(), 0) self.assertEqual(Book.authors.through.objects.using('default').count(), 0)
mark.delete(using='other')
self.assertEqual(Person.objects.using('other').count(), 0) self.assertEqual(Book.objects.using('other').count(), 1) self.assertEqual(Book.authors.through.objects.using('other').count(), 0)
pro = Book.objects.create(title="Pro Django", published=datetime.date(2008, 12, 16))
dive = Book.objects.using('other').create(title="Dive into Python", published=datetime.date(2009, 5, 4)) chris = Person.objects.using('other').create(name="Chris Mills")
pro.editor = george pro.save()
self.assertEqual( list(Person.objects.using('default').filter(edited__title='Pro Django').values_list('name', flat=True)), ['George Vilches'] ) self.assertEqual( list(Person.objects.using('other').filter(edited__title='Pro Django').values_list('name', flat=True)), [] )
chris = Person.objects.using('other').get(name="Chris Mills") dive = Book.objects.using('other').get(title="Dive into Python")
self.assertEqual(list(chris.edited.values_list('title', flat=True)), ['Dive into Python'])
dive.editor = chris dive.save()
html5 = Book.objects.using('other').create(title="Dive into HTML5", published=datetime.date(2010, 3, 15)) self.assertEqual( list(Person.objects.using('other').filter(edited__title='Dive into HTML5').values_list('name', flat=True)), [] )
chris.edited.remove(html5) self.assertEqual( list(Person.objects.using('other').filter(edited__title='Dive into HTML5').values_list('name', flat=True)), [] ) self.assertEqual( list( Person.objects.using('other').filter(edited__title='Dive into Python').values_list('name', flat=True) ), ['Chris Mills'] )
chris.edited.clear() self.assertEqual( list(Person.objects.using('other').filter(edited__title='Dive into HTML5').values_list('name', flat=True)), [] ) self.assertEqual( list( Person.objects.using('other').filter(edited__title='Dive into Python').values_list('name', flat=True) ), [] )
chris.edited.create(title='Dive into Water', published=datetime.date(2010, 3, 15)) self.assertEqual( list(Person.objects.using('other').filter(edited__title='Dive into HTML5').values_list('name', flat=True)), [] ) self.assertEqual( list(Person.objects.using('other').filter(edited__title='Dive into Water').values_list('name', flat=True)), ['Chris Mills'] ) self.assertEqual( list( Person.objects.using('other').filter(edited__title='Dive into Python').values_list('name', flat=True) ), [] )
pro = Book.objects.create(title="Pro Django", published=datetime.date(2008, 12, 16)) marty = Person.objects.create(name="Marty Alchin")
dive = Book.objects.using('other').create(title="Dive into Python", published=datetime.date(2009, 5, 4))
with self.assertRaises(ValueError): dive.editor = marty
with self.assertRaises(ValueError): with transaction.atomic(using='default'): marty.edited.set([pro, dive])
with self.assertRaises(ValueError): with transaction.atomic(using='default'): marty.edited.add(dive)
self.assertEqual(Person.objects.using('default').count(), 0) self.assertEqual(Pet.objects.using('default').count(), 0)
mark.delete(using='other')
self.assertEqual(Person.objects.using('other').count(), 0) self.assertEqual(Pet.objects.using('other').count(), 0)
alice = User.objects.db_manager('default').create_user('alice', 'alice@example.com') alice_profile = UserProfile.objects.using('default').create(user=alice, flavor='chocolate')
bob = User.objects.db_manager('other').create_user('bob', 'bob@example.com') bob_profile = UserProfile.objects.using('other').create(user=bob, flavor='crunchy frog')
alice = User.objects.using('default').get(username="alice") self.assertEqual(alice.userprofile.flavor, "chocolate")
self.assertEqual( list( User.objects.using('default') .filter(userprofile__flavor='chocolate').values_list('username', flat=True) ), ['alice'] ) self.assertEqual( list( User.objects.using('other') .filter(userprofile__flavor='chocolate').values_list('username', flat=True) ), [] )
alice_profile = UserProfile.objects.using('default').get(flavor='chocolate') bob_profile = UserProfile.objects.using('other').get(flavor='crunchy frog')
self.assertEqual(alice_profile.user.username, 'alice') self.assertEqual(bob_profile.user.username, 'bob')
alice = User.objects.db_manager('default').create_user('alice', 'alice@example.com')
bob = User.objects.db_manager('other').create_user('bob', 'bob@example.com')
alice_profile = UserProfile.objects.using('default').create(user=alice, flavor='chocolate') with self.assertRaises(ValueError): bob.userprofile = alice_profile
bob_profile = UserProfile.objects.using('other').create(user=bob, flavor='crunchy frog')
charlie = User(pk=51, username='charlie', email='charlie@example.com') charlie.set_unusable_password()
self.assertEqual(new_bob_profile._state.db, None) self.assertEqual(charlie._state.db, None)
new_bob_profile.user = bob charlie.userprofile = bob_profile self.assertEqual(new_bob_profile._state.db, 'other') self.assertEqual(charlie._state.db, 'other')
self.assertEqual(list(User.objects.using('other').values_list('username', flat=True)), ['bob']) self.assertEqual(list(UserProfile.objects.using('other').values_list('flavor', flat=True)), ['crunchy frog'])
charlie.save() bob_profile.save() new_bob_profile.save() self.assertEqual(list(User.objects.using('default').values_list('username', flat=True)), ['alice']) self.assertEqual(list(User.objects.using('other').values_list('username', flat=True)), ['bob', 'charlie']) self.assertEqual(list(UserProfile.objects.using('default').values_list('flavor', flat=True)), ['chocolate']) self.assertEqual( list(UserProfile.objects.using('other').values_list('flavor', flat=True)), ['crunchy frog', 'spring surprise'] )
denise = User.objects.db_manager('other').create_user('denise', 'denise@example.com') denise_profile = UserProfile(flavor="tofu", user=denise)
self.assertEqual(list(UserProfile.objects.using('default').values_list('flavor', flat=True)), ['chocolate']) self.assertEqual( list(UserProfile.objects.using('other').values_list('flavor', flat=True)), ['crunchy frog', 'spring surprise'] )
denise_profile.save() self.assertEqual(list(UserProfile.objects.using('default').values_list('flavor', flat=True)), ['chocolate']) self.assertEqual( list(UserProfile.objects.using('other').values_list('flavor', flat=True)), ['crunchy frog', 'spring surprise', 'tofu'] )
pro = Book.objects.create(title="Pro Django", published=datetime.date(2008, 12, 16)) review1 = Review.objects.create(source="Python Monthly", content_object=pro)
dive = Book.objects.using('other').create(title="Dive into Python", published=datetime.date(2009, 5, 4))
dive = Book.objects.using('other').get(title="Dive into Python")
self.assertEqual(list(dive.reviews.all().values_list('source', flat=True)), ['Python Weekly'])
dive.reviews.add(review2) self.assertEqual( list(Review.objects.using('default').filter(object_id=dive.pk).values_list('source', flat=True)), [] ) self.assertEqual( list(Review.objects.using('other').filter(object_id=dive.pk).values_list('source', flat=True)), ['Python Monthly', 'Python Weekly'] )
dive.reviews.remove(review1) self.assertEqual( list(Review.objects.using('default').filter(object_id=dive.pk).values_list('source', flat=True)), [] ) self.assertEqual( list(Review.objects.using('other').filter(object_id=dive.pk).values_list('source', flat=True)), ['Python Monthly'] )
dive.reviews.clear() self.assertEqual( list(Review.objects.using('default').filter(object_id=dive.pk).values_list('source', flat=True)), [] ) self.assertEqual( list(Review.objects.using('other').filter(object_id=dive.pk).values_list('source', flat=True)), [] )
dive.reviews.create(source='Python Daily') self.assertEqual( list(Review.objects.using('default').filter(object_id=dive.pk).values_list('source', flat=True)), [] ) self.assertEqual( list(Review.objects.using('other').filter(object_id=dive.pk).values_list('source', flat=True)), ['Python Daily'] )
pro = Book.objects.create(title="Pro Django", published=datetime.date(2008, 12, 16)) review1 = Review.objects.create(source="Python Monthly", content_object=pro)
dive = Book.objects.using('other').create(title="Dive into Python", published=datetime.date(2009, 5, 4))
with self.assertRaises(ValueError): review1.content_object = dive
with self.assertRaises(ValueError): with transaction.atomic(using='other'): dive.reviews.add(review1)
review3 = Review(source="Python Daily") self.assertEqual(review3._state.db, None)
review3.content_object = dive self.assertEqual(review3._state.db, 'other') self.assertEqual( list(Review.objects.using('default').filter(object_id=pro.pk).values_list('source', flat=True)), ['Python Monthly'] ) self.assertEqual( list(Review.objects.using('other').filter(object_id=dive.pk).values_list('source', flat=True)), ['Python Weekly'] )
review3.save() self.assertEqual( list(Review.objects.using('default').filter(object_id=pro.pk).values_list('source', flat=True)), ['Python Monthly'] ) self.assertEqual( list(Review.objects.using('other').filter(object_id=dive.pk).values_list('source', flat=True)), ['Python Daily', 'Python Weekly'] )
self.assertEqual(Book.objects.using('default').count(), 0) self.assertEqual(Review.objects.using('default').count(), 0)
dive.delete(using='other')
self.assertEqual(Book.objects.using('other').count(), 0) self.assertEqual(Review.objects.using('other').count(), 0)
mark = Person.objects.using('other').create(name="Mark Pilgrim") Book.objects.using('other').create( title="Dive into Python", published=datetime.date(2009, 5, 4), editor=mark, )
book = Book.objects.using('other').select_related('editor').get(title="Dive into Python")
self.assertEqual(book.editor._state.db, 'other')
with self.assertRaises(ValueError): str(qs.query)
with self.assertRaises(ValueError): for obj in qs: pass
mark.book_set.create(title="Dive into Python", published=datetime.date(2009, 5, 4), extra_arg=True) mark.book_set.get_or_create(title="Dive into Python", published=datetime.date(2009, 5, 4), extra_arg=True) mark.edited.create(title="Dive into Water", published=datetime.date(2009, 5, 4), extra_arg=True) mark.edited.get_or_create(title="Dive into Water", published=datetime.date(2009, 5, 4), extra_arg=True)
connection_router = ConnectionRouter([TestRouter(), WriteRouter()]) self.assertListEqual([r.__class__.__name__ for r in connection_router.routers], ['TestRouter', 'WriteRouter'])
@override_settings(DATABASE_ROUTERS=[TestRouter()]) class RouterTestCase(TestCase): multi_db = True
self.assertTrue(router.allow_migrate_model('default', User)) self.assertTrue(router.allow_migrate_model('default', Book))
self.assertFalse(router.allow_migrate_model('default', User)) self.assertTrue(router.allow_migrate_model('default', Book))
Book.objects.using('other').create(title="Dive into Python", published=datetime.date(2009, 5, 4))
Book.objects.filter(title='Pro Django').update(pages=200)
Book.objects.get(title='Pro Django')
pro = Book.objects.using('default').get(title='Pro Django')
self.assertEqual(pro.pages, 200)
Book.objects.using('other').filter(title='Dive into Python').update(pages=300) self.assertEqual(Book.objects.get(title='Dive into Python').pages, 300)
self.assertEqual(list(pro.authors.values_list('name', flat=True)), ['Marty Alchin']) self.assertEqual(pro.editor.name, 'Marty Alchin')
book, created = Book.objects.get_or_create(title="Pro Django") self.assertFalse(created)
self.assertEqual(Book.objects.using('default').count(), 2) self.assertEqual(Book.objects.using('other').count(), 1) self.assertEqual(Book.objects.count(), 1)
Book.objects.filter(pages__gt=150).delete()
self.assertEqual(Book.objects.using('default').count(), 1) self.assertEqual(Book.objects.using('other').count(), 1)
msg = "<Book: Dive into Python> instance isn't saved. Use bulk=False or save the object first." with self.assertRaisesMessage(ValueError, msg): marty.edited.set([dive])
pro = Book.objects.using('default').create(title="Pro Django", published=datetime.date(2008, 12, 16))
dive = Book.objects.using('other').create(title="Dive into Python", published=datetime.date(2009, 5, 4))
try: dive.editor = marty except ValueError: self.fail("Assignment across primary/replica databases with a common source should be ok")
self.assertEqual(marty._state.db, 'default') self.assertEqual(pro._state.db, 'default') self.assertEqual(dive._state.db, 'other') self.assertEqual(mark._state.db, 'other')
dive.save() self.assertEqual(dive._state.db, 'default')
try: Book.objects.using('default').get(title='Dive into Python').delete() except Book.DoesNotExist: self.fail('Source database should have a copy of saved object')
dive = Book.objects.using('other').get(title='Dive into Python') self.assertEqual(dive._state.db, 'other')
try: marty.edited.set([pro, dive], bulk=False) except ValueError: self.fail("Assignment across primary/replica databases with a common source should be ok")
self.assertEqual(marty._state.db, 'default') self.assertEqual(pro._state.db, 'default') self.assertEqual(dive._state.db, 'default') self.assertEqual(mark._state.db, 'other')
try: Book.objects.using('default').get(title='Dive into Python').delete() except Book.DoesNotExist: self.fail('Source database should have a copy of saved object')
dive = Book.objects.using('other').get(title='Dive into Python') self.assertEqual(dive._state.db, 'other')
try: marty.edited.add(dive, bulk=False) except ValueError: self.fail("Assignment across primary/replica databases with a common source should be ok")
self.assertEqual(marty._state.db, 'default') self.assertEqual(pro._state.db, 'default') self.assertEqual(dive._state.db, 'default') self.assertEqual(mark._state.db, 'other')
try: Book.objects.using('default').get(title='Dive into Python').delete() except Book.DoesNotExist: self.fail('Source database should have a copy of saved object')
dive = Book.objects.using('other').get(title='Dive into Python')
chris = Person(name="Chris Mills") html5 = Book(title="Dive into HTML5", published=datetime.date(2010, 3, 15)) self.assertEqual(chris._state.db, None) self.assertEqual(html5._state.db, None)
self.assertEqual(dive._state.db, 'other') chris.save() dive.editor = chris html5.editor = mark
water = Book(title="Dive into Water", published=datetime.date(2001, 1, 1), editor=mark) self.assertEqual(water._state.db, 'default')
mark.save(using='default')
mark.save(using='other') self.assertEqual(mark._state.db, 'other')
cheesecake = mark.edited.create(title='Dive into Cheesecake', published=datetime.date(2010, 3, 15)) self.assertEqual(cheesecake._state.db, 'default')
cheesecake, created = mark.edited.get_or_create( title='Dive into Cheesecake', published=datetime.date(2010, 3, 15), ) self.assertEqual(cheesecake._state.db, 'default')
pro = Book.objects.using('other').create(pk=1, title="Pro Django", published=datetime.date(2008, 12, 16))
pro.save(using='default') marty.save(using='default') dive.save(using='other') mark.save(using='other')
self.assertEqual(Book.objects.using('default').count(), 2) self.assertEqual(Book.objects.using('other').count(), 2) self.assertEqual(Person.objects.using('default').count(), 2) self.assertEqual(Person.objects.using('other').count(), 2)
try: marty.book_set.set([pro, dive]) except ValueError: self.fail("Assignment across primary/replica databases with a common source should be ok")
self.assertEqual(marty._state.db, 'default') self.assertEqual(pro._state.db, 'default') self.assertEqual(dive._state.db, 'other') self.assertEqual(mark._state.db, 'other')
self.assertEqual(Book.authors.through.objects.using('default').count(), 2) self.assertEqual(Book.authors.through.objects.using('other').count(), 0)
Book.authors.through.objects.using('default').delete()
try: marty.book_set.add(dive) except ValueError: self.fail("Assignment across primary/replica databases with a common source should be ok")
self.assertEqual(marty._state.db, 'default') self.assertEqual(pro._state.db, 'default') self.assertEqual(dive._state.db, 'other') self.assertEqual(mark._state.db, 'other')
self.assertEqual(Book.authors.through.objects.using('default').count(), 1) self.assertEqual(Book.authors.through.objects.using('other').count(), 0)
Book.authors.through.objects.using('default').delete()
try: dive.authors.set([mark, marty]) except ValueError: self.fail("Assignment across primary/replica databases with a common source should be ok")
self.assertEqual(marty._state.db, 'default') self.assertEqual(pro._state.db, 'default') self.assertEqual(dive._state.db, 'other') self.assertEqual(mark._state.db, 'other')
self.assertEqual(Book.authors.through.objects.using('default').count(), 2) self.assertEqual(Book.authors.through.objects.using('other').count(), 0)
Book.authors.through.objects.using('default').delete()
try: dive.authors.add(marty) except ValueError: self.fail("Assignment across primary/replica databases with a common source should be ok")
self.assertEqual(marty._state.db, 'default') self.assertEqual(pro._state.db, 'default') self.assertEqual(dive._state.db, 'other') self.assertEqual(mark._state.db, 'other')
self.assertEqual(Book.authors.through.objects.using('default').count(), 1) self.assertEqual(Book.authors.through.objects.using('other').count(), 0)
alice = dive.authors.create(name='Alice') self.assertEqual(alice._state.db, 'default')
alice, created = dive.authors.get_or_create(name='Alice') self.assertEqual(alice._state.db, 'default')
alice = User.objects.db_manager('default').create_user('alice', 'alice@example.com')
bob = User.objects.db_manager('other').create_user('bob', 'bob@example.com')
alice_profile = UserProfile.objects.create(user=alice, flavor='chocolate') try: bob.userprofile = alice_profile except ValueError: self.fail("Assignment across primary/replica databases with a common source should be ok")
self.assertEqual(alice._state.db, 'default') self.assertEqual(alice_profile._state.db, 'default') self.assertEqual(bob._state.db, 'other')
bob.save() self.assertEqual(bob._state.db, 'default')
pro = Book.objects.using( 'default').create(title="Pro Django", published=datetime.date(2008, 12, 16))
dive = Book.objects.using( 'other').create(title="Dive into Python", published=datetime.date(2009, 5, 4))
try: review1.content_object = dive except ValueError: self.fail("Assignment across primary/replica databases with a common source should be ok")
self.assertEqual(pro._state.db, 'default') self.assertEqual(review1._state.db, 'default') self.assertEqual(dive._state.db, 'other') self.assertEqual(review2._state.db, 'other')
dive.save() self.assertEqual(review1._state.db, 'default') self.assertEqual(dive._state.db, 'default')
try: Book.objects.using('default').get(title='Dive into Python').delete() except Book.DoesNotExist: self.fail('Source database should have a copy of saved object')
dive = Book.objects.using('other').get(title='Dive into Python') self.assertEqual(dive._state.db, 'other')
try: dive.reviews.add(review1) except ValueError: self.fail("Assignment across primary/replica databases with a common source should be ok")
self.assertEqual(pro._state.db, 'default') self.assertEqual(review1._state.db, 'default') self.assertEqual(dive._state.db, 'other') self.assertEqual(review2._state.db, 'other')
dive.save() self.assertEqual(dive._state.db, 'default')
try: Book.objects.using('default').get(title='Dive into Python').delete() except Book.DoesNotExist: self.fail('Source database should have a copy of saved object')
review3 = Review(source="Python Daily") self.assertEqual(review3._state.db, None)
review3.content_object = dive self.assertEqual(review3._state.db, 'default')
dive = Book.objects.using('other').get(title='Dive into Python') nyt = dive.reviews.create(source="New York Times", content_object=dive) self.assertEqual(nyt._state.db, 'default')
str(qs.query)
self.assertEqual(list(qs.values_list('title', flat=True)), ['Dive into Python'])
User.objects.create_user('alice', 'alice@example.com')
User.objects.db_manager('default').create_user('bob', 'bob@example.com')
alice = User.objects.using('other').get(username='alice')
bob = User.objects.using('default').get(username='bob')
self.assertEqual(User.objects.using('default').count(), 1) self.assertEqual(User.objects.using('other').count(), 1)
new_io = StringIO() management.call_command('dumpdata', 'auth', format='json', database='default', stdout=new_io) command_output = new_io.getvalue().strip() self.assertEqual(command_output, '[]')
new_io = StringIO() management.call_command('dumpdata', 'auth', format='json', database='other', stdout=new_io) command_output = new_io.getvalue().strip() self.assertIn('"email": "alice@example.com"', command_output)
try: Book.objects.get(title="Pro Django") Book.objects.using('default').get(title="Pro Django") except Book.DoesNotExist: self.fail('"Pro Django" should exist on default database')
try: Book.objects.using('other').get(title="Dive into Python") except Book.DoesNotExist: self.fail('"Dive into Python" should exist on other database')
try: Book.objects.get(title="The Definitive Guide to Django") Book.objects.using('default').get(title="The Definitive Guide to Django") Book.objects.using('other').get(title="The Definitive Guide to Django") except Book.DoesNotExist: self.fail('"The Definitive Guide to Django" should exist on both databases')
self.assertEqual(command_output, "Installed 0 object(s) (of 2) from 1 fixture(s)")
pre_save_receiver = DatabaseReceiver() post_save_receiver = DatabaseReceiver() pre_delete_receiver = DatabaseReceiver() post_delete_receiver = DatabaseReceiver() signals.pre_save.connect(sender=Person, receiver=pre_save_receiver) signals.post_save.connect(sender=Person, receiver=post_save_receiver) signals.pre_delete.connect(sender=Person, receiver=pre_delete_receiver) signals.post_delete.connect(sender=Person, receiver=post_delete_receiver) p = Person.objects.create(name='Darth Vader') p.save() self.assertEqual(pre_save_receiver._database, DEFAULT_DB_ALIAS) self.assertEqual(post_save_receiver._database, DEFAULT_DB_ALIAS) p.delete() self.assertEqual(pre_delete_receiver._database, DEFAULT_DB_ALIAS) self.assertEqual(post_delete_receiver._database, DEFAULT_DB_ALIAS) p.save(using="other") self.assertEqual(pre_save_receiver._database, "other") self.assertEqual(post_save_receiver._database, "other") p.delete(using="other") self.assertEqual(pre_delete_receiver._database, "other") self.assertEqual(post_delete_receiver._database, "other")
receiver = DatabaseReceiver() signals.m2m_changed.connect(receiver=receiver)
b = Book.objects.create(title="Pro Django", published=datetime.date(2008, 12, 16)) p = Person.objects.create(name="Marty Alchin")
Book.objects.using('other').create(pk=b.pk, title=b.title, published=b.published) Person.objects.using('other').create(pk=p.pk, name=p.name)
b.authors.add(p) self.assertEqual(receiver._database, DEFAULT_DB_ALIAS) with self.override_router(): b.authors.add(p) self.assertEqual(receiver._database, "other")
b.authors.remove(p) self.assertEqual(receiver._database, DEFAULT_DB_ALIAS) with self.override_router(): b.authors.remove(p) self.assertEqual(receiver._database, "other")
p.book_set.add(b) self.assertEqual(receiver._database, DEFAULT_DB_ALIAS) with self.override_router(): p.book_set.add(b) self.assertEqual(receiver._database, "other")
b.authors.clear() self.assertEqual(receiver._database, DEFAULT_DB_ALIAS) with self.override_router(): b.authors.clear() self.assertEqual(receiver._database, "other")
b.authors.add(p) b.authors.remove(p) b.authors.clear() b.authors.set([p]) b.delete()
person.delete()
return 'default'
def db_for_write(self, model, **hints): return 'writer'
from django.contrib import admin from django.db import models
class SongAdmin(admin.ModelAdmin): pass site.register(Song, SongAdmin)
self.check_ordering_of_field_choices([self.b2, self.b1])
self.check_ordering_of_field_choices([self.b2, self.b1])
self.check_ordering_of_field_choices([self.b1, self.b2])
def formfield_for_foreignkey(self, db_field, request, **kwargs): if db_field.name == 'band': kwargs["queryset"] = Band.objects.filter(rank__gt=2) return super(SongAdmin, self).formfield_for_foreignkey(db_field, request, **kwargs)
with self.assertRaises(Http404): get_object_or_404(Article, title="Foo")
self.assertEqual( get_object_or_404(Article, title__contains="Run"), article )
self.assertEqual( get_object_or_404(a1.article_set, title__contains="Run"), article )
with self.assertRaises(Http404): get_object_or_404(a1.article_set, title__contains="Camelot")
self.assertEqual( get_object_or_404(Article.by_a_sir, title="Run away!"), article )
self.assertEqual( get_object_or_404(Article.objects.all(), title__contains="Run"), article )
with self.assertRaises(Http404): get_object_or_404(Article.objects.none(), title__contains="Run")
self.assertEqual( get_list_or_404(a1.article_set, title__icontains="Run"), [article] )
with self.assertRaises(Http404): get_list_or_404(a1.article_set, title__icontains="Shrubbery")
self.assertEqual( get_list_or_404(Article.by_a_sir, title__icontains="Run"), [article] )
self.assertEqual( get_list_or_404(Article.objects.all(), title__icontains="Run"), [article] )
msg = "First argument to get_object_or_404() must be a Model, Manager, or QuerySet, not 'str'." with self.assertRaisesMessage(ValueError, msg): get_object_or_404(str("Article"), title__icontains="Run")
msg = "First argument to get_list_or_404() must be a Model, Manager, or QuerySet, not 'list'." with self.assertRaisesMessage(ValueError, msg): get_list_or_404([Article], title__icontains="Run")
self.pre_signals = ( len(signals.pre_save.receivers), len(signals.post_save.receivers), len(signals.pre_delete.receivers), len(signals.post_delete.receivers), )
post_signals = ( len(signals.pre_save.receivers), len(signals.post_save.receivers), len(signals.pre_delete.receivers), len(signals.post_delete.receivers), ) self.assertEqual(self.pre_signals, post_signals)
p1.save_base(raw=True) self.assertEqual(data, [ (p1, True), (p1, False, True), ]) data[:] = []
class PostDeleteHandler(object): def __init__(self, data): self.data = data
b1.authors.set([a1]) self.assertEqual(data, []) b1.authors.set([]) self.assertEqual(data, [])
from django.contrib.contenttypes.fields import ( GenericForeignKey, GenericRelation, ) from django.contrib.contenttypes.models import ContentType from django.db import models from django.utils.encoding import python_2_unicode_compatible
id = models.IntegerField(primary_key=True)
class Alfa(models.Model): name = models.CharField(max_length=10, null=True)
books = Book.objects.order_by('id') qs1 = books.filter(id__in=qs) qs2 = books.filter(id__in=list(qs)) self.assertEqual(list(qs1), list(qs2))
list(qs) books = Book.objects.order_by('id') qs1 = books.filter(id__in=qs) qs2 = books.filter(id__in=list(qs)) self.assertEqual(list(qs1), list(qs2))
qs = Publisher.objects.extra(select={ 'name_of_shortest_book': shortest_book_sql, }).annotate(total_books=Count('book')) list(qs)
self.assertEqual( Author.objects.order_by("name").aggregate(Avg("age")), {"age__avg": Approximate(37.444, places=1)} )
self.assertEqual( Book.objects.aggregate(Sum("pages")), {"pages__sum": 3703}, )
self.assertEqual( Book.objects.aggregate(Sum('pages'), Avg('pages')), {'pages__sum': 3703, 'pages__avg': Approximate(617.166, places=2)} )
self.assertEqual( Book.objects.values().aggregate(Sum('pages'), Avg('pages')), {'pages__sum': 3703, 'pages__avg': Approximate(617.166, places=2)} )
self.assertEqual( Book.objects.extra(select={'price_per_page': 'price / pages'}).aggregate(Sum('pages')), {'pages__sum': 3703} )
obj = Book.objects.annotate(mean_auth_age=Avg("authors__age")).extra( select={"manufacture_cost": "price * .5"}).get(pk=self.b2.pk) self.assertObjectAttrs( obj, contact_id=self.a3.id, isbn='067232959', mean_auth_age=45.0, name='Sams Teach Yourself Django in 24 Hours', pages=528, price=Decimal("23.09"), pubdate=datetime.date(2008, 3, 3), publisher_id=self.p2.id, rating=3.0 ) self.assertIn(obj.manufacture_cost, (11.545, Decimal('11.545')))
obj = Book.objects.extra(select={'manufacture_cost': 'price * .5'}).annotate( mean_auth_age=Avg('authors__age')).get(pk=self.b2.pk) self.assertObjectAttrs( obj, contact_id=self.a3.id, isbn='067232959', mean_auth_age=45.0, name='Sams Teach Yourself Django in 24 Hours', pages=528, price=Decimal("23.09"), pubdate=datetime.date(2008, 3, 3), publisher_id=self.p2.id, rating=3.0 ) self.assertIn(obj.manufacture_cost, (11.545, Decimal('11.545')))
obj = Book.objects.annotate(mean_auth_age=Avg('authors__age')).extra( select={'manufacture_cost': 'price * .5'}).values().get(pk=self.b2.pk) manufacture_cost = obj['manufacture_cost'] self.assertIn(manufacture_cost, (11.545, Decimal('11.545'))) del obj['manufacture_cost'] self.assertEqual(obj, { 'id': self.b2.id, 'contact_id': self.a3.id, 'isbn': '067232959', 'mean_auth_age': 45.0, 'name': 'Sams Teach Yourself Django in 24 Hours', 'pages': 528, 'price': Decimal('23.09'), 'pubdate': datetime.date(2008, 3, 3), 'publisher_id': self.p2.id, 'rating': 3.0, })
obj = Book.objects.values().annotate(mean_auth_age=Avg('authors__age')).extra( select={'manufacture_cost': 'price * .5'}).get(pk=self.b2.pk) manufacture_cost = obj['manufacture_cost'] self.assertIn(manufacture_cost, (11.545, Decimal('11.545'))) del obj['manufacture_cost'] self.assertEqual(obj, { 'id': self.b2.id, 'contact_id': self.a3.id, 'isbn': '067232959', 'mean_auth_age': 45.0, 'name': 'Sams Teach Yourself Django in 24 Hours', 'pages': 528, 'price': Decimal('23.09'), 'pubdate': datetime.date(2008, 3, 3), 'publisher_id': self.p2.id, 'rating': 3.0 })
obj = Book.objects.annotate(mean_auth_age=Avg('authors__age')).extra( select={'price_per_page': 'price / pages'}).values('name').get(pk=self.b1.pk) self.assertEqual(obj, { "name": 'The Definitive Guide to Django: Web Development Done Right', })
qs = Book.objects.annotate(n_authors=Count('authors')).values('name').filter(n_authors__gt=2) self.assertQuerysetEqual( qs, [ {"name": 'Python Web Development with Django'} ], lambda b: b, )
obj = Book.objects.values('name').annotate(mean_auth_age=Avg('authors__age')).extra( select={'price_per_page': 'price / pages'}).get(pk=self.b1.pk) self.assertEqual(obj, { 'mean_auth_age': 34.5, 'name': 'The Definitive Guide to Django: Web Development Done Right', })
self.assertEqual( len(Author.objects.annotate(Avg('friends__age')).values()), 9 )
qs = ( Book.objects .values('price') .annotate(oldest=Max('authors__age')) .order_by('oldest', 'price') .annotate(Max('publisher__num_awards')) ) self.assertQuerysetEqual( qs, [ {'price': Decimal("30"), 'oldest': 35, 'publisher__num_awards__max': 3}, {'price': Decimal("29.69"), 'oldest': 37, 'publisher__num_awards__max': 7}, {'price': Decimal("23.09"), 'oldest': 45, 'publisher__num_awards__max': 1}, {'price': Decimal("75"), 'oldest': 57, 'publisher__num_awards__max': 9}, {'price': Decimal("82.8"), 'oldest': 57, 'publisher__num_awards__max': 7} ], lambda b: b, )
vals = ( Book.objects .all() .annotate(num_authors=Count('authors__id')) .aggregate(Max('pages'), Max('price'), Sum('num_authors'), Avg('num_authors')) ) self.assertEqual(vals, { 'num_authors__sum': 10, 'num_authors__avg': Approximate(1.666, places=2), 'pages__max': 1132, 'price__max': Decimal("82.80") })
self.assertEqual( Book.objects.annotate(c=Count('authors')).values('c').aggregate(Max('c')), {'c__max': 3} )
with self.assertRaises(FieldError): Book.objects.all().aggregate(num_authors=Count('foo'))
self.assertEqual( Book.objects.annotate(num_authors=Count('authors')).count(), 6 )
vals = Book.objects.annotate(num_authors=Count('authors')).aggregate(Max('num_authors')) self.assertEqual( vals, {'num_authors__max': 3} )
vals = Book.objects.aggregate(number=Max('pages'), select=Max('pages')) self.assertEqual( vals, {'number': 1132, 'select': 1132} )
obj = Book.objects.select_related('publisher').annotate( num_authors=Count('authors')).values().get(isbn='013790395') self.assertEqual(obj, { 'contact_id': self.a8.id, 'id': self.b5.id, 'isbn': '013790395', 'name': 'Artificial Intelligence: A Modern Approach', 'num_authors': 2, 'pages': 1132, 'price': Decimal("82.8"), 'pubdate': datetime.date(1995, 1, 15), 'publisher_id': self.p3.id, 'rating': 4.0, })
self.assertEqual( len(Book.objects.annotate(num_authors=Count('authors'))), 6 ) self.assertEqual( len(Book.objects.annotate(num_authors=Count('authors')).filter(num_authors__gt=2)), 1 ) self.assertEqual( len(Book.objects.annotate(num_authors=Count('authors')).exclude(num_authors__gt=2)), 5 )
qs = ( Publisher.objects .annotate(num_books=Count('book')) .filter(num_books__lt=F('num_awards') / 2) .order_by('name') .values('name', 'num_books', 'num_awards') ) self.assertQuerysetEqual( qs, [ {'num_books': 1, 'name': 'Morgan Kaufmann', 'num_awards': 9}, {'num_books': 2, 'name': 'Prentice Hall', 'num_awards': 7} ], lambda p: p, )
qs = ( Publisher.objects .annotate(num_books=Count('book')) .filter(num_awards__gt=2 * F('num_books')) .order_by('name') .values('name', 'num_books', 'num_awards') ) self.assertQuerysetEqual( qs, [ {'num_books': 1, 'name': 'Morgan Kaufmann', 'num_awards': 9}, {'num_books': 2, 'name': 'Prentice Hall', 'num_awards': 7} ], lambda p: p, )
qs = ( Clues.objects .values('EntryID__Entry') .annotate(Appearances=Count('EntryID'), Distinct_Clues=Count('Clue', distinct=True)) ) self.assertQuerysetEqual(qs, [])
e = Entries.objects.create(Entry='foo') c = Clues.objects.create(EntryID=e, Clue='bar') qs = Clues.objects.select_related('EntryID').annotate(Count('ID')) self.assertQuerysetEqual( qs, [c], lambda x: x) self.assertEqual(qs[0].EntryID, e) self.assertIs(qs[0].EntryID.Exclude, False)
self.assertEqual( Book.objects.filter(id__in=[]).count(), 0 )
self.assertQuerysetEqual( Book.objects.annotate(num_authors=Count('authors')).order_by('publisher__name', 'name'), [ "Practical Django Projects", "The Definitive Guide to Django: Web Development Done Right", "Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp", "Artificial Intelligence: A Modern Approach", "Python Web Development with Django", "Sams Teach Yourself Django in 24 Hours", ], lambda b: b.name )
qs = Book.objects.filter(rating__lt=4.5).select_related().annotate(Avg('authors__age')) self.assertQuerysetEqual( qs, [ ('Artificial Intelligence: A Modern Approach', 51.5, 'Prentice Hall', 'Peter Norvig'), ('Practical Django Projects', 29.0, 'Apress', 'James Bennett'), ( 'Python Web Development with Django', Approximate(30.333, places=2), 'Prentice Hall', 'Jeffrey Forcier', ), ('Sams Teach Yourself Django in 24 Hours', 45.0, 'Sams', 'Brad Dayley') ], lambda b: (b.name, b.authors__age__avg, b.publisher.name, b.contact.name) )
qs = Book.objects.extra(select={'pub': 'publisher_id'}).values('pub').annotate(Count('id')).order_by('pub') self.assertQuerysetEqual( qs, [ {'pub': self.b1.id, 'id__count': 2}, {'pub': self.b2.id, 'id__count': 1}, {'pub': self.b3.id, 'id__count': 2}, {'pub': self.b4.id, 'id__count': 1} ], lambda b: b )
ids = ( Book.objects .filter(pages__gt=100) .annotate(n_authors=Count('authors')) .filter(n_authors__gt=2) .order_by('n_authors') ) self.assertQuerysetEqual( Book.objects.filter(id__in=ids), [ "Python Web Development with Django", ], lambda b: b.name )
qstr = str(Book.objects.values('publisher').annotate(max_pages=Max('pages')).order_by().query) self.assertEqual(qstr[qstr.index('GROUP BY'):].count(', '), 0)
with self.assertRaises(ValueError): Book.objects.all().annotate(Avg('authors__age'), authors__age__avg=Avg('authors__age'))
with self.assertRaises(ValueError): Author.objects.annotate(age=Avg('friends__age'))
with self.assertRaises(ValueError): Author.objects.annotate(friends=Count('friends'))
results = Author.objects.values('name').annotate(age=Count('book_contact_set')).order_by('name') self.assertEqual(len(results), 9) self.assertEqual(results[0]['name'], 'Adrian Holovaty') self.assertEqual(results[0]['age'], 1)
results = Author.objects.values('name').annotate(age=Avg('friends__age')).order_by('name') self.assertEqual(len(results), 9) self.assertEqual(results[0]['name'], 'Adrian Holovaty') self.assertEqual(results[0]['age'], 32.0)
results = Author.objects.values('name').annotate(friends=Count('friends')).order_by('name') self.assertEqual(len(results), 9) self.assertEqual(results[0]['name'], 'Adrian Holovaty') self.assertEqual(results[0]['friends'], 2)
with self.assertRaises(ValueError): Author.objects.annotate(book_contact_set=Avg('friends__age'))
qs = Book.objects.annotate(num_authors=Count('authors')) pickle.dumps(qs)
query = qs.query.get_compiler(qs.db).as_sql()[0] qs2 = pickle.loads(pickle.dumps(qs)) self.assertEqual( qs2.query.get_compiler(qs2.db).as_sql()[0], query, )
books = Book.objects.all() books.aggregate(Avg("authors__age")) self.assertQuerysetEqual( books.all(), [ 'Artificial Intelligence: A Modern Approach', 'Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp', 'Practical Django Projects', 'Python Web Development with Django', 'Sams Teach Yourself Django in 24 Hours', 'The Definitive Guide to Django: Web Development Done Right' ], lambda b: b.name )
qs = Book.objects.annotate(num_authors=Count('authors')).filter(num_authors=2).dates('pubdate', 'day') self.assertQuerysetEqual( qs, [ datetime.date(1995, 1, 15), datetime.date(2007, 12, 6), ], lambda b: b )
qs = ( Book.objects .annotate(mean_auth_age=Avg('authors__age')) .extra(select={'sheets': '(pages + %s) / %s'}, select_params=[1, 2]) .order_by('sheets') .values('sheets') ) self.assertQuerysetEqual( qs, [ 150, 175, 224, 264, 473, 566 ], lambda b: int(b["sheets"]) )
self.assertEqual( Book.objects.values('publisher').annotate(Count('publisher')).count(), 4 ) self.assertEqual( Book.objects.annotate(Count('publisher')).values('publisher').count(), 6 )
publishers = Publisher.objects.filter(id__in=[1, 2]) self.assertEqual( sorted(p.name for p in publishers), [ "Apress", "Sams" ] )
self.assertEqual( HardbackBook.objects.aggregate(n_pages=Sum('book_ptr__pages')), {'n_pages': 2078} )
with self.assertRaises(FieldError): Book.objects.annotate(mean_age=Avg('authors__age')).annotate(Avg('mean_age'))
self.assertEqual( Author.objects.none().aggregate(Avg('age')), {'age__avg': None} )
qs = Book.objects.values("name").annotate( n_authors=Count("authors") ).filter( pages__lt=F("n_authors") * 200 ).values_list("pk") self.assertQuerysetEqual( Book.objects.filter(pk__in=qs), [ "Python Web Development with Django" ], attrgetter("name") )
qs = Book.objects.values_list("name").annotate( n_authors=Count("authors") ).filter( pages__gt=F("n_authors") ).values_list("name", flat=True) self.assertEqual( list(qs), list(Book.objects.values_list("name", flat=True)) )
qs = Author.objects.annotate(book_cnt=Count('book')).filter(book_cnt=2).order_by('name') self.assertQuerysetEqual( qs, ['Peter Norvig'], lambda b: b.name ) qs = Author.objects.annotate(book_count=Count('book')).filter(book_count=2).order_by('name') self.assertQuerysetEqual( qs, ['Peter Norvig'], lambda b: b.name ) qs = Author.objects.annotate(Count('book')).filter(book__count=2).order_by('name') self.assertQuerysetEqual( qs, ['Peter Norvig'], lambda b: b.name ) self.assertEqual( Author.objects.annotate(Count('book')).aggregate(Max('book__count')), {'book__count__max': 2} )
self.assertEqual(len(qs.exclude(publisher=-1)), 6)
_, _, group_by = results.query.get_compiler(using='default').pre_sql_setup() self.assertEqual(len(group_by), 1) self.assertIn('id', group_by[0][0]) self.assertNotIn('name', group_by[0][0]) self.assertNotIn('age', group_by[0][0])
self.assertEqual( [(a.name, a.num_contacts) for a in results.order_by('name')], [ ('Adrian Holovaty', 1), ('Brad Dayley', 1), ('Jacob Kaplan-Moss', 0), ('James Bennett', 1), ('Jeffrey Forcier', 1), ('Paul Bissex', 0), ('Peter Norvig', 2), ('Stuart Russell', 0), ('Wesley J. Chun', 0), ] )
results = Author.objects.only('id', 'name').annotate(num_contacts=Count('book_contact_set')) _, _, grouping = results.query.get_compiler(using='default').pre_sql_setup() self.assertEqual(len(grouping), 1) self.assertIn('id', grouping[0][0]) self.assertNotIn('name', grouping[0][0]) self.assertNotIn('age', grouping[0][0])
self.assertEqual( [(a.name, a.num_contacts) for a in results.order_by('name')], [ ('Adrian Holovaty', 1), ('Brad Dayley', 1), ('Jacob Kaplan-Moss', 0), ('James Bennett', 1), ('Jeffrey Forcier', 1), ('Paul Bissex', 0), ('Peter Norvig', 2), ('Stuart Russell', 0), ('Wesley J. Chun', 0), ] )
results = Book.objects.select_related('contact').annotate( num_authors=Count('authors')) _, _, grouping = results.query.get_compiler(using='default').pre_sql_setup() self.assertEqual(len(grouping), 1 if connection.features.allows_group_by_pk else 2) self.assertIn('id', grouping[0][0]) self.assertNotIn('name', grouping[0][0]) self.assertNotIn('contact', grouping[0][0])
self.assertEqual( [(b.name, b.num_authors) for b in results.order_by('name')], [ ('Artificial Intelligence: A Modern Approach', 2), ('Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp', 1), ('Practical Django Projects', 1), ('Python Web Development with Django', 3), ('Sams Teach Yourself Django in 24 Hours', 1), ('The Definitive Guide to Django: Web Development Done Right', 2) ] )
wmpk = WithManualPK.objects.create(id=django_book.pk) ItemTag.objects.create( object_id=wmpk.id, tag='hi mom', content_type=ContentType.objects.get_for_model(wmpk), ) ai_book = Book.objects.get(name__startswith='Paradigms of Artificial Intelligence') ItemTag.objects.create( object_id=ai_book.id, tag='intermediate', content_type=ContentType.objects.get_for_model(ai_book), )
qs = Author.objects.annotate(Count('book')).filter( Q(name='Peter Norvig') | Q(age=F('book__count') + 33) ).order_by('name') self.assertQuerysetEqual( qs, ['Adrian Holovaty', 'Peter Norvig'], lambda b: b.name )
qs = Book.objects.annotate(avg_price=Avg('price')).aggregate( publisher_awards=Sum('publisher__num_awards') ) self.assertEqual(qs['publisher_awards'], 30)
vals1 = Book.objects.values('rating', 'price').distinct().aggregate(result=Sum('rating')) vals2 = Book.objects.aggregate(result=Sum('rating') - Value(4.0)) self.assertEqual(vals1, vals2)
qs = qs.all() self.assertQuerysetEqual( qs, [c], lambda x: x) self.assertEqual(qs[0].alfa, a)
qs = Charlie.objects.filter(alfa__name__isnull=False).annotate(Count('alfa__name')) self.assertIn(' INNER JOIN ', str(qs.query)) qs = Charlie.objects.annotate(Count('alfa__name')).filter(alfa__name__isnull=False) self.assertIn(' INNER JOIN ', str(qs.query)) qs = Charlie.objects.annotate(Count('alfa__name')) self.assertIn(' LEFT OUTER JOIN ', str(qs.query))
field = models.CharField(max_length=65) name, path, args, kwargs = field.deconstruct() self.assertIsNone(name) field.set_attributes_from_name("is_awesome_test") name, path, args, kwargs = field.deconstruct() self.assertEqual(name, "is_awesome_test") self.assertIsInstance(name, six.text_type) field = models.ForeignKey("some_fake.ModelName", models.CASCADE) name, path, args, kwargs = field.deconstruct() self.assertIsNone(name) field.set_attributes_from_name("author") name, path, args, kwargs = field.deconstruct() self.assertEqual(name, "author")
field = models.DateTimeField(auto_now=True, auto_now_add=True) name, path, args, kwargs = field.deconstruct() self.assertEqual(path, "django.db.models.DateTimeField") self.assertEqual(args, []) self.assertEqual(kwargs, {"auto_now_add": True, "auto_now": True})
field = models.FileField(upload_to="foo/bar", max_length=200) name, path, args, kwargs = field.deconstruct() self.assertEqual(path, "django.db.models.FileField") self.assertEqual(args, []) self.assertEqual(kwargs, {"upload_to": "foo/bar", "max_length": 200})
from django.contrib.auth.models import Permission field = models.ForeignKey("auth.Permission", models.CASCADE) field.remote_field.model = Permission field.remote_field.field_name = "id" name, path, args, kwargs = field.deconstruct() self.assertEqual(path, "django.db.models.ForeignKey") self.assertEqual(args, []) self.assertEqual(kwargs, {"to": "auth.Permission", "on_delete": models.CASCADE}) self.assertFalse(hasattr(kwargs['to'], "setting_name")) field = models.ForeignKey("auth.User", models.CASCADE) name, path, args, kwargs = field.deconstruct() self.assertEqual(path, "django.db.models.ForeignKey") self.assertEqual(args, []) self.assertEqual(kwargs, {"to": "auth.User", "on_delete": models.CASCADE}) self.assertEqual(kwargs['to'].setting_name, "AUTH_USER_MODEL") field = models.ForeignKey("something.Else", models.CASCADE) name, path, args, kwargs = field.deconstruct() self.assertEqual(path, "django.db.models.ForeignKey") self.assertEqual(args, []) self.assertEqual(kwargs, {"to": "something.Else", "on_delete": models.CASCADE}) field = models.ForeignKey("auth.User", models.SET_NULL) name, path, args, kwargs = field.deconstruct() self.assertEqual(path, "django.db.models.ForeignKey") self.assertEqual(args, []) self.assertEqual(kwargs, {"to": "auth.User", "on_delete": models.SET_NULL}) field = models.ForeignKey("auth.Permission", models.CASCADE, to_field="foobar") name, path, args, kwargs = field.deconstruct() self.assertEqual(path, "django.db.models.ForeignKey") self.assertEqual(args, []) self.assertEqual(kwargs, {"to": "auth.Permission", "to_field": "foobar", "on_delete": models.CASCADE}) field = models.ForeignKey("auth.Permission", models.CASCADE, related_name="foobar") name, path, args, kwargs = field.deconstruct() self.assertEqual(path, "django.db.models.ForeignKey") self.assertEqual(args, []) self.assertEqual(kwargs, {"to": "auth.Permission", "related_name": "foobar", "on_delete": models.CASCADE})
field = models.ForeignKey("auth.Permission", models.CASCADE) name, path, args, kwargs = field.deconstruct()
field = models.ManyToManyField("auth.Permission") name, path, args, kwargs = field.deconstruct() self.assertEqual(path, "django.db.models.ManyToManyField") self.assertEqual(args, []) self.assertEqual(kwargs, {"to": "auth.Permission"}) self.assertFalse(hasattr(kwargs['to'], "setting_name")) field = models.ManyToManyField("auth.User") name, path, args, kwargs = field.deconstruct() self.assertEqual(path, "django.db.models.ManyToManyField") self.assertEqual(args, []) self.assertEqual(kwargs, {"to": "auth.User"}) self.assertEqual(kwargs['to'].setting_name, "AUTH_USER_MODEL") field = models.ManyToManyField("auth.Permission", through="auth.Group") name, path, args, kwargs = field.deconstruct() self.assertEqual(path, "django.db.models.ManyToManyField") self.assertEqual(args, []) self.assertEqual(kwargs, {"to": "auth.Permission", "through": "auth.Group"}) field = models.ManyToManyField("auth.Permission", db_table="custom_table") name, path, args, kwargs = field.deconstruct() self.assertEqual(path, "django.db.models.ManyToManyField") self.assertEqual(args, []) self.assertEqual(kwargs, {"to": "auth.Permission", "db_table": "custom_table"}) field = models.ManyToManyField("auth.Permission", related_name="custom_table") name, path, args, kwargs = field.deconstruct() self.assertEqual(path, "django.db.models.ManyToManyField") self.assertEqual(args, []) self.assertEqual(kwargs, {"to": "auth.Permission", "related_name": "custom_table"})
field = models.ManyToManyField("auth.Permission") name, path, args, kwargs = field.deconstruct()
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
apps = Apps() verbose_name = ' ' verbose_name_plural = ' '
apps = Apps()
from __future__ import unicode_literals
from __future__ import unicode_literals
for db in connections: recorder = MigrationRecorder(connections[db]) recorder.migration_qs.filter(app='migrations').delete()
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
Publisher = apps.get_model('migrations', 'Publisher') Publisher.objects.create(name='Test Publisher') raise RuntimeError('Abort migration')
plan = executor.migration_plan([("migrations", "0002_second")]) self.assertEqual( plan, [ (executor.loader.graph.nodes["migrations", "0001_initial"], False), (executor.loader.graph.nodes["migrations", "0002_second"], False), ], ) self.assertTableNotExists("migrations_author") self.assertTableNotExists("migrations_book") executor.migrate([("migrations", "0002_second")]) self.assertTableExists("migrations_author") self.assertTableExists("migrations_book") executor.loader.build_graph() plan = executor.migration_plan([("migrations", None)]) self.assertEqual( plan, [ (executor.loader.graph.nodes["migrations", "0002_second"], True), (executor.loader.graph.nodes["migrations", "0001_initial"], True), ], ) executor.migrate([("migrations", None)]) self.assertTableNotExists("migrations_author") self.assertTableNotExists("migrations_book")
leaves = [key for key in executor.loader.graph.leaf_nodes() if key[0] == "migrations"] self.assertEqual(leaves, [("migrations", "0001_squashed_0002")]) plan = executor.migration_plan([("migrations", "0001_squashed_0002")]) self.assertEqual( plan, [ (executor.loader.graph.nodes["migrations", "0001_squashed_0002"], False), ], ) self.assertTableNotExists("migrations_author") self.assertTableNotExists("migrations_book") executor.migrate([("migrations", "0001_squashed_0002")]) self.assertTableExists("migrations_author") self.assertTableExists("migrations_book") executor.loader.build_graph() plan = executor.migration_plan([("migrations", None)]) self.assertEqual( plan, [ (executor.loader.graph.nodes["migrations", "0001_squashed_0002"], True), ], ) executor.migrate([("migrations", None)]) self.assertTableNotExists("migrations_author") self.assertTableNotExists("migrations_book")
executor = MigrationExecutor(connection) plan = executor.migration_plan([ ("migrations", "0002_second"), ("migrations2", "0001_initial"), ]) self.assertEqual( plan, [ (executor.loader.graph.nodes["migrations", "0001_initial"], False), (executor.loader.graph.nodes["migrations", "0002_second"], False), (executor.loader.graph.nodes["migrations2", "0001_initial"], False), ], ) executor.migrate([ ("migrations", "0002_second"), ("migrations2", "0001_initial") ], fake=True) executor.loader.build_graph() plan = executor.migration_plan([ ("migrations", "0002_second"), ("migrations2", "0001_initial"), ]) self.assertEqual(plan, []) executor.recorder.record_unapplied("migrations2", "0001_initial") executor.recorder.record_unapplied("migrations", "0002_second") executor.recorder.record_unapplied("migrations", "0001_initial")
executor = MigrationExecutor(connection) plan = executor.migration_plan([("migrations", "0002_second")]) self.assertEqual( plan, [ (executor.loader.graph.nodes["migrations", "0001_initial"], False), (executor.loader.graph.nodes["migrations", "0002_second"], False), ], ) executor.migrate(None, plan) executor.loader.build_graph() self.assertIn(('migrations', '0001_initial'), executor.loader.applied_migrations) self.assertIn(('migrations', '0002_second'), executor.loader.applied_migrations) self.assertNotIn(('migrations2', '0001_initial'), executor.loader.applied_migrations)
plan = executor.migration_plan([ ("migrations", None), ("migrations2", "0001_initial"), ]) msg = ( 'Migration plans with both forwards and backwards migrations are ' 'not supported. Please split your migration process into separate ' 'plans of only forwards OR backwards migrations.' ) with self.assertRaisesMessage(InvalidMigrationPlan, msg) as cm: executor.migrate(None, plan) self.assertEqual( cm.exception.args[1], [ (executor.loader.graph.nodes["migrations", "0002_second"], True), (executor.loader.graph.nodes["migrations", "0001_initial"], True), (executor.loader.graph.nodes["migrations2", "0001_initial"], False), ], ) executor.loader.build_graph() executor.migrate([ ("migrations", None), ("migrations2", None), ]) self.assertTableNotExists("migrations_author") self.assertTableNotExists("migrations_book") self.assertTableNotExists("migrations2_otherauthor")
self.assertTableNotExists("migrations_author") self.assertTableNotExists("migrations_tribble") self.assertEqual( executor.migration_plan([("migrations", "0001_initial")]), [ (executor.loader.graph.nodes["migrations", "0001_initial"], False), ], ) executor.migrate([("migrations", "0001_initial")]) self.assertTableExists("migrations_author") self.assertTableExists("migrations_tribble") self.assertEqual(state["faked"], False) executor.loader.build_graph() executor.migrate([("migrations", None)], fake=True) self.assertTableExists("migrations_author") self.assertTableExists("migrations_tribble") self.assertEqual(state["faked"], True) executor.loader.build_graph() self.assertEqual( executor.migration_plan([("migrations", "0001_initial")]), [ (executor.loader.graph.nodes["migrations", "0001_initial"], False), ], ) with self.assertRaises(DatabaseError): executor.migrate([("migrations", "0001_initial")]) state = {"faked": None} executor.migrate([("migrations", "0001_initial")], fake_initial=True) self.assertEqual(state["faked"], True) executor.loader.build_graph() executor.migrate([("migrations", None)]) self.assertTableNotExists("migrations_author") self.assertTableNotExists("migrations_tribble")
executor.migrate([("migrations", "0001_initial")]) self.assertTableExists("migrations_author") self.assertTableExists("migrations_tribble") old_table_names = connection.introspection.table_names connection.introspection.table_names = lambda c: [x for x in old_table_names(c) if x != "auth_user"] migrations_apps = executor.loader.project_state(("migrations", "0001_initial")).apps global_apps.get_app_config("migrations").models["author"] = migrations_apps.get_model("migrations", "author") try: migration = executor.loader.get_migration("auth", "0001_initial") self.assertEqual(executor.detect_soft_applied(None, migration)[0], True) finally: connection.introspection.table_names = old_table_names del global_apps.get_app_config("migrations").models["author"] executor.loader.build_graph() executor.migrate([("migrations", None)]) self.assertTableNotExists("migrations_author") self.assertTableNotExists("migrations_tribble")
"migrations_project", "migrations_task", "migrations_project_tasks", "migrations_task_projects",
executor.migrate([("migrations", "0001_initial")]) executor.migrate([("migrations", None)], fake=True) for table in tables[:3]: self.assertTableExists(table) migration = executor.loader.get_migration("migrations", "0001_initial") self.assertEqual(executor.detect_soft_applied(None, migration)[0], True) migration = executor.loader.get_migration("migrations", "0002_initial") self.assertEqual(executor.detect_soft_applied(None, migration)[0], False)
executor.loader.build_graph() executor.migrate([("migrations", "0001_initial")], fake=True) executor.migrate([("migrations", "0002_initial")]) executor.loader.build_graph() executor.migrate([("migrations", None)], fake=True) migration = executor.loader.get_migration("migrations", "0002_initial") self.assertEqual(executor.detect_soft_applied(None, migration)[0], True)
with connection.schema_editor() as editor: for table in tables[2:]: editor.execute(editor.sql_delete_table % {"table": table}) migration = executor.loader.get_migration("migrations", "0001_initial") self.assertEqual(executor.detect_soft_applied(None, migration)[0], False)
with connection.schema_editor() as editor: for table in tables[:2]: editor.execute(editor.sql_delete_table % {"table": table}) for table in tables: self.assertTableNotExists(table)
executor.loader.build_graph()
executor.migrate([ ("lookuperror_a", "0004_a4"), ("lookuperror_c", "0003_c3"), ]) self.assertTableExists("lookuperror_a_a4") self.assertTableExists("lookuperror_c_c3")
executor.loader.build_graph()
executor.migrate([ ("lookuperror_a", None), ("lookuperror_b", None), ("lookuperror_c", None), ]) self.assertTableNotExists("lookuperror_a_a1") self.assertTableNotExists("lookuperror_b_b1") self.assertTableNotExists("lookuperror_c_c1")
executor.loader.build_graph()
executor.migrate([("lookuperror_a", None)])
executor.loader.build_graph()
executor.migrate([ ("lookuperror_b", None), ("lookuperror_c", None) ]) self.assertTableNotExists("lookuperror_a_a1") self.assertTableNotExists("lookuperror_b_b1") self.assertTableNotExists("lookuperror_c_c1")
executor.loader.build_graph() state = executor.migrate([ ('mutate_state_a', '0001_initial'), ]) self.assertIn('added', dict(state.models['mutate_state_b', 'b'].fields)) executor.loader.build_graph() state = executor.migrate([ ('mutate_state_a', None), ]) self.assertIn('added', dict(state.models['mutate_state_b', 'b'].fields))
self.assertTableNotExists("migrations_author") self.assertTableNotExists("migrations_tribble") executor.migrate([ ("migrations", "0001_initial"), ("migrations", "0002_second"), ]) executor.loader.build_graph()
executor.migrate([ ("author_app", "0001_initial"), ("book_app", "0001_initial"), ]) self.assertTableExists("author_app_author") self.assertTableExists("book_app_book") executor.loader.build_graph()
executor.migrate([("author_app", "0002_alter_id")])
executor.loader.build_graph()
with connection.schema_editor() as editor: editor.execute(editor.sql_delete_table % {"table": "book_app_book"}) editor.execute(editor.sql_delete_table % {"table": "author_app_author"}) self.assertTableNotExists("author_app_author") self.assertTableNotExists("book_app_book")
recorder.record_applied("migrations", "0001_initial") executor = MigrationExecutor(connection) executor.migrate([("migrations", "0002_second")], fake=True)
self.assertIn( ("migrations", "0001_squashed_0002"), recorder.applied_migrations(), )
recorder.record_applied("migrations", "0001_initial") recorder.record_applied("migrations", "0002_second") executor = MigrationExecutor(connection) executor.migrate([("migrations", "0001_squashed_0002")])
self.assertIn( ("migrations", "0001_squashed_0002"), recorder.applied_migrations(), )
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
self.assertTableNotExists("migrations_ipaddressfield") call_command("migrate", verbosity=0) self.assertTableExists("migrations_ipaddressfield") call_command("migrate", "migrations", "zero", verbosity=0) self.assertTableNotExists("migrations_ipaddressfield")
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
validator = RegexValidator(regex=re.compile(r'^\w+$', re.U)) string = MigrationWriter.serialize(validator)[0] self.assertEqual(string, "django.core.validators.RegexValidator(regex=re.compile('^\\\\w+$', 32))") self.serialize_round_trip(validator)
validator = RegexValidator(r'^[0-9]+$', flags=re.U) string = MigrationWriter.serialize(validator)[0] self.assertEqual(string, "django.core.validators.RegexValidator('^[0-9]+$', flags=32)") self.serialize_round_trip(validator)
validator = RegexValidator('^[-a-zA-Z0-9_]+$', 'Invalid', 'invalid') string = MigrationWriter.serialize(validator)[0] self.assertEqual(string, "django.core.validators.RegexValidator('^[-a-zA-Z0-9_]+$', 'Invalid', 'invalid')") self.serialize_round_trip(validator)
validator = EmailValidator(message="hello") string = MigrationWriter.serialize(validator)[0] self.assertEqual(string, "django.core.validators.EmailValidator(message='hello')") self.serialize_round_trip(validator)
self.assertIsInstance(output, six.binary_type, "Migration as_string returned unicode") result = self.safe_exec(output) self.assertIn("Migration", result) tokens = tokenize.generate_tokens(six.StringIO(str(output)).readline) for token_type, token_source, (srow, scol), __, line in tokens: if token_type == tokenize.STRING: self.assertFalse( token_source.startswith('u'), "Unicode literal prefix found at %d:%d: %r" % ( srow, scol, line.strip() ) )
@ignore_warnings(category=ImportWarning) def test_migration_path(self): test_apps = [ 'migrations.migrations_test_apps.normal', 'migrations.migrations_test_apps.with_package_model', 'migrations.migrations_test_apps.without_init_file', ]
class DeconstructibleInstances(object): def deconstruct(self): return ('DeconstructibleInstances', [], {})
self.assertEqual([name for name, mgr in food_state.managers], ['food_mgr']) self.assertTrue(all(isinstance(name, six.text_type) for name, mgr in food_state.managers)) self.assertEqual(food_state.managers[0][1].args, ('a', 'b', 1, 2))
self.assertEqual(food_no_managers_state.managers, [])
self.assertEqual([name for name, mgr in food_no_default_manager_state.managers], ['food_no_mgr', 'food_mgr']) self.assertTrue(all(isinstance(name, six.text_type) for name, mgr in food_no_default_manager_state.managers)) self.assertEqual(food_no_default_manager_state.managers[0][1].__class__, models.Manager) self.assertIsInstance(food_no_default_manager_state.managers[1][1], FoodManager)
('default', base_mgr), ('food_mgr2', mgr2), (b'food_mgr1', mgr1),
apps = Apps(["migrations"])
ms = ModelState.from_model(Novel) with self.assertRaises(InvalidBasesError): ms.render(apps)
ModelState.from_model(Book).render(apps) ModelState.from_model(Novel).render(apps)
ms = ModelState.from_model(FooBar) with self.assertRaises(InvalidBasesError): ms.render(apps)
ModelState.from_model(Foo).render(apps) self.assertSequenceEqual(ModelState.from_model(Foo).bases, [models.Model]) ModelState.from_model(Bar).render(apps) self.assertSequenceEqual(ModelState.from_model(Bar).bases, [models.Model]) ModelState.from_model(FooBar).render(apps) self.assertSequenceEqual(ModelState.from_model(FooBar).bases, ['migrations.foo', 'migrations.bar']) ModelState.from_model(SubFooBar).render(apps) self.assertSequenceEqual(ModelState.from_model(SubFooBar).bases, ['migrations.foobar'])
project_state = ProjectState() project_state.add_model(ModelState.from_model(A)) project_state.add_model(ModelState.from_model(B)) project_state.add_model(ModelState.from_model(C)) project_state.add_model(ModelState.from_model(D)) project_state.add_model(ModelState.from_model(E)) project_state.add_model(ModelState.from_model(F)) final_apps = project_state.apps self.assertEqual(len(final_apps.get_models()), 6)
project_state = ProjectState() project_state.add_model(ModelState.from_model(A)) project_state.add_model(ModelState.from_model(B)) project_state.add_model(ModelState.from_model(C)) project_state.add_model(ModelState.from_model(F)) with self.assertRaises(InvalidBasesError): project_state.apps
project_state = ProjectState() project_state.add_model(ModelState.from_model(A)) project_state.add_model(ModelState.from_model(B)) self.assertEqual(len(project_state.apps.get_models()), 2)
self.assertIs(model_a_old._meta.get_field('b').related_model, model_b_old) self.assertIs(model_b_old._meta.get_field('a_ptr').related_model, model_a_old)
self.assertIsNot(model_a_old, model_a_new) self.assertIsNot(model_b_old, model_b_new) self.assertIsNot(model_c_old, model_c_new) self.assertIs(model_a_old._meta.get_field('b').related_model, model_b_old) self.assertIs(model_b_old._meta.get_field('a_ptr').related_model, model_a_old) self.assertIs(model_a_new._meta.get_field('b').related_model, model_b_new) self.assertIs(model_b_new._meta.get_field('a_ptr').related_model, model_a_new) self.assertIs(model_a_new._meta.get_field('from_c').related_model, model_c_new) self.assertIs(model_c_new._meta.get_field('to_a').related_model, model_a_new)
model_a_old = get_model_a(old_state) model_a_new = get_model_a(project_state) self.assertIsNot(model_a_old, model_a_new) self.assertEqual(len(model_a_old._meta.related_objects), 1) self.assertEqual(len(model_a_new._meta.related_objects), 0)
project_state = ProjectState() project_state.add_model(ModelState.from_model(A)) project_state.add_model(ModelState.from_model(B)) old_state = project_state.clone()
operation.state_forwards("something", project_state)
field_to_a_old = model_a_old._meta.get_field("to_a") self.assertEqual(field_to_a_old.m2m_field_name(), "from_a") self.assertEqual(field_to_a_old.m2m_reverse_field_name(), "to_a") self.assertIs(field_to_a_old.related_model, model_a_old) self.assertIs(field_to_a_old.remote_field.through._meta.get_field('to_a').related_model, model_a_old) self.assertIs(field_to_a_old.remote_field.through._meta.get_field('from_a').related_model, model_a_old)
field_to_a_new = model_a_new._meta.get_field("to_a") self.assertEqual(field_to_a_new.m2m_field_name(), "from_a") self.assertEqual(field_to_a_new.m2m_reverse_field_name(), "to_a") self.assertIs(field_to_a_new.related_model, model_a_new) self.assertIs(field_to_a_new.remote_field.through._meta.get_field('to_a').related_model, model_a_new) self.assertIs(field_to_a_new.remote_field.through._meta.get_field('from_a').related_model, model_a_new)
project_state = ProjectState() project_state.add_model(ModelState( "migrations", "Tag", [ ("id", models.AutoField(primary_key=True)), ("name", models.CharField(max_length=100)), ("hidden", models.BooleanField()), ], {}, None, ))
project_state = ProjectState() project_state.add_model(ModelState( "migrations", "Tag", [ ("id", models.AutoField(primary_key=True)), ("name", models.CharField(max_length=99)), ("hidden", models.BooleanField()), ], {}, None, )) self.assertNotEqual(project_state, other_state) self.assertEqual(project_state == other_state, False)
project_state = ProjectState() project_state.add_model(ModelState.from_model(Author)) project_state.add_model(ModelState.from_model(Publisher)) project_state.add_model(ModelState.from_model(Book)) project_state.add_model(ModelState.from_model(Magazine)) self.assertEqual(len(project_state.apps.get_models()), 4)
project_state = ProjectState() project_state.add_model(ModelState.from_model(Book)) msg = ( "The field migrations.Book.author was declared with a lazy reference " "to 'migrations.author', but app 'migrations' doesn't provide model 'author'.\n" "The field migrations.Book.publisher was declared with a lazy reference " "to 'migrations.publisher', but app 'migrations' doesn't provide model 'publisher'." ) with self.assertRaisesMessage(ValueError, msg): project_state.apps
project_state = ProjectState() project_state.add_model(ModelState.from_model(Magazine)) msg = ( "The field migrations.Magazine.authors was declared with a lazy reference " "to 'migrations.author\', but app 'migrations' doesn't provide model 'author'.\n" "The field migrations.Magazine_authors.author was declared with a lazy reference " "to \'migrations.author\', but app 'migrations' doesn't provide model 'author'." ) with self.assertRaisesMessage(ValueError, msg): project_state.apps
project_state.add_model(ModelState.from_model(Book)) msg = ( "The field migrations.Book.author was declared with a lazy reference " "to 'migrations.author', but app 'migrations' doesn't provide model 'author'.\n" "The field migrations.Book.publisher was declared with a lazy reference " "to 'migrations.publisher', but app 'migrations' doesn't provide model 'publisher'.\n" "The field migrations.Magazine.authors was declared with a lazy reference " "to 'migrations.author', but app 'migrations' doesn't provide model 'author'.\n" "The field migrations.Magazine_authors.author was declared with a lazy reference " "to 'migrations.author', but app 'migrations' doesn't provide model 'author'." ) with self.assertRaisesMessage(ValueError, msg): project_state.apps
project_state = ProjectState() project_state.add_model(ModelState.from_model(TestModel)) with self.assertRaises(ValueError): project_state.apps
project_state = ProjectState(real_apps=["contenttypes"]) project_state.add_model(ModelState.from_model(TestModel)) rendered_state = project_state.apps self.assertEqual( len([x for x in rendered_state.get_models() if x._meta.app_label == "migrations"]), 1, )
project_state = ProjectState() project_state.add_model(ModelState.from_model(Author)) project_state.add_model(ModelState.from_model(Book)) self.assertEqual( [name for name, field in project_state.models["migrations", "book"].fields], ["id", "author"], )
self.assertEqual([name for name, mgr in food_state.managers], ['food_mgr']) self.assertEqual(food_state.managers[0][1].args, ('a', 'b', 1, 2))
self.assertRelated(A, [M, P, Q, Z]) self.assertRelated(M, [P, Q, Z]) self.assertRelated(P, [M, Q, Z]) self.assertRelated(Q, [M, P, Z]) self.assertRelated(Z, [M, P, Q])
from __future__ import unicode_literals
from __future__ import unicode_literals
Editor = apps.get_model('migrations', 'Editor') Editor.objects.create(name='Test Editor') raise RuntimeError('Abort migration')
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
project_state = ProjectState() new_state = project_state.clone() operation.state_forwards(app_label, new_state) self.assertTableNotExists("%s_pony" % app_label) with connection.schema_editor() as editor: operation.database_forwards(app_label, editor, project_state, new_state) if should_run: self.assertTableExists("%s_pony" % app_label) else: self.assertTableNotExists("%s_pony" % app_label) with connection.schema_editor() as editor: operation.database_backwards(app_label, editor, new_state, project_state) self.assertTableNotExists("%s_pony" % app_label)
new_state = project_state.clone() operation.state_forwards(app_label, new_state) self.assertEqual(new_state, project_state) self.assertEqual(project_state.apps.get_model(app_label, "Pony").objects.count(), 0) with connection.schema_editor() as editor: operation.database_forwards(app_label, editor, project_state, new_state) Pony = project_state.apps.get_model(app_label, "Pony") if should_run: self.assertEqual(Pony.objects.count(), 2) else: self.assertEqual(Pony.objects.count(), 0)
def inner_method(models, schema_editor): Pony = models.get_model(app_label, "Pony") Pony.objects.create(pink=1, weight=3.55) Pony.objects.create(weight=5)
new_state = project_state.clone() operation.state_forwards(app_label, new_state) self.assertEqual(new_state, project_state) self.assertEqual(project_state.apps.get_model(app_label, "Pony").objects.count(), 0) with connection.schema_editor() as editor: operation.database_forwards(app_label, editor, project_state, new_state) Pony = project_state.apps.get_model(app_label, "Pony") if should_run: self.assertEqual(Pony.objects.count(), 2) else: self.assertEqual(Pony.objects.count(), 0)
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
import functools import re
graph = MigrationGraph() graph.add_node(("testapp", "0001_initial"), None) graph.add_node(("testapp", "0002_foobar"), None) graph.add_node(("otherapp", "0001_initial"), None) graph.add_dependency("testapp.0002_foobar", ("testapp", "0002_foobar"), ("testapp", "0001_initial")) graph.add_dependency("testapp.0002_foobar", ("testapp", "0002_foobar"), ("otherapp", "0001_initial")) before = self.make_project_state([]) after = self.make_project_state([self.author_empty, self.other_pony, self.other_stable]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() changes = autodetector.arrange_for_graph(changes, graph) self.assertEqual(changes["testapp"][0].name, "0003_author") self.assertEqual(changes["testapp"][0].dependencies, [("testapp", "0002_foobar")]) self.assertEqual(changes["otherapp"][0].name, "0002_pony_stable") self.assertEqual(changes["otherapp"][0].dependencies, [("otherapp", "0001_initial")])
before = self.make_project_state([]) after = self.make_project_state([self.author_empty, self.other_pony, self.other_stable, self.third_thing]) autodetector = MigrationAutodetector(before, after, MigrationQuestioner({"ask_initial": True})) changes = autodetector._detect_changes() graph = MigrationGraph() changes = autodetector.arrange_for_graph(changes, graph) changes["testapp"][0].dependencies.append(("otherapp", "0001_initial")) changes = autodetector._trim_to_apps(changes, {"testapp"}) self.assertEqual(changes["testapp"][0].name, "0001_initial") self.assertEqual(changes["otherapp"][0].name, "0001_initial") self.assertNotIn("thirdapp", changes)
graph = MigrationGraph() graph.add_node(("testapp", "0001_initial"), None) graph.add_node(("testapp", "0002_foobar"), None) graph.add_node(("otherapp", "0001_initial"), None) graph.add_dependency("testapp.0002_foobar", ("testapp", "0002_foobar"), ("testapp", "0001_initial"))
before = self.make_project_state([]) after = self.make_project_state([self.author_empty, self.other_pony, self.other_stable]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes()
migration_name = 'custom_name' changes = autodetector.arrange_for_graph(changes, graph, migration_name)
self.assertEqual(changes["testapp"][0].name, "0003_%s" % migration_name) self.assertEqual(changes["testapp"][0].dependencies, [("testapp", "0002_foobar")]) self.assertEqual(changes["otherapp"][0].name, "0002_%s" % migration_name) self.assertEqual(changes["otherapp"][0].dependencies, [("otherapp", "0001_initial")])
before = self.make_project_state([]) after = self.make_project_state([self.other_pony_food]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'otherapp', 1) self.assertOperationTypes(changes, 'otherapp', 0, ["CreateModel"]) self.assertOperationAttributes(changes, "otherapp", 0, 0, name="Pony") self.assertEqual([name for name, mgr in changes['otherapp'][0].operations[0].managers], ['food_qs', 'food_mgr', 'food_mgr_kwargs'])
before = self.make_project_state([self.author_empty]) after = self.make_project_state([]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["DeleteModel"]) self.assertOperationAttributes(changes, "testapp", 0, 0, name="Author")
before = self.make_project_state([self.author_empty]) after = self.make_project_state([self.author_name]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["AddField"]) self.assertOperationAttributes(changes, "testapp", 0, 0, name="name")
before = self.make_project_state([self.author_empty]) after = self.make_project_state([self.author_dates_of_birth_auto_now]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["AddField", "AddField", "AddField"]) self.assertOperationFieldAttributes(changes, "testapp", 0, 0, auto_now=True) self.assertOperationFieldAttributes(changes, "testapp", 0, 1, auto_now=True) self.assertOperationFieldAttributes(changes, "testapp", 0, 2, auto_now=True)
before = self.make_project_state([self.author_empty]) after = self.make_project_state([self.author_dates_of_birth_auto_now_add]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["AddField", "AddField", "AddField"]) self.assertOperationFieldAttributes(changes, "testapp", 0, 0, auto_now_add=True) self.assertOperationFieldAttributes(changes, "testapp", 0, 1, auto_now_add=True) self.assertOperationFieldAttributes(changes, "testapp", 0, 2, auto_now_add=True)
before = self.make_project_state([self.author_empty]) after = self.make_project_state([self.author_dates_of_birth_auto_now_add]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["AddField", "AddField", "AddField"]) self.assertOperationFieldAttributes(changes, "testapp", 0, 0, auto_now_add=True) self.assertOperationFieldAttributes(changes, "testapp", 0, 1, auto_now_add=True) self.assertOperationFieldAttributes(changes, "testapp", 0, 2, auto_now_add=True) self.assertEqual(mocked_ask_method.call_count, 3)
before = self.make_project_state([self.author_name]) after = self.make_project_state([self.author_empty]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["RemoveField"]) self.assertOperationAttributes(changes, "testapp", 0, 0, name="name")
before = self.make_project_state([self.author_name]) after = self.make_project_state([self.author_name_longer]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["AlterField"]) self.assertOperationAttributes(changes, "testapp", 0, 0, name="name", preserve_default=True)
before = self.make_project_state([ModelState("testapp", "Author", [ ("id", models.AutoField(primary_key=True)), ("file", models.FileField(max_length=200, upload_to=content_file_name('file'))), ])]) after = self.make_project_state([ModelState("testapp", "Author", [ ("id", models.AutoField(primary_key=True)), ("file", models.FileField(max_length=200, upload_to=content_file_name('file'))), ])]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 0)
args_changed = self.make_project_state([ModelState("testapp", "Author", [ ("id", models.AutoField(primary_key=True)), ("file", models.FileField(max_length=200, upload_to=content_file_name('other-file'))), ])]) autodetector = MigrationAutodetector(before, args_changed) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ['AlterField']) value = changes['testapp'][0].operations[0].field.upload_to self.assertEqual( (_content_file_name, ('other-file',), {}), (value.func, value.args, value.keywords) )
before = self.make_project_state([self.author_name_null]) after = self.make_project_state([self.author_name_default]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["AlterField"]) self.assertOperationAttributes(changes, "testapp", 0, 0, name="name", preserve_default=True) self.assertOperationFieldAttributes(changes, "testapp", 0, 0, default='Ada Lovelace')
before = self.make_project_state([self.author_name_null]) after = self.make_project_state([self.author_name]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertEqual(mocked_ask_method.call_count, 1) self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["AlterField"]) self.assertOperationAttributes(changes, "testapp", 0, 0, name="name", preserve_default=True) self.assertOperationFieldAttributes(changes, "testapp", 0, 0, default=models.NOT_PROVIDED)
before = self.make_project_state([self.author_name_null]) after = self.make_project_state([self.author_name]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertEqual(mocked_ask_method.call_count, 1) self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["AlterField"]) self.assertOperationAttributes(changes, "testapp", 0, 0, name="name", preserve_default=False) self.assertOperationFieldAttributes(changes, "testapp", 0, 0, default="Some Name")
before = self.make_project_state([self.author_name]) after = self.make_project_state([self.author_name_renamed]) autodetector = MigrationAutodetector(before, after, MigrationQuestioner({"ask_rename": True})) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["RenameField"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, old_name="name", new_name="names")
before = self.make_project_state([self.author_with_book, self.book]) after = self.make_project_state([self.author_renamed_with_book, self.book_with_author_renamed]) autodetector = MigrationAutodetector(before, after, MigrationQuestioner({"ask_rename_model": True})) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["RenameModel"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, old_name="Author", new_name="Writer") self.assertNumberMigrations(changes, 'otherapp', 0)
before = self.make_project_state([self.author_with_m2m_through, self.publisher, self.contract]) after = self.make_project_state([self.author_with_renamed_m2m_through, self.publisher, self.contract_renamed]) autodetector = MigrationAutodetector(before, after, MigrationQuestioner({'ask_rename_model': True})) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ['RenameModel']) self.assertOperationAttributes(changes, 'testapp', 0, 0, old_name='Contract', new_name='Deal')
before = self.make_project_state([self.author_with_book, self.book]) after = self.make_project_state([self.author_renamed_with_book, self.book_with_field_and_author_renamed]) autodetector = MigrationAutodetector(before, after, MigrationQuestioner({ "ask_rename": True, "ask_rename_model": True, })) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["RenameModel"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, old_name="Author", new_name="Writer") self.assertNumberMigrations(changes, 'otherapp', 1) self.assertOperationTypes(changes, 'otherapp', 0, ["RenameField"]) self.assertOperationAttributes(changes, 'otherapp', 0, 0, old_name="author", new_name="writer")
before = self.make_project_state([]) after = self.make_project_state([self.author_name, self.book, self.edition]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["CreateModel"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, name="Author") self.assertMigrationDependencies(changes, 'testapp', 0, []) self.assertNumberMigrations(changes, 'otherapp', 1) self.assertOperationTypes(changes, 'otherapp', 0, ["CreateModel"]) self.assertOperationAttributes(changes, 'otherapp', 0, 0, name="Book") self.assertMigrationDependencies(changes, 'otherapp', 0, [("testapp", "auto_1")]) self.assertNumberMigrations(changes, 'thirdapp', 1) self.assertOperationTypes(changes, 'thirdapp', 0, ["CreateModel"]) self.assertOperationAttributes(changes, 'thirdapp', 0, 0, name="Edition") self.assertMigrationDependencies(changes, 'thirdapp', 0, [("otherapp", "auto_1")])
before = self.make_project_state([]) after = self.make_project_state([self.author_empty, self.author_proxy_third, self.book_proxy_fk]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["CreateModel"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, name="Author") self.assertMigrationDependencies(changes, 'testapp', 0, []) self.assertNumberMigrations(changes, 'otherapp', 1) self.assertOperationTypes(changes, 'otherapp', 0, ["CreateModel"]) self.assertOperationAttributes(changes, 'otherapp', 0, 0, name="Book") self.assertMigrationDependencies(changes, 'otherapp', 0, [("thirdapp", "auto_1")]) self.assertNumberMigrations(changes, 'thirdapp', 1) self.assertOperationTypes(changes, 'thirdapp', 0, ["CreateModel"]) self.assertOperationAttributes(changes, 'thirdapp', 0, 0, name="AuthorProxy") self.assertMigrationDependencies(changes, 'thirdapp', 0, [("testapp", "auto_1")])
before = self.make_project_state([]) after = self.make_project_state([self.author_with_publisher, self.publisher]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["CreateModel", "CreateModel", "AddField"]) self.assertOperationAttributes(changes, "testapp", 0, 0, name="Author") self.assertOperationAttributes(changes, "testapp", 0, 1, name="Publisher") self.assertOperationAttributes(changes, "testapp", 0, 2, name="publisher") self.assertMigrationDependencies(changes, 'testapp', 0, [])
before = self.make_project_state([]) after = self.make_project_state([self.author_with_book, self.book, self.publisher_with_book]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["CreateModel", "CreateModel"]) self.assertOperationAttributes(changes, "testapp", 0, 0, name="Author") self.assertOperationAttributes(changes, "testapp", 0, 1, name="Publisher") self.assertMigrationDependencies(changes, 'testapp', 0, [("otherapp", "auto_1")]) self.assertNumberMigrations(changes, 'otherapp', 2) self.assertOperationTypes(changes, 'otherapp', 0, ["CreateModel"]) self.assertOperationTypes(changes, 'otherapp', 1, ["AddField"]) self.assertMigrationDependencies(changes, 'otherapp', 0, []) self.assertMigrationDependencies(changes, 'otherapp', 1, [("otherapp", "auto_1"), ("testapp", "auto_1")]) self.assertTrue(changes['otherapp'][0].initial) self.assertTrue(changes['otherapp'][1].initial)
before = self.make_project_state([]) after = self.make_project_state([self.author_with_publisher, self.publisher_with_author]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["CreateModel", "CreateModel", "AddField"]) self.assertOperationAttributes(changes, "testapp", 0, 0, name="Author") self.assertOperationAttributes(changes, "testapp", 0, 1, name="Publisher") self.assertOperationAttributes(changes, "testapp", 0, 2, name="publisher") self.assertMigrationDependencies(changes, 'testapp', 0, [])
before = self.make_project_state([]) after = self.make_project_state([self.knight, self.rabbit]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'eggs', 1) self.assertOperationTypes(changes, 'eggs', 0, ["CreateModel", "CreateModel", "AlterUniqueTogether"]) self.assertNotIn("unique_together", changes['eggs'][0].operations[0].options) self.assertNotIn("unique_together", changes['eggs'][0].operations[1].options) self.assertMigrationDependencies(changes, 'eggs', 0, [])
before = self.make_project_state([self.author_empty]) after = self.make_project_state([self.author_with_db_table_options]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["AlterModelTable"]) self.assertOperationAttributes(changes, "testapp", 0, 0, name="author", table="author_one")
before = self.make_project_state([self.author_with_db_table_options]) after = self.make_project_state([self.author_with_new_db_table_options]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["AlterModelTable"]) self.assertOperationAttributes(changes, "testapp", 0, 0, name="author", table="author_two")
before = self.make_project_state([self.author_with_db_table_options]) after = self.make_project_state([self.author_empty]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["AlterModelTable"]) self.assertOperationAttributes(changes, "testapp", 0, 0, name="author", table=None)
before = self.make_project_state([self.author_with_db_table_options]) after = self.make_project_state([self.author_with_db_table_options]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertEqual(len(changes), 0)
before = self.make_project_state([self.author_with_db_table_options]) after = self.make_project_state([self.author_renamed_with_db_table_options]) autodetector = MigrationAutodetector(before, after, MigrationQuestioner({"ask_rename_model": True})) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["RenameModel"]) self.assertOperationAttributes(changes, "testapp", 0, 0, old_name="Author", new_name="NewAuthor")
before = self.make_project_state([self.author_with_db_table_options]) after = self.make_project_state([self.author_renamed_with_new_db_table_options]) autodetector = MigrationAutodetector(before, after, MigrationQuestioner({"ask_rename_model": True})) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["RenameModel", "AlterModelTable"]) self.assertOperationAttributes(changes, "testapp", 0, 0, old_name="Author", new_name="NewAuthor") self.assertOperationAttributes(changes, "testapp", 0, 1, name="newauthor", table="author_three")
self.assertNumberMigrations(changes, "testapp", 0)
model_state_not_specified = ModelState("a", "model", [("id", models.AutoField(primary_key=True))]) model_state_none = ModelState("a", "model", [ ("id", models.AutoField(primary_key=True)) ], { "index_together": None, "unique_together": None, }) model_state_empty = ModelState("a", "model", [ ("id", models.AutoField(primary_key=True)) ], { "index_together": set(), "unique_together": set(), })
before = self.make_project_state([self.author_empty, self.book]) after = self.make_project_state([self.author_empty, self.book_foo_together]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, "otherapp", 1) self.assertOperationTypes(changes, "otherapp", 0, ["AlterUniqueTogether", "AlterIndexTogether"]) self.assertOperationAttributes(changes, "otherapp", 0, 0, name="book", unique_together={("author", "title")}) self.assertOperationAttributes(changes, "otherapp", 0, 1, name="book", index_together={("author", "title")})
self.assertNumberMigrations(changes, "otherapp", 1) self.assertOperationTypes(changes, "otherapp", 0, ["AlterUniqueTogether", "AlterIndexTogether"]) self.assertOperationAttributes(changes, "otherapp", 0, 0, name="book", unique_together=set()) self.assertOperationAttributes(changes, "otherapp", 0, 1, name="book", index_together=set())
before = self.make_project_state([self.author_empty, self.book_foo_together]) after = self.make_project_state([self.author_empty, self.book_with_no_author]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, "otherapp", 1) self.assertOperationTypes(changes, "otherapp", 0, [ "AlterUniqueTogether", "AlterIndexTogether", "RemoveField" ]) self.assertOperationAttributes(changes, "otherapp", 0, 0, name="book", unique_together=set()) self.assertOperationAttributes(changes, "otherapp", 0, 1, name="book", index_together=set()) self.assertOperationAttributes(changes, "otherapp", 0, 2, model_name="book", name="author")
before = self.make_project_state([self.author_empty, self.book_foo_together]) after = self.make_project_state([self.author_empty, self.book_foo_together]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertEqual(len(changes), 0)
before = self.make_project_state([self.author_empty, self.book_foo_together]) after = self.make_project_state([self.author_empty, self.book_foo_together_2]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, "otherapp", 1) self.assertOperationTypes(changes, "otherapp", 0, ["AlterUniqueTogether", "AlterIndexTogether"]) self.assertOperationAttributes(changes, "otherapp", 0, 0, name="book", unique_together={("title", "author")}) self.assertOperationAttributes(changes, "otherapp", 0, 1, name="book", index_together={("title", "author")})
self.assertNumberMigrations(changes, "otherapp", 1) self.assertOperationTypes(changes, "otherapp", 0, ["AddField", "AlterUniqueTogether", "AlterIndexTogether"]) self.assertOperationAttributes(changes, "otherapp", 0, 1, name="book", unique_together={("title", "newfield")}) self.assertOperationAttributes(changes, "otherapp", 0, 2, name="book", index_together={("title", "newfield")})
self.assertEqual(len(changes['otherapp']), 1) migration = changes['otherapp'][0] self.assertEqual(len(migration.operations), 4) self.assertOperationTypes( changes, 'otherapp', 0, ['CreateModel', 'AddField', 'AlterUniqueTogether', 'AlterIndexTogether'] )
self.assertNumberMigrations(changes, "otherapp", 1) self.assertOperationTypes(changes, "otherapp", 0, ["RemoveField", "AlterUniqueTogether", "AlterIndexTogether"]) self.assertOperationAttributes(changes, "otherapp", 0, 0, model_name="book", name="newfield") self.assertOperationAttributes(changes, "otherapp", 0, 1, name="book", unique_together={("author", "title")}) self.assertOperationAttributes(changes, "otherapp", 0, 2, name="book", index_together={("author", "title")})
self.assertNumberMigrations(changes, "otherapp", 1) self.assertOperationTypes(changes, "otherapp", 0, ["RenameField", "AlterUniqueTogether", "AlterIndexTogether"]) self.assertOperationAttributes(changes, "otherapp", 0, 1, name="book", unique_together={ ("title", "newfield2") }) self.assertOperationAttributes(changes, "otherapp", 0, 2, name="book", index_together={("title", "newfield2")})
before = self.make_project_state([self.author_empty]) after = self.make_project_state([self.author_empty, self.author_proxy]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, "testapp", 1) self.assertOperationTypes(changes, "testapp", 0, ["CreateModel"]) self.assertOperationAttributes(changes, "testapp", 0, 0, name="AuthorProxy", options={"proxy": True})
before = self.make_project_state([self.author_empty, self.author_proxy]) after = self.make_project_state([self.author_empty, self.author_proxy_notproxy]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, "testapp", 1) self.assertOperationTypes(changes, "testapp", 0, ["DeleteModel", "CreateModel"]) self.assertOperationAttributes(changes, "testapp", 0, 0, name="AuthorProxy") self.assertOperationAttributes(changes, "testapp", 0, 1, name="AuthorProxy", options={})
before = self.make_project_state([]) after = self.make_project_state([self.author_empty, self.author_proxy_third, self.book_proxy_fk]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertEqual(changes['otherapp'][0].operations[0].fields[2][1].remote_field.field_name, 'id')
before = self.make_project_state([]) after = self.make_project_state([self.author_custom_pk, self.author_proxy_third, self.book_proxy_fk]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertEqual(changes['otherapp'][0].operations[0].fields[2][1].remote_field.field_name, 'pk_field')
before = self.make_project_state([self.author_empty]) after = self.make_project_state([self.author_empty, self.author_unmanaged]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["CreateModel"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, name="AuthorUnmanaged", options={"managed": False})
before = self.make_project_state([self.author_empty, self.author_unmanaged]) after = self.make_project_state([self.author_empty, self.author_unmanaged_managed]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["AlterModelOptions"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, name="authorunmanaged", options={})
before = self.make_project_state([self.author_empty, self.author_unmanaged_managed]) after = self.make_project_state([self.author_empty, self.author_unmanaged]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, "testapp", 0, ["AlterModelOptions"]) self.assertOperationAttributes(changes, "testapp", 0, 0, name="authorunmanaged", options={"managed": False})
before = self.make_project_state([]) after = self.make_project_state([self.author_unmanaged_default_pk, self.book]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertEqual(changes['otherapp'][0].operations[0].fields[2][1].remote_field.field_name, 'id')
before = self.make_project_state([]) after = self.make_project_state([self.author_unmanaged_custom_pk, self.book]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertEqual(changes['otherapp'][0].operations[0].fields[2][1].remote_field.field_name, 'pk_field')
self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["CreateModel"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, name="Author") self.assertMigrationDependencies(changes, 'testapp', 0, [("__setting__", "AUTH_USER_MODEL")])
self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["AlterField"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, model_name="author", name='user') fk_field = changes['testapp'][0].operations[0].field to_model = '%s.%s' % ( fk_field.remote_field.model._meta.app_label, fk_field.remote_field.model._meta.object_name, ) self.assertEqual(to_model, 'thirdapp.CustomUser')
before = self.make_project_state([self.author_empty]) after = self.make_project_state([self.author_name_default]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["AddField"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, name="name")
self.assertEqual(len(changes), 0)
before = self.make_project_state([self.author_name_deconstructible_list_1]) after = self.make_project_state([self.author_name_deconstructible_list_2]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertEqual(changes, {})
before = self.make_project_state([self.author_name_deconstructible_list_1]) after = self.make_project_state([self.author_name_deconstructible_list_3]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertEqual(len(changes), 1)
before = self.make_project_state([self.author_name_deconstructible_tuple_1]) after = self.make_project_state([self.author_name_deconstructible_tuple_2]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertEqual(changes, {})
before = self.make_project_state([self.author_name_deconstructible_tuple_1]) after = self.make_project_state([self.author_name_deconstructible_tuple_3]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertEqual(len(changes), 1)
before = self.make_project_state([self.author_name_deconstructible_dict_1]) after = self.make_project_state([self.author_name_deconstructible_dict_2]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertEqual(changes, {})
before = self.make_project_state([self.author_name_deconstructible_dict_1]) after = self.make_project_state([self.author_name_deconstructible_dict_3]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertEqual(len(changes), 1)
before = self.make_project_state([self.author_name_nested_deconstructible_1]) after = self.make_project_state([self.author_name_nested_deconstructible_2]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertEqual(changes, {})
before = self.make_project_state([self.author_name_nested_deconstructible_1]) after = self.make_project_state([self.author_name_nested_deconstructible_changed_arg]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertEqual(len(changes), 1)
before = self.make_project_state([self.author_name_nested_deconstructible_1]) after = self.make_project_state([self.author_name_nested_deconstructible_extra_arg]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertEqual(len(changes), 1)
before = self.make_project_state([self.author_name_nested_deconstructible_1]) after = self.make_project_state([self.author_name_nested_deconstructible_changed_kwarg]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertEqual(len(changes), 1)
before = self.make_project_state([self.author_name_nested_deconstructible_1]) after = self.make_project_state([self.author_name_nested_deconstructible_extra_kwarg]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertEqual(len(changes), 1)
default=models.IntegerField,
before = self.make_project_state([]) after = self.make_project_state([author]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["CreateModel"])
before = self.make_project_state([self.author_with_publisher_string]) after = self.make_project_state([self.author_with_publisher, self.publisher]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["CreateModel", "RemoveField", "AddField"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, name="Publisher") self.assertOperationAttributes(changes, 'testapp', 0, 1, name="publisher_name") self.assertOperationAttributes(changes, 'testapp', 0, 2, name="publisher")
self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["RemoveField", "DeleteModel"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, name="publisher") self.assertOperationAttributes(changes, 'testapp', 0, 1, name="Publisher")
self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["AddField"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, name="publishers")
self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["AlterField"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, name="publishers")
self.assertNumberMigrations(changes, "testapp", 1) self.assertOperationTypes(changes, "testapp", 0, [ "CreateModel", "CreateModel", "CreateModel", "AddField", "AddField" ]) self.assertOperationAttributes(changes, 'testapp', 0, 0, name="Author") self.assertOperationAttributes(changes, 'testapp', 0, 1, name="Contract") self.assertOperationAttributes(changes, 'testapp', 0, 2, name="Publisher") self.assertOperationAttributes(changes, 'testapp', 0, 3, model_name='contract', name='publisher') self.assertOperationAttributes(changes, 'testapp', 0, 4, model_name='author', name='publishers')
after = self.make_project_state([self.book_with_no_author, self.author_name]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, "otherapp", 1) self.assertOperationTypes(changes, "otherapp", 0, ["RemoveField", "RemoveField", "RemoveField", "DeleteModel"]) self.assertOperationAttributes(changes, 'otherapp', 0, 0, name="author", model_name='attribution') self.assertOperationAttributes(changes, 'otherapp', 0, 1, name="book", model_name='attribution') self.assertOperationAttributes(changes, 'otherapp', 0, 2, name="authors", model_name='book') self.assertOperationAttributes(changes, 'otherapp', 0, 3, name='Attribution')
after = self.make_project_state([self.author_name]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, "otherapp", 1) self.assertOperationTypes(changes, "otherapp", 0, [ "RemoveField", "RemoveField", "RemoveField", "DeleteModel", "DeleteModel" ]) self.assertOperationAttributes(changes, 'otherapp', 0, 0, name="author", model_name='attribution') self.assertOperationAttributes(changes, 'otherapp', 0, 1, name="book", model_name='attribution') self.assertOperationAttributes(changes, 'otherapp', 0, 2, name="authors", model_name='book') self.assertOperationAttributes(changes, 'otherapp', 0, 3, name='Attribution') self.assertOperationAttributes(changes, 'otherapp', 0, 4, name='Book')
self.assertNumberMigrations(changes, "testapp", 1) self.assertOperationTypes(changes, "testapp", 0, [ "RemoveField", "RemoveField", "RemoveField", "DeleteModel", "DeleteModel" ]) self.assertOperationAttributes(changes, "testapp", 0, 0, name="publishers", model_name='author') self.assertOperationAttributes(changes, "testapp", 0, 1, name="author", model_name='contract') self.assertOperationAttributes(changes, "testapp", 0, 2, name="publisher", model_name='contract') self.assertOperationAttributes(changes, "testapp", 0, 3, name="Author") self.assertOperationAttributes(changes, "testapp", 0, 4, name="Contract")
self.assertNumberMigrations(changes, "testapp", 1) self.assertOperationTypes(changes, "testapp", 0, ["CreateModel", "RemoveField", "AddField"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, name='Publisher') self.assertOperationAttributes(changes, 'testapp', 0, 1, name="publishers", model_name='author') self.assertOperationAttributes(changes, 'testapp', 0, 2, name="publishers", model_name='author')
self.assertNumberMigrations(changes, "testapp", 1) self.assertOperationTypes(changes, "testapp", 0, ["RemoveField", "AddField", "DeleteModel"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, name="publishers", model_name='author') self.assertOperationAttributes(changes, 'testapp', 0, 1, name="publishers", model_name='author') self.assertOperationAttributes(changes, 'testapp', 0, 2, name='Publisher') self.assertOperationFieldAttributes(changes, 'testapp', 0, 1, max_length=100)
self.assertNumberMigrations(changes, "testapp", 1) self.assertOperationTypes(changes, "testapp", 0, ["RemoveField", "RemoveField", "DeleteModel", "DeleteModel"]) self.assertOperationAttributes(changes, "testapp", 0, 0, name="publisher", model_name='author') self.assertOperationAttributes(changes, "testapp", 0, 1, name="author", model_name='publisher') self.assertOperationAttributes(changes, "testapp", 0, 2, name="Author") self.assertOperationAttributes(changes, "testapp", 0, 3, name="Publisher")
self.assertNumberMigrations(changes, "testapp", 1) self.assertOperationTypes(changes, "testapp", 0, ["AlterModelOptions"]) self.assertOperationAttributes(changes, "testapp", 0, 0, options={ "permissions": [('can_hire', 'Can hire')], "verbose_name": "Authi", })
before = self.make_project_state([self.author_with_options]) after = self.make_project_state([self.author_empty]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, "testapp", 1) self.assertOperationTypes(changes, "testapp", 0, ["AlterModelOptions"]) self.assertOperationAttributes(changes, "testapp", 0, 0, name="author", options={})
self.assertNumberMigrations(changes, "testapp", 1) self.assertOperationTypes(changes, "testapp", 0, ["AlterModelOptions"]) self.assertOperationAttributes(changes, "testapp", 0, 0, name="authorproxy", options={ "verbose_name": "Super Author" })
before = self.make_project_state([self.book, self.author_with_book]) after = self.make_project_state([self.book, self.author_with_book_order_wrt]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["AlterOrderWithRespectTo"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, name="author", order_with_respect_to="book")
before = self.make_project_state([self.author_name]) after = self.make_project_state([self.book, self.author_with_book_order_wrt]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["AddField", "AlterOrderWithRespectTo"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, model_name="author", name="book") self.assertOperationAttributes(changes, 'testapp', 0, 1, name="author", order_with_respect_to="book")
before = self.make_project_state([self.book, self.author_with_book_order_wrt]) after = self.make_project_state([self.author_name]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["AlterOrderWithRespectTo", "RemoveField"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, name="author", order_with_respect_to=None) self.assertOperationAttributes(changes, 'testapp', 0, 1, model_name="author", name="book")
before = self.make_project_state([]) after = self.make_project_state([self.book, self.author_with_book_order_wrt]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["CreateModel", "AlterOrderWithRespectTo"]) self.assertOperationAttributes(changes, 'testapp', 0, 1, name="author", order_with_respect_to="book") self.assertNotIn("_order", [name for name, field in changes['testapp'][0].operations[0].fields])
before = self.make_project_state([self.other_pony]) after = self.make_project_state([self.other_pony_food]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'otherapp', 1) self.assertOperationTypes(changes, 'otherapp', 0, ["AlterModelManagers"]) self.assertOperationAttributes(changes, 'otherapp', 0, 0, name="pony") self.assertEqual([name for name, mgr in changes['otherapp'][0].operations[0].managers], ['food_qs', 'food_mgr', 'food_mgr_kwargs']) self.assertEqual(changes['otherapp'][0].operations[0].managers[1][1].args, ('a', 'b', 1, 2)) self.assertEqual(changes['otherapp'][0].operations[0].managers[2][1].args, ('x', 'y', 3, 4))
before = self.make_project_state([]) after = self.make_project_state([self.custom_user, self.aardvark]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'thirdapp', 1) self.assertOperationTypes(changes, 'thirdapp', 0, ["CreateModel", "CreateModel"]) self.assertOperationAttributes(changes, 'thirdapp', 0, 0, name="CustomUser") self.assertOperationAttributes(changes, 'thirdapp', 0, 1, name="Aardvark")
before = self.make_project_state([]) after = self.make_project_state([self.custom_user_no_inherit, self.aardvark]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes()
self.assertNumberMigrations(changes, 'thirdapp', 1) self.assertOperationTypes(changes, 'thirdapp', 0, ["CreateModel", "CreateModel"]) self.assertOperationAttributes(changes, 'thirdapp', 0, 0, name="CustomUser") self.assertOperationAttributes(changes, 'thirdapp', 0, 1, name="Aardvark")
before = self.make_project_state([]) after = self.make_project_state([self.aardvark_based_on_author, self.author_name]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["CreateModel", "CreateModel"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, name="Author") self.assertOperationAttributes(changes, 'testapp', 0, 1, name="Aardvark")
before = self.make_project_state([]) after = self.make_project_state([A, B, C, D, E]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, "app", 1) self.assertOperationTypes(changes, "app", 0, [ "CreateModel", "CreateModel", "CreateModel", "CreateModel", "CreateModel" ]) self.assertOperationAttributes(changes, "app", 0, 0, name="A") self.assertOperationAttributes(changes, "app", 0, 1, name="B") self.assertOperationAttributes(changes, "app", 0, 2, name="C") self.assertOperationAttributes(changes, "app", 0, 3, name="D") self.assertOperationAttributes(changes, "app", 0, 4, name="E")
before = self.make_project_state([]) after = self.make_project_state([self.author_empty, self.author_proxy, self.author_proxy_proxy]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["CreateModel", "CreateModel", "CreateModel"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, name="Author") self.assertOperationAttributes(changes, 'testapp', 0, 1, name="AuthorProxy") self.assertOperationAttributes(changes, 'testapp', 0, 2, name="AAuthorProxyProxy")
before = self.make_project_state([]) after = self.make_project_state([self.aardvark_pk_fk_author, self.author_name]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["CreateModel", "CreateModel"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, name="Author") self.assertOperationAttributes(changes, 'testapp', 0, 1, name="Aardvark")
loader = MigrationLoader(connection) before = self.make_project_state([]) after = self.make_project_state([self.book_migrations_fk]) after.real_apps = ["migrations"] autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes(graph=loader.graph) self.assertNumberMigrations(changes, 'otherapp', 1) self.assertOperationTypes(changes, 'otherapp', 0, ["CreateModel"]) self.assertOperationAttributes(changes, 'otherapp', 0, 0, name="Book") self.assertMigrationDependencies(changes, 'otherapp', 0, [("migrations", "__first__")])
loader = MigrationLoader(connection) before = self.make_project_state([]) after = self.make_project_state([self.book_migrations_fk]) after.real_apps = ["migrations"] autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes(graph=loader.graph) self.assertNumberMigrations(changes, 'otherapp', 1) self.assertOperationTypes(changes, 'otherapp', 0, ["CreateModel"]) self.assertOperationAttributes(changes, 'otherapp', 0, 0, name="Book") self.assertMigrationDependencies(changes, 'otherapp', 0, [("migrations", "0002_second")])
before = self.make_project_state([self.author_name, self.publisher_with_author]) after = self.make_project_state([self.aardvark_testapp, self.publisher_with_aardvark_author]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["CreateModel", "AlterField", "DeleteModel"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, name="Aardvark") self.assertOperationAttributes(changes, 'testapp', 0, 1, name="author") self.assertOperationAttributes(changes, 'testapp', 0, 2, name="Author")
before = self.make_project_state([self.author_name, self.book]) after = self.make_project_state([self.author_with_book, self.book]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["AddField"]) self.assertOperationAttributes(changes, 'testapp', 0, 0, name="book") self.assertMigrationDependencies(changes, 'testapp', 0, [("otherapp", "__first__")])
before = self.make_project_state([]) after = self.make_project_state([address, person, apackage, country]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, 'a', 2) self.assertNumberMigrations(changes, 'b', 1) self.assertOperationTypes(changes, 'a', 0, ["CreateModel", "CreateModel"]) self.assertOperationTypes(changes, 'a', 1, ["AddField"]) self.assertOperationTypes(changes, 'b', 0, ["CreateModel", "CreateModel"])
before = self.make_project_state([]) after = self.make_project_state([address, tenant]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes()
self.assertNumberMigrations(changes, 'a', 2) self.assertOperationTypes(changes, 'a', 0, ["CreateModel"]) self.assertOperationTypes(changes, 'a', 1, ["AddField"]) self.assertMigrationDependencies(changes, 'a', 0, []) self.assertMigrationDependencies(changes, 'a', 1, [('a', 'auto_1'), ('b', 'auto_1')]) self.assertNumberMigrations(changes, 'b', 1) self.assertOperationTypes(changes, 'b', 0, ["CreateModel"]) self.assertMigrationDependencies(changes, 'b', 0, [('__setting__', 'AUTH_USER_MODEL')])
before = self.make_project_state([]) after = self.make_project_state([address, tenant]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes()
self.assertNumberMigrations(changes, 'a', 2) self.assertOperationTypes(changes, 'a', 0, ["CreateModel"]) self.assertOperationTypes(changes, 'a', 1, ["AddField"]) self.assertMigrationDependencies(changes, 'a', 0, []) self.assertMigrationDependencies(changes, 'a', 1, [('__setting__', 'AUTH_USER_MODEL'), ('a', 'auto_1')]) self.assertNumberMigrations(changes, 'b', 1) self.assertOperationTypes(changes, 'b', 0, ["CreateModel"]) self.assertMigrationDependencies(changes, 'b', 0, [('a', 'auto_1')])
before = self.make_project_state([]) after = self.make_project_state([person]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes()
self.assertNumberMigrations(changes, 'a', 1) self.assertOperationTypes(changes, 'a', 0, ["CreateModel"]) self.assertMigrationDependencies(changes, 'a', 0, [])
self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["AddField", "AddField"]) self.assertOperationAttributes(changes, 'testapp', 0, 0)
self.assertNumberMigrations(changes, 'testapp', 1) self.assertOperationTypes(changes, 'testapp', 0, ["AddField", "AddField"]) self.assertOperationAttributes(changes, 'testapp', 0, 0)
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
table_names = [ '_pony_stables', '_pony_vans', '_pony', '_stable', '_van', ] tables = [(app_label + table_name) for table_name in table_names] with connection.cursor() as cursor: table_names = connection.introspection.table_names(cursor) connection.disable_constraint_checking() sql_delete_table = connection.schema_editor().sql_delete_table with transaction.atomic(): for table in tables: if table in table_names: cursor.execute(sql_delete_table % { "table": connection.ops.quote_name(table), }) connection.enable_constraint_checking()
model_options = { "swappable": "TEST_SWAP_MODEL", "index_together": [["weight", "pink"]] if index_together else [], "unique_together": [["pink", "weight"]] if unique_together else [], } if options: model_options["permissions"] = [("can_groom", "Can groom")] if db_table: model_options["db_table"] = db_table operations = [migrations.CreateModel( "Pony", [ ("id", models.AutoField(primary_key=True)), ("pink", models.IntegerField(default=3)), ("weight", models.FloatField()), ], options=model_options, )] if second_model: operations.append(migrations.CreateModel( "Stable", [ ("id", models.AutoField(primary_key=True)), ] )) if third_model: operations.append(migrations.CreateModel( "Van", [ ("id", models.AutoField(primary_key=True)), ] )) if related_model: operations.append(migrations.CreateModel( "Rider", [ ("id", models.AutoField(primary_key=True)), ("pony", models.ForeignKey("Pony", models.CASCADE)), ("friend", models.ForeignKey("self", models.CASCADE)) ], )) if mti_model: operations.append(migrations.CreateModel( "ShetlandPony", fields=[ ('pony_ptr', models.OneToOneField( 'Pony', models.CASCADE, auto_created=True, parent_link=True, primary_key=True, to_field='id', serialize=False, )), ("cuteness", models.IntegerField(default=1)), ], bases=['%s.Pony' % app_label], )) if proxy_model: operations.append(migrations.CreateModel( "ProxyPony", fields=[], options={"proxy": True}, bases=['%s.Pony' % app_label], )) if manager_model: operations.append(migrations.CreateModel( "Food", fields=[ ("id", models.AutoField(primary_key=True)), ], managers=[ ("food_qs", FoodQuerySet.as_manager()), ("food_mgr", FoodManager("a", "b")), ("food_mgr_kwargs", FoodManager("x", "y", 3, 4)), ] ))
project_state = ProjectState() new_state = project_state.clone() operation.state_forwards("test_crmo", new_state) self.assertEqual(new_state.models["test_crmo", "pony"].name, "Pony") self.assertEqual(len(new_state.models["test_crmo", "pony"].fields), 2) self.assertTableNotExists("test_crmo_pony") with connection.schema_editor() as editor: operation.database_forwards("test_crmo", editor, project_state, new_state) self.assertTableExists("test_crmo_pony") with connection.schema_editor() as editor: operation.database_backwards("test_crmo", editor, new_state, project_state) self.assertTableNotExists("test_crmo_pony") definition = operation.deconstruct() self.assertEqual(definition[0], "CreateModel") self.assertEqual(definition[1], []) self.assertEqual(sorted(definition[2].keys()), ["fields", "name"]) operation = migrations.CreateModel("Foo", fields=[], managers=[("objects", models.Manager())]) definition = operation.deconstruct() self.assertNotIn('managers', definition[2])
project_state = ProjectState() self.assertTableNotExists("test_crmoua_pony") self.assertTableNotExists("test_crmoua_rider") with connection.schema_editor() as editor: new_state = project_state.clone() operation1.state_forwards("test_crmoua", new_state) operation1.database_forwards("test_crmoua", editor, project_state, new_state) project_state, new_state = new_state, new_state.clone() operation2.state_forwards("test_crmoua", new_state) operation2.database_forwards("test_crmoua", editor, project_state, new_state) project_state, new_state = new_state, new_state.clone() operation3.state_forwards("test_crmoua", new_state) operation3.database_forwards("test_crmoua", editor, project_state, new_state) self.assertTableExists("test_crmoua_pony") self.assertTableExists("test_crmoua_rider")
new_state = project_state.clone() operation.state_forwards("test_crmomm", new_state) self.assertTableNotExists("test_crmomm_stable_ponies") with connection.schema_editor() as editor: operation.database_forwards("test_crmomm", editor, project_state, new_state) self.assertTableExists("test_crmomm_stable") self.assertTableExists("test_crmomm_stable_ponies") self.assertColumnNotExists("test_crmomm_stable", "ponies") with atomic(): Pony = new_state.apps.get_model("test_crmomm", "Pony") Stable = new_state.apps.get_model("test_crmomm", "Stable") stable = Stable.objects.create() p1 = Pony.objects.create(pink=False, weight=4.55) p2 = Pony.objects.create(pink=True, weight=5.43) stable.ponies.add(p1, p2) self.assertEqual(stable.ponies.count(), 2) stable.ponies.all().delete() with connection.schema_editor() as editor: operation.database_backwards("test_crmomm", editor, new_state, project_state) self.assertTableNotExists("test_crmomm_stable") self.assertTableNotExists("test_crmomm_stable_ponies")
operation = migrations.CreateModel( "ShetlandPony", [ ('pony_ptr', models.OneToOneField( 'test_crmoih.Pony', models.CASCADE, auto_created=True, primary_key=True, to_field='id', serialize=False, )), ("cuteness", models.IntegerField(default=1)), ], ) new_state = project_state.clone() operation.state_forwards("test_crmoih", new_state) self.assertIn(("test_crmoih", "shetlandpony"), new_state.models) self.assertTableNotExists("test_crmoih_shetlandpony") with connection.schema_editor() as editor: operation.database_forwards("test_crmoih", editor, project_state, new_state) self.assertTableExists("test_crmoih_shetlandpony") with connection.schema_editor() as editor: operation.database_backwards("test_crmoih", editor, new_state, project_state) self.assertTableNotExists("test_crmoih_shetlandpony")
operation = migrations.CreateModel( "ProxyPony", [], options={"proxy": True}, bases=("test_crprmo.Pony", ), ) self.assertEqual(operation.describe(), "Create proxy model ProxyPony") new_state = project_state.clone() operation.state_forwards("test_crprmo", new_state) self.assertIn(("test_crprmo", "proxypony"), new_state.models) self.assertTableNotExists("test_crprmo_proxypony") self.assertTableExists("test_crprmo_pony") with connection.schema_editor() as editor: operation.database_forwards("test_crprmo", editor, project_state, new_state) self.assertTableNotExists("test_crprmo_proxypony") self.assertTableExists("test_crprmo_pony") with connection.schema_editor() as editor: operation.database_backwards("test_crprmo", editor, new_state, project_state) self.assertTableNotExists("test_crprmo_proxypony") self.assertTableExists("test_crprmo_pony") definition = operation.deconstruct() self.assertEqual(definition[0], "CreateModel") self.assertEqual(definition[1], []) self.assertEqual(sorted(definition[2].keys()), ["bases", "fields", "name", "options"])
operation = migrations.CreateModel( "UnmanagedPony", [], options={"proxy": True}, bases=("test_crummo.Pony", ), ) self.assertEqual(operation.describe(), "Create proxy model UnmanagedPony") new_state = project_state.clone() operation.state_forwards("test_crummo", new_state) self.assertIn(("test_crummo", "unmanagedpony"), new_state.models) self.assertTableNotExists("test_crummo_unmanagedpony") self.assertTableExists("test_crummo_pony") with connection.schema_editor() as editor: operation.database_forwards("test_crummo", editor, project_state, new_state) self.assertTableNotExists("test_crummo_unmanagedpony") self.assertTableExists("test_crummo_pony") with connection.schema_editor() as editor: operation.database_backwards("test_crummo", editor, new_state, project_state) self.assertTableNotExists("test_crummo_unmanagedpony") self.assertTableExists("test_crummo_pony")
operation = migrations.CreateModel( "Food", fields=[ ("id", models.AutoField(primary_key=True)), ], managers=[ ("food_qs", FoodQuerySet.as_manager()), ("food_mgr", FoodManager("a", "b")), ("food_mgr_kwargs", FoodManager("x", "y", 3, 4)), ] ) self.assertEqual(operation.describe(), "Create model Food") new_state = project_state.clone() operation.state_forwards("test_cmoma", new_state) self.assertIn(("test_cmoma", "food"), new_state.models) managers = new_state.models["test_cmoma", "food"].managers self.assertEqual(managers[0][0], "food_qs") self.assertIsInstance(managers[0][1], models.Manager) self.assertEqual(managers[1][0], "food_mgr") self.assertIsInstance(managers[1][1], FoodManager) self.assertEqual(managers[1][1].args, ("a", "b", 1, 2)) self.assertEqual(managers[2][0], "food_mgr_kwargs") self.assertIsInstance(managers[2][1], FoodManager) self.assertEqual(managers[2][1].args, ("x", "y", 3, 4))
operation = migrations.DeleteModel("Pony") self.assertEqual(operation.describe(), "Delete model Pony") new_state = project_state.clone() operation.state_forwards("test_dlmo", new_state) self.assertNotIn(("test_dlmo", "pony"), new_state.models) self.assertTableExists("test_dlmo_pony") with connection.schema_editor() as editor: operation.database_forwards("test_dlmo", editor, project_state, new_state) self.assertTableNotExists("test_dlmo_pony") with connection.schema_editor() as editor: operation.database_backwards("test_dlmo", editor, new_state, project_state) self.assertTableExists("test_dlmo_pony") definition = operation.deconstruct() self.assertEqual(definition[0], "DeleteModel") self.assertEqual(definition[1], []) self.assertEqual(list(definition[2]), ["name"])
operation = migrations.DeleteModel("ProxyPony") new_state = project_state.clone() operation.state_forwards("test_dlprmo", new_state) self.assertIn(("test_dlprmo", "proxypony"), project_state.models) self.assertNotIn(("test_dlprmo", "proxypony"), new_state.models) self.assertTableExists("test_dlprmo_pony") self.assertTableNotExists("test_dlprmo_proxypony") with connection.schema_editor() as editor: operation.database_forwards("test_dlprmo", editor, project_state, new_state) self.assertTableExists("test_dlprmo_pony") self.assertTableNotExists("test_dlprmo_proxypony") with connection.schema_editor() as editor: operation.database_backwards("test_dlprmo", editor, new_state, project_state) self.assertTableExists("test_dlprmo_pony") self.assertTableNotExists("test_dlprmo_proxypony")
operation = migrations.RenameModel("Pony", "Horse") self.assertEqual(operation.describe(), "Rename model Pony to Horse") self.assertIn(("test_rnmo", "pony"), project_state.models) self.assertNotIn(("test_rnmo", "horse"), project_state.models) self.assertTableExists("test_rnmo_pony") self.assertTableNotExists("test_rnmo_horse") if connection.features.supports_foreign_keys: self.assertFKExists("test_rnmo_rider", ["pony_id"], ("test_rnmo_pony", "id")) self.assertFKNotExists("test_rnmo_rider", ["pony_id"], ("test_rnmo_horse", "id")) new_state = project_state.clone() new_state = self.apply_operations("test_rnmo", new_state, [operation]) self.assertNotIn(("test_rnmo", "pony"), new_state.models) self.assertIn(("test_rnmo", "horse"), new_state.models) self.assertEqual("test_rnmo.Horse", new_state.models["test_rnmo", "rider"].fields[1][1].remote_field.model) self.assertTableNotExists("test_rnmo_pony") self.assertTableExists("test_rnmo_horse") if connection.features.supports_foreign_keys: self.assertFKNotExists("test_rnmo_rider", ["pony_id"], ("test_rnmo_pony", "id")) self.assertFKExists("test_rnmo_rider", ["pony_id"], ("test_rnmo_horse", "id")) original_state = self.unapply_operations("test_rnmo", project_state, [operation]) self.assertIn(("test_rnmo", "pony"), original_state.models) self.assertNotIn(("test_rnmo", "horse"), original_state.models) self.assertEqual("Pony", original_state.models["test_rnmo", "rider"].fields[1][1].remote_field.model) self.assertTableExists("test_rnmo_pony") self.assertTableNotExists("test_rnmo_horse") if connection.features.supports_foreign_keys: self.assertFKExists("test_rnmo_rider", ["pony_id"], ("test_rnmo_pony", "id")) self.assertFKNotExists("test_rnmo_rider", ["pony_id"], ("test_rnmo_horse", "id")) definition = operation.deconstruct() self.assertEqual(definition[0], "RenameModel") self.assertEqual(definition[1], []) self.assertEqual(definition[2], {'old_name': "Pony", 'new_name': "Horse"})
operation = migrations.RenameModel("Rider", "HorseRider") self.assertEqual(operation.describe(), "Rename model Rider to HorseRider") new_state = project_state.clone() operation.state_forwards("test_rmwsrf", new_state) self.assertNotIn(("test_rmwsrf", "rider"), new_state.models) self.assertIn(("test_rmwsrf", "horserider"), new_state.models) self.assertEqual( "test_rmwsrf.HorseRider", new_state.models["test_rmwsrf", "horserider"].fields[2][1].remote_field.model ) self.assertTableExists("test_rmwsrf_rider") self.assertTableNotExists("test_rmwsrf_horserider") if connection.features.supports_foreign_keys: self.assertFKExists("test_rmwsrf_rider", ["friend_id"], ("test_rmwsrf_rider", "id")) self.assertFKNotExists("test_rmwsrf_rider", ["friend_id"], ("test_rmwsrf_horserider", "id")) with connection.schema_editor() as editor: operation.database_forwards("test_rmwsrf", editor, project_state, new_state) self.assertTableNotExists("test_rmwsrf_rider") self.assertTableExists("test_rmwsrf_horserider") if connection.features.supports_foreign_keys: self.assertFKNotExists("test_rmwsrf_horserider", ["friend_id"], ("test_rmwsrf_rider", "id")) self.assertFKExists("test_rmwsrf_horserider", ["friend_id"], ("test_rmwsrf_horserider", "id")) with connection.schema_editor() as editor: operation.database_backwards("test_rmwsrf", editor, new_state, project_state) self.assertTableExists("test_rmwsrf_rider") self.assertTableNotExists("test_rmwsrf_horserider") if connection.features.supports_foreign_keys: self.assertFKExists("test_rmwsrf_rider", ["friend_id"], ("test_rmwsrf_rider", "id")) self.assertFKNotExists("test_rmwsrf_rider", ["friend_id"], ("test_rmwsrf_horserider", "id"))
operation = migrations.RenameModel("ShetlandPony", "LittleHorse") self.assertEqual(operation.describe(), "Rename model ShetlandPony to LittleHorse") new_state = project_state.clone() operation.state_forwards("test_rmwsc", new_state) self.assertNotIn(("test_rmwsc", "shetlandpony"), new_state.models) self.assertIn(("test_rmwsc", "littlehorse"), new_state.models) self.assertEqual( project_state.models["test_rmwsc", "rider"].fields[1][1].remote_field.model, new_state.models["test_rmwsc", "rider"].fields[1][1].remote_field.model ) self.assertTableExists("test_rmwsc_shetlandpony") self.assertTableNotExists("test_rmwsc_littlehorse") if connection.features.supports_foreign_keys: self.assertFKExists("test_rmwsc_rider", ["pony_id"], ("test_rmwsc_pony", "id")) self.assertFKNotExists("test_rmwsc_rider", ["pony_id"], ("test_rmwsc_shetlandpony", "id")) with connection.schema_editor() as editor: operation.database_forwards("test_rmwsc", editor, project_state, new_state) self.assertTableNotExists("test_rmwsc_shetlandpony") self.assertTableExists("test_rmwsc_littlehorse") if connection.features.supports_foreign_keys: self.assertFKExists("test_rmwsc_rider", ["pony_id"], ("test_rmwsc_pony", "id")) self.assertFKNotExists("test_rmwsc_rider", ["pony_id"], ("test_rmwsc_littlehorse", "id"))
operation = migrations.AddField( "Pony", "height", models.FloatField(null=True, default=5), ) self.assertEqual(operation.describe(), "Add field height to Pony") project_state, new_state = self.make_test_state("test_adfl", operation) self.assertEqual(len(new_state.models["test_adfl", "pony"].fields), 4) field = [ f for n, f in new_state.models["test_adfl", "pony"].fields if n == "height" ][0] self.assertEqual(field.default, 5) self.assertColumnNotExists("test_adfl_pony", "height") with connection.schema_editor() as editor: operation.database_forwards("test_adfl", editor, project_state, new_state) self.assertColumnExists("test_adfl_pony", "height") with connection.schema_editor() as editor: operation.database_backwards("test_adfl", editor, new_state, project_state) self.assertColumnNotExists("test_adfl_pony", "height") definition = operation.deconstruct() self.assertEqual(definition[0], "AddField") self.assertEqual(definition[1], []) self.assertEqual(sorted(definition[2]), ["field", "model_name", "name"])
migrations.AddField( "Pony", "digits", models.CharField(max_length=10, default="42"), ), migrations.AddField( "Pony", "quotes", models.CharField(max_length=10, default='"\'"'), ),
migrations.AddField( "Pony", "digits", models.TextField(default="42"), ), migrations.AddField( "Pony", "quotes", models.TextField(default='"\'"'), ),
migrations.AddField( "Pony", "digits", models.BinaryField(default=b"42"), ), migrations.AddField( "Pony", "quotes", models.BinaryField(default=b'"\'"'), ),
self.assertEqual(bytes(pony.blob), b"some text") self.assertEqual(bytes(pony.empty), b"") self.assertEqual(bytes(pony.digits), b"42") self.assertEqual(bytes(pony.quotes), b'"\'"')
operation = migrations.AddField( "Pony", "height", models.FloatField(null=True, default=4), preserve_default=False, ) new_state = project_state.clone() operation.state_forwards("test_adflpd", new_state) self.assertEqual(len(new_state.models["test_adflpd", "pony"].fields), 4) field = [ f for n, f in new_state.models["test_adflpd", "pony"].fields if n == "height" ][0] self.assertEqual(field.default, NOT_PROVIDED) project_state.apps.get_model("test_adflpd", "pony").objects.create( weight=4, ) self.assertColumnNotExists("test_adflpd_pony", "height") with connection.schema_editor() as editor: operation.database_forwards("test_adflpd", editor, project_state, new_state) self.assertColumnExists("test_adflpd_pony", "height") definition = operation.deconstruct() self.assertEqual(definition[0], "AddField") self.assertEqual(definition[1], []) self.assertEqual(sorted(definition[2]), ["field", "model_name", "name", "preserve_default"])
operation = migrations.AddField("Pony", "stables", models.ManyToManyField("Stable", related_name="ponies")) new_state = project_state.clone() operation.state_forwards("test_adflmm", new_state) self.assertEqual(len(new_state.models["test_adflmm", "pony"].fields), 4) self.assertTableNotExists("test_adflmm_pony_stables") with connection.schema_editor() as editor: operation.database_forwards("test_adflmm", editor, project_state, new_state) self.assertTableExists("test_adflmm_pony_stables") self.assertColumnNotExists("test_adflmm_pony", "stables") with atomic(): Pony = new_state.apps.get_model("test_adflmm", "Pony") p = Pony.objects.create(pink=False, weight=4.55) p.stables.create() self.assertEqual(p.stables.count(), 1) p.stables.all().delete() with connection.schema_editor() as editor: operation.database_backwards("test_adflmm", editor, new_state, project_state) self.assertTableNotExists("test_adflmm_pony_stables")
Pony = project_state.apps.get_model("test_alflmm", "Pony") p = Pony.objects.create(pink=False, weight=4.55) p.places.create() self.assertEqual(p.places.count(), 1) p.places.all().delete()
self.unapply_operations("test_rmflmm", with_field_state, operations=operations) self.assertTableExists("test_rmflmm_pony_stables")
operation = migrations.RemoveField("Pony", "pink") self.assertEqual(operation.describe(), "Remove field pink from Pony") new_state = project_state.clone() operation.state_forwards("test_rmfl", new_state) self.assertEqual(len(new_state.models["test_rmfl", "pony"].fields), 2) self.assertColumnExists("test_rmfl_pony", "pink") with connection.schema_editor() as editor: operation.database_forwards("test_rmfl", editor, project_state, new_state) self.assertColumnNotExists("test_rmfl_pony", "pink") with connection.schema_editor() as editor: operation.database_backwards("test_rmfl", editor, new_state, project_state) self.assertColumnExists("test_rmfl_pony", "pink") definition = operation.deconstruct() self.assertEqual(definition[0], "RemoveField") self.assertEqual(definition[1], []) self.assertEqual(definition[2], {'model_name': "Pony", 'name': 'pink'})
operation = migrations.AlterModelTable("Pony", "test_almota_pony_2") self.assertEqual(operation.describe(), "Rename table for Pony to test_almota_pony_2") new_state = project_state.clone() operation.state_forwards("test_almota", new_state) self.assertEqual(new_state.models["test_almota", "pony"].options["db_table"], "test_almota_pony_2") self.assertTableExists("test_almota_pony") self.assertTableNotExists("test_almota_pony_2") with connection.schema_editor() as editor: operation.database_forwards("test_almota", editor, project_state, new_state) self.assertTableNotExists("test_almota_pony") self.assertTableExists("test_almota_pony_2") with connection.schema_editor() as editor: operation.database_backwards("test_almota", editor, new_state, project_state) self.assertTableExists("test_almota_pony") self.assertTableNotExists("test_almota_pony_2") definition = operation.deconstruct() self.assertEqual(definition[0], "AlterModelTable") self.assertEqual(definition[1], []) self.assertEqual(definition[2], {'name': "Pony", 'table': "test_almota_pony_2"})
operation = migrations.AlterModelTable("Pony", "test_almota_pony") new_state = project_state.clone() operation.state_forwards("test_almota", new_state) self.assertEqual(new_state.models["test_almota", "pony"].options["db_table"], "test_almota_pony") self.assertTableExists("test_almota_pony") with connection.schema_editor() as editor: operation.database_forwards("test_almota", editor, project_state, new_state) self.assertTableExists("test_almota_pony") with connection.schema_editor() as editor: operation.database_backwards("test_almota", editor, new_state, project_state) self.assertTableExists("test_almota_pony")
first_state = project_state.clone() operation = migrations.AddField("Pony", "stables", models.ManyToManyField("Stable")) operation.state_forwards(app_label, first_state) with connection.schema_editor() as editor: operation.database_forwards(app_label, editor, project_state, first_state) original_m2m_table = "%s_%s" % (pony_db_table, "stables") new_m2m_table = "%s_%s" % (app_label, "pony_stables") self.assertTableExists(original_m2m_table) self.assertTableNotExists(new_m2m_table) second_state = first_state.clone() operation = migrations.AlterModelTable(name='pony', table=None) operation.state_forwards(app_label, second_state) with connection.schema_editor() as editor: operation.database_forwards(app_label, editor, first_state, second_state) self.assertTableExists(new_m2m_table) self.assertTableNotExists(original_m2m_table) with connection.schema_editor() as editor: operation.database_backwards(app_label, editor, second_state, first_state) self.assertTableExists(original_m2m_table) self.assertTableNotExists(new_m2m_table)
operation = migrations.AlterField("Pony", "pink", models.IntegerField(null=True)) self.assertEqual(operation.describe(), "Alter field pink on Pony") new_state = project_state.clone() operation.state_forwards("test_alfl", new_state) self.assertEqual(project_state.models["test_alfl", "pony"].get_field_by_name("pink").null, False) self.assertEqual(new_state.models["test_alfl", "pony"].get_field_by_name("pink").null, True) self.assertColumnNotNull("test_alfl_pony", "pink") with connection.schema_editor() as editor: operation.database_forwards("test_alfl", editor, project_state, new_state) self.assertColumnNull("test_alfl_pony", "pink") with connection.schema_editor() as editor: operation.database_backwards("test_alfl", editor, new_state, project_state) self.assertColumnNotNull("test_alfl_pony", "pink") definition = operation.deconstruct() self.assertEqual(definition[0], "AlterField") self.assertEqual(definition[1], []) self.assertEqual(sorted(definition[2]), ["field", "model_name", "name"])
operation = migrations.AlterField("Pony", "id", models.IntegerField(primary_key=True)) new_state = project_state.clone() operation.state_forwards("test_alflpk", new_state) self.assertIsInstance(project_state.models["test_alflpk", "pony"].get_field_by_name("id"), models.AutoField) self.assertIsInstance(new_state.models["test_alflpk", "pony"].get_field_by_name("id"), models.IntegerField) with connection.schema_editor() as editor: operation.database_forwards("test_alflpk", editor, project_state, new_state) with connection.schema_editor() as editor: operation.database_backwards("test_alflpk", editor, new_state, project_state)
operation = migrations.AlterField("Pony", "id", models.FloatField(primary_key=True)) new_state = project_state.clone() operation.state_forwards("test_alflpkfk", new_state) self.assertIsInstance(project_state.models["test_alflpkfk", "pony"].get_field_by_name("id"), models.AutoField) self.assertIsInstance(new_state.models["test_alflpkfk", "pony"].get_field_by_name("id"), models.FloatField)
with connection.schema_editor() as editor: operation.database_forwards("test_alflpkfk", editor, project_state, new_state) assertIdTypeEqualsFkType() with connection.schema_editor() as editor: operation.database_backwards("test_alflpkfk", editor, new_state, project_state) assertIdTypeEqualsFkType()
operation = migrations.RenameField("Pony", "pink", "blue") self.assertEqual(operation.describe(), "Rename field pink on Pony to blue") new_state = project_state.clone() operation.state_forwards("test_rnfl", new_state) self.assertIn("blue", [n for n, f in new_state.models["test_rnfl", "pony"].fields]) self.assertNotIn("pink", [n for n, f in new_state.models["test_rnfl", "pony"].fields]) self.assertIn("blue", new_state.models["test_rnfl", "pony"].options['unique_together'][0]) self.assertNotIn("pink", new_state.models["test_rnfl", "pony"].options['unique_together'][0]) self.assertIn("blue", new_state.models["test_rnfl", "pony"].options['index_together'][0]) self.assertNotIn("pink", new_state.models["test_rnfl", "pony"].options['index_together'][0]) self.assertColumnExists("test_rnfl_pony", "pink") self.assertColumnNotExists("test_rnfl_pony", "blue") with connection.schema_editor() as editor: operation.database_forwards("test_rnfl", editor, project_state, new_state) self.assertColumnExists("test_rnfl_pony", "blue") self.assertColumnNotExists("test_rnfl_pony", "pink") with connection.cursor() as cursor: cursor.execute("INSERT INTO test_rnfl_pony (blue, weight) VALUES (1, 1)") with self.assertRaises(IntegrityError): with atomic(): cursor.execute("INSERT INTO test_rnfl_pony (blue, weight) VALUES (1, 1)") cursor.execute("DELETE FROM test_rnfl_pony") self.assertIndexExists("test_rnfl_pony", ["weight", "blue"]) with connection.schema_editor() as editor: operation.database_backwards("test_rnfl", editor, new_state, project_state) self.assertColumnExists("test_rnfl_pony", "pink") self.assertColumnNotExists("test_rnfl_pony", "blue") self.assertIndexExists("test_rnfl_pony", ["weight", "pink"]) definition = operation.deconstruct() self.assertEqual(definition[0], "RenameField") self.assertEqual(definition[1], []) self.assertEqual(definition[2], {'model_name': "Pony", 'old_name': "pink", 'new_name': "blue"})
operation = migrations.AlterUniqueTogether("Pony", [("pink", "weight")]) self.assertEqual(operation.describe(), "Alter unique_together for Pony (1 constraint(s))") new_state = project_state.clone() operation.state_forwards("test_alunto", new_state) self.assertEqual(len(project_state.models["test_alunto", "pony"].options.get("unique_together", set())), 0) self.assertEqual(len(new_state.models["test_alunto", "pony"].options.get("unique_together", set())), 1) with connection.cursor() as cursor: cursor.execute("INSERT INTO test_alunto_pony (pink, weight) VALUES (1, 1)") cursor.execute("INSERT INTO test_alunto_pony (pink, weight) VALUES (1, 1)") cursor.execute("DELETE FROM test_alunto_pony") with connection.schema_editor() as editor: operation.database_forwards("test_alunto", editor, project_state, new_state) cursor.execute("INSERT INTO test_alunto_pony (pink, weight) VALUES (1, 1)") with self.assertRaises(IntegrityError): with atomic(): cursor.execute("INSERT INTO test_alunto_pony (pink, weight) VALUES (1, 1)") cursor.execute("DELETE FROM test_alunto_pony") with connection.schema_editor() as editor: operation.database_backwards("test_alunto", editor, new_state, project_state) cursor.execute("INSERT INTO test_alunto_pony (pink, weight) VALUES (1, 1)") cursor.execute("INSERT INTO test_alunto_pony (pink, weight) VALUES (1, 1)") cursor.execute("DELETE FROM test_alunto_pony") operation = migrations.AlterUniqueTogether("Pony", ("pink", "weight")) operation.state_forwards("test_alunto", new_state) self.assertEqual(len(new_state.models["test_alunto", "pony"].options.get("unique_together", set())), 1) definition = operation.deconstruct() self.assertEqual(definition[0], "AlterUniqueTogether") self.assertEqual(definition[1], []) self.assertEqual(definition[2], {'name': "Pony", 'unique_together': {("pink", "weight")}})
operation = migrations.AlterIndexTogether("Pony", [("pink", "weight")]) self.assertEqual(operation.describe(), "Alter index_together for Pony (1 constraint(s))") new_state = project_state.clone() operation.state_forwards("test_alinto", new_state) self.assertEqual(len(project_state.models["test_alinto", "pony"].options.get("index_together", set())), 0) self.assertEqual(len(new_state.models["test_alinto", "pony"].options.get("index_together", set())), 1) self.assertIndexNotExists("test_alinto_pony", ["pink", "weight"]) with connection.schema_editor() as editor: operation.database_forwards("test_alinto", editor, project_state, new_state) self.assertIndexExists("test_alinto_pony", ["pink", "weight"]) with connection.schema_editor() as editor: operation.database_backwards("test_alinto", editor, new_state, project_state) self.assertIndexNotExists("test_alinto_pony", ["pink", "weight"]) definition = operation.deconstruct() self.assertEqual(definition[0], "AlterIndexTogether") self.assertEqual(definition[1], []) self.assertEqual(definition[2], {'name': "Pony", 'index_together': {("pink", "weight")}})
operation = migrations.AlterModelOptions("Pony", {"permissions": [("can_groom", "Can groom")]}) self.assertEqual(operation.describe(), "Change Meta options on Pony") new_state = project_state.clone() operation.state_forwards("test_almoop", new_state) self.assertEqual(len(project_state.models["test_almoop", "pony"].options.get("permissions", [])), 0) self.assertEqual(len(new_state.models["test_almoop", "pony"].options.get("permissions", [])), 1) self.assertEqual(new_state.models["test_almoop", "pony"].options["permissions"][0][0], "can_groom") definition = operation.deconstruct() self.assertEqual(definition[0], "AlterModelOptions") self.assertEqual(definition[1], []) self.assertEqual(definition[2], {'name': "Pony", 'options': {"permissions": [("can_groom", "Can groom")]}})
operation = migrations.AlterModelOptions("Pony", {}) self.assertEqual(operation.describe(), "Change Meta options on Pony") new_state = project_state.clone() operation.state_forwards("test_almoop", new_state) self.assertEqual(len(project_state.models["test_almoop", "pony"].options.get("permissions", [])), 1) self.assertEqual(len(new_state.models["test_almoop", "pony"].options.get("permissions", [])), 0) definition = operation.deconstruct() self.assertEqual(definition[0], "AlterModelOptions") self.assertEqual(definition[1], []) self.assertEqual(definition[2], {'name': "Pony", 'options': {}})
operation = migrations.AlterOrderWithRespectTo("Rider", "pony") self.assertEqual(operation.describe(), "Set order_with_respect_to on Rider to pony") new_state = project_state.clone() operation.state_forwards("test_alorwrtto", new_state) self.assertIsNone( project_state.models["test_alorwrtto", "rider"].options.get("order_with_respect_to", None) ) self.assertEqual( new_state.models["test_alorwrtto", "rider"].options.get("order_with_respect_to", None), "pony" ) self.assertColumnNotExists("test_alorwrtto_rider", "_order") rendered_state = project_state.apps pony = rendered_state.get_model("test_alorwrtto", "Pony").objects.create(weight=50) rendered_state.get_model("test_alorwrtto", "Rider").objects.create(pony=pony, friend_id=1) rendered_state.get_model("test_alorwrtto", "Rider").objects.create(pony=pony, friend_id=2) with connection.schema_editor() as editor: operation.database_forwards("test_alorwrtto", editor, project_state, new_state) self.assertColumnExists("test_alorwrtto_rider", "_order") updated_riders = new_state.apps.get_model("test_alorwrtto", "Rider").objects.all() self.assertEqual(updated_riders[0]._order, 0) self.assertEqual(updated_riders[1]._order, 0) with connection.schema_editor() as editor: operation.database_backwards("test_alorwrtto", editor, new_state, project_state) self.assertColumnNotExists("test_alorwrtto_rider", "_order") definition = operation.deconstruct() self.assertEqual(definition[0], "AlterOrderWithRespectTo") self.assertEqual(definition[1], []) self.assertEqual(definition[2], {'name': "Rider", 'order_with_respect_to': "pony"})
operation = migrations.AlterModelManagers( "Pony", managers=[ ("food_qs", FoodQuerySet.as_manager()), ("food_mgr", FoodManager("a", "b")), ("food_mgr_kwargs", FoodManager("x", "y", 3, 4)), ] ) self.assertEqual(operation.describe(), "Change managers on Pony") managers = project_state.models["test_almoma", "pony"].managers self.assertEqual(managers, [])
operation = migrations.AlterModelManagers("Food", managers=[]) self.assertEqual(operation.describe(), "Change managers on Food") self.assertIn(("test_almomae", "food"), project_state.models) managers = project_state.models["test_almomae", "food"].managers self.assertEqual(managers[0][0], "food_qs") self.assertIsInstance(managers[0][1], models.Manager) self.assertEqual(managers[1][0], "food_mgr") self.assertIsInstance(managers[1][1], FoodManager) self.assertEqual(managers[1][1].args, ("a", "b", 1, 2)) self.assertEqual(managers[2][0], "food_mgr_kwargs") self.assertIsInstance(managers[2][1], FoodManager) self.assertEqual(managers[2][1].args, ("x", "y", 3, 4))
create_operation = migrations.CreateModel( name="Rider", fields=[ ("id", models.AutoField(primary_key=True)), ("pony", models.ForeignKey("Pony", models.CASCADE)), ], ) create_state = project_state.clone() create_operation.state_forwards("test_alfk", create_state) alter_operation = migrations.AlterField( model_name='Rider', name='pony', field=models.ForeignKey("Pony", models.CASCADE, editable=False), ) alter_state = create_state.clone() alter_operation.state_forwards("test_alfk", alter_state) with connection.schema_editor() as editor: create_operation.database_forwards("test_alfk", editor, project_state, create_state) alter_operation.database_forwards("test_alfk", editor, create_state, alter_state)
operation = migrations.AlterField( model_name="Rider", name="pony", field=models.FloatField(), ) project_state, new_state = self.make_test_state("test_afknfk", operation, related_model=True) self.assertColumnExists("test_afknfk_rider", "pony_id") self.assertColumnNotExists("test_afknfk_rider", "pony") with connection.schema_editor() as editor: operation.database_forwards("test_afknfk", editor, project_state, new_state) self.assertColumnExists("test_afknfk_rider", "pony") self.assertColumnNotExists("test_afknfk_rider", "pony_id") with connection.schema_editor() as editor: operation.database_backwards("test_afknfk", editor, new_state, project_state) self.assertColumnExists("test_afknfk_rider", "pony_id") self.assertColumnNotExists("test_afknfk_rider", "pony")
operation = migrations.RunSQL( "CREATE TABLE i_love_ponies (id int, special_thing varchar(15));\n" "INSERT INTO i_love_ponies (id, special_thing) VALUES (1, 'i love ponies'); -- this is magic!\n" "INSERT INTO i_love_ponies (id, special_thing) VALUES (2, 'i love django');\n" "UPDATE i_love_ponies SET special_thing = 'Ponies' WHERE special_thing LIKE '%%ponies';" "UPDATE i_love_ponies SET special_thing = 'Django' WHERE special_thing LIKE '%django';",
"DELETE FROM i_love_ponies WHERE special_thing LIKE '%Django%';" "DELETE FROM i_love_ponies WHERE special_thing LIKE '%%Ponies%%';" "DROP TABLE i_love_ponies",
new_state = project_state.clone() operation.state_forwards("test_runsql", new_state) self.assertEqual(len(new_state.models["test_runsql", "somethingelse"].fields), 1) self.assertTableNotExists("i_love_ponies") with connection.schema_editor(collect_sql=True) as editor: operation.database_forwards("test_runsql", editor, project_state, new_state) self.assertIn("LIKE '%%ponies';", "\n".join(editor.collected_sql)) operation.database_backwards("test_runsql", editor, project_state, new_state) self.assertIn("LIKE '%%Ponies%%';", "\n".join(editor.collected_sql)) with connection.schema_editor() as editor: operation.database_forwards("test_runsql", editor, project_state, new_state) self.assertTableExists("i_love_ponies") with connection.cursor() as cursor: cursor.execute("SELECT COUNT(*) FROM i_love_ponies") self.assertEqual(cursor.fetchall()[0][0], 2) cursor.execute("SELECT COUNT(*) FROM i_love_ponies WHERE special_thing = 'Django'") self.assertEqual(cursor.fetchall()[0][0], 1) cursor.execute("SELECT COUNT(*) FROM i_love_ponies WHERE special_thing = 'Ponies'") self.assertEqual(cursor.fetchall()[0][0], 1) self.assertTrue(operation.reversible) with connection.schema_editor() as editor: operation.database_backwards("test_runsql", editor, new_state, project_state) self.assertTableNotExists("i_love_ponies") definition = operation.deconstruct() self.assertEqual(definition[0], "RunSQL") self.assertEqual(definition[1], []) self.assertEqual(sorted(definition[2]), ["reverse_sql", "sql", "state_operations"]) self.assertIs(False, operation.reduce(operation, [])) elidable_operation = migrations.RunSQL('SELECT 1 FROM void;', elidable=True) self.assertEqual(elidable_operation.reduce(operation, []), [operation])
operation = migrations.RunSQL( ["CREATE TABLE i_love_ponies (id int, special_thing varchar(15));"], ["DROP TABLE i_love_ponies"], ) param_operation = migrations.RunSQL( ( "INSERT INTO i_love_ponies (id, special_thing) VALUES (1, 'Django');", ["INSERT INTO i_love_ponies (id, special_thing) VALUES (2, %s);", ['Ponies']], ("INSERT INTO i_love_ponies (id, special_thing) VALUES (%s, %s);", (3, 'Python',)), ), [ "DELETE FROM i_love_ponies WHERE special_thing = 'Django';", ["DELETE FROM i_love_ponies WHERE special_thing = 'Ponies';", None], ("DELETE FROM i_love_ponies WHERE id = %s OR special_thing = %s;", [3, 'Python']), ] )
self.assertTableNotExists("i_love_ponies") new_state = project_state.clone() with connection.schema_editor() as editor: operation.database_forwards("test_runsql", editor, project_state, new_state)
with connection.schema_editor() as editor: param_operation.database_forwards("test_runsql", editor, project_state, new_state) with connection.cursor() as cursor: cursor.execute("SELECT COUNT(*) FROM i_love_ponies") self.assertEqual(cursor.fetchall()[0][0], 3)
with connection.schema_editor() as editor: operation.database_backwards("test_runsql", editor, new_state, project_state) self.assertTableNotExists("i_love_ponies")
[ ["INSERT INTO foo (bar) VALUES ('buz');"] ], ( ("DELETE FROM foo WHERE bar = 'buz';", 'invalid', 'parameter count'), ),
def inner_method(models, schema_editor): Pony = models.get_model("test_runpython", "Pony") Pony.objects.create(pink=1, weight=3.55) Pony.objects.create(weight=5)
new_state = project_state.clone() operation.state_forwards("test_runpython", new_state) self.assertEqual(new_state, project_state) self.assertEqual(project_state.apps.get_model("test_runpython", "Pony").objects.count(), 0) with connection.schema_editor() as editor: operation.database_forwards("test_runpython", editor, project_state, new_state) self.assertEqual(project_state.apps.get_model("test_runpython", "Pony").objects.count(), 2) self.assertTrue(operation.reversible) with connection.schema_editor() as editor: operation.database_backwards("test_runpython", editor, project_state, new_state) self.assertEqual(project_state.apps.get_model("test_runpython", "Pony").objects.count(), 0) with self.assertRaises(ValueError): migrations.RunPython("print 'ahahaha'") definition = operation.deconstruct() self.assertEqual(definition[0], "RunPython") self.assertEqual(definition[1], []) self.assertEqual(sorted(definition[2]), ["code", "reverse_code"])
no_reverse_operation = migrations.RunPython(inner_method) self.assertFalse(no_reverse_operation.reversible) with connection.schema_editor() as editor: no_reverse_operation.database_forwards("test_runpython", editor, project_state, new_state) with self.assertRaises(NotImplementedError): no_reverse_operation.database_backwards("test_runpython", editor, new_state, project_state) self.assertEqual(project_state.apps.get_model("test_runpython", "Pony").objects.count(), 2)
definition = operation.deconstruct() self.assertEqual(definition[0], "RunPython") self.assertEqual(definition[1], []) self.assertEqual(sorted(definition[2]), ["code"])
self.assertIs(False, operation.reduce(operation, [])) elidable_operation = migrations.RunPython(inner_method, elidable=True) self.assertEqual(elidable_operation.reduce(operation, []), [operation])
if connection.features.can_rollback_ddl: self.assertEqual(project_state.apps.get_model("test_runpythonatomic", "Pony").objects.count(), 0) with self.assertRaises(ValueError): with connection.schema_editor() as editor: atomic_migration.apply(project_state, editor) self.assertEqual(project_state.apps.get_model("test_runpythonatomic", "Pony").objects.count(), 0) with self.assertRaises(ValueError): with connection.schema_editor() as editor: non_atomic_migration.apply(project_state, editor) self.assertEqual(project_state.apps.get_model("test_runpythonatomic", "Pony").objects.count(), 0) else: self.assertEqual(project_state.apps.get_model("test_runpythonatomic", "Pony").objects.count(), 0) with self.assertRaises(ValueError): with connection.schema_editor() as editor: atomic_migration.apply(project_state, editor) self.assertEqual(project_state.apps.get_model("test_runpythonatomic", "Pony").objects.count(), 0) with self.assertRaises(ValueError): with connection.schema_editor() as editor: non_atomic_migration.apply(project_state, editor) self.assertEqual(project_state.apps.get_model("test_runpythonatomic", "Pony").objects.count(), 1) definition = non_atomic_migration.operations[0].deconstruct() self.assertEqual(definition[0], "RunPython") self.assertEqual(definition[1], []) self.assertEqual(sorted(definition[2]), ["atomic", "code"])
database_operation = migrations.RunSQL( "CREATE TABLE i_love_ponies (id int, special_thing int);", "DROP TABLE i_love_ponies;" ) state_operation = migrations.CreateModel("SomethingElse", [("id", models.AutoField(primary_key=True))]) operation = migrations.SeparateDatabaseAndState( state_operations=[state_operation], database_operations=[database_operation] ) self.assertEqual(operation.describe(), "Custom state/database change combination") new_state = project_state.clone() operation.state_forwards("test_separatedatabaseandstate", new_state) self.assertEqual(len(new_state.models["test_separatedatabaseandstate", "somethingelse"].fields), 1) self.assertTableNotExists("i_love_ponies") with connection.schema_editor() as editor: operation.database_forwards("test_separatedatabaseandstate", editor, project_state, new_state) self.assertTableExists("i_love_ponies") self.assertTrue(operation.reversible) with connection.schema_editor() as editor: operation.database_backwards("test_separatedatabaseandstate", editor, new_state, project_state) self.assertTableNotExists("i_love_ponies") definition = operation.deconstruct() self.assertEqual(definition[0], "SeparateDatabaseAndState") self.assertEqual(definition[1], []) self.assertEqual(sorted(definition[2]), ["database_operations", "state_operations"])
database_operations = [ migrations.CreateModel( "ILovePonies", [("id", models.AutoField(primary_key=True))], options={"db_table": "iloveponies"}, ), migrations.CreateModel( "ILoveMorePonies", [("id", models.IntegerField(primary_key=True))], options={"db_table": "ilovemoreponies"}, ), migrations.DeleteModel("ILoveMorePonies"), migrations.CreateModel( "ILoveEvenMorePonies", [("id", models.AutoField(primary_key=True))], options={"db_table": "iloveevenmoreponies"}, ), ] state_operations = [ migrations.CreateModel( "SomethingElse", [("id", models.AutoField(primary_key=True))], options={"db_table": "somethingelse"}, ), migrations.DeleteModel("SomethingElse"), migrations.CreateModel( "SomethingCompletelyDifferent", [("id", models.AutoField(primary_key=True))], options={"db_table": "somethingcompletelydifferent"}, ), ] operation = migrations.SeparateDatabaseAndState( state_operations=state_operations, database_operations=database_operations, ) new_state = project_state.clone() operation.state_forwards(app_label, new_state)
self.assertNotIn((app_label, "somethingelse"), new_state.models) self.assertEqual(len(new_state.models[app_label, "somethingcompletelydifferent"].fields), 1) self.assertNotIn((app_label, "iloveponiesonies"), new_state.models) self.assertNotIn((app_label, "ilovemoreponies"), new_state.models) self.assertNotIn((app_label, "iloveevenmoreponies"), new_state.models) self.assertTableNotExists("somethingelse") self.assertTableNotExists("somethingcompletelydifferent") self.assertTableNotExists("ilovemoreponies") if after_db: self.assertTableExists("iloveponies") self.assertTableExists("iloveevenmoreponies") else: self.assertTableNotExists("iloveponies") self.assertTableNotExists("iloveevenmoreponies")
with connection.schema_editor() as editor: operation.database_forwards(app_label, editor, project_state, new_state) assertModelsAndTables(after_db=True) self.assertTrue(operation.reversible) with connection.schema_editor() as editor: operation.database_backwards(app_label, editor, new_state, project_state) assertModelsAndTables(after_db=False)
project_state = ProjectState() new_state = project_state.clone() operation.state_forwards("test_crigsw", new_state) self.assertEqual(new_state.models["test_crigsw", "pony"].name, "Pony") self.assertEqual(len(new_state.models["test_crigsw", "pony"].fields), 2) self.assertTableNotExists("test_crigsw_pony") with connection.schema_editor() as editor: operation.database_forwards("test_crigsw", editor, project_state, new_state) self.assertTableNotExists("test_crigsw_pony") with connection.schema_editor() as editor: operation.database_backwards("test_crigsw", editor, new_state, project_state) self.assertTableNotExists("test_crigsw_pony")
self.assertTableNotExists("test_dligsw_pony") with connection.schema_editor() as editor: operation.database_forwards("test_dligsw", editor, project_state, new_state) self.assertTableNotExists("test_dligsw_pony") with connection.schema_editor() as editor: operation.database_backwards("test_dligsw", editor, new_state, project_state) self.assertTableNotExists("test_dligsw_pony")
operation = migrations.AddField( "Pony", "height", models.FloatField(null=True, default=5), ) project_state, new_state = self.make_test_state("test_adfligsw", operation) self.assertTableNotExists("test_adfligsw_pony") with connection.schema_editor() as editor: operation.database_forwards("test_adfligsw", editor, project_state, new_state) self.assertTableNotExists("test_adfligsw_pony") with connection.schema_editor() as editor: operation.database_backwards("test_adfligsw", editor, new_state, project_state) self.assertTableNotExists("test_adfligsw_pony")
self.assertOptimizesTo( [ migrations.CreateModel("Foo", [("name", models.CharField(max_length=255))]), migrations.CreateModel("Bar", [("size", models.IntegerField())]), migrations.DeleteModel("Foo"), ], [ migrations.CreateModel("Bar", [("size", models.IntegerField())]), ], ) self.assertOptimizesTo( [ migrations.CreateModel("Foo", [("name", models.CharField(max_length=255))]), migrations.CreateModel("Bar", [("size", models.IntegerField())]), migrations.DeleteModel("Bar"), migrations.DeleteModel("Foo"), ], [], ) self.assertOptimizesTo( [ migrations.CreateModel("Foo", [("name", models.CharField(max_length=255))]), migrations.CreateModel("Bar", [("size", models.IntegerField())]), migrations.DeleteModel("Foo"), migrations.DeleteModel("Bar"), ], [], ) self.assertOptimizesTo( [ migrations.CreateModel("Foo", [("name", models.CharField(max_length=255))]), migrations.CreateModel("Bar", [("other", models.ForeignKey("testapp.Foo", models.CASCADE))]), migrations.DeleteModel("Foo"), ], [ migrations.CreateModel("Foo", [("name", models.CharField(max_length=255))]), migrations.CreateModel("Bar", [("other", models.ForeignKey("testapp.Foo", models.CASCADE))]), migrations.DeleteModel("Foo"), ], ) self.assertOptimizesTo( [ migrations.CreateModel("Foo", [("name", models.CharField(max_length=255))]), migrations.CreateModel("Bar", [("size", models.IntegerField())], bases=("testapp.Foo", )), migrations.DeleteModel("Foo"), ], [ migrations.CreateModel("Foo", [("name", models.CharField(max_length=255))]), migrations.CreateModel("Bar", [("size", models.IntegerField())], bases=("testapp.Foo", )), migrations.DeleteModel("Foo"), ], )
self.assertOptimizesTo( [ migrations.CreateModel("Foo", [("name", models.CharField(max_length=255))]), migrations.CreateModel("LinkThrough", []), migrations.AddField( "Foo", "link", models.ManyToManyField("migrations.Link", through="migrations.LinkThrough") ), ], [ migrations.CreateModel("Foo", [("name", models.CharField(max_length=255))]), migrations.CreateModel("LinkThrough", []), migrations.AddField( "Foo", "link", models.ManyToManyField("migrations.Link", through="migrations.LinkThrough") ), ], )
self.assertOptimizesTo( [ migrations.CreateModel("Foo", [ ("a", models.IntegerField()), ("b", models.IntegerField()), ]), alter, migrations.AddField("Foo", "c", models.IntegerField()), ], [ migrations.CreateModel("Foo", [ ("a", models.IntegerField()), ("b", models.IntegerField()), ("c", models.IntegerField()), ]), alter, ], )
self.assertDoesNotOptimize( [ migrations.CreateModel("Foo", [ ("a", models.IntegerField()), ("b", models.IntegerField()), ]), alter, migrations.AlterField("Foo", "b", models.CharField(max_length=255)), ], )
self.assertDoesNotOptimize( [ migrations.CreateModel("Foo", [ ("a", models.IntegerField()), ("b", models.IntegerField()), ]), alter, migrations.RenameField("Foo", "b", "c"), ], )
self.assertDoesNotOptimize( [ migrations.CreateModel("Foo", [ ("a", models.IntegerField()), ("b", models.IntegerField()), ]), alter, migrations.RemoveField("Foo", "b"), ], )
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
recorder_other = MigrationRecorder(connections['other']) self.assertEqual( set((x, y) for (x, y) in recorder_other.applied_migrations() if x == "myapp"), set(), ) recorder.record_unapplied("myapp", "0432_ponies") self.assertEqual( set((x, y) for (x, y) in recorder.applied_migrations() if x == "myapp"), set(), )
migration_loader = MigrationLoader(connection) self.assertEqual( migration_loader.graph.forwards_plan(("migrations", "0002_second")), [ ("migrations", "0001_initial"), ("migrations", "0002_second"), ], ) project_state = migration_loader.project_state(("migrations", "0002_second")) self.assertEqual(len(project_state.models), 2)
self.assertIn("basic", project_state.real_apps)
migration_loader = MigrationLoader(connection) self.assertEqual( migration_loader.graph.forwards_plan(("migrations", "0001_initial")), [ ('contenttypes', '0001_initial'), ('auth', '0001_initial'), ("migrations", "0001_initial"), ], ) project_state = migration_loader.project_state(("migrations", "0001_initial")) self.assertEqual(len([m for a, m in project_state.models if a == "migrations"]), 1)
migration_loader = MigrationLoader(connection) self.assertEqual( migration_loader.graph.forwards_plan(("migrations", "0002_second")), [ ("migrations", "0001_initial"), ("migrations", "0003_third"), ("migrations", "0002_second"), ], )
self.assertEqual( len([x for x in migration_loader.graph.nodes if x[0] == "migrations"]), 1, ) recorder.record_applied("migrations", "0001_initial") migration_loader.build_graph() self.assertEqual( len([x for x in migration_loader.graph.nodes if x[0] == "migrations"]), 2, )
loader.build_graph() self.assertEqual(num_nodes(), 5)
recorder.record_applied("migrations", "1_auto") loader.build_graph() self.assertEqual(num_nodes(), 4)
recorder.record_applied("migrations", "3_auto") loader.build_graph() self.assertEqual(num_nodes(), 4)
recorder.record_applied("migrations", "5_auto") loader.build_graph() self.assertEqual(num_nodes(), 2)
loader.build_graph() self.assertEqual(num_nodes(), 5)
recorder.record_applied("migrations", "1_auto") loader.build_graph() self.assertEqual(num_nodes(), 4)
msg = ("Migration migrations.6_auto depends on nonexistent node ('migrations', '5_auto'). " "Django tried to replace migration migrations.5_auto with any of " "[migrations.3_squashed_5] but wasn't able to because some of the replaced " "migrations are already applied.")
recorder.record_applied("migrations", "5_auto") loader.build_graph() self.assertEqual(num_nodes(), 2)
loader.build_graph() plan = set(loader.graph.forwards_plan(('app1', '4_auto'))) plan = plan - loader.applied_migrations expected_plan = { ('app1', '1_auto'), ('app2', '1_squashed_2'), ('app1', '2_squashed_3'), ('app1', '4_auto'), } self.assertEqual(plan, expected_plan)
recorder.record_applied('app1', '1_auto') recorder.record_applied('app1', '2_auto') loader.build_graph() plan = set(loader.graph.forwards_plan(('app1', '4_auto'))) plan = plan - loader.applied_migrations expected_plan = { ('app2', '1_squashed_2'), ('app1', '3_auto'), ('app1', '4_auto'), } self.assertEqual(plan, expected_plan)
recorder.record_applied('app2', '1_auto') loader.build_graph() plan = set(loader.graph.forwards_plan(('app1', '4_auto'))) plan = plan - loader.applied_migrations expected_plan = { ('app2', '2_auto'), ('app1', '3_auto'), ('app1', '4_auto'), } self.assertEqual(plan, expected_plan)
from __future__ import unicode_literals
self.assertTableNotExists("migrations_author") self.assertTableNotExists("migrations_tribble") self.assertTableNotExists("migrations_book") call_command("migrate", "migrations", "0001", verbosity=0) self.assertTableExists("migrations_author") self.assertTableExists("migrations_tribble") self.assertTableNotExists("migrations_book") call_command("migrate", verbosity=0) self.assertTableExists("migrations_author") self.assertTableNotExists("migrations_tribble") self.assertTableExists("migrations_book") call_command("migrate", "migrations", "zero", verbosity=0) self.assertTableNotExists("migrations_author") self.assertTableNotExists("migrations_tribble") self.assertTableNotExists("migrations_book")
self.assertTableNotExists("migrations_author") self.assertTableNotExists("migrations_tribble") call_command("migrate", "migrations", "0001", verbosity=0) call_command("migrate", "migrations", "zero", fake=True, verbosity=0) with self.assertRaises(DatabaseError): call_command("migrate", "migrations", "0001", fake_initial=True, verbosity=0)
call_command("migrate", "migrations", "zero", verbosity=0) self.assertTableNotExists("migrations_author") self.assertTableNotExists("migrations_tribble") self.assertTableNotExists("migrations_book")
for db in connections: self.assertTableNotExists("migrations_author", using=db) self.assertTableNotExists("migrations_tribble", using=db) call_command("migrate", "migrations", "0001", verbosity=0) call_command("migrate", "migrations", "0001", verbosity=0, database="other") self.assertTableExists("migrations_author") self.assertTableNotExists("migrations_tribble") self.assertTableNotExists("migrations_author", using="other") self.assertTableExists("migrations_tribble", using="other")
call_command("migrate", "migrations", "zero", fake=True, verbosity=0) call_command("migrate", "migrations", "zero", fake=True, verbosity=0, database="other") self.assertTableExists("migrations_author") self.assertTableExists("migrations_tribble", using="other") with self.assertRaises(DatabaseError): call_command("migrate", "migrations", "0001", verbosity=0) out = six.StringIO() with mock.patch('django.core.management.color.supports_color', lambda *args: False): call_command("migrate", "migrations", "0001", fake_initial=True, stdout=out, verbosity=1) call_command("migrate", "migrations", "0001", fake_initial=True, verbosity=0, database="other") self.assertIn( "migrations.0001_initial... faked", out.getvalue().lower() ) call_command("migrate", verbosity=0) call_command("migrate", verbosity=0, database="other") self.assertTableExists("migrations_author") self.assertTableNotExists("migrations_tribble") self.assertTableExists("migrations_book") self.assertTableNotExists("migrations_author", using="other") self.assertTableNotExists("migrations_tribble", using="other") self.assertTableNotExists("migrations_book", using="other") call_command("migrate", "migrations", "zero", fake=True, verbosity=0) call_command("migrate", "migrations", "zero", fake=True, verbosity=0, database="other") self.assertTableExists("migrations_author") self.assertTableNotExists("migrations_tribble") self.assertTableExists("migrations_book") with self.assertRaises(DatabaseError): call_command("migrate", "migrations", verbosity=0) with self.assertRaises(DatabaseError): call_command("migrate", "migrations", fake_initial=True, verbosity=0) call_command("migrate", "migrations", fake=True, verbosity=0) call_command("migrate", "migrations", fake=True, verbosity=0, database="other") call_command("migrate", "migrations", "zero", verbosity=0) call_command("migrate", "migrations", "zero", verbosity=0, database="other") for db in connections: self.assertTableNotExists("migrations_author", using=db) self.assertTableNotExists("migrations_tribble", using=db) self.assertTableNotExists("migrations_book", using=db)
call_command("migrate", "migrations", fake=True, verbosity=0) call_command("migrate", "migrations", "zero", verbosity=0)
call_command("showmigrations", "migrations", format='list', stdout=out, verbosity=0, no_color=True) self.assertEqual( 'migrations\n' ' [x] 0001_initial\n' ' [ ] 0002_second\n', out.getvalue().lower() ) call_command("migrate", "migrations", "zero", verbosity=0)
call_command("migrate", "migrations", "zero", verbosity=0)
call_command("migrate", "migrations", verbosity=0)
call_command("migrate", "migrations", "zero", verbosity=0)
del apps._pending_operations[('migrations', 'tribble')]
call_command("migrate", "migrations", "zero", verbosity=0)
init_file = os.path.join(migration_dir, "__init__.py") self.assertTrue(os.path.exists(init_file))
initial_file = os.path.join(migration_dir, "0001_initial.py") self.assertTrue(os.path.exists(initial_file))
self.assertIn('\\xfa\\xf1\\xed\\xa9\\xf3\\xf0\\xe9 \\xb5\\xf3\\xf0\\xe9\\xf8', content) self.assertIn('\\xfa\\xf1\\xed\\xa9\\xf3\\xf0\\xe9 \\xb5\\xf3\\xf0\\xe9\\xf8\\xdf', content)
importlib.invalidate_caches()
apps.register_model('migrations', UnserializableModel)
initial_file = os.path.join(migration_dir, "0001_initial.py") self.assertTrue(os.path.exists(initial_file))
content = content.replace(' ', '') self.assertIn('dependencies=[\n]', content) self.assertIn('operations=[\n]', content)
with mock.patch('django.db.migrations.questioner.input', mock.Mock(return_value='N')): with self.temporary_migration_module(module="migrations.test_migrations_conflict") as migration_dir: call_command("makemigrations", "migrations", name="merge", merge=True, interactive=True, verbosity=0) merge_file = os.path.join(migration_dir, '0003_merge.py') self.assertFalse(os.path.exists(merge_file))
with mock.patch('django.db.migrations.questioner.input', mock.Mock(return_value='y')): out = six.StringIO() with self.temporary_migration_module(module="migrations.test_migrations_conflict") as migration_dir: call_command("makemigrations", "migrations", name="merge", merge=True, interactive=True, stdout=out) merge_file = os.path.join(migration_dir, '0003_merge.py') self.assertTrue(os.path.exists(merge_file)) self.assertIn("Created new merge migration", force_text(out.getvalue()))
self.assertIn("Add field silly_date to sillymodel", out.getvalue())
self.assertIn("- Add field silly_char to sillymodel", out.getvalue())
initial_file = os.path.join(migration_dir, "0001_initial.py") self.assertTrue(os.path.exists(initial_file))
self.assertIn(" - Create model SillyModel", out.getvalue())
out = six.StringIO() with mock.patch('django.db.migrations.questioner.input', mock.Mock(return_value='N')): with self.temporary_migration_module(module="migrations.test_migrations_conflict") as migration_dir: call_command("makemigrations", "migrations", name="merge", merge=True, stdout=out) merge_file = os.path.join(migration_dir, '0003_merge.py') self.assertFalse(os.path.exists(merge_file)) self.assertNotIn("Created new merge migration", out.getvalue())
with mock.patch('django.db.migrations.questioner.input', mock.Mock(return_value='y')): out = six.StringIO() with self.temporary_migration_module(app_label="migrated_app") as migration_dir: call_command("makemigrations", "migrated_app", name="merge", merge=True, interactive=True, stdout=out) merge_file = os.path.join(migration_dir, '0003_merge.py') self.assertFalse(os.path.exists(merge_file)) self.assertIn("No conflicts detected to merge.", out.getvalue())
with mock.patch('django.db.migrations.questioner.input', mock.Mock(return_value='N')): out = six.StringIO() with mock.patch('django.core.management.color.supports_color', lambda *args: False): call_command( "makemigrations", "conflicting_app_with_dependencies", merge=True, interactive=True, stdout=out ) val = out.getvalue().lower() self.assertIn('merging conflicting_app_with_dependencies\n', val) self.assertIn( ' branch 0002_conflicting_second\n' ' - create model something\n', val ) self.assertIn( ' branch 0002_second\n' ' - delete model tribble\n' ' - remove field silly_field from author\n' ' - add field rating to author\n' ' - create model book\n', val )
self.assertTrue(os.path.exists(migration_file)) with codecs.open(migration_file, "r", encoding="utf-8") as fp: content = fp.read()
migration_name_0001 = "my_initial_migration" content = cmd("0001", migration_name_0001) self.assertIn("dependencies=[\n]", content)
if hasattr(importlib, 'invalidate_caches'): importlib.invalidate_caches()
migration_name_0002 = "my_custom_migration" content = cmd("0002", migration_name_0002, "--empty") self.assertIn("dependencies=[\n('migrations','0001_%s'),\n]" % migration_name_0001, content) self.assertIn("operations=[\n]", content)
with mock.patch('django.db.migrations.questioner.sys.stdout', new_callable=six.StringIO) as prompt_stdout: out = six.StringIO() with self.temporary_migration_module(module='migrations.test_auto_now_add'): call_command('makemigrations', 'migrations', interactive=True, stdout=out) output = force_text(out.getvalue()) prompt_output = force_text(prompt_stdout.getvalue()) self.assertIn("You can accept the default 'timezone.now' by pressing 'Enter'", prompt_output) self.assertIn("Add field creation_date to entry", output)
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
graph = MigrationGraph() graph.add_node(("app_a", "0001"), None) graph.add_node(("app_a", "0002"), None) graph.add_node(("app_a", "0003"), None) graph.add_node(("app_a", "0004"), None) graph.add_node(("app_b", "0001"), None) graph.add_node(("app_b", "0002"), None) graph.add_dependency("app_a.0004", ("app_a", "0004"), ("app_a", "0003")) graph.add_dependency("app_a.0003", ("app_a", "0003"), ("app_a", "0002")) graph.add_dependency("app_a.0002", ("app_a", "0002"), ("app_a", "0001")) graph.add_dependency("app_a.0003", ("app_a", "0003"), ("app_b", "0002")) graph.add_dependency("app_b.0002", ("app_b", "0002"), ("app_b", "0001")) self.assertEqual( graph.forwards_plan(("app_a", "0001")), [('app_a', '0001')], ) self.assertEqual( graph.forwards_plan(("app_b", "0002")), [("app_b", "0001"), ("app_b", "0002")], ) self.assertEqual( graph.forwards_plan(("app_a", "0004")), [ ('app_b', '0001'), ('app_b', '0002'), ('app_a', '0001'), ('app_a', '0002'), ('app_a', '0003'), ('app_a', '0004'), ], ) self.assertEqual( graph.backwards_plan(("app_b", "0002")), [('app_a', '0004'), ('app_a', '0003'), ('app_b', '0002')], ) self.assertEqual( graph.root_nodes(), [('app_a', '0001'), ('app_b', '0001')], ) self.assertEqual( graph.leaf_nodes(), [('app_a', '0004'), ('app_b', '0002')], )
graph = MigrationGraph() graph.add_node(("app_a", "0001"), None) graph.add_node(("app_a", "0002"), None) graph.add_node(("app_a", "0003"), None) graph.add_node(("app_a", "0004"), None) graph.add_node(("app_b", "0001"), None) graph.add_node(("app_b", "0002"), None) graph.add_node(("app_c", "0001"), None) graph.add_node(("app_c", "0002"), None) graph.add_dependency("app_a.0004", ("app_a", "0004"), ("app_a", "0003")) graph.add_dependency("app_a.0003", ("app_a", "0003"), ("app_a", "0002")) graph.add_dependency("app_a.0002", ("app_a", "0002"), ("app_a", "0001")) graph.add_dependency("app_a.0003", ("app_a", "0003"), ("app_b", "0002")) graph.add_dependency("app_b.0002", ("app_b", "0002"), ("app_b", "0001")) graph.add_dependency("app_a.0004", ("app_a", "0004"), ("app_c", "0002")) graph.add_dependency("app_c.0002", ("app_c", "0002"), ("app_c", "0001")) graph.add_dependency("app_c.0001", ("app_c", "0001"), ("app_b", "0001")) graph.add_dependency("app_c.0002", ("app_c", "0002"), ("app_a", "0002")) self.assertEqual( graph.forwards_plan(("app_c", "0002")), [('app_b', '0001'), ('app_c', '0001'), ('app_a', '0001'), ('app_a', '0002'), ('app_c', '0002')], ) self.assertEqual( graph.forwards_plan(("app_a", "0004")), [ ('app_b', '0001'), ('app_c', '0001'), ('app_a', '0001'), ('app_a', '0002'), ('app_c', '0002'), ('app_b', '0002'), ('app_a', '0003'), ('app_a', '0004'), ], ) self.assertEqual( graph.backwards_plan(("app_b", "0001")), [ ('app_a', '0004'), ('app_c', '0002'), ('app_c', '0001'), ('app_a', '0003'), ('app_b', '0002'), ('app_b', '0001'), ], ) self.assertEqual( graph.root_nodes(), [('app_a', '0001'), ('app_b', '0001'), ('app_c', '0001')], ) self.assertEqual( graph.leaf_nodes(), [('app_a', '0004'), ('app_b', '0002'), ('app_c', '0002')], )
graph = MigrationGraph() graph.add_node(("app_a", "0001"), None) graph.add_node(("app_a", "0002"), None) graph.add_node(("app_a", "0003"), None) graph.add_node(("app_b", "0001"), None) graph.add_node(("app_b", "0002"), None) graph.add_dependency("app_a.0003", ("app_a", "0003"), ("app_a", "0002")) graph.add_dependency("app_a.0002", ("app_a", "0002"), ("app_a", "0001")) graph.add_dependency("app_a.0001", ("app_a", "0001"), ("app_b", "0002")) graph.add_dependency("app_b.0002", ("app_b", "0002"), ("app_b", "0001")) graph.add_dependency("app_b.0001", ("app_b", "0001"), ("app_a", "0003")) with self.assertRaises(CircularDependencyError): graph.forwards_plan(("app_a", "0003"), )
graph = MigrationGraph() graph.add_node(("app_a", "0001"), None) graph.add_node(("app_a", "0002"), None) graph.add_node(("app_a", "0003"), None) graph.add_node(("app_b", "0001"), None) graph.add_dependency("app_a.0003", ("app_a", "0003"), ("app_a", "0002")) graph.add_dependency("app_a.0002", ("app_a", "0002"), ("app_a", "0001")) msg = "Migration app_a.0001 dependencies reference nonexistent parent node ('app_b', '0002')" with self.assertRaisesMessage(NodeNotFoundError, msg): graph.add_dependency("app_a.0001", ("app_a", "0001"), ("app_b", "0002"))
graph = MigrationGraph() graph.add_node(("app_a", "0001"), None) msg = "Migration app_a.0002 dependencies reference nonexistent child node ('app_a', '0002')" with self.assertRaisesMessage(NodeNotFoundError, msg): graph.add_dependency("app_a.0002", ("app_a", "0002"), ("app_a", "0001"))
graph = MigrationGraph() graph.add_node(("app_a", "0001"), None) graph.add_dependency("app_a.0001", ("app_a", "0001"), ("app_b", "0002"), skip_validation=True) msg = "Migration app_a.0001 dependencies reference nonexistent parent node ('app_b', '0002')" with self.assertRaisesMessage(NodeNotFoundError, msg): graph.validate_consistency() graph.add_node(("app_b", "0002"), None) graph.validate_consistency() graph.add_dependency("app_a.0002", ("app_a", "0002"), ("app_a", "0001"), skip_validation=True) msg = "Migration app_a.0002 dependencies reference nonexistent child node ('app_a', '0002')" with self.assertRaisesMessage(NodeNotFoundError, msg): graph.validate_consistency() graph.add_node(("app_a", "0002"), None) graph.validate_consistency() msg = "app_a.0001 (req'd by app_a.0002) is missing!" graph.add_dummy_node( key=("app_a", "0001"), origin="app_a.0002", error_message=msg ) with self.assertRaisesMessage(NodeNotFoundError, msg): graph.validate_consistency()
graph = MigrationGraph() graph.add_dummy_node(key=("app_a", "0001"), origin="app_a.0002", error_message="BAD!") graph.add_dummy_node(key=("app_a", "0002"), origin="app_b.0001", error_message="BAD!") graph.add_dependency("app_a.0002", ("app_a", "0002"), ("app_a", "0001"), skip_validation=True) graph.add_node(("app_c", "0001"), None) graph.add_node(("app_b", "0001"), None) graph.add_dependency("app_a.0001", ("app_a", "0001"), ("app_c", "0001"), skip_validation=True) graph.add_dependency("app_b.0001", ("app_b", "0001"), ("app_a", "0002"), skip_validation=True) msg = ( "Unable to find replacement node ('app_a', '0001_squashed_0002'). It was either" " never added to the migration graph, or has been removed." ) with self.assertRaisesMessage(NodeNotFoundError, msg): graph.remove_replaced_nodes( replacement=("app_a", "0001_squashed_0002"), replaced=[("app_a", "0001"), ("app_a", "0002")] ) graph.add_node(("app_a", "0001_squashed_0002"), None) with self.assertRaisesMessage(NodeNotFoundError, "BAD!"): graph.validate_consistency() graph.remove_replaced_nodes( replacement=("app_a", "0001_squashed_0002"), replaced=[("app_a", "0001"), ("app_a", "0002")] ) graph.validate_consistency() parent_node = graph.node_map[("app_c", "0001")] replacement_node = graph.node_map[("app_a", "0001_squashed_0002")] child_node = graph.node_map[("app_b", "0001")] self.assertIn(parent_node, replacement_node.parents) self.assertIn(replacement_node, parent_node.children) self.assertIn(child_node, replacement_node.children) self.assertIn(replacement_node, child_node.parents)
graph = MigrationGraph() graph.add_node(("app_a", "0001"), None) graph.add_node(("app_a", "0002"), None) graph.add_dependency("app_a.0002", ("app_a", "0002"), ("app_a", "0001")) msg = ( "Unable to remove replacement node ('app_a', '0001_squashed_0002'). It was" " either never added to the migration graph, or has been removed already." ) with self.assertRaisesMessage(NodeNotFoundError, msg): graph.remove_replacement_node( replacement=("app_a", "0001_squashed_0002"), replaced=[("app_a", "0001"), ("app_a", "0002")] ) graph.add_node(("app_a", "0001_squashed_0002"), None) graph.add_node(("app_b", "0001"), None) graph.add_dependency("app_b.0001", ("app_b", "0001"), ("app_a", "0001_squashed_0002")) graph.remove_replacement_node( replacement=("app_a", "0001_squashed_0002"), replaced=[("app_a", "0001"), ("app_a", "0002")] ) graph.validate_consistency() replaced_node = graph.node_map[("app_a", "0002")] child_node = graph.node_map[("app_b", "0001")] self.assertIn(child_node, replaced_node.children) self.assertIn(replaced_node, child_node.parents) other_replaced_node = graph.node_map[("app_a", "0001")] self.assertNotIn(child_node, other_replaced_node.children) self.assertNotIn(other_replaced_node, child_node.parents)
from __future__ import unicode_literals
def f(): return 42
__slots__ = 'a',
base = base or {} setting = {k: base.copy() for k in _caches_setting_base.keys()} for key, cache_params in setting.items(): cache_params.update(_caches_setting_base[key]) cache_params.update(params) return setting
cache.set("key", "value") self.assertEqual(cache.get("key"), "value")
cache.add("addkey1", "value") result = cache.add("addkey1", "newvalue") self.assertFalse(result) self.assertEqual(cache.get("addkey1"), "value")
cache.set('somekey', 'value')
self.assertFalse(caches['prefix'].has_key('somekey'))
self.assertIsNone(cache.get("does_not_exist")) self.assertEqual(cache.get("does_not_exist", "bang!"), "bang!")
cache.set('a', 'a') cache.set('b', 'b') cache.set('c', 'c') cache.set('d', 'd') self.assertDictEqual(cache.get_many(['a', 'c', 'd']), {'a': 'a', 'c': 'c', 'd': 'd'}) self.assertDictEqual(cache.get_many(['a', 'b', 'e']), {'a': 'a', 'b': 'b'})
cache.set("key1", "spam") cache.set("key2", "eggs") self.assertEqual(cache.get("key1"), "spam") cache.delete("key1") self.assertIsNone(cache.get("key1")) self.assertEqual(cache.get("key2"), "eggs")
cache.set("hello1", "goodbye1") self.assertTrue(cache.has_key("hello1")) self.assertFalse(cache.has_key("goodbye1")) cache.set("no_expiry", "here", None) self.assertTrue(cache.has_key("no_expiry"))
cache.set("hello2", "goodbye2") self.assertIn("hello2", cache) self.assertNotIn("goodbye2", cache)
cache.set('answer', 41) self.assertEqual(cache.incr('answer'), 42) self.assertEqual(cache.get('answer'), 42) self.assertEqual(cache.incr('answer', 10), 52) self.assertEqual(cache.get('answer'), 52) self.assertEqual(cache.incr('answer', -10), 42) with self.assertRaises(ValueError): cache.incr('does_not_exist')
cache.set('answer', 43) self.assertEqual(cache.decr('answer'), 42) self.assertEqual(cache.get('answer'), 42) self.assertEqual(cache.decr('answer', 10), 32) self.assertEqual(cache.get('answer'), 32) self.assertEqual(cache.decr('answer', -10), 42) with self.assertRaises(ValueError): cache.decr('does_not_exist')
stuff = { 'string': 'this is a string', 'int': 42, 'list': [1, 2, 3, 4], 'tuple': (1, 2, 3, 4), 'dict': {'A': 1, 'B': 2}, 'function': f, 'class': C, } cache.set("stuff", stuff) self.assertEqual(cache.get("stuff"), stuff)
expensive_calculation.num_runs = 0 Poll.objects.all().delete() my_poll = Poll.objects.create(question="Well?") self.assertEqual(Poll.objects.count(), 1) pub_date = my_poll.pub_date cache.set('question', my_poll) cached_poll = cache.get('question') self.assertEqual(cached_poll.pub_date, pub_date) self.assertEqual(expensive_calculation.num_runs, 1)
expensive_calculation.num_runs = 0 Poll.objects.all().delete() Poll.objects.create(question="What?") self.assertEqual(expensive_calculation.num_runs, 1) defer_qs = Poll.objects.all().defer('question') self.assertEqual(defer_qs.count(), 1) self.assertEqual(expensive_calculation.num_runs, 1) cache.set('deferred_queryset', defer_qs) self.assertEqual(expensive_calculation.num_runs, 1)
expensive_calculation.num_runs = 0 Poll.objects.all().delete() Poll.objects.create(question="What?") self.assertEqual(expensive_calculation.num_runs, 1) defer_qs = Poll.objects.all().defer('question') self.assertEqual(defer_qs.count(), 1) cache.set('deferred_queryset', defer_qs) self.assertEqual(expensive_calculation.num_runs, 1) runs_before_cache_read = expensive_calculation.num_runs cache.get('deferred_queryset') self.assertEqual(expensive_calculation.num_runs, runs_before_cache_read)
cache.set('expire1', 'very quickly', 1) cache.set('expire2', 'very quickly', 1) cache.set('expire3', 'very quickly', 1)
stuff = { 'ascii': 'ascii_value', 'unicode_ascii': 'Itrntinliztin1', 'Itrntinliztin': 'Itrntinliztin2', 'ascii2': {'x': 1} } for (key, value) in stuff.items(): cache.set(key, value) self.assertEqual(cache.get(key), value)
for (key, value) in stuff.items(): cache.delete(key) cache.add(key, value) self.assertEqual(cache.get(key), value)
for (key, value) in stuff.items(): cache.delete(key) cache.set_many(stuff) for (key, value) in stuff.items(): self.assertEqual(cache.get(key), value)
from zlib import compress, decompress value = 'value_to_be_compressed' compressed_value = compress(value.encode())
cache.set('binary1', compressed_value) compressed_result = cache.get('binary1') self.assertEqual(compressed_value, compressed_result) self.assertEqual(value, decompress(compressed_result).decode())
cache.add('binary1-add', compressed_value) compressed_result = cache.get('binary1-add') self.assertEqual(compressed_value, compressed_result) self.assertEqual(value, decompress(compressed_result).decode())
cache.set_many({'binary1-set_many': compressed_value}) compressed_result = cache.get('binary1-set_many') self.assertEqual(compressed_value, compressed_result) self.assertEqual(value, decompress(compressed_result).decode())
cache.set_many({"key1": "spam", "key2": "eggs"}) self.assertEqual(cache.get("key1"), "spam") self.assertEqual(cache.get("key2"), "eggs")
cache.set_many({"key1": "spam", "key2": "eggs"}, 1) time.sleep(2) self.assertIsNone(cache.get("key1")) self.assertIsNone(cache.get("key2"))
cache.set("key1", "spam") cache.set("key2", "eggs") cache.set("key3", "ham") cache.delete_many(["key1", "key2"]) self.assertIsNone(cache.get("key1")) self.assertIsNone(cache.get("key2")) self.assertEqual(cache.get("key3"), "ham")
cache.set("key1", "spam") cache.set("key2", "eggs") cache.clear() self.assertIsNone(cache.get("key1")) self.assertIsNone(cache.get("key2"))
cache.set("key1", "spam", 100.2) self.assertEqual(cache.get("key1"), "spam")
for i in range(1, initial_count): cull_cache.set('cull%d' % i, 'value', 1000) count = 0 for i in range(1, initial_count): if cull_cache.has_key('cull%d' % i): count = count + 1 self.assertEqual(count, final_count)
def func(key, *args): return key
key = 'key with spaces and ' cache.set(key, 'value') self.assertEqual(len(w), 1) self.assertIsInstance(w[0].message, CacheKeyWarning) self.assertEqual( str(w[0].message.args[0]), "Cache key contains characters that will cause errors if used " "with memcached: %r" % key, )
key = ('a' * 250) + '' cache.set(key, 'value') self.assertEqual(len(w), 1) self.assertIsInstance(w[0].message, CacheKeyWarning) self.assertEqual( str(w[0].message.args[0]), 'Cache key will cause errors if used with memcached: ' '%r (longer than %s)' % (key, 250), )
cache.set('answer1', 42) self.assertEqual(cache.get('answer1'), 42) self.assertEqual(cache.get('answer1', version=1), 42) self.assertIsNone(cache.get('answer1', version=2))
cache.set('answer2', 42, version=2) self.assertIsNone(cache.get('answer2')) self.assertIsNone(cache.get('answer2', version=1)) self.assertEqual(cache.get('answer2', version=2), 42)
caches['v2'].set('answer3', 42) self.assertIsNone(cache.get('answer3')) self.assertIsNone(cache.get('answer3', version=1)) self.assertEqual(cache.get('answer3', version=2), 42)
caches['v2'].set('answer4', 42, version=1) self.assertEqual(cache.get('answer4'), 42) self.assertEqual(cache.get('answer4', version=1), 42) self.assertIsNone(cache.get('answer4', version=2))
cache.add('answer1', 42, version=2) self.assertIsNone(cache.get('answer1', version=1)) self.assertEqual(cache.get('answer1', version=2), 42)
caches['v2'].add('answer2', 42) self.assertIsNone(cache.get('answer2', version=1)) self.assertEqual(cache.get('answer2', version=2), 42)
caches['v2'].add('answer3', 42, version=1) self.assertEqual(cache.get('answer3', version=1), 42) self.assertIsNone(cache.get('answer3', version=2))
self.assertTrue(cache.has_key('answer1')) self.assertTrue(cache.has_key('answer1', version=1)) self.assertFalse(cache.has_key('answer1', version=2))
cache.set_many({'ford1': 37, 'arthur1': 42}) self.assertDictEqual(cache.get_many(['ford1', 'arthur1']), {'ford1': 37, 'arthur1': 42}) self.assertDictEqual(cache.get_many(['ford1', 'arthur1'], version=1), {'ford1': 37, 'arthur1': 42}) self.assertDictEqual(cache.get_many(['ford1', 'arthur1'], version=2), {})
cache.set_many({'ford2': 37, 'arthur2': 42}, version=2) self.assertDictEqual(cache.get_many(['ford2', 'arthur2']), {}) self.assertDictEqual(cache.get_many(['ford2', 'arthur2'], version=1), {}) self.assertDictEqual(cache.get_many(['ford2', 'arthur2'], version=2), {'ford2': 37, 'arthur2': 42})
caches['v2'].set_many({'ford3': 37, 'arthur3': 42}) self.assertDictEqual(cache.get_many(['ford3', 'arthur3']), {}) self.assertDictEqual(cache.get_many(['ford3', 'arthur3'], version=1), {}) self.assertDictEqual(cache.get_many(['ford3', 'arthur3'], version=2), {'ford3': 37, 'arthur3': 42})
caches['v2'].set_many({'ford4': 37, 'arthur4': 42}, version=1) self.assertDictEqual(cache.get_many(['ford4', 'arthur4']), {'ford4': 37, 'arthur4': 42}) self.assertDictEqual(cache.get_many(['ford4', 'arthur4'], version=1), {'ford4': 37, 'arthur4': 42}) self.assertDictEqual(cache.get_many(['ford4', 'arthur4'], version=2), {})
cache.set('answer1', 42) self.assertEqual(cache.get('answer1'), 42) self.assertIsNone(caches['custom_key'].get('answer1')) self.assertIsNone(caches['custom_key2'].get('answer1'))
with self.assertRaises(pickle.PickleError): cache.add('unpicklable', Unpicklable())
cache_add.return_value = False self.assertEqual(cache.get_or_set('key', 'default'), 'default')
LOCATION='test cache table'
super(DBCacheTests, self).setUp() self.create_table()
super(DBCacheTests, self).tearDown() self.drop_table()
LOCATION='createcachetable_dry_run_mode'
with self.assertNumQueries(0, using='default'): management.call_command('createcachetable', database='default', verbosity=0, interactive=False) num = 5 if connections['other'].features.can_rollback_ddl else 3 with self.assertNumQueries(num, using='other'): management.call_command('createcachetable', database='other', verbosity=0, interactive=False)
caches['prefix']._cache = cache._cache caches['prefix']._expire_info = cache._expire_info
memcached_params = {} for _cache_params in settings.CACHES.values(): if _cache_params['BACKEND'].startswith('django.core.cache.backends.memcached.'): memcached_params = _cache_params
with self.assertRaises(Exception): cache.set('key with spaces', 'value') with self.assertRaises(Exception): cache.set('a' * 251, 'value')
@unittest.skipUnless( memcached_params.get('BACKEND') == 'django.core.cache.backends.memcached.MemcachedCache', "cache with python-memcached library not available") def test_memcached_uses_highest_pickle_version(self): for cache_key, cache_config in settings.CACHES.items(): if cache_config['BACKEND'] == 'django.core.cache.backends.memcached.MemcachedCache': self.assertEqual(caches[cache_key]._cache.pickleProtocol, pickle.HIGHEST_PROTOCOL)
cache.set('infinite_foo', 'bar') self.assertEqual(cache.get('infinite_foo'), 'bar')
cache.set('future_foo', 'bar') self.assertEqual(cache.get('future_foo'), 'bar')
pass
pass
max_value_length = getattr(cache._lib, 'SERVER_MAX_VALUE_LENGTH', 1048576)
value = cache.get('small_value') self.assertTrue(value is None or value == large_value)
for cache_params in settings.CACHES.values(): cache_params.update({'LOCATION': self.dirname}) setting_changed.send(self.__class__, setting='CACHES', enter=False)
shutil.rmtree(self.dirname)
cache.set('unpicklable', UnpicklableType())
key = 'some key with spaces' * 15 val = 'a value' cache.set(key, val) self.assertEqual(cache.get(key), val)
self.DEFAULT_TIMEOUT = caches[DEFAULT_CACHE_ALIAS].default_timeout
(None, ('Accept-Encoding',), 'Accept-Encoding'), ('Accept-Encoding', ('accept-encoding',), 'Accept-Encoding'), ('Accept-Encoding', ('ACCEPT-ENCODING',), 'Accept-Encoding'), ('Cookie', ('Accept-Encoding',), 'Cookie, Accept-Encoding'), ('Cookie, Accept-Encoding', ('Accept-Encoding',), 'Cookie, Accept-Encoding'), ('Cookie, Accept-Encoding', ('Accept-Encoding', 'cookie'), 'Cookie, Accept-Encoding'), (None, ('Accept-Encoding', 'COOKIE'), 'Accept-Encoding, COOKIE'), ('Cookie, Accept-Encoding', ('Accept-Encoding', 'cookie'), 'Cookie, Accept-Encoding'), ('Cookie , Accept-Encoding', ('Accept-Encoding', 'cookie'), 'Cookie, Accept-Encoding'),
self.assertIsNone(get_cache_key(request)) learn_cache_key(request, response)
key_prefix = 'localprefix' learn_cache_key(request, response, key_prefix=key_prefix) self.assertEqual( get_cache_key(request, key_prefix=key_prefix), 'views.decorators.cache.cache_page.localprefix.GET.' '18a03f9c9649f7d684af5db3524f5c99.d41d8cd98f00b204e9800998ecf8427e' )
self.assertIsNone(get_cache_key(request)) learn_cache_key(request, response)
learn_cache_key(request, response)
(None, {'private': True}, {'private'}), ('', {'private': True}, {'private'}),
('private', {'private': True}, {'private'}), ('private', {'public': True}, {'public'}), ('public', {'public': True}, {'public'}), ('public', {'private': True}, {'private'}), ('must-revalidate,max-age=60,private', {'public': True}, {'must-revalidate', 'max-age=60', 'public'}), ('must-revalidate,max-age=60,public', {'private': True}, {'must-revalidate', 'max-age=60', 'private'}), ('must-revalidate,max-age=60', {'public': True}, {'must-revalidate', 'max-age=60', 'public'}),
tz = force_text(timezone.get_current_timezone_name(), errors='ignore') tz = tz.encode('ascii', 'ignore').decode('ascii').replace(' ', '_') response = HttpResponse() key = learn_cache_key(request, response) self.assertIn(tz, key, "Cache keys should include the time zone name when time zones are active") key2 = get_cache_key(request) self.assertEqual(key, key2)
class CustomTzName(timezone.UTC): name = ''
request = self.factory.get(self.path, {'foo': 'bar', 'other': 'true'}) request._cache_update_cache = True
self.assertIsNone(get_cache_data) response = HttpResponse() content = 'Check for cache with QUERY_STRING' response.content = content UpdateCacheMiddleware().process_response(request, response) get_cache_data = FetchFromCacheMiddleware().process_request(request) self.assertIsNotNone(get_cache_data) self.assertEqual(get_cache_data.content, content.encode()) request = self.factory.get(self.path, {'foo': 'bar', 'somethingelse': 'true'}) request._cache_update_cache = True get_cache_data = FetchFromCacheMiddleware().process_request(request) self.assertIsNone(get_cache_data)
en_message = "Hello world!" es_message = "Hola mundo!"
self.assertIsNotNone(get_cache_data) self.assertEqual(get_cache_data.content, en_message.encode()) self.assertTrue(get_cache_data.has_header('ETag')) with self.settings(USE_ETAGS=False): request._cache_update_cache = True set_cache(request, 'en', en_message) get_cache_data = FetchFromCacheMiddleware().process_request(request) self.assertFalse(get_cache_data.has_header('ETag')) request = self.factory.get(self.path) request._cache_update_cache = True set_cache(request, 'es', es_message) translation.activate('en') get_cache_data = FetchFromCacheMiddleware().process_request(request) self.assertEqual(get_cache_data.content, en_message.encode()) translation.activate('es') get_cache_data = FetchFromCacheMiddleware().process_request(request) self.assertEqual(get_cache_data.content, es_message.encode()) translation.deactivate()
content = ['Check for cache with streaming content.'] response = StreamingHttpResponse(content) UpdateCacheMiddleware().process_response(request, response)
middleware = CacheMiddleware()
self.assertEqual(middleware.cache_timeout, 30) self.assertEqual(middleware.key_prefix, 'middlewareprefix') self.assertEqual(middleware.cache_alias, 'other')
as_view_decorator = CacheMiddleware(cache_alias=None, key_prefix=None)
self.assertEqual(as_view_decorator.cache_alias, 'default')
as_view_decorator_with_custom = CacheMiddleware(cache_timeout=60, cache_alias='other', key_prefix='foo')
result = middleware.process_request(request) self.assertIsNone(result)
response = middleware.process_response(request, response)
result = middleware.process_request(request) self.assertIsNotNone(result) self.assertEqual(result.content, b'Hello World 1')
result = prefix_middleware.process_request(request) self.assertIsNone(result)
result = timeout_middleware.process_request(request) self.assertIsNotNone(result) self.assertEqual(result.content, b'Hello World 1')
default_view = cache_page(3)(hello_world_view) default_with_prefix_view = cache_page(3, key_prefix='prefix1')(hello_world_view)
response = default_view(request, '1') self.assertEqual(response.content, b'Hello World 1')
response = default_view(request, '2') self.assertEqual(response.content, b'Hello World 1')
response = explicit_default_view(request, '3') self.assertEqual(response.content, b'Hello World 1')
response = explicit_default_with_prefix_view(request, '4') self.assertEqual(response.content, b'Hello World 4')
response = explicit_default_with_prefix_view(request, '5') self.assertEqual(response.content, b'Hello World 4')
response = default_with_prefix_view(request, '6') self.assertEqual(response.content, b'Hello World 4')
response = other_view(request, '7') self.assertEqual(response.content, b'Hello World 7')
response = other_view(request, '8') self.assertEqual(response.content, b'Hello World 7')
response = other_with_prefix_view(request, '9') self.assertEqual(response.content, b'Hello World 9')
time.sleep(2)
caches['default'] response = default_view(request, '11') self.assertEqual(response.content, b'Hello World 1')
response = default_with_prefix_view(request, '12') self.assertEqual(response.content, b'Hello World 4')
response = explicit_default_view(request, '13') self.assertEqual(response.content, b'Hello World 1')
response = explicit_default_with_prefix_view(request, '14') self.assertEqual(response.content, b'Hello World 4')
response = other_view(request, '15') self.assertEqual(response.content, b'Hello World 15')
response = other_with_prefix_view(request, '16') self.assertEqual(response.content, b'Hello World 16')
self.assertIsNone(cache_middleware.process_request(request))
(None, ('Accept-Encoding',), 'Accept-Encoding'), ('Accept-Encoding', ('accept-encoding',), 'Accept-Encoding'), ('Accept-Encoding', ('ACCEPT-ENCODING',), 'Accept-Encoding'), ('Cookie', ('Accept-Encoding',), 'Cookie, Accept-Encoding'), ('Cookie, Accept-Encoding', ('Accept-Encoding',), 'Cookie, Accept-Encoding'), ('Cookie, Accept-Encoding', ('Accept-Encoding', 'cookie'), 'Cookie, Accept-Encoding'), (None, ('Accept-Encoding', 'COOKIE'), 'Accept-Encoding, COOKIE'), ('Cookie, Accept-Encoding', ('Accept-Encoding', 'cookie'), 'Cookie, Accept-Encoding'), ('Cookie , Accept-Encoding', ('Accept-Encoding', 'cookie'), 'Cookie, Accept-Encoding'),
self.assertIsNone(get_cache_key(request)) learn_cache_key(request, response)
learn_cache_key(request, response, key_prefix=key_prefix) self.assertEqual( get_cache_key(request, key_prefix=key_prefix), 'views.decorators.cache.cache_page.localprefix.GET.' '58a0a05c8a5620f813686ff969c26853.d41d8cd98f00b204e9800998ecf8427e' )
self.assertIsNone(get_cache_key(request)) learn_cache_key(request, response) self.assertEqual( get_cache_key(request), 'views.decorators.cache.cache_page.settingsprefix.GET.' '0f1c2d56633c943073c4569d9a9502fe.d41d8cd98f00b204e9800998ecf8427e' )
self.assertNumQueries(2, self._collect, 0)
n.collect(objs)
display_value = display_for_field(None, models.NullBooleanField(), self.empty_value) expected = '<img src="%sadmin/img/icon-unknown.svg" alt="None" />' % settings.STATIC_URL self.assertHTMLEqual(display_value, expected)
class MockModelAdmin(object): def my_property(self): return "this if from property" my_property.short_description = 'property short description' test_from_property = property(my_property)
class MyForm(forms.Form): text = forms.CharField(label=mark_safe('<i>text</i>')) cb = forms.BooleanField(label=mark_safe('<i>cb</i>'))
class MyForm(forms.Form): text = forms.CharField(label='&text') cb = forms.BooleanField(label='&cb')
from __future__ import unicode_literals
'admin_articles-0-id': str(self.a1.pk), 'admin_articles-0-site': str(self.site.pk), 'admin_articles-0-title': 'Changed Title', 'admin_articles-1-id': str(a2.pk), 'admin_articles-1-site': str(self.site.pk), 'admin_articles-1-title': 'Title second article', 'admin_articles-1-DELETE': 'on', 'admin_articles-2-site': str(self.site.pk), 'admin_articles-2-title': 'Added article',
log_entry.action_flag = 4 self.assertEqual(six.text_type(log_entry), 'LogEntry Object')
logentry.content_type = None logentry.save()
proxy_add_url = reverse('admin:admin_utils_articleproxy_add') response = self.client.post(proxy_add_url, post_data) self.assertRedirects(response, changelist_url) proxy_addition_log = LogEntry.objects.latest('id') self.assertEqual(proxy_addition_log.action_flag, ADDITION) self.assertEqual(proxy_addition_log.content_type, proxy_content_type)
article_id = proxy_addition_log.object_id proxy_change_url = reverse('admin:admin_utils_articleproxy_change', args=(article_id,)) post_data['title'] = 'New' response = self.client.post(proxy_change_url, post_data) self.assertRedirects(response, changelist_url) proxy_change_log = LogEntry.objects.latest('id') self.assertEqual(proxy_change_log.action_flag, CHANGE) self.assertEqual(proxy_change_log.content_type, proxy_content_type)
proxy_delete_url = reverse('admin:admin_utils_articleproxy_delete', args=(article_id,)) response = self.client.post(proxy_delete_url, {'post': 'yes'}) self.assertRedirects(response, changelist_url) proxy_delete_log = LogEntry.objects.latest('id') self.assertEqual(proxy_delete_log.action_flag, DELETION) self.assertEqual(proxy_delete_log.content_type, proxy_content_type)
class Entity(models.Model): pass
Answer = None Post = None Question = None
self.assertQuerysetEqual( self.q1.answer_set.all(), [ "John", "Paul", "George", "Ringo", ], attrgetter("text"), )
a1 = self.q1.answer_set.all()[0] self.assertEqual(a1.text, "John") self.assertEqual(a1.get_next_in_order().text, "Paul")
a1 = self.q1.answer_set.all()[1] id_list = [o.pk for o in self.q1.answer_set.all()] self.assertSequenceEqual(a1.question.get_answer_order(), id_list)
a2 = self.Answer.objects.create(text="Number five", question=self.q1) self.assertListEqual( list(a1.question.get_answer_order()), list(a2.question.get_answer_order()) )
a = self.Answer.objects.create(text="Number five", question=self.q1)
id_list = [o.pk for o in self.q1.answer_set.all()] x = id_list.pop() id_list.insert(-1, x)
self.assertNotEqual(list(a.question.get_answer_order()), id_list)
a.question.set_answer_order(id_list) self.assertQuerysetEqual( self.q1.answer_set.all(), [ "John", "Paul", "George", "Number five", "Ringo" ], attrgetter("text") )
gc.collect() time.sleep(0.1)
gc.collect() gc.collect()
self.assertFalse(signal.has_listeners()) self.assertEqual(signal.receivers, [])
d_signal.disconnect(receiver_1_arg)
class Author(models.Model): name = models.CharField(max_length=150)
class SystemInfo(models.Model): system_name = models.CharField(max_length=32)
self.assertEqual(len(list(Article.objects.all())), 3)
self.assertEqual(len(list(Comment.objects.all())), 4)
with self.assertRaises(TypeError): class ProxyModel(SwappableModel):
resp = ProxyBug.objects.get(version__icontains='beta') self.assertEqual(repr(resp), '<ProxyBug: ProxyBug:fix this>')
resp = ProxyBug.objects.select_related().get(version__icontains='beta') self.assertEqual(repr(resp), '<ProxyBug: ProxyBug:fix this>')
resp = ProxyProxyBug.objects.select_related().get( version__icontains='beta' ) self.assertEqual(repr(resp), '<ProxyProxyBug: ProxyProxyBug:fix this>')
resp = ProxyImprovement.objects.select_related().get( reporter__name__icontains='butor' ) self.assertEqual( repr(resp), '<ProxyImprovement: ProxyImprovement:improve that>' )
resp = ProxyImprovement.objects.select_related().get( associated_bug__summary__icontains='fix' ) self.assertEqual( repr(resp), '<ProxyImprovement: ProxyImprovement:improve that>' )
@override_settings(DEBUG=True) class SelectForUpdateTests(TransactionTestCase):
self.person = Person.objects.create(name='Reinhardt')
self.new_connection = connection.copy()
self.cursor = self.new_connection.cursor() sql = 'SELECT * FROM %(db_table)s %(for_update)s;' % { 'db_table': Person._meta.db_table, 'for_update': self.new_connection.ops.for_update_sql(), } self.cursor.execute(sql, ()) self.cursor.fetchone()
self.new_connection.rollback() self.new_connection.set_autocommit(True)
for_update_sql = tested_connection.ops.for_update_sql(nowait) sql = tested_connection.queries[-1]['sql'] return bool(sql.find(for_update_sql) > -1)
with transaction.atomic(): people = list( Person.objects.all().select_for_update(nowait=nowait) ) people[0].name = 'Fred' people[0].save()
connection.close()
self.start_blocking_transaction()
status = [] thread = threading.Thread( target=self.run_select_for_update, args=(status,) )
thread.start() sanity_count = 0 while len(status) != 1 and sanity_count < 10: sanity_count += 1 time.sleep(1) if sanity_count >= 10: raise ValueError('Thread did not run and block')
p = Person.objects.get(pk=self.person.pk) self.assertEqual('Reinhardt', p.name)
self.end_blocking_transaction() thread.join(5.0)
self.assertFalse(thread.isAlive())
transaction.commit()
connection.close()
width = models.IntegerField(editable=False) height = models.IntegerField(editable=False) image = models.ImageField(storage=temp_storage, upload_to=custom_upload_path, width_field='width', height_field='height') path = models.CharField(max_length=16, blank=True, default='')
return None
class Student(models.Model): character = models.ForeignKey(Character, models.CASCADE) study = models.CharField(max_length=30)
class Photo(models.Model): title = models.CharField(max_length=30) image = models.FileField(storage=temp_storage, upload_to='tests')
def __init__(self, *args, **kwargs): super(Photo, self).__init__(*args, **kwargs) self._savecount = 0
class StrictAssignmentFieldSpecific(models.Model): title = models.CharField(max_length=30) _should_error = False
class Award(models.Model): name = models.CharField(max_length=30) character = models.ForeignKey(Character, models.SET_NULL, blank=False, null=True)
f1 = FormForTestingIsValid(data) self.assertTrue(f1.is_valid())
self.assertIn('no-field', e.args[0])
class ReplaceField(forms.ModelForm): url = forms.BooleanField()
class ReplaceField(forms.ModelForm): url = forms.BooleanField()
class PriceFormWithoutQuantity(forms.ModelForm): class Meta: model = Price exclude = ('quantity',)
class PriceFormWithoutQuantity(forms.ModelForm): class Meta: model = Price fields = ('price',) form = PriceFormWithoutQuantity({'price': '6.00'}) self.assertTrue(form.is_valid())
self.assertEqual(form.instance.price, Decimal('6.00')) self.assertIsNone(form.instance.quantity) self.assertIsNone(form.instance.pk)
class BadForm(ArticleForm, BaseCategoryForm): pass
with self.assertRaises(ValueError): InvalidModelForm()
with self.assertRaises(ValueError): InvalidModelForm(instance=Category)
form = DateTimePostForm({'title': "Django 1.0 is released", 'posted': '2008-09-03'}) self.assertTrue(form.is_valid()) form = DateTimePostForm({'slug': "Django 1.0", 'posted': '2008-01-01'}) self.assertTrue(form.is_valid()) form = DateTimePostForm({'subtitle': "Finally", 'posted': '2008-09-30'}) self.assertTrue(form.is_valid())
for c in categories: self.assertIn(c.pk, d['categories']) self.assertIsInstance(d['categories'], list)
categories = [ Category(name='TestName1', slug='TestName1', url='url1'), Category(name='TestName2', slug='TestName2', url='url2'), Category(name='TestName3', slug='TestName3', url='url3') ] for c in categories: c.save() writer = Writer(name='Test writer') writer.save()
for c in categories: self.assertIn(c.pk, d['categories']) self.assertIsInstance(d['categories'], list)
def formfield_for_dbfield(db_field, **kwargs): if db_field.name == 'categories': kwargs['initial'] = lambda: Category.objects.all().order_by('name')[:2] return db_field.formfield(**kwargs)
f = BaseCategoryForm({'name': 'Third test', 'slug': 'third-test', 'url': 'third'}) self.assertTrue(f.is_valid()) c1 = f.save(commit=False) self.assertEqual(c1.name, "Third test") self.assertEqual(Category.objects.count(), 0) c1.save() self.assertEqual(Category.objects.count(), 1)
f = BaseCategoryForm({'name': '', 'slug': 'not a slug!', 'url': 'foo'}) self.assertEqual(f.errors['name'], ['This field is required.']) self.assertEqual( f.errors['slug'], ["Enter a valid 'slug' consisting of letters, numbers, underscores or hyphens."] ) self.assertEqual(f.cleaned_data, {'url': 'foo'}) with self.assertRaises(ValueError): f.save() f = BaseCategoryForm({'name': '', 'slug': '', 'url': 'foo'}) with self.assertRaises(ValueError): f.save()
class PartialArticleForm(forms.ModelForm): class Meta: model = Article fields = ('headline', 'pub_date')
class PartialArticleFormWithSlug(forms.ModelForm): class Meta: model = Article fields = ('headline', 'slug', 'pub_date')
f = ArticleForm(form_data) new_art = f.save() new_art = Article.objects.get(id=new_art.id) art_id_1 = new_art.id self.assertQuerysetEqual(new_art.categories.order_by('name'), ["Entertainment", "It's a test"])
form_data['categories'] = [] f = ArticleForm(form_data, instance=new_art) new_art = f.save() self.assertEqual(new_art.id, art_id_1) new_art = Article.objects.get(id=art_id_1) self.assertQuerysetEqual(new_art.categories.all(), [])
f = ArticleForm(form_data) new_art = f.save() art_id_2 = new_art.id self.assertNotIn(art_id_2, (None, art_id_1)) new_art = Article.objects.get(id=art_id_2) self.assertQuerysetEqual(new_art.categories.all(), [])
form_data['categories'] = [six.text_type(self.c1.id), six.text_type(self.c2.id)] f = ArticleForm(form_data) new_art = f.save(commit=False)
new_art.save() art_id_3 = new_art.id self.assertNotIn(art_id_3, (None, art_id_1, art_id_2))
new_art = Article.objects.get(id=art_id_3) self.assertQuerysetEqual(new_art.categories.all(), [])
f.save_m2m() self.assertQuerysetEqual(new_art.categories.order_by('name'), ["Entertainment", "It's a test"])
class ShortCategory(forms.ModelForm): name = forms.CharField(max_length=5) slug = forms.CharField(max_length=5) url = forms.CharField(max_length=3)
def test_modelchoicefield(self): f = forms.ModelChoiceField(Category.objects.all()) self.assertEqual(list(f.choices), [ ('', '---------'), (self.c1.pk, 'Entertainment'), (self.c2.pk, "It's a test"), (self.c3.pk, 'Third')]) with self.assertRaises(ValidationError): f.clean('') with self.assertRaises(ValidationError): f.clean(None) with self.assertRaises(ValidationError): f.clean(0)
with self.assertRaises(ValidationError): f.clean([['fail']]) with self.assertRaises(ValidationError): f.clean([{'foo': 'bar'}])
c4 = Category.objects.create(name='Fourth', url='4th') self.assertEqual(f.clean(c4.id).name, 'Fourth')
Category.objects.get(url='4th').delete() with self.assertRaises(ValidationError): f.clean(c4.id)
self.assertEqual(len(f.choices), 2)
f.queryset = Category.objects.exclude(name='Third') self.assertEqual(list(f.choices), [ ('', '---------'), (self.c1.pk, 'Entertainment'), (self.c2.pk, "It's a test")]) self.assertEqual(f.clean(self.c2.id).name, "It's a test") with self.assertRaises(ValidationError): f.clean(self.c3.id)
gen_one = list(f.choices) gen_two = f.choices self.assertEqual(gen_one[2], (self.c2.pk, "It's a test")) self.assertEqual(list(gen_two), [ ('', '---------'), (self.c1.pk, 'Entertainment'), (self.c2.pk, "It's a test")])
f.queryset = Category.objects.all() f.label_from_instance = lambda obj: "category " + str(obj) self.assertEqual(list(f.choices), [ ('', '---------'), (self.c1.pk, 'category Entertainment'), (self.c2.pk, "category It's a test"), (self.c3.pk, 'category Third')])
self.assertIsNot(field1, ModelChoiceForm.base_fields['category']) self.assertIs(field1.widget.choices.field, field1)
with self.assertRaises(ValidationError): f.clean([['fail']]) with self.assertRaises(ValidationError): f.clean([{'foo': 'bar'}])
c6 = Category.objects.create(id=1006, name='Sixth', url='6th') self.assertQuerysetEqual(f.clean([c6.id]), ["Sixth"])
Category.objects.get(url='6th').delete() with self.assertRaises(ValidationError): f.clean([c6.id])
f.queryset = Category.objects.exclude(name='Third') self.assertEqual(list(f.choices), [ (self.c1.pk, 'Entertainment'), (self.c2.pk, "It's a test")]) self.assertQuerysetEqual(f.clean([self.c2.id]), ["It's a test"]) with self.assertRaises(ValidationError): f.clean([self.c3.id]) with self.assertRaises(ValidationError): f.clean([str(self.c2.id), str(self.c3.id)])
model = BetterWriter fields = '__all__'
model = WriterProfile fields = '__all__'
new_author = Author.objects.get(pk=author.pk) self.assertEqual(new_author.publication, None)
f = TextFileForm(data={'description': 'Assistance'}) self.assertFalse(f.is_valid()) f = TextFileForm(data={'description': 'Assistance'}, files={}) self.assertFalse(f.is_valid())
f = TextFileForm( data={'description': 'Assistance'}, files={'file': SimpleUploadedFile('test1.txt', b'hello world')}) self.assertTrue(f.is_valid()) self.assertEqual(type(f.cleaned_data['file']), SimpleUploadedFile) instance = f.save() self.assertEqual(instance.file.name, 'tests/test1.txt') instance.file.delete()
f = TextFileForm( data={'description': 'Assistance'}, files={'file': SimpleUploadedFile('test1.txt', b'hello world')}) self.assertTrue(f.is_valid()) self.assertEqual(type(f.cleaned_data['file']), SimpleUploadedFile) instance = f.save() self.assertEqual(instance.file.name, 'tests/test1.txt')
f = TextFileForm( data={'description': 'Assistance'}, files={'file': SimpleUploadedFile('test-maxlength.txt', b'hello world')}) self.assertFalse(f.is_valid())
f = TextFileForm( data={'description': 'Assistance'}, instance=instance) self.assertTrue(f.is_valid()) self.assertEqual(f.cleaned_data['file'].name, 'tests/test1.txt') instance = f.save() self.assertEqual(instance.file.name, 'tests/test1.txt')
instance.file.delete()
f = TextFileForm( data={'description': 'Assistance'}, files={'file': SimpleUploadedFile('test2.txt', b'hello world')}, instance=instance) self.assertTrue(f.is_valid()) instance = f.save() self.assertEqual(instance.file.name, 'tests/test2.txt')
instance.file.delete() instance.delete()
f = TextFileForm(data={'description': 'Assistance'}) f.fields['file'].required = False self.assertTrue(f.is_valid()) instance = f.save() self.assertEqual(instance.file.name, '')
f = TextFileForm( data={'description': 'New Description'}, instance=instance) f.fields['file'].required = False self.assertTrue(f.is_valid()) instance = f.save() self.assertEqual(instance.description, 'New Description') self.assertEqual(instance.file.name, 'tests/test3.txt')
instance.file.delete() instance.delete()
form = CFFForm(data={'f': None}) form.save()
filename = os.path.join(os.path.dirname(upath(__file__)), "test.png") with open(filename, "rb") as fp: img = fp.read()
data = {'title': 'Testing'} files = {"image": SimpleUploadedFile('test.png', img, 'image/png')}
self.assertEqual(p._savecount, 1)
p = Photo.objects.get() p.image.delete(save=False)
instance.image.delete(save=False) f = ImageFileForm( data={'description': 'An image'}, files={'image': SimpleUploadedFile('test.png', image_data)}) self.assertTrue(f.is_valid()) self.assertEqual(type(f.cleaned_data['image']), SimpleUploadedFile) instance = f.save() self.assertEqual(instance.image.name, 'tests/test.png') self.assertEqual(instance.width, 16) self.assertEqual(instance.height, 16)
instance.image.delete(save=False)
instance.image.delete(save=False) instance.delete()
instance.image.delete(save=False) instance.delete()
if connection.features.interprets_empty_strings_as_nulls: expected_null_imagefield_repr = '' else: expected_null_imagefield_repr = None
f = OptionalImageFileForm( data={'description': 'New Description'}, instance=instance) self.assertTrue(f.is_valid()) instance = f.save() self.assertEqual(instance.description, 'New Description') self.assertEqual(instance.image.name, 'tests/test3.png') self.assertEqual(instance.width, 16) self.assertEqual(instance.height, 16)
instance.image.delete() instance.delete()
f = ImageFileForm( data={'description': 'And a final one', 'path': 'foo'}, files={'image': SimpleUploadedFile('test4.png', image_data)}) self.assertTrue(f.is_valid()) instance = f.save() self.assertEqual(instance.image.name, 'foo/test4.png') instance.delete()
self.assertNotIn('created', ArticleForm().fields)
f = ArticleForm() with self.assertRaises(ValidationError): f.fields['status'].clean('42')
self.assertEqual(form.instance.left, 1)
Form = modelform_factory(Person, fields="__all__") self.assertNotEqual(Form.base_fields['name'].widget.__class__, forms.Textarea)
Form = modelform_factory(Person, fields="__all__", widgets={'name': widget}) self.assertEqual(Form.base_fields['name'].widget.__class__, forms.Textarea)
with self.assertRaises(TypeError): modelform_factory(Person, fields="__all__", formfield_callback='not a function or callable')
form.instance._should_error = True self.assertFalse(form.is_valid()) self.assertEqual(form.errors, { 'title': ['Cannot set attribute', 'This field cannot be blank.'] })
form.instance._should_error = True self.assertFalse(form.is_valid()) self.assertEqual(form.errors, { '__all__': ['Cannot set attribute'], 'title': ['This field cannot be blank.'] })
PASSWORD_HASHERS = [ 'django.contrib.auth.hashers.MD5PasswordHasher', ]
functions = list(reversed(functions))
require_http_methods(["GET"]), require_GET, require_POST, require_safe, condition(lambda r: None, lambda r: None),
vary_on_headers('Accept-language'), vary_on_cookie,
cache_page(60 * 15), cache_control(private=True), never_cache,
user_passes_test(lambda u: True), login_required, permission_required('change_world'),
staff_member_required,
keep_lazy(HttpResponse), keep_lazy_text, lazy,
def simple_dec(func): def wrapper(arg): return func("test:" + arg) return wraps(func)(wrapper)
def myattr_dec(func): def wrapper(*args, **kwargs): return func(*args, **kwargs) wrapper.myattr = True return wraps(func)(wrapper)
@myattr_dec @myattr2_dec def func(): pass
class TestPlain(object): @myattr_dec_m @myattr2_dec_m def method(self): "A method" pass
@method_decorator(myattr_dec_m, "method") class TestMethodAndClass(object): @method_decorator(myattr2_dec_m) def method(self): "A method" pass
decorators = (myattr_dec_m, myattr2_dec_m)
with self.assertRaisesMessage(TypeError, "'set' object"): @method_decorator(decorators, "method") class TestIterable(object): def method(self): "A method" pass
def test_argumented(self): class Test(object): @method_decorator(ClsDec(False)) def method(self): return True
decorators = (add_exclamation_mark, add_question_mark)
r = XFrameOptionsMiddleware().process_response(req, resp) self.assertEqual(r.get('X-Frame-Options', None), None)
@python_2_unicode_compatible class SelfRefer(models.Model): name = models.CharField(max_length=10) references = models.ManyToManyField('self') related = models.ManyToManyField('self')
@python_2_unicode_compatible class TagCollection(Tag): tags = models.ManyToManyField(Tag, related_name='tag_collections')
@python_2_unicode_compatible class Entry(models.Model): name = models.CharField(max_length=10) topics = models.ManyToManyField(Tag) related = models.ManyToManyField(Tag, related_name="similar")
class SelfReferChild(SelfRefer): pass
@python_2_unicode_compatible class Line(models.Model): name = models.CharField(max_length=100)
class User(models.Model): name = models.CharField(max_length=30) friends = models.ManyToManyField(auth.User)
class Post(models.Model): primary_lines = models.ManyToManyField(Line, related_name='+') secondary_lines = models.ManyToManyField(Line, related_name='+')
self.assertIs(t1.entry_set.__class__, t1.entry_set.__class__) self.assertIs(e1.topics.__class__, e1.topics.__class__)
self.assertIs(e1.topics.__class__, e2.topics.__class__) self.assertIs(t1.entry_set.__class__, t2.entry_set.__class__)
m1 = RegressionModelSplit(name='1') m1.save()
foo = Line.objects.create(name='foo') bar = Line.objects.create(name='bar') post = Post.objects.create() post.primary_lines.add(foo) post.secondary_lines.add(bar) self.assertQuerysetEqual(post.primary_lines.all(), ['<Line: foo>']) self.assertQuerysetEqual(post.secondary_lines.all(), ['<Line: bar>'])
s1 = Person.objects.only('name').get(pk=s.pk) with self.assertNumQueries(1): s1.save()
with self.assertNumQueries(1): e1.profile.save() reloaded_profile = Profile.objects.get(pk=profile_boss.pk) self.assertEqual(reloaded_profile.name, profile_boss.name) self.assertEqual(reloaded_profile.salary, 3000)
with self.assertNumQueries(0): s.save(update_fields=[]) self.assertEqual(len(pre_save_data), 0) self.assertEqual(len(post_save_data), 0)
self.assertEqual(Employee.objects.count(), 1) self.assertEqual(Person.objects.count(), 1) with self.assertNumQueries(2): s.save(update_fields=['name', 'employee_num'])
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
self.assertEqual(Article.objects.all()[0], self.a4)
self.assertEqual(str(connections.query).count(" JOIN "), 6)
SpecialClient.objects.create(name='Troy Buswell', state=wa, status=active, value=42) troy = SpecialClient.objects.select_related('state').defer('state__name').get(name='Troy Buswell')
troy = SpecialClient.objects.select_related('state').defer('value', 'state__name').get(name='Troy Buswell')
troy = SpecialClient.objects.select_related('state').only('name', 'state').get(name='Troy Buswell')
self.assertNotIn('LEFT OUTER', str(qs.query))
self.assertIn('LEFT OUTER', str(qs.query))
from __future__ import unicode_literals
from __future__ import unicode_literals
self.assertEqual(Foo.objects.get(friend__contains=b'\xc3\xa7'), fx)
self.assertEqual(Article.objects.filter(submitted_from__contains='32').count(), 0)
c = Comment.objects.select_related().get(id=c1.id) self.assertEqual(c.post, p) self.assertEqual(Comment.objects.select_related().get(id=c2.id).post, None)
self.assertIsNone(Comment.objects.select_related('post').filter(post__isnull=True)[0].post)
self.assertEqual(Item.objects.get(q1), item) self.assertEqual(Item.objects.get(q2), item)
qs1 = Item.objects.filter(q1) & Item.objects.filter(q2) qs2 = Item.objects.filter(q2) & Item.objects.filter(q1) qs3 = Item.objects.filter(q1) | Item.objects.filter(q2) qs4 = Item.objects.filter(q2) | Item.objects.filter(q1)
self.assertEqual(list(qs1), list(qs2)) self.assertEqual(list(qs3), list(qs4))
class Note(models.Model): content_type = models.ForeignKey(ContentType, models.CASCADE) object_id = models.PositiveIntegerField() content_object = GenericForeignKey() note = models.TextField()
class Developer(models.Model): name = models.CharField(max_length=15)
qs = Contact.objects.filter(Q(notes__note__icontains=r'other note') | Q(organizations__name__icontains=r'org name')) self.assertIn(org_contact, qs) qs = Contact.objects.filter( Q(organizations__name__icontains=r'org name') | Q(notes__note__icontains=r'other note')) self.assertIn(org_contact, qs)
dev1 = Developer(name='Joe') note = Note(note='Deserves promotion', content_object=dev1) with self.assertRaises(IntegrityError): note.save()
g1 = Guild.objects.create(name='First guild') note = Note(note='Note for guild', content_object=g1) note.save()
b1 = Board.objects.create(name='') tag = Tag(label='VP', content_object=b1) tag.save()
hs1 = HasLinkThing.objects.create() hs2 = HasLinkThing.objects.create() hs3 = HasLinkThing.objects.create() hs4 = HasLinkThing.objects.create() l1 = Link.objects.create(content_object=hs3) l2 = Link.objects.create(content_object=hs4) self.assertQuerysetEqual( HasLinkThing.objects.filter(links=l1), [hs3], lambda x: x) self.assertQuerysetEqual( HasLinkThing.objects.filter(links=l2), [hs4], lambda x: x) self.assertQuerysetEqual( HasLinkThing.objects.exclude(links=l2), [hs1, hs2, hs3], lambda x: x, ordered=False) self.assertQuerysetEqual( HasLinkThing.objects.exclude(links=l1), [hs1, hs2, hs4], lambda x: x, ordered=False)
self.assertIn("content_type_id", str(B.objects.exclude(a__flag=None).query).lower()) self.assertNotIn(" join ", str(B.objects.exclude(a__flag=True).query).lower()) self.assertIn("content_type_id", str(B.objects.exclude(a__flag=True).query).lower())
self.assertEqual(qs.count(), 1) self.assertEqual(qs[0].links__sum, l.id) l.delete() qs = qs.all() self.assertEqual(qs.count(), 1) self.assertIs(qs[0].links__sum, None) self.assertEqual(qs.filter(links__sum__isnull=True).count(), 1) self.assertEqual(qs.filter(links__sum__isnull=False).count(), 0)
with self.assertRaises(ProtectedError): related.delete()
default_manager = models.Manager() objects = HiddenInventoryManager()
from __future__ import unicode_literals
class MyModelAdmin(admin.ModelAdmin): pass for k in admin_overrides: setattr(MyModelAdmin, k, admin_overrides[k])
ma = MyModelAdmin(model, admin.site) ff = ma.formfield_for_dbfield(model._meta.get_field(fieldname), request=None)
if isinstance(ff.widget, widgets.RelatedFieldWidgetWrapper): widget = ff.widget.widget else: widget = ff.widget
self.assertTrue( isinstance(widget, widgetclass), "Wrong widget for %s.%s: expected %s, got %s" % ( model.__class__.__name__, fieldname, widgetclass, type(widget), ) )
return ff
response = self.client.post(reverse('admin:admin_widgets_event_add'), post_data) self.assertContains(response, 'Select a valid choice. That choice is not one of the available choices.')
response = self.client.post(reverse('admin:admin_widgets_event_add'), {"main_band": test_str})
w = widgets.FilteredSelectMultiple('test\\', False) self.assertHTMLEqual( w.render('test', 'test'), '<select multiple="multiple" name="test" class="selectfilter" ' 'data-field-name="test\\" data-is-stacked="0">\n</select>' )
w = widgets.FilteredSelectMultiple('test\\', True) self.assertHTMLEqual( w.render('test', 'test'), '<select multiple="multiple" name="test" class="selectfilterstacked" ' 'data-field-name="test\\" data-is-stacked="1">\n</select>' )
w = widgets.AdminDateWidget(attrs={'size': 20, 'class': 'myDateField'}) self.assertHTMLEqual( w.render('test', datetime(2007, 12, 1, 9, 30)), '<input value="2007-12-01" type="text" class="myDateField" name="test" size="20" />', )
w = widgets.AdminTimeWidget(attrs={'size': 20, 'class': 'myTimeField'}) self.assertHTMLEqual( w.render('test', datetime(2007, 12, 1, 9, 30)), '<input value="09:30:00" type="text" class="myTimeField" name="test" size="20" />', )
w = widgets.AdminURLFieldWidget() self.assertEqual( w.render('test', 'http://example.com/<sometag>some text</sometag>'), '<p class="url">Currently: ' '<a href="http://example.com/%3Csometag%3Esome%20text%3C/sometag%3E">' 'http://example.com/&lt;sometag&gt;some text&lt;/sometag&gt;</a><br />' 'Change: <input class="vURLField" name="test" type="url" ' 'value="http://example.com/&lt;sometag&gt;some text&lt;/sometag&gt;" /></p>' ) self.assertEqual( w.render('test', 'http://example-.com/<sometag>some text</sometag>'), '<p class="url">Currently: ' '<a href="http://xn--example--7za4pnc.com/%3Csometag%3Esome%20text%3C/sometag%3E">' 'http://example-.com/&lt;sometag&gt;some text&lt;/sometag&gt;</a><br />' 'Change: <input class="vURLField" name="test" type="url" ' 'value="http://example-.com/&lt;sometag&gt;some text&lt;/sometag&gt;" /></p>' ) self.assertEqual( w.render('test', 'http://www.example.com/%C3%A4"><script>alert("XSS!")</script>"'), '<p class="url">Currently: ' '<a href="http://www.example.com/%C3%A4%22%3E%3Cscript%3Ealert(%22XSS!%22)%3C/script%3E%22">' 'http://www.example.com/%C3%A4&quot;&gt;&lt;script&gt;' 'alert(&quot;XSS!&quot;)&lt;/script&gt;&quot;</a><br />' 'Change: <input class="vURLField" name="test" type="url" ' 'value="http://www.example.com/%C3%A4&quot;&gt;&lt;script&gt;' 'alert(&quot;XSS!&quot;)&lt;/script&gt;&quot;" /></p>' )
apple = models.Inventory.objects.create(barcode=86, name='Apple') models.Inventory.objects.create(barcode=22, name='Pear') core = models.Inventory.objects.create( barcode=87, name='Core', parent=apple ) rel = models.Inventory._meta.get_field('parent').remote_field w = widgets.ForeignKeyRawIdWidget(rel, widget_admin_site) self.assertHTMLEqual( w.render('test', core.parent_id, attrs={}), '<input type="text" name="test" value="86" ' 'class="vForeignKeyRawIdAdminField" />' '<a href="/admin_widgets/inventory/?_to_field=barcode" ' 'class="related-lookup" id="lookup_id_test" title="Lookup"></a>' '&nbsp;<strong><a href="/admin_widgets/inventory/%(pk)s/change/">' 'Apple</a></strong>' % {'pk': apple.pk} )
big_honeycomb = models.Honeycomb.objects.create(location='Old tree') big_honeycomb.bee_set.create() rel = models.Bee._meta.get_field('honeycomb').remote_field
subject1 = models.Individual.objects.create(name='Subject #1') models.Individual.objects.create(name='Child', parent=subject1) rel = models.Individual._meta.get_field('parent').remote_field
rel = models.Inventory._meta.get_field('parent').remote_field w = widgets.ForeignKeyRawIdWidget(rel, widget_admin_site)
consultor1 = models.Advisor.objects.create(name='Rockstar Techie')
w = widgets.RelatedFieldWidgetWrapper(w, rel, widget_admin_site) self.assertFalse(w.can_add_related)
self.selenium.get(self.live_server_url + reverse('admin:admin_widgets_member_add'))
self.assertEqual(self.get_css_value('#calendarbox0', 'display'), 'none') self.selenium.find_element_by_id('calendarlink0').click() self.assertEqual(self.get_css_value('#calendarbox0', 'display'), 'block') self.selenium.find_element_by_tag_name('body').send_keys([Keys.ESCAPE]) self.assertEqual(self.get_css_value('#calendarbox0', 'display'), 'none')
self.assertEqual(self.get_css_value('#clockbox0', 'display'), 'none') self.selenium.find_element_by_id('clocklink0').click() self.assertEqual(self.get_css_value('#clockbox0', 'display'), 'block') self.assertEqual( [ x.text for x in self.selenium.find_elements_by_xpath("//ul[@class='timelist']/li/a") ], ['Now', 'Midnight', '6 a.m.', 'Noon', '6 p.m.'] ) self.selenium.find_element_by_tag_name('body').send_keys([Keys.ESCAPE]) self.assertEqual(self.get_css_value('#clockbox0', 'display'), 'none')
self.selenium.get(self.live_server_url + reverse('admin:admin_widgets_member_add'))
self.selenium.find_element_by_id('id_birthdate_0').send_keys('2013-06-01')
self.selenium.find_element_by_id('calendarlink0').click()
calendar0 = self.selenium.find_element_by_id('calendarin0') tds = calendar0.find_elements_by_tag_name('td')
for td in tds[:6] + tds[-6:]: self.assertEqual(td.get_attribute('class'), 'nonday')
self.selenium.get(self.live_server_url + reverse('admin:admin_widgets_member_add'))
self.selenium.find_element_by_id('id_birthdate_0').send_keys('2013-06-01')
self.selenium.find_element_by_id('calendarlink0').click()
calendar0 = self.selenium.find_element_by_id('calendarin0') tds = calendar0.find_elements_by_tag_name('td')
selected = tds[6] self.assertEqual(selected.get_attribute('class'), 'selected')
self.selenium.get(self.live_server_url + reverse('admin:admin_widgets_member_add'))
self.selenium.find_element_by_id('calendarlink0').click()
calendar0 = self.selenium.find_element_by_id('calendarin0') tds = calendar0.find_elements_by_tag_name('td')
selected = [td for td in tds if td.get_attribute('class') == 'selected']
member = models.Member.objects.create(name='Bob', birthdate=datetime(1984, 5, 15), gender='M')
month_string = 'May' path = os.path.join(os.path.dirname(import_module('django.contrib.admin').__file__), 'locale') for language_code, language_name in settings.LANGUAGES: try: catalog = gettext.translation('djangojs', path, [language_code]) except IOError: continue if month_string in catalog._catalog: month_name = catalog._catalog[month_string] else: month_name = month_string
may_translation = month_name expected_caption = '{0:s} {1:d}'.format(may_translation.upper(), 1984)
with override_settings(LANGUAGE_CODE=language_code, USE_L10N=True):
url = reverse('admin:admin_widgets_member_change', args=(member.pk,)) self.selenium.get(self.live_server_url + url) self.selenium.find_element_by_id('calendarlink0').click() self.wait_for_text('#calendarin0 caption', expected_caption)
tz = pytz.timezone('America/Chicago') utc_now = datetime.now(pytz.utc) tz_yesterday = (utc_now - timedelta(days=1)).astimezone(tz).tzname() tz_tomorrow = (utc_now + timedelta(days=1)).astimezone(tz).tzname() if tz_yesterday != tz_tomorrow: error_margin += timedelta(hours=1)
shortcuts = self.selenium.find_elements_by_css_selector('.field-birthdate .datetimeshortcuts')
self.selenium.find_elements_by_css_selector('.field-birthdate .timezonewarning')
self.selenium.find_element_by_tag_name('form').submit() self.wait_page_loaded()
member = models.Member.objects.get(name='test') self.assertGreater(member.birthdate, now - error_margin) self.assertLess(member.birthdate, now + error_margin)
@override_settings(TIME_ZONE='US/Eastern') class DateTimePickerAltTimezoneSeleniumTests(DateTimePickerShortcutsSeleniumTests): pass
self.assertSelectOptions(from_box, [ str(self.arthur.id), str(self.bob.id), str(self.cliff.id), str(self.jason.id), str(self.jenny.id), str(self.john.id), ]) self.assertSelectOptions(to_box, [str(self.lisa.id), str(self.peter.id)]) self.assertActiveButtons(mode, field_name, False, False, True, True)
if mode == 'horizontal': self.selenium.find_element_by_id(choose_all_link).click() elif mode == 'vertical': for option in self.selenium.find_elements_by_css_selector(from_box + ' > option'): option.click() self.selenium.find_element_by_id(choose_link).click() self.assertSelectOptions(from_box, []) self.assertSelectOptions(to_box, [ str(self.lisa.id), str(self.peter.id), str(self.arthur.id), str(self.bob.id), str(self.cliff.id), str(self.jason.id), str(self.jenny.id), str(self.john.id), ]) self.assertActiveButtons(mode, field_name, False, False, False, True)
if mode == 'horizontal': self.selenium.find_element_by_id(remove_all_link).click() elif mode == 'vertical': for option in self.selenium.find_elements_by_css_selector(to_box + ' > option'): option.click() self.selenium.find_element_by_id(remove_link).click() self.assertSelectOptions(from_box, [ str(self.lisa.id), str(self.peter.id), str(self.arthur.id), str(self.bob.id), str(self.cliff.id), str(self.jason.id), str(self.jenny.id), str(self.john.id), ]) self.assertSelectOptions(to_box, []) self.assertActiveButtons(mode, field_name, False, False, True, False)
from_lisa_select_option = self.get_select_option(from_box, str(self.lisa.id))
self.assertEqual(from_lisa_select_option.get_attribute('title'), from_lisa_select_option.get_attribute('text'))
to_lisa_select_option = self.get_select_option(to_box, str(self.lisa.id)) self.assertEqual(to_lisa_select_option.get_attribute('title'), to_lisa_select_option.get_attribute('text'))
self.get_select_option(to_box, str(self.lisa.id)).click() self.get_select_option(to_box, str(self.bob.id)).click() self.assertActiveButtons(mode, field_name, False, True, True, True) self.selenium.find_element_by_id(remove_link).click() self.assertActiveButtons(mode, field_name, False, False, True, True)
self.get_select_option(from_box, str(self.arthur.id)).click() self.get_select_option(from_box, str(self.cliff.id)).click() self.selenium.find_element_by_id(choose_link).click()
self.get_select_option(from_box, str(self.peter.id)).click() self.get_select_option(from_box, str(self.lisa.id)).click()
self.assertSelectedOptions(from_box, [str(self.peter.id), str(self.lisa.id)]) self.selenium.find_element_by_id(remove_link).click() self.assertSelectedOptions(from_box, [str(self.peter.id), str(self.lisa.id)])
self.get_select_option(from_box, str(self.peter.id)).click() self.get_select_option(from_box, str(self.lisa.id)).click()
self.get_select_option(to_box, str(self.jason.id)).click() self.get_select_option(to_box, str(self.john.id)).click()
self.assertSelectedOptions(to_box, [str(self.jason.id), str(self.john.id)]) self.selenium.find_element_by_id(choose_link).click() self.assertSelectedOptions(to_box, [str(self.jason.id), str(self.john.id)])
self.get_select_option(to_box, str(self.jason.id)).click() self.get_select_option(to_box, str(self.john.id)).click()
self.assertEqual(self.selenium.current_url, original_url)
self.selenium.find_element_by_xpath('//input[@value="Save"]').click() self.wait_page_loaded()
self.assertSelectOptions(from_box, [ str(self.arthur.id), str(self.bob.id), str(self.cliff.id), str(self.jason.id), str(self.jenny.id), str(self.john.id), ])
input.send_keys('a') self.assertSelectOptions(from_box, [str(self.arthur.id), str(self.jason.id)]) input.send_keys('R') self.assertSelectOptions(from_box, [str(self.arthur.id)])
input.send_keys([Keys.BACK_SPACE]) self.assertSelectOptions(from_box, [str(self.arthur.id), str(self.jason.id)]) input.send_keys([Keys.BACK_SPACE]) self.assertSelectOptions(from_box, [ str(self.arthur.id), str(self.bob.id), str(self.cliff.id), str(self.jason.id), str(self.jenny.id), str(self.john.id), ])
input.send_keys('a') self.assertSelectOptions(from_box, [str(self.arthur.id), str(self.jason.id)]) self.get_select_option(from_box, str(self.jason.id)).click() self.selenium.find_element_by_id(choose_link).click() self.assertSelectOptions(from_box, [str(self.arthur.id)]) self.assertSelectOptions(to_box, [ str(self.lisa.id), str(self.peter.id), str(self.jason.id), ])
self.get_select_option(to_box, str(self.jason.id)).click() self.selenium.find_element_by_id(remove_link).click() input.send_keys('ja') self.assertSelectOptions(from_box, [str(self.jason.id)]) input.send_keys([Keys.ENTER]) self.assertSelectOptions(to_box, [str(self.peter.id), str(self.jason.id)]) input.send_keys([Keys.BACK_SPACE, Keys.BACK_SPACE])
self.selenium.find_element_by_xpath('//input[@value="Save"]').click() self.wait_page_loaded()
self.selenium.find_element_by_link_text('Home').click() self.selenium.back() expected_unselected_values = [ str(self.arthur.id), str(self.bob.id), str(self.cliff.id), str(self.jason.id), str(self.jenny.id), str(self.john.id), ] expected_selected_values = [str(self.lisa.id), str(self.peter.id)] self.assertSelectOptions('#id_students_from', expected_unselected_values) self.assertSelectOptions('#id_students_to', expected_selected_values) self.assertSelectOptions('#id_alumni_from', expected_unselected_values) self.assertSelectOptions('#id_alumni_to', expected_selected_values)
self.selenium.execute_script("location.reload()") self.wait_page_loaded()
self.assertEqual(self.selenium.find_element_by_id('id_main_band').get_attribute('value'), '')
self.selenium.find_element_by_id('lookup_id_main_band').click() self.wait_for_popup() self.selenium.switch_to.window('id_main_band') link = self.selenium.find_element_by_link_text('Bogey Blues') self.assertIn('/band/42/', link.get_attribute('href')) link.click()
self.selenium.switch_to.window(main_window) self.wait_for_value('#id_main_band', '42')
self.selenium.find_element_by_id('lookup_id_main_band').click() self.wait_for_popup() self.selenium.switch_to.window('id_main_band') link = self.selenium.find_element_by_link_text('Green Potatoes') self.assertIn('/band/98/', link.get_attribute('href')) link.click()
self.selenium.switch_to.window(main_window) self.wait_for_value('#id_main_band', '98')
self.assertEqual(self.selenium.find_element_by_id('id_supporting_bands').get_attribute('value'), '')
self.assertEqual( self.selenium.find_element_by_css_selector('.field-supporting_bands p.help').text, 'Supporting Bands.' )
self.selenium.find_element_by_id('lookup_id_supporting_bands').click() self.wait_for_popup() self.selenium.switch_to.window('id_supporting_bands') link = self.selenium.find_element_by_link_text('Bogey Blues') self.assertIn('/band/42/', link.get_attribute('href')) link.click()
self.selenium.switch_to.window(main_window) self.wait_for_value('#id_supporting_bands', '42')
self.selenium.find_element_by_id('lookup_id_supporting_bands').click() self.wait_for_popup() self.selenium.switch_to.window('id_supporting_bands') link = self.selenium.find_element_by_link_text('Green Potatoes') self.assertIn('/band/98/', link.get_attribute('href')) link.click()
self.selenium.switch_to.window(main_window) self.wait_for_value('#id_supporting_bands', '42,98')
self.selenium.find_element_by_id('add_id_user').click() self.wait_for_popup() self.selenium.switch_to.window('id_user') password_field = self.selenium.find_element_by_id('id_password') password_field.send_keys('password')
self.selenium.find_element_by_css_selector('#id_user option[value=newuser]')
self.selenium.find_element_by_id('change_id_user').click() self.wait_for_popup() self.selenium.switch_to.window('id_user')
self.selenium.find_element_by_css_selector(save_button_css_selector).click() self.wait_for_text('li.success', 'The profile "changednewuser" was added successfully.') profiles = models.Profile.objects.all() self.assertEqual(len(profiles), 1) self.assertEqual(profiles[0].user.username, username_value)
from __future__ import unicode_literals
encoding = locale.getpreferredencoding() username = 'rle' password = 'ssame' try: username_str = force_str(username, encoding) password_str = force_str(password, encoding) pgpass_bytes = force_bytes( 'somehost:444:dbname:%s:%s' % (username, password), encoding=encoding, ) except UnicodeEncodeError: if six.PY2: self.skipTest("Your locale can't run this test.") self.assertEqual( self._run_it({ 'NAME': 'dbname', 'USER': username_str, 'PASSWORD': password_str, 'HOST': 'somehost', 'PORT': 444, }), ( ['psql', '-U', username_str, '-h', 'somehost', '-p', '444', 'dbname'], pgpass_bytes, ) )
d = Donut(name='Apple Fritter') d.baked_time = datetime.datetime(year=2007, month=4, day=20, hour=16, minute=19, second=59) d.save()
with self.assertRaises(ValueError): d.save()
self.assertIsInstance(b.baked_timestamp, datetime.datetime) self.assertIsInstance(b.baked_date, datetime.date) self.assertNotIsInstance(b.baked_date, datetime.datetime)
a.gender = '' self.assertEqual(a.get_gender_display(), '')
if kwargs['using'] == MIGRATE_DATABASE: self.call_counter = self.call_counter + 1 self.call_args = kwargs self.signal.disconnect(self, sender=APP_CONFIG)
pre_migrate_receiver = OneTimeReceiver(signals.pre_migrate) post_migrate_receiver = OneTimeReceiver(signals.post_migrate)
self.assertFalse(args['plan'][0][1]) self.assertIsInstance(args['apps'], migrations.state.StateApps)
from __future__ import unicode_literals
super(Person, self).save(*args, **kwargs) self.data.append("After save")
super(Person, self).delete() self.data.append("After deletion")
content_type = models.ForeignKey(ContentType, models.CASCADE) object_pk = models.TextField() content_object = GenericForeignKey(ct_field="content_type", fk_field="object_pk")
return sorted(self.houses.all(), key=lambda house: -house.rooms.count())[0]
with self.assertNumQueries(2): book = Book.objects.prefetch_related('bookwithyear').all()[0] with self.assertNumQueries(0): with self.assertRaises(BookWithYear.DoesNotExist): book.bookwithyear
with self.assertNumQueries(3): author = Author.objects.prefetch_related('books__read_by').get(name="Charlotte") lists = [[six.text_type(r) for r in b.read_by.all()] for b in author.books.all()]
self.assertEqual(self.book1.authors.count(), 3)
self.assertEqual(self.author1.books.count(), 2)
with self.assertRaises(ValueError): self.traverse_qs( Person.objects.prefetch_related('houses__rooms', Prefetch('houses', queryset=House.objects.all())), [['houses', 'rooms']] )
with self.assertRaises(AttributeError): self.traverse_qs( Person.objects.prefetch_related( 'houses_lst__rooms', Prefetch('houses', queryset=House.objects.all(), to_attr='houses_lst') ), [['houses', 'rooms']] )
self.traverse_qs( Person.objects.prefetch_related('houses__rooms', 'houses'), [['houses', 'rooms']] )
with self.assertNumQueries(2): lst1 = self.traverse_qs( Person.objects.prefetch_related('houses'), [['houses']] )
with self.assertNumQueries(2): lst2 = self.traverse_qs( Person.objects.prefetch_related(Prefetch('houses')), [['houses']] ) self.assertEqual(lst1, lst2) with self.assertNumQueries(2): lst2 = self.traverse_qs( Person.objects.prefetch_related(Prefetch('houses', to_attr='houses_lst')), [['houses_lst']] ) self.assertEqual(lst1, lst2)
with self.assertNumQueries(2): lst1 = self.traverse_qs( House.objects.prefetch_related('occupants'), [['occupants']] )
with self.assertNumQueries(2): lst2 = self.traverse_qs( House.objects.prefetch_related(Prefetch('occupants')), [['occupants']] ) self.assertEqual(lst1, lst2) with self.assertNumQueries(2): lst2 = self.traverse_qs( House.objects.prefetch_related(Prefetch('occupants', to_attr='occupants_lst')), [['occupants_lst']] ) self.assertEqual(lst1, lst2)
with self.assertNumQueries(3): lst1 = self.traverse_qs( Room.objects.prefetch_related('house__occupants'), [['house', 'occupants']] )
with self.assertNumQueries(3): lst2 = self.traverse_qs( Room.objects.prefetch_related(Prefetch('house__occupants')), [['house', 'occupants']] ) self.assertEqual(lst1, lst2) with self.assertNumQueries(3): lst2 = self.traverse_qs( Room.objects.prefetch_related(Prefetch('house__occupants', to_attr='occupants_lst')), [['house', 'occupants_lst']] ) self.assertEqual(lst1, lst2)
with self.assertNumQueries(3): lst1 = self.traverse_qs( TaggedItem.objects.filter(tag='houses').prefetch_related('content_object__rooms'), [['content_object', 'rooms']] )
with self.assertNumQueries(3): lst2 = self.traverse_qs( TaggedItem.objects.prefetch_related( Prefetch('content_object'), Prefetch('content_object__rooms', to_attr='rooms_lst') ), [['content_object', 'rooms_lst']] ) self.assertEqual(lst1, lst2)
with self.assertNumQueries(3): lst1 = self.traverse_qs( Person.objects.prefetch_related('houses', 'houses__rooms'), [['houses', 'rooms']] )
with self.assertNumQueries(3): lst2 = self.traverse_qs( Person.objects.prefetch_related(Prefetch('houses'), 'houses__rooms'), [['houses', 'rooms']] ) self.assertEqual(lst1, lst2) with self.assertNumQueries(3): lst2 = self.traverse_qs( Person.objects.prefetch_related(Prefetch('houses'), Prefetch('houses__rooms')), [['houses', 'rooms']] ) self.assertEqual(lst1, lst2) with self.assertNumQueries(3): lst2 = self.traverse_qs( Person.objects.prefetch_related(Prefetch('houses', to_attr='houses_lst'), 'houses_lst__rooms'), [['houses_lst', 'rooms']] ) self.assertEqual(lst1, lst2) with self.assertNumQueries(3): lst2 = self.traverse_qs( Person.objects.prefetch_related( Prefetch('houses', to_attr='houses_lst'), Prefetch('houses_lst__rooms', to_attr='rooms_lst') ), [['houses_lst', 'rooms_lst']] ) self.assertEqual(lst1, lst2)
with self.assertNumQueries(4): lst1 = self.traverse_qs( Bookmark.objects.prefetch_related('tags', 'tags__content_object', 'favorite_tags'), [['tags', 'content_object'], ['favorite_tags']] )
with self.assertNumQueries(4): lst2 = self.traverse_qs( Bookmark.objects.prefetch_related( Prefetch('tags', to_attr='tags_lst'), Prefetch('tags_lst__content_object'), Prefetch('favorite_tags'), ), [['tags_lst', 'content_object'], ['favorite_tags']] ) self.assertEqual(lst1, lst2)
with self.assertNumQueries(5): lst1 = self.traverse_qs( Person.objects.prefetch_related( 'houses__rooms', 'primary_house__occupants__houses', ), [['primary_house', 'occupants', 'houses']] )
with self.assertNumQueries(5): lst2 = self.traverse_qs( Person.objects.prefetch_related( 'houses__rooms', Prefetch('primary_house__occupants', to_attr='occupants_lst'), 'primary_house__occupants_lst__houses', ), [['primary_house', 'occupants_lst', 'houses']] ) self.assertEqual(lst1, lst2)
with self.assertNumQueries(4): lst1 = self.traverse_qs( Person.objects.prefetch_related( 'houses', 'all_houses__occupants__houses', ), [['all_houses', 'occupants', 'houses']] )
with self.assertNumQueries(4): lst2 = self.traverse_qs( Person.objects.prefetch_related( 'houses', Prefetch('all_houses__occupants', to_attr='occupants_lst'), 'all_houses__occupants_lst__houses', ), [['all_houses', 'occupants_lst', 'houses']] ) self.assertEqual(lst1, lst2)
with self.assertNumQueries(2): lst1 = list(Person.objects.prefetch_related('houses')) with self.assertNumQueries(2): lst2 = list(Person.objects.prefetch_related( Prefetch('houses', queryset=House.objects.all(), to_attr='houses_lst'))) self.assertEqual( self.traverse_qs(lst1, [['houses']]), self.traverse_qs(lst2, [['houses_lst']]) )
with self.assertNumQueries(2): lst2 = list( Person.objects.prefetch_related( Prefetch( 'houses', queryset=House.objects.filter(pk__in=[self.house1.pk, self.house3.pk]), to_attr='houses_lst', ) ) ) self.assertEqual(len(lst2[0].houses_lst), 1) self.assertEqual(lst2[0].houses_lst[0], self.house1) self.assertEqual(len(lst2[1].houses_lst), 1) self.assertEqual(lst2[1].houses_lst[0], self.house3)
with self.assertNumQueries(3): lst1 = list(Person.objects.prefetch_related('houses__rooms')) with self.assertNumQueries(3): lst2 = list(Person.objects.prefetch_related( Prefetch('houses__rooms', queryset=Room.objects.all(), to_attr='rooms_lst'))) self.assertEqual( self.traverse_qs(lst1, [['houses', 'rooms']]), self.traverse_qs(lst2, [['houses', 'rooms_lst']]) )
with self.assertNumQueries(3): lst1 = list(Person.objects.prefetch_related('houses__owner')) with self.assertNumQueries(2): lst2 = list(Person.objects.prefetch_related( Prefetch('houses', queryset=House.objects.select_related('owner')))) self.assertEqual( self.traverse_qs(lst1, [['houses', 'owner']]), self.traverse_qs(lst2, [['houses', 'owner']]) )
inner_rooms_qs = Room.objects.filter(pk__in=[self.room1_1.pk, self.room1_2.pk]) houses_qs_prf = House.objects.prefetch_related( Prefetch('rooms', queryset=inner_rooms_qs, to_attr='rooms_lst')) with self.assertNumQueries(4): lst2 = list(Person.objects.prefetch_related( Prefetch('houses', queryset=houses_qs_prf.filter(pk=self.house1.pk), to_attr='houses_lst'), Prefetch('houses_lst__rooms_lst__main_room_of') ))
houses = House.objects.select_related('owner') with self.assertNumQueries(6): rooms = Room.objects.all().prefetch_related('house') lst1 = self.traverse_qs(rooms, [['house', 'owner']]) with self.assertNumQueries(2): rooms = Room.objects.all().prefetch_related(Prefetch('house', queryset=houses.all())) lst2 = self.traverse_qs(rooms, [['house', 'owner']]) self.assertEqual(lst1, lst2) with self.assertNumQueries(2): houses = House.objects.select_related('owner') rooms = Room.objects.all().prefetch_related(Prefetch('house', queryset=houses.all(), to_attr='house_attr')) lst2 = self.traverse_qs(rooms, [['house_attr', 'owner']]) self.assertEqual(lst1, lst2) room = Room.objects.all().prefetch_related( Prefetch('house', queryset=houses.filter(address='DoesNotExist')) ).first() with self.assertRaises(ObjectDoesNotExist): getattr(room, 'house') room = Room.objects.all().prefetch_related( Prefetch('house', queryset=houses.filter(address='DoesNotExist'), to_attr='house_attr') ).first() self.assertIsNone(room.house_attr) rooms = Room.objects.all().prefetch_related(Prefetch('house', queryset=House.objects.only('name'))) with self.assertNumQueries(2): getattr(rooms.first().house, 'name') with self.assertNumQueries(3): getattr(rooms.first().house, 'address')
houses = House.objects.select_related('owner') with self.assertNumQueries(6): rooms = Room.objects.all().prefetch_related('main_room_of') lst1 = self.traverse_qs(rooms, [['main_room_of', 'owner']]) with self.assertNumQueries(2): rooms = Room.objects.all().prefetch_related(Prefetch('main_room_of', queryset=houses.all())) lst2 = self.traverse_qs(rooms, [['main_room_of', 'owner']]) self.assertEqual(lst1, lst2) with self.assertNumQueries(2): rooms = list( Room.objects.all().prefetch_related( Prefetch('main_room_of', queryset=houses.all(), to_attr='main_room_of_attr') ) ) lst2 = self.traverse_qs(rooms, [['main_room_of_attr', 'owner']]) self.assertEqual(lst1, lst2) room = Room.objects.filter(main_room_of__isnull=False).prefetch_related( Prefetch('main_room_of', queryset=houses.filter(address='DoesNotExist')) ).first() with self.assertRaises(ObjectDoesNotExist): getattr(room, 'main_room_of') room = Room.objects.filter(main_room_of__isnull=False).prefetch_related( Prefetch('main_room_of', queryset=houses.filter(address='DoesNotExist'), to_attr='main_room_of_attr') ).first() self.assertIsNone(room.main_room_of_attr)
person = Person.objects.prefetch_related( Prefetch('houses', queryset=House.objects.filter(name='House 1')), ).get(pk=self.person1.pk) self.assertEqual( list(person.houses.all()), list(person.houses.all().all()), )
houses_2 = House.objects.prefetch_related(Prefetch('rooms')) persons = Person.objects.prefetch_related(Prefetch('houses', queryset=houses_2)) houses = House.objects.prefetch_related(Prefetch('occupants', queryset=persons))
del Person.houses.related_manager_cls._apply_rel_filters del Person.houses.related_manager_cls.get_queryset try: with warnings.catch_warnings(record=True) as warns: warnings.simplefilter('always') list(Person.objects.prefetch_related( Prefetch('houses', queryset=House.objects.filter(name='House 1')) )) finally: del Person.houses.related_manager_cls msg = ( 'The `django.db.models.fields.related_descriptors.ManyRelatedManager` class ' 'must implement a `_apply_rel_filters()` method that accepts a `QuerySet` as ' 'its single argument and returns an appropriately filtered version of it.' )
qs = Department.objects.prefetch_related('teachers') depts = "".join("%s department: %s\n" % (dept.name, ", ".join(six.text_type(t) for t in dept.teachers.all())) for dept in qs)
with self.assertNumQueries(3): qs = TaggedItem.objects.prefetch_related('content_object') list(qs)
with self.assertNumQueries(2): qs = Comment.objects.prefetch_related('content_object') [c.content_object for c in qs]
with self.assertNumQueries(3): qs = TaggedItem.objects.filter(content_type=ct, tag='awesome').prefetch_related('content_object__read_by') readers_of_awesome_books = {r.name for tag in qs for r in tag.content_object.read_by.all()} self.assertEqual(readers_of_awesome_books, {"me", "you", "someone"})
self.assertEqual(list(bookmark.tags.all()), list(bookmark.tags.all().all()))
self.assertIn('authorwithage', connection.queries[-1]['sql'].lower()) self.assertIn(' IN ', connection.queries[-1]['sql'])
qs = Person.objects.prefetch_related('houses__rooms', 'primary_house__occupants') [list(p.primary_house.occupants.all()) for p in qs]
with self.assertNumQueries(2): qs = Employee.objects.select_related('boss').prefetch_related('boss__serfs') co_serfs = [list(e.boss.serfs.all()) if e.boss is not None else [] for e in qs]
with self.assertNumQueries(3): qs = Employee.objects.prefetch_related('boss__serfs') co_serfs = [list(e.boss.serfs.all()) if e.boss is not None else [] for e in qs]
bulk = Employee.objects.prefetch_related('serfs').in_bulk([boss1.pk, boss2.pk]) for b in bulk.values(): list(b.serfs.all())
qs1 = B.prefetch_related('authors') with self.assertNumQueries(2, using='other'): books = "".join("%s (%s)\n" % (book.title, ", ".join(a.name for a in book.authors.all())) for book in qs1) self.assertEqual(books, "Poems (Charlotte, Anne, Emily)\n" "Jane Eyre (Charlotte)\n" "Wuthering Heights (Emily)\n" "Sense and Sensibility (Jane)\n")
qs2 = A.prefetch_related('books') with self.assertNumQueries(2, using='other'): authors = "".join("%s: %s\n" % (author.name, ", ".join(b.title for b in author.books.all())) for author in qs2) self.assertEqual(authors, "Charlotte: Poems, Jane Eyre\n" "Anne: Poems\n" "Emily: Poems, Wuthering Heights\n" "Jane: Sense and Sensibility\n")
with self.assertNumQueries(2, using='other'): books = ", ".join(a.first_book.title for a in A.prefetch_related('first_book')) self.assertEqual("Poems, Sense and Sensibility", books)
with self.assertNumQueries(2, using='other'): books = "".join("%s (%s)\n" % (b.title, ", ".join(a.name for a in b.first_time_authors.all())) for b in B.prefetch_related('first_time_authors')) self.assertEqual(books, "Poems (Charlotte Bronte)\n" "Sense and Sensibility (Jane Austen)\n")
with self.assertNumQueries(2, using='other'): authors = ", ".join(a.author.name for a in A.prefetch_related('author'))
with self.assertNumQueries(2, using='other'): ages = ", ".join(str(a.authorwithage.age) for a in A.prefetch_related('authorwithage'))
with self.assertNumQueries(2, using='other'): prefetch = Prefetch('first_time_authors', queryset=Author.objects.all()) books = "".join("%s (%s)\n" % (b.title, ", ".join(a.name for a in b.first_time_authors.all())) for b in B.prefetch_related(prefetch)) self.assertEqual(books, "Poems (Charlotte Bronte)\n" "Sense and Sensibility (Jane Austen)\n")
with self.assertNumQueries(2, using='other'): prefetch = Prefetch('first_time_authors', queryset=Author.objects.using('other')) books = "".join("%s (%s)\n" % (b.title, ", ".join(a.name for a in b.first_time_authors.all())) for b in B.prefetch_related(prefetch)) self.assertEqual(books, "Poems (Charlotte Bronte)\n" "Sense and Sensibility (Jane Austen)\n")
with self.assertNumQueries(1, using='default'), self.assertNumQueries(1, using='other'): prefetch = Prefetch('first_time_authors', queryset=Author.objects.using('default')) books = "".join("%s (%s)\n" % (b.title, ", ".join(a.name for a in b.first_time_authors.all())) for b in B.prefetch_related(prefetch)) self.assertEqual(books, "Poems ()\n" "Sense and Sensibility ()\n")
house.main_room = self.rooms[-3] house.save()
with self.assertNumQueries(4): spooky = Pet.objects.prefetch_related('fleas_hosted__current_room__house').get(name='Spooky') with self.assertNumQueries(0): self.assertEqual('Racoon', spooky.fleas_hosted.all()[0].current_room.name)
with self.assertNumQueries(5): spooky = Pet.objects.prefetch_related('people__houses__rooms__fleas').get(name='Spooky') with self.assertNumQueries(0): self.assertEqual(3, len(spooky.people.all()[0].houses.all()[0].rooms.all()[0].fleas.all()))
with self.assertNumQueries(3): racoon = Room.objects.prefetch_related('fleas__people_visited').get(name='Racoon') with self.assertNumQueries(0): self.assertEqual('Bob', racoon.fleas.all()[0].people_visited.all()[0].name)
with self.assertNumQueries(3): redwood = House.objects.prefetch_related('rooms__fleas').get(name='Redwood') with self.assertNumQueries(0): self.assertEqual(3, len(redwood.rooms.all()[0].fleas.all()))
with self.assertNumQueries(4): redwood = House.objects.prefetch_related('rooms__fleas__pets_visited').get(name='Redwood') with self.assertNumQueries(0): self.assertEqual('Spooky', redwood.rooms.all()[0].fleas.all()[0].pets_visited.all()[0].name)
self.r = Reporter(name='John Smith') self.r.save() self.a = Article(headline="First", reporter=self.r) self.a.save() self.a2 = self.r.article_set.create(headline="Second") self.a3 = Article(headline="Third", reporter=None) self.a3.save() self.r2 = Reporter(name='Paul Jones') self.r2.save() self.a4 = self.r2.article_set.create(headline='Fourth')
r = self.a.reporter self.assertEqual(r.id, self.r.id)
self.assertQuerysetEqual(self.r.article_set.all(), ['<Article: First>', '<Article: Second>']) self.assertQuerysetEqual(self.r.article_set.filter(headline__startswith='Fir'), ['<Article: First>']) self.assertEqual(self.r.article_set.count(), 2)
a3 = Article.objects.get(pk=self.a3.pk) with self.assertRaises(AttributeError): getattr(a3.reporter, 'id') self.assertEqual(a3.reporter, None) self.assertQuerysetEqual(Article.objects.filter(reporter__isnull=True), ['<Article: Third>']) self.assertQuerysetEqual(Article.objects.filter(reporter=None), ['<Article: Third>']) self.assertQuerysetEqual(self.r.article_set.all(), ['<Article: First>', '<Article: Second>']) self.r.article_set.add(a3) self.assertQuerysetEqual( self.r.article_set.all(), ['<Article: First>', '<Article: Second>', '<Article: Third>'] ) self.r.article_set.remove(a3) self.assertQuerysetEqual(self.r.article_set.all(), ['<Article: First>', '<Article: Second>']) self.assertQuerysetEqual(Article.objects.filter(reporter__isnull=True), ['<Article: Third>'])
with self.assertRaises(Reporter.DoesNotExist): self.r.article_set.remove(self.a4) self.assertQuerysetEqual(self.r2.article_set.all(), ['<Article: Fourth>'])
self.r2.article_set.set([self.a2, self.a3]) self.assertQuerysetEqual(self.r2.article_set.all(), ['<Article: Second>', '<Article: Third>']) self.r2.article_set.set([self.a3, self.a4], clear=True) self.assertQuerysetEqual(self.r2.article_set.all(), ['<Article: Fourth>', '<Article: Third>']) self.r2.article_set.set([]) self.assertQuerysetEqual(self.r2.article_set.all(), []) self.assertQuerysetEqual( Article.objects.filter(reporter__isnull=True), ['<Article: Fourth>', '<Article: Second>', '<Article: Third>'] )
self.r2.article_set.set([self.a2, self.a3]) self.assertQuerysetEqual(self.r2.article_set.all(), ['<Article: Second>', '<Article: Third>']) self.r.article_set.clear() self.assertQuerysetEqual(self.r.article_set.all(), []) self.assertQuerysetEqual( Article.objects.filter(reporter__isnull=True), ['<Article: First>', '<Article: Fourth>'] )
self.r2.article_set.set([self.a2, self.a3])
def __init__(self, custom_optional_arg=None, model=None, query=None, using=None, hints=None): super(CustomInitQuerySet, self).__init__(model=model, query=query, using=using, hints=hints)
manager.public_method() with self.assertRaises(AttributeError): manager._private_method()
manager._optin_private_method() with self.assertRaises(AttributeError): manager.optout_public_method()
queryset = manager.values_list('first_name', flat=True).filter() self.assertEqual(list(queryset), [six.text_type("Bugs")]) self.assertEqual(queryset._filter_CustomQuerySet, True)
self.b1.favorite_books(manager='fun_people').remove(droopy, bulk=bulk) self.assertQuerysetEqual( self.b1.favorite_books(manager='boring_people').all(), [ "Droopy", ], lambda c: c.first_name, ordered=False, ) self.b1.favorite_books(manager='boring_people').remove(droopy, bulk=bulk) self.assertQuerysetEqual( self.b1.favorite_books(manager='boring_people').all(), [ ], lambda c: c.first_name, ordered=False, ) droopy.favorite_book = self.b1 droopy.save()
self.b1.favorite_books(manager='fun_people').clear(bulk=bulk) self.assertQuerysetEqual( self.b1.favorite_books(manager='boring_people').all(), [ "Droopy", ], lambda c: c.first_name, ordered=False, ) self.assertQuerysetEqual( self.b1.favorite_books(manager='fun_people').all(), [ ], lambda c: c.first_name, ordered=False, )
self.b1.favorite_things(manager='fun_people').remove(droopy, bulk=bulk) self.assertQuerysetEqual( self.b1.favorite_things(manager='boring_people').all(), [ "Droopy", ], lambda c: c.first_name, ordered=False, )
self.b1.favorite_things(manager='boring_people').remove(droopy, bulk=bulk) self.assertQuerysetEqual( self.b1.favorite_things(manager='boring_people').all(), [ ], lambda c: c.first_name, ordered=False, ) droopy.favorite_thing = self.b1 droopy.save()
self.b1.favorite_things(manager='fun_people').clear(bulk=bulk) self.assertQuerysetEqual( self.b1.favorite_things(manager='boring_people').all(), [ "Droopy", ], lambda c: c.first_name, ordered=False, ) self.assertQuerysetEqual( self.b1.favorite_things(manager='fun_people').all(), [ ], lambda c: c.first_name, ordered=False, )
self.b1.authors(manager='fun_people').remove(droopy) self.assertQuerysetEqual( self.b1.authors(manager='boring_people').all(), [ "Droopy", ], lambda c: c.first_name, ordered=False, )
self.b1.authors(manager='boring_people').remove(droopy) self.assertQuerysetEqual( self.b1.authors(manager='boring_people').all(), [ ], lambda c: c.first_name, ordered=False, ) self.b1.authors.add(droopy)
self.b1.authors(manager='fun_people').clear() self.assertQuerysetEqual( self.b1.authors(manager='boring_people').all(), [ "Droopy", ], lambda c: c.first_name, ordered=False, ) self.assertQuerysetEqual( self.b1.authors(manager='fun_people').all(), [ ], lambda c: c.first_name, ordered=False, )
Car.cars.create(name="Corvette", mileage=21, top_speed=180) Car.cars.create(name="Neon", mileage=31, top_speed=100)
self.assertQuerysetEqual( Car.fast_cars.all(), [ "Corvette", ], lambda c: c.name ) self.assertQuerysetEqual( FastCarAsDefault.cars.order_by("name"), [ "Corvette", "Neon", ], lambda c: c.name ) self.assertQuerysetEqual( FastCarAsDefault._default_manager.all(), [ "Corvette", ], lambda c: c.name ) self.assertQuerysetEqual( FastCarAsBase.cars.order_by("name"), [ "Corvette", "Neon", ], lambda c: c.name ) self.assertQuerysetEqual( FastCarAsBase._base_manager.all(), [ "Corvette", ], lambda c: c.name )
self.assertEqual(RestrictedModel.plain_manager.count(), 1)
self.assertEqual(len(RestrictedModel.plain_manager.all()), 0)
obj = RelatedModel.objects.create(name="xyzzy") OneToOneRestrictedModel.objects.create(name="foo", is_public=False, related=obj) obj = RelatedModel.objects.get(name="xyzzy") obj.delete() self.assertEqual(len(OneToOneRestrictedModel.plain_manager.all()), 0)
self.session.delete()
self.accessed = False self.modified = False
try: session = self.backend('1') try: session.save() except AttributeError: self.fail( "The session object did not save properly. " "Middleware may be saving cache items without namespaces." ) self.assertNotEqual(session.session_key, '1') self.assertEqual(session.get('cat'), None) session.delete() finally: session.delete('1')
def test_default_expiry(self): self.assertEqual(self.session.get_expiry_age(), settings.SESSION_COOKIE_AGE)
self.session.set_expiry(0) self.assertEqual(self.session.get_expiry_age(), settings.SESSION_COOKIE_AGE)
original_now = timezone.now try: timezone.now = lambda: modification self.session.set_expiry(timedelta(seconds=10)) finally: timezone.now = original_now
with override_settings(SESSION_EXPIRE_AT_BROWSER_CLOSE=False): self.session.set_expiry(10) self.assertFalse(self.session.get_expire_at_browser_close())
data = {'a test key': 'a test value'} encoded = self.session.encode(data) self.assertEqual(self.session.decode(encoded), data)
self.assertEqual(len(calls), 1) self.assertIn('corrupted', calls[0])
with override_settings(SESSION_SERIALIZER='django.contrib.sessions.serializers.PickleSerializer'):
old_session_key = None new_session_key = None try: self.session['foo'] = 'bar' self.session.set_expiry(-timedelta(seconds=10)) self.session.save() old_session_key = self.session.session_key new_session = self.backend(self.session.session_key) new_session_key = new_session.session_key self.assertNotIn('foo', new_session) finally: self.session.delete(old_session_key) self.session.delete(new_session_key)
self.assertNotEqual(session.session_key, 'someunknownkey')
s1 = self.backend() s1['test_data'] = 'value1' s1.save(must_create=True)
s2 = self.backend(s1.session_key) s2.delete()
s1['test_data'] = 'value2' with self.assertRaises(UpdateError): s1.save()
self.session['y'] = 1 self.session.save()
self.model.objects.save(s.session_key, {'y': 2}, s.expire_date) del self.session._session_cache self.assertEqual(self.session['y'], 2)
self.session['foo'] = 'bar' self.session.set_expiry(3600) self.session.save()
other_session = self.backend() other_session['foo'] = 'bar' other_session.set_expiry(-3600) other_session.save()
self.assertEqual(2, self.model.objects.count()) with override_settings(SESSION_ENGINE=self.session_engine): management.call_command('clearsessions') self.assertEqual(1, self.model.objects.count())
self.session['_auth_user_id'] = 42 self.session.save()
s = self.model.objects.get(session_key=self.session.session_key) self.assertEqual(s.account_id, 42)
self.session.pop('_auth_user_id') self.session.save()
s = self.model.objects.get(session_key=self.session.session_key) self.assertEqual(s.account_id, None)
@ignore_warnings(module="django.core.cache.backends.base") def test_load_overlong_key(self): self.session._session_key = (string.ascii_letters + string.digits) * 20 self.assertEqual(self.session.load(), {})
with self.assertRaises(InvalidCacheBackendError): self.backend()
class FileSessionTests(SessionTestsMixin, unittest.TestCase):
self.original_session_file_path = settings.SESSION_FILE_PATH self.temp_session_store = settings.SESSION_FILE_PATH = tempfile.mkdtemp() if hasattr(self.backend, '_storage_path'): del self.backend._storage_path super(FileSessionTests, self).setUp()
with self.assertRaises(ImproperlyConfigured): self.backend()
with self.assertRaises(InvalidSessionKey): self.backend()._key_to_file("a\\b\\c")
with self.assertRaises(InvalidSessionKey): self.backend()._key_to_file("a/b/c")
self.session['foo'] = 'bar' self.session.set_expiry(3600) self.session.save()
other_session = self.backend() other_session['foo'] = 'bar' other_session.set_expiry(-3600) other_session.save()
other_session2 = self.backend() other_session2['foo'] = 'bar' other_session2.save()
self.assertEqual(3, count_sessions()) management.call_command('clearsessions') self.assertEqual(1, count_sessions())
@ignore_warnings(module="django.core.cache.backends.base") def test_load_overlong_key(self): self.session._session_key = (string.ascii_letters + string.digits) * 20 self.assertEqual(self.session.load(), {})
self.session = self.backend()
middleware.process_request(request) request.session['hello'] = 'world'
response = middleware.process_response(request, response) self.assertTrue( response.cookies[settings.SESSION_COOKIE_NAME]['secure'])
middleware.process_request(request) request.session['hello'] = 'world'
response = middleware.process_response(request, response) self.assertTrue( response.cookies[settings.SESSION_COOKIE_NAME]['httponly']) self.assertIn( http_cookies.Morsel._reserved['httponly'], str(response.cookies[settings.SESSION_COOKIE_NAME]) )
middleware.process_request(request) request.session['hello'] = 'world'
response = middleware.process_response(request, response) self.assertFalse(response.cookies[settings.SESSION_COOKIE_NAME]['httponly'])
middleware.process_request(request) request.session['hello'] = 'world'
response = middleware.process_response(request, response)
self.assertNotIn('hello', request.session.load())
response = middleware.process_response(request, response)
self.assertEqual(response.status_code, 302) self.assertEqual(response['Location'], path)
request.COOKIES[settings.SESSION_COOKIE_NAME] = 'abc'
middleware.process_request(request) request.session.flush()
response = middleware.process_response(request, response)
self.assertEqual( 'Set-Cookie: {}={}; expires=Thu, 01-Jan-1970 00:00:00 GMT; ' 'Max-Age=0; Path=/'.format( settings.SESSION_COOKIE_NAME, '""' if sys.version_info >= (3, 5) else '', ), str(response.cookies[settings.SESSION_COOKIE_NAME]) )
request.COOKIES[settings.SESSION_COOKIE_NAME] = 'abc'
middleware.process_request(request) request.session.flush()
response = middleware.process_response(request, response)
self.assertEqual( 'Set-Cookie: {}={}; Domain=.example.local; expires=Thu, ' '01-Jan-1970 00:00:00 GMT; Max-Age=0; Path=/'.format( settings.SESSION_COOKIE_NAME, '""' if sys.version_info >= (3, 5) else '', ), str(response.cookies[settings.SESSION_COOKIE_NAME]) )
middleware.process_request(request) request.session.flush()
response = middleware.process_response(request, response)
self.assertEqual(response.cookies, {}) self.assertEqual(response['Vary'], 'Cookie')
middleware.process_request(request) request.session['foo'] = 'bar' response = middleware.process_response(request, response) self.assertEqual(tuple(request.session.items()), (('foo', 'bar'),)) self.assertIn( 'Set-Cookie: sessionid=%s' % request.session.session_key, str(response.cookies) ) self.assertEqual(response['Vary'], 'Cookie')
del request.session['foo'] response = HttpResponse('Session test') response = middleware.process_response(request, response) self.assertEqual(dict(request.session.values()), {}) session = Session.objects.get(session_key=request.session.session_key) self.assertEqual(session.get_decoded(), {}) self.assertGreater(len(request.session.session_key), 8) self.assertIn( 'Set-Cookie: sessionid=%s' % request.session.session_key, str(response.cookies) ) self.assertEqual(response['Vary'], 'Cookie')
class CookieSessionTests(SessionTestsMixin, unittest.TestCase):
super(CookieSessionTests, self).test_actual_expiry()
self.assertEqual(self.session.serializer, JSONSerializer) self.session.save()
for method in SimpleView.http_method_names: kwargs = dict(((method, "value"),)) with self.assertRaises(TypeError): SimpleView.as_view(**kwargs)
CustomizableView.as_view(parameter="value") with self.assertRaises(TypeError): CustomizableView.as_view(foobar="value")
response2 = self.client.get('/template/cached/bar/') self.assertEqual(response2.status_code, 200)
response = RedirectView.as_view(url='/bar/')(self.rf.request(PATH_INFO='/foo/')) self.assertEqual(response.status_code, 302)
self.assertIn('test_name', context) self.assertEqual(context['kwarg_test'], 'kwarg_value') self.assertEqual(context['custom_key'], 'custom_value')
context = test_view.get_context_data(test_name='test_value') self.assertEqual(context['test_name'], 'test_value')
test_view = views.CustomSingleObjectView() test_view.context_object_name = 'pony' context = test_view.get_context_data() self.assertEqual(context['pony'], test_view.object)
test_view = views.CustomSingleObjectView() context = test_view.get_context_data() self.assertEqual(context['object'], test_view.object)
context = test_view.get_context_data() self.assertEqual(context['object_list'], test_view.queryset)
context = test_view.get_context_data(object_list=queryset) self.assertEqual(context['object_list'], queryset)
from __future__ import unicode_literals
url(r'^template/no_template/$', TemplateView.as_view()), url(r'^template/login_required/$', login_required(TemplateView.as_view())), url(r'^template/simple/(?P<foo>\w+)/$', TemplateView.as_view(template_name='generic_views/about.html')), url(r'^template/custom/(?P<foo>\w+)/$', views.CustomTemplateView.as_view(template_name='generic_views/about.html')), url(r'^template/content_type/$', TemplateView.as_view(template_name='generic_views/robots.txt', content_type='text/plain')),
url(r'^detail/obj/$', views.ObjectDetail.as_view()), url(r'^detail/artist/(?P<pk>[0-9]+)/$', views.ArtistDetail.as_view(), name="artist_detail"), url(r'^detail/author/(?P<pk>[0-9]+)/$', views.AuthorDetail.as_view(), name="author_detail"), url(r'^detail/author/bycustompk/(?P<foo>[0-9]+)/$', views.AuthorDetail.as_view(pk_url_kwarg='foo')), url(r'^detail/author/byslug/(?P<slug>[\w-]+)/$', views.AuthorDetail.as_view()), url(r'^detail/author/bycustomslug/(?P<foo>[\w-]+)/$', views.AuthorDetail.as_view(slug_url_kwarg='foo')), url(r'^detail/author/bypkignoreslug/(?P<pk>[0-9]+)-(?P<slug>[\w-]+)/$', views.AuthorDetail.as_view()), url(r'^detail/author/bypkandslug/(?P<pk>[0-9]+)-(?P<slug>[\w-]+)/$', views.AuthorDetail.as_view(query_pk_and_slug=True)), url(r'^detail/author/(?P<pk>[0-9]+)/template_name_suffix/$', views.AuthorDetail.as_view(template_name_suffix='_view')), url(r'^detail/author/(?P<pk>[0-9]+)/template_name/$', views.AuthorDetail.as_view(template_name='generic_views/about.html')), url(r'^detail/author/(?P<pk>[0-9]+)/context_object_name/$', views.AuthorDetail.as_view(context_object_name='thingy')), url(r'^detail/author/(?P<pk>[0-9]+)/custom_detail/$', views.AuthorCustomDetail.as_view()), url(r'^detail/author/(?P<pk>[0-9]+)/dupe_context_object_name/$', views.AuthorDetail.as_view(context_object_name='object')), url(r'^detail/page/(?P<pk>[0-9]+)/field/$', views.PageDetail.as_view()), url(r'^detail/author/invalid/url/$', views.AuthorDetail.as_view()), url(r'^detail/author/invalid/qs/$', views.AuthorDetail.as_view(queryset=None)), url(r'^detail/nonmodel/1/$', views.NonModelDetail.as_view()), url(r'^detail/doesnotexist/(?P<pk>[0-9]+)/$', views.ObjectDoesNotExistDetail.as_view()), url(r'^contact/$', views.ContactView.as_view()), url(r'^late-validation/$', views.LateValidationView.as_view()),
url(r'^edit/artists/create/$', views.ArtistCreate.as_view()), url(r'^edit/artists/(?P<pk>[0-9]+)/update/$', views.ArtistUpdate.as_view()),
url(r'^dates/books/$', views.BookArchive.as_view()), url(r'^dates/books/context_object_name/$', views.BookArchive.as_view(context_object_name='thingies')), url(r'^dates/books/allow_empty/$', views.BookArchive.as_view(allow_empty=True)), url(r'^dates/books/template_name/$', views.BookArchive.as_view(template_name='generic_views/list.html')), url(r'^dates/books/template_name_suffix/$', views.BookArchive.as_view(template_name_suffix='_detail')), url(r'^dates/books/invalid/$', views.BookArchive.as_view(queryset=None)), url(r'^dates/books/paginated/$', views.BookArchive.as_view(paginate_by=10)), url(r'^dates/books/reverse/$', views.BookArchive.as_view(queryset=models.Book.objects.order_by('pubdate'))), url(r'^dates/books/by_month/$', views.BookArchive.as_view(date_list_period='month')), url(r'^dates/booksignings/$', views.BookSigningArchive.as_view()), url(r'^dates/books/sortedbyname/$', views.BookArchive.as_view(ordering='name')), url(r'^dates/books/sortedbynamedec/$', views.BookArchive.as_view(ordering='-name')),
url(r'^list/dict/$', views.DictList.as_view()), url(r'^list/dict/paginated/$', views.DictList.as_view(paginate_by=1)), url(r'^list/artists/$', views.ArtistList.as_view(), name="artists_list"), url(r'^list/authors/$', views.AuthorList.as_view(), name="authors_list"), url(r'^list/authors/paginated/$', views.AuthorList.as_view(paginate_by=30)), url(r'^list/authors/paginated/(?P<page>[0-9]+)/$', views.AuthorList.as_view(paginate_by=30)), url(r'^list/authors/paginated-orphaned/$', views.AuthorList.as_view(paginate_by=30, paginate_orphans=2)), url(r'^list/authors/notempty/$', views.AuthorList.as_view(allow_empty=False)), url(r'^list/authors/notempty/paginated/$', views.AuthorList.as_view(allow_empty=False, paginate_by=2)), url(r'^list/authors/template_name/$', views.AuthorList.as_view(template_name='generic_views/list.html')), url(r'^list/authors/template_name_suffix/$', views.AuthorList.as_view(template_name_suffix='_objects')), url(r'^list/authors/context_object_name/$', views.AuthorList.as_view(context_object_name='author_list')), url(r'^list/authors/dupe_context_object_name/$', views.AuthorList.as_view(context_object_name='object_list')), url(r'^list/authors/invalid/$', views.AuthorList.as_view(queryset=None)), url(r'^list/authors/paginated/custom_class/$', views.AuthorList.as_view(paginate_by=5, paginator_class=views.CustomPaginator)), url(r'^list/authors/paginated/custom_page_kwarg/$', views.AuthorList.as_view(paginate_by=30, page_kwarg='pagina')), url(r'^list/authors/paginated/custom_constructor/$', views.AuthorListCustomPaginator.as_view()), url(r'^list/books/sorted/$', views.BookList.as_view(ordering='name')), url(r'^list/books/sortedbypagesandnamedec/$', views.BookList.as_view(ordering=('pages', '-name'))),
url(r'^dates/books/(?P<year>[0-9]{4})/$', views.BookYearArchive.as_view()), url(r'^dates/books/(?P<year>[0-9]{4})/make_object_list/$', views.BookYearArchive.as_view(make_object_list=True)), url(r'^dates/books/(?P<year>[0-9]{4})/allow_empty/$', views.BookYearArchive.as_view(allow_empty=True)), url(r'^dates/books/(?P<year>[0-9]{4})/allow_future/$', views.BookYearArchive.as_view(allow_future=True)), url(r'^dates/books/(?P<year>[0-9]{4})/paginated/$', views.BookYearArchive.as_view(make_object_list=True, paginate_by=30)), url(r'^dates/books/(?P<year>\d{4})/sortedbyname/$', views.BookYearArchive.as_view(make_object_list=True, ordering='name')), url(r'^dates/books/(?P<year>\d{4})/sortedbypageandnamedec/$', views.BookYearArchive.as_view(make_object_list=True, ordering=('pages', '-name'))), url(r'^dates/books/no_year/$', views.BookYearArchive.as_view()), url(r'^dates/books/(?P<year>[0-9]{4})/reverse/$', views.BookYearArchive.as_view(queryset=models.Book.objects.order_by('pubdate'))), url(r'^dates/booksignings/(?P<year>[0-9]{4})/$', views.BookSigningYearArchive.as_view()),
url(r'^dates/books/(?P<year>[0-9]{4})/(?P<month>[a-z]{3})/$', views.BookMonthArchive.as_view()), url(r'^dates/books/(?P<year>[0-9]{4})/(?P<month>[0-9]{1,2})/$', views.BookMonthArchive.as_view(month_format='%m')), url(r'^dates/books/(?P<year>[0-9]{4})/(?P<month>[a-z]{3})/allow_empty/$', views.BookMonthArchive.as_view(allow_empty=True)), url(r'^dates/books/(?P<year>[0-9]{4})/(?P<month>[a-z]{3})/allow_future/$', views.BookMonthArchive.as_view(allow_future=True)), url(r'^dates/books/(?P<year>[0-9]{4})/(?P<month>[a-z]{3})/paginated/$', views.BookMonthArchive.as_view(paginate_by=30)), url(r'^dates/books/(?P<year>[0-9]{4})/no_month/$', views.BookMonthArchive.as_view()), url(r'^dates/booksignings/(?P<year>[0-9]{4})/(?P<month>[a-z]{3})/$', views.BookSigningMonthArchive.as_view()),
url(r'^dates/books/(?P<year>[0-9]{4})/week/(?P<week>[0-9]{1,2})/$', views.BookWeekArchive.as_view()), url(r'^dates/books/(?P<year>[0-9]{4})/week/(?P<week>[0-9]{1,2})/allow_empty/$', views.BookWeekArchive.as_view(allow_empty=True)), url(r'^dates/books/(?P<year>[0-9]{4})/week/(?P<week>[0-9]{1,2})/allow_future/$', views.BookWeekArchive.as_view(allow_future=True)), url(r'^dates/books/(?P<year>[0-9]{4})/week/(?P<week>[0-9]{1,2})/paginated/$', views.BookWeekArchive.as_view(paginate_by=30)), url(r'^dates/books/(?P<year>[0-9]{4})/week/no_week/$', views.BookWeekArchive.as_view()), url(r'^dates/books/(?P<year>[0-9]{4})/week/(?P<week>[0-9]{1,2})/monday/$', views.BookWeekArchive.as_view(week_format='%W')), url(r'^dates/booksignings/(?P<year>[0-9]{4})/week/(?P<week>[0-9]{1,2})/$', views.BookSigningWeekArchive.as_view()),
url(r'^dates/books/(?P<year>[0-9]{4})/(?P<month>[a-z]{3})/(?P<day>[0-9]{1,2})/$', views.BookDayArchive.as_view()), url(r'^dates/books/(?P<year>[0-9]{4})/(?P<month>[0-9]{1,2})/(?P<day>[0-9]{1,2})/$', views.BookDayArchive.as_view(month_format='%m')), url(r'^dates/books/(?P<year>[0-9]{4})/(?P<month>[a-z]{3})/(?P<day>[0-9]{1,2})/allow_empty/$', views.BookDayArchive.as_view(allow_empty=True)), url(r'^dates/books/(?P<year>[0-9]{4})/(?P<month>[a-z]{3})/(?P<day>[0-9]{1,2})/allow_future/$', views.BookDayArchive.as_view(allow_future=True)), url(r'^dates/books/(?P<year>[0-9]{4})/(?P<month>[a-z]{3})/(?P<day>[0-9]{1,2})/allow_empty_and_future/$', views.BookDayArchive.as_view(allow_empty=True, allow_future=True)), url(r'^dates/books/(?P<year>[0-9]{4})/(?P<month>[a-z]{3})/(?P<day>[0-9]{1,2})/paginated/$', views.BookDayArchive.as_view(paginate_by=True)), url(r'^dates/books/(?P<year>[0-9]{4})/(?P<month>[a-z]{3})/no_day/$', views.BookDayArchive.as_view()), url(r'^dates/booksignings/(?P<year>[0-9]{4})/(?P<month>[a-z]{3})/(?P<day>[0-9]{1,2})/$', views.BookSigningDayArchive.as_view()),
url(r'^dates/books/today/$', views.BookTodayArchive.as_view()), url(r'^dates/books/today/allow_empty/$', views.BookTodayArchive.as_view(allow_empty=True)), url(r'^dates/booksignings/today/$', views.BookSigningTodayArchive.as_view()),
url(r'^dates/books/(?P<year>[0-9]{4})/(?P<month>[a-z]{3})/(?P<day>[0-9]{1,2})/(?P<pk>[0-9]+)/$', views.BookDetail.as_view()), url(r'^dates/books/(?P<year>[0-9]{4})/(?P<month>[0-9]{1,2})/(?P<day>[0-9]{1,2})/(?P<pk>[0-9]+)/$', views.BookDetail.as_view(month_format='%m')), url(r'^dates/books/(?P<year>[0-9]{4})/(?P<month>[a-z]{3})/(?P<day>[0-9]{1,2})/(?P<pk>[0-9]+)/allow_future/$', views.BookDetail.as_view(allow_future=True)), url(r'^dates/books/(?P<year>[0-9]{4})/(?P<month>[a-z]{3})/(?P<day>[0-9]{1,2})/nopk/$', views.BookDetail.as_view()),
url(r'^accounts/login/$', auth_views.login)
author = self.get_object() context = {'custom_' + self.get_context_object_name(author): author} return self.render_to_response(context)
self.object = None
from __future__ import unicode_literals
res = self.client.get('/list/authors/paginated/') self.assertEqual(res.status_code, 200) self.assertTemplateUsed(res, 'generic_views/author_list.html') self.assertEqual(list(res.context['object_list']), list(Author.objects.all())) self.assertIs(res.context['author_list'], res.context['object_list']) self.assertEqual(res.context['page_obj'].number, 1) self.assertEqual(res.context['paginator'].num_pages, 1) self.assertFalse(res.context['is_paginated'])
self.assertEqual(len(res.context['object_list']), 7)
self.assertEqual(len(res.context['object_list']), 7)
self._make_authors(3) with self.assertNumQueries(1): self.client.get('/list/authors/notempty/') with self.assertNumQueries(3): self.client.get('/list/authors/notempty/paginated/')
self._make_authors(1) res = self.client.get('/list/authors/paginated/2/') self.assertEqual(res.status_code, 404) self.assertEqual(force_str(res.context.get('reason')), "Invalid page (2): That page contains no results")
from __future__ import unicode_literals
_make_books(20, base_date=datetime.date.today()) with self.assertNumQueries(2): self.client.get('/dates/books/') with self.assertNumQueries(4): self.client.get('/dates/books/paginated/')
with self.assertNumQueries(2): self.client.get('/dates/books/reverse/')
self.assertEqual(res.context['next_year'], None) self.assertEqual(res.context['previous_year'], datetime.date(2006, 1, 1))
self.assertEqual(res.context['next_year'], datetime.date(2000, 1, 1)) self.assertEqual(res.context['previous_year'], datetime.date(1998, 1, 1))
year = datetime.date.today().year + 1 Book.objects.create(name="The New New Testement", pages=600, pubdate=datetime.date(year, 1, 1)) res = self.client.get('/dates/books/%s/' % year) self.assertEqual(res.status_code, 404)
Book.objects.create(name="Zebras for Dummies", pages=600, pubdate=datetime.date(2006, 9, 1)) res = self.client.get('/dates/books/2006/sortedbyname/') self.assertEqual(res.status_code, 200) self.assertEqual(list(res.context['date_list']), [datetime.date(2006, 5, 1), datetime.date(2006, 9, 1)]) self.assertEqual( list(res.context['book_list']), list(Book.objects.filter(pubdate__year=2006).order_by('name')) ) self.assertEqual( list(res.context['object_list']), list(Book.objects.filter(pubdate__year=2006).order_by('name')) ) self.assertTemplateUsed(res, 'generic_views/book_archive_year.html')
with self.assertNumQueries(4): self.client.get('/dates/books/2008/reverse/')
self.assertEqual(res.context['next_month'], None) self.assertEqual(res.context['previous_month'], datetime.date(2006, 5, 1))
res = self.client.get('/dates/books/2000/jan/') self.assertEqual(res.status_code, 404)
res = self.client.get('/dates/books/2000/jan/allow_empty/') self.assertEqual(res.status_code, 200) self.assertEqual(list(res.context['date_list']), []) self.assertEqual(list(res.context['book_list']), []) self.assertEqual(res.context['month'], datetime.date(2000, 1, 1))
self.assertEqual(res.context['next_month'], datetime.date(2000, 2, 1)) self.assertEqual(res.context['previous_month'], datetime.date(1999, 12, 1))
url = datetime.date.today().strftime('/dates/books/%Y/%b/allow_empty/').lower() res = self.client.get(url) self.assertEqual(res.status_code, 200) self.assertEqual(res.context['next_month'], None)
res = self.client.get('/dates/books/%s/' % urlbit) self.assertEqual(res.status_code, 404)
res = self.client.get('/dates/books/%s/allow_future/' % urlbit) self.assertEqual(res.status_code, 200) self.assertEqual(res.context['date_list'][0], b.pubdate) self.assertEqual(list(res.context['book_list']), [b]) self.assertEqual(res.context['month'], future)
self.assertEqual(res.context['next_month'], None) self.assertEqual(res.context['previous_month'], datetime.date(2008, 10, 1))
res = self.client.get('/dates/books/2008/oct/allow_future/') self.assertEqual(res.status_code, 200) self.assertEqual(res.context['next_month'], future) self.assertEqual(res.context['previous_month'], datetime.date(2006, 5, 1))
res = self.client.get('/dates/books/2010/nov/') self.assertEqual(res.status_code, 200) self.assertEqual(res.context['previous_month'], datetime.date(2010, 10, 1)) res = self.client.get('/dates/books/2010/oct/') self.assertEqual(res.status_code, 200) self.assertEqual(res.context['previous_month'], datetime.date(2010, 9, 1))
self.assertEqual(res.context['next_week'], None) self.assertEqual(res.context['previous_week'], datetime.date(2006, 4, 30))
res = self.client.get('/dates/books/2008/week/12/') self.assertEqual(res.status_code, 404)
res = self.client.get('/dates/books/2008/week/12/allow_empty/') self.assertEqual(res.status_code, 200) self.assertEqual(list(res.context['book_list']), []) self.assertEqual(res.context['week'], datetime.date(2008, 3, 23))
self.assertEqual(res.context['next_week'], datetime.date(2008, 3, 30)) self.assertEqual(res.context['previous_week'], datetime.date(2008, 3, 16))
url = datetime.date.today().strftime('/dates/books/%Y/week/%U/allow_empty/').lower() res = self.client.get(url) self.assertEqual(res.status_code, 200) self.assertEqual(res.context['next_week'], None)
future = datetime.date(datetime.date.today().year + 1, 1, 7) future_sunday = future - datetime.timedelta(days=(future.weekday() + 1) % 7) b = Book.objects.create(name="The New New Testement", pages=600, pubdate=future)
self.assertEqual(res.context['next_week'], None) self.assertEqual(res.context['previous_week'], datetime.date(2008, 9, 28))
res = self.client.get('/dates/books/2008/week/39/allow_future/') self.assertEqual(res.status_code, 200) self.assertEqual(res.context['next_week'], future_sunday) self.assertEqual(res.context['previous_week'], datetime.date(2006, 4, 30))
res = self.client.get('/dates/books/2008/week/39/') self.assertEqual(res.status_code, 200) self.assertEqual(res.context['week'], datetime.date(2008, 9, 28))
self.assertEqual(res.context['next_day'], None) self.assertEqual(res.context['previous_day'], datetime.date(2006, 5, 1))
res = self.client.get('/dates/books/2000/jan/1/') self.assertEqual(res.status_code, 404)
res = self.client.get('/dates/books/2000/jan/1/allow_empty/') self.assertEqual(res.status_code, 200) self.assertEqual(list(res.context['book_list']), []) self.assertEqual(res.context['day'], datetime.date(2000, 1, 1))
self.assertEqual(res.context['next_day'], datetime.date(2000, 1, 2)) self.assertEqual(res.context['previous_day'], datetime.date(1999, 12, 31))
url = datetime.date.today().strftime('/dates/books/%Y/%b/%d/allow_empty/').lower() res = self.client.get(url) self.assertEqual(res.status_code, 200) self.assertEqual(res.context['next_day'], None)
res = self.client.get('/dates/books/%s/' % urlbit) self.assertEqual(res.status_code, 404)
res = self.client.get('/dates/books/%s/allow_future/' % urlbit) self.assertEqual(res.status_code, 200) self.assertEqual(list(res.context['book_list']), [b]) self.assertEqual(res.context['day'], future)
self.assertEqual(res.context['next_day'], None) self.assertEqual(res.context['previous_day'], datetime.date(2008, 10, 1))
res = self.client.get('/dates/books/2008/oct/01/allow_future/') self.assertEqual(res.status_code, 200) self.assertEqual(res.context['next_day'], future) self.assertEqual(res.context['previous_day'], datetime.date(2006, 5, 1))
today = datetime.date.today() yesterday = today - datetime.timedelta(days=1) res = self.client.get('/dates/books/%s/allow_empty_and_future/' % yesterday.strftime('%Y/%b/%d').lower()) self.assertEqual(res.context['next_day'], today)
bs.event_date = datetime.datetime(2008, 4, 1, 22, 0, tzinfo=timezone.utc) bs.save() res = self.client.get('/dates/booksignings/2008/apr/2/') self.assertEqual(res.status_code, 200) bs.event_date = datetime.datetime(2008, 4, 2, 22, 0, tzinfo=timezone.utc) bs.save() res = self.client.get('/dates/booksignings/2008/apr/2/') self.assertEqual(res.status_code, 404)
bs.event_date = datetime.datetime(2008, 4, 1, 22, 0, tzinfo=timezone.utc) bs.save() res = self.client.get('/dates/booksignings/2008/apr/2/%d/' % bs.pk) self.assertEqual(res.status_code, 200) bs.event_date = datetime.datetime(2008, 4, 2, 22, 0, tzinfo=timezone.utc) bs.save() res = self.client.get('/dates/booksignings/2008/apr/2/%d/' % bs.pk) self.assertEqual(res.status_code, 404)
res = self.client.post( '/edit/authors/create/interpolate_redirect_nonascii/', {'name': 'John Doe', 'slug': 'john-doe'} ) self.assertEqual(res.status_code, 302) pk = Author.objects.get(name='John Doe').pk self.assertRedirects(res, '/%C3%A9dit/author/{}/update/'.format(pk))
res = self.client.post( '/edit/author/%d/update/' % a.pk, {'name': 'Randall Munroe (xkcd)', 'slug': 'randall-munroe'} ) self.assertEqual(res.status_code, 302) self.assertRedirects(res, '/list/authors/') self.assertQuerysetEqual(Author.objects.all(), ['<Author: Randall Munroe (xkcd)>'])
res = self.client.post( '/edit/author/%d/update/interpolate_redirect_nonascii/' % a.pk, {'name': 'John Doe', 'slug': 'john-doe'} ) self.assertEqual(res.status_code, 302) pk = Author.objects.get(name='John Doe').pk self.assertRedirects(res, '/%C3%A9dit/author/{}/update/'.format(pk))
with self.assertRaises(ImproperlyConfigured): self.client.post( '/edit/author/%d/update/naive/' % a.pk, {'name': 'Randall Munroe (author of xkcd)', 'slug': 'randall-munroe'} )
res = self.client.post('/edit/author/update/', {'name': 'Randall Munroe (xkcd)', 'slug': 'randall-munroe'}) self.assertEqual(res.status_code, 302) self.assertRedirects(res, '/list/authors/') self.assertQuerysetEqual(Author.objects.all(), ['<Author: Randall Munroe (xkcd)>'])
res = self.client.post('/edit/author/%d/delete/' % a.pk) self.assertEqual(res.status_code, 302) self.assertRedirects(res, '/list/authors/') self.assertQuerysetEqual(Author.objects.all(), [])
a = Author.objects.create(**{'name': 'Randall Munroe', 'slug': 'randall-munroe'}) res = self.client.delete('/edit/author/%d/delete/' % a.pk) self.assertEqual(res.status_code, 302) self.assertRedirects(res, '/list/authors/') self.assertQuerysetEqual(Author.objects.all(), [])
a = Author.objects.create(**{'name': 'Randall Munroe', 'slug': 'randall-munroe'}) res = self.client.post('/edit/author/{}/delete/interpolate_redirect_nonascii/'.format(a.pk)) self.assertEqual(res.status_code, 302) self.assertRedirects(res, '/%C3%A9dit/authors/create/?deleted={}'.format(a.pk))
with self.assertRaises(ImproperlyConfigured): self.client.post('/edit/author/%d/delete/naive/' % a.pk)
from __future__ import unicode_literals
cls.site1 = Site(pk=1, domain='example.com', name='example.com') cls.site1.save() cls.fp1 = FlatPage.objects.create( url='/flatpage/', title='A Flatpage', content="Isn't it flat!", enable_comments=False, template_name='', registration_required=False ) cls.fp2 = FlatPage.objects.create( url='/location/flatpage/', title='A Nested Flatpage', content="Isn't it flat and deep!", enable_comments=False, template_name='', registration_required=False ) cls.fp3 = FlatPage.objects.create( url='/sekrit/', title='Sekrit Flatpage', content="Isn't it sekrit!", enable_comments=False, template_name='', registration_required=True ) cls.fp4 = FlatPage.objects.create( url='/location/sekrit/', title='Sekrit Nested Flatpage', content="Isn't it sekrit and deep!", enable_comments=False, template_name='', registration_required=True ) cls.fp1.sites.add(cls.site1) cls.fp2.sites.add(cls.site1) cls.fp3.sites.add(cls.site1) cls.fp4.sites.add(cls.site1)
urlpatterns = [ url(r'^flatpages/sitemap\.xml$', views.sitemap, {'sitemaps': {'flatpages': FlatPageSitemap}}, name='django.contrib.sitemaps.views.sitemap'),
cls.site1 = Site(pk=1, domain='example.com', name='example.com') cls.site1.save()
Site._meta._expire_cache() self.form_data = { 'title': "A test page", 'content': "This is a test", 'sites': [settings.SITE_ID], }
cls.site1 = Site(pk=1, domain='example.com', name='example.com') cls.site1.save() cls.fp1 = FlatPage.objects.create( url='/flatpage/', title='A Flatpage', content="Isn't it flat!", enable_comments=False, template_name='', registration_required=False ) cls.fp2 = FlatPage.objects.create( url='/location/flatpage/', title='A Nested Flatpage', content="Isn't it flat and deep!", enable_comments=False, template_name='', registration_required=False ) cls.fp3 = FlatPage.objects.create( url='/sekrit/', title='Sekrit Flatpage', content="Isn't it sekrit!", enable_comments=False, template_name='', registration_required=True ) cls.fp4 = FlatPage.objects.create( url='/location/sekrit/', title='Sekrit Nested Flatpage', content="Isn't it sekrit and deep!", enable_comments=False, template_name='', registration_required=True ) cls.fp1.sites.add(cls.site1) cls.fp2.sites.add(cls.site1) cls.fp3.sites.add(cls.site1) cls.fp4.sites.add(cls.site1)
], ROOT_URLCONF='flatpages_tests.urls', TEMPLATES=FLATPAGES_TEMPLATES, SITE_ID=1,
], ROOT_URLCONF='flatpages_tests.urls', TEMPLATES=FLATPAGES_TEMPLATES, SITE_ID=1,
cls.site1 = Site(pk=1, domain='example.com', name='example.com') cls.site1.save() cls.fp1 = FlatPage.objects.create( url='/flatpage/', title='A Flatpage', content="Isn't it flat!", enable_comments=False, template_name='', registration_required=False ) cls.fp2 = FlatPage.objects.create( url='/location/flatpage/', title='A Nested Flatpage', content="Isn't it flat and deep!", enable_comments=False, template_name='', registration_required=False ) cls.fp3 = FlatPage.objects.create( url='/sekrit/', title='Sekrit Flatpage', content="Isn't it sekrit!", enable_comments=False, template_name='', registration_required=True ) cls.fp4 = FlatPage.objects.create( url='/location/sekrit/', title='Sekrit Nested Flatpage', content="Isn't it sekrit and deep!", enable_comments=False, template_name='', registration_required=True ) cls.fp1.sites.add(cls.site1) cls.fp2.sites.add(cls.site1) cls.fp3.sites.add(cls.site1) cls.fp4.sites.add(cls.site1)
cls.site1 = Site(pk=1, domain='example.com', name='example.com') cls.site1.save() cls.fp1 = FlatPage.objects.create( url='/flatpage/', title='A Flatpage', content="Isn't it flat!", enable_comments=False, template_name='', registration_required=False ) cls.fp2 = FlatPage.objects.create( url='/location/flatpage/', title='A Nested Flatpage', content="Isn't it flat and deep!", enable_comments=False, template_name='', registration_required=False ) cls.fp3 = FlatPage.objects.create( url='/sekrit/', title='Sekrit Flatpage', content="Isn't it sekrit!", enable_comments=False, template_name='', registration_required=True ) cls.fp4 = FlatPage.objects.create( url='/location/sekrit/', title='Sekrit Nested Flatpage', content="Isn't it sekrit and deep!", enable_comments=False, template_name='', registration_required=True ) cls.fp1.sites.add(cls.site1) cls.fp2.sites.add(cls.site1) cls.fp3.sites.add(cls.site1) cls.fp4.sites.add(cls.site1)
Site.objects.clear_cache()
raise ImportError("Oops")
@python_2_unicode_compatible class Person(models.Model): name = models.CharField(max_length=128)
@python_2_unicode_compatible class Event(models.Model): title = models.CharField(max_length=50) invitees = models.ManyToManyField( Person, through='Invitation', through_fields=('event', 'invitee'), related_name='events_invited', )
inviter = models.ForeignKey(Person, models.CASCADE, related_name='invitations_sent') invitee = models.ForeignKey(Person, models.CASCADE, related_name='invitations')
another = models.ForeignKey(Employee, models.SET_NULL, related_name="rel_another_set", null=True) target = models.ForeignKey(Employee, models.CASCADE, related_name="rel_target_set") source = models.ForeignKey(Employee, models.CASCADE, related_name="rel_source_set")
self.assertQuerysetEqual( tony.friends.all(), ['Chris'], attrgetter("name") )
self.assertQuerysetEqual( self.curry.ingredients.all(), [self.pea, self.potato, self.tomato], lambda x: x ) self.assertEqual(self.tomato.recipes.get(), self.curry)
fail_silently = request.POST.get('fail_silently', None) for msg in request.POST.getlist('messages'): if fail_silently is not None: getattr(messages, message_type)(request, msg, fail_silently=fail_silently) else: getattr(messages, message_type)(request, msg)
encoded_data = encoded_data[1:]
cookie = response.cookies.get(storage.cookie_name) if not cookie or cookie['max-age'] == 0: return 0 data = storage._decode(cookie.value) if not data: return 0 if data[-1] == CookieStorage.not_finished: data.pop() return len(data)
example_messages = ['test', 'me'] set_cookie_data(storage, example_messages) self.assertEqual(list(storage), example_messages)
storage = self.get_storage() response = self.get_response() storage.add(constants.INFO, 'test') storage.update(response) self.assertIn('test', response.cookies['messages'].value) self.assertEqual(response.cookies['messages']['domain'], '.example.com') self.assertEqual(response.cookies['messages']['expires'], '') self.assertEqual(response.cookies['messages']['secure'], True) self.assertEqual(response.cookies['messages']['httponly'], True)
storage = self.get_storage() response = self.get_response() storage.add(constants.INFO, 'test') for m in storage:
example_messages = ['test', 'me'] set_cookie_data(storage, example_messages, invalid=True) self.assertEqual(list(storage), [])
msg_size = int((CookieStorage.max_cookie_size - 54) / 4.5 - 37) for i in range(5): storage.add(constants.INFO, str(i) * msg_size) unstored_messages = storage.update(response)
messages = [Message(constants.INFO, 'message %s') for x in range(5)] encoder = MessageEncoder(separators=(',', ':')) encoded_messages = encoder.encode(messages)
encoded_messages = json.loads(encoded_messages) for obj in encoded_messages: obj.pop(1) encoded_messages = json.dumps(encoded_messages, separators=(',', ':'))
decoded_messages = json.loads(encoded_messages, cls=MessageDecoder) self.assertEqual(messages, decoded_messages)
example_messages = ['test', 'me'] set_session_data(storage, example_messages) self.assertEqual(list(storage), example_messages)
example_messages = [str(i) for i in range(5)] set_cookie_data(cookie_storage, example_messages)
self.get_session_storage(storage)._get = None
self.assertEqual(list(storage), example_messages)
self.get_session_storage(storage)._get = None
self.assertEqual(list(storage), [])
example_messages = [str(i) for i in range(5)] set_cookie_data(cookie_storage, example_messages[:4] + [CookieStorage.not_finished]) set_session_data(session_storage, example_messages[4:])
self.assertEqual(list(storage), example_messages)
example_messages = [str(i) for i in range(5)] set_cookie_data(cookie_storage, [CookieStorage.not_finished], encode_empty=True) set_session_data(session_storage, example_messages)
self.assertEqual(list(storage), example_messages)
set_cookie_data(cookie_storage, ['cookie', CookieStorage.not_finished]) set_session_data(session_storage, ['session'])
response = self.get_response() list(storage) storage.update(response) session_storing = self.stored_session_messages_count(storage, response) self.assertEqual(session_storing, 0)
self.get_session_storage(storage)._store = None
msg_size = int((CookieStorage.max_cookie_size - 54) / 4.5 - 37) for i in range(5): storage.add(constants.INFO, str(i) * msg_size) storage.update(response)
self.old_level_tags = base.LEVEL_TAGS base.LEVEL_TAGS = utils.get_level_tags()
response = self.client.get(show_url) for msg in data['messages']: self.assertNotContains(response, msg)
data = list(storage) self.assertTrue(storage.used) self.assertEqual(data, list(storage))
request = self.get_request() self.assertEqual(get_level(request), constants.INFO)
storage = self.get_storage() request._messages = storage self.assertEqual(get_level(request), constants.INFO)
add_level_messages(storage) self.assertEqual(len(storage), 5)
article = Article.objects.annotate( headline=Coalesce('summary', 'text', output_field=TextField()), )
article = Article.objects.annotate( headline=Coalesce(Lower('summary'), Lower('text'), output_field=TextField()), )
article = Article.objects.annotate( title_text=Upper(Concat('title', V(' - '), 'text', output_field=TextField())), ).get(title='The Title') expected = article.title + ' - ' + article.text self.assertEqual(expected.upper(), article.title_text)
self.assertEqual(len(list(pair.flatten())), 3)
self.assertEqual(str(qs.query), str(qs.all().query))
Author.objects.filter(alias__isnull=True).update( alias=Lower(Substr('name', 1, 5)), )
if tzinfo is not None: value = value.astimezone(tzinfo)
if isinstance(value, datetime): return value.replace(month=1, day=1, hour=0, minute=0, second=0, microsecond=0) return value.replace(month=1, day=1)
value = timezone.make_aware(value.replace(tzinfo=None), tzinfo)
qs = DTModel.objects.filter(start_datetime__year=2015) self.assertEqual(qs.count(), 1) query_string = str(qs.query).lower() self.assertEqual(query_string.count(' between '), 1) self.assertEqual(query_string.count('extract'), 0)
qs = DTModel.objects.filter(start_date__year=2015) self.assertEqual(qs.count(), 1) query_string = str(qs.query).lower() self.assertEqual(query_string.count(' between '), 1) self.assertEqual(query_string.count('extract'), 0)
management.call_command('loaddata', 'fixture1.json', verbosity=0) self.assertQuerysetEqual(Article.objects.all(), [ '<Article: Time to reform copyright>', '<Article: Poker has no place on ESPN>', ])
self._dumpdata_assert( ['fixtures'], '[{"pk": 1, "model": "fixtures.category", "fields": {"description": "Latest news stories", "title": ' '"News Stories"}}, {"pk": 2, "model": "fixtures.article", "fields": {"headline": "Poker has no place ' 'on ESPN", "pub_date": "2006-06-16T12:00:00"}}, {"pk": 3, "model": "fixtures.article", "fields": ' '{"headline": "Time to reform copyright", "pub_date": "2006-06-16T13:00:00"}}]' )
self._dumpdata_assert( ['fixtures.Category'], '[{"pk": 1, "model": "fixtures.category", "fields": {"description": "Latest news stories", ' '"title": "News Stories"}}]' )
self._dumpdata_assert( ['fixtures.Article'], '[{"pk": 2, "model": "fixtures.article", "fields": {"headline": "Poker has no place on ESPN", ' '"pub_date": "2006-06-16T12:00:00"}}, {"pk": 3, "model": "fixtures.article", "fields": {"headline": ' '"Time to reform copyright", "pub_date": "2006-06-16T13:00:00"}}]' )
self._dumpdata_assert( ['fixtures.Category', 'fixtures.Article'], '[{"pk": 1, "model": "fixtures.category", "fields": {"description": "Latest news stories", ' '"title": "News Stories"}}, {"pk": 2, "model": "fixtures.article", "fields": {"headline": "Poker has ' 'no place on ESPN", "pub_date": "2006-06-16T12:00:00"}}, {"pk": 3, "model": "fixtures.article", ' '"fields": {"headline": "Time to reform copyright", "pub_date": "2006-06-16T13:00:00"}}]' )
self._dumpdata_assert( ['fixtures.Article', 'fixtures.Article'], ( '[{"pk": 2, "model": "fixtures.article", "fields": {"headline": "Poker has no place on ESPN", ' '"pub_date": "2006-06-16T12:00:00"}}, {"pk": 3, "model": "fixtures.article", "fields": {"headline": ' '"Time to reform copyright", "pub_date": "2006-06-16T13:00:00"}}]' ) )
self._dumpdata_assert( ['fixtures.Article', 'fixtures'], '[{"pk": 1, "model": "fixtures.category", "fields": {"description": "Latest news stories", "title": ' '"News Stories"}}, {"pk": 2, "model": "fixtures.article", "fields": {"headline": "Poker has no place ' 'on ESPN", "pub_date": "2006-06-16T12:00:00"}}, {"pk": 3, "model": "fixtures.article", "fields": ' '{"headline": "Time to reform copyright", "pub_date": "2006-06-16T13:00:00"}}]' )
self._dumpdata_assert( ['fixtures', 'fixtures.Article'], '[{"pk": 1, "model": "fixtures.category", "fields": {"description": "Latest news stories", "title": ' '"News Stories"}}, {"pk": 2, "model": "fixtures.article", "fields": {"headline": "Poker has no place ' 'on ESPN", "pub_date": "2006-06-16T12:00:00"}}, {"pk": 3, "model": "fixtures.article", "fields": ' '{"headline": "Time to reform copyright", "pub_date": "2006-06-16T13:00:00"}}]' )
self._dumpdata_assert( ['fixtures'], '[{"pk": 1, "model": "fixtures.category", "fields": {"description": "Latest news stories", "title": ' '"News Stories"}}, {"pk": 2, "model": "fixtures.article", "fields": {"headline": "Poker has no ' 'place on ESPN", "pub_date": "2006-06-16T12:00:00"}}, {"pk": 3, "model": "fixtures.article", "fields":' ' {"headline": "Time to reform copyright", "pub_date": "2006-06-16T13:00:00"}}]' )
self._dumpdata_assert( ['fixtures.Category', 'sites'], '[{"pk": 1, "model": "fixtures.category", "fields": {"description": "Latest news stories", "title": ' '"News Stories"}}, {"pk": 1, "model": "sites.site", "fields": {"domain": "example.com", "name": ' '"example.com"}}]' )
management.call_command('loaddata', 'fixture2.json', verbosity=0) self.assertQuerysetEqual(Article.objects.all(), [ '<Article: Django conquers world!>', '<Article: Copyright is fine the way it is>', '<Article: Poker has no place on ESPN>', ])
management.call_command('loaddata', 'fixture3.xml', verbosity=0) self.assertQuerysetEqual(Article.objects.all(), [ '<Article: XML identified as leading cause of cancer>', '<Article: Django conquers world!>', '<Article: Copyright is fine the way it is>', '<Article: Poker on TV is great!>', ])
management.call_command('loaddata', 'fixture6.json', verbosity=0) self.assertQuerysetEqual(Tag.objects.all(), [ '<Tag: <Article: Copyright is fine the way it is> tagged "copyright">', '<Tag: <Article: Copyright is fine the way it is> tagged "law">', ], ordered=False)
management.call_command('loaddata', 'fixture7.xml', verbosity=0) self.assertQuerysetEqual(Tag.objects.all(), [ '<Tag: <Article: Copyright is fine the way it is> tagged "copyright">', '<Tag: <Article: Copyright is fine the way it is> tagged "legal">', '<Tag: <Article: Django conquers world!> tagged "django">', '<Tag: <Article: Django conquers world!> tagged "world domination">', ], ordered=False)
management.call_command('loaddata', 'fixture8.json', verbosity=0) self.assertQuerysetEqual(Visa.objects.all(), [ '<Visa: Django Reinhardt Can add user, Can change user, Can delete user>', '<Visa: Stephane Grappelli Can add user>', '<Visa: Prince >' ], ordered=False)
management.call_command('loaddata', 'fixture9.xml', verbosity=0) self.assertQuerysetEqual(Visa.objects.all(), [ '<Visa: Django Reinhardt Can add user, Can change user, Can delete user>', '<Visa: Stephane Grappelli Can add user, Can delete user>', '<Visa: Artist formerly known as "Prince" Can change user>' ], ordered=False)
self.assertQuerysetEqual(Article.objects.all(), [ '<Article: XML identified as leading cause of cancer>', '<Article: Django conquers world!>', '<Article: Copyright is fine the way it is>', '<Article: Poker on TV is great!>', ])
self._dumpdata_assert( ['fixtures.book'], '[{"pk": 1, "model": "fixtures.book", "fields": {"name": "Music for all ages", "authors": [3, 1]}}]' )
self._dumpdata_assert( ['fixtures.book'], '[{"pk": 1, "model": "fixtures.book", "fields": {"name": "Music for all ages", "authors": [["Artist ' 'formerly known as \\"Prince\\""], ["Django Reinhardt"]]}}]', natural_foreign_keys=True )
self._dumpdata_assert( ['fixtures.person'], '[{"fields": {"name": "Django Reinhardt"}, "model": "fixtures.person"}, {"fields": {"name": "Stephane ' 'Grappelli"}, "model": "fixtures.person"}, {"fields": {"name": "Artist formerly known as ' '\\"Prince\\""}, "model": "fixtures.person"}]', natural_primary_keys=True )
self._dumpdata_assert( ['fixtures'], '[{"pk": 1, "model": "fixtures.category", "fields": {"description": "Latest news stories", "title": ' '"News Stories"}}, {"pk": 2, "model": "fixtures.article", "fields": {"headline": "Poker on TV is ' 'great!", "pub_date": "2006-06-16T11:00:00"}}, {"pk": 3, "model": "fixtures.article", "fields": ' '{"headline": "Copyright is fine the way it is", "pub_date": "2006-06-16T14:00:00"}}, {"pk": 4, ' '"model": "fixtures.article", "fields": {"headline": "Django conquers world!", "pub_date": ' '"2006-06-16T15:00:00"}}, {"pk": 5, "model": "fixtures.article", "fields": {"headline": "XML ' 'identified as leading cause of cancer", "pub_date": "2006-06-16T16:00:00"}}, {"pk": 1, "model": ' '"fixtures.tag", "fields": {"tagged_type": ["fixtures", "article"], "name": "copyright", "tagged_id": ' '3}}, {"pk": 2, "model": "fixtures.tag", "fields": {"tagged_type": ["fixtures", "article"], "name": ' '"legal", "tagged_id": 3}}, {"pk": 3, "model": "fixtures.tag", "fields": {"tagged_type": ["fixtures", ' '"article"], "name": "django", "tagged_id": 4}}, {"pk": 4, "model": "fixtures.tag", "fields": ' '{"tagged_type": ["fixtures", "article"], "name": "world domination", "tagged_id": 4}}, {"pk": 1, ' '"model": "fixtures.person", "fields": {"name": "Django Reinhardt"}}, {"pk": 2, "model": ' '"fixtures.person", "fields": {"name": "Stephane Grappelli"}}, {"pk": 3, "model": "fixtures.person", ' '"fields": {"name": "Artist formerly known as \\"Prince\\""}}, {"pk": 1, "model": "fixtures.visa", ' '"fields": {"person": ["Django Reinhardt"], "permissions": [["add_user", "auth", "user"], ' '["change_user", "auth", "user"], ["delete_user", "auth", "user"]]}}, {"pk": 2, "model": ' '"fixtures.visa", "fields": {"person": ["Stephane Grappelli"], "permissions": [["add_user", "auth", ' '"user"], ["delete_user", "auth", "user"]]}}, {"pk": 3, "model": "fixtures.visa", "fields": {"person":' ' ["Artist formerly known as \\"Prince\\""], "permissions": [["change_user", "auth", "user"]]}}, ' '{"pk": 1, "model": "fixtures.book", "fields": {"name": "Music for all ages", "authors": [["Artist ' 'formerly known as \\"Prince\\""], ["Django Reinhardt"]]}}]', natural_foreign_keys=True )
self._dumpdata_assert( ['fixtures'], '<?xml version="1.0" encoding="utf-8"?><django-objects version="1.0"><object pk="1" ' 'model="fixtures.category"><field type="CharField" name="title">News Stories</field><field ' 'type="TextField" name="description">Latest news stories</field></object><object pk="2" ' 'model="fixtures.article"><field type="CharField" name="headline">Poker on TV is great!</field><field ' 'type="DateTimeField" name="pub_date">2006-06-16T11:00:00</field></object><object pk="3" ' 'model="fixtures.article"><field type="CharField" name="headline">Copyright is fine the way it ' 'is</field><field type="DateTimeField" name="pub_date">2006-06-16T14:00:00</field></object><object ' 'pk="4" model="fixtures.article"><field type="CharField" name="headline">Django conquers world!' '</field><field type="DateTimeField" name="pub_date">2006-06-16T15:00:00</field></object><object ' 'pk="5" model="fixtures.article"><field type="CharField" name="headline">XML identified as leading ' 'cause of cancer</field><field type="DateTimeField" name="pub_date">2006-06-16T16:00:00</field>' '</object><object pk="1" model="fixtures.tag"><field type="CharField" name="name">copyright</field>' '<field to="contenttypes.contenttype" name="tagged_type" rel="ManyToOneRel"><natural>fixtures' '</natural><natural>article</natural></field><field type="PositiveIntegerField" name="tagged_id">3' '</field></object><object pk="2" model="fixtures.tag"><field type="CharField" name="name">legal' '</field><field to="contenttypes.contenttype" name="tagged_type" rel="ManyToOneRel"><natural>' 'fixtures</natural><natural>article</natural></field><field type="PositiveIntegerField" ' 'name="tagged_id">3</field></object><object pk="3" model="fixtures.tag"><field type="CharField" ' 'name="name">django</field><field to="contenttypes.contenttype" name="tagged_type" ' 'rel="ManyToOneRel"><natural>fixtures</natural><natural>article</natural></field><field ' 'type="PositiveIntegerField" name="tagged_id">4</field></object><object pk="4" model="fixtures.tag">' '<field type="CharField" name="name">world domination</field><field to="contenttypes.contenttype" ' 'name="tagged_type" rel="ManyToOneRel"><natural>fixtures</natural><natural>article</natural></field>' '<field type="PositiveIntegerField" name="tagged_id">4</field></object><object pk="1" ' 'model="fixtures.person"><field type="CharField" name="name">Django Reinhardt</field></object>' '<object pk="2" model="fixtures.person"><field type="CharField" name="name">Stephane Grappelli' '</field></object><object pk="3" model="fixtures.person"><field type="CharField" name="name">' 'Artist formerly known as "Prince"</field></object><object pk="1" model="fixtures.visa"><field ' 'to="fixtures.person" name="person" rel="ManyToOneRel"><natural>Django Reinhardt</natural></field>' '<field to="auth.permission" name="permissions" rel="ManyToManyRel"><object><natural>add_user' '</natural><natural>auth</natural><natural>user</natural></object><object><natural>change_user' '</natural><natural>auth</natural><natural>user</natural></object><object><natural>delete_user' '</natural><natural>auth</natural><natural>user</natural></object></field></object><object pk="2" ' 'model="fixtures.visa"><field to="fixtures.person" name="person" rel="ManyToOneRel"><natural>Stephane' ' Grappelli</natural></field><field to="auth.permission" name="permissions" rel="ManyToManyRel">' '<object><natural>add_user</natural><natural>auth</natural><natural>user</natural></object><object>' '<natural>delete_user</natural><natural>auth</natural><natural>user</natural></object></field>' '</object><object pk="3" model="fixtures.visa"><field to="fixtures.person" name="person" ' 'rel="ManyToOneRel"><natural>Artist formerly known as "Prince"</natural></field><field ' 'to="auth.permission" name="permissions" rel="ManyToManyRel"><object><natural>change_user</natural>' '<natural>auth</natural><natural>user</natural></object></field></object><object pk="1" ' 'model="fixtures.book"><field type="CharField" name="name">Music for all ages</field><field ' 'to="fixtures.person" name="authors" rel="ManyToManyRel"><object><natural>Artist formerly known as ' '"Prince"</natural></object><object><natural>Django Reinhardt</natural></object></field></object>' '</django-objects>', format='xml', natural_foreign_keys=True )
Site.objects.all().delete() management.call_command('loaddata', 'fixture1.json', verbosity=0)
self._dumpdata_assert( ['sites', 'fixtures'], '[{"pk": 1, "model": "sites.site", "fields": {"domain": "example.com", "name": "example.com"}}]', exclude_list=['fixtures'])
self._dumpdata_assert( ['sites', 'fixtures'], '[{"pk": 1, "model": "sites.site", "fields": {"domain": "example.com", "name": "example.com"}}, ' '{"pk": 1, "model": "fixtures.category", "fields": {"description": "Latest news stories", "title": ' '"News Stories"}}]', exclude_list=['fixtures.Article', 'fixtures.Book'] )
self._dumpdata_assert( ['sites', 'fixtures'], '[{"pk": 1, "model": "sites.site", "fields": {"domain": "example.com", "name": "example.com"}}, ' '{"pk": 1, "model": "fixtures.category", "fields": {"description": "Latest news stories", "title": ' '"News Stories"}}]', exclude_list=['fixtures.Article', 'fixtures.Book'] )
self._dumpdata_assert( ['sites', 'fixtures'], '[{"pk": 1, "model": "fixtures.category", "fields": {"description": "Latest news stories", "title": ' '"News Stories"}}]', exclude_list=['fixtures.Article', 'fixtures.Book', 'sites'] )
with self.assertRaisesMessage(management.CommandError, "No installed app with label 'foo_app'."): self._dumpdata_assert(['fixtures', 'sites'], '', exclude_list=['foo_app'])
with self.assertRaisesMessage(management.CommandError, "Unknown model in excludes: fixtures.FooModel"): self._dumpdata_assert(['fixtures', 'sites'], '', exclude_list=['fixtures.FooModel'])
self._dumpdata_assert( ['fixtures.Spy'], '[{"pk": %d, "model": "fixtures.spy", "fields": {"cover_blown": false}}]' % spy1.pk ) self._dumpdata_assert( ['fixtures.Spy'], '[{"pk": %d, "model": "fixtures.spy", "fields": {"cover_blown": true}}, {"pk": %d, "model": ' '"fixtures.spy", "fields": {"cover_blown": false}}]' % (spy2.pk, spy1.pk), use_base_manager=True )
options['verbosity'] = 0 new_io = six.StringIO() new_io.isatty = lambda: True options.update({'stdout': new_io, 'stderr': new_io}) management.call_command('dumpdata', 'fixtures', **options) self.assertEqual(new_io.getvalue(), '')
management.call_command('loaddata', 'fixture4.json', verbosity=0) self.assertQuerysetEqual(Article.objects.all(), [ '<Article: Django pets kitten>', ])
management.call_command('loaddata', 'fixture5.json.zip', verbosity=0) self.assertQuerysetEqual(Article.objects.all(), [ '<Article: WoW subscribers now outnumber readers>', ])
management.call_command('loaddata', 'fixture5.zip', verbosity=0) self.assertQuerysetEqual(Article.objects.all(), [ '<Article: WoW subscribers now outnumber readers>', ])
with self.assertRaises(management.CommandError) as cm: management.call_command('loaddata', 'fixture5', verbosity=0) self.assertIn("Multiple fixtures named 'fixture5'", cm.exception.args[0])
management.call_command('loaddata', 'db_fixture_1', verbosity=0) management.call_command('loaddata', 'db_fixture_2', verbosity=0) self.assertQuerysetEqual(Article.objects.all(), [ '<Article: Who needs more than one database?>', '<Article: Who needs to use compressed data?>', ])
if connection.vendor == 'mysql': connection.cursor().execute("SET sql_mode = 'TRADITIONAL'") with self.assertRaises(IntegrityError) as cm: management.call_command('loaddata', 'invalid.json', verbosity=0) self.assertIn("Could not load fixtures.Article(pk=1):", cm.exception.args[0])
management.call_command('loaddata', 'db_fixture_1', verbosity=0, using='default') management.call_command('loaddata', 'db_fixture_2', verbosity=0, using='default') self.assertQuerysetEqual(Article.objects.all(), [ '<Article: Who needs more than one database?>', '<Article: Who needs to use compressed data?>', ])
with self.assertRaisesMessage(CommandError, "No fixture named 'db_fixture_3' found."): management.call_command('loaddata', 'db_fixture_3', verbosity=0) with self.assertRaisesMessage(CommandError, "No fixture named 'db_fixture_3' found."): management.call_command('loaddata', 'db_fixture_3', verbosity=0, using='default') self.assertQuerysetEqual(Article.objects.all(), [])
management.call_command('loaddata', 'fixture1', verbosity=0)
management.call_command('loaddata', 'fixture6', verbosity=0) self.assertQuerysetEqual(Tag.objects.all(), [ '<Tag: <Article: Time to reform copyright> tagged "copyright">', '<Tag: <Article: Time to reform copyright> tagged "law">' ], ordered=False)
self._dumpdata_assert( ['fixtures'], '[{"pk": 1, "model": "fixtures.category", "fields": {"description": "Latest news stories", "title": ' '"News Stories"}}, {"pk": 2, "model": "fixtures.article", "fields": {"headline": "Poker has no place ' 'on ESPN", "pub_date": "2006-06-16T12:00:00"}}, {"pk": 3, "model": "fixtures.article", "fields": ' '{"headline": "Time to reform copyright", "pub_date": "2006-06-16T13:00:00"}}, {"pk": 1, "model": ' '"fixtures.tag", "fields": {"tagged_type": ["fixtures", "article"], "name": "copyright", "tagged_id": ' '3}}, {"pk": 2, "model": "fixtures.tag", "fields": {"tagged_type": ["fixtures", "article"], "name": ' '"law", "tagged_id": 3}}, {"pk": 1, "model": "fixtures.person", "fields": {"name": "Django ' 'Reinhardt"}}, {"pk": 2, "model": "fixtures.person", "fields": {"name": "Stephane Grappelli"}}, ' '{"pk": 3, "model": "fixtures.person", "fields": {"name": "Prince"}}]', natural_foreign_keys=True )
self._dumpdata_assert( ['fixtures'], '<?xml version="1.0" encoding="utf-8"?><django-objects version="1.0"><object pk="1" ' 'model="fixtures.category"><field type="CharField" name="title">News Stories</field><field ' 'type="TextField" name="description">Latest news stories</field></object><object pk="2" ' 'model="fixtures.article"><field type="CharField" name="headline">Poker has no place on ESPN</field>' '<field type="DateTimeField" name="pub_date">2006-06-16T12:00:00</field></object><object pk="3" ' 'model="fixtures.article"><field type="CharField" name="headline">Time to reform copyright</field>' '<field type="DateTimeField" name="pub_date">2006-06-16T13:00:00</field></object><object pk="1" ' 'model="fixtures.tag"><field type="CharField" name="name">copyright</field><field ' 'to="contenttypes.contenttype" name="tagged_type" rel="ManyToOneRel"><natural>fixtures</natural>' '<natural>article</natural></field><field type="PositiveIntegerField" name="tagged_id">3</field>' '</object><object pk="2" model="fixtures.tag"><field type="CharField" name="name">law</field><field ' 'to="contenttypes.contenttype" name="tagged_type" rel="ManyToOneRel"><natural>fixtures</natural>' '<natural>article</natural></field><field type="PositiveIntegerField" name="tagged_id">3</field>' '</object><object pk="1" model="fixtures.person"><field type="CharField" name="name">Django Reinhardt' '</field></object><object pk="2" model="fixtures.person"><field type="CharField" name="name">Stephane ' 'Grappelli</field></object><object pk="3" model="fixtures.person"><field type="CharField" name="name">' 'Prince</field></object></django-objects>', format='xml', natural_foreign_keys=True )
management.call_command('loaddata', 'fixture1', verbosity=0) self.assertQuerysetEqual(Article.objects.all(), [ '<Article: Time to reform copyright>', '<Article: Poker has no place on ESPN>', ])
with self.assertRaises(management.CommandError) as cm: management.call_command('loaddata', 'fixture2', verbosity=0) self.assertIn("Multiple fixtures named 'fixture2'", cm.exception.args[0])
self.assertQuerysetEqual(Article.objects.all(), [ '<Article: Time to reform copyright>', '<Article: Poker has no place on ESPN>', ])
self._dumpdata_assert( ['fixtures'], '[{"pk": 1, "model": "fixtures.category", "fields": {"description": "Latest news stories", "title": ' '"News Stories"}}, {"pk": 2, "model": "fixtures.article", "fields": {"headline": "Poker has no place ' 'on ESPN", "pub_date": "2006-06-16T12:00:00"}}, {"pk": 3, "model": "fixtures.article", "fields": ' '{"headline": "Time to reform copyright", "pub_date": "2006-06-16T13:00:00"}}]' )
management.call_command('loaddata', 'fixture4', verbosity=0) self.assertQuerysetEqual(Article.objects.all(), [ '<Article: Django pets kitten>', '<Article: Time to reform copyright>', '<Article: Poker has no place on ESPN>', ])
from __future__ import unicode_literals
"Big data" * 68000, encode=base64.encodestring if PY2 else base64.encodebytes)
with open(os.path.join(tdir, UNICODE_FILENAME), 'w+b') as file1: file1.write(b'b' * (2 ** 10)) file1.seek(0)
filenames = ['', 'C:\\Windows\\']
received = json.loads(response.content.decode('utf-8')) for i, name in enumerate(filenames): self.assertIsNone(received.get('file%s' % i))
scary_file_names = [
received = json.loads(response.content.decode('utf-8')) for i, name in enumerate(scary_file_names): got = received["file%s" % i] self.assertEqual(got, "hax0rd.txt")
('long_filename', '%s.txt' % long_str, '%s.txt' % long_str[:251]), ('long_extension', 'foo.%s' % long_str, '.%s' % long_str[:254]), ('no_extension', long_str, long_str[:255]), ('no_filename', '.%s' % long_str, '.%s' % long_str[:254]), ('long_everything', '%s.%s' % (long_str, long_str), '.%s' % long_str[:254]),
smallfile.write(b'a' * (2 ** 21)) smallfile.seek(0)
bigfile.write(b'a' * (10 * 2 ** 20)) bigfile.seek(0)
response = self.client.post('/quota/', {'f': smallfile}) got = json.loads(response.content.decode('utf-8')) self.assertIn('f', got)
response = self.client.post("/quota/", {'f': bigfile}) got = json.loads(response.content.decode('utf-8')) self.assertNotIn('f', got)
with self.assertRaises(AttributeError): self.client.post('/quota/broken/', {'f': file})
self.assertTrue(hasattr(request, '_files'))
self.assertFalse(hasattr(request, '_files'))
try: client.FakePayload(b'a').read(2) except Exception as err: reference_error = err
self.client.handler = POSTAccessingHandler()
self.assertEqual(err.__class__, uploadhandler.CustomUploadError)
vars = {'boundary': 'oUrBoUnDaRyStRiNg'} post_data = [ '--%(boundary)s', 'Content-Disposition: form-data; name="file_field"; filename="MiXeD_cAsE.txt"', 'Content-Type: application/octet-stream', '', 'file contents\n' '', '--%(boundary)s--\r\n', ] response = self.client.post( '/filename_case/', '\r\n'.join(post_data) % vars, 'multipart/form-data; boundary=%(boundary)s' % vars ) self.assertEqual(response.status_code, 200) id = int(response.content) obj = FileModel.objects.get(pk=id) self.assertEqual(os.path.basename(obj.testfile.path), 'MiXeD_cAsE.txt')
open(UPLOAD_TO, 'wb').close() self.addCleanup(os.remove, UPLOAD_TO) with self.assertRaises(IOError) as exc_info: with SimpleUploadedFile('foo.txt', b'x') as file: self.obj.testfile.save('foo.txt', file, save=False) self.assertEqual(exc_info.exception.args[0], "%s exists and is not a directory." % UPLOAD_TO)
MultiPartParser({ 'CONTENT_TYPE': 'multipart/form-data; boundary=_foo', 'CONTENT_LENGTH': '1' }, StringIO('x'), [], 'utf-8')
if os.path.dirname(form_data['file_field'].name) != '': return HttpResponseServerError() return HttpResponse('')
largefile = request.FILES['file_field2'] obj = FileModel() obj.testfile.save(largefile.name, largefile)
if not request.FILES['file_unicode'].name.endswith(UNICODE_FILENAME): return HttpResponseServerError()
uni_named_file = request.FILES['file_unicode'] obj = FileModel.objects.create(testfile=uni_named_file) full_name = '%s/%s' % (UPLOAD_TO, uni_named_file.name) if not os.path.exists(full_name): response = HttpResponseServerError()
obj.delete() os.unlink(full_name)
r = self.client.get('/check_unicode/') self.assertContains(r, '') self.assertContains(r, b'\xe5\xb3\xa0'.decode('utf-8'))
r = self.client.get('/check_unicode/') self.assertNotContains(r, '') self.assertNotContains(r, b'\xe3\x81\xaf\xe3\x81\x9f\xe3\x81\x91'.decode('utf-8'))
self.assertTemplateNotUsed(response, 'GET Template')
response = self.client.get('/permanent_redirect_view/') try: self.assertRedirects(response, '/get_view/') except AssertionError as e: self.assertIn("Response didn't redirect as expected: Response code was 301 (expected 302)", str(e))
self.assertRedirects(response, '/some_view/')
self.assertRedirects(response, 'http://testserver/permanent_redirect_view/')
self.assertRedirects(response, 'http://testserver/permanent_redirect_view/', msg_prefix='abc')
self.assertRedirects(response, '/redirect_to_self/', status_code=302, target_status_code=302) self.assertEqual(len(response.redirect_chain), 2)
self.assertRedirects(response, '/circular_redirect_2/', status_code=302, target_status_code=302) self.assertEqual(len(response.redirect_chain), 4)
self.assertEqual(response.request.get('wsgi.url_scheme'), 'https') self.assertEqual(response.request.get('SERVER_NAME'), 'otherserver') self.assertEqual(response.request.get('SERVER_PORT'), '8443')
response = self.client.get('/get_view/', follow=True) try: self.assertRedirects(response, '/get_view/') except AssertionError as e: self.assertIn("Response didn't redirect as expected: Response code was 200 (expected 302)", str(e))
response = self.client.get('/get_view/') try: self.assertRedirects(response, '/get_view/') except AssertionError as e: self.assertIn("Response didn't redirect as expected: Response code was 200 (expected 302)", str(e))
for follow, secure in itertools.product([True, False], repeat=2): response = self.client.get('/https_redirect_view/', follow=follow, secure=secure) self.assertRedirects(response, 'https://testserver/secure_view/', status_code=302) with self.assertRaises(AssertionError): self.assertRedirects(response, 'http://testserver/secure_view/', status_code=302)
self.response_form_errors = self.getResponse({ 'form-TOTAL_FORMS': '2', 'form-INITIAL_FORMS': '2', 'form-0-text': 'Raise non-field error', 'form-0-email': 'not an email address', 'form-0-value': 37, 'form-0-single': 'b', 'form-0-multi': ('b', 'c', 'e'), 'form-1-text': 'Hello World', 'form-1-email': 'email@domain.com', 'form-1-value': 37, 'form-1-single': 'b', 'form-1-multi': ('b', 'c', 'e'), }) self.response_nonform_errors = self.getResponse({ 'form-TOTAL_FORMS': '2', 'form-INITIAL_FORMS': '2', 'form-0-text': 'Hello World', 'form-0-email': 'email@domain.com', 'form-0-value': 37, 'form-0-single': 'b', 'form-0-multi': ('b', 'c', 'e'), 'form-1-text': 'Hello World', 'form-1-email': 'email@domain.com', 'form-1-value': 37, 'form-1-single': 'b', 'form-1-multi': ('b', 'c', 'e'), })
c = Client() login = c.login(username='testclient', password='password') self.assertTrue(login, 'Could not log in')
response = c.get("/login_protected_redirect_view/")
self.assertRedirects(response, "/get_view/")
response = self.client.get("/login_protected_view/") self.assertEqual(response.status_code, 200) self.assertEqual(response.context['user'].username, 'testclient')
login = self.client.login(username='staff', password='password') self.assertTrue(login, 'Could not log in') try: self.client.get("/staff_only/") except CustomTestException: self.fail("Staff should be able to visit this page")
@override_settings(ROOT_URLCONF='test_client_regress.urls') class UrlconfSubstitutionTests(SimpleTestCase):
class zzUrlconfSubstitutionTests(SimpleTestCase):
self.assertEqual({'None', 'True', 'False', 'hello', 'goodbye', 'python', 'dolly'}, l.keys())
with self.settings(TEMPLATES=[{ 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'APP_DIRS': True, 'OPTIONS': { 'context_processors': [ 'test_client_regress.context_processors.special', ], }, }]): response = self.client.get("/request_context_view/") self.assertContains(response, 'Path: /request_context_view/')
response = self.client.get('/check_session/') self.assertEqual(response.status_code, 200) self.assertEqual(response.content, b'NO')
response = self.client.get('/set_session/') self.assertEqual(response.status_code, 200) self.assertEqual(response.content, b'set_session')
response = self.client.get('/check_session/') self.assertEqual(response.status_code, 200) self.assertEqual(response.content, b'YES')
login = self.client.login(username='testclient', password='password') self.assertTrue(login, 'Could not log in')
response = self.client.get('/check_session/') self.assertEqual(response.status_code, 200) self.assertEqual(response.content, b'YES')
self.assertNotEqual(response.content, b'request method: HEAD') self.assertEqual(response.content, b'')
data = '{"test": "json"}' response = self.client.post('/request_methods/', data=data, content_type='application/json') self.assertEqual(response.status_code, 200) self.assertEqual(response.content, b'request method: POST')
data = '{"test": "json"}' response = self.client.put('/request_methods/', data=data, content_type='application/json') self.assertEqual(response.status_code, 200) self.assertEqual(response.content, b'request method: PUT')
data = '{"test": "json"}' response = self.client.patch('/request_methods/', data=data, content_type='application/json') self.assertEqual(response.status_code, 200) self.assertEqual(response.content, b'request method: PATCH')
response = self.client.get('/body/', data='', content_type='application/json') self.assertEqual(response.content, b'') response = self.client.post('/body/', data='', content_type='application/json') self.assertEqual(response.content, b'') response = self.client.head('/body/', data='', content_type='application/json') self.assertEqual(response.content, b'')
for method_name in ('get', 'head'): method = getattr(self.client, method_name) response = method("/request_data/", data={'foo': 'whiz'}) self.assertEqual(response.context['get-foo'], 'whiz')
response = method("/request_data/?foo=whiz") self.assertEqual(response.context['get-foo'], 'whiz')
response = method("/request_data/?foo=whiz", data={'foo': 'bang'}) self.assertEqual(response.context['get-foo'], 'bang')
response = self.client.post("/request_data/", data={'foo': 'whiz'}) self.assertEqual(response.context['get-foo'], None) self.assertEqual(response.context['post-foo'], 'whiz')
response = self.client.post("/request_data/?foo=whiz") self.assertEqual(response.context['get-foo'], 'whiz') self.assertEqual(response.context['post-foo'], None)
response = self.client.post("/request_data/?foo=whiz", data={'foo': 'bang'}) self.assertEqual(response.context['get-foo'], 'whiz') self.assertEqual(response.context['post-foo'], 'bang')
json = '{"english": "mountain pass"}' response = self.client.post("/parse_unicode_json/", json, content_type="application/json") self.assertEqual(response.content, json.encode())
json = '{"dog": ""}' response = self.client.post("/parse_unicode_json/", json, content_type="application/json; charset=utf-8") self.assertEqual(response.content, json.encode('utf-8'))
json = '{"dog": ""}' response = self.client.post("/parse_unicode_json/", json, content_type="application/json; charset=utf-16") self.assertEqual(response.content, json.encode('utf-16'))
json = '{"dog": ""}' response = self.client.post("/parse_unicode_json/", json, content_type="application/json; charset=koi8-r") self.assertEqual(response.content, json.encode('koi8-r'))
self.client.get('/') self.common_test_that_should_always_pass()
self.common_test_that_should_always_pass()
obj_dict = json.loads(request.body.decode(charset)) obj_json = json.dumps(obj_dict, cls=DjangoJSONEncoder, ensure_ascii=False) response = HttpResponse(obj_json.encode(charset), status=200, content_type='application/json; charset=%s' % charset) response['Content-Disposition'] = 'attachment; filename=testfile.json' return response
request.special_path = request.path return render(request, 'request_context.html')
cls.non_lob_fields = [ f.name for f in CaseTestModel._meta.get_fields() if not (f.is_relation and f.auto_created) and not isinstance(f, (models.BinaryField, models.TextField)) ]
test_combined_expression = unittest.expectedFailure(test_combined_expression)
When(integer=1, then=Value(b'one', output_field=models.BinaryField())), When(integer=2, then=Value(b'two', output_field=models.BinaryField())), default=Value(b'', output_field=models.BinaryField()),
When(integer=1, then=Value(timedelta(1), output_field=models.DurationField())), When(integer=2, then=Value(timedelta(2), output_field=models.DurationField())),
When(integer=1, then=Value('1.1.1.1')), When(integer=2, then=Value('2.2.2.2')), output_field=models.GenericIPAddressField(),
When(integer=1, then=Value(time(1), output_field=models.TimeField())), When(integer=2, then=Value(time(2), output_field=models.TimeField())),
When(integer=1, then=Value( UUID('11111111111111111111111111111111'), output_field=models.UUIDField(), )), When(integer=2, then=Value( UUID('22222222222222222222222222222222'), output_field=models.UUIDField(), )),
self.assertQuerysetEqual( CaseTestModel.objects.filter(pk=o.pk).annotate( foo=Case( When(fk_rel__pk=1, then=2), default=3, output_field=models.IntegerField() ), ), [(o, 3)], lambda x: (x, x.foo) ) self.assertQuerysetEqual( CaseTestModel.objects.filter(pk=o.pk).annotate( foo=Case( When(fk_rel__isnull=True, then=2), default=3, output_field=models.IntegerField() ), ), [(o, 2)], lambda x: (x, x.foo) )
self.assertQuerysetEqual( CaseTestModel.objects.filter(pk=o.pk).annotate( foo=Case( When(fk_rel__pk=1, then=2), default=3, output_field=models.IntegerField() ), bar=Case( When(fk_rel__pk=1, then=4), default=5, output_field=models.IntegerField() ), ), [(o, 3, 5)], lambda x: (x, x.foo, x.bar) ) self.assertQuerysetEqual( CaseTestModel.objects.filter(pk=o.pk).annotate( foo=Case( When(fk_rel__isnull=True, then=2), default=3, output_field=models.IntegerField() ), bar=Case( When(fk_rel__isnull=True, then=4), default=5, output_field=models.IntegerField() ), ), [(o, 2, 4)], lambda x: (x, x.foo, x.bar) )
self.assertQuerysetEqual( qs, [(1, 2), (2, 2), (2, 2), (3, 2), (3, 2), (3, 2), (4, 1), (10, 1)], lambda x: x[1:] )
qs = CaseTestModel.objects.values_list('id', 'integer').annotate( cnt=models.Sum( Case(When(~Q(fk_rel__integer=1), then=1), default=2), output_field=models.IntegerField() ), ).annotate( cnt2=models.Sum( Case(When(~Q(fk_rel__integer=1), then=1), default=2), output_field=models.IntegerField() ), ).order_by('integer') self.assertEqual(str(qs.query).count(' JOIN '), 1) self.assertQuerysetEqual( qs, [(1, 2, 2), (2, 2, 2), (2, 2, 2), (3, 2, 2), (3, 2, 2), (3, 2, 2), (4, 1, 1), (10, 1, 1)], lambda x: x[1:] )
class SchoolManager(models.Manager): def get_queryset(self): return super(SchoolManager, self).get_queryset().filter(is_public=True)
self.assertEqual(repr(self.r1.place), '<Place: Demon Dogs the place>') self.assertEqual(repr(self.p1.restaurant), '<Restaurant: Demon Dogs the restaurant>') with self.assertRaisesMessage(Restaurant.DoesNotExist, 'Place has no restaurant'): self.p2.restaurant self.assertFalse(hasattr(self.p2, 'restaurant'))
self.r1.place = self.p2 self.r1.save() self.assertEqual(repr(self.p2.restaurant), '<Restaurant: Ace Hardware the restaurant>') self.assertEqual(repr(self.r1.place), '<Place: Ace Hardware the place>') self.assertEqual(self.p2.pk, self.r1.pk) self.p1.restaurant = self.r1 self.assertEqual(repr(self.p1.restaurant), '<Restaurant: Demon Dogs the restaurant>') r = Restaurant.objects.get(pk=self.p1.id) self.assertEqual(repr(r.place), '<Place: Demon Dogs the place>')
self.assertQuerysetEqual(Restaurant.objects.all(), [ '<Restaurant: Demon Dogs the restaurant>', ]) self.assertQuerysetEqual(Place.objects.order_by('name'), [ '<Place: Ace Hardware the place>', '<Place: Demon Dogs the place>', ])
w = self.r1.waiter_set.create(name='Joe') self.assertEqual(repr(w), '<Waiter: Joe the waiter at Demon Dogs the restaurant>')
def assert_filter_waiters(**params): self.assertQuerysetEqual(Waiter.objects.filter(**params), [ '<Waiter: Joe the waiter at Demon Dogs the restaurant>' ]) assert_filter_waiters(restaurant__place__exact=self.p1.pk) assert_filter_waiters(restaurant__place__exact=self.p1) assert_filter_waiters(restaurant__place__pk=self.p1.pk) assert_filter_waiters(restaurant__exact=self.r1.pk) assert_filter_waiters(restaurant__exact=self.r1) assert_filter_waiters(restaurant__pk=self.r1.pk) assert_filter_waiters(restaurant=self.r1.pk) assert_filter_waiters(restaurant=self.r1) assert_filter_waiters(id__exact=w.pk) assert_filter_waiters(pk=w.pk) r = Restaurant.objects.get(pk=self.r1.pk) r.delete() self.assertEqual(Waiter.objects.count(), 0)
o1 = ManualPrimaryKey(primary_key="abc123", name="primary") o1.save() o2 = RelatedModel(link=o1, name="secondary") o2.save()
x1 = MultiModel(link1=self.p1, link2=o1, name="x1") x1.save() self.assertEqual(repr(o1.multimodel), '<MultiModel: Multimodel x1>') mm = MultiModel(link1=self.p2, link2=o1, name="x1") with self.assertRaises(IntegrityError): with transaction.atomic(): mm.save()
with self.assertRaises(Restaurant.DoesNotExist): place.restaurant
self.p1.undergroundbar bar.place.name = 'foo' bar.place = None bar.save() self.p1.delete()
ug_bar = UndergroundBar.objects.create(place=p, serves_cocktails=False) p.undergroundbar = None self.assertIsNone(ug_bar.place) ug_bar.save() ug_bar.refresh_from_db() self.assertIsNone(ug_bar.place)
p.undergroundbar = None
p = Place.objects.get(name="Demon Dogs") r = p.restaurant
self.assertIs(p.restaurant, r)
del p._restaurant_cache self.assertIsNot(p.restaurant, r)
r2 = Restaurant.objects.get(pk=r.pk) p.restaurant = r2 self.assertIs(p.restaurant, r2)
ug_bar = UndergroundBar.objects.create(place=p, serves_cocktails=False) ug_bar.place = None self.assertIsNone(ug_bar.place)
setattr(p, 'restaurant', None)
with self.assertRaises(ValueError): setattr(p, 'restaurant', p)
p = Place.objects.get(name="Demon Dogs") r = Restaurant(place=p) self.assertIs(r.place, p)
p = Place() r = Restaurant(place=p) self.assertTrue(r.place is p)
p = Place.objects.get(name="Demon Dogs") r = Restaurant(place_id=p.id) self.assertIsNot(r.place, p) self.assertEqual(r.place, p)
r = Restaurant.objects.get(pk=self.r1.pk) p = r.place with self.assertNumQueries(0): self.assertEqual(p.restaurant, r)
p = Place.objects.get(pk=self.p1.pk) r = p.restaurant with self.assertNumQueries(0): self.assertEqual(r.place, p)
with self.assertNumQueries(0): with self.assertRaises(UndergroundBar.DoesNotExist): p.undergroundbar
with self.assertNumQueries(0): with self.assertRaises(UndergroundBar.DoesNotExist): p.undergroundbar
if connection.features.supports_nullable_unique_constraints: UndergroundBar.objects.create()
with self.assertNumQueries(0): with self.assertRaises(UndergroundBar.DoesNotExist): p.undergroundbar
p.undergroundbar = b
msg = "save() prohibited to prevent data loss due to unsaved related object 'place'." with self.assertNumQueries(0): with self.assertRaisesMessage(ValueError, msg): b.save()
self.assertQuerysetEqual( School.objects.all(), ["<School: School object>"] )
self.assertQuerysetEqual( Director.objects.all(), ["<Director: Director object>"] )
self.assertEqual(private_director.school, private_school)
self.assertEqual(private_school.director, private_director)
School._default_manager.use_for_related_fields = True try: private_director = Director._base_manager.get(pk=private_director.pk) with self.assertRaises(School.DoesNotExist): private_director.school finally: School._default_manager.use_for_related_fields = False
self.assertFalse(hasattr(Director(), 'director')) self.assertFalse(hasattr(School(), 'school'))
q2 = Restaurant.objects.filter(place_id__in=q1) self.assertQuerysetEqual(q2, [r], lambda x: x) q2 = Restaurant.objects.filter( pk__in=Restaurant.objects.filter(place__id=r.place.pk) ) self.assertQuerysetEqual(q2, [r], lambda x: x)
managed = True
@python_2_unicode_compatible class C02(models.Model): mm_a = models.ManyToManyField(A02, through="Intermediate") f_a = models.CharField(max_length=10, db_index=True) f_b = models.IntegerField()
class Proxy1(models.Model): class Meta: db_table = "unmanaged_models_proxy1"
class Unmanaged2(models.Model): mm = models.ManyToManyField(Unmanaged1)
class Managed1(models.Model): mm = models.ManyToManyField(Unmanaged1)
a = A01.objects.create(f_a="foo", f_b=42) B01.objects.create(fk_a=a, f_a="fred", f_b=1729) c = C01.objects.create(f_a="barney", f_b=1) c.mm_a.set([a])
a2 = A02.objects.all()[0] self.assertIsInstance(a2, A02) self.assertEqual(a2.f_a, "foo")
from functools import partial from os import path
url(r'^non_existing_url/', partial(defaults.page_not_found, exception=None)), url(r'^server_error/', defaults.server_error),
url(r'raises/$', views.raises),
url(r'^old_jsi18n/$', i18n.javascript_catalog, js_info_dict), url(r'^old_jsi18n/app1/$', i18n.javascript_catalog, js_info_dict_app1), url(r'^old_jsi18n/app2/$', i18n.javascript_catalog, js_info_dict_app2), url(r'^old_jsi18n/app5/$', i18n.javascript_catalog, js_info_dict_app5), url(r'^old_jsi18n_english_translation/$', i18n.javascript_catalog, js_info_dict_english_translation), url(r'^old_jsi18n_multi_packages1/$', i18n.javascript_catalog, js_info_dict_multi_packages1), url(r'^old_jsi18n_multi_packages2/$', i18n.javascript_catalog, js_info_dict_multi_packages2), url(r'^old_jsi18n_admin/$', i18n.javascript_catalog, js_info_dict_admin), url(r'^old_jsi18n_template/$', views.old_jsi18n), url(r'^old_jsi18n_multi_catalogs/$', views.old_jsi18n_multi_catalogs), url(r'^old_jsoni18n/$', i18n.json_catalog, js_info_dict),
url(r'^i18n/', include('django.conf.urls.i18n')), url(r'^jsi18n/$', i18n.JavaScriptCatalog.as_view(packages=['view_tests'])), url(r'^jsi18n/app1/$', i18n.JavaScriptCatalog.as_view(packages=['view_tests.app1'])), url(r'^jsi18n/app2/$', i18n.JavaScriptCatalog.as_view(packages=['view_tests.app2'])), url(r'^jsi18n/app5/$', i18n.JavaScriptCatalog.as_view(packages=['view_tests.app5'])), url(r'^jsi18n_english_translation/$', i18n.JavaScriptCatalog.as_view(packages=['view_tests.app0'])), url(r'^jsi18n_multi_packages1/$', i18n.JavaScriptCatalog.as_view(packages=['view_tests.app1', 'view_tests.app2'])), url(r'^jsi18n_multi_packages2/$', i18n.JavaScriptCatalog.as_view(packages=['view_tests.app3', 'view_tests.app4'])), url(r'^jsi18n_admin/$', i18n.JavaScriptCatalog.as_view(packages=['django.contrib.admin', 'view_tests'])), url(r'^jsi18n_template/$', views.jsi18n), url(r'^jsi18n_multi_catalogs/$', views.jsi18n_multi_catalogs), url(r'^jsoni18n/$', i18n.JSONCatalog.as_view(packages=['view_tests'])),
url(r'^site_media/(?P<path>.*)$', static.serve, {'document_root': media_dir}),
from __future__ import unicode_literals
from __future__ import unicode_literals
url('^/target/$', views.index_page),
urlpatterns += [ url('^nonascii_redirect/$', RedirectView.as_view( url='//target/', permanent=False)), url('^permanent_nonascii_redirect/$', RedirectView.as_view( url='//target/', permanent=True)), ]
urlpatterns += [ url(r'^json/response/$', views.json_response_view), ]
def callable(): raise Exception try: raise Exception except Exception: return technical_500_response(request, *sys.exc_info())
try: raise Exception except Exception: return technical_500_response(request, *sys.exc_info())
try: return render(request, path) except TemplateDoesNotExist: return technical_500_response(request, *sys.exc_info())
return render(request, [], {})
admin_email_handler = [ h for h in logger.handlers if h.__class__.__name__ == "AdminEmailHandler" ][0] orig_filters = admin_email_handler.filters admin_email_handler.filters = [] admin_email_handler.include_html = True logger.error( 'Internal Server Error: %s', request.path, exc_info=exc_info, extra={'status_code': 500, 'request': request}, ) admin_email_handler.filters = orig_filters
'timestamp': datetime.datetime(2013, 5, 19, 20), 'value': decimal.Decimal('3.14'),
from __future__ import unicode_literals
self.assertContains(response, json.dumps(trans_txt), 1) if lang_code == 'fr': self.assertContains(response, '"month name\\u0004May": "mai"', 1)
response = self.client.get('/old_jsi18n_admin/?language=de') self.assertContains(response, '\\x04')
available_apps = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'view_tests', ]
for url in self.non_existing_urls: response = self.client.get(url) self.assertNotEqual(response.content, 'NOTPROVIDED') self.assertNotEqual(response.content, '')
from __future__ import unicode_literals
test_settings = dict( MIDDLEWARE=['django.middleware.common.CommonMiddleware'], LANGUAGE_COOKIE_NAME='mylanguage', LANGUAGE_COOKIE_AGE=3600 * 7 * 2, LANGUAGE_COOKIE_DOMAIN='.example.com', LANGUAGE_COOKIE_PATH='/test/', ) with self.settings(**test_settings): post_data = dict(language='pl', next='/views/') response = self.client.post('/i18n/setlang/', data=post_data) language_cookie = response.cookies.get('mylanguage') self.assertEqual(language_cookie.value, 'pl') self.assertEqual(language_cookie['domain'], '.example.com') self.assertEqual(language_cookie['path'], '/test/') self.assertEqual(language_cookie['max-age'], 3600 * 7 * 2)
test_settings = dict( MIDDLEWARE=None, MIDDLEWARE_CLASSES=['django.middleware.common.CommonMiddleware'], LANGUAGE_COOKIE_NAME='mylanguage', LANGUAGE_COOKIE_AGE=3600 * 7 * 2, LANGUAGE_COOKIE_DOMAIN='.example.com', LANGUAGE_COOKIE_PATH='/test/', ) with self.settings(**test_settings): post_data = dict(language='pl', next='/views/') response = self.client.post('/i18n/setlang/', data=post_data) language_cookie = response.cookies.get('mylanguage') self.assertEqual(language_cookie.value, 'pl') self.assertEqual(language_cookie['domain'], '.example.com') self.assertEqual(language_cookie['path'], '/test/') self.assertEqual(language_cookie['max-age'], 3600 * 7 * 2)
self.assertEqual(reverse('with_parameter', kwargs={'parameter': 'x'}), '/test-setlang/x/') lang_code = self._get_inactive_language_code()
response = self.client.post( '/i18n/setlang/', data={'language': 'en'}, follow=True, HTTP_REFERER='/nl/vertaald/' ) self.assertRedirects(response, '/en/translated/')
response = self.client.post( '/i18n/setlang/', data={'language': 'en'}, follow=True, HTTP_REFERER='/nl/vertaald/' ) self.assertRedirects(response, '/en/translated/')
self.assertContains(response, json.dumps(trans_txt), 1) if lang_code == 'fr': self.assertContains(response, '"month name\\u0004May": "mai"', 1)
self.assertContains(response, 'django.pluralidx = function(count) { return (count == 1) ? 0 : 1; };') self.assertNotContains(response, 'var newcatalog =')
response = self.client.get('/jsi18n_admin/?language=de') self.assertContains(response, '\\x04')
available_apps = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'view_tests', ]
self.assertEqual(len(second_chunk.strip()), 1449)
) self.assertIsInstance(response, HttpResponseNotModified)
from __future__ import unicode_literals
response = self.client.get('/raises400/') self.assertContains(response, '<div class="context" id="', status_code=400)
@override_settings(TEMPLATES=[{ 'BACKEND': 'django.template.backends.django.DjangoTemplates', }]) def test_403(self): response = self.client.get('/raises403/') self.assertContains(response, '<h1>403 Forbidden</h1>', status_code=403)
@override_settings(TEMPLATES=[{ 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'OPTIONS': { 'loaders': [ ('django.template.loaders.locmem.Loader', { '403.html': 'This is a test template for a 403 error ({{ exception }}).', }), ], }, }]) def test_403_template(self): response = self.client.get('/raises403/') self.assertContains(response, 'test template', status_code=403) self.assertContains(response, '(Insufficient Permissions).', status_code=403)
self.assertContains(response, '<div class="context" id="', status_code=500) match = re.search(b'<div class="context" id="(?P<id>[^"]+)">', response.content) self.assertIsNotNone(match) id_repr = match.group('id') self.assertFalse( re.search(b'[^c0-9]', id_repr), "Numeric IDs in debug response HTML page shouldn't be localized (value: %s)." % id_repr )
allow_database_queries = True
TEMPLATES=[{ 'BACKEND': 'django.template.backends.dummy.TemplateStrings', }],
response = self.client.get('/raises400/') self.assertContains(response, '<div class="context" id="', status_code=400)
url = reverse('raises_template_does_not_exist', kwargs={"path": "notfound.html"}) response = self.client.get(url) self.assertContains(response, '<div class="context" id="', status_code=500)
self.assertContains(response, 'cooked_eggs', status_code=500) self.assertContains(response, 'scrambled', status_code=500) self.assertContains(response, 'sauce', status_code=500) self.assertContains(response, 'worcestershire', status_code=500)
self.assertContains(response, k, status_code=500) self.assertContains(response, v, status_code=500)
self.assertContains(response, 'cooked_eggs', status_code=500) self.assertContains(response, 'scrambled', status_code=500) self.assertContains(response, 'sauce', status_code=500) self.assertNotContains(response, 'worcestershire', status_code=500)
self.assertContains(response, k, status_code=500)
self.assertNotContains(response, 'sausage-value', status_code=500) self.assertNotContains(response, 'bacon-value', status_code=500)
self.assertContains(response, 'cooked_eggs', status_code=500) self.assertNotContains(response, 'scrambled', status_code=500) self.assertContains(response, 'sauce', status_code=500) self.assertNotContains(response, 'worcestershire', status_code=500)
self.assertContains(response, k, status_code=500) self.assertNotContains(response, v, status_code=500)
body_plain = force_text(email.body) self.assertNotIn('cooked_eggs', body_plain) self.assertNotIn('scrambled', body_plain) self.assertNotIn('sauce', body_plain) self.assertNotIn('worcestershire', body_plain)
body_html = force_text(email.alternatives[0][0]) self.assertIn('cooked_eggs', body_html) self.assertIn('scrambled', body_html) self.assertIn('sauce', body_html) self.assertIn('worcestershire', body_html)
self.assertIn(k, body_plain) self.assertIn(v, body_plain) self.assertIn(k, body_html) self.assertIn(v, body_html)
body_plain = force_text(email.body) self.assertNotIn('cooked_eggs', body_plain) self.assertNotIn('scrambled', body_plain) self.assertNotIn('sauce', body_plain) self.assertNotIn('worcestershire', body_plain)
body_html = force_text(email.alternatives[0][0]) self.assertIn('cooked_eggs', body_html) self.assertIn('scrambled', body_html) self.assertIn('sauce', body_html) self.assertNotIn('worcestershire', body_html)
self.assertIn(k, body_plain)
self.assertNotIn('sausage-value', body_plain) self.assertNotIn('bacon-value', body_plain) self.assertNotIn('sausage-value', body_html) self.assertNotIn('bacon-value', body_html)
body = force_text(email.body) self.assertNotIn('cooked_eggs', body) self.assertNotIn('scrambled', body) self.assertNotIn('sauce', body) self.assertNotIn('worcestershire', body) for k, v in self.breakfast_data.items(): self.assertIn(k, body) self.assertNotIn(v, body)
exc_type, exc_value, tb = sys.exc_info()
self.assertEqual(2, html.count(explicit_exc.format("Top level"))) self.assertEqual(2, html.count(implicit_exc.format("Second exception")))
from __future__ import unicode_literals
from __future__ import unicode_literals
url(r'^admin/', admin.site.urls),
def test_not(self): var = IfParser(["not", False]).parse() self.assertEqual("(not (literal False))", repr(var)) self.assertTrue(var.eval({}))
self.assertCalcEqual(True, [False, 'and', False, 'or', True])
self.assertCalcEqual(True, [True, 'or', False, 'and', False])
self.assertCalcEqual(True, [1, 'or', 1, '==', 2])
from __future__ import unicode_literals
c = Context({'name': "Jack & Jill"}) t = self.engine.from_string("{% load custom %}{% escape_explicit %}") self.assertEqual(t.render(c), "Hello Jack &amp; Jill!")
c = Context({'name': "Jack & Jill"}) t = self.engine.from_string("{% load custom %}{% escape_format_html %}") self.assertEqual(t.render(c), "Hello Jack &amp; Jill!")
self.verify_tag(custom.no_params, 'no_params') self.verify_tag(custom.one_param, 'one_param') self.verify_tag(custom.explicit_no_context, 'explicit_no_context') self.verify_tag(custom.no_params_with_context, 'no_params_with_context') self.verify_tag(custom.params_and_context, 'params_and_context') self.verify_tag(custom.simple_unlimited_args_kwargs, 'simple_unlimited_args_kwargs') self.verify_tag(custom.simple_tag_without_context_parameter, 'simple_tag_without_context_parameter')
msg = ( "'simple_tag_without_context_parameter' is decorated with " "takes_context=True so it must have a first argument of 'context'" ) with self.assertRaisesMessage(TemplateSyntaxError, msg): self.engine.from_string('{% load custom %}{% simple_tag_without_context_parameter 123 %}')
msg = ( "'inclusion_tag_without_context_parameter' is decorated with " "takes_context=True so it must have a first argument of 'context'" ) with self.assertRaisesMessage(TemplateSyntaxError, msg): self.engine.from_string('{% load inclusion %}{% inclusion_tag_without_context_parameter 123 %}')
self.verify_tag(inclusion.inclusion_no_params, 'inclusion_no_params') self.verify_tag(inclusion.inclusion_one_param, 'inclusion_one_param') self.verify_tag(inclusion.inclusion_explicit_no_context, 'inclusion_explicit_no_context') self.verify_tag(inclusion.inclusion_no_params_with_context, 'inclusion_no_params_with_context') self.verify_tag(inclusion.inclusion_params_and_context, 'inclusion_params_and_context') self.verify_tag(inclusion.inclusion_two_params, 'inclusion_two_params') self.verify_tag(inclusion.inclusion_one_default, 'inclusion_one_default') self.verify_tag(inclusion.inclusion_unlimited_args, 'inclusion_unlimited_args') self.verify_tag(inclusion.inclusion_only_unlimited_args, 'inclusion_only_unlimited_args') self.verify_tag(inclusion.inclusion_tag_without_context_parameter, 'inclusion_tag_without_context_parameter') self.verify_tag(inclusion.inclusion_tag_use_l10n, 'inclusion_tag_use_l10n') self.verify_tag(inclusion.inclusion_unlimited_args_kwargs, 'inclusion_unlimited_args_kwargs')
self.verify_tag(custom.assignment_no_params, 'assignment_no_params')
msg = ( "'assignment_tag_without_context_parameter' is decorated with " "takes_context=True so it must have a first argument of 'context'" ) with self.assertRaisesMessage(TemplateSyntaxError, msg): self.engine.from_string('{% load custom %}{% assignment_tag_without_context_parameter 123 as var %}')
class CustomURLConfMiddleware(MiddlewareMixin): def process_request(self, request): request.urlconf = 'template_tests.alternate_urls'
response = self._response() self.assertFalse(response.is_rendered) response.render() self.assertTrue(response.is_rendered)
response = self._response().render() self.assertEqual(response.content, b'foo')
template = engines['django'].from_string('bar{{ baz }}') response.template_name = template response.render() self.assertEqual(response.content, b'foo')
response.content = 'bar' self.assertEqual(response.content, b'bar')
response = self._response() self.assertFalse(response.is_rendered)
response = self._response().render() res = [x for x in response] self.assertEqual(res, [b'foo'])
response = self._response() self.assertFalse(response.is_rendered) with self.assertRaises(ContentNotRenderedError): response.content self.assertFalse(response.is_rendered)
response = self._response().render() self.assertEqual(response.content, b'foo')
response = self._response() self.assertFalse(response.is_rendered) response.content = 'spam' self.assertTrue(response.is_rendered) self.assertEqual(response.content, b'spam') response.content = 'baz' self.assertEqual(response.content, b'baz')
response.render() self.assertEqual(response.content, b'First template\n') self.assertEqual(post, ['post1', 'post2'])
response = SimpleTemplateResponse('first/test.html', { 'value': 123, 'fn': datetime.now, }) with self.assertRaises(ContentNotRenderedError): pickle.dumps(response)
response.render() pickled_response = pickle.dumps(response) unpickled_response = pickle.loads(pickled_response)
template_attrs = ('template_name', 'context_data', '_post_render_callbacks') for attr in template_attrs: self.assertFalse(hasattr(unpickled_response, attr))
for attr in template_attrs: with self.assertRaises(AttributeError): getattr(unpickled_response, attr)
response = self._response('{{ foo }}{{ processors }}', {'processors': 'no'}).render() self.assertEqual(response.content, b'no')
response = TemplateResponse( self.factory.get('/'), 'first/test.html', { 'value': 123, 'fn': datetime.now, } ) with self.assertRaises(ContentNotRenderedError): pickle.dumps(response)
response.render() pickled_response = pickle.dumps(response) unpickled_response = pickle.loads(pickled_response)
template_attrs = ( 'template_name', 'context_data', '_post_render_callbacks', '_request', ) for attr in template_attrs: self.assertFalse(hasattr(unpickled_response, attr))
for attr in template_attrs: with self.assertRaises(AttributeError): getattr(unpickled_response, attr)
response2 = self.client.get('/template_response_view/') self.assertEqual(response2.status_code, 200)
response2 = self.client.get('/template_response_view/') self.assertEqual(response2.status_code, 200)
from __future__ import unicode_literals
url(r'^$', views.index, name='index'), url(r'^client/([0-9,]+)/$', views.client, name='client'), url(r'^client/(?P<id>[0-9]+)/(?P<action>[^/]+)/$', views.client_action, name='client_action'), url(r'^client/(?P<client_id>[0-9]+)/(?P<action>[^/]+)/$', views.client_action, name='client_action'), url(r'^named-client/([0-9]+)/$', views.client2, name="named.client"),
url(r'^/(\w+)/$', views.client2, name="_"), url(r'^/(?P<tag>\S+)/$', views.client2, name="__2"),
url(r'ns1/', include((ns_patterns, 'app'), 'ns1')), url(r'ns2/', include((ns_patterns, 'app'))),
from __future__ import unicode_literals
engine = Engine() t1 = engine.from_string(' {{ var }}') s = b'\xc5\xa0\xc4\x90\xc4\x86\xc5\xbd\xc4\x87\xc5\xbe\xc5\xa1\xc4\x91 {{ var }}' t2 = engine.from_string(s) with self.assertRaises(TemplateEncodingError): engine.from_string(b'\x80\xc5\xc0')
Context({b"var": b"foo"}) Context({"var": b"foo"}) c3 = Context({b"var": ""}) Context({"var": b"\xc4\x90\xc4\x91"})
self.assertEqual(t1.render(c3), t2.render(c3)) self.assertIsInstance(t1.render(c3), six.text_type) self.assertIsInstance(t1.render(c3), SafeData)
from django.http import HttpResponse from django.template.response import TemplateResponse
@setup({'namedendblocks02': '1{% block first %}_{% block second %}' '2{% endblock first %}_{% endblock second %}3'}) def test_namedendblocks02(self): with self.assertRaises(TemplateSyntaxError): self.engine.get_template('namedendblocks02')
def gen(): yield 1 yield 2 iter2 = iter([1, 2, 3]) output2 = template.render(Context({'foo': range(3), 'get_value': lambda: next(iter2)})) self.assertEqual( output2, '[0,1,2,3]', 'Expected [0,1,2,3] in second parallel template, got {}'.format(output2) ) yield 3
@setup({ 'autoescape-tag04': '{% autoescape off %}{{ first }} {% autoescape on %}{{ first }}{% endautoescape %}{% endautoescape %}' }) def test_autoescape_tag04(self): output = self.engine.render_to_string('autoescape-tag04', {'first': '<a>'}) self.assertEqual(output, '<a> &lt;a&gt;')
@setup({'autoescape-tag06': '{{ first }}'}) def test_autoescape_tag06(self): output = self.engine.render_to_string('autoescape-tag06', {'first': mark_safe('<b>first</b>')}) self.assertEqual(output, '<b>first</b>')
@setup({'autoescape-tag09': r'{{ unsafe }}'}) def test_autoescape_tag09(self): output = self.engine.render_to_string('autoescape-tag09', {'unsafe': UnsafeClass()}) self.assertEqual(output, 'you &amp; me')
@setup({'autoescape-filters01': '{{ var|cut:"&" }}'}) def test_autoescape_filters01(self): output = self.engine.render_to_string('autoescape-filters01', {'var': 'this & that'}) self.assertEqual(output, 'this that')
from django.template import RequestContext, TemplateSyntaxError from django.test import RequestFactory, SimpleTestCase, override_settings from django.urls import NoReverseMatch, resolve
@setup({'url01': '{% url "client" client.id %}'}) def test_url01(self): output = self.engine.render_to_string('url01', {'client': {'id': 1}}) self.assertEqual(output, '/client/1/')
@setup({'url-fail01': '{% url %}'}) def test_url_fail01(self): with self.assertRaises(TemplateSyntaxError): self.engine.get_template('url-fail01')
@setup({'url-asvar01': '{% url "index" as url %}'}) def test_url_asvar01(self): output = self.engine.render_to_string('url-asvar01') self.assertEqual(output, '')
@setup({'if-tag-filter01': '{% if foo|length == 5 %}yes{% else %}no{% endif %}'}) def test_if_tag_filter01(self): output = self.engine.render_to_string('if-tag-filter01', {'foo': 'abcde'}) self.assertEqual(output, 'yes')
@setup({'if-tag-eq01': '{% if foo == bar %}yes{% else %}no{% endif %}'}) def test_if_tag_eq01(self): output = self.engine.render_to_string('if-tag-eq01') self.assertEqual(output, 'yes')
@setup({'if-tag-noteq01': '{% if foo != bar %}yes{% else %}no{% endif %}'}) def test_if_tag_noteq01(self): output = self.engine.render_to_string('if-tag-noteq01') self.assertEqual(output, 'no')
@setup({'if-tag-gt-01': '{% if 2 > 1 %}yes{% else %}no{% endif %}'}) def test_if_tag_gt_01(self): output = self.engine.render_to_string('if-tag-gt-01') self.assertEqual(output, 'yes')
@setup({'if-tag-in-01': '{% if 1 in x %}yes{% else %}no{% endif %}'}) def test_if_tag_in_01(self): output = self.engine.render_to_string('if-tag-in-01', {'x': [1]}) self.assertEqual(output, 'yes')
@setup({'if-tag-and01': '{% if foo and bar %}yes{% else %}no{% endif %}'}) def test_if_tag_and01(self): output = self.engine.render_to_string('if-tag-and01', {'foo': True, 'bar': True}) self.assertEqual(output, 'yes')
@setup({'if-tag-or01': '{% if foo or bar %}yes{% else %}no{% endif %}'}) def test_if_tag_or01(self): output = self.engine.render_to_string('if-tag-or01', {'foo': True, 'bar': True}) self.assertEqual(output, 'yes')
@setup({'if-tag-not01': '{% if not foo %}no{% else %}yes{% endif %}'}) def test_if_tag_not01(self): output = self.engine.render_to_string('if-tag-not01', {'foo': True}) self.assertEqual(output, 'yes')
@setup({'if-tag-error01': '{% if %}yes{% endif %}'}) def test_if_tag_error01(self): with self.assertRaises(TemplateSyntaxError): self.engine.get_template('if-tag-error01')
with self.assertRaises(TemplateSyntaxError): self.engine.render_to_string('if-tag-single-eq', {'foo': 1})
output = self.engine.render_to_string('template', {'foo': False}) self.assertEqual(output, 'yes')
@setup({'widthratio08': '{% widthratio %}'}) def test_widthratio08(self): with self.assertRaises(TemplateSyntaxError): self.engine.get_template('widthratio08')
@setup({'widthratio12a': '{% widthratio a b c %}'}) def test_widthratio12a(self): output = self.engine.render_to_string('widthratio12a', {'a': 'a', 'c': 100, 'b': 100}) self.assertEqual(output, '')
@setup({'widthratio16': '{% widthratio a b 100 as variable %}-{{ variable }}-'}) def test_widthratio16(self): output = self.engine.render_to_string('widthratio16', {'a': 50, 'b': 100}) self.assertEqual(output, '-50-')
from __future__ import unicode_literals
@setup({'i18n28_2': '{% load i18n %}' '{% get_language_info for "de" as l %}' '{{ l.code }}: {{ l.name }}/{{ l.name_local }} bidi={{ l.bidi }}'}) def test_i18n28_2(self): output = self.engine.render_to_string('i18n28_2') self.assertEqual(output, 'de: German/Deutsch bidi=False')
@setup({'i18n34': '{% load i18n %}{% blocktrans %}{{ missing }}{% endblocktrans %}'}) def test_i18n34(self): output = self.engine.render_to_string('i18n34') if self.engine.string_if_invalid: self.assertEqual(output, 'INVALID') else: self.assertEqual(output, '')
@setup({'i18n35': '{% load i18n %}{% trans "Page not found" as page_not_found %}{{ page_not_found }}'}) def test_i18n35(self): with translation.override('de'): output = self.engine.render_to_string('i18n35') self.assertEqual(output, 'Seite nicht gefunden')
@setup({'i18n38': '{% load i18n custom %}' '{% get_language_info for "de"|noop:"x y" as l %}' '{{ l.code }}: {{ l.name }}/{{ l.name_local }}/' '{{ l.name_translated }} bidi={{ l.bidi }}'}) def test_i18n38(self): with translation.override('cs'): output = self.engine.render_to_string('i18n38') self.assertEqual(output, 'de: German/Deutsch/nmecky bidi=False')
@setup({'i18n39': '{% load i18n %}' '{% blocktrans asvar page_not_found %}Page not found{% endblocktrans %}' '>{{ page_not_found }}<'}) def test_i18n39(self): with translation.override('de'): output = self.engine.render_to_string('i18n39') self.assertEqual(output, '>Seite nicht gefunden<')
from __future__ import unicode_literals
@setup({'now02': '{% now "DATE_FORMAT" %}'}) def test_now02(self): output = self.engine.render_to_string('now02') self.assertEqual(output, date_format(datetime.now()))
@setup({'load03': '{% load echo from testtags %}{% echo this that theother %}'}) def test_load03(self): output = self.engine.render_to_string('load03') self.assertEqual(output, 'this that theother')
@setup({'load07': '{% load echo other_echo bad_tag from testtags %}'}) def test_load07(self): msg = "'bad_tag' is not a valid tag or filter in tag library 'testtags'" with self.assertRaisesMessage(TemplateSyntaxError, msg): self.engine.get_template('load07')
@setup({'regroup05': '{% regroup data by bar as %}'}) def test_regroup05(self): with self.assertRaises(TemplateSyntaxError): self.engine.get_template('regroup05')
@setup(inheritance_templates) def test_inheritance31(self): output = self.engine.render_to_string('inheritance31', {'optional': True}) self.assertEqual(output, '1two3')
@setup(inheritance_templates) def test_inheritance39(self): output = self.engine.render_to_string('inheritance39', {'optional': True}) self.assertEqual(output, '1new23')
warnings.filterwarnings( "ignore", "Using a non-integer number instead of an " "integer will result in an error in the future", DeprecationWarning )
@setup({'ifequal-split01': '{% ifequal a "test man" %}yes{% else %}no{% endifequal %}'}) def test_ifequal_split01(self): output = self.engine.render_to_string('ifequal-split01') self.assertEqual(output, 'no')
@setup({'ifequal-numeric01': '{% ifequal x 5 %}yes{% endifequal %}'}) def test_ifequal_numeric01(self): output = self.engine.render_to_string('ifequal-numeric01', {'x': '5'}) self.assertEqual(output, '')
@setup({'ifequal-filter01': '{% ifequal a|upper "A" %}x{% endifequal %}'}) def test_ifequal_filter01(self): output = self.engine.render_to_string('ifequal-filter01', {'a': 'a'}) self.assertEqual(output, 'x')
@setup({'basic-syntax13': "{{ va>r }}"}) def test_basic_syntax13(self): with self.assertRaises(TemplateSyntaxError): self.engine.get_template('basic-syntax13')
@setup({'basic-syntax21': "a {{ moo %} b"}) def test_basic_syntax21(self): output = self.engine.render_to_string('basic-syntax21') self.assertEqual(output, "a {{ moo %} b")
@setup({'basic-syntax25': '{{ "fred" }}'}) def test_basic_syntax25(self): output = self.engine.render_to_string('basic-syntax25') self.assertEqual(output, "fred")
@setup({'basic-syntax28': "{{ a.b }}"}) def test_basic_syntax28(self): output = self.engine.render_to_string('basic-syntax28', {'a': SilentGetItemClass()}) if self.engine.string_if_invalid: self.assertEqual(output, 'INVALID') else: self.assertEqual(output, '')
@setup({'basic-syntax30': "{{ 1.2.3 }}"}) def test_basic_syntax30(self): output = self.engine.render_to_string( 'basic-syntax30', {"1": {"2": {"3": "d"}}} ) self.assertEqual(output, 'd')
@setup({'basic-syntax35': "{{ 1 }}"}) def test_basic_syntax35(self): output = self.engine.render_to_string('basic-syntax35', {"1": "abc"}) self.assertEqual(output, '1')
@setup({'cache11': '{% load cache %}{% cache %}{% endcache %}'}) def test_cache11(self): with self.assertRaises(TemplateSyntaxError): self.engine.get_template('cache11')
@setup({'include-error01': '{% include "basic-syntax01" with %}'}) def test_include_error01(self): with self.assertRaises(TemplateSyntaxError): self.engine.get_template('include-error01')
template = engine.get_template('test_extends_error.html') with self.assertRaises(TemplateDoesNotExist) as e: template.render(Context()) self.assertEqual(e.exception.args[0], 'missing.html')
sorted_kwarg = sorted(six.iteritems(kwargs), key=operator.itemgetter(0)) return "simple_unlimited_args_kwargs - Expected result: %s / %s" % ( ', '.join(six.text_type(arg) for arg in [one, two] + list(args)), ', '.join('%s=%s' % (k, v) for (k, v) in sorted_kwarg) )
sorted_kwarg = sorted(six.iteritems(kwargs), key=operator.itemgetter(0)) return {"result": "inclusion_unlimited_args_kwargs - Expected result: %s / %s" % ( ', '.join(six.text_type(arg) for arg in [one, two] + list(args)), ', '.join('%s=%s' % (k, v) for (k, v) in sorted_kwarg) )}
with self.assertRaises(TemplateSyntaxError): FilterExpression("article._hidden|upper", p)
self.assertEqual(Variable("_(article.section)").resolve(c), "News") self.assertEqual(Variable('_("Good News")').resolve(c), "Good News") self.assertEqual(Variable("_('Better News')").resolve(c), "Better News")
self.assertEqual( Variable(r'"Some \"Good\" News"').resolve(c), 'Some "Good" News' ) self.assertEqual( Variable(r"'Some \'Better\' News'").resolve(c), "Some 'Better' News" )
with self.assertRaises(TemplateSyntaxError): Variable("article._hidden")
with six.assertRaisesRegex(self, TypeError, "Variable must be a string or number, got <(class|type) 'dict'>"): Variable({})
'1|no_arguments', '1|one_argument:"1"', '1|one_opt_argument', '1|one_opt_argument:"1"', '1|two_one_opt_arg:"1"',
template = engine.get_template('other-recursive.html') output = template.render(Context({})) self.assertEqual(output.strip(), 'fs3/recursive fs2/recursive fs/recursive')
self.assertEqual(len(cache), 4) expected_path = os.path.join('fs', 'other-recursive.html') self.assertTrue(cache['other-recursive.html'].origin.name.endswith(expected_path))
output = engine.render_to_string('index.html') self.assertEqual(output, 'base')
t = self.engine.from_string('{{ my_doodad.value }}') self.assertEqual(t.render(c), '')
self.assertEqual(my_doodad.num_calls, 1)
t = self.engine.from_string('{{ my_doodad.the_value }}') self.assertEqual(t.render(c), '42') self.assertEqual(my_doodad.num_calls, 2)
t = self.engine.from_string('{{ my_doodad.value }}') self.assertEqual(t.render(c), '') t = self.engine.from_string('{{ my_doodad.the_value }}') self.assertEqual(t.render(c), '')
self.assertEqual(my_doodad.num_calls, 0)
t = self.engine.from_string('{{ my_doodad.value }}') self.assertEqual(t.render(c), '42') t = self.engine.from_string('{{ my_doodad.the_value }}') self.assertEqual(t.render(c), '')
self.assertEqual(my_doodad.num_calls, 0)
self.assertEqual(my_doodad.num_calls, 0)
from __future__ import unicode_literals
template = self.engine.get_template('index.html') self.assertEqual(template.origin.name, os.path.join(TEMPLATE_DIR, 'index.html')) self.assertEqual(template.origin.template_name, 'index.html') self.assertEqual(template.origin.loader, self.engine.template_loaders[0].loaders[0])
loader = self.engine.template_loaders[0] source, name = loader.load_template('index.html') self.assertEqual(template.origin.template_name, 'index.html')
with self.assertRaises(TemplateDoesNotExist): loader.find_template(template_name)
t1, name = self.engine.find_template('test.html', (os.path.join(TEMPLATE_DIR, 'first'),)) t2, name = self.engine.find_template('test.html', (os.path.join(TEMPLATE_DIR, 'second'),))
self.assertNotEqual(t1.render(Context({})), t2.render(Context({})))
check_sources(b'\xc3\x85ngstr\xc3\xb6m', ['/dir1/ngstrm', '/dir2/ngstrm']) check_sources('ngstrm', ['/dir1/ngstrm', '/dir2/ngstrm'])
test_once = kwargs.get('test_once', False)
templates["inclusion.html"] = "{{ result }}"
@override_settings(TEMPLATES=None) @functools.wraps(func) def inner(self): libraries = getattr(self, 'libraries', {})
@python_2_unicode_compatible class UnsafeClass: def __str__(self): return 'you & me'
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
self.assertEqual(upper('\xeb'), '\xcb')
@setup({'length06': '{{ int|length }}'}) def test_length06(self): output = self.engine.render_to_string('length06', {'int': 7}) self.assertEqual(output, '0')
@setup({'chaining03': '{{ a|cut:"b"|capfirst }}.{{ b|cut:"b"|capfirst }}'}) def test_chaining03(self): output = self.engine.render_to_string('chaining03', {'a': 'a < b', 'b': mark_safe('a < b')}) self.assertEqual(output, 'A &lt; .A < ')
@setup({'chaining05': '{{ a|escape|capfirst }}'}) def test_chaining05(self): reset_warning_registry() with warnings.catch_warnings(record=True) as warns: warnings.simplefilter('always') output = self.engine.render_to_string('chaining05', {'a': 'a < b'}) self.assertEqual(output, 'A &lt; b')
@setup({'chaining07': '{{ a|force_escape|cut:";" }}'}) def test_chaining07(self): output = self.engine.render_to_string('chaining07', {'a': 'a < b'}) self.assertEqual(output, 'a &amp;lt b')
@setup({'date04': '{{ d|date:"o" }}'}) def test_date04(self): output = self.engine.render_to_string('date04', {'d': datetime(2008, 12, 29)}) self.assertEqual(output, '2009')
@setup({'date06': '{{ d|date:"e" }}'}) def test_date06(self): output = self.engine.render_to_string( 'date06', {'d': datetime(2009, 3, 12, tzinfo=timezone.get_fixed_timezone(30))} ) self.assertEqual(output, '+0030')
@setup({'date08': '{{ t|date:"H:i" }}'}) def test_date08(self): output = self.engine.render_to_string('date08', {'t': time(0, 1)}) self.assertEqual(output, '00:01')
@setup({'timeuntil01': '{{ a|timeuntil }}'}) def test_timeuntil01(self): output = self.engine.render_to_string('timeuntil01', {'a': datetime.now() + timedelta(minutes=2, seconds=10)}) self.assertEqual(output, '2\xa0minutes')
@setup({'timeuntil04': '{{ a|timeuntil:b }}'}) def test_timeuntil04(self): output = self.engine.render_to_string( 'timeuntil04', {'a': self.now - timedelta(days=1), 'b': self.now - timedelta(days=2)}, ) self.assertEqual(output, '1\xa0day')
@setup({'timeuntil06': '{{ earlier|timeuntil }}'}) def test_timeuntil06(self): output = self.engine.render_to_string('timeuntil06', {'earlier': self.now - timedelta(days=7)}) self.assertEqual(output, '0\xa0minutes')
@requires_tz_support @setup({'timeuntil10': '{{ a|timeuntil }}'}) def test_timeuntil10(self): output = self.engine.render_to_string('timeuntil10', {'a': self.now_tz}) self.assertEqual(output, '0\xa0minutes')
@setup({'timeuntil13': '{{ a|timeuntil:b }}'}) def test_timeuntil13(self): output = self.engine.render_to_string('timeuntil13', {'a': self.today, 'b': self.today}) self.assertEqual(output, '0\xa0minutes')
from __future__ import unicode_literals
@setup({'cut05': '{% autoescape off %}{{ a|cut:";" }} {{ b|cut:";" }}{% endautoescape %}'}) def test_cut05(self): output = self.engine.render_to_string('cut05', {"a": "x&y", "b": mark_safe("x&amp;y")}) self.assertEqual(output, "x&y x&ampy")
from __future__ import unicode_literals
@ignore_warnings(category=RemovedInDjango20Warning) @setup({'force-escape05': '{% autoescape off %}{{ a|force_escape|escape }}{% endautoescape %}'}) def test_force_escape05(self): output = self.engine.render_to_string('force-escape05', {"a": "x&y"}) self.assertEqual(output, "x&amp;y")
from __future__ import unicode_literals
from __future__ import unicode_literals
@setup({'timesince01': '{{ a|timesince }}'}) def test_timesince01(self): output = self.engine.render_to_string( 'timesince01', {'a': datetime.now() + timedelta(minutes=-1, seconds=-10)} ) self.assertEqual(output, '1\xa0minute')
@setup({'timesince04': '{{ a|timesince:b }}'}) def test_timesince04(self): output = self.engine.render_to_string( 'timesince04', {'a': self.now - timedelta(days=2), 'b': self.now - timedelta(days=1)}, ) self.assertEqual(output, '1\xa0day')
@setup({'timesince06': '{{ a|timesince:b }}'}) def test_timesince06(self): output = self.engine.render_to_string('timesince06', {'a': self.now_tz - timedelta(hours=8), 'b': self.now_tz}) self.assertEqual(output, '8\xa0hours')
@setup({'timesince07': '{{ earlier|timesince }}'}) def test_timesince07(self): output = self.engine.render_to_string('timesince07', {'earlier': self.now - timedelta(days=7)}) self.assertEqual(output, '1\xa0week')
@setup({'timesince11': '{{ a|timesince }}'}) def test_timesince11(self): output = self.engine.render_to_string('timesince11', {'a': self.now}) self.assertEqual(output, '0\xa0minutes')
@setup({'timesince17': '{{ a|timesince:b }}'}) def test_timesince17(self): output = self.engine.render_to_string('timesince17', {'a': self.today, 'b': self.today}) self.assertEqual(output, '0\xa0minutes')
from __future__ import unicode_literals
@setup({'urlize05': '{% autoescape off %}{{ a|urlize }}{% endautoescape %}'}) def test_urlize05(self): output = self.engine.render_to_string('urlize05', {'a': "<script>alert('foo')</script>"}) self.assertEqual(output, "<script>alert('foo')</script>")
@setup({'urlize07': '{{ a|urlize }}'}) def test_urlize07(self): output = self.engine.render_to_string('urlize07', {'a': "Email me at me@example.com"}) self.assertEqual( output, 'Email me at <a href="mailto:me@example.com">me@example.com</a>', )
self.assertEqual( urlize('www.server.com"abc'), '<a href="http://www.server.com" rel="nofollow">www.server.com</a>&quot;abc', ) self.assertEqual( urlize('www.server.com\'abc'), '<a href="http://www.server.com" rel="nofollow">www.server.com</a>&#39;abc', ) self.assertEqual( urlize('www.server.com<abc'), '<a href="http://www.server.com" rel="nofollow">www.server.com</a>&lt;abc', ) self.assertEqual( urlize('www.server.com>abc'), '<a href="http://www.server.com" rel="nofollow">www.server.com</a>&gt;abc', )
@setup({'length_is07': '{% if "X"|length_is:0 %}Length is 0{% else %}Length not 0{% endif %}'}) def test_length_is07(self): output = self.engine.render_to_string('length_is07', {}) self.assertEqual(output, 'Length not 0')
@setup({'length_is09': '{{ var|length_is:"fish" }}'}) def test_length_is09(self): output = self.engine.render_to_string('length_is09', {'var': 'django'}) self.assertEqual(output, '')
from __future__ import unicode_literals
test_many_zeroes = expectedFailure(test_many_zeroes)
@ignore_warnings(category=RemovedInDjango20Warning) @setup({'escape03': '{% autoescape off %}{{ a|escape|escape }}{% endautoescape %}'}) def test_escape03(self): output = self.engine.render_to_string('escape03', {"a": "x&y"}) self.assertEqual(output, "x&amp;y")
from __future__ import unicode_literals
self.assertEqual(lower('\xcb'), '\xeb')
@setup({'join05': '{{ a|join:var }}'}) def test_join05(self): output = self.engine.render_to_string('join05', {'a': ['alpha', 'beta & me'], 'var': ' & '}) self.assertEqual(output, 'alpha &amp; beta &amp; me')
from __future__ import unicode_literals
import warnings
test_context.push()
a.update({'a': 1}) self.assertNotEqual(a, b)
a.update({'c': 3}) b.update({'c': 3}) self.assertNotEqual(a, b)
b.update({'a': 1}) self.assertEqual(a, b)
self.assertEqual(len(ctx.dicts), 4)
test_data = {'x': 'y', 'v': 'z', 'd': {'o': object, 'a': 'b'}}
request = RequestFactory().get('/')
url(r'^template_response_view/$', views.template_response_view),
url(r'^snark/', views.snark, name='snark'),
from __future__ import unicode_literals
from __future__ import unicode_literals
class Scene(models.Model): scene = models.CharField(max_length=255) setting = models.CharField(max_length=255)
if connection.vendor == 'postgresql' and connection.pg_version >= 90400: class JSONModel(models.Model): field = JSONField(blank=True, null=True) else: class JSONModel(object): pass
from __future__ import unicode_literals
from __future__ import unicode_literals
CreateExtension('uuid-ossp'), HStoreExtension(), TrigramExtension(), UnaccentExtension(),
from __future__ import unicode_literals
from __future__ import unicode_literals
from __future__ import unicode_literals
instance = IntegerArrayModel(field=['1']) instance.save() loaded = IntegerArrayModel.objects.get() self.assertEqual(loaded.field, [1])
self.assertSequenceEqual( CharArrayModel.objects.filter(field__contains=['text']), [] )
self.assertEqual(errors[0].id, 'postgres.E001') self.assertIn('max_length', errors[0].msg)
self.assertEqual(errors[0].id, 'postgres.E001') self.assertIn('max_length', errors[0].msg)
table_name = 'postgres_tests_integerarraydefaultmodel' with connection.cursor() as cursor: self.assertNotIn(table_name, connection.introspection.table_names(cursor)) call_command('migrate', 'postgres_tests', verbosity=0) with connection.cursor() as cursor: self.assertIn(table_name, connection.introspection.table_names(cursor)) call_command('migrate', 'postgres_tests', 'zero', verbosity=0) with connection.cursor() as cursor: self.assertNotIn(table_name, connection.introspection.table_names(cursor))
self.assertEqual(like_constraint_field_names, ['char2']) with connection.cursor() as cursor: indexes = connection.introspection.get_indexes(cursor, table_name) self.assertIn('char', indexes) self.assertIn('char2', indexes) self.assertIn('text', indexes) call_command('migrate', 'postgres_tests', 'zero', verbosity=0) with connection.cursor() as cursor: self.assertNotIn(table_name, connection.introspection.table_names(cursor))
field.clean([1, None], None)
form = JsonForm({'name': 'xyz', 'jfield': '["foo"]'}) self.assertIn('[&quot;foo&quot;]</textarea>', form.as_p())
form = JsonForm({'name': 'xy', 'jfield': '{"foo"}'}) self.assertEqual(form.as_p().count(escape('{"foo"}')), 2)
o2o_setnull = models.ForeignKey(R, models.SET_NULL, null=True, related_name="o2o_nullable_set")
class AvatarProxy(Avatar): class Meta: proxy = True
replacement_r = R.objects.create()
b.delete()
self.assertNumQueries(5, s.delete) self.assertFalse(S.objects.exists())
calls = []
calls = []
self.assertNumQueries(4, a.delete) self.assertFalse(User.objects.exists()) self.assertFalse(Avatar.objects.exists()) self.assertEqual(len(calls), 1) models.signals.post_delete.disconnect(noop, sender=User)
batch_size = connection.ops.bulk_batch_size(['pk'], objs) batches = int(ceil(float(len(objs)) / batch_size)) fetches_to_mem = 1 + batches queries = fetches_to_mem + TEST_SIZE // GET_ITERATOR_CHUNK_SIZE self.assertNumQueries(queries, Avatar.objects.all().delete) self.assertFalse(Avatar.objects.exists())
expected_num_queries = (ceil(TEST_SIZE // batch_size) + ceil(TEST_SIZE // GET_ITERATOR_CHUNK_SIZE) + 2)
r = R.objects.create() h1 = HiddenUser.objects.create(r=r) HiddenUser.objects.create(r=r) HiddenUserProfile.objects.create(user=h1) existed_objs = { R._meta.label: R.objects.count(), HiddenUser._meta.label: HiddenUser.objects.count(), A._meta.label: A.objects.count(), MR._meta.label: MR.objects.count(), HiddenUserProfile._meta.label: HiddenUserProfile.objects.count(), } deleted, deleted_objs = R.objects.all().delete() for k, v in existed_objs.items(): self.assertEqual(deleted_objs[k], v)
with self.assertNumQueries(2): avatar.delete()
self.assertNumQueries(2, a.delete) self.assertFalse(User.objects.exists()) self.assertFalse(Avatar.objects.exists())
self.assertNumQueries(2, f.delete)
self.assertNumQueries(2, f.delete)
c.delete() self.assertFalse(Child.objects.exists()) self.assertEqual(Parent.objects.count(), 1) self.assertEqual(Parent.objects.filter(pk=p.pk).count(), 1) self.assertNumQueries(2, p.delete) self.assertFalse(Parent.objects.exists()) c = Child.objects.create() p = c.parent_ptr self.assertNumQueries(2, p.delete) self.assertFalse(Parent.objects.exists()) self.assertFalse(Child.objects.exists())
self.assertNumQueries(1, User.objects.all().delete) a = Avatar.objects.create(desc='a') User.objects.bulk_create(User(avatar=a) for i in range(0, 2000)) self.assertNumQueries(2, a.delete) self.assertEqual(User.objects.count(), 0)
response = self.client.get(url) self.assertContains(response, 'Have request') response = self.client.get(url) self.assertContains(response, 'Not secure') response = self.client.get(url, {'is_secure': 'blah'}) self.assertContains(response, 'Not secure') response = self.client.post(url, {'is_secure': 'blah'}) self.assertContains(response, 'Not secure') response = self.client.get(url) self.assertContains(response, url) response = self.client.get(url, {'path': '/blah/'}) self.assertContains(response, url) response = self.client.post(url, {'path': '/blah/'}) self.assertContains(response, url)
response = self.client.get(url) self.assertContains(response, 'Have debug')
with override_settings(DEBUG=False): response = self.client.get(url) self.assertNotContains(response, 'Have debug')
self.assertContains(response, 'Third query list: 2') self.assertContains(response, 'Fourth query list: 3')
self.assertQuerysetEqual( self.company_query.filter(num_employees__gt=F("num_chairs")), [ { "num_chairs": 5, "name": "Example Inc.", "num_employees": 2300, }, { "num_chairs": 1, "name": "Test GmbH", "num_employees": 32 }, ], lambda o: o )
self.company_query.update(num_chairs=F("num_employees")) self.assertQuerysetEqual( self.company_query, [ { "num_chairs": 2300, "name": "Example Inc.", "num_employees": 2300 }, { "num_chairs": 3, "name": "Foobar Ltd.", "num_employees": 3 }, { "num_chairs": 32, "name": "Test GmbH", "num_employees": 32 } ], lambda o: o )
self.company_query.update(num_chairs=F("num_employees") + 2) self.assertQuerysetEqual( self.company_query, [ { 'num_chairs': 2302, 'name': 'Example Inc.', 'num_employees': 2300 }, { 'num_chairs': 5, 'name': 'Foobar Ltd.', 'num_employees': 3 }, { 'num_chairs': 34, 'name': 'Test GmbH', 'num_employees': 32 } ], lambda o: o, )
self. company_query.update( num_chairs=F('num_employees') + 2 * F('num_employees') ) self.assertQuerysetEqual( self.company_query, [ { 'num_chairs': 6900, 'name': 'Example Inc.', 'num_employees': 2300 }, { 'num_chairs': 9, 'name': 'Foobar Ltd.', 'num_employees': 3 }, { 'num_chairs': 96, 'name': 'Test GmbH', 'num_employees': 32 } ], lambda o: o, )
self.company_query.update( num_chairs=((F('num_employees') + 2) * F('num_employees')) ) self.assertQuerysetEqual( self.company_query, [ { 'num_chairs': 5294600, 'name': 'Example Inc.', 'num_employees': 2300 }, { 'num_chairs': 15, 'name': 'Foobar Ltd.', 'num_employees': 3 }, { 'num_chairs': 1088, 'name': 'Test GmbH', 'num_employees': 32 } ], lambda o: o, )
self.assertEqual( Company.objects.update(point_of_contact=F('ceo')), 3 ) self.assertQuerysetEqual( Company.objects.all(), [ "Joe Smith", "Frank Meyer", "Max Mustermann", ], lambda c: six.text_type(c.point_of_contact), ordered=False )
Company.objects.update(point_of_contact=F('ceo')) c = Company.objects.all()[0] c.point_of_contact = Employee.objects.create(firstname="Guido", lastname="van Rossum") c.save()
test_gmbh = Company.objects.get(name="Test GmbH") self.assertEqual(test_gmbh.num_employees, 32) test_gmbh.num_employees = F("num_employees") + 4 test_gmbh.save() test_gmbh = Company.objects.get(pk=test_gmbh.pk) self.assertEqual(test_gmbh.num_employees, 36)
test_co = Company( name=Lower(Value("UPPER")), num_employees=32, num_chairs=1, ceo=Employee.objects.create(firstname="Just", lastname="Doit", salary=30), ) test_co.save() test_co.refresh_from_db() self.assertEqual(test_co.name, "upper")
with self.assertRaisesMessage(FieldError, 'Aggregate functions are not allowed in this query'): Company.objects.create( name='Company', num_employees=Max(Value(1)), num_chairs=1, ceo=Employee.objects.create(firstname="Just", lastname="Doit", salary=30), )
test_gmbh = Company.objects.get(name="Test GmbH")
test_gmbh = Company.objects.get(name="Test GmbH") acme = Company( name="The Acme Widget Co.", num_employees=12, num_chairs=5, ceo=test_gmbh.ceo ) acme.num_employees = F("num_employees") + 16 msg = ( 'Failed to insert expression "Col(expressions_company, ' 'expressions.Company.num_employees) + Value(16)" on ' 'expressions.Company.num_employees. F() expressions can only be ' 'used to update, not to insert.' ) with self.assertRaisesMessage(ValueError, msg): acme.save()
qs = Employee.objects.filter( company_ceo_set__num_chairs=F('company_ceo_set__num_employees')) self.assertEqual(str(qs.query).count('JOIN'), 1)
qs = Employee.objects.filter( company_ceo_set__num_chairs=F('company_ceo_set__num_employees'), company_ceo_set__num_chairs__gte=1) self.assertEqual(str(qs.query).count('JOIN'), 1)
qs = Employee.objects.filter( company_ceo_set__num_employees=F('pk'), pk=F('company_ceo_set__num_employees') ) self.assertEqual(str(qs.query).count('JOIN'), 1)
qs = Employee.objects.filter( company_ceo_set__num_employees=F('pk') ).filter( company_ceo_set__num_employees=F('company_ceo_set__num_employees') ) self.assertEqual(str(qs.query).count('JOIN'), 2)
n_qs = Number.objects.filter(id=f) self.assertEqual(n_qs.get(), n) self.assertEqual(c_qs.get(), c)
Number.objects.filter(pk=self.n.pk).update( integer=F('integer') + 15, float=F('float') + 42.7 )
Number.objects.filter(pk=self.n.pk).update(integer=F('integer') - 15, float=F('float') - 42.7)
Number.objects.filter(pk=self.n.pk).update(integer=F('integer') * 15, float=F('float') * 42.7)
Number.objects.filter(pk=self.n.pk).update(integer=F('integer') / 2, float=F('float') / 42.7)
Number.objects.filter(pk=self.n.pk).update(integer=F('integer') % 20)
Number.objects.filter(pk=self.n.pk).update(integer=F('integer').bitand(56))
Number.objects.filter(pk=self.n.pk).update(integer=F('integer').bitor(48))
Number.objects.filter(pk=self.n.pk).update(integer=F('integer') ** 2, float=F('float') ** 1.5) self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 1764) self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(61.02, places=2))
Number.objects.filter(pk=self.n.pk).update(integer=15 + F('integer'), float=42.7 + F('float'))
self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 57) self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(58.200, places=3))
self.assertEqual(Number.objects.get(pk=self.n.pk).integer, -27) self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(27.200, places=3))
Number.objects.filter(pk=self.n.pk).update(integer=15 * F('integer'), float=42.7 * F('float'))
Number.objects.filter(pk=self.n.pk).update(integer=640 / F('integer'), float=42.7 / F('float'))
Number.objects.filter(pk=self.n.pk).update(integer=69 % F('integer'))
Number.objects.filter(pk=self.n.pk).update(integer=2 ** F('integer'), float=1.5 ** F('float')) self.assertEqual(Number.objects.get(pk=self.n.pk).integer, 4398046511104) self.assertEqual(Number.objects.get(pk=self.n.pk).float, Approximate(536.308, places=3))
cls.deltas = [] cls.delays = [] cls.days_long = []
end = stime + delta0 e0 = Experiment.objects.create( name='e0', assigned=sday, start=stime, end=end, completed=end.date(), estimated_time=delta0, ) cls.deltas.append(delta0) cls.delays.append(e0.start - datetime.datetime.combine(e0.assigned, midnight)) cls.days_long.append(e0.completed - e0.assigned)
if connection.features.supports_microsecond_precision: delay = datetime.timedelta(1) end = stime + delay + delta1 e1 = Experiment.objects.create( name='e1', assigned=sday, start=stime + delay, end=end, completed=end.date(), estimated_time=delta1, ) cls.deltas.append(delta1) cls.delays.append(e1.start - datetime.datetime.combine(e1.assigned, midnight)) cls.days_long.append(e1.completed - e1.assigned)
end = stime + delta2 e2 = Experiment.objects.create( name='e2', assigned=sday - datetime.timedelta(3), start=stime, end=end, completed=end.date(), estimated_time=datetime.timedelta(hours=1), ) cls.deltas.append(delta2) cls.delays.append(e2.start - datetime.datetime.combine(e2.assigned, midnight)) cls.days_long.append(e2.completed - e2.assigned)
delay = datetime.timedelta(4) end = stime + delay + delta3 e3 = Experiment.objects.create( name='e3', assigned=sday, start=stime + delay, end=end, completed=end.date(), estimated_time=delta3, ) cls.deltas.append(delta3) cls.delays.append(e3.start - datetime.datetime.combine(e3.assigned, midnight)) cls.days_long.append(e3.completed - e3.assigned)
end = stime + delta4 e4 = Experiment.objects.create( name='e4', assigned=sday - datetime.timedelta(10), start=stime, end=end, completed=end.date(), estimated_time=delta4 - datetime.timedelta(1), ) cls.deltas.append(delta4) cls.delays.append(e4.start - datetime.datetime.combine(e4.assigned, midnight)) cls.days_long.append(e4.completed - e4.assigned) cls.expnames = [e.name for e in Experiment.objects.all()]
queryset = Experiment.objects.filter(end__lt=F('start') + datetime.timedelta(hours=1)) q1 = str(queryset.query) q2 = str(queryset.query) self.assertEqual(q1, q2)
qs = Experiment.objects.filter(end__lt=F('start') + datetime.timedelta(hours=1)) qs2 = qs.all() list(qs) list(qs2)
over_estimate = Experiment.objects.exclude(name='e1').filter( completed__gt=self.stime + F('estimated_time'), ).order_by('name') self.assertQuerysetEqual(over_estimate, ['e3', 'e4'], lambda e: e.name)
environ['QUERY_STRING'] = str(raw_query_string, 'iso-8859-1')
self.assertListEqual(got, ['caf', 'caf', 'caf\ufffd', 'caf'])
self.assertEqual(request.COOKIES['want'], force_str("caf"))
self.assertIsInstance(request.COOKIES, dict)
self.assertEqual(response.status_code, 400)
script_name = get_script_name({'SCRIPT_URL': '/foobar/'}) self.assertEqual(script_name, '/foobar/')
return SelfRef.objects.get(selfref=self).pk
a.save() self.assertIsNotNone(a.id) self.assertEqual(Article.objects.all().count(), 1)
a = Article(None, 'Fourth article', pub_date=datetime(2005, 7, 31)) a.save() self.assertEqual(a.headline, 'Fourth article')
self.assertIn(a, Article.objects.all()) self.assertTrue(Article.objects.filter(id=a.id).exists())
a9 = Article( headline='Article 9', pub_date=datetime(2005, 7, 31, 12, 30, 45, 180), ) a9.save() self.assertEqual(Article.objects.get(pk=a9.pk).pub_date, datetime(2005, 7, 31, 12, 30, 45, 180))
a9 = Article( headline='Article 9', pub_date=datetime(2005, 7, 31, 12, 30, 45, 180), ) a9.save() self.assertEqual( Article.objects.get(id__exact=a9.id).pub_date, datetime(2005, 7, 31, 12, 30, 45), )
a = Article.objects.create( headline='Article', pub_date=datetime(2008, 12, 31, 23, 59, 59, 999999), ) self.assertEqual( Article.objects.get(pk=a.pk).pub_date, datetime(2008, 12, 31, 23, 59, 59), )
a101 = Article( id=101, headline='Article 101', pub_date=datetime(2005, 7, 31, 12, 30, 45), ) a101.save() a101 = Article.objects.get(pk=101) self.assertEqual(a101.headline, 'Article 101')
a10 = Article.objects.create( headline="Article 10", pub_date=datetime(2005, 7, 31, 12, 30, 45), ) self.assertEqual(Article.objects.get(headline="Article 10"), a10)
Article.objects.create( headline='Article 11', pub_date=datetime(2008, 1, 1), ) Article.objects.create( headline='Article 12', pub_date=datetime(2008, 12, 31, 23, 59, 59, 999999), ) self.assertQuerysetEqual( Article.objects.filter(pub_date__year=2008), ["<Article: Article 11>", "<Article: Article 12>"] )
a = Article( headline='\u6797\u539f \u3081\u3050\u307f', pub_date=datetime(2005, 7, 28), ) a.save() self.assertEqual(Article.objects.get(pk=a.id).headline, '\u6797\u539f \u3081\u3050\u307f')
a10 = Article.objects.create( headline="Article 10", pub_date=datetime(2005, 7, 31, 12, 30, 45), ) a11 = Article.objects.create( headline='Article 11', pub_date=datetime(2008, 1, 1), ) a12 = Article.objects.create( headline='Article 12', pub_date=datetime(2008, 12, 31, 23, 59, 59, 999999), )
Article.objects.create( headline="Article 10", pub_date=datetime(2005, 7, 31, 12, 30, 45), ) Article.objects.create( headline='Article 11', pub_date=datetime(2008, 1, 1), ) Article.objects.create( headline='Article 12', pub_date=datetime(2008, 12, 31, 23, 59, 59, 999999), )
Article.objects.create( headline="Article 10", pub_date=datetime(2005, 7, 31, 12, 30, 45), ) Article.objects.create( headline='Article 11', pub_date=datetime(2008, 1, 1), ) Article.objects.create( headline='Article 12', pub_date=datetime(2008, 12, 31, 23, 59, 59, 999999), )
article.headline = lazy article.save() self.assertEqual(article.headline, notlazy) Article.objects.update(headline=lazy) article = Article.objects.get() self.assertEqual(article.headline, notlazy) Article.objects.all().delete() Article.objects.bulk_create([Article(headline=lazy, pub_date=datetime.now())]) article = Article.objects.get() self.assertEqual(article.headline, notlazy)
with self.assertRaises(TypeError): EmptyQuerySet() self.assertIsInstance(Article.objects.none(), EmptyQuerySet) self.assertFalse(isinstance('', EmptyQuerySet))
Article.objects.create(headline='foo', pub_date=datetime.now()) with self.assertNumQueries(0): qs = Article.objects.none().values_list('pk') self.assertIsInstance(qs, EmptyQuerySet) self.assertEqual(len(qs), 0)
Article.objects.create(headline='foo', pub_date=datetime.now())
Article.objects.create(headline='foo', pub_date=datetime.now()) with self.assertNumQueries(0): self.assertEqual(len(Article.objects.none().values_list('id').order_by('id')), 0) with self.assertNumQueries(0): self.assertEqual(len(Article.objects.none().filter( id__in=Article.objects.values_list('id', flat=True))), 0)
Article.objects.create(headline='foo', pub_date=datetime.now()) with self.assertNumQueries(0): self.assertEqual(len(Article.objects.none().distinct('headline', 'pub_date')), 0)
self.assertEqual(hash(Article(id=1)), hash(1)) with self.assertRaises(TypeError): hash(Article())
self.a = Article( id=None, headline='Swallow programs in Python', pub_date=datetime(2005, 7, 28), ) self.a.save()
self.a.headline = 'Parrot programs in Python' self.a.save()
self.assertQuerysetEqual(Article.objects.all(), ['<Article: Parrot programs in Python>'])
self.assertEqual(Article.objects.get(id__exact=self.a.id), self.a) self.assertEqual(Article.objects.get(headline__startswith='Swallow'), self.a) self.assertEqual(Article.objects.get(pub_date__year=2005), self.a) self.assertEqual(Article.objects.get(pub_date__year=2005, pub_date__month=7), self.a) self.assertEqual(Article.objects.get(pub_date__year=2005, pub_date__month=7, pub_date__day=28), self.a) self.assertEqual(Article.objects.get(pub_date__week_day=5), self.a)
self.assertEqual(Article.objects.get(id=self.a.id), self.a) self.assertEqual(Article.objects.get(headline='Swallow programs in Python'), self.a)
with self.assertRaisesMessage(ObjectDoesNotExist, "Article matching query does not exist."): Article.objects.get(id__exact=2000,) with self.assertRaises(ObjectDoesNotExist): Article.objects.get(pub_date__year=2005, pub_date__month=8) with self.assertRaisesMessage(ObjectDoesNotExist, "Article matching query does not exist."): Article.objects.get(pub_date__week_day=6,)
self.assertEqual(Article.objects.get(pk=self.a.id), self.a)
self.assertQuerysetEqual(Article.objects.filter(pk__in=[self.a.id]), ["<Article: Swallow programs in Python>"])
a = Article.objects.get(pk=self.a.id) b = Article.objects.get(pk=self.a.id) self.assertEqual(a, b)
a = Article( id=None, headline='Swallow bites Python', pub_date=datetime(2005, 7, 28), ) a.save()
msg = "get() returned more than one Article -- it returned 2!" with self.assertRaisesMessage(MultipleObjectsReturned, msg): Article.objects.get(headline__startswith='Swallow',) with self.assertRaisesMessage(MultipleObjectsReturned, msg): Article.objects.get(pub_date__year=2005,) with self.assertRaisesMessage(MultipleObjectsReturned, msg): Article.objects.get(pub_date__year=2005, pub_date__month=7)
Article.objects.filter(pk=a.pk).delete()
called = False
with self.assertRaises(DatabaseError): asos.save(force_update=True) with self.assertRaises(DatabaseError): asos.save(update_fields=['pub_date'])
return val - timedelta(microseconds=val.microsecond)
self.assertFalse(hasattr(s3_copy.selfref, 'touched')) self.assertEqual(s3_copy.selfref, s2)
assertion_error = None try: class MultipleAutoFields(models.Model): auto1 = models.AutoField(primary_key=True) auto2 = models.AutoField(primary_key=True) except AssertionError as exc: assertion_error = exc assert str(assertion_error) == "A model can't have more than one AutoField."
parent = ModelToValidate.objects.create(number=11, name='Other Name') mtv = ModelToValidate(number=10, name='Some Name', parent_id=parent.pk) self.assertFailsValidation(mtv.full_clean, ['parent'])
data = { 'title': 'The state of model validation', 'pub_date': '2010-1-10 14:49:00' } form = ArticleForm(data) self.assertEqual(list(form.errors), []) article = form.save(commit=False) article.author = self.author article.save()
data = { 'title': 'The state of model validation', } article = Article(author_id=self.author.id) form = ArticleForm(data, instance=article) self.assertEqual(list(form.errors), []) self.assertNotEqual(form.instance.pub_date, None) article = form.save()
data = { 'title': 'The state of model validation', 'pub_date': 'never' } article = Article(author_id=self.author.id) form = ArticleForm(data, instance=article) self.assertEqual(list(form.errors), ['pub_date'])
giptm = GenericIPAddressTestModel(generic_ip="2001::1:0:0:0:0:2") giptm.save() giptm = GenericIPAddressTestModel(generic_ip="2001:0:1:2") self.assertFailsValidation(giptm.full_clean, ['generic_ip'])
giptm = GenericIPAddressTestModel(generic_ip="::ffff:10.10.10.10") giptm.save() giptm = GenericIPAddressTestModel(generic_ip="10.10.10.10") self.assertIsNone(giptm.full_clean())
giptm = GenericIPAddrUnpackUniqueTest(generic_v4unpack_ip="::ffff:18.52.18.52") giptm.save() giptm = GenericIPAddrUnpackUniqueTest(generic_v4unpack_ip="18.52.18.52") self.assertFailsValidation(giptm.full_clean, ['generic_v4unpack_ip'])
with self.assertNumQueries(0): mtv = ModelToValidate(number=10, name='Some Name') setattr(mtv, '_adding', True) mtv.full_clean()
with self.assertNumQueries(1): mtv = ModelToValidate(number=10, name='Some Name', id=123) setattr(mtv, '_adding', True) mtv.full_clean()
with self.assertNumQueries(0): mtv = ModelToValidate(number=10, name='Some Name') mtv.full_clean()
p = Post(title="Work on Django 1.1 begins", posted=datetime.date(2008, 9, 3)) p.full_clean()
p = Post(title="Django 1.0 is released", posted=datetime.datetime(2008, 9, 4)) p.full_clean()
from __future__ import unicode_literals
self._test_validation_messages( f, 'fo', ["'fo' value has an invalid format. It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format."] ) self._test_validation_messages( f, '2011-10-32', ["'2011-10-32' value has the correct format (YYYY-MM-DD) but it is an invalid date."] ) self._test_validation_messages( f, '2011-10-32 10:10', ["'2011-10-32 10:10' value has the correct format (YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]) " "but it is an invalid date/time."] )
self._test_validation_messages( f, 'fo', ["'fo' value has an invalid format. It must be in HH:MM[:ss[.uuuuuu]] format."] ) self._test_validation_messages( f, '25:50', ["'25:50' value has the correct format (HH:MM[:ss[.uuuuuu]]) but it is an invalid time."] )
fake_app = object()
application = object()
lookup_name = 'testyear'
lhs_sql, lhs_params = self.process_lhs(compiler, connection, self.lhs.lhs) rhs_sql, rhs_params = self.process_rhs(compiler, connection) params = lhs_params + rhs_params + lhs_params + rhs_params return ("%(lhs)s >= (%(rhs)s || '-01-01')::date " "AND %(lhs)s <= (%(rhs)s || '-12-31')::date" % {'lhs': lhs_sql, 'rhs': rhs_sql}, params)
real_lhs = self.lhs.lhs lhs_sql, params = self.process_lhs(compiler, connection, real_lhs) rhs_sql, rhs_params = self.process_rhs(compiler, connection) params.extend(rhs_params) return "%s <= (%s || '-12-31')::date" % (lhs_sql, rhs_sql), params
params = lhs_params + rhs_params + lhs_params + rhs_params return ("%s >= date_trunc('month', %s) and " "%s < date_trunc('month', %s) + interval '1 months'" % (lhs, rhs, lhs, rhs), params)
[a1, a2, a3, a4], lambda x: x)
baseqs.filter(age__mult3__gte=models.F('average_rating')), [a2, a3], lambda x: x)
self.assertQuerysetEqual( baseqs.filter(birthdate__testyear__lt=2012), [self.a1], lambda x: x)
baseqs = Author.objects.order_by('name') self.assertIn( '<= (2011 || ', str(baseqs.filter(birthdate__testyear__lte=2011).query)) self.assertIn( '-12-31', str(baseqs.filter(birthdate__testyear__lte=2011).query))
def as_custom_sql(self, compiler, connection): lhs_sql, lhs_params = self.process_lhs(compiler, connection, self.lhs.lhs) rhs_sql, rhs_params = self.process_rhs(compiler, connection) params = lhs_params + rhs_params + lhs_params + rhs_params return ("%(lhs)s >= str_to_date(concat(%(rhs)s, '-01-01'), '%%%%Y-%%%%m-%%%%d') " "AND %(lhs)s <= str_to_date(concat(%(rhs)s, '-12-31'), '%%%%Y-%%%%m-%%%%d')" % {'lhs': lhs_sql, 'rhs': rhs_sql}, params) setattr(YearExact, 'as_' + connection.vendor, as_custom_sql) self.assertIn( 'concat(', str(Author.objects.filter(birthdate__testyear=2012).query))
class CustomYearExact(YearExact): def as_custom_sql(self, compiler, connection): lhs_sql, lhs_params = self.process_lhs(compiler, connection, self.lhs.lhs) rhs_sql, rhs_params = self.process_rhs(compiler, connection) params = lhs_params + rhs_params + lhs_params + rhs_params return ("%(lhs)s >= str_to_date(CONCAT(%(rhs)s, '-01-01'), '%%%%Y-%%%%m-%%%%d') " "AND %(lhs)s <= str_to_date(CONCAT(%(rhs)s, '-12-31'), '%%%%Y-%%%%m-%%%%d')" % {'lhs': lhs_sql, 'rhs': rhs_sql}, params) setattr(CustomYearExact, 'as_' + connection.vendor, CustomYearExact.as_custom_sql) YearTransform.register_lookup(CustomYearExact) self.assertIn( 'CONCAT(', str(Author.objects.filter(birthdate__testyear=2012).query))
lookup_name = 'testyear' call_order = []
with self.assertRaises(FieldError): Author.objects.filter(birthdate__testyear__junk=2012) self.assertEqual(TrackCallsYearTransform.call_order, ['lookup', 'transform']) TrackCallsYearTransform.call_order = [] with self.assertRaises(FieldError): Author.objects.filter(birthdate__testyear__junk__more_junk=2012) self.assertEqual(TrackCallsYearTransform.call_order, ['transform']) TrackCallsYearTransform.call_order = [] Author.objects.filter(birthdate__testyear=2012) self.assertEqual(TrackCallsYearTransform.call_order, ['lookup']) TrackCallsYearTransform.call_order = [] Author.objects.filter(birthdate__testyear__exact=2012) self.assertEqual(TrackCallsYearTransform.call_order, ['lookup'])
return now.replace(tzinfo=tz) + tz.utcoffset(now)
with translation.override('ja'), self.settings(USE_L10N=True): self.humanize_tester([100], ['100'], 'intcomma')
date_one = datetime.datetime(today.year, today.month, today.day, tzinfo=tz_one) naturalday_one = humanize.naturalday(date_one) date_two = datetime.datetime(today.year, today.month, today.day, tzinfo=tz_two) naturalday_two = humanize.naturalday(date_two)
self.assertNotEqual(naturalday_one, naturalday_two)
dt = datetime.datetime(2012, 3, 9, 1, 30, tzinfo=utc)
result_list_with_tz_support = result_list[:] assert result_list_with_tz_support[-4] == '2\xa0days, 6\xa0hours from now' result_list_with_tz_support[-4] == '2\xa0days, 5\xa0hours from now'
from __future__ import unicode_literals
email = EmailMessage( 'Subject', 'Content', 'from@example.com', ['to@example.com', 'other@example.com'], cc=['cc@example.com', 'cc.other@example.com'] ) message = email.message() self.assertEqual(message['Cc'], 'cc@example.com, cc.other@example.com') self.assertEqual( email.recipients(), ['to@example.com', 'other@example.com', 'cc@example.com', 'cc.other@example.com'] )
email = EmailMessage( 'Subject', 'Content', 'from@example.com', ['to@example.com', 'other@example.com'], cc=['cc@example.com', 'cc.other@example.com'], bcc=['bcc@example.com'] ) message = email.message() self.assertEqual(message['Cc'], 'cc@example.com, cc.other@example.com') self.assertEqual( email.recipients(), ['to@example.com', 'other@example.com', 'cc@example.com', 'cc.other@example.com', 'bcc@example.com'] )
self.assertEqual( message['Subject'].encode(), b'Long subject lines that get wrapped should contain a space continuation\n' b' character to get expected behavior in Outlook and Thunderbird' )
email = EmailMessage('Subject', 'Content', 'bounce@example.com', ['list-subscriber@example.com', 'list-subscriber2@example.com']) message = email.message() self.assertEqual(message['To'], 'list-subscriber@example.com, list-subscriber2@example.com') self.assertEqual(email.to, ['list-subscriber@example.com', 'list-subscriber2@example.com'])
text_content = 'Firstname Srname is a great guy.' html_content = '<p>Firstname Srname is a <strong>great</strong> guy.</p>' msg = EmailMultiAlternatives('Subject', text_content, 'from@example.com', ['to@example.com']) msg.encoding = 'iso-8859-1' msg.attach_alternative(html_content, "text/html") payload0 = msg.message().get_payload(0) self.assertMessageHasHeaders(payload0, { ('MIME-Version', '1.0'), ('Content-Type', 'text/plain; charset="iso-8859-1"'), ('Content-Transfer-Encoding', 'quoted-printable')}) self.assertTrue(payload0.as_bytes().endswith(b'\n\nFirstname S=FCrname is a great guy.')) payload1 = msg.message().get_payload(1) self.assertMessageHasHeaders(payload1, { ('MIME-Version', '1.0'), ('Content-Type', 'text/html; charset="iso-8859-1"'), ('Content-Transfer-Encoding', 'quoted-printable')}) self.assertTrue( payload1.as_bytes().endswith(b'\n\n<p>Firstname S=FCrname is a <strong>great</strong> guy.</p>') )
msg.attach("une pice jointe.pdf", b"%PDF-1.4.%...", mimetype="application/pdf") msg_bytes = msg.message().as_bytes() message = message_from_bytes(msg_bytes) payload = message.get_payload() self.assertEqual(payload[1].get_filename(), 'une pice jointe.pdf')
('file.txt', 'text/plain'), ('file.png', 'image/png'), ('file_txt', None), ('file_png', None), ('file_txt.png', 'image/png'), ('file_png.txt', 'text/plain'),
connection = mail.get_connection('mail.custombackend.EmailBackend') send_mail('Subject', 'Content', 'from@example.com', ['to@example.com'], connection=connection) self.assertEqual(mail.outbox, []) self.assertEqual(len(connection.test_outbox), 1) self.assertEqual(connection.test_outbox[0].subject, 'Subject')
email = EmailMessage( 'Subject', 'From the future', 'bounce@example.com', ['to@example.com'], headers={'From': 'from@example.com'}, ) self.assertNotIn(b'>From the future', email.message().as_bytes())
msg = EmailMessage( 'Subject', 'UTF-8 encoded body', 'bounce@example.com', ['to@example.com'], headers={'From': 'from@example.com'}, ) self.assertNotIn(b'Content-Transfer-Encoding: base64', msg.message().as_bytes())
msg = EmailMessage( 'Subject', 'Body with only ASCII characters.', 'bounce@example.com', ['to@example.com'], headers={'From': 'from@example.com'}, ) s = msg.message().as_bytes() self.assertNotIn(b'Content-Transfer-Encoding: quoted-printable', s) self.assertIn(b'Content-Transfer-Encoding: 7bit', s)
msg = EmailMessage( 'Subject', 'Body with latin characters: .', 'bounce@example.com', ['to@example.com'], headers={'From': 'from@example.com'}, ) s = msg.message().as_bytes() self.assertNotIn(b'Content-Transfer-Encoding: quoted-printable', s) self.assertIn(b'Content-Transfer-Encoding: 8bit', s)
child_msg = EmailMessage( 'Child Subject', 'Some body of child message', 'bounce@example.com', ['to@example.com'], headers={'From': 'from@example.com'}, ) child_s = child_msg.message().as_string()
parent_msg = EmailMessage( 'Parent Subject', 'Some parent body', 'bounce@example.com', ['to@example.com'], headers={'From': 'from@example.com'}, )
parent_msg.attach(content=child_s, mimetype='message/rfc822') parent_s = parent_msg.message().as_string()
self.assertIn(str('Child Subject'), parent_s)
parent_msg = EmailMessage( 'Parent Subject', 'Some parent body', 'bounce@example.com', ['to@example.com'], headers={'From': 'from@example.com'}, ) parent_msg.attach(content=child_msg.message(), mimetype='message/rfc822') parent_s = parent_msg.message().as_string()
self.assertIn(str('Child Subject'), parent_s)
parent_msg = EmailMessage( 'Parent Subject', 'Some parent body', 'bounce@example.com', ['to@example.com'], headers={'From': 'from@example.com'}, ) parent_msg.attach(content=child_msg, mimetype='message/rfc822') parent_s = parent_msg.message().as_string()
self.assertIn(str('Child Subject'), parent_s)
self.assertEqual(sanitize_address('to@example.com', 'ascii'), 'to@example.com') self.assertEqual(sanitize_address('to@example.com', 'utf-8'), 'to@example.com') self.assertEqual(sanitize_address(b'to@example.com', 'utf-8'), 'to@example.com')
self.assertEqual( sanitize_address(('A name', 'to@example.com'), 'ascii'), 'A name <to@example.com>' ) if PY3: self.assertEqual( sanitize_address(('A name', 'to@example.com'), 'utf-8'), '=?utf-8?q?A_name?= <to@example.com>' ) else: self.assertEqual( sanitize_address(('A name', 'to@example.com'), 'utf-8'), 'A name <to@example.com>' )
self.assertEqual( sanitize_address('t@example.com', 'utf-8'), '=?utf-8?b?dMOz?=@example.com' ) self.assertEqual( sanitize_address(('T Example', 't@example.com'), 'utf-8'), '=?utf-8?q?T=C3=B3_Example?= <=?utf-8?b?dMOz?=@example.com>' )
with self.assertRaises(BadHeaderError): send_mail('Subject\nMultiline', 'Content', 'from@example.com', ['to@example.com'])
pass
if sys.version_info >= (3, 5): kwargs['decode_data'] = True smtpd.SMTPServer.__init__(self, *args, **kwargs) self._sink = [] self.active = False self.active_lock = threading.Lock() self.sink_lock = threading.Lock()
lp, domain = mailfrom.split('@', 1) lp = Header(lp, 'utf-8').encode() mailfrom = '@'.join([lp, domain])
msg = None for i, m in enumerate(smtp_messages): if m[:4] == 'data': msg = smtp_messages[i + 1] break
msg = msg.replace('\r\n', '') self.assertNotIn('\r', msg) self.assertNotIn('\n', msg)
self.test_outbox.extend(email_messages) return len(email_messages)
from __future__ import unicode_literals
cls.site1 = Site(pk=1, domain='testserver', name='testserver') cls.site1.save() cls.author1 = Author.objects.create(name='Boris') cls.article1 = Article.objects.create( title='Old Article', slug='old_article', author=cls.author1, date_created=datetime.datetime(2001, 1, 1, 21, 22, 23) ) cls.article2 = Article.objects.create( title='Current Article', slug='current_article', author=cls.author1, date_created=datetime.datetime(2007, 9, 17, 21, 22, 23) ) cls.article3 = Article.objects.create( title='Future Article', slug='future_article', author=cls.author1, date_created=datetime.datetime(3000, 1, 1, 21, 22, 23) ) cls.scheme1 = SchemeIncludedURL.objects.create(url='http://test_scheme_included_http/') cls.scheme2 = SchemeIncludedURL.objects.create(url='https://test_scheme_included_https/') cls.scheme3 = SchemeIncludedURL.objects.create(url='//test_default_scheme_kept/')
object_id = models.PositiveIntegerField() content_object = GenericForeignKey()
content_object = GenericForeignKey()
connections['other'].ensure_connection()
from __future__ import unicode_literals
from __future__ import unicode_literals
with self.assertNumQueries(1): ContentType.objects.get_for_model(ContentType)
with self.assertNumQueries(0): ct = ContentType.objects.get_for_model(ContentType) with self.assertNumQueries(0): ContentType.objects.get_for_id(ct.id) with self.assertNumQueries(0): ContentType.objects.get_by_natural_key('contenttypes', 'contenttype')
ContentType.objects.clear_cache() with self.assertNumQueries(1): ContentType.objects.get_for_model(ContentType)
ContentType.objects.clear_cache() with self.assertNumQueries(1): ContentType.objects.get_by_natural_key('contenttypes', 'contenttype') with self.assertNumQueries(0): ContentType.objects.get_by_natural_key('contenttypes', 'contenttype')
with self.assertNumQueries(1): cts = ContentType.objects.get_for_models(ContentType, FooWithUrl) self.assertEqual(cts, { ContentType: ContentType.objects.get_for_model(ContentType), FooWithUrl: ContentType.objects.get_for_model(FooWithUrl), })
ContentType.objects.get_for_model(ContentType) with self.assertNumQueries(1): cts = ContentType.objects.get_for_models(ContentType, FooWithUrl) self.assertEqual(cts, { ContentType: ContentType.objects.get_for_model(ContentType), FooWithUrl: ContentType.objects.get_for_model(FooWithUrl), })
ContentType.objects.get_for_model(ContentType) ContentType.objects.get_for_model(FooWithUrl) with self.assertNumQueries(0): cts = ContentType.objects.get_for_models(ContentType, FooWithUrl) self.assertEqual(cts, { ContentType: ContentType.objects.get_for_model(ContentType), FooWithUrl: ContentType.objects.get_for_model(FooWithUrl), })
ConcreteModel.objects.create(name="Concrete") DeferredConcreteModel = ConcreteModel.objects.only('pk').get().__class__ DeferredProxyModel = ProxyModel.objects.only('pk').get().__class__
ConcreteModel.objects.create(name="Concrete") DeferredConcreteModel = ConcreteModel.objects.only('pk').get().__class__ DeferredProxyModel = ProxyModel.objects.only('pk').get().__class__
ct_fetched = ContentType.objects.get_for_id(ct.pk) self.assertIsNone(ct_fetched.model_class())
self.assertContains(response, '<input type="hidden" name="next" value="/admindocs/" />', html=True) self.client.force_login(self.superuser) response = self.client.get(reverse('django-admindocs-docroot')) self.assertContains(response, '<h1>Documentation</h1>', html=True) self.assertContains(response, '<h1 id="site-name"><a href="/admin/">Django administration</a></h1>')
self.assertContains(response, 'Base view for admindocs views.')
response = self.client.get(reverse('django-admindocs-filters')) self.assertContains(response, '<title>Template filters</title>', html=True)
response = self.client.get(reverse('django-admindocs-tags')) self.assertContains(response, '<title>Template tags</title>', html=True)
self.assertContains(self.response, "<td>first name - The person's first name</td>") self.assertContains(self.response, "<td>last name - The person's last name</td>")
self.assertContains(self.response, "<p>Get the full name of the person</p>")
self.assertContains(self.response, company_markup)
self.assertContains(self.response, "%s\n - place of work" % company_markup)
self.assertContains( self.response, "number of related %s objects" % (link % ("admin_docs.group", "admin_docs.Group")) ) self.assertContains( self.response, "all related %s objects" % (link % ("admin_docs.group", "admin_docs.Group")) )
self.assertContains(self.response, '<p>&quot;raw&quot; directive disabled.</p>',) self.assertContains(self.response, '.. raw:: html\n :file: admin_docs/evilfile.txt') self.assertContains(self.response, '<p>&quot;include&quot; directive disabled.</p>',) self.assertContains(self.response, '.. include:: admin_docs/evilfile.txt') out = self.docutils_stderr.getvalue() self.assertIn('"raw" directive disabled', out) self.assertIn('"include" directive disabled', out)
from __future__ import unicode_literals
articles = Article.objects.all() self.assertQuerysetEqual( articles.filter(headline__startswith='Hello') & articles.filter(headline__startswith='Goodbye'), [] ) self.assertQuerysetEqual( articles.filter(headline__startswith='Hello') & articles.filter(headline__contains='bye'), [ 'Hello and goodbye' ], attrgetter("headline") )
self.assertQuerysetEqual( Article.objects.filter(Q(pk=self.a1) | ~Q(pk=self.a2)), [ 'Hello', 'Hello and goodbye' ], attrgetter("headline") )
self.assertQuerysetEqual( Article.objects.filter(Q(pk=self.a1) & (~Q(pk=self.a2) | Q(pk=self.a3))), [ 'Hello' ], attrgetter("headline"), )
self.assertQuerysetEqual( Article.objects.complex_filter({'pk': self.a1}), [ 'Hello' ], attrgetter("headline"), )
self.assertQuerysetEqual( Article.objects.filter(pk__in=[]), [] ) self.assertQuerysetEqual( Article.objects.filter(Q(pk__in=[]) | Q(headline__icontains='goodbye')), [ 'Goodbye', 'Hello and goodbye' ], attrgetter("headline"), )
self.assertQuerysetEqual( Article.objects.filter(Q(headline__startswith='Hello'), Q(headline__contains='bye')), [ 'Hello and goodbye' ], attrgetter("headline") ) self.assertQuerysetEqual( Article.objects.filter(Q(headline__contains='bye'), headline__startswith='Hello'), [ 'Hello and goodbye' ], attrgetter("headline"), )
self.assertEqual( Article.objects.get(Q(headline__startswith='Hello'), Q(headline__contains='bye')).headline, 'Hello and goodbye' )
@skipUnlessDBFeature('test_db_allows_multiple_connections') class DeleteLockingTest(TransactionTestCase):
self.conn2 = connection.copy() self.conn2.set_autocommit(False)
self.conn2.rollback() self.conn2.close()
self.assertEqual(3, Book.objects.count())
with self.conn2.cursor() as cursor2: cursor2.execute("DELETE from delete_regress_book WHERE id = 1") self.conn2.commit()
Book.objects.filter(pagecount__lt=250).delete()
self.assertEqual(AwardNote.objects.count(), 0)
self.assertEqual(PlayedWithNote.objects.count(), 0)
test_image = Image() test_image.save() foo_image = FooImage(my_image=test_image) foo_image.save()
test_file = File.objects.get(pk=test_image.pk) foo_file = FooFile(my_file=test_file) foo_file.save()
self.assertEqual(len(Image.objects.all()), 0) self.assertEqual(len(File.objects.all()), 0)
self.assertEqual(len(FooImage.objects.all()), 0) self.assertEqual(len(FooFile.objects.all()), 0)
test_photo = Photo.objects.get(pk=test_image.pk) foo_photo = FooPhoto(my_photo=test_photo) foo_photo.save()
self.assertEqual(len(Photo.objects.all()), 0) self.assertEqual(len(Image.objects.all()), 0) self.assertEqual(len(File.objects.all()), 0)
self.assertEqual(len(FooPhoto.objects.all()), 0) self.assertEqual(len(FooFile.objects.all()), 0) self.assertEqual(len(FooImage.objects.all()), 0)
self.assertEqual(len(File.objects.all()), 0) self.assertEqual(len(Image.objects.all()), 0)
self.assertEqual(len(FooFile.objects.all()), 0) self.assertEqual(len(FooImage.objects.all()), 0)
image = Image.objects.create() as_file = File.objects.get(pk=image.pk) FooFileProxy.objects.create(my_file=as_file)
Login.objects.update(description='description') with self.assertNumQueries(1): Login.objects.distinct('description').order_by('pk').filter( orgunit__name__isnull=False ).delete() self.assertFalse(Login.objects.filter(pk=self.l1.pk).exists()) self.assertTrue(Login.objects.filter(pk=self.l2.pk).exists())
h = House.objects.create(address='Foo') OrderedPerson.objects.create(name='Jack', lives_in=h) OrderedPerson.objects.create(name='Bob', lives_in=h) OrderedPerson.objects.filter(lives_in__address='Foo').delete() self.assertEqual(OrderedPerson.objects.count(), 0)
self.assertEqual(event.dt, dt.replace(microsecond=0))
self.assertEqual(event.dt.replace(tzinfo=EAT), dt)
self.assertEqual(event.dt.replace(tzinfo=EAT), dt)
@skipUnlessDBFeature('supports_timezones') @skipIfDBFeature('supports_microsecond_precision') def test_aware_datetime_in_local_timezone_with_microsecond_unsupported(self): dt = datetime.datetime(2011, 9, 1, 13, 20, 30, 405060, tzinfo=EAT) Event.objects.create(dt=dt) event = Event.objects.get() self.assertIsNone(event.dt.tzinfo) self.assertEqual(event.dt.replace(tzinfo=EAT), dt.replace(microsecond=0))
self.assertEqual(event.dt.replace(tzinfo=EAT), dt)
self.assertEqual(event.dt.replace(tzinfo=EAT), dt)
Event.objects.create(dt=datetime.datetime(2011, 9, 1, 23, 20, 20)) Event.objects.create(dt=datetime.datetime(2011, 9, 1, 13, 20, 30)) Event.objects.create(dt=datetime.datetime(2011, 9, 1, 3, 20, 40)) result = Event.objects.all().aggregate(Min('dt'), Max('dt')) self.assertEqual(result, { 'dt__min': datetime.datetime(2011, 9, 1, 3, 20, 40), 'dt__max': datetime.datetime(2011, 9, 1, 23, 20, 20), })
morning = Session.objects.create(name='morning') afternoon = Session.objects.create(name='afternoon') SessionEvent.objects.create(dt=datetime.datetime(2011, 9, 1, 23, 20, 20), session=afternoon) SessionEvent.objects.create(dt=datetime.datetime(2011, 9, 1, 13, 20, 30), session=afternoon) SessionEvent.objects.create(dt=datetime.datetime(2011, 9, 1, 3, 20, 40), session=morning) morning_min_dt = datetime.datetime(2011, 9, 1, 3, 20, 40) afternoon_min_dt = datetime.datetime(2011, 9, 1, 13, 20, 30) self.assertQuerysetEqual( Session.objects.annotate(dt=Min('events__dt')).order_by('dt'), [morning_min_dt, afternoon_min_dt], transform=lambda d: d.dt) self.assertQuerysetEqual( Session.objects.annotate(dt=Min('events__dt')).filter(dt__lt=afternoon_min_dt), [morning_min_dt], transform=lambda d: d.dt) self.assertQuerysetEqual( Session.objects.annotate(dt=Min('events__dt')).filter(dt__gte=afternoon_min_dt), [afternoon_min_dt], transform=lambda d: d.dt)
dt = datetime.datetime(2011, 9, 1, 13, 20, 30) event = Event.objects.create(dt=dt) self.assertQuerysetEqual( Event.objects.raw('SELECT * FROM timezones_event WHERE dt = %s', [dt]), [event], transform=lambda d: d)
day = datetime.date(2011, 9, 1) AllDayEvent.objects.create(day=day) dt = datetime.datetime(2011, 9, 1, 22, 30, 0, tzinfo=UTC) self.assertTrue(AllDayEvent.objects.filter(day__gte=dt).exists())
self.assertEqual(event.dt, dt.replace(tzinfo=EAT))
self.assertEqual(event.dt, dt.replace(tzinfo=EAT))
self.assertEqual(event.dt, dt.replace(microsecond=0, tzinfo=EAT))
self.assertEqual(event.dt, dt.replace(microsecond=0))
self.assertEqual(Event.objects.filter(dt__exact=dt).count(), 1) self.assertEqual(Event.objects.filter(dt__lte=dt).count(), 1) self.assertEqual(Event.objects.filter(dt__gt=dt).count(), 0) self.assertEqual(len(recorded), 3) for warning in recorded: msg = str(warning.message) self.assertTrue(msg.startswith("DateTimeField Event.dt " "received a naive datetime"))
self.assertEqual(Event.objects.filter(dt__year=2011).count(), 1) self.assertEqual(Event.objects.filter(dt__month=1).count(), 1) self.assertEqual(Event.objects.filter(dt__day=1).count(), 1) self.assertEqual(Event.objects.filter(dt__week_day=7).count(), 1) self.assertEqual(Event.objects.filter(dt__hour=22).count(), 1) self.assertEqual(Event.objects.filter(dt__minute=30).count(), 2) self.assertEqual(Event.objects.filter(dt__second=0).count(), 2)
Event.objects.create(dt=datetime.datetime(2011, 9, 1, 23, 20, 20, tzinfo=EAT)) Event.objects.create(dt=datetime.datetime(2011, 9, 1, 13, 20, 30, tzinfo=EAT)) Event.objects.create(dt=datetime.datetime(2011, 9, 1, 3, 20, 40, tzinfo=EAT)) result = Event.objects.all().aggregate(Min('dt'), Max('dt')) self.assertEqual(result, { 'dt__min': datetime.datetime(2011, 9, 1, 3, 20, 40, tzinfo=EAT), 'dt__max': datetime.datetime(2011, 9, 1, 23, 20, 20, tzinfo=EAT), })
morning = Session.objects.create(name='morning') afternoon = Session.objects.create(name='afternoon') SessionEvent.objects.create(dt=datetime.datetime(2011, 9, 1, 23, 20, 20, tzinfo=EAT), session=afternoon) SessionEvent.objects.create(dt=datetime.datetime(2011, 9, 1, 13, 20, 30, tzinfo=EAT), session=afternoon) SessionEvent.objects.create(dt=datetime.datetime(2011, 9, 1, 3, 20, 40, tzinfo=EAT), session=morning) morning_min_dt = datetime.datetime(2011, 9, 1, 3, 20, 40, tzinfo=EAT) afternoon_min_dt = datetime.datetime(2011, 9, 1, 13, 20, 30, tzinfo=EAT) self.assertQuerysetEqual( Session.objects.annotate(dt=Min('events__dt')).order_by('dt'), [morning_min_dt, afternoon_min_dt], transform=lambda d: d.dt) self.assertQuerysetEqual( Session.objects.annotate(dt=Min('events__dt')).filter(dt__lt=afternoon_min_dt), [morning_min_dt], transform=lambda d: d.dt) self.assertQuerysetEqual( Session.objects.annotate(dt=Min('events__dt')).filter(dt__gte=afternoon_min_dt), [afternoon_min_dt], transform=lambda d: d.dt)
dt = datetime.datetime(2011, 9, 1, 13, 20, 30, tzinfo=EAT) event = Event.objects.create(dt=dt) self.assertQuerysetEqual( Event.objects.raw('SELECT * FROM timezones_event WHERE dt = %s', [dt]), [event], transform=lambda d: d)
day = datetime.date(2011, 9, 1) AllDayEvent.objects.create(day=day) dt = datetime.datetime(2011, 9, 1, 22, 30, 0, tzinfo=UTC) self.assertFalse(AllDayEvent.objects.filter(day__gte=dt).exists())
e = MaybeEvent.objects.create() self.assertEqual(e.dt, None)
if connection.features.supports_timezones: raise SkipTest("Database has feature(s) supports_timezones") if not connection.features.test_db_allows_multiple_connections: raise SkipTest("Database doesn't support feature(s): test_db_allows_multiple_connections")
connection.timezone del connection.timezone connection.timezone_name del connection.timezone_name
connection.timezone del connection.timezone connection.timezone_name del connection.timezone_name
six.assertRegex(self, yaml, r"\n fields: {dt: !(!timestamp)? '%s'}" % re.escape(dt))
def t(*result): return '|'.join(datetimes[key].isoformat() for key in result)
tpl = Template("{% load tz %}{{ dt|localtime }}|{{ dt|utc }}") ctx = Context({'dt': datetime.datetime(2011, 9, 1, 12, 20, 30)})
tpl = Template("{% load tz %}{{ dt|timezone:tz }}") ctx = Context({'dt': datetime.datetime(2011, 9, 1, 13, 20, 30), 'tz': pytz.timezone('Europe/Paris')}) self.assertEqual(tpl.render(ctx), "2011-09-01T12:20:30+02:00")
tpl = Template("{% load tz %}{{ dt|timezone:'Europe/Paris' }}") ctx = Context({'dt': datetime.datetime(2011, 9, 1, 13, 20, 30), 'tz': pytz.timezone('Europe/Paris')}) self.assertEqual(tpl.render(ctx), "2011-09-01T12:20:30+02:00")
ctx = Context({'dt': None, 'tz': ICT}) self.assertEqual(tpl.render(ctx), "None|||") ctx = Context({'dt': 'not a date', 'tz': ICT}) self.assertEqual(tpl.render(ctx), "not a date|||") tpl = Template("{% load tz %}{{ dt|timezone:tz }}") ctx = Context({'dt': datetime.datetime(2011, 9, 1, 13, 20, 30), 'tz': None}) self.assertEqual(tpl.render(ctx), "") ctx = Context({'dt': datetime.datetime(2011, 9, 1, 13, 20, 30), 'tz': 'not a tz'}) self.assertEqual(tpl.render(ctx), "")
ctx = Context({'dt': datetime.datetime(2011, 9, 1, 13, 20, 30, tzinfo=EAT), 'tz': pytz.timezone('Europe/Paris')}) self.assertEqual(tpl.render(ctx), "2011-09-01T12:20:30+02:00")
ctx = Context({'dt': datetime.datetime(2011, 9, 1, 13, 20, 30, tzinfo=EAT), 'tz': 'Europe/Paris'}) self.assertEqual(tpl.render(ctx), "2011-09-01T12:20:30+02:00")
tpl = Template("{% load tz %}{{ dt }}") ctx = Context({'dt': datetime.datetime(2011, 9, 1, 12, 20, 30, tzinfo=EAT)})
self.assertTrue(tpl.render(ctx).startswith("2011"))
tpl = Template("{% now \"O\" %}") self.assertEqual(tpl.render(Context({})), "+0300") with timezone.override(ICT): self.assertEqual(tpl.render(Context({})), "+0700")
self.assertTrue(form.is_valid()) self.assertEqual(form.cleaned_data['dt'], datetime.datetime(2011, 3, 27, 2, 30, 0))
self.assertTrue(form.is_valid()) self.assertEqual(form.cleaned_data['dt'], datetime.datetime(2011, 10, 30, 2, 30, 0))
self.assertFalse(form.is_valid())
t = Timestamp.objects.get() response = self.client.get(reverse('admin_tz:timezones_timestamp_change', args=(t.pk,))) self.assertContains(response, t.created.astimezone(EAT).isoformat())
t = Timestamp.objects.get() with timezone.override(ICT): response = self.client.get(reverse('admin_tz:timezones_timestamp_change', args=(t.pk,))) self.assertContains(response, t.created.astimezone(ICT).isoformat())
from __future__ import unicode_literals
verbose_name = 'Chapter?'
class Color2(Color): class Meta: proxy = True
class Title(models.Model): pass
class FieldOverridePost(Post): class Meta: proxy = True
slug = models.SlugField(max_length=1000, db_index=False)
class ReferencedByParent(models.Model): name = models.CharField(max_length=20, unique=True)
class ReferencedByInline(models.Model): name = models.CharField(max_length=20, unique=True)
class Recipe(models.Model): rname = models.CharField(max_length=20, unique=True)
class NotReferenced(models.Model): pass
class ExplicitlyProvidedPK(models.Model): name = models.IntegerField(primary_key=True)
class ReferencedByGenRel(models.Model): content_type = models.ForeignKey(ContentType, on_delete=models.CASCADE) object_id = models.PositiveIntegerField() content_object = GenericForeignKey('content_type', 'object_id')
from __future__ import unicode_literals
cls.inline_post_data = { "name": "Test section", "article_set-TOTAL_FORMS": "6", "article_set-INITIAL_FORMS": "3", "article_set-MAX_NUM_FORMS": "0", "article_set-0-id": cls.a1.pk, "article_set-0-title": "Norske bostaver  skaper problemer", "article_set-0-content": "&lt;p&gt;Middle content&lt;/p&gt;", "article_set-0-date_0": "2008-03-18", "article_set-0-date_1": "11:54:58", "article_set-0-section": cls.s1.pk, "article_set-1-id": cls.a2.pk, "article_set-1-title": "Need a title.", "article_set-1-content": "&lt;p&gt;Oldest content&lt;/p&gt;", "article_set-1-date_0": "2000-03-18", "article_set-1-date_1": "11:54:58", "article_set-2-id": cls.a3.pk, "article_set-2-title": "Need a title.", "article_set-2-content": "&lt;p&gt;Newest content&lt;/p&gt;", "article_set-2-date_0": "2009-03-18", "article_set-2-date_1": "11:54:58", "article_set-3-id": "", "article_set-3-title": "", "article_set-3-content": "", "article_set-3-date_0": "", "article_set-3-date_1": "", "article_set-4-id": "", "article_set-4-title": "", "article_set-4-content": "", "article_set-4-date_0": "", "article_set-4-date_1": "", "article_set-5-id": "", "article_set-5-title": "", "article_set-5-content": "", "article_set-5-date_0": "", "article_set-5-date_1": "", }
"article_set-TOTAL_FORMS": "3", "article_set-INITIAL_FORMS": "0", "article_set-MAX_NUM_FORMS": "0",
self.assertEqual(Section.objects.latest('id').article_set.count(), 2)
self.assertContains(response, 'column-callable_year') self.assertContains(response, 'field-callable_year') self.assertContains(response, 'column-lambda8') self.assertContains(response, 'field-lambda8')
response = self.client.get(reverse('admin:admin_views_article_changelist'), {'o': '-6'}) self.assertContentBefore( response, '2000', '2008', "Results of sorting on ModelAdmin method are out of order." ) self.assertContentBefore( response, '2008', '2009', "Results of sorting on ModelAdmin method are out of order." )
response = self.client.get(reverse('admin:admin_views_person_changelist'), {'o': '1.2'}) self.assertContentBefore(response, link3, link1) self.assertContentBefore(response, link1, link2)
response = self.client.get(reverse('admin:admin_views_person_changelist'), {'o': '-2.1'}) self.assertContentBefore(response, link2, link3) self.assertContentBefore(response, link3, link1)
response = self.client.get(reverse('admin:admin_views_language_changelist'), {'o': '-1'}) self.assertContentBefore(response, link1, link2)
dt = datetime.datetime.now() p1 = Podcast.objects.create(name="A", release_date=dt) p2 = Podcast.objects.create(name="B", release_date=dt - datetime.timedelta(10)) link1 = reverse('admin:admin_views_podcast_change', args=(p1.pk,)) link2 = reverse('admin:admin_views_podcast_change', args=(p2.pk,))
dt = datetime.datetime.now() p1 = Podcast.objects.create(name="A", release_date=dt) p2 = Podcast.objects.create(name="B", release_date=dt - datetime.timedelta(10)) link1 = reverse('admin:admin_views_podcast_change', args=(quote(p1.pk),)) link2 = reverse('admin:admin_views_podcast_change', args=(quote(p2.pk),))
self.assertContains(response, '<th scope="col"', count=5)
self.assertContentBefore(response, 'Name', 'Colored name')
self.assertContentBefore(response, link2, link1)
self.assertContains(response, '<th scope="col"', count=3, msg_prefix=url) self.assertEqual(response.context['cl'].get_ordering_field_columns(), {2: 'asc'}) self.assertContentBefore(response, 'The First Item', 'The Middle Item') self.assertContentBefore(response, 'The Middle Item', 'The Last Item')
self.assertContains(response, '<a href="?%s">' % query_string) filtered_response = self.client.get('%s?%s' % (changelist_url, query_string)) self.assertEqual(filtered_response.status_code, 200) for obj in filtered_response.context['cl'].queryset.all(): self.assertTrue(params['test'](obj, value))
response = self.client.get(changelist_url, {'notarealfield__whatever': '5'}) self.assertRedirects(response, '%s?e=1' % changelist_url)
response = self.client.get(changelist_url, {'pub_date__gte': 'foo'}) self.assertRedirects(response, '%s?e=1' % changelist_url)
response = self.client.get("%s?color__value__startswith=red" % reverse('admin:admin_views_thing_changelist')) self.assertEqual(response.status_code, 200) response = self.client.get("%s?color__value=red" % reverse('admin:admin_views_thing_changelist')) self.assertEqual(response.status_code, 200)
response = self.client.get("%s?age__gt=30" % reverse('admin:admin_views_person_changelist')) self.assertEqual(response.status_code, 200)
with patch_logger('django.security.DisallowedModelAdminToField', 'error') as calls: response = self.client.get(reverse('admin:admin_views_section_changelist'), {TO_FIELD_VAR: 'name'}) self.assertEqual(response.status_code, 400) self.assertEqual(len(calls), 1)
response = self.client.get(reverse('admin:admin_views_notreferenced_changelist'), {TO_FIELD_VAR: 'id'}) self.assertEqual(response.status_code, 200)
response = self.client.get(reverse('admin:admin_views_recipe_changelist'), {TO_FIELD_VAR: 'rname'}) self.assertEqual(response.status_code, 200)
response = self.client.get(reverse('admin:admin_views_ingredient_changelist'), {TO_FIELD_VAR: 'iname'}) self.assertEqual(response.status_code, 200)
response = self.client.get(reverse('admin:admin_views_referencedbyparent_changelist'), {TO_FIELD_VAR: 'name'}) self.assertEqual(response.status_code, 200)
response = self.client.get(reverse('admin:admin_views_referencedbyinline_changelist'), {TO_FIELD_VAR: 'name'}) self.assertEqual(response.status_code, 200)
url = reverse('admin:admin_views_referencedbygenrel_changelist') with patch_logger('django.security.DisallowedModelAdminToField', 'error') as calls: response = self.client.get(url, {TO_FIELD_VAR: 'object_id'}) self.assertEqual(response.status_code, 400) self.assertEqual(len(calls), 1)
with patch_logger('django.security.DisallowedModelAdminToField', 'error') as calls: response = self.client.post(reverse('admin:admin_views_section_add'), {TO_FIELD_VAR: 'name'}) self.assertEqual(response.status_code, 400) self.assertEqual(len(calls), 1)
url = "%s?leader__name=Palin&leader__age=27" % reverse('admin:admin_views_inquisition_changelist') response = self.client.get(url) self.assertEqual(response.status_code, 200)
self.assertContains(response, '<th class="field-__str__">UnchangeableObject object</th>', html=True)
'DIRS': [ os.path.join(os.path.dirname(upath(__file__)), 'templates'), os.path.join(os.path.dirname(os.path.dirname(upath(__file__))), 'templates'), ], 'APP_DIRS': True, 'OPTIONS': { 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], },
response = self.client.get(reverse('admin:admin_views_customarticle_changelist')) self.assertContains(response, "var hello = 'Hello!';") self.assertTemplateUsed(response, 'custom_admin/change_list.html')
response = self.client.get(reverse('admin:admin_views_customarticle_add')) self.assertTemplateUsed(response, 'custom_admin/add_form.html')
post = self.client.post(reverse('admin:admin_views_customarticle_add'), { 'content': '<p>great article</p>', 'date_0': '2008-03-18', 'date_1': '10:54:39' }) self.assertRedirects(post, reverse('admin:admin_views_customarticle_changelist')) self.assertEqual(CustomArticle.objects.all().count(), 1) article_pk = CustomArticle.objects.all()[0].pk
response = self.client.get(reverse('admin:admin_views_customarticle_change', args=(article_pk,))) self.assertTemplateUsed(response, 'custom_admin/change_form.html') response = self.client.get(reverse('admin:admin_views_customarticle_delete', args=(article_pk,))) self.assertTemplateUsed(response, 'custom_admin/delete_confirmation.html') response = self.client.post(reverse('admin:admin_views_customarticle_changelist'), data={ 'index': 0, 'action': ['delete_selected'], '_selected_action': ['1'], }) self.assertTemplateUsed(response, 'custom_admin/delete_selected_confirmation.html') response = self.client.get(reverse('admin:admin_views_customarticle_history', args=(article_pk,))) self.assertTemplateUsed(response, 'custom_admin/object_history.html')
self.assertNotContains(response, 'value="test_value"') self.assertContains(response, 'value="overridden_value"')
TEMPLATES=[{ 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'APP_DIRS': True, 'OPTIONS': { 'context_processors': [ 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], }, }],
opts = Article._meta
cls.adduser.user_permissions.add(get_perm(Article, get_permission_codename('add', opts))) cls.changeuser.user_permissions.add(get_perm(Article, get_permission_codename('change', opts))) cls.nostaffuser.user_permissions.add(get_perm(Article, get_permission_codename('change', opts)))
cls.deleteuser.user_permissions.add(get_perm(Article, get_permission_codename('delete', opts))) cls.deleteuser.user_permissions.add(get_perm(Section, get_permission_codename('delete', Section._meta)))
cls.index_url = reverse('admin:index') cls.super_login = { REDIRECT_FIELD_NAME: cls.index_url, 'username': 'super', 'password': 'secret', } cls.super_email_login = { REDIRECT_FIELD_NAME: cls.index_url, 'username': 'super@example.com', 'password': 'secret', } cls.super_email_bad_login = { REDIRECT_FIELD_NAME: cls.index_url, 'username': 'super@example.com', 'password': 'notsecret', } cls.adduser_login = { REDIRECT_FIELD_NAME: cls.index_url, 'username': 'adduser', 'password': 'secret', } cls.changeuser_login = { REDIRECT_FIELD_NAME: cls.index_url, 'username': 'changeuser', 'password': 'secret', } cls.deleteuser_login = { REDIRECT_FIELD_NAME: cls.index_url, 'username': 'deleteuser', 'password': 'secret', } cls.nostaff_login = { REDIRECT_FIELD_NAME: reverse('has_permission_admin:index'), 'username': 'nostaff', 'password': 'secret', } cls.joepublic_login = { REDIRECT_FIELD_NAME: cls.index_url, 'username': 'joepublic', 'password': 'secret', } cls.no_username_login = { REDIRECT_FIELD_NAME: cls.index_url, 'password': 'secret', }
response = self.client.get(self.index_url) self.assertRedirects(response, login_url) login = self.client.post(login_url, self.super_login) self.assertRedirects(login, self.index_url) self.assertFalse(login.context) self.client.get(reverse('admin:logout'))
response = self.client.get(self.index_url) self.assertEqual(response.status_code, 302) login = self.client.post(login_url, self.super_email_login) self.assertContains(login, ERROR_MESSAGE) login = self.client.post(login_url, self.super_email_bad_login) self.assertContains(login, ERROR_MESSAGE) new_user = User(username='jondoe', password='secret', email='super@example.com') new_user.save() login = self.client.post(login_url, self.super_email_login) self.assertContains(login, ERROR_MESSAGE)
response = self.client.get(self.index_url) self.assertEqual(response.status_code, 302) login = self.client.post(login_url, self.adduser_login) self.assertRedirects(login, self.index_url) self.assertFalse(login.context) self.client.get(reverse('admin:logout'))
response = self.client.get(self.index_url) self.assertEqual(response.status_code, 302) login = self.client.post(login_url, self.changeuser_login) self.assertRedirects(login, self.index_url) self.assertFalse(login.context) self.client.get(reverse('admin:logout'))
response = self.client.get(self.index_url) self.assertEqual(response.status_code, 302) login = self.client.post(login_url, self.deleteuser_login) self.assertRedirects(login, self.index_url) self.assertFalse(login.context) self.client.get(reverse('admin:logout'))
response = self.client.get(self.index_url) self.assertEqual(response.status_code, 302) login = self.client.post(login_url, self.joepublic_login) self.assertEqual(login.status_code, 200) self.assertContains(login, ERROR_MESSAGE)
response = self.client.get(self.index_url) self.assertEqual(response.status_code, 302) login = self.client.post(login_url, self.no_username_login) self.assertEqual(login.status_code, 200) form = login.context[0].get('form') self.assertEqual(form.errors['username'][0], 'This field is required.')
response = self.client.get(reverse('has_permission_admin:index')) self.assertEqual(response.status_code, 302) login = self.client.post(reverse('has_permission_admin:login'), self.joepublic_login) self.assertEqual(login.status_code, 200) self.assertContains(login, 'permission denied')
response = self.client.get(reverse('has_permission_admin:index')) self.assertEqual(response.status_code, 302) login = self.client.post(reverse('has_permission_admin:login'), self.nostaff_login) self.assertRedirects(login, reverse('has_permission_admin:index')) self.assertFalse(login.context) self.client.get(reverse('has_permission_admin:logout'))
response = self.client.get(reverse('has_permission_admin:index')) self.assertEqual(response.status_code, 302) login = self.client.post(reverse('has_permission_admin:login'), { REDIRECT_FIELD_NAME: reverse('has_permission_admin:index'), 'username': 'deleteuser', 'password': 'secret', }) self.assertRedirects(login, reverse('has_permission_admin:index')) self.assertFalse(login.context) self.client.get(reverse('has_permission_admin:logout'))
login = self.client.post(login_url, self.super_login) self.assertRedirects(login, self.index_url) self.assertFalse(login.context)
login = self.client.post(login_url, self.joepublic_login) self.assertEqual(login.status_code, 200) self.assertContains(login, ERROR_MESSAGE)
login = self.client.post(login_url, self.super_login) self.assertRedirects(login, self.index_url) self.assertFalse(login.context)
login = self.client.post(login_url, self.super_login) self.assertRedirects(login, self.index_url) self.assertFalse(login.context) self.client.get(reverse('admin:logout'))
response = self.client.get(self.index_url, follow=True) self.assertContains(response, 'login-form') self.assertNotContains(response, hint_template.format(''), status_code=200)
self.client.force_login(self.nostaffuser) response = self.client.get(self.index_url, follow=True) self.assertContains(response, 'login-form') self.assertContains(response, hint_template.format(self.nostaffuser.username), status_code=200)
self.client.force_login(self.changeuser) self.assertEqual(self.client.session.test_cookie_worked(), False) response = self.client.get(reverse('admin:admin_views_article_add')) self.assertEqual(response.status_code, 403) post = self.client.post(reverse('admin:admin_views_article_add'), add_dict) self.assertEqual(post.status_code, 403) self.assertEqual(Article.objects.count(), 3) self.client.get(reverse('admin:logout'))
self.client.force_login(self.adduser) addpage = self.client.get(reverse('admin:admin_views_article_add')) change_list_link = '&rsaquo; <a href="%s">Articles</a>' % reverse('admin:admin_views_article_changelist') self.assertNotContains( addpage, change_list_link, msg_prefix='User restricted to add permission is given link to change list view in breadcrumbs.' ) post = self.client.post(reverse('admin:admin_views_article_add'), add_dict) self.assertRedirects(post, self.index_url) self.assertEqual(Article.objects.count(), 4) self.assertEqual(len(mail.outbox), 1) self.assertEqual(mail.outbox[0].subject, 'Greetings from a created object') self.client.get(reverse('admin:logout'))
addition_log = LogEntry.objects.all()[0] new_article = Article.objects.last() article_ct = ContentType.objects.get_for_model(Article) self.assertEqual(addition_log.user_id, self.adduser.pk) self.assertEqual(addition_log.content_type_id, article_ct.pk) self.assertEqual(addition_log.object_id, str(new_article.pk)) self.assertEqual(addition_log.object_repr, "Dm ikke") self.assertEqual(addition_log.action_flag, ADDITION) self.assertEqual(addition_log.get_change_message(), "Added.")
self.client.force_login(self.superuser) addpage = self.client.get(reverse('admin:admin_views_article_add')) self.assertContains( addpage, change_list_link, msg_prefix='Unrestricted user is not given link to change list view in breadcrumbs.' ) post = self.client.post(reverse('admin:admin_views_article_add'), add_dict) self.assertRedirects(post, reverse('admin:admin_views_article_changelist')) self.assertEqual(Article.objects.count(), 5) self.client.get(reverse('admin:logout'))
self.client.force_login(self.joepublicuser) self.client.force_login(self.superuser) self.assertEqual(self.client.session.test_cookie_worked(), False)
self.client.force_login(self.adduser) response = self.client.get(article_changelist_url) self.assertEqual(response.status_code, 403) response = self.client.get(article_change_url) self.assertEqual(response.status_code, 403) post = self.client.post(article_change_url, change_dict) self.assertEqual(post.status_code, 403) self.client.get(reverse('admin:logout'))
self.client.force_login(self.changeuser) response = self.client.get(article_changelist_url) self.assertEqual(response.status_code, 200) response = self.client.get(article_change_url) self.assertEqual(response.status_code, 200) post = self.client.post(article_change_url, change_dict) self.assertRedirects(post, article_changelist_url) self.assertEqual(Article.objects.get(pk=self.a1.pk).content, '<p>edited article</p>')
change_dict['title'] = '' post = self.client.post(article_change_url, change_dict) self.assertContains( post, 'Please correct the error below.', msg_prefix='Singular error message not found in response to post with one error' )
r1 = RowLevelChangePermissionModel.objects.create(id=1, name="odd id") r2 = RowLevelChangePermissionModel.objects.create(id=2, name="even id") change_url_1 = reverse('admin:admin_views_rowlevelchangepermissionmodel_change', args=(r1.pk,)) change_url_2 = reverse('admin:admin_views_rowlevelchangepermissionmodel_change', args=(r2.pk,)) for login_user in [self.superuser, self.adduser, self.changeuser, self.deleteuser]: self.client.force_login(login_user) response = self.client.get(change_url_1) self.assertEqual(response.status_code, 403) response = self.client.post(change_url_1, {'name': 'changed'}) self.assertEqual(RowLevelChangePermissionModel.objects.get(id=1).name, 'odd id') self.assertEqual(response.status_code, 403) response = self.client.get(change_url_2) self.assertEqual(response.status_code, 200) response = self.client.post(change_url_2, {'name': 'changed'}) self.assertEqual(RowLevelChangePermissionModel.objects.get(id=2).name, 'changed') self.assertRedirects(response, self.index_url) self.client.get(reverse('admin:logout'))
article_count = Article.objects.count() self.client.force_login(self.adduser) post = self.client.post(article_change_url, change_dict_save_as_new) self.assertRedirects(post, self.index_url) self.assertEqual(Article.objects.count(), article_count + 1) self.client.logout()
article_count = Article.objects.count() self.client.force_login(self.changeuser) post = self.client.post(article_change_url, change_dict_save_as_new) self.assertEqual(post.status_code, 403) self.assertEqual(Article.objects.count(), article_count)
article_count = Article.objects.count() self.client.force_login(self.superuser) post = self.client.post(article_change_url, change_dict_save_as_new) self.assertEqual(Article.objects.count(), article_count + 1) new_article = Article.objects.latest('id') self.assertRedirects(post, reverse('admin:admin_views_article_change', args=(new_article.pk,)))
self.client.force_login(self.adduser) response = self.client.get(delete_url) self.assertEqual(response.status_code, 403) post = self.client.post(delete_url, delete_dict) self.assertEqual(post.status_code, 403) self.assertEqual(Article.objects.count(), 3) self.client.logout()
self.client.force_login(self.deleteuser) response = self.client.get(reverse('admin:admin_views_section_delete', args=(self.s1.pk,))) self.assertContains(response, "<h2>Summary</h2>") self.assertContains(response, "<li>Articles: 3</li>") self.assertContains(response, "admin_views/article/%s/" % self.a1.pk)
self.client.force_login(self.adduser) response = self.client.get(reverse('admin:admin_views_article_history', args=(self.a1.pk,))) self.assertEqual(response.status_code, 403) self.client.get(reverse('admin:logout'))
self.client.force_login(self.changeuser) response = self.client.get(reverse('admin:admin_views_article_history', args=(self.a1.pk,))) self.assertEqual(response.status_code, 200)
rl1 = RowLevelChangePermissionModel.objects.create(name="odd id") rl2 = RowLevelChangePermissionModel.objects.create(name="even id") for login_user in [self.superuser, self.adduser, self.changeuser, self.deleteuser]: self.client.force_login(login_user) url = reverse('admin:admin_views_rowlevelchangepermissionmodel_history', args=(rl1.pk,)) response = self.client.get(url) self.assertEqual(response.status_code, 403)
url = reverse('admin:admin_views_article_add') add_link_text = 'add_id_section' response = self.client.get(url) self.assertNotContains(response, add_link_text) user = User.objects.get(username='adduser') perm = get_perm(Section, get_permission_codename('add', Section._meta)) user.user_permissions.add(perm) response = self.client.get(url) self.assertContains(response, add_link_text)
url = reverse('admin:admin_views_article_add') change_link_text = 'change_id_section' response = self.client.get(url) self.assertFalse(get_change_related(response)) self.assertNotContains(response, change_link_text) user = User.objects.get(username='adduser') perm = get_perm(Section, get_permission_codename('change', Section._meta)) user.user_permissions.add(perm) response = self.client.get(url) self.assertTrue(get_change_related(response)) self.assertContains(response, change_link_text)
url = reverse('admin:admin_views_article_add') delete_link_text = 'delete_id_sub_section' response = self.client.get(url) self.assertFalse(get_delete_related(response)) self.assertNotContains(response, delete_link_text) user = User.objects.get(username='adduser') perm = get_perm(Section, get_permission_codename('delete', Section._meta)) user.user_permissions.add(perm) response = self.client.get(url) self.assertTrue(get_delete_related(response)) self.assertContains(response, delete_link_text)
change_user.user_permissions.remove(permission) response = self.client.get(reverse('admin:app_list', args=('admin_views',))) self.assertEqual(response.status_code, 403)
change_user.user_permissions.add(permission) response = self.client.get(reverse('admin:app_list', args=('admin_views',))) self.assertEqual(response.status_code, 200)
response = self.client.get(shortcut_url, follow=True) self.assertTemplateUsed(response, 'admin/login.html')
self.client.force_login(self.superuser) response = self.client.get(shortcut_url, follow=False) self.assertEqual(response.status_code, 302) six.assertRegex(self, response.url, 'http://(testserver|example.com)/dummy/foo/')
post_data = { "title": "Fun & games", "content": "Some content", "date_0": "2015-10-31", "date_1": "16:35:00", "_save": "Save", } response = self.client.post(reverse('admin:admin_views_article_add'), post_data, follow=True) self.assertContains( response, '<li class="success">The article "Fun &amp; games" was added successfully.</li>', html=True )
cls.changeuser = User.objects.create_user(username='changeuser', password='secret', is_staff=True) cls.changeuser.user_permissions.add(get_perm(Report, get_permission_codename('change', Report._meta)))
self.assertEqual(r.status_code, 200) self.client.get(reverse('admin:logout'))
pk_final_url = escape(iri_to_uri(quote(self.pk))) change_url = reverse( 'admin:admin_views_modelwithstringprimarykey_change', args=('__fk__',) ).replace('__fk__', pk_final_url) should_contain = '<th class="field-__str__"><a href="%s">%s</a></th>' % (change_url, escape(self.pk)) self.assertContains(response, should_contain)
change_url = reverse( 'admin:admin_views_modelwithstringprimarykey_change', args=('__fk__',) ).replace('__fk__', escape(iri_to_uri(quote(self.pk)))) should_contain = '<a href="%s">%s</a>' % (change_url, escape(self.pk)) self.assertContains(response, should_contain)
"chapter_set-TOTAL_FORMS": "6", "chapter_set-INITIAL_FORMS": "3", "chapter_set-MAX_NUM_FORMS": "0", "chapter_set-0-id": self.chap1.pk, "chapter_set-0-title": "Norske bostaver  skaper problemer", "chapter_set-0-content": "&lt;p&gt;Svrt frustrerende med UnicodeDecodeError&lt;/p&gt;", "chapter_set-1-id": self.chap2.id, "chapter_set-1-title": "Kjrlighet.", "chapter_set-1-content": "&lt;p&gt;La kjrligheten til de lidende seire.&lt;/p&gt;", "chapter_set-2-id": self.chap3.id, "chapter_set-2-title": "Need a title.", "chapter_set-2-content": "&lt;p&gt;Newest content&lt;/p&gt;", "chapter_set-3-id": "", "chapter_set-3-title": "", "chapter_set-3-content": "", "chapter_set-4-id": "", "chapter_set-4-title": "", "chapter_set-4-content": "", "chapter_set-5-id": "", "chapter_set-5-title": "", "chapter_set-5-content": "",
self.assertContains(response, "<input", count=19) self.assertContains(response, "<select", count=4)
data = { "form-TOTAL_FORMS": "3", "form-INITIAL_FORMS": "3", "form-MAX_NUM_FORMS": "0",
data = { "form-TOTAL_FORMS": "2", "form-INITIAL_FORMS": "2", "form-MAX_NUM_FORMS": "0",
data = { "form-TOTAL_FORMS": "1", "form-INITIAL_FORMS": "1", "form-MAX_NUM_FORMS": "0",
"form-1-id": str(fd2.id), "form-1-reference": "456", "form-1-driver": "bill", "form-1-restaurant": "thai",
"form-1-id": str(fd2.id), "form-1-reference": "456", "form-1-driver": "bill", "form-1-restaurant": "thai",
"form-2-id": str(fd3.id), "form-2-reference": "789", "form-2-driver": "bill", "form-2-restaurant": "thai",
data = { "form-TOTAL_FORMS": "1", "form-INITIAL_FORMS": "1", "form-MAX_NUM_FORMS": "0",
"_save": "Save",
data = { "form-TOTAL_FORMS": "1", "form-INITIAL_FORMS": "1", "form-MAX_NUM_FORMS": "0",
data = { "form-TOTAL_FORMS": "4", "form-INITIAL_FORMS": "4", "form-MAX_NUM_FORMS": "0",
"_save": "Save",
self.assertEqual(response.status_code, 302)
self.assertEqual(Category.objects.get(id=1).order, 14) self.assertEqual(Category.objects.get(id=2).order, 13) self.assertEqual(Category.objects.get(id=3).order, 1) self.assertEqual(Category.objects.get(id=4).order, 0)
data = { "form-TOTAL_FORMS": "3", "form-INITIAL_FORMS": "3", "form-MAX_NUM_FORMS": "0",
data = { "form-TOTAL_FORMS": "3", "form-INITIAL_FORMS": "3", "form-MAX_NUM_FORMS": "0",
self.assertContains(response, 'id="id_form-0-id"', 1) self.assertContains(response, 'id="id_form-1-id"', 1) self.assertContains( response, '<div class="hiddenfields">\n' '<input type="hidden" name="form-0-id" value="%d" id="id_form-0-id" />' '<input type="hidden" name="form-1-id" value="%d" id="id_form-1-id" />\n</div>' % (story2.id, story1.id), html=True ) self.assertContains(response, '<td class="field-id">%d</td>' % story1.id, 1) self.assertContains(response, '<td class="field-id">%d</td>' % story2.id, 1)
self.assertContains(response, 'id="id_form-0-id"', 1) self.assertContains(response, 'id="id_form-1-id"', 1) self.assertContains( response, '<div class="hiddenfields">\n' '<input type="hidden" name="form-0-id" value="%d" id="id_form-0-id" />' '<input type="hidden" name="form-1-id" value="%d" id="id_form-1-id" />\n</div>' % (story2.id, story1.id), html=True ) self.assertContains(response, '<th class="field-id"><a href="%s">%d</a></th>' % (link1, story1.id), 1) self.assertContains(response, '<th class="field-id"><a href="%s">%d</a></th>' % (link2, story2.id), 1)
self.assertContains(response, "\n1 recommendation\n")
self.assertContains(response, "\n1 recommendation\n")
self.assertContains(response, "\n0 recommendations\n")
self.assertContains(response, "\n1 person\n") self.assertContains(response, "Guido")
self.assertContains(response, "\n0 persons\n") self.assertNotContains(response, "Guido")
self.assertContains(response, "\n1 pluggable search person\n") self.assertContains(response, "Bob")
self.assertContains(response, "\n1 pluggable search person\n") self.assertContains(response, "Amy")
response = self.client.get(reverse('admin:admin_views_persona_add')) names = name_re.findall(response.content) self.assertEqual(len(names), len(set(names)))
post_data = { "name": "Test Name", "accounts-TOTAL_FORMS": "1", "accounts-INITIAL_FORMS": "0", "accounts-MAX_NUM_FORMS": "0", "accounts-0-username": foo_user, "accounts-2-TOTAL_FORMS": "1", "accounts-2-INITIAL_FORMS": "0", "accounts-2-MAX_NUM_FORMS": "0", "accounts-2-0-username": bar_user, }
self.assertEqual(len(names), len(set(names)))
response = self.client.post(reverse('admin:admin_views_question_changelist'), delete_confirmation_data) self.assertContains(response, "would require deleting the following protected related objects") self.assertEqual(Question.objects.count(), 2)
self.assertEqual(response.status_code, 200) self.assertContains(response, "<li>Unchangeable object: UnchangeableObject object</li>", 1, html=True)
'action': ['external_mail', 'delete_selected'], 'index': 0
self.assertEqual(len(mail.outbox), 1) self.assertEqual(mail.outbox[0].subject, 'Greetings from a function action')
post_data = {"name": "First Gadget"} response = self.client.post(reverse('admin:admin_views_gadget_add'), post_data)
response = self.client.get(reverse('admin:admin_views_gadget_changelist')) response = self.client.get(reverse('admin:admin_views_gadget_changelist')) self.assertEqual(response.status_code, 200) self.assertNotContains(response, 'First Gadget')
Person.objects.create(name='person1', gender=1) Person.objects.create(name='person2', gender=2) changelist_url = reverse('admin:admin_views_person_changelist')
with self.assertNumQueries(5): resp = self.client.get(changelist_url) self.assertEqual(resp.context['selection_note'], '0 of 2 selected') self.assertEqual(resp.context['selection_note_all'], 'All 2 selected') with self.assertNumQueries(5): extra = {'q': 'not_in_name'} resp = self.client.get(changelist_url, extra) self.assertEqual(resp.context['selection_note'], '0 of 0 selected') self.assertEqual(resp.context['selection_note_all'], 'All 0 selected') with self.assertNumQueries(5): extra = {'q': 'person'} resp = self.client.get(changelist_url, extra) self.assertEqual(resp.context['selection_note'], '0 of 2 selected') self.assertEqual(resp.context['selection_note_all'], 'All 2 selected') with self.assertNumQueries(5): extra = {'gender__exact': '1'} resp = self.client.get(changelist_url, extra) self.assertEqual(resp.context['selection_note'], '0 of 1 selected') self.assertEqual(resp.context['selection_note_all'], '1 selected')
self.assertEqual(CoverLetter.objects.count(), 0) post_data = { "author": "Candidate, Best", "_save": "Save", } response = self.client.post(reverse('admin:admin_views_coverletter_add'), post_data, follow=True) self.assertEqual(response.status_code, 200) self.assertEqual(CoverLetter.objects.count(), 1) pk = CoverLetter.objects.all()[0].pk self.assertContains( response, '<li class="success">The cover letter "<a href="%s">' 'Candidate, Best</a>" was added successfully.</li>' % reverse('admin:admin_views_coverletter_change', args=(pk,)), html=True )
self.assertEqual(ShortMessage.objects.count(), 0) post_data = { "content": "What's this SMS thing?", "_save": "Save", } response = self.client.post(reverse('admin:admin_views_shortmessage_add'), post_data, follow=True) self.assertEqual(response.status_code, 200) self.assertEqual(ShortMessage.objects.count(), 1) pk = ShortMessage.objects.all()[0].pk self.assertContains( response, '<li class="success">The short message "<a href="%s">' 'ShortMessage object</a>" was added successfully.</li>' % reverse('admin:admin_views_shortmessage_change', args=(pk,)), html=True )
self.assertEqual(Telegram.objects.count(), 0) post_data = { "title": "Urgent telegram", "_save": "Save", } response = self.client.post(reverse('admin:admin_views_telegram_add'), post_data, follow=True) self.assertEqual(response.status_code, 200) self.assertEqual(Telegram.objects.count(), 1) pk = Telegram.objects.all()[0].pk self.assertContains( response, '<li class="success">The telegram "<a href="%s">' 'Urgent telegram</a>" was added successfully.</li>' % reverse('admin:admin_views_telegram_change', args=(pk,)), html=True )
self.assertEqual(Paper.objects.count(), 0) post_data = { "title": "My Modified Paper Title", "_save": "Save", } response = self.client.post(reverse('admin:admin_views_paper_add'), post_data, follow=True) self.assertEqual(response.status_code, 200) self.assertEqual(Paper.objects.count(), 1) pk = Paper.objects.all()[0].pk self.assertContains( response, '<li class="success">The paper "<a href="%s">' 'Paper object</a>" was added successfully.</li>' % reverse('admin:admin_views_paper_change', args=(pk,)), html=True )
cl = CoverLetter.objects.create(author="John Doe") self.assertEqual(CoverLetter.objects.count(), 1) response = self.client.get(reverse('admin:admin_views_coverletter_change', args=(cl.pk,))) self.assertEqual(response.status_code, 200) post_data = { "author": "John Doe II", "_save": "Save", } url = reverse('admin:admin_views_coverletter_change', args=(cl.pk,)) response = self.client.post(url, post_data, follow=True) self.assertEqual(response.status_code, 200) self.assertEqual(CoverLetter.objects.count(), 1) self.assertContains( response, '<li class="success">The cover letter "<a href="%s">' 'John Doe II</a>" was changed successfully.</li>' % reverse('admin:admin_views_coverletter_change', args=(cl.pk,)), html=True )
sm = ShortMessage.objects.create(content="This is expensive") self.assertEqual(ShortMessage.objects.count(), 1) response = self.client.get(reverse('admin:admin_views_shortmessage_change', args=(sm.pk,))) self.assertEqual(response.status_code, 200) post_data = { "content": "Too expensive", "_save": "Save", } url = reverse('admin:admin_views_shortmessage_change', args=(sm.pk,)) response = self.client.post(url, post_data, follow=True) self.assertEqual(response.status_code, 200) self.assertEqual(ShortMessage.objects.count(), 1) self.assertContains( response, '<li class="success">The short message "<a href="%s">' 'ShortMessage object</a>" was changed successfully.</li>' % reverse('admin:admin_views_shortmessage_change', args=(sm.pk,)), html=True )
t = Telegram.objects.create(title="Frist Telegram") self.assertEqual(Telegram.objects.count(), 1) response = self.client.get(reverse('admin:admin_views_telegram_change', args=(t.pk,))) self.assertEqual(response.status_code, 200) post_data = { "title": "Telegram without typo", "_save": "Save", } response = self.client.post(reverse('admin:admin_views_telegram_change', args=(t.pk,)), post_data, follow=True) self.assertEqual(response.status_code, 200) self.assertEqual(Telegram.objects.count(), 1) self.assertContains( response, '<li class="success">The telegram "<a href="%s">' 'Telegram without typo</a>" was changed successfully.</li>' % reverse('admin:admin_views_telegram_change', args=(t.pk,)), html=True )
p = Paper.objects.create(title="My Paper Title") self.assertEqual(Paper.objects.count(), 1) response = self.client.get(reverse('admin:admin_views_paper_change', args=(p.pk,))) self.assertEqual(response.status_code, 200) post_data = { "title": "My Modified Paper Title", "_save": "Save", } response = self.client.post(reverse('admin:admin_views_paper_change', args=(p.pk,)), post_data, follow=True) self.assertEqual(response.status_code, 200) self.assertEqual(Paper.objects.count(), 1) self.assertContains( response, '<li class="success">The paper "<a href="%s">' 'Paper object</a>" was changed successfully.</li>' % reverse('admin:admin_views_paper_change', args=(p.pk,)), html=True )
file1 = tempfile.NamedTemporaryFile(suffix=".file1") file1.write(b'a' * (2 ** 21)) filename = file1.name file1.close() self.gallery = Gallery(name="Test Gallery") self.gallery.save() self.picture = Picture(name="Test Picture", image=filename, gallery=self.gallery) self.picture.save()
self.post_data['widget_set-0-name'] = "Widget 1" collector_url = reverse('admin:admin_views_collector_change', args=(self.collector.pk,)) response = self.client.post(collector_url, self.post_data) self.assertEqual(response.status_code, 302) self.assertEqual(Widget.objects.count(), 1) self.assertEqual(Widget.objects.all()[0].name, "Widget 1") widget_id = Widget.objects.all()[0].id
response = self.client.get(collector_url) self.assertContains(response, 'name="widget_set-0-id"')
self.post_data['widget_set-INITIAL_FORMS'] = "1" self.post_data['widget_set-0-id'] = str(widget_id) self.post_data['widget_set-0-name'] = "Widget 1" response = self.client.post(collector_url, self.post_data) self.assertEqual(response.status_code, 302) self.assertEqual(Widget.objects.count(), 1) self.assertEqual(Widget.objects.all()[0].name, "Widget 1")
self.post_data['widget_set-INITIAL_FORMS'] = "1" self.post_data['widget_set-0-id'] = str(widget_id) self.post_data['widget_set-0-name'] = "Widget 1 Updated" response = self.client.post(collector_url, self.post_data) self.assertEqual(response.status_code, 302) self.assertEqual(Widget.objects.count(), 1) self.assertEqual(Widget.objects.all()[0].name, "Widget 1 Updated")
self.post_data['grommet_set-0-name'] = "Grommet 1" collector_url = reverse('admin:admin_views_collector_change', args=(self.collector.pk,)) response = self.client.post(collector_url, self.post_data) self.assertEqual(response.status_code, 302) self.assertEqual(Grommet.objects.count(), 1) self.assertEqual(Grommet.objects.all()[0].name, "Grommet 1")
response = self.client.get(collector_url) self.assertContains(response, 'name="grommet_set-0-code"')
self.post_data['grommet_set-INITIAL_FORMS'] = "1" self.post_data['grommet_set-0-code'] = str(Grommet.objects.all()[0].code) self.post_data['grommet_set-0-name'] = "Grommet 1" response = self.client.post(collector_url, self.post_data) self.assertEqual(response.status_code, 302) self.assertEqual(Grommet.objects.count(), 1) self.assertEqual(Grommet.objects.all()[0].name, "Grommet 1")
self.post_data['grommet_set-INITIAL_FORMS'] = "1" self.post_data['grommet_set-0-code'] = str(Grommet.objects.all()[0].code) self.post_data['grommet_set-0-name'] = "Grommet 1 Updated" response = self.client.post(collector_url, self.post_data) self.assertEqual(response.status_code, 302) self.assertEqual(Grommet.objects.count(), 1) self.assertEqual(Grommet.objects.all()[0].name, "Grommet 1 Updated")
self.post_data['doohickey_set-0-code'] = "DH1" self.post_data['doohickey_set-0-name'] = "Doohickey 1" collector_url = reverse('admin:admin_views_collector_change', args=(self.collector.pk,)) response = self.client.post(collector_url, self.post_data) self.assertEqual(response.status_code, 302) self.assertEqual(DooHickey.objects.count(), 1) self.assertEqual(DooHickey.objects.all()[0].name, "Doohickey 1")
response = self.client.get(collector_url) self.assertContains(response, 'name="doohickey_set-0-code"')
self.post_data['doohickey_set-INITIAL_FORMS'] = "1" self.post_data['doohickey_set-0-code'] = "DH1" self.post_data['doohickey_set-0-name'] = "Doohickey 1" response = self.client.post(collector_url, self.post_data) self.assertEqual(response.status_code, 302) self.assertEqual(DooHickey.objects.count(), 1) self.assertEqual(DooHickey.objects.all()[0].name, "Doohickey 1")
self.post_data['doohickey_set-INITIAL_FORMS'] = "1" self.post_data['doohickey_set-0-code'] = "DH1" self.post_data['doohickey_set-0-name'] = "Doohickey 1 Updated" response = self.client.post(collector_url, self.post_data) self.assertEqual(response.status_code, 302) self.assertEqual(DooHickey.objects.count(), 1) self.assertEqual(DooHickey.objects.all()[0].name, "Doohickey 1 Updated")
self.post_data['whatsit_set-0-index'] = "42" self.post_data['whatsit_set-0-name'] = "Whatsit 1" collector_url = reverse('admin:admin_views_collector_change', args=(self.collector.pk,)) response = self.client.post(collector_url, self.post_data) self.assertEqual(response.status_code, 302) self.assertEqual(Whatsit.objects.count(), 1) self.assertEqual(Whatsit.objects.all()[0].name, "Whatsit 1")
response = self.client.get(collector_url) self.assertContains(response, 'name="whatsit_set-0-index"')
self.post_data['whatsit_set-INITIAL_FORMS'] = "1" self.post_data['whatsit_set-0-index'] = "42" self.post_data['whatsit_set-0-name'] = "Whatsit 1" response = self.client.post(collector_url, self.post_data) self.assertEqual(response.status_code, 302) self.assertEqual(Whatsit.objects.count(), 1) self.assertEqual(Whatsit.objects.all()[0].name, "Whatsit 1")
self.post_data['whatsit_set-INITIAL_FORMS'] = "1" self.post_data['whatsit_set-0-index'] = "42" self.post_data['whatsit_set-0-name'] = "Whatsit 1 Updated" response = self.client.post(collector_url, self.post_data) self.assertEqual(response.status_code, 302) self.assertEqual(Whatsit.objects.count(), 1) self.assertEqual(Whatsit.objects.all()[0].name, "Whatsit 1 Updated")
self.post_data['fancydoodad_set-0-name'] = "Fancy Doodad 1" collector_url = reverse('admin:admin_views_collector_change', args=(self.collector.pk,)) response = self.client.post(collector_url, self.post_data) self.assertEqual(response.status_code, 302) self.assertEqual(FancyDoodad.objects.count(), 1) self.assertEqual(FancyDoodad.objects.all()[0].name, "Fancy Doodad 1") doodad_pk = FancyDoodad.objects.all()[0].pk
response = self.client.get(collector_url) self.assertContains(response, 'name="fancydoodad_set-0-doodad_ptr"')
self.post_data['fancydoodad_set-INITIAL_FORMS'] = "1" self.post_data['fancydoodad_set-0-doodad_ptr'] = str(doodad_pk) self.post_data['fancydoodad_set-0-name'] = "Fancy Doodad 1" response = self.client.post(collector_url, self.post_data) self.assertEqual(response.status_code, 302) self.assertEqual(FancyDoodad.objects.count(), 1) self.assertEqual(FancyDoodad.objects.all()[0].name, "Fancy Doodad 1")
self.post_data['fancydoodad_set-INITIAL_FORMS'] = "1" self.post_data['fancydoodad_set-0-doodad_ptr'] = str(doodad_pk) self.post_data['fancydoodad_set-0-name'] = "Fancy Doodad 1 Updated" response = self.client.post(collector_url, self.post_data) self.assertEqual(response.status_code, 302) self.assertEqual(FancyDoodad.objects.count(), 1) self.assertEqual(FancyDoodad.objects.all()[0].name, "Fancy Doodad 1 Updated")
Category.objects.create(id=1, order=1, collector=self.collector) Category.objects.create(id=2, order=2, collector=self.collector) Category.objects.create(id=3, order=0, collector=self.collector) Category.objects.create(id=4, order=0, collector=self.collector)
self.post_data.update({ "name": "Frederick Clegg",
self.assertEqual(response.status_code, 302)
self.assertEqual(self.collector.category_set.count(), 4) self.assertEqual(Category.objects.get(id=1).order, 14) self.assertEqual(Category.objects.get(id=2).order, 13) self.assertEqual(Category.objects.get(id=3).order, 1) self.assertEqual(Category.objects.get(id=4).order, 0)
self.selenium.find_element_by_id('id_pubdate').send_keys('2012-02-18') self.get_select_option('#id_status', 'option two').click() self.selenium.find_element_by_id('id_name').send_keys(' this is the mAin nM and it\'s awome') slug1 = self.selenium.find_element_by_id('id_slug1').get_attribute('value') slug2 = self.selenium.find_element_by_id('id_slug2').get_attribute('value') slug3 = self.selenium.find_element_by_id('id_slug3').get_attribute('value') self.assertEqual(slug1, 'main-name-and-its-awesomeiii-2012-02-18') self.assertEqual(slug2, 'option-two-main-name-and-its-awesomeiii') self.assertEqual(slug3, 'main-n\xe0m\xeb-and-its-aw\u03b5\u0161ome\u0131\u0131\u0131')
self.selenium.find_element_by_id('id_relatedprepopulated_set-0-pubdate').send_keys('2011-12-17') self.get_select_option('#id_relatedprepopulated_set-0-status', 'option one').click() self.selenium.find_element_by_id('id_relatedprepopulated_set-0-name').send_keys( ' here is a ske inline ! ' ) slug1 = self.selenium.find_element_by_id('id_relatedprepopulated_set-0-slug1').get_attribute('value') slug2 = self.selenium.find_element_by_id('id_relatedprepopulated_set-0-slug2').get_attribute('value') self.assertEqual(slug1, 'here-stacked-inline-2011-12-17') self.assertEqual(slug2, 'option-one-here-stacked-inline')
self.selenium.find_elements_by_link_text('Add another Related prepopulated')[0].click() self.selenium.find_element_by_id('id_relatedprepopulated_set-1-pubdate').send_keys('1999-01-25') self.get_select_option('#id_relatedprepopulated_set-1-status', 'option two').click() self.selenium.find_element_by_id('id_relatedprepopulated_set-1-name').send_keys( ' now you haVe anther ske inline with a very ... ' 'loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooog text... ' ) slug1 = self.selenium.find_element_by_id('id_relatedprepopulated_set-1-slug1').get_attribute('value') slug2 = self.selenium.find_element_by_id('id_relatedprepopulated_set-1-slug2').get_attribute('value') self.assertEqual(slug1, 'now-you-have-another-stacked-inline-very-loooooooo') self.assertEqual(slug2, 'option-two-now-you-have-another-stacked-inline-very-looooooo')
self.selenium.find_element_by_id('id_relatedprepopulated_set-2-0-pubdate').send_keys('1234-12-07') self.get_select_option('#id_relatedprepopulated_set-2-0-status', 'option two').click() self.selenium.find_element_by_id('id_relatedprepopulated_set-2-0-name').send_keys( 'And now, with a tbla inline !!!' ) slug1 = self.selenium.find_element_by_id('id_relatedprepopulated_set-2-0-slug1').get_attribute('value') slug2 = self.selenium.find_element_by_id('id_relatedprepopulated_set-2-0-slug2').get_attribute('value') self.assertEqual(slug1, 'and-now-tabular-inline-1234-12-07') self.assertEqual(slug2, 'option-two-and-now-tabular-inline')
self.selenium.find_elements_by_link_text('Add another Related prepopulated')[1].click() self.selenium.find_element_by_id('id_relatedprepopulated_set-2-1-pubdate').send_keys('1981-08-22') self.get_select_option('#id_relatedprepopulated_set-2-1-status', 'option one').click() self.selenium.find_element_by_id('id_relatedprepopulated_set-2-1-name').send_keys( 'a tbla inline with ignored ;"&*^\%$#@-/`~ characters' ) slug1 = self.selenium.find_element_by_id('id_relatedprepopulated_set-2-1-slug1').get_attribute('value') slug2 = self.selenium.find_element_by_id('id_relatedprepopulated_set-2-1-slug2').get_attribute('value') self.assertEqual(slug1, 'tabular-inline-ignored-characters-1981-08-22') self.assertEqual(slug2, 'option-one-tabular-inline-ignored-characters')
self.selenium.find_element_by_xpath('//input[@value="Save"]').click() self.wait_page_loaded() self.assertEqual(MainPrepopulated.objects.all().count(), 1) MainPrepopulated.objects.get( name=' this is the mAin nM and it\'s awome', pubdate='2012-02-18', status='option two', slug1='main-name-and-its-awesomeiii-2012-02-18', slug2='option-two-main-name-and-its-awesomeiii', ) self.assertEqual(RelatedPrepopulated.objects.all().count(), 4) RelatedPrepopulated.objects.get( name=' here is a ske inline ! ', pubdate='2011-12-17', status='option one', slug1='here-stacked-inline-2011-12-17', slug2='option-one-here-stacked-inline', ) RelatedPrepopulated.objects.get( name=' now you haVe anther ske inline with a very ... loooooooooooooooooo', pubdate='1999-01-25', status='option two', slug1='now-you-have-another-stacked-inline-very-loooooooo', slug2='option-two-now-you-have-another-stacked-inline-very-looooooo', ) RelatedPrepopulated.objects.get( name='And now, with a tbla inline !!!', pubdate='1234-12-07', status='option two', slug1='and-now-tabular-inline-1234-12-07', slug2='option-two-and-now-tabular-inline', ) RelatedPrepopulated.objects.get( name='a tbla inline with ignored ;"&*^\%$#@-/`~ characters', pubdate='1981-08-22', status='option one', slug1='tabular-inline-ignored-characters-1981-08-22', slug2='option-one-tabular-inline-ignored-characters', )
item = MainPrepopulated.objects.create( name=' this is the mAin nM', pubdate='2012-02-18', status='option two', slug1='', slug2='', ) self.admin_login(username='super', password='secret', login_url=reverse('admin:index'))
slug1 = self.selenium.find_element_by_id('id_slug1').get_attribute('value') slug2 = self.selenium.find_element_by_id('id_slug2').get_attribute('value') self.assertEqual(slug1, 'main-name-best-2012-02-18') self.assertEqual(slug2, 'option-two-main-name-best')
self.selenium.find_element_by_xpath('//input[@value="Save"]').click() self.wait_page_loaded()
slug1 = self.selenium.find_element_by_id('id_slug1').get_attribute('value') slug2 = self.selenium.find_element_by_id('id_slug2').get_attribute('value') self.assertEqual(slug1, 'main-name-best-2012-02-18') self.assertEqual(slug2, 'option-two-main-name-best')
self.admin_login(username='super', password='secret', login_url=reverse('admin:index')) self.selenium.get(self.live_server_url + reverse('admin:admin_views_picture_add')) self.assertEqual( self.selenium.switch_to.active_element, self.selenium.find_element_by_id('id_name') )
self.selenium.get(self.live_server_url + reverse('admin:admin_views_reservation_add')) self.assertEqual( self.selenium.switch_to.active_element, self.selenium.find_element_by_id('id_start_date_0') )
self.selenium.find_element_by_class_name('cancel-link').click() self.wait_for_text('#content h1', 'Change pizza') self.assertEqual(self.selenium.current_url, full_url) self.assertEqual(Pizza.objects.count(), 1)
self.selenium.find_element_by_class_name('cancel-link').click() self.wait_for_text('#content h1', 'Change pizza') self.assertEqual(self.selenium.current_url, full_url) self.assertEqual(Pizza.objects.count(), 1) self.assertEqual(Topping.objects.count(), 2)
self.selenium.find_element_by_id('change_id_form-0-section').click() self.wait_for_popup() self.selenium.switch_to.window(self.selenium.window_handles[-1]) self.wait_for_text('#content h1', 'Change section') name_input = self.selenium.find_element_by_id('id_name') name_input.clear() name_input.send_keys('edited section') self.selenium.find_element_by_xpath('//input[@value="Save"]').click() self.selenium.switch_to.window(self.selenium.window_handles[0]) select = Select(self.selenium.find_element_by_id('id_form-0-section')) self.assertEqual(select.first_selected_option.text, 'edited section')
self.selenium.find_element_by_id('add_id_form-0-section').click() self.wait_for_popup() self.selenium.switch_to.window(self.selenium.window_handles[-1]) self.wait_for_text('#content h1', 'Add section') self.selenium.find_element_by_id('id_name').send_keys('new section') self.selenium.find_element_by_xpath('//input[@value="Save"]').click() self.selenium.switch_to.window(self.selenium.window_handles[0]) select = Select(self.selenium.find_element_by_id('id_form-0-section')) self.assertEqual(select.first_selected_option.text, 'new section')
self.selenium.find_element_by_link_text(str(parent2.pk)).click() self.selenium.switch_to.window(self.selenium.window_handles[0]) value = self.selenium.find_element_by_id('id_form-0-parent').get_attribute('value') self.assertEqual(value, str(parent2.pk))
self.assertContains(response, "<input", count=15) self.assertContains(response, formats.localize(datetime.date.today())) self.assertContains(response, "<label>Awesomeness level:</label>") self.assertContains(response, "Very awesome.") self.assertContains(response, "Unknown coolness.") self.assertContains(response, "foo")
self.assertContains(response, "Multiline<br />test<br />string") self.assertContains(response, "<p>Multiline<br />html<br />content</p>", html=True) self.assertContains(response, "InlineMultiline<br />test<br />string") self.assertContains(response, "<p>Multiline<br />html<br />content<br />with allow tags</p>", html=True)
self.assertContains(response, 'test<br /><br />test<br /><br />test<br /><br />test') self.assertContains(response, 'test<br />link')
pd.plot = None pd.save()
self.assertContains(response, threepwood.username, count=2) self.assertNotContains(response, marley.username)
m = re.search(br'<a href="([^"]*)"[^>]* id="lookup_id_inquisition"', response.content)
popup_url = urljoin(response.request['PATH_INFO'], popup_url) response2 = self.client.get(popup_url) self.assertContains(response2, "Spain") self.assertNotContains(response2, "England")
m = re.search(br'<a href="([^"]*)"[^>]* id="lookup_id_defendant0"', response.content)
popup_url = urljoin(response.request['PATH_INFO'], popup_url) response2 = self.client.get(popup_url) self.assertContains(response2, "Kilbraken") self.assertNotContains(response2, "Palin")
m = re.search(br'<a href="([^"]*)"[^>]* id="lookup_id_defendant1"', response.content)
popup_url = urljoin(response.request['PATH_INFO'], popup_url) response2 = self.client.get(popup_url) self.assertNotContains(response2, "Kilbraken") self.assertContains(response2, "Palin")
ContentType.objects.clear_cache()
ContentType.objects.clear_cache()
self.assertContains(response, 'class="form-row field-title"') self.assertContains(response, 'class="form-row field-content"') self.assertContains(response, 'class="form-row field-public"') self.assertContains(response, 'class="form-row field-awesomeness_level"') self.assertContains(response, 'class="form-row field-coolness"') self.assertContains(response, 'class="form-row field-value"')
self.assertContains(response, '<td class="field-url">') self.assertContains(response, '<td class="field-posted">')
response = self.client.get(reverse('admin:index')) self.assertContains(response, '<div class="app-admin_views module">') self.assertContains(response, '<tr class="model-actor">') self.assertContains(response, '<tr class="model-album">')
response = self.client.get(reverse('admin:app_list', args=('admin_views',))) self.assertContains(response, '<div class="app-admin_views module">') self.assertContains(response, '<tr class="model-actor">') self.assertContains(response, '<tr class="model-album">')
self.assertContains(response, "<h2>Built-in tags</h2>", count=2, html=True)
self.assertContains(response, '<h3 id="built_in-autoescape">autoescape</h3>', html=True) self.assertContains(response, '<li><a href="#built_in-autoescape">autoescape</a></li>', html=True)
self.assertContains(response, '<h3 id="flatpages-get_flatpages">get_flatpages</h3>', html=True) self.assertContains(response, '<li><a href="#flatpages-get_flatpages">get_flatpages</a></li>', html=True)
self.assertContains(response, "<h2>admin_list</h2>", count=2, html=True)
self.assertContains(response, '<h3 id="admin_list-admin_actions">admin_actions</h3>', html=True) self.assertContains(response, '<li><a href="#admin_list-admin_actions">admin_actions</a></li>', html=True)
self.assertContains(response, "<h2>Built-in filters</h2>", count=2, html=True)
self.assertContains(response, '<h3 id="built_in-add">add</h3>', html=True) self.assertContains(response, '<li><a href="#built_in-add">add</a></li>', html=True)
self.assertNotContains(response, 'release_date__day=') for date in DATES: self.assert_contains_month_link(response, date) self.assert_non_localized_year(response, 2000)
self.assertNotContains(response, 'release_date__day=') self.assertNotContains(response, 'release_date__month=') for date in DATES: self.assert_contains_year_link(response, date)
for date in DATES: url = '%s?release_date__year=%d' % ( reverse('admin:admin_views_podcast_changelist'), date.year) response = self.client.get(url) self.assert_contains_month_link(response, date) self.assert_non_localized_year(response, 2000) self.assert_non_localized_year(response, 2003) self.assert_non_localized_year(response, 2005)
response = self.client.get(reverse('admin:logout'), follow=True) self.assertEqual(response.status_code, 200) self.assertTemplateUsed(response, 'admin/login.html') self.assertEqual(response.request['PATH_INFO'], reverse('admin:login')) self.assertContains(response, '<input type="hidden" name="next" value="%s" />' % reverse('admin:index'))
change_user_url = reverse('admin:auth_user_change', args=(self.joepublicuser.pk,)) self.assertURLEqual( 'http://testserver{}?_changelist_filters=is_staff__exact%3D0%26is_superuser__exact%3D0'.format( change_user_url ), 'http://testserver{}?_changelist_filters=is_staff__exact%3D0%26is_superuser__exact%3D0'.format( change_user_url ) )
with self.assertRaises(AssertionError): self.assertURLEqual( 'http://testserver{}?_changelist_filters=is_staff__exact%3D0%26is_superuser__exact%3D0'.format( change_user_url ), 'http://testserver{}?_changelist_filters=is_staff__exact%3D1%26is_superuser__exact%3D1'.format( change_user_url ) )
self.assertURLEqual( 'http://testserver{}?_changelist_filters=is_staff__exact%3D0%26is_superuser__exact%3D0'.format( change_user_url ), '{}?_changelist_filters=is_staff__exact%3D0%26is_superuser__exact%3D0'.format(change_user_url) )
self.assertURLEqual( '{}?is_staff__exact=0&is_superuser__exact=0'.format(reverse('admin:auth_user_changelist')), '{}?is_superuser__exact=0&is_staff__exact=0'.format(reverse('admin:auth_user_changelist')) )
self.assertURLEqual( '{}?_changelist_filters=is_staff__exact%3D0%26is_superuser__exact%3D0'.format(change_user_url), '{}?_changelist_filters=is_superuser__exact%3D0%26is_staff__exact%3D0'.format(change_user_url) )
detail_link = re.search( '<a href="(.*?)">{}</a>'.format(self.joepublicuser.username), force_text(response.content) ) self.assertURLEqual(detail_link.group(1), self.get_change_url())
response = self.client.get(self.get_change_url()) self.assertEqual(response.status_code, 200)
form_action = re.search( '<form enctype="multipart/form-data" action="(.*?)" method="post" id="user_form".*?>', force_text(response.content) ) self.assertURLEqual(form_action.group(1), '?%s' % self.get_preserved_filters_querystring())
history_link = re.search( '<a href="(.*?)" class="historylink">History</a>', force_text(response.content) ) self.assertURLEqual(history_link.group(1), self.get_history_url())
delete_link = re.search( '<a href="(.*?)" class="deletelink">Delete</a>', force_text(response.content) ) self.assertURLEqual(delete_link.group(1), self.get_delete_url())
post_data = { 'username': 'joepublic', 'last_login_0': '2007-05-30', 'last_login_1': '13:20:10', 'date_joined_0': '2007-05-30', 'date_joined_1': '13:20:10', }
post_data['_continue'] = 1 response = self.client.post(self.get_change_url(), data=post_data) self.assertEqual(response.status_code, 302) self.assertURLEqual( response.url, self.get_change_url() ) post_data.pop('_continue')
post_data['_addanother'] = 1 response = self.client.post(self.get_change_url(), data=post_data) self.assertEqual(response.status_code, 302) self.assertURLEqual( response.url, self.get_add_url() ) post_data.pop('_addanother')
response = self.client.get(self.get_add_url()) self.assertEqual(response.status_code, 200)
form_action = re.search( '<form enctype="multipart/form-data" action="(.*?)" method="post" id="user_form".*?>', force_text(response.content) ) self.assertURLEqual(form_action.group(1), '?%s' % self.get_preserved_filters_querystring())
post_data['_save'] = 1 response = self.client.post(self.get_add_url(), data=post_data) self.assertEqual(response.status_code, 302) self.assertURLEqual( response.url, self.get_change_url(User.objects.get(username='dummy').pk) ) post_data.pop('_save')
post_data['username'] = 'dummy2' post_data['_continue'] = 1 response = self.client.post(self.get_add_url(), data=post_data) self.assertEqual(response.status_code, 302) self.assertURLEqual( response.url, self.get_change_url(User.objects.get(username='dummy2').pk) ) post_data.pop('_continue')
post_data['username'] = 'dummy3' post_data['_addanother'] = 1 response = self.client.post(self.get_add_url(), data=post_data) self.assertEqual(response.status_code, 302) self.assertURLEqual( response.url, self.get_add_url() ) post_data.pop('_addanother')
response = self.client.post(self.get_delete_url(), {'post': 'yes'}) self.assertEqual(response.status_code, 302) self.assertURLEqual( response.url, self.get_changelist_url() )
post_data = {"family_name": "Test1", "dependentchild_set-TOTAL_FORMS": "1", "dependentchild_set-INITIAL_FORMS": "0", "dependentchild_set-MAX_NUM_FORMS": "1", "dependentchild_set-0-id": "", "dependentchild_set-0-parent": "", "dependentchild_set-0-family_name": "Test2"} response = self.client.post(reverse('admin:admin_views_parentwithdependentchildren_add'), post_data)
self.assertIn('some_required_info', response.context['adminform'].form.errors)
for error_set in response.context['inline_admin_formset'].formset.errors: self.assertEqual(['Children must share a family name with their parents in this contrived test case'], error_set.get('__all__'))
post_data = {"family_name": "Test2", "dependentchild_set-TOTAL_FORMS": "1", "dependentchild_set-INITIAL_FORMS": "0", "dependentchild_set-MAX_NUM_FORMS": "1", "dependentchild_set-0-id": "", "dependentchild_set-0-parent": str(pwdc.id), "dependentchild_set-0-family_name": "Test1"} response = self.client.post( reverse('admin:admin_views_parentwithdependentchildren_change', args=(pwdc.id,)), post_data )
self.assertIn('some_required_info', response.context['adminform'].form.errors)
for error_set in response.context['inline_admin_formset'].formset.errors: self.assertEqual(['Children must share a family name with their parents in this contrived test case'], error_set.get('__all__'))
CityAdmin.view_on_site = True
self.assertEqual(len(apps), 2)
admin_views = apps[0] self.assertEqual(admin_views['app_label'], 'admin_views') self.assertEqual(len(admin_views['models']), 1) self.assertEqual(admin_views['models'][0]['object_name'], 'Article')
auth = apps[1] self.assertEqual(auth['app_label'], 'auth') self.assertEqual(len(auth['models']), 1) user = auth['models'][0] self.assertEqual(user['object_name'], 'User')
from __future__ import unicode_literals
return 'list-display-sketch'
return super(PersonAdmin, self).get_queryset(request).order_by('age')
return [ url(r'^extra/$', self.extra, name='cable_extra'), ]
class RelatedPrepopulatedInline1(admin.StackedInline): fieldsets = ( (None, { 'fields': (('pubdate', 'status'), ('name', 'slug1', 'slug2',),) }), ) formfield_overrides = {models.CharField: {'strip': False}} model = RelatedPrepopulated extra = 1 prepopulated_fields = {'slug1': ['name', 'pubdate'], 'slug2': ['status', 'name']}
urlpatterns = super(UnchangeableObjectAdmin, self).get_urls() return [p for p in urlpatterns if p.name and not p.name.endswith("_change")]
site.register(Book, inlines=[ChapterInline]) site.register(Promo) site.register(ChapterXtra1, ChapterXtra1Admin) site.register(Pizza, PizzaAdmin) site.register(Topping, ToppingAdmin) site.register(Album, AlbumAdmin) site.register(Question) site.register(Answer) site.register(PrePopulatedPost, PrePopulatedPostAdmin) site.register(ComplexSortedPerson, ComplexSortedPersonAdmin) site.register(FilteredManager, CustomManagerAdmin) site.register(PluggableSearchPerson, PluggableSearchPersonAdmin) site.register(PrePopulatedPostLargeSlug, PrePopulatedPostLargeSlugAdmin) site.register(AdminOrderedField, AdminOrderedFieldAdmin) site.register(AdminOrderedModelMethod, AdminOrderedModelMethodAdmin) site.register(AdminOrderedAdminMethod, AdminOrderedAdminMethodAdmin) site.register(AdminOrderedCallable, AdminOrderedCallableAdmin) site.register(Color2, CustomTemplateFilterColorAdmin) site.register(Simple, AttributeErrorRaisingAdmin) site.register(UserMessenger, MessageTestingAdmin) site.register(Choice, ChoiceList) site.register(ParentWithDependentChildren, ParentWithDependentChildrenAdmin) site.register(EmptyModelHidden, EmptyModelHiddenAdmin) site.register(EmptyModelVisible, EmptyModelVisibleAdmin) site.register(EmptyModelMixin, EmptyModelMixinAdmin) site.register(StumpJoke) site.register(Recipe) site.register(Ingredient) site.register(NotReferenced) site.register(ExplicitlyProvidedPK, GetFormsetsArgumentCheckingAdmin) site.register(ImplicitlyGeneratedPK, GetFormsetsArgumentCheckingAdmin)
site.register(User, UserAdmin) site.register(Group, GroupAdmin)
site2 = admin.AdminSite(name="namespaced_admin") site2.register(User, UserAdmin) site2.register(Group, GroupAdmin) site2.register(ParentWithUUIDPK) site2.register( RelatedWithUUIDPKModel, list_display=['pk', 'parent'], list_editable=['parent'], raw_id_fields=['parent'], ) site2.register(Person, save_as_continue=False)
def index(self, request, extra_context=None): return super(Admin2, self).index(request, {'foo': '*bar*'})
def get_queryset(self, request): qs = super(UserLimitedAdmin, self).get_queryset(request) return qs.filter(is_superuser=False)
Site.objects.clear_cache()
feed_elem = doc.getElementsByTagName('rss') self.assertEqual(len(feed_elem), 1) feed = feed_elem[0] self.assertEqual(feed.getAttribute('version'), '2.0')
chan_elem = feed.getElementsByTagName('channel') self.assertEqual(len(chan_elem), 1) chan = chan_elem[0]
d = Entry.objects.latest('published').published last_build_date = rfc2822_date(timezone.make_aware(d, TZ))
self.assertChildNodeContent(chan, { 'title': 'My blog', 'link': 'http://example.com/blog/', })
self.assertEqual( chan.getElementsByTagName('atom:link')[0].getAttribute('href'), 'http://example.com/syndication/rss2/' )
d = Entry.objects.get(pk=1).published pub_date = rfc2822_date(timezone.make_aware(d, TZ))
self.assertIsNone(item.getElementsByTagName( 'guid')[0].attributes.get('isPermaLink'))
feed_elem = doc.getElementsByTagName('rss') self.assertEqual(len(feed_elem), 1) feed = feed_elem[0] self.assertEqual(feed.getAttribute('version'), '0.91')
chan_elem = feed.getElementsByTagName('channel') self.assertEqual(len(chan_elem), 1) chan = chan_elem[0] self.assertChildNodes( chan, [ 'title', 'link', 'description', 'language', 'lastBuildDate', 'item', 'atom:link', 'ttl', 'copyright', 'category', ] )
self.assertChildNodeContent(chan, { 'title': 'My blog', 'link': 'http://example.com/blog/', }) self.assertCategories(chan, ['python', 'django'])
self.assertEqual( chan.getElementsByTagName('atom:link')[0].getAttribute('href'), 'http://example.com/syndication/rss091/' )
response = self.client.get('/syndication/atom/') feed = minidom.parseString(response.content).firstChild updated = feed.getElementsByTagName('updated')[0].firstChild.wholeText
response = self.client.get('/syndication/latest/') feed = minidom.parseString(response.content).firstChild updated = feed.getElementsByTagName('updated')[0].firstChild.wholeText
response = self.client.get('/syndication/naive-dates/') doc = minidom.parseString(response.content) updated = doc.getElementsByTagName('updated')[0].firstChild.wholeText
response = self.client.get('/syndication/no_pubdate/') self.assertFalse(response.has_header('Last-Modified'))
def item_title(self): return "Not in a template"
return item.published.replace(tzinfo=get_fixed_timezone(42))
with self.assertNumQueries(2): pools = tournament_1.pool_set.all() | Pool.objects.filter(pk=self.p3.pk) related_objects = set(pool.tournament for pool in pools) self.assertEqual(related_objects, {tournament_1, tournament_2}) with self.assertNumQueries(2): pools = Pool.objects.filter(pk=self.p3.pk) | tournament_1.pool_set.all() related_objects = set(pool.tournament for pool in pools) self.assertEqual(related_objects, {tournament_1, tournament_2})
thing = models.CharField(max_length=100, blank=True, choices=Things())
managed = False
managed = False
managed = False
management.call_command("check", stdout=six.StringIO())
date = models.DateField(db_column="event_date")
admin.site.empty_value_display = '???' m = ChildAdmin(Child, admin.site) cl = ChangeList(request, Child, *get_changelist_args(m)) cl.formset = None template = Template('{% load admin_list %}{% spaceless %}{% result_list cl %}{% endspaceless %}') context = Context({'cl': cl}) table_output = template.render(context) link = reverse('admin:admin_changelist_child_change', args=(new_child.id,)) row_html = ( '<tbody><tr class="row1"><th class="field-name"><a href="%s">name</a></th>' '<td class="field-parent nowrap">???</td></tr></tbody>' % link ) self.assertNotEqual(table_output.find(row_html), -1, 'Failed to find expected row element: %s' % table_output)
m.list_display = ['id', 'name', 'parent'] m.list_display_links = ['id'] m.list_editable = ['name'] cl = ChangeList(request, Child, *get_changelist_args(m)) FormSet = m.get_changelist_formset(request) cl.formset = FormSet(queryset=cl.result_list) template = Template('{% load admin_list %}{% spaceless %}{% result_list cl %}{% endspaceless %}') context = Context({'cl': cl}) table_output = template.render(context) hiddenfields_div = ( '<div class="hiddenfields">' '<input type="hidden" name="form-0-id" value="%d" id="id_form-0-id" />' '</div>' ) % new_child.id self.assertInHTML(hiddenfields_div, table_output, msg_prefix='Failed to find hidden fields')
editable_name_field = ( '<input name="form-0-name" value="name" class="vTextField" ' 'maxlength="30" type="text" id="id_form-0-name" />' ) self.assertInHTML( '<td class="field-name">%s</td>' % editable_name_field, table_output, msg_prefix='Failed to find "name" list_editable field', )
m.list_display = ['id', 'name', 'parent'] m.list_display_links = ['id'] m.list_editable = ['name'] with self.assertRaises(IncorrectLookupParameters): ChangeList(request, Child, *get_changelist_args(m))
m.custom_method = custom_method m.list_display = ['id', 'name', 'parent', 'custom_method']
self.assertEqual(cl.result_count, 1)
self.assertEqual(cl.result_count, 1)
self.assertEqual(cl.result_count, 1)
self.assertEqual(cl.result_count, 1)
self.assertEqual(cl.result_count, 1)
Child.objects.create(parent=parent, name='Daniel') Child.objects.create(parent=parent, name='Daniel')
self.assertEqual(cl.queryset.count(), 1)
self.assertEqual(cl.queryset.count(), 1)
self.assertEqual(cl.queryset.count(), 1)
m = ChildAdmin(Child, custom_site) cl = ChangeList(request, Child, *get_changelist_args(m)) self.assertEqual(cl.queryset.count(), 60) self.assertEqual(cl.paginator.count, 60) self.assertEqual(list(cl.paginator.page_range), [1, 2, 3, 4, 5, 6])
m = FilteredChildAdmin(Child, custom_site) cl = ChangeList(request, Child, *get_changelist_args(m)) self.assertEqual(cl.queryset.count(), 30) self.assertEqual(cl.paginator.count, 30) self.assertEqual(list(cl.paginator.page_range), [1, 2, 3])
m = custom_site._registry[Child] request = self._mocked_authenticated_request('/child/', user_noparents) response = m.changelist_view(request) self.assertNotContains(response, 'Parent object')
m = DynamicListDisplayChildAdmin(Child, custom_site) request = self._mocked_authenticated_request('/child/', user_parents) response = m.changelist_view(request) self.assertContains(response, 'Parent object')
custom_site.register(Child, ChildAdmin) m = custom_site._registry[Child] request = self._mocked_authenticated_request('/child/', user_noparents) response = m.changelist_view(request) self.assertContains(response, 'Parent object')
request = self.factory.get('/child/', data={ALL_VAR: ''})
m = ChildAdmin(Child, custom_site) m.list_max_show_all = 200 cl = ChangeList(request, Child, *get_changelist_args(m)) cl.get_results(request) self.assertEqual(len(cl.result_list), 60)
m = ChildAdmin(Child, custom_site) m.list_max_show_all = 30 cl = ChangeList(request, Child, *get_changelist_args(m)) cl.get_results(request) self.assertEqual(len(cl.result_list), 10)
self.assertContains(response, six.text_type(swallow.origin)) self.assertContains(response, six.text_type(swallow.load)) self.assertContains(response, six.text_type(swallow.speed)) self.assertContains(response, '<td class="field-swallowonetoone">-</td>') self.assertContains(response, '<td class="field-swallowonetoone">%s</td>' % swallow_o2o)
a = Swallow.objects.create(origin='Swallow A', load=4, speed=1) b = Swallow.objects.create(origin='Swallow B', load=2, speed=2) c = Swallow.objects.create(origin='Swallow C', load=5, speed=5) d = Swallow.objects.create(origin='Swallow D', load=9, speed=9)
data = { 'form-TOTAL_FORMS': '3', 'form-INITIAL_FORMS': '3', 'form-MIN_NUM_FORMS': '0', 'form-MAX_NUM_FORMS': '1000', 'form-0-id': str(d.pk), 'form-1-id': str(c.pk), 'form-2-id': str(a.pk), 'form-0-load': '9.0', 'form-0-speed': '9.0', 'form-1-load': '5.0', 'form-1-speed': '5.0', 'form-2-load': '5.0', 'form-2-speed': '4.0', '_save': 'Save', } response = self.client.post(changelist_url, data, follow=True, extra={'o': '-2'})
self.assertContains(response, '1 swallow was changed successfully.') self.assertContains(response, a.origin) a.refresh_from_db() self.assertEqual(a.load, float(data['form-2-load'])) self.assertEqual(a.speed, float(data['form-2-speed'])) b.refresh_from_db() self.assertEqual(b.load, 2) self.assertEqual(b.speed, 2) c.refresh_from_db() self.assertEqual(c.load, float(data['form-1-load'])) self.assertEqual(c.speed, float(data['form-1-speed'])) d.refresh_from_db() self.assertEqual(d.load, float(data['form-0-load'])) self.assertEqual(d.speed, float(data['form-0-speed'])) self.assertEqual(len(Swallow.objects.all()), 4)
check_results_order()
UnorderedObjectAdmin.ordering = ['bool'] check_results_order()
UnorderedObjectAdmin.ordering = ['bool', '-pk'] check_results_order() UnorderedObjectAdmin.ordering = ['bool', 'pk'] check_results_order(ascending=True) UnorderedObjectAdmin.ordering = ['-id', 'bool'] check_results_order() UnorderedObjectAdmin.ordering = ['id', 'bool'] check_results_order(ascending=True)
check_results_order(ascending=True)
OrderedObjectAdmin.ordering = ['bool'] check_results_order()
OrderedObjectAdmin.ordering = ['bool', '-pk'] check_results_order() OrderedObjectAdmin.ordering = ['bool', 'pk'] check_results_order(ascending=True) OrderedObjectAdmin.ordering = ['-id', 'bool'] check_results_order() OrderedObjectAdmin.ordering = ['id', 'bool'] check_results_order(ascending=True)
m = DynamicListFilterChildAdmin(Child, custom_site) request = self._mocked_authenticated_request('/child/', user_noparents) response = m.changelist_view(request) self.assertEqual(response.context_data['cl'].list_filter, ['name', 'age'])
m = DynamicListFilterChildAdmin(Child, custom_site) request = self._mocked_authenticated_request('/child/', user_parents) response = m.changelist_view(request) self.assertEqual(response.context_data['cl'].list_filter, ('parent', 'name', 'age'))
m = GroupAdmin(Group, custom_site) request = self.factory.get('/group/') cl = ChangeList(request, Group, *get_changelist_args(m)) per_page = cl.list_per_page = 10
Group.objects.all().delete() for i in range(objects_count): Group.objects.create(name='test band')
cl.page_num = page_num cl.get_results(request) real_page_range = pagination(cl)['page_range']
self.assertNotIn('Add ', response.rendered_content)
self.assertEqual(template.render(context), '')
rows = self.selenium.find_elements_by_css_selector( '%s #result_list tbody tr' % form_id) self.assertEqual(len(rows), 1)
selection_indicator = self.selenium.find_element_by_css_selector( '%s .action-counter' % form_id) self.assertEqual(selection_indicator.text, "0 of 1 selected")
row_selector = self.selenium.find_element_by_css_selector( '%s #result_list tbody tr:first-child .action-select' % form_id) row_selector.click() self.assertEqual(selection_indicator.text, "1 of 1 selected")
TestModel.objects.create(name='Test Object') self.i18n_model = I18nTestModel.objects.create(name='Test Object')
Site.objects.clear_cache()
response = self.client.get('/simple/sitemap.xml') self.assertContains(response, '<priority>0.5</priority>') self.assertContains(response, '<lastmod>%s</lastmod>' % date.today()) deactivate()
from __future__ import unicode_literals
from __future__ import unicode_literals
management.call_command("loaddata", "fixture1.json", verbosity=0) self.assertQuerysetEqual( Article.objects.all(), [ "Time to reform copyright", "Poker has no place on ESPN", ], lambda a: a.headline, )
management.call_command("loaddata", "fixture2.json", verbosity=0) self.assertQuerysetEqual( Article.objects.all(), [ "Django conquers world!", "Copyright is fine the way it is", "Poker has no place on ESPN", ], lambda a: a.headline, )
with self.assertRaisesMessage(CommandError, "No fixture named 'unknown' found."): management.call_command("loaddata", "unknown.json", verbosity=0)
self.assertTrue(apps.ready) self.assertTrue(Apps().ready)
self.assertEqual(apps.get_model('admin', 'loGentrY'), LogEntry) with self.assertRaises(LookupError): apps.get_model('Admin', 'LogEntry')
self.assertEqual(apps.get_model('admin.LogEntry'), LogEntry) with self.assertRaises(LookupError): apps.get_model('admin.LogExit') with self.assertRaises(ValueError): apps.get_model('admin_LogEntry')
body = {} new_apps = Apps(["apps"]) meta_contents = { 'app_label': "apps", 'apps': new_apps, } meta = type(str("Meta"), tuple(), meta_contents) body['Meta'] = meta body['__module__'] = TotallyNormal.__module__ temp_model = type(str("SouthPonies"), (models.Model,), body) self.assertListEqual(list(apps.get_app_config("apps").get_models()), old_models) with self.assertRaises(LookupError): apps.get_model("apps", "SouthPonies") self.assertEqual(new_apps.get_model("apps", "SouthPonies"), temp_model)
body = {} body['Meta'] = type(str("Meta"), tuple(), meta_contents) body['__module__'] = TotallyNormal.__module__ msg = ( "Model 'apps.southponies' was already registered. " "Reloading models is not advised as it can lead to inconsistencies, " "most notably with related models." ) with self.assertRaisesMessage(RuntimeWarning, msg): type(str("SouthPonies"), (models.Model,), body)
body = {} body['Meta'] = type(str("Meta"), tuple(), meta_contents) body['__module__'] = TotallyNormal.__module__ + '.whatever' with self.assertRaisesMessage(RuntimeError, "Conflicting 'southponies' models in application 'apps':"): type(str("SouthPonies"), (models.Model,), body)
model_keys = [('apps', model_name) for model_name in ['lazya', 'lazyb', 'lazyb', 'lazyc', 'lazya']] apps.lazy_model_operation(test_func, *model_keys)
self.assertSetEqual(set(apps._pending_operations) - initial_pending, {('apps', 'lazyb')})
apps.lazy_model_operation(test_func, ('apps', 'lazyb'))
self.assertSetEqual(set(apps._pending_operations) - initial_pending, {('apps', 'lazyc')})
self.assertListEqual(model_classes, [LazyA, LazyB, LazyB, LazyC, LazyA])
base_location = os.path.join(HERE, 'namespace_package_base') other_location = os.path.join(HERE, 'namespace_package_other_base') app_path = os.path.join(base_location, 'nsapp')
with extend_sys_path(self.base_location, self.other_location): with self.assertRaises(ImproperlyConfigured): with self.settings(INSTALLED_APPS=['nsapp']): pass
with extend_sys_path(self.base_location, self.other_location): with self.settings(INSTALLED_APPS=['nsapp.apps.NSAppConfig']): app_config = apps.get_app_config('nsapp') self.assertEqual(app_config.path, upath(self.app_path))
id2 = models.AutoField(primary_key=True) name2 = models.CharField(max_length=50)
self.assertIsNone(p2.image)
parent = models.OneToOneField(Place, models.CASCADE, primary_key=True, parent_link=True) main_site = models.ForeignKey(Place, models.CASCADE, related_name='lot')
w1 = Worker.objects.create(name="Fred", age=35, job="Quarry worker") Worker.objects.create(name="Barney", age=34, job="Quarry worker")
self.assertQuerysetEqual( Worker.objects.values("name"), [ {"name": "Barney"}, {"name": "Fred"}, ], lambda o: o )
self.assertEqual(Student._meta.ordering, [])
with self.assertRaises(AttributeError): CommonInfo.objects.all()
self.assertQuerysetEqual(Place.objects.filter(supplier__name="foo"), []) with self.assertRaises(FieldError): Restaurant.objects.filter(supplier__name="foo")
post = Post.objects.create(title="Lorem Ipsum") post.attached_comment_set.create(content="Save $ on V1agr@", is_spam=True) post.attached_link_set.create( content="The Web framework for perfections with deadlines.", url="http://www.djangoproject.com/" )
with self.assertRaises(AttributeError): getattr(post, "attached_%(class)s_set")
msg = "Cannot resolve keyword 'attached_comment_set' into field." with self.assertRaisesMessage(FieldError, msg): Post.objects.filter(attached_comment_set__is_spam=True)
self.assertEqual( [f.name for f in Restaurant._meta.fields], ["id", "name", "address", "place_ptr", "rating", "serves_hot_dogs", "serves_pizza", "chef"] ) self.assertEqual( [f.name for f in ItalianRestaurant._meta.fields], ["id", "name", "address", "place_ptr", "rating", "serves_hot_dogs", "serves_pizza", "chef", "restaurant_ptr", "serves_gnocchi"], ) self.assertEqual(Restaurant._meta.ordering, ["-rating"])
self.assertEqual(s.titles.related_val, (s.id,)) self.assertQuerysetEqual(s.titles.all(), [])
with CaptureQueriesContext(connection) as captured_queries: Place.objects.filter(pk=supplier.pk).update(name=supplier.name) expected_sql = captured_queries[0]['sql'] with CaptureQueriesContext(connection) as captured_queries: supplier.save(update_fields=('name',)) for query in captured_queries: sql = query['sql'] if 'UPDATE' in sql: self.assertEqual(expected_sql, sql)
self.assertNotEqual(Place(id=1), Restaurant(id=1)) self.assertNotEqual(Restaurant(id=1), Place(id=1))
self.assertQuerysetEqual( Restaurant.objects.filter(name="Demon Dogs"), [ "Demon Dogs", ], attrgetter("name") ) self.assertQuerysetEqual( ItalianRestaurant.objects.filter(address="1234 W. Ash"), [ "Ristorante Miron", ], attrgetter("name") )
p = Place.objects.get(name="Demon Dogs") self.assertIs(type(p), Place)
self.assertEqual( Place.objects.get(name="Demon Dogs").restaurant, Restaurant.objects.get(name="Demon Dogs") ) self.assertEqual( Place.objects.get(name="Ristorante Miron").restaurant.italianrestaurant, ItalianRestaurant.objects.get(name="Ristorante Miron") ) self.assertEqual( Restaurant.objects.get(name="Ristorante Miron").italianrestaurant, ItalianRestaurant.objects.get(name="Ristorante Miron") )
with self.assertRaises(ItalianRestaurant.DoesNotExist): Place.objects.get(name="Demon Dogs").restaurant.italianrestaurant
with self.assertRaises(Place.DoesNotExist): ItalianRestaurant.objects.get(name="The Noodle Void")
with self.assertRaises(Place.MultipleObjectsReturned): Restaurant.objects.get()
s1 = Supplier.objects.create(name="Joe's Chickens", address="123 Sesame St") s1.customers .set([self.restaurant, self.italian_restaurant]) s2 = Supplier.objects.create(name="Luigi's Pasta", address="456 Sesame St") s2.customers.set([self.italian_restaurant])
p = Place.objects.get(name="Joe's Chickens") with self.assertRaises(Restaurant.DoesNotExist): p.restaurant
rows = Restaurant.objects.filter( serves_hot_dogs=True, name__contains="D" ).update( name="Demon Puppies", serves_hot_dogs=False ) self.assertEqual(rows, 1)
self.assertQuerysetEqual( ItalianRestaurant.objects.values("name", "rating"), [ {"rating": 4, "name": "Ristorante Miron"}, ], lambda o: o )
self.assertNumQueries( 2, lambda: ItalianRestaurant.objects.all()[0].chef ) self.assertNumQueries( 1, lambda: ItalianRestaurant.objects.select_related("chef")[0].chef )
with self.assertNumQueries(2): objs = list(qs.all()) self.assertTrue(objs[1].italianrestaurant.serves_gnocchi)
self.assertEqual(qs[0].name, 'Demon Dogs') self.assertEqual(qs[0].rating, 2) self.assertEqual(qs[1].italianrestaurant.name, 'Ristorante Miron') self.assertEqual(qs[1].italianrestaurant.rating, 4)
Supplier.objects.create( name="Central market", address="610 some street", ) self.assertQuerysetEqual( Place.objects.filter(supplier__isnull=False), [ "Central market", ], attrgetter("name") ) self.assertQuerysetEqual( Place.objects.filter(supplier__isnull=True).order_by("name"), [ "Demon Dogs", "Ristorante Miron", ], attrgetter("name") )
Supplier.objects.create( name="Central market", address="610 some street", ) self.assertQuerysetEqual( Place.objects.exclude(supplier__isnull=False).order_by("name"), [ "Demon Dogs", "Ristorante Miron", ], attrgetter("name") ) self.assertQuerysetEqual( Place.objects.exclude(supplier__isnull=True), [ "Central market", ], attrgetter("name") )
logger = logging.getLogger('django.server') original_handlers = logger.handlers logger.handlers = [logging.NullHandler()] try: request = WSGIRequest(RequestFactory().get('/').environ) request.makefile = lambda *args, **kwargs: BytesIO() handler = WSGIRequestHandler(request, '192.168.0.2', None) level_status_codes = { 'info': [200, 301, 304], 'warning': [400, 403, 404], 'error': [500, 503], }
messages = _log_level_code(level, status_code) self.assertIn('GET A %d' % status_code, messages[0])
for wrong_level in level_status_codes.keys(): if wrong_level != level: messages = _log_level_code(wrong_level, status_code) self.assertEqual(len(messages), 0)
class UnclosableBytesIO(BytesIO): def close(self): pass
with patch_logger('django.server', 'info'): WSGIRequestHandler(request, '192.168.0.2', server)
address_predefined = 'DJANGO_LIVE_TEST_SERVER_ADDRESS' in os.environ old_address = os.environ.get('DJANGO_LIVE_TEST_SERVER_ADDRESS')
cls.raises_exception('localhost', ImproperlyConfigured)
cls.raises_exception('blahblahblah:8081', socket.error)
cls.raises_exception('localhost:8081,', ImproperlyConfigured) cls.raises_exception('localhost:8081,blah', ImproperlyConfigured) cls.raises_exception('localhost:8081-', ImproperlyConfigured) cls.raises_exception('localhost:8081-blah', ImproperlyConfigured) cls.raises_exception('localhost:8081-8082-8083', ImproperlyConfigured)
if address_predefined: os.environ['DJANGO_LIVE_TEST_SERVER_ADDRESS'] = old_address else: del os.environ['DJANGO_LIVE_TEST_SERVER_ADDRESS']
cls.live_server_url_test = [cls.live_server_url]
pass
return
self.assertNotEqual( self.live_server_url, TestCase.live_server_url, "Acquired duplicate server addresses for server threads: %s" % self.live_server_url )
field12 = models.IntegerField("verbose field12") field13 = models.GenericIPAddressField("verbose field13", protocol="ipv4") field14 = models.NullBooleanField("verbose field14") field15 = models.PositiveIntegerField("verbose field15") field16 = models.PositiveSmallIntegerField("verbose field16") field17 = models.SlugField("verbose field17") field18 = models.SmallIntegerField("verbose field18") field19 = models.TextField("verbose field19") field20 = models.TimeField("verbose field20") field21 = models.URLField("verbose field21") field22 = models.UUIDField("verbose field22") field23 = models.DurationField("verbose field23")
class DecimalLessThanOne(models.Model): d = models.DecimalField(max_digits=3, decimal_places=3)
class FieldClassAttributeModel(models.Model): field_class = models.CharField
temp_storage_dir = tempfile.mkdtemp() temp_storage = FileSystemStorage(temp_storage_dir) temp_upload_to_dir = os.path.join(temp_storage.location, 'tests')
from __future__ import unicode_literals
b5 = BooleanModel.objects.all().extra(select={'string_col': 'string'})[0] self.assertNotIsInstance(b5.pk, bool)
ma = FksToBooleans.objects.select_related('bf').get(pk=m1.id) self.assertEqual(ma.bf.bfield, True) self.assertEqual(ma.nbf.nbfield, True)
mb = FksToBooleans.objects.select_related().get(pk=m1.id) mc = FksToBooleans.objects.select_related().get(pk=m2.id) self.assertEqual(mb.bf.bfield, True) self.assertEqual(mb.nbf.nbfield, True) self.assertEqual(mc.bf.bfield, False) self.assertEqual(mc.nbf.nbfield, False)
self.assertEqual(1, true_cardinality_flags)
self.assertEqual(MANY_TO_MANY_CLASSES, {f.__class__ for f in m2m_type_fields})
for field in m2m_type_fields: reverse_field = field.remote_field self.assertTrue(reverse_field.is_relation) self.assertTrue(reverse_field.many_to_many) self.assertTrue(reverse_field.related_model)
self.assertEqual(ONE_TO_MANY_CLASSES, {f.__class__ for f in o2m_type_fields})
for field in o2m_type_fields: if field.concrete: reverse_field = field.remote_field self.assertTrue(reverse_field.is_relation and reverse_field.many_to_one)
self.assertEqual(MANY_TO_ONE_CLASSES, {f.__class__ for f in m2o_type_fields})
for obj in m2o_type_fields: if hasattr(obj, 'field'): reverse_field = obj.field self.assertTrue(reverse_field.is_relation and reverse_field.one_to_many)
self.assertEqual(ONE_TO_ONE_CLASSES, {f.__class__ for f in o2o_type_fields})
for obj in o2o_type_fields: if hasattr(obj, 'field'): reverse_field = obj.field self.assertTrue(reverse_field.is_relation and reverse_field.one_to_one)
self.assertFalse(AllFieldsModel._meta.get_field('m2m').null) self.assertTrue(AllFieldsModel._meta.get_field('reverse2').null)
lazy_func = lazy(lambda x: 0 / 0, int) f = models.CharField(choices=[(lazy_func('group'), (('a', 'A'), ('b', 'B')))]) self.assertEqual(f.get_choices(True)[0], ('', '---------'))
class Person(): pass PersonWithHeight = PersonWithHeightAndWidth = PersonDimensionsFirst = Person PersonTwoImages = Person
PersonModel = PersonWithHeightAndWidth File = ImageFile
if width is None and height is None: with self.assertRaises(ValueError): getattr(field, 'width') with self.assertRaises(ValueError): getattr(field, 'height') else: self.assertEqual(field.width, width) self.assertEqual(field.height, height)
width_field_name = field_name + '_width' if hasattr(instance, width_field_name): self.assertEqual(getattr(instance, width_field_name), width) height_field_name = field_name + '_height' if hasattr(instance, height_field_name): self.assertEqual(getattr(instance, height_field_name), height)
p1 = self.PersonModel(name="Joe") p1.mugshot.save("mug", self.file1) p2 = self.PersonModel(name="Bob") p2.mugshot.save("mug", self.file2) self.assertEqual(p1.mugshot == p2.mugshot, False) self.assertEqual(p1.mugshot != p2.mugshot, True)
p1_db = self.PersonModel.objects.get(name="Joe") self.assertEqual(p1_db.mugshot == p2.mugshot, False) self.assertEqual(p1_db.mugshot != p2.mugshot, True)
self.assertEqual(p1_db.mugshot == p1.mugshot, True) self.assertEqual(hash(p1_db.mugshot), hash(p1.mugshot)) self.assertEqual(p1_db.mugshot != p1.mugshot, False)
p = self.PersonModel.objects.get(name="Joan") self.assertEqual(p.mugshot.closed, True)
p.mugshot.size self.assertEqual(p.mugshot.closed, True)
self.assertIsInstance(p.mugshot, TestImageFieldFile) self.assertEqual(bool(p.mugshot), False)
p = self.PersonModel(name='Joe') p.mugshot = self.file1 self.check_dimensions(p, 4, 8)
p.mugshot = None self.check_dimensions(p, None, None)
p.mugshot.save("mug", self.file2) self.check_dimensions(p, 8, 4)
p.mugshot.delete(save=False) self.assertEqual(p.mugshot, None) self.check_dimensions(p, None, None)
p.mugshot.save("mug", self.file1) self.check_dimensions(p, 4, 8)
p = self.PersonModel.objects.get(name='Joe') self.assertEqual(p.mugshot.was_opened, False) self.check_dimensions(p, 4, 8) self.assertEqual(p.mugshot.was_opened, True) p.mugshot.was_opened = False self.check_dimensions(p, 4, 8) self.assertEqual(p.mugshot.was_opened, False)
p.mugshot = self.file2 self.check_dimensions(p, 8, 4) self.assertEqual(p.mugshot.was_opened, True)
p.mugshot = None self.check_dimensions(p, None, None, 'mugshot') self.check_dimensions(p, 8, 4, 'headshot') p.headshot = None self.check_dimensions(p, None, None, 'mugshot') self.check_dimensions(p, None, None, 'headshot')
p.headshot.delete(save=True) self.check_dimensions(p, 4, 8, 'mugshot') self.check_dimensions(p, None, None, 'headshot') p.mugshot.delete(save=False) self.check_dimensions(p, None, None, 'mugshot') self.check_dimensions(p, None, None, 'headshot')
p.mugshot.save("mug", self.file1) p.headshot.save("head", self.file2) self.check_dimensions(p, 4, 8, 'mugshot') self.check_dimensions(p, 8, 4, 'headshot')
p = self.PersonModel.objects.get(name='Joe') self.assertEqual(p.mugshot.was_opened, False) self.assertEqual(p.headshot.was_opened, False) self.check_dimensions(p, 4, 8, 'mugshot') self.check_dimensions(p, 8, 4, 'headshot') self.assertEqual(p.mugshot.was_opened, True) self.assertEqual(p.headshot.was_opened, True) p.mugshot.was_opened = False p.headshot.was_opened = False self.check_dimensions(p, 4, 8, 'mugshot') self.check_dimensions(p, 8, 4, 'headshot') self.assertEqual(p.mugshot.was_opened, False) self.assertEqual(p.headshot.was_opened, False)
p.mugshot = self.file2 p.headshot = self.file1 self.check_dimensions(p, 8, 4, 'mugshot') self.check_dimensions(p, 4, 8, 'headshot') self.assertEqual(p.mugshot.was_opened, True) self.assertEqual(p.headshot.was_opened, True)
u1_found = PrimaryKeyUUIDModel.objects.filter(id=u1.id).exists() u2_found = PrimaryKeyUUIDModel.objects.exclude(id=u1.id).exists() self.assertTrue(u1_found) self.assertTrue(u2_found) self.assertEqual(PrimaryKeyUUIDModel.objects.count(), 2)
u1 = PrimaryKeyUUIDModel.objects.create() u2 = PrimaryKeyUUIDModel.objects.create() r = RelatedToUUIDModel.objects.create(uuid_fk=u1) RelatedToUUIDModel.objects.update(uuid_fk=u2) r.refresh_from_db() self.assertEqual(r.uuid_fk, u2)
UUIDGrandchild().save()
available_apps = ['model_fields']
Foo.objects.filter(d__gte=100000000000)
DateTimeModel.objects.create(d=d, dt=dt2, t=t) self.assertEqual(m, DateTimeModel.objects.get(dt__date=d))
dt1 = datetime.datetime(2014, 3, 12, 10, 22, 23, 240000, tzinfo=timezone.get_current_timezone()) dt2 = datetime.datetime(2014, 3, 12, 21, 22, 23, 240000, tzinfo=timezone.get_current_timezone()) t = datetime.time(21, 22, 23, 240000) m1 = DateTimeModel.objects.create(d=d, dt=dt1, t=t) m2 = DateTimeModel.objects.create(d=d, dt=dt2, t=t) self.assertQuerysetEqual( DateTimeModel.objects.filter(dt__date=d), [repr(m1), repr(m2)], ordered=False ) with self.settings(TIME_ZONE='UTC'): self.assertQuerysetEqual(DateTimeModel.objects.filter(dt__date=d), [repr(m1)])
instance.size = instance with transaction.atomic(): with self.assertRaises(TypeError): instance.save() instance.size = 2.5 instance.save() self.assertTrue(instance.id) instance.size = instance msg = ( 'Tried to update field model_fields.FloatModel.size with a model ' 'instance, <FloatModel: FloatModel object>. Use a value ' 'compatible with FloatField.' ) with transaction.atomic(): with self.assertRaisesMessage(TypeError, msg): instance.save() obj = FloatModel.objects.get(pk=instance.id) obj.size = obj with self.assertRaises(TypeError): obj.save()
dm.save() dm = DataModel.objects.get(pk=dm.pk) self.assertEqual(bytes(dm.data), bytes(bdata)) self.assertEqual(bytes(dm.short_data), b'\x08')
from __future__ import unicode_literals
self.client.defaults['HTTP_IF_NONE_MATCH'] = '"%s", "%s"' % (ETAG, EXPIRED_ETAG) response = self.client.get('/condition/') self.assertNotModified(response)
self.client.defaults['HTTP_IF_MODIFIED_SINCE'] = LAST_MODIFIED_STR self.client.defaults['HTTP_IF_NONE_MATCH'] = '"%s"' % ETAG response = self.client.get('/condition/') self.assertNotModified(response)
class Rock(Mineral): tags = GenericRelation(TaggedItem)
class AllowsNullGFK(models.Model): content_type = models.ForeignKey(ContentType, models.SET_NULL, null=True) object_id = models.PositiveIntegerField(null=True) content_object = GenericForeignKey()
self.bacon.tags.create(tag="fatty") self.bacon.tags.create(tag="salty") self.lion.tags.create(tag="yellow") self.lion.tags.create(tag="hairy")
self.comp_func = lambda obj: ( obj.tag, obj.content_type.model_class(), obj.object_id )
self.assertEqual(tag.tag, 'stinky')
TaggedItem.objects.create(content_object=self.quartz, tag="shiny") TaggedItem.objects.create(content_object=self.quartz, tag="clearish")
with self.assertNumQueries(1): bacon.tags.add(t1, t2) self.assertEqual(t1.content_object, bacon) self.assertEqual(t2.content_object, bacon)
with self.assertNumQueries(2): bacon.tags.add(t1, t2, bulk=False) self.assertEqual(t1.content_object, bacon) self.assertEqual(t2.content_object, bacon)
bacon = Vegetable.objects.create(name="Bacon", is_yucky=False) bacon.tags.create(tag="fatty") bacon.tags.create(tag="salty") self.assertEqual(2, bacon.tags.count())
with self.assertRaises(FieldError): TaggedItem.objects.filter(vegetable__isnull=True)
tiger = Animal.objects.create(common_name="tiger") cheetah = Animal.objects.create(common_name="cheetah") bear = Animal.objects.create(common_name="bear")
Comparison.objects.create( first_obj=cheetah, other_obj=tiger, comparative="faster" ) Comparison.objects.create( first_obj=tiger, other_obj=cheetah, comparative="cooler" )
tiger.comparisons.create(other_obj=bear, comparative="cooler") tiger.comparisons.create(other_obj=cheetah, comparative="stronger") self.assertQuerysetEqual(cheetah.comparisons.all(), [ "<Comparison: cheetah is faster than tiger>" ])
self.assertQuerysetEqual(tiger.comparisons.filter(comparative="cooler"), [ "<Comparison: tiger is cooler than cheetah>", "<Comparison: tiger is cooler than bear>", ], ordered=False)
subjective = ["cooler"] tiger.comparisons.filter(comparative__in=subjective).delete() self.assertQuerysetEqual(Comparison.objects.all(), [ "<Comparison: cheetah is faster than tiger>", "<Comparison: tiger is stronger than cheetah>" ], ordered=False)
cheetah.delete() self.assertQuerysetEqual(Comparison.objects.all(), [ "<Comparison: tiger is stronger than None>" ])
quartz = Mineral.objects.create(name="Quartz", hardness=7) valuedtag = ValuableTaggedItem.objects.create( content_object=quartz, tag="shiny", value=10 ) self.assertEqual(valuedtag.content_object, quartz)
granite = ValuableRock.objects.create(name='granite', hardness=5) ValuableTaggedItem.objects.create(content_object=granite, tag="countertop", value=1) self.assertEqual(ValuableRock.objects.filter(tags__value=1).count(), 1) self.assertEqual(ValuableRock.objects.filter(tags__tag="countertop").count(), 1)
tailless = Gecko.objects.create(has_tail=False) tag = TaggedItem.objects.create(content_object=tailless, tag="lizard") self.assertEqual(tag.content_object, tailless)
quartz = Mineral.objects.create(name="Quartz", hardness=7) tag, created = TaggedItem.objects.get_or_create(tag="shiny", defaults={'content_object': quartz}) self.assertTrue(created) self.assertEqual(tag.tag, "shiny") self.assertEqual(tag.content_object.id, quartz.id)
quartz = Mineral.objects.create(name="Quartz", hardness=7) diamond = Mineral.objects.create(name="Diamond", hardness=7) tag, created = TaggedItem.objects.update_or_create(tag="shiny", defaults={'content_object': quartz}) self.assertTrue(created) self.assertEqual(tag.content_object.id, quartz.id)
new_id = max(Vegetable.objects.order_by('-id')[0].id, Mineral.objects.order_by('-id')[0].id) + 1 broccoli = Vegetable.objects.create(id=new_id, name="Broccoli") diamond = Mineral.objects.create(id=new_id, name="Diamond", hardness=7) tag = TaggedItem.objects.create(content_object=broccoli, tag="yummy") tag.content_type = ContentType.objects.get_for_model(diamond) self.assertEqual(tag.content_object, diamond)
AllowsNullGFK(content_object=None) TaggedItem(content_object=None)
third = models.ForeignKey(OuterB, models.SET_NULL, null=True)
self.assertQuerysetEqual(Choice.objects.filter(choice__exact=None), [])
self.assertQuerysetEqual(Choice.objects.filter(choice__iexact=None), [])
self.assertQuerysetEqual( Choice.objects.exclude(choice=None).order_by('id'), [ '<Choice: Choice: Because. in poll Q: Why? >', '<Choice: Choice: Why Not? in poll Q: Why? >' ] )
with self.assertRaises(FieldError): Choice.objects.filter(foo__exact=None)
with self.assertRaises(ValueError): Choice.objects.filter(id__gt=None)
p2 = Poll(question="How?") self.assertEqual(repr(p2.choice_set.all()), '<QuerySet []>')
OuterB.objects.create(data="reverse") self.assertQuerysetEqual( OuterB.objects.filter(inner__isnull=False), [] ) Inner.objects.create(first=obj) self.assertQuerysetEqual( OuterB.objects.exclude(inner__isnull=False), ['<OuterB: OuterB object>'] )
Restaurant.objects.bulk_create([ Restaurant(name='foo') for i in range(0, 2) ]) self.assertEqual(Restaurant.objects.count(), 2)
Restaurant.objects.bulk_create([ Restaurant() for i in range(0, 501) ])
id_range = range(100000, 101000, 2) self.assertEqual(TwoFields.objects.filter(id__in=id_range).count(), 500) self.assertEqual(TwoFields.objects.exclude(id__in=id_range).count(), 500)
self.lock = threading.Lock()
ordering = ('author__extra__note', 'author__name', 'rank')
assert False, 'type checking should happen without calling model __iter__'
class Individual(models.Model): alive = models.BooleanField()
cls.e2 = ExtraInfo.objects.create(info='e2', note=n2, value=41) e1 = ExtraInfo.objects.create(info='e1', note=cls.n1, value=42)
cls.rank1 = Ranking.objects.create(rank=2, author=cls.a2)
self.assertNotIn('w0', str(qs4.query).lower()) self.assertTrue(str(qs4.query).lower().count('u0'), 2)
query = Item.objects.filter(tags=self.t2).query self.assertNotIn(LOUTER, [x.join_type for x in query.alias_map.values()])
self.assertQuerysetEqual( Item.objects.filter(Q(tags=self.t1) & Q(tags=self.t2)), [] ) self.assertQuerysetEqual( Item.objects.filter(Q(tags=self.t1), Q(creator__name='fred') | Q(tags=self.t2)), [] )
self.assertQuerysetEqual( Item.objects.filter(tags__in=[self.t1, self.t2]).order_by('name')[:3], ['<Item: one>', '<Item: one>', '<Item: two>'] ) self.assertQuerysetEqual( Item.objects.filter(tags__in=[self.t1, self.t2]).distinct().order_by('name')[:3], ['<Item: one>', '<Item: two>'] )
self.assertQuerysetEqual(Author.objects.filter(Q(id__in=[])), []) self.assertQuerysetEqual( Author.objects.filter(Q(id__in=[]) | Q(id__in=[])), [] )
xx = Item(name='four', created=self.time1, creator=self.a2, note=self.n1) xx.save() self.assertEqual( Item.objects.exclude(name='two').values('creator', 'name').distinct().count(), 4 ) self.assertEqual( ( Item.objects .exclude(name='two') .extra(select={'foo': '%s'}, select_params=(1,)) .values('creator', 'name', 'foo') .distinct() .count() ), 4 ) self.assertEqual( ( Item.objects .exclude(name='two') .extra(select={'foo': '%s'}, select_params=(1,)) .values('creator', 'name') .distinct() .count() ), 4 ) xx.delete()
self.assertQuerysetEqual( Item.objects.exclude(tags__name='t1').order_by('name'), ['<Item: four>', '<Item: three>'] ) self.assertQuerysetEqual( Item.objects.exclude(tags__name='t1').exclude(tags__name='t4'), ['<Item: three>'] )
query = Item.objects.exclude(creator__in=[self.a1, self.a2]).query self.assertNotIn(LOUTER, [x.join_type for x in query.alias_map.values()])
qs = Author.objects.filter(id=self.a1.id).filter(Q(extra__note=self.n1) | Q(item__note=self.n3)) self.assertEqual( len([ x for x in qs.query.alias_map.values() if x.join_type == LOUTER and qs.query.alias_refcount[x.table_alias] ]), 1 )
self.assertQuerysetEqual( Tag.objects.filter(parent__isnull=True).order_by('name'), ['<Tag: t1>'] ) self.assertQuerysetEqual( Tag.objects.exclude(parent__isnull=True).order_by('name'), ['<Tag: t2>', '<Tag: t3>', '<Tag: t4>', '<Tag: t5>'] ) self.assertQuerysetEqual( Tag.objects.exclude(Q(parent__name='t1') | Q(parent__isnull=True)).order_by('name'), ['<Tag: t4>', '<Tag: t5>'] ) self.assertQuerysetEqual( Tag.objects.exclude(Q(parent__isnull=True) | Q(parent__name='t1')).order_by('name'), ['<Tag: t4>', '<Tag: t5>'] ) self.assertQuerysetEqual( Tag.objects.exclude(Q(parent__parent__isnull=True)).order_by('name'), ['<Tag: t4>', '<Tag: t5>'] ) self.assertQuerysetEqual( Tag.objects.filter(~Q(parent__parent__isnull=True)).order_by('name'), ['<Tag: t4>', '<Tag: t5>'] )
with self.assertRaisesMessage(AssertionError, 'Cannot combine queries on two different base models.'): Author.objects.all() & Tag.objects.all() with self.assertRaisesMessage(AssertionError, 'Cannot combine queries on two different base models.'): Author.objects.all() | Tag.objects.all()
self.assertQuerysetEqual( Item.objects.order_by('note__note', 'name'), ['<Item: two>', '<Item: four>', '<Item: one>', '<Item: three>'] )
self.assertQuerysetEqual( Author.objects.order_by('extra', '-name'), ['<Author: a2>', '<Author: a1>', '<Author: a4>', '<Author: a3>'] )
self.assertQuerysetEqual( Cover.objects.all(), ['<Cover: first>', '<Cover: second>'] )
self.assertQuerysetEqual( Item.objects.order_by('creator', 'name'), ['<Item: one>', '<Item: three>', '<Item: two>', '<Item: four>'] )
self.assertQuerysetEqual( Item.objects.filter(tags__isnull=False).order_by('tags', 'id'), ['<Item: one>', '<Item: two>', '<Item: one>', '<Item: two>', '<Item: four>'] )
qs = Item.objects.order_by('name') self.assertQuerysetEqual( qs, ['<Item: four>', '<Item: one>', '<Item: three>', '<Item: two>'] ) self.assertEqual(len(qs.query.tables), 1)
self.assertTrue(repr(qs[0].note), '<Note: n2>') self.assertEqual(repr(qs[0].creator.extra.note), '<Note: n1>')
self.assertValueQuerysetEqual( Note.objects.values('misc').distinct().order_by('note', '-misc'), [{'misc': 'foo'}, {'misc': 'bar'}, {'misc': 'foo'}] )
self.assertIn('note_id', ExtraInfo.objects.values()[0])
self.assertValueQuerysetEqual( ExtraInfo.objects.values('note_id'), [{'note_id': 1}, {'note_id': 2}] )
self.assertValueQuerysetEqual( ExtraInfo.objects.values('note'), [{'note': 1}, {'note': 2}] )
s = [('a', '%s'), ('b', '%s')] params = ['one', 'two'] if {'a': 1, 'b': 2}.keys() == ['a', 'b']: s.reverse() params.reverse()
d = Item.objects.extra(select=OrderedDict(s), select_params=params).values('a', 'b')[0] self.assertEqual(d, {'a': 'one', 'b': 'two'})
l = ( Item.objects .extra(select={ 'count': 'select count(*) from queries_item_tags where queries_item_tags.item_id = queries_item.id' }) .order_by('-count') ) self.assertEqual([o.count for o in l], [2, 2, 1, 0])
self.assertEqual(Item.objects.count(), 4) self.assertEqual(Item.objects.datetimes('created', 'month').count(), 1) self.assertEqual(Item.objects.datetimes('created', 'day').count(), 2) self.assertEqual(len(Item.objects.datetimes('created', 'day')), 2) self.assertEqual(Item.objects.datetimes('created', 'day')[0], datetime.datetime(2007, 12, 19, 0, 0))
self.assertQuerysetEqual( Item.objects.datetimes('created', 'day').extra(select={'a': 1}), ['datetime.datetime(2007, 12, 19, 0, 0)', 'datetime.datetime(2007, 12, 20, 0, 0)'] ) self.assertQuerysetEqual( Item.objects.extra(select={'a': 1}).datetimes('created', 'day'), ['datetime.datetime(2007, 12, 19, 0, 0)', 'datetime.datetime(2007, 12, 20, 0, 0)'] )
self.assertQuerysetEqual( Item.objects.datetimes('modified', 'day'), ['datetime.datetime(2007, 12, 19, 0, 0)'] )
self.assertValueQuerysetEqual( Item.objects.values('note__note').order_by('queries_note.note', 'id'), [{'note__note': 'n2'}, {'note__note': 'n3'}, {'note__note': 'n3'}, {'note__note': 'n3'}] )
self.assertQuerysetEqual( Tag.objects.filter(parent=self.t1, name='t3').order_by('name'), ['<Tag: t3>'] ) self.assertQuerysetEqual( Tag.objects.exclude(parent=self.t1, name='t3').order_by('name'), ['<Tag: t1>', '<Tag: t2>', '<Tag: t4>', '<Tag: t5>'] ) self.assertQuerysetEqual( Item.objects.exclude(tags__name='t1', name='one').order_by('name').distinct(), ['<Item: four>', '<Item: three>', '<Item: two>'] ) self.assertQuerysetEqual( Item.objects.filter(name__in=['three', 'four']).exclude(tags__name='t1').order_by('name'), ['<Item: four>', '<Item: three>'] )
self.assertQuerysetEqual( Item.objects.exclude(~Q(tags__name='t1', name='one')), ['<Item: one>'] ) self.assertQuerysetEqual( Item.objects.filter(~Q(tags__name='t1', name='one'), name='two'), ['<Item: two>'] ) self.assertQuerysetEqual( Item.objects.exclude(~Q(tags__name='t1', name='one'), name='two'), ['<Item: four>', '<Item: one>', '<Item: three>'] )
pickle.dumps(Item.objects.all())
qs = Item.objects.select_related() query = qs.query.get_compiler(qs.db).as_sql()[0] query2 = pickle.loads(pickle.dumps(qs.query)) self.assertEqual( query2.get_compiler(qs.db).as_sql()[0], query )
qs = Item.objects.defer('name', 'creator') q2 = pickle.loads(pickle.dumps(qs)) self.assertEqual(list(qs), list(q2)) q3 = pickle.loads(pickle.dumps(qs, pickle.HIGHEST_PROTOCOL)) self.assertEqual(list(qs), list(q3))
self.assertQuerysetEqual( Item.objects.filter(created__in=[self.time1, self.time2]), ['<Item: one>', '<Item: two>'] )
Eaten.objects.create(meal='m') q = Eaten.objects.none() with self.assertNumQueries(0): self.assertQuerysetEqual(q.all(), []) self.assertQuerysetEqual(q.filter(meal='m'), []) self.assertQuerysetEqual(q.exclude(meal='m'), []) self.assertQuerysetEqual(q.complex_filter({'pk': 1}), []) self.assertQuerysetEqual(q.select_related('food'), []) self.assertQuerysetEqual(q.annotate(Count('food')), []) self.assertQuerysetEqual(q.order_by('meal', 'food'), []) self.assertQuerysetEqual(q.distinct(), []) self.assertQuerysetEqual( q.extra(select={'foo': "1"}), [] ) q.query.low_mark = 1 with self.assertRaisesMessage(AssertionError, 'Cannot change a query once a slice has been taken'): q.extra(select={'foo': "1"}) self.assertQuerysetEqual(q.reverse(), []) self.assertQuerysetEqual(q.defer('meal'), []) self.assertQuerysetEqual(q.only('meal'), [])
self.assertEqual( len(Note.objects.order_by('extrainfo__info').distinct()), 3 )
qs = Item.objects.datetimes('created', 'month') pickle.loads(pickle.dumps(qs))
self.assertQuerysetEqual( Tag.objects.filter(name__in=Tag.objects.filter(parent=self.t1).values('name')), ['<Tag: t2>', '<Tag: t3>'] )
with self.assertRaisesMessage(TypeError, 'Cannot use multi-field values as a filter value.'): Tag.objects.filter(name__in=Tag.objects.filter(parent=self.t1).values('name', 'id')) with self.assertRaisesMessage(TypeError, 'Cannot use multi-field values as a filter value.'): Tag.objects.filter(name__in=Tag.objects.filter(parent=self.t1).values_list('name', 'id'))
self.assertValueQuerysetEqual( Note.objects.values_list("note", flat=True).values("id").order_by("id"), [{'id': 1}, {'id': 2}, {'id': 3}] ) self.assertQuerysetEqual( Annotation.objects.filter(notes__in=Note.objects.filter(note="n1").values_list('note').values('id')), ['<Annotation: a1>'] )
self.assertEqual(Tag.objects.filter(name__in=()).update(name="foo"), 0)
def f(): return iter([]) n_obj = Note.objects.all()[0]
self.assertIsNone(subq._result_cache)
self.assertIsNone(subq._result_cache)
self.assertIsNone(subq._result_cache)
self.assertQuerysetEqual( Item.objects.exclude(modified=self.time1).order_by('name'), ['<Item: four>', '<Item: three>', '<Item: two>'] ) self.assertQuerysetEqual( Tag.objects.exclude(parent__name=self.t1.name), ['<Tag: t1>', '<Tag: t4>', '<Tag: t5>'] )
self.assertEqual(len(Tag.objects.order_by('parent__name')), 5)
self.assertQuerysetEqual( Note.objects.none() | Note.objects.all(), ['<Note: n1>', '<Note: n2>', '<Note: n3>'] ) self.assertQuerysetEqual( Note.objects.all() | Note.objects.none(), ['<Note: n1>', '<Note: n2>', '<Note: n3>'] ) self.assertQuerysetEqual(Note.objects.none() & Note.objects.all(), []) self.assertQuerysetEqual(Note.objects.all() & Note.objects.none(), [])
qs = Tag.objects.values_list('id', flat=True).order_by('id') qs.query.bump_prefix(qs.query) first = qs[0] self.assertEqual(list(qs), list(range(first, first + 5)))
self.assertQuerysetEqual( Author.objects.filter(Q(item__note__extrainfo=self.e2) | Q(report=self.r1, name='xyz')), ['<Author: a2>'] ) self.assertQuerysetEqual( Author.objects.filter(Q(report=self.r1, name='xyz') | Q(item__note__extrainfo=self.e2)), ['<Author: a2>'] ) self.assertQuerysetEqual( Annotation.objects.filter(Q(tag__parent=self.t1) | Q(notes__note='n1', name='a1')), ['<Annotation: a1>'] ) xx = ExtraInfo.objects.create(info='xx', note=self.n3) self.assertQuerysetEqual( Note.objects.filter(Q(extrainfo__author=self.a1) | Q(extrainfo=xx)), ['<Note: n1>', '<Note: n3>'] ) q = Note.objects.filter(Q(extrainfo__author=self.a1) | Q(extrainfo=xx)).query self.assertEqual( len([x for x in q.alias_map.values() if x.join_type == LOUTER and q.alias_refcount[x.table_alias]]), 1 )
q = Tag.objects.filter(parent__isnull=True)
q = Tag.objects.filter(parent__parent__isnull=False)
q = Tag.objects.filter(parent__parent=self.t1) self.assertQuerysetEqual( q, ['<Tag: t4>', '<Tag: t5>'], ) self.assertEqual(str(q.query).count('LEFT OUTER JOIN'), 0) self.assertEqual(str(q.query).count('INNER JOIN'), 1)
q = NamedCategory.objects.filter(tag__isnull=True) self.assertEqual(str(q.query).count('LEFT OUTER JOIN'), 1) self.assertEqual(str(q.query).count('INNER JOIN'), 1) self.assertQuerysetEqual(q, [])
q = NamedCategory.objects.filter(tag__parent__isnull=True) self.assertEqual(str(q.query).count('INNER JOIN'), 1) self.assertEqual(str(q.query).count('LEFT OUTER JOIN'), 1) self.assertQuerysetEqual(q, ['<NamedCategory: Generic>'])
q = Author.objects.filter(item__tags__isnull=True) self.assertQuerysetEqual( q, ['<Author: a2>', '<Author: a3>'], ) self.assertEqual(str(q.query).count('LEFT OUTER JOIN'), 2) self.assertNotIn('INNER JOIN', str(q.query))
q = Author.objects.filter(item__tags__isnull=False) self.assertQuerysetEqual( q, ['<Author: a1>', '<Author: a1>', '<Author: a2>', '<Author: a2>', '<Author: a4>'] ) self.assertEqual(str(q.query).count('LEFT OUTER JOIN'), 0) self.assertEqual(str(q.query).count('INNER JOIN'), 2)
q = Author.objects.filter(item__tags__parent__parent__isnull=True) self.assertQuerysetEqual( q, ['<Author: a1>', '<Author: a1>', '<Author: a2>', '<Author: a2>', '<Author: a2>', '<Author: a3>'] ) self.assertEqual(str(q.query).count('LEFT OUTER JOIN'), 4) self.assertEqual(str(q.query).count('INNER JOIN'), 0)
q = Author.objects.filter(item__isnull=True) self.assertQuerysetEqual( q, ['<Author: a3>'] ) self.assertEqual(str(q.query).count('LEFT OUTER JOIN'), 1) self.assertEqual(str(q.query).count('INNER JOIN'), 0)
q = Tag.objects.filter(Q(parent__isnull=True) | Q(parent=self.t1)) self.assertQuerysetEqual( q, ['<Tag: t1>', '<Tag: t2>', '<Tag: t3>'] ) self.assertEqual(str(q.query).count('LEFT OUTER JOIN'), 0) self.assertEqual(str(q.query).count('INNER JOIN'), 0)
q1 = Tag.objects.filter(parent__isnull=True) q2 = Tag.objects.filter(parent__isnull=False)
qs = Author.objects.annotate(Count('item')) qs = qs.filter(~Q(extra__value=0))
self.assertQuerysetEqual(Number.objects.filter(num__lt=4), []) self.assertQuerysetEqual(Number.objects.filter(num__gt=8, num__lt=12), []) self.assertQuerysetEqual( Number.objects.filter(num__gt=8, num__lt=13), ['<Number: 12>'] ) self.assertQuerysetEqual( Number.objects.filter(Q(num__lt=4) | Q(num__gt=8, num__lt=12)), [] ) self.assertQuerysetEqual( Number.objects.filter(Q(num__gt=8, num__lt=12) | Q(num__lt=4)), [] ) self.assertQuerysetEqual( Number.objects.filter(Q(num__gt=8) & Q(num__lt=12) | Q(num__lt=4)), [] ) self.assertQuerysetEqual( Number.objects.filter(Q(num__gt=7) & Q(num__lt=12) | Q(num__lt=4)), ['<Number: 8>'] )
self.assertQuerysetEqual( Number.objects.filter(num__gt=11.9), ['<Number: 12>'] ) self.assertQuerysetEqual(Number.objects.filter(num__gt=12), []) self.assertQuerysetEqual(Number.objects.filter(num__gt=12.0), []) self.assertQuerysetEqual(Number.objects.filter(num__gt=12.1), []) self.assertQuerysetEqual( Number.objects.filter(num__lt=12), ['<Number: 4>', '<Number: 8>'], ordered=False ) self.assertQuerysetEqual( Number.objects.filter(num__lt=12.0), ['<Number: 4>', '<Number: 8>'], ordered=False ) self.assertQuerysetEqual( Number.objects.filter(num__lt=12.1), ['<Number: 4>', '<Number: 8>', '<Number: 12>'], ordered=False ) self.assertQuerysetEqual( Number.objects.filter(num__gte=11.9), ['<Number: 12>'] ) self.assertQuerysetEqual( Number.objects.filter(num__gte=12), ['<Number: 12>'] ) self.assertQuerysetEqual( Number.objects.filter(num__gte=12.0), ['<Number: 12>'] ) self.assertQuerysetEqual(Number.objects.filter(num__gte=12.1), []) self.assertQuerysetEqual(Number.objects.filter(num__gte=12.9), []) self.assertQuerysetEqual( Number.objects.filter(num__lte=11.9), ['<Number: 4>', '<Number: 8>'], ordered=False ) self.assertQuerysetEqual( Number.objects.filter(num__lte=12), ['<Number: 4>', '<Number: 8>', '<Number: 12>'], ordered=False ) self.assertQuerysetEqual( Number.objects.filter(num__lte=12.0), ['<Number: 4>', '<Number: 8>', '<Number: 12>'], ordered=False ) self.assertQuerysetEqual( Number.objects.filter(num__lte=12.1), ['<Number: 4>', '<Number: 8>', '<Number: 12>'], ordered=False ) self.assertQuerysetEqual( Number.objects.filter(num__lte=12.9), ['<Number: 4>', '<Number: 8>', '<Number: 12>'], ordered=False )
count = Number.objects.count() qs = Number.objects.all()
self.assertQuerysetEqual(Valid.objects.all(), [])
with self.assertRaisesMessage(AssertionError, "'name' isn't a DateField or DateTimeField."): Item.objects.datetimes('name', 'month')
q1 = Report.objects.filter(Q(creator__isnull=True) | Q(creator__extra__info='e1')) q2 = Report.objects.filter(Q(creator__isnull=True)) | Report.objects.filter(Q(creator__extra__info='e1')) self.assertQuerysetEqual(q1, ["<Report: r1>", "<Report: r3>"], ordered=False) self.assertEqual(str(q1.query), str(q2.query))
Report.objects.create(name='r4', creator=self.a1) q1 = Author.objects.filter(report__name='r5') q2 = Author.objects.filter(report__name='r4').filter(report__name='r1') combined = q1 | q2 self.assertEqual(str(combined.query).count('JOIN'), 2) self.assertEqual(len(combined), 1) self.assertEqual(combined[0].name, 'a1')
ManagedModel.objects.create(data='mm1', tag=self.t1, public=True) self.assertEqual(ManagedModel.objects.update(data='mm'), 1)
if connection.features.interprets_empty_strings_as_nulls: expected_null_charfield_repr = '' else: expected_null_charfield_repr = None self.assertValueQuerysetEqual( Report.objects.values_list("creator__extra__info", flat=True).order_by("name"), ['e1', 'e2', expected_null_charfield_repr], )
self.assertQuerysetEqual( Report.objects.select_related("creator", "creator__extra").order_by("name"), ['<Report: r1>', '<Report: r2>', '<Report: r3>'] )
qs = Author.objects.order_by().order_by('name') self.assertIn('ORDER BY', qs.query.get_compiler(qs.db).as_sql()[0])
c1 = SimpleCategory.objects.create(name="category1") c2 = SimpleCategory.objects.create(name="category2") CategoryItem.objects.create(category=c1) CategoryItem.objects.create(category=c2) CategoryItem.objects.create(category=c1) self.assertQuerysetEqual( SimpleCategory.objects.order_by('categoryitem', 'pk'), [c1, c2, c1], lambda x: x)
self.assertQuerysetEqual( Tag.objects.filter(id__in=Tag.objects.filter(id__in=[])), [] )
n1 = Note.objects.create(note='n1', misc='foo', id=1) n2 = Note.objects.create(note='n2', misc='bar', id=2) e1 = ExtraInfo.objects.create(info='e1', note=n1) e2 = ExtraInfo.objects.create(info='e2', note=n2) a1 = Author.objects.create(name='a1', num=1001, extra=e1) a2 = Author.objects.create(name='a2', num=2002, extra=e1) a3 = Author.objects.create(name='a3', num=3003, extra=e2) cls.rank1 = Ranking.objects.create(rank=2, author=a2) Ranking.objects.create(rank=1, author=a3) Ranking.objects.create(rank=3, author=a1)
self.assertQuerysetEqual( Ranking.objects.all(), ['<Ranking: 3: a1>', '<Ranking: 2: a2>', '<Ranking: 1: a3>'] ) self.assertQuerysetEqual( Ranking.objects.all().order_by('rank'), ['<Ranking: 1: a3>', '<Ranking: 2: a2>', '<Ranking: 3: a1>'] )
self.assertQuerysetEqual( Ranking.objects.extra(tables=['django_site'], order_by=['-django_site.id', 'rank']), ['<Ranking: 1: a3>', '<Ranking: 2: a2>', '<Ranking: 3: a1>'] )
dicts = qs.values('id', 'rank').order_by('id') self.assertEqual( [d['rank'] for d in dicts], [2, 1, 3] )
qs = Ranking.objects.extra(select={'good': 'case when rank > 2 then 1 else 0 end'}) dicts = qs.values().order_by('id') for d in dicts: del d['id'] del d['author_id'] self.assertEqual( [sorted(d.items()) for d in dicts], [[('good', 0), ('rank', 2)], [('good', 0), ('rank', 1)], [('good', 1), ('rank', 3)]] )
qs = Ranking.objects.extra(tables=['django_site']) qs.query.get_compiler(qs.db).as_sql() qs.query.get_compiler(qs.db).as_sql()
self.assertQuerysetEqual( Ranking.objects.filter(author__name='a1'), ['<Ranking: 3: a1>'] ) self.assertEqual( Ranking.objects.filter(author__name='a1').update(rank='4'), 1 ) r = Ranking.objects.filter(author__name='a1')[0] self.assertNotEqual(r.id, r.author.id) self.assertEqual(r.rank, 4) r.rank = 3 r.save() self.assertQuerysetEqual( Ranking.objects.all(), ['<Ranking: 3: a1>', '<Ranking: 2: a2>', '<Ranking: 1: a3>'] )
self.assertQuerysetEqual( Note.objects.exclude(Q()), ['<Note: n1>', '<Note: n2>'] ) self.assertQuerysetEqual( Note.objects.filter(~Q()), ['<Note: n1>', '<Note: n2>'] ) self.assertQuerysetEqual( Note.objects.filter(~Q() | ~Q()), ['<Note: n1>', '<Note: n2>'] ) self.assertQuerysetEqual( Note.objects.exclude(~Q() & ~Q()), ['<Note: n1>', '<Note: n2>'] )
self.assertEqual( Note.objects.extra(select={'foo': "'%%s'"})[0].foo, '%s' ) self.assertEqual( Note.objects.extra(select={'foo': "'%%s bar %%s'"})[0].foo, '%s bar %s' ) self.assertEqual( Note.objects.extra(select={'foo': "'bar %%s'"})[0].foo, 'bar %s' )
self.assertQuerysetEqual(X.objects.all(), []) self.assertQuerysetEqual(X.objects.select_related(), [])
self.assertEqual(Celebrity.objects.count(), num_celebs)
Plaything.objects.create(name="p1") self.assertQuerysetEqual( Plaything.objects.all(), ['<Plaything: p1>'] )
Plaything.objects.create(name="p1") s = SingleObject.objects.create(name='s') r = RelatedObject.objects.create(single=s, f=1) Plaything.objects.create(name="p2", others=r) qs = Plaything.objects.all().filter(others__isnull=False).order_by('pk') self.assertNotIn('JOIN', str(qs.query)) qs = Plaything.objects.all().filter(others__f__isnull=False).order_by('pk') self.assertIn('INNER', str(qs.query)) qs = qs.order_by('others__single__name') self.assertEqual(str(qs.query).count('LEFT'), 1) self.assertEqual(str(qs.query).count('INNER'), 1) self.assertQuerysetEqual( qs, ['<Plaything: p2>'] )
LeafA.objects.create(data='first') self.assertQuerysetEqual(LeafA.objects.all(), ['<LeafA: first>']) self.assertQuerysetEqual( LeafA.objects.filter(Q(data='first') | Q(join__b__data='second')), ['<LeafA: first>'] )
self.assertQuerysetEqual( (ExtraInfo.objects.filter(note=self.n1) | ExtraInfo.objects.filter(info='e2')).filter(note=self.n1), ['<ExtraInfo: e1>'] ) self.assertQuerysetEqual( (ExtraInfo.objects.filter(info='e2') | ExtraInfo.objects.filter(note=self.n1)).filter(note=self.n1), ['<ExtraInfo: e1>'] )
qs = Tag.objects.all() i1, i2 = iter(qs), iter(qs) self.assertEqual(repr(next(i1)), '<Tag: t1>') self.assertEqual(repr(next(i1)), '<Tag: t2>') self.assertEqual(repr(next(i2)), '<Tag: t1>') self.assertEqual(repr(next(i2)), '<Tag: t2>') self.assertEqual(repr(next(i2)), '<Tag: t3>') self.assertEqual(repr(next(i1)), '<Tag: t3>')
qs = Annotation.objects.filter(notes__in=Note.objects.filter(note="xyzzy")) self.assertEqual( qs.query.get_compiler(qs.db).as_sql()[0].count('SELECT'), 2 )
self.assertQuerysetEqual( Tag.objects.exclude(parent__annotation__name="a1"), ['<Tag: t1>', '<Tag: t4>', '<Tag: t5>'] )
self.assertQuerysetEqual( Annotation.objects.exclude(tag__children__name="t2"), ['<Annotation: a2>'] )
self.assertQuerysetEqual( Annotation.objects.filter(notes__in=Note.objects.filter(note="n1")), ['<Annotation: a1>'] )
q1 = Tag.objects.order_by('name') self.assertIsNot(q1, q1.all())
query = "SELECT * FROM queries_note WHERE note = %s" params = ['n1'] qs = Note.objects.raw(query, params=params) self.assertEqual(repr(qs), "<RawQuerySet: SELECT * FROM queries_note WHERE note = n1>")
self.assertQuerysetEqual( Note.objects.filter(pk__in=(x for x in ())), [] )
Item.objects.create(name="a_b", created=datetime.datetime.now(), creator=self.a2, note=self.n1) Item.objects.create(name="x%y", created=datetime.datetime.now(), creator=self.a2, note=self.n1) self.assertQuerysetEqual( Item.objects.filter(name__iexact="A_b"), ['<Item: a_b>'] ) self.assertQuerysetEqual( Item.objects.filter(name__iexact="x%Y"), ['<Item: x%y>'] ) self.assertQuerysetEqual( Item.objects.filter(name__istartswith="A_b"), ['<Item: a_b>'] ) self.assertQuerysetEqual( Item.objects.filter(name__iendswith="A_b"), ['<Item: a_b>'] )
self.assertEqual(len(captured_queries), 1) qstr = captured_queries[0]['sql'] id, name = connection.ops.quote_name('id'), connection.ops.quote_name('name') self.assertNotIn(id, qstr) self.assertNotIn(name, qstr)
list(n_list) self.assertEqual(ExtraInfo.objects.filter(note__in=n_list)[0].info, 'good')
self.assertQuerysetEqual( Number.objects.none().values('num').order_by('num'), [] )
q = Author.objects.none() self.assertQuerysetEqual(q.values(), []) self.assertQuerysetEqual(q.values_list(), [])
qs = Number.objects.extra(select=OrderedDict([('value_plus_x', 'num+%s'), ('value_minus_x', 'num-%s')]), select_params=(1, 2)) qs = qs.order_by('value_minus_x') qs = qs.values('num') self.assertQuerysetEqual(qs, [{'num': 72}], self.identity)
qs = Number.objects.extra(select={'value_plus_one': 'num+1', 'value_minus_one': 'num-1'}) qs = qs.order_by('value_minus_one').order_by('value_plus_one') qs = qs.values('num') self.assertQuerysetEqual(qs, [{'num': 72}], self.identity)
qs = Number.objects.extra(select={ 'value_plus_one': 'num+1', 'value_minus_one': 'num-1', 'constant_value': '1' }) qs = qs.order_by('value_plus_one', 'value_minus_one', 'constant_value') qs = qs.values('num') self.assertQuerysetEqual(qs, [{'num': 72}], self.identity)
qs = Number.objects.extra( select={'value_plus_one': 'num+1', 'value_minus_one': 'num-1'}, order_by=['value_minus_one']) qs = qs.values('num')
qs = Number.objects.extra( select={'value_plus_x': 'num+%s'}, select_params=[1], order_by=['value_plus_x']) qs = qs.filter(num=72) qs = qs.values('num') self.assertQuerysetEqual(qs, [{'num': 72}], self.identity)
qs = Number.objects.extra(select=OrderedDict([('value_plus_x', 'num+%s'), ('value_minus_x', 'num-%s')]), select_params=(72, 72)) qs = qs.order_by('value_minus_x') qs = qs.filter(num=1) qs = qs.values('num') self.assertQuerysetEqual(qs, [], self.identity)
qs = Number.objects.extra(select={'value_plus_one': 'num+1'}) qs = qs.order_by('value_plus_one') qs = qs.values_list('num') self.assertQuerysetEqual(qs, [(72,)], self.identity)
qs = Number.objects.extra(select={'value_plus_one': 'num+1'}) qs = qs.order_by('value_plus_one') qs = qs.values_list('num', flat=True) self.assertQuerysetEqual(qs, [72], self.identity)
msg = "Cannot resolve keyword %r into field. Join on 'name' not permitted." % 'foo' with self.assertRaisesMessage(FieldError, msg): Tag.objects.values_list('name__foo')
self.assertQuerysetEqual( self.get_ordered_articles()[2:][0:2], ["<Article: Article 3>", "<Article: Article 4>"] ) self.assertQuerysetEqual( self.get_ordered_articles()[2:][:2], ["<Article: Article 3>", "<Article: Article 4>"] ) self.assertQuerysetEqual(self.get_ordered_articles()[2:][2:3], ["<Article: Article 5>"])
self.assertQuerysetEqual( self.get_ordered_articles()[5:], ["<Article: Article 6>", "<Article: Article 7>"] )
self.assertQuerysetEqual(Article.objects.all()[0:0], []) self.assertQuerysetEqual(Article.objects.all()[0:0][:10], []) self.assertEqual(Article.objects.all()[:0].count(), 0) with self.assertRaisesMessage(AssertionError, 'Cannot change a query once a slice has been taken.'): Article.objects.all()[:0].latest('created')
self.assertNumQueries(0, lambda: list(Number.objects.all()[1:1]))
ReservedName.objects.create(name='a', order=42) ReservedName.objects.create(name='b', order=37) self.assertQuerysetEqual( ReservedName.objects.all().order_by('order'), ['<ReservedName: b>', '<ReservedName: a>'] ) self.assertQuerysetEqual( ReservedName.objects.extra(select={'stuff': 'name'}, order_by=('order', 'stuff')), ['<ReservedName: b>', '<ReservedName: a>'] )
with self.assertRaisesMessage(FieldError, 'Infinite loop caused by ordering.'):
self.assertEqual(len(Tag.objects.order_by('parent')), 5)
self.assertQuerysetEqual( LoopX.objects.all().order_by('y__x__y__x__id'), [] )
@skipUnlessDBFeature('requires_explicit_null_ordering_when_grouping') def test_null_ordering_added(self): query = Tag.objects.values_list('parent_id', flat=True).order_by().query query.group_by = ['parent_id'] sql = query.get_compiler(DEFAULT_DB_ALIAS).as_sql()[0] fragment = "ORDER BY " pos = sql.find(fragment) self.assertEqual(sql.find(fragment, pos + 1), -1) self.assertEqual(sql.find("NULL", pos + len(fragment)), pos + len(fragment))
@skipUnlessDBFeature('supports_1000_query_parameters') def test_ticket14244(self): numbers = list(range(2050)) Number.objects.all().delete() Number.objects.bulk_create(Number(num=num) for num in numbers) self.assertEqual( Number.objects.filter(num__in=numbers[:1000]).count(), 1000 ) self.assertEqual( Number.objects.filter(num__in=numbers[:1001]).count(), 1001 ) self.assertEqual( Number.objects.filter(num__in=numbers[:2000]).count(), 2000 ) self.assertEqual( Number.objects.filter(num__in=numbers).count(), len(numbers) )
try: DumbCategory.objects.create() except TypeError: self.fail( "Creation of an instance of a model with only the PK field " "shouldn't error out after bulk insert refactoring (#17056)" )
cls.o1 = Order.objects.create(pk=1) cls.o2 = Order.objects.create(pk=2) cls.o3 = Order.objects.create(pk=3)
cls.oi1 = OrderItem.objects.create(order=cls.o1, status=1) cls.oi2 = OrderItem.objects.create(order=cls.o1, status=1) cls.oi3 = OrderItem.objects.create(order=cls.o1, status=1)
cls.oi4 = OrderItem.objects.create(order=cls.o2, status=1) cls.oi5 = OrderItem.objects.create(order=cls.o2, status=2) cls.oi6 = OrderItem.objects.create(order=cls.o2, status=3)
cls.oi7 = OrderItem.objects.create(order=cls.o3, status=2) cls.oi8 = OrderItem.objects.create(order=cls.o3, status=3) cls.oi9 = OrderItem.objects.create(order=cls.o3, status=4)
self.assertIs(inner_qs._result_cache, None)
qs = Article.objects.order_by('invalid_column') with self.assertRaises(FieldError): list(qs) with self.assertRaises(FieldError): list(qs)
q_obj = ( Q(d__name='foo') | Q(b__name='foo') | Q(b__c__name='foo') ) qset = ModelA.objects.filter(q_obj) self.assertEqual(list(qset), [self.a1]) self.assertEqual(str(qset.query).count('INNER JOIN'), 1)
qs1_doubleneg = Identifier.objects.exclude(~Q(program__id=p1.id, channel__id=c1.id)).order_by('pk') qs1_filter = Identifier.objects.filter(program__id=p1.id, channel__id=c1.id).order_by('pk') self.assertQuerysetEqual(qs1_doubleneg, qs1_filter, lambda x: x) self.assertEqual(str(qs1_filter.query).count('JOIN'), str(qs1_doubleneg.query).count('JOIN')) self.assertEqual(2, str(qs1_doubleneg.query).count('INNER JOIN')) self.assertEqual(str(qs1_filter.query).count('INNER JOIN'), str(qs1_doubleneg.query).count('INNER JOIN'))
qs1_filter = Identifier.objects.filter( Q(program__id=p2.id, channel__id=c1.id) | Q(program__id=p1.id) ).order_by('pk') qs1_doubleneg = Identifier.objects.exclude( ~Q(Q(program__id=p2.id, channel__id=c1.id) | Q(program__id=p1.id)) ).order_by('pk') self.assertQuerysetEqual(qs1_doubleneg, qs1_filter, lambda x: x) self.assertEqual(str(qs1_filter.query).count('JOIN'), str(qs1_doubleneg.query).count('JOIN')) self.assertEqual(1, str(qs1_doubleneg.query).count('INNER JOIN')) self.assertEqual(str(qs1_filter.query).count('INNER JOIN'), str(qs1_doubleneg.query).count('INNER JOIN'))
qs1 = Identifier.objects.filter( ~Q(~Q(program__id=p2.id, channel__id=c1.id) & Q(program__id=p1.id)) ).order_by('pk') qs2 = Identifier.objects.filter( Q(Q(program__id=p2.id, channel__id=c1.id) | ~Q(program__id=p1.id)) ).order_by('pk') self.assertQuerysetEqual(qs1, qs2, lambda x: x) self.assertEqual(str(qs1.query).count('JOIN'), str(qs2.query).count('JOIN')) self.assertEqual(0, str(qs1.query).count('INNER JOIN')) self.assertEqual(str(qs1.query).count('INNER JOIN'), str(qs2.query).count('INNER JOIN'))
t = Tag.objects.create() qs = Tag.objects.filter(annotation__tag=t.pk) self.assertIn('INNER JOIN', str(qs.query)) self.assertEqual(list(qs), [])
qs = BaseA.objects.filter(a__f1='foo') self.assertEqual(str(qs.query).count('INNER JOIN'), 1) qs = qs.filter(Q(b__f1='foo') | Q(b__f2='foo')) self.assertEqual(str(qs.query).count('INNER JOIN'), 2) qs = BaseA.objects.filter(Q(b__f1='foo') | Q(b__f2='foo')) self.assertEqual(str(qs.query).count('INNER JOIN'), 1) qs = qs.filter(a__f1='foo') self.assertEqual(str(qs.query).count('INNER JOIN'), 2)
qs = qs.filter(Q(b__f1='foo') | Q(c__f2='foo')) self.assertEqual(str(qs.query).count('INNER JOIN'), 1) self.assertEqual(str(qs.query).count('LEFT OUTER JOIN'), 2) qs = BaseA.objects.filter(Q(b__f1='foo') | Q(c__f2='foo')) self.assertEqual(str(qs.query).count('LEFT OUTER JOIN'), 2) qs = qs.filter(a__f1='foo') self.assertEqual(str(qs.query).count('INNER JOIN'), 1) self.assertEqual(str(qs.query).count('LEFT OUTER JOIN'), 2)
qs = qs.filter(Q(a__f1='foo') | Q(b__f2='foo')) self.assertEqual(str(qs.query).count('INNER JOIN'), 1) self.assertEqual(str(qs.query).count('LEFT OUTER JOIN'), 1)
qs = BaseA.objects.filter( Q(a__f1='foo') | Q(b__f2='foo')).filter(a__f2='bar') self.assertEqual(str(qs.query).count('INNER JOIN'), 1) self.assertEqual(str(qs.query).count('LEFT OUTER JOIN'), 1)
qs = qs.filter(a__f1='foo') self.assertEqual(str(qs.query).count('INNER JOIN'), 1)
self.assertEqual(str(qs.query).count('JOIN'), 0) qs = qs.filter(Q(a__f1='foo') | Q(b__f1='foo')) self.assertEqual(str(qs.query).count('INNER JOIN'), 1) self.assertEqual(str(qs.query).count('LEFT OUTER JOIN'), 1) qs = BaseA.objects.filter(Q(a__f1='foo') | Q(b__f1='foo')) self.assertEqual(str(qs.query).count('LEFT OUTER JOIN'), 2) qs = qs.filter(Q(a=1) | Q(a=2)) self.assertEqual(str(qs.query).count('INNER JOIN'), 1) self.assertEqual(str(qs.query).count('LEFT OUTER JOIN'), 1)
self.assertQuerysetEqual( Identifier.objects.exclude(program__channel=channel).order_by('name'), ['<Identifier: channel>', '<Identifier: extra>'] ) self.assertQuerysetEqual( Identifier.objects.exclude(program__channel=None).order_by('name'), ['<Identifier: program>'] )
self.assertEqual(list(children), [my2]) self.assertEqual(list(parents), [my1])
o1 = Order.objects.create(id=-2) o2 = Order.objects.create(id=-1) oi1 = OrderItem.objects.create(order=o1, status=0) oi1.status = oi1.pk oi1.save() OrderItem.objects.create(order=o2, status=0)
self.assertQuerysetEqual( Order.objects.filter(items__in=OrderItem.objects.values_list('status')), [o1.pk], lambda x: x.pk)
qs = Item.objects.exclude( note__isnull=False ).filter( name='something', creator__extra__isnull=True ).order_by() self.assertEqual(1, str(qs.query).count('INNER JOIN')) self.assertEqual(0, str(qs.query).count('OUTER JOIN'))
qs = Paragraph.objects.filter((Q(pk=p2.pk) | ~Q(pk__in=[])) & Q(pk=p1.pk)) self.assertQuerysetEqual(qs, [p1], lambda x: x)
with self.assertRaisesMessage(ValueError, self.error % (self.wrong_type, ObjectA._meta.object_name)): ObjectB.objects.get(objecta=self.wrong_type)
with self.assertRaisesMessage(ValueError, self.error % (self.ob, ObjectA._meta.object_name)): ObjectB.objects.filter(objecta__in=[self.poa, self.ob])
self.assertQuerysetEqual(ObjectB.objects.filter(objecta=self.poa).order_by('name'), out_b) self.assertQuerysetEqual(ObjectA.objects.filter(objectb__in=self.pob).order_by('pk'), out_a * 2)
self.assertQuerysetEqual(ObjectB.objects.filter(objecta__in=[self.coa]), []) self.assertQuerysetEqual(ObjectB.objects.filter(objecta__in=[self.poa, self.coa]).order_by('name'), out_b) self.assertQuerysetEqual( ObjectB.objects.filter(objecta__in=iter([self.poa, self.coa])).order_by('name'), out_b )
self.assertQuerysetEqual(ObjectC.objects.exclude(childobjecta=self.oa), out_c)
with self.assertNumQueries(0): ObjectB.objects.filter(objecta__in=ObjectA.objects.all())
ob = ObjectB.objects.get(name='ob') ob.num = ob.objecta.pk ob.save() pob = ObjectB.objects.get(name='pob') pob.num = pob.objecta.pk pob.save() self.assertQuerysetEqual(ObjectB.objects.filter( objecta__in=ObjectB.objects.all().values_list('num') ).order_by('pk'), ['<ObjectB: ob>', '<ObjectB: pob>'])
task_get.creator.staffuser.staff task_get.owner.staffuser.staff qs = Task.objects.select_related( 'creator__staffuser__staff', 'owner__staffuser__staff') self.assertEqual(str(qs.query).count(' JOIN '), 6) task_select_related = qs.get(pk=task.pk) with self.assertNumQueries(0): self.assertEqual(task_select_related.creator.staffuser.staff, task_get.creator.staffuser.staff) self.assertEqual(task_select_related.owner.staffuser.staff, task_get.owner.staffuser.staff)
qs = Node.objects.values('parent__parent__id') self.assertIn(' LEFT OUTER JOIN ', str(qs.query))
a1 = Ticket23605A.objects.create() a2 = Ticket23605A.objects.create() c1 = Ticket23605C.objects.create(field_c0=10000.0) Ticket23605B.objects.create( field_b0=10000.0, field_b1=True, modelc_fk=c1, modela_fk=a1) complex_q = Q(pk__in=Ticket23605A.objects.filter( Q( ticket23605b__field_b0__gte=1000000 / F("ticket23605b__modelc_fk__field_c0") ) & Q(ticket23605b__field_b1=True) & ~Q(ticket23605b__pk__in=Ticket23605B.objects.filter( ~( Q(field_b1=True) & Q(field_b0__gte=1000000 / F("modelc_fk__field_c0")) ) ))).filter(ticket23605b__field_b1=True)) qs1 = Ticket23605A.objects.filter(complex_q) self.assertQuerysetEqual(qs1, [a1], lambda x: x) qs2 = Ticket23605A.objects.exclude(complex_q) self.assertQuerysetEqual(qs2, [a2], lambda x: x)
for k in kwargs: assert k in [f.attname for f in self._meta.fields], \ "Author.__init__ got an unexpected parameter: %s" % k
self.assertEqual( getattr(item, field.attname), getattr(orig_item, field.attname) ) self.assertEqual( type(getattr(item, field.attname)), type(getattr(orig_item, field.attname)) )
self.assertNotEqual(author.last_name, None)
first_iterations = 0 for index, raw_author in enumerate(raw_authors): self.assertEqual(normal_authors[index], raw_author) first_iterations += 1
second_iterations = 0 for index, raw_author in enumerate(raw_authors): self.assertEqual(normal_authors[index], raw_author) second_iterations += 1
query = "SELECT * FROM raw_query_author ORDER BY id ASC" third_author = Author.objects.raw(query)[2] self.assertEqual(third_author.first_name, 'Bob')
with self.assertRaises(Article.DoesNotExist): Article.objects.earliest()
self.assertEqual(Article.objects.earliest(), a1) self.assertEqual( Article.objects.filter(pub_date__gt=datetime(2005, 7, 26)).earliest(), a2 )
self.assertEqual(Article.objects.earliest('expire_date'), a2) self.assertEqual(Article.objects.filter( pub_date__gt=datetime(2005, 7, 26)).earliest('expire_date'), a2)
self.assertEqual(Article.objects.order_by('id').earliest(), a1)
Article.objects.model._meta.get_latest_by = None with self.assertRaisesMessage( AssertionError, "earliest() and latest() require either a field_name parameter or " "'get_latest_by' in the model" ): Article.objects.earliest()
with self.assertRaises(Article.DoesNotExist): Article.objects.latest()
self.assertEqual(Article.objects.latest(), a4) self.assertEqual( Article.objects.filter(pub_date__lt=datetime(2005, 7, 27)).latest(), a1 )
self.assertEqual(Article.objects.latest('expire_date'), a1) self.assertEqual( Article.objects.filter(pub_date__gt=datetime(2005, 7, 26)).latest('expire_date'), a3, )
self.assertEqual(Article.objects.order_by('id').latest(), a4)
Article.objects.model._meta.get_latest_by = None with self.assertRaisesMessage( AssertionError, "earliest() and latest() require either a field_name parameter or " "'get_latest_by' in the model" ): Article.objects.latest()
Person.objects.create(name="Ralph", birthday=datetime(1950, 1, 1)) p2 = Person.objects.create(name="Stephanie", birthday=datetime(1960, 2, 3)) with self.assertRaises(AssertionError): Person.objects.latest() self.assertEqual(Person.objects.latest("birthday"), p2)
self.assertEqual( Person.objects.last(), p2) self.assertEqual( Person.objects.order_by('-name').last(), p1) self.assertEqual( Person.objects.filter(birthday__lte=datetime(1955, 1, 1)).last(), p1) self.assertIs( Person.objects.filter(birthday__lte=datetime(1940, 1, 1)).last(), None)
with self.assertRaises(IndexError): IndexErrorArticle.objects.all()[0] with self.assertRaises(IndexError): IndexErrorArticle.objects.all().first() with self.assertRaises(IndexError): IndexErrorArticle.objects.all().last()
IndexErrorArticle.objects.create( headline="Article 1", pub_date=datetime(2005, 7, 26), expire_date=datetime(2005, 9, 1) ) check()
data = BytesIO(data) for chunk in iter(lambda: data.read(MAX_SOCKET_CHUNK_SIZE), b''): self._write(chunk) self._flush()
def finish_response(self): try: if not self.result_is_file() or not self.sendfile(): for data in self.result: self.write(data) self.finish_content() finally: self.close()
return [b'x' * (MAX_SOCKET_CHUNK_SIZE + MAX_SOCKET_CHUNK_SIZE // 2)]
class SimpleTestCaseSubclass(SimpleTestCase): pass
del settings.USE_L10N with self.assertRaises(AttributeError): getattr(settings, 'USE_L10N') self.assertNotIn('USE_I18N', dir(settings)) self.assertNotIn('USE_L10N', dir(settings))
self.assertEqual('override', settings.TEST) with self.assertRaises(AttributeError): getattr(settings, 'TEST2')
self.assertEqual(os.path.splitext(w[0].filename)[0], os.path.splitext(__file__)[0]) self.assertEqual(str(w[0].message), 'Overriding setting TEST_WARN can lead to unexpected behavior.')
lazy_settings.APPEND_SLASH self.assertEqual(repr(lazy_settings), expected)
from __future__ import unicode_literals
return six.text_type(value)
from __future__ import unicode_literals
with self.assertRaises(SerializerDoesNotExist) as cm: serializers.get_serializer("nonsense") self.assertEqual(cm.exception.args, ("nonsense",))
for stream in (StringIO(), HttpResponse()): serializers.serialize(self.serializer_name, [obj], indent=2, stream=stream)
string_data = serializers.serialize(self.serializer_name, [obj], indent=2)
if isinstance(stream, StringIO): self.assertEqual(string_data, stream.getvalue()) else: self.assertEqual(string_data, stream.content.decode('utf-8'))
serialized_data = serializers.serialize( self.serializer_name, [obj], indent=2, fields=('field1', 'field3') ) result = next(serializers.deserialize(self.serializer_name, serialized_data))
self.assertEqual(result.object.field1, 'first') self.assertEqual(result.object.field2, '') self.assertEqual(result.object.field3, 'third')
self.assertTrue(Article.objects.filter(headline=old_headline)) self.assertFalse(Article.objects.filter(headline=new_headline))
self.assertTrue(Article.objects.filter(headline=new_headline)) self.assertFalse(Article.objects.filter(headline=old_headline))
self.assertEqual(deserial_objs[0].object.__class__, Author)
a = Article.objects.create( author=self.jane, headline="Nobody remembers the early years", pub_date=datetime(1, 2, 3, 4, 5, 6))
with transaction.atomic(): objs = serializers.deserialize(self.serializer_name, self.fwd_ref_str) with connection.constraint_checks_disabled(): for obj in objs: obj.save()
with connection.constraint_checks_disabled(): objects = [ NaturalKeyAnchor.objects.create(id=1100, data="Natural Key Anghor"), FKDataNaturalKey.objects.create(id=1101, data_id=1100), FKDataNaturalKey.objects.create(id=1102, data_id=None), ] serialized_data = serializers.serialize(format, objects, indent=2, use_natural_foreign_keys=True)
for obj in objects: instance = obj.__class__.objects.get(id=obj.pk) self.assertEqual( obj.data, instance.data, "Objects with PK=%d not equal; expected '%s' (%s), got '%s' (%s)" % ( obj.pk, obj.data, type(obj.data), instance, type(instance.data), ) )
adrian = NaturalKeyAnchor.objects.create(**book1) james = NaturalKeyAnchor.objects.create(**book2)
string_data = serializers.serialize( format, NaturalKeyAnchor.objects.all(), indent=2, use_natural_foreign_keys=True, use_natural_primary_keys=True, )
james.delete()
books = list(serializers.deserialize(format, string_data)) self.assertEqual(len(books), 2) self.assertEqual(books[0].object.title, book1['title']) self.assertEqual(books[0].object.pk, adrian.pk) self.assertEqual(books[1].object.title, book2['title']) self.assertEqual(books[1].object.pk, None)
register_tests(NaturalKeySerializerTests, 'test_%s_natural_key_serializer', natural_key_serializer_test) register_tests(NaturalKeySerializerTests, 'test_%s_serializer_natural_keys', natural_key_test)
models.Model.save(instance) created = [instance] for klass, field in instance._meta.parents.items(): created.append(klass.objects.get(id=pk)) return created
data_obj = (data_create, data_compare) generic_obj = (generic_create, generic_compare) fk_obj = (fk_create, fk_compare) m2m_obj = (m2m_create, m2m_compare) im2m_obj = (im2m_create, im2m_compare) im_obj = (im_create, im_compare) o2o_obj = (o2o_create, o2o_compare) pk_obj = (pk_create, pk_compare) inherited_obj = (inherited_create, inherited_compare) uuid_obj = uuid.uuid4()
(im_obj, 480, Intermediate, {'right': 300, 'left': 470}), (im_obj, 481, Intermediate, {'right': 300, 'left': 490}), (im_obj, 482, Intermediate, {'right': 500, 'left': 470}), (im_obj, 483, Intermediate, {'right': 500, 'left': 490}), (im_obj, 484, Intermediate, {'right': 300, 'left': 470, 'extra': "extra"}), (im_obj, 485, Intermediate, {'right': 300, 'left': 490, 'extra': "extra"}), (im_obj, 486, Intermediate, {'right': 500, 'left': 470, 'extra': "extra"}), (im_obj, 487, Intermediate, {'right': 500, 'left': 490, 'extra': "extra"}),
(pk_obj, 640, EmailPKData, "hovercraft@example.com"), (pk_obj, 660, FilePathPKData, "/foo/bar/whiz.txt"), (pk_obj, 670, DecimalPKData, decimal.Decimal('12.345')), (pk_obj, 671, DecimalPKData, decimal.Decimal('-12.345')), (pk_obj, 672, DecimalPKData, decimal.Decimal('0.0')), (pk_obj, 673, FloatPKData, 12.345), (pk_obj, 674, FloatPKData, -12.345), (pk_obj, 675, FloatPKData, 0.0), (pk_obj, 680, IntegerPKData, 123456789), (pk_obj, 681, IntegerPKData, -123456789), (pk_obj, 682, IntegerPKData, 0), (pk_obj, 695, GenericIPAddressPKData, "fe80:1424:2223:6cff:fe8a:2e8a:2151:abcd"), (pk_obj, 720, PositiveIntegerPKData, 123456789), (pk_obj, 730, PositiveSmallIntegerPKData, 12), (pk_obj, 740, SlugPKData, "this-is-a-slug"), (pk_obj, 750, SmallPKData, 12), (pk_obj, 751, SmallPKData, -12), (pk_obj, 752, SmallPKData, 0), (pk_obj, 791, UUIDData, uuid_obj), (fk_obj, 792, FKToUUID, uuid_obj),
if connection.features.interprets_empty_strings_as_nulls: test_data = [data for data in test_data if not (data[0] == data_obj and data[2]._meta.get_field('data').empty_strings_allowed and data[3] is None)]
if connection.features.allows_auto_pk_0: test_data.extend([ (data_obj, 0, Anchor, "Anchor 0"), (fk_obj, 465, FKData, 0), ])
objects = [] instance_count = {} for (func, pk, klass, datum) in test_data: with connection.constraint_checks_disabled(): objects.extend(func[0](pk, klass, datum))
for klass in instance_count: instance_count[klass] = klass.objects.count()
objects.extend(Tag.objects.all())
serialized_data = serializers.serialize(format, objects, indent=2)
for (func, pk, klass, datum) in test_data: func[1](self, pk, klass, datum)
for klass, count in instance_count.items(): self.assertEqual(count, klass.objects.count())
data = models.OneToOneField(Anchor, models.CASCADE, primary_key=True)
from __future__ import unicode_literals
serializers._serializers = {}
serializers._serializers = {}
if isinstance(field_value, six.string_types): ret_list.append(field_value) else: ret_list.append(str(field_value))
from __future__ import unicode_literals
from django.db import models from django.utils.encoding import python_2_unicode_compatible
self.assertEqual(formset.is_valid(), False) self.assertEqual(Poem.objects.count(), 0)
data['poem_set-0-DELETE'] = 'on' formset = PoemFormSet(data, instance=poet) self.assertEqual(formset.is_valid(), True) formset.save() self.assertEqual(Poem.objects.count(), 0)
self.assertEqual(formset.is_valid(), False) self.assertEqual(Poem.objects.count(), 1)
data['poem_set-0-DELETE'] = 'on' formset = PoemFormSet(data, instance=poet) self.assertEqual(formset.is_valid(), True) formset.save() self.assertEqual(Poem.objects.count(), 0)
ChildFormSet = inlineformset_factory(School, Child, exclude=['father', 'mother']) school = School.objects.create(name='test') mother = Parent.objects.create(name='mother') father = Parent.objects.create(name='father') data = { 'child_set-TOTAL_FORMS': '1', 'child_set-INITIAL_FORMS': '0', 'child_set-MAX_NUM_FORMS': '0', 'child_set-0-name': 'child', } formset = ChildFormSet(data, instance=school) self.assertEqual(formset.is_valid(), True) objects = formset.save(commit=False) for obj in objects: obj.mother = mother obj.father = father obj.save() self.assertEqual(school.child_set.count(), 1)
inlineformset_factory( Parent, Child, exclude=['school'], fk_name='mother' )
poet = Poet.objects.create(id=0, name='test') poet.poem_set.create(name='test poem') PoemFormSet = inlineformset_factory(Poet, Poem, fields="__all__", extra=0) formset = PoemFormSet(None, instance=poet) self.assertEqual(len(formset.forms), 1)
from __future__ import unicode_literals
self.req.META['HTTP_REFERER'] = b'http://testserver/c/\xd0\xbb\xd0\xb8/' BrokenLinkEmailsMiddleware().process_response(self.req, self.resp) self.assertEqual(len(mail.outbox), 1)
self.req.META['HTTP_REFERER'] = '/another/url/' self.req.META['HTTP_USER_AGENT'] = b'\xd0\xbb\xd0\xb8\xff\xff' BrokenLinkEmailsMiddleware().process_response(self.req, self.resp) self.assertEqual(len(mail.outbox), 1) self.assertIn('User agent: \u043b\u0438\ufffd\ufffd\n', mail.outbox[0].body)
self.req.META['HTTP_REFERER'] = 'http://testserver%s' % self.req.path BrokenLinkEmailsMiddleware().process_response(self.req, self.resp) self.assertEqual(len(mail.outbox), 0)
self.req.META['HTTP_X_PROTO'] = 'https' self.req.META['SERVER_PORT'] = 443 with self.settings(SECURE_PROXY_SSL_HEADER=('HTTP_X_PROTO', 'https')): BrokenLinkEmailsMiddleware().process_response(self.req, self.resp) self.assertEqual(len(mail.outbox), 0)
def get_xframe_options_value(self, request, response): if getattr(request, 'sameorigin', False): return 'SAMEORIGIN' if getattr(response, 'sameorigin', False): return 'SAMEORIGIN' return 'DENY'
from __future__ import unicode_literals
self.assertEqual(Employee.objects.get(employee_code=123), self.dan)
e = Employee.objects.get(pk=123) self.assertEqual(e.pk, 123) self.assertEqual(e.employee_code, 123)
Business.objects.create(name='ja')
Employee.objects.create( employee_code=123, first_name="Frank", last_name="Jones" ) with self.assertRaises(IntegrityError): with transaction.atomic(): Employee.objects.create(employee_code=123, first_name="Fred", last_name="Jones")
new_bar = Bar.objects.create() new_foo = Foo.objects.create(bar=new_bar)
@skipIfDBFeature('supports_unspecified_pk') def test_required_pk(self): with self.assertRaises(IntegrityError): with transaction.atomic(): Employee.objects.create(first_name="Tom", last_name="Smith")
@python_2_unicode_compatible class Thing(models.Model): when = models.CharField(max_length=1, primary_key=True)
self.local_models = []
self.delete_tables() new_apps.clear_cache() for model in new_apps.get_models(): model._meta._expire_cache() if 'schema' in new_apps.all_models: for model in self.local_models: for many_to_many in model._meta.many_to_many: through = many_to_many.remote_field.through if through and through._meta.auto_created: del new_apps.all_models['schema'][through._meta.model_name] del new_apps.all_models['schema'][model._meta.model_name]
for name, (type, desc) in columns.items(): if isinstance(type, tuple): columns[name] = (type[0], desc) if not columns: raise DatabaseError("Table does not exist (empty pragma)") return columns
with connection.schema_editor() as editor: editor.create_model(Author) list(Author.objects.all()) with connection.schema_editor() as editor: editor.delete_model(Author) with self.assertRaises(DatabaseError): list(Author.objects.all())
with connection.schema_editor() as editor: editor.create_model(Book) editor.create_model(Author) editor.create_model(Tag) list(Author.objects.all()) list(Book.objects.all()) with self.assertRaises(IntegrityError): Book.objects.create( author_id=1, title="Much Ado About Foreign Keys", pub_date=datetime.datetime.now(), ) old_field = Book._meta.get_field("author") new_field = ForeignKey(Tag, CASCADE) new_field.set_attributes_from_name("author") with connection.schema_editor() as editor: editor.alter_field(Book, old_field, new_field, strict=True) constraints = self.get_constraints(Book._meta.db_table) for name, details in constraints.items(): if details['columns'] == ["author_id"] and details['foreign_key']: self.assertEqual(details['foreign_key'], ('schema_tag', 'id')) break else: self.fail("No FK constraint for author_id found")
with connection.schema_editor() as editor: editor.create_model(Author) editor.create_model(AuthorRef) constraints = self.get_constraints(AuthorRef._meta.db_table) for details in constraints.values(): if details['columns'] == ['author_id'] and details['foreign_key']: self.assertEqual(details['foreign_key'], ('schema_author', 'id')) break else: self.fail('No FK constraint for author_id found')
with connection.schema_editor() as editor: editor.create_model(Tag) editor.create_model(Author) editor.create_model(BookWeak) list(Author.objects.all()) list(Tag.objects.all()) list(BookWeak.objects.all()) constraints = self.get_constraints(BookWeak._meta.db_table) for name, details in constraints.items(): if details['columns'] == ["author_id"] and details['foreign_key']: self.fail("FK constraint for author_id found") new_field = ForeignKey(Tag, CASCADE, db_constraint=False) new_field.set_attributes_from_name("tag") with connection.schema_editor() as editor: editor.add_field(Author, new_field) constraints = self.get_constraints(Author._meta.db_table) for name, details in constraints.items(): if details['columns'] == ["tag_id"] and details['foreign_key']: self.fail("FK constraint for tag_id found") new_field2 = ForeignKey(Tag, CASCADE) new_field2.set_attributes_from_name("tag") with connection.schema_editor() as editor: editor.alter_field(Author, new_field, new_field2, strict=True) constraints = self.get_constraints(Author._meta.db_table) for name, details in constraints.items(): if details['columns'] == ["tag_id"] and details['foreign_key']: self.assertEqual(details['foreign_key'], ('schema_tag', 'id')) break else: self.fail("No FK constraint for tag_id found") new_field2 = ForeignKey(Tag, CASCADE) new_field2.set_attributes_from_name("tag") with connection.schema_editor() as editor: editor.alter_field(Author, new_field2, new_field, strict=True) constraints = self.get_constraints(Author._meta.db_table) for name, details in constraints.items(): if details['columns'] == ["tag_id"] and details['foreign_key']: self.fail("FK constraint for tag_id found")
with connection.schema_editor() as editor: editor.create_model(Tag) editor.create_model(LocalAuthorWithM2M) list(LocalAuthorWithM2M.objects.all()) list(Tag.objects.all()) new_field = M2MFieldClass(Tag, related_name="authors", db_constraint=False) new_field.contribute_to_class(LocalAuthorWithM2M, "tags") with connection.schema_editor() as editor: editor.add_field(LocalAuthorWithM2M, new_field) constraints = self.get_constraints(new_field.remote_field.through._meta.db_table) for name, details in constraints.items(): if details['columns'] == ["tag_id"] and details['foreign_key']: self.fail("FK constraint for tag_id found")
with connection.schema_editor() as editor: editor.create_model(Author) columns = self.column_classes(Author) self.assertNotIn("age", columns) new_field = IntegerField(null=True) new_field.set_attributes_from_name("age") with connection.schema_editor() as editor: editor.add_field(Author, new_field) columns = self.column_classes(Author) self.assertEqual(columns['age'][0], "IntegerField") self.assertEqual(columns['age'][1][6], True)
with connection.schema_editor() as editor: editor.create_model(Author) columns = self.column_classes(Author) self.assertNotIn("age", columns) Author.objects.create(name="Andrew", height=30) Author.objects.create(name="Andrea") new_field = CharField(max_length=30, default="Godwin") new_field.set_attributes_from_name("surname") with connection.schema_editor() as editor: editor.add_field(Author, new_field) columns = self.column_classes(Author) self.assertEqual(columns['surname'][0], "CharField") self.assertEqual(columns['surname'][1][6], connection.features.interprets_empty_strings_as_nulls)
with connection.schema_editor() as editor: editor.create_model(Author) columns = self.column_classes(Author) self.assertNotIn("age", columns) Author.objects.create(name="Andrew", height=30) Author.objects.create(name="Andrea") new_field = BooleanField(default=False) new_field.set_attributes_from_name("awesome") with connection.schema_editor() as editor: editor.add_field(Author, new_field) columns = self.column_classes(Author) field_type = columns['awesome'][0] self.assertEqual( field_type, connection.features.introspected_boolean_field_type(new_field, created_separately=True) )
def get_default(self): return self.default
with connection.schema_editor() as editor: editor.create_model(Author) Author.objects.create(name="Andrew", height=30) Author.objects.create(name="Andrea") new_field = TestTransformField(default={1: 2}) new_field.set_attributes_from_name("thing") with connection.schema_editor() as editor: editor.add_field(Author, new_field) columns = self.column_classes(Author) field_type, field_info = columns['thing'] self.assertEqual(field_type, 'IntegerField') self.assertEqual(Author.objects.extra(where=["thing = 1"]).count(), 2)
with connection.schema_editor() as editor: editor.create_model(Author) new_field = BinaryField(blank=True) new_field.set_attributes_from_name("bits") with connection.schema_editor() as editor: editor.add_field(Author, new_field) columns = self.column_classes(Author) self.assertIn(columns['bits'][0], ("BinaryField", "TextField"))
with connection.schema_editor() as editor: editor.create_model(Author) new_field = MediumBlobField(blank=True, default=b'123') new_field.set_attributes_from_name('bits') with connection.schema_editor() as editor: editor.add_field(Author, new_field) columns = self.column_classes(Author) self.assertEqual(columns['bits'][0], "TextField")
with connection.schema_editor() as editor: editor.create_model(Author) columns = self.column_classes(Author) self.assertEqual(columns['name'][0], "CharField") self.assertEqual(bool(columns['name'][1][6]), bool(connection.features.interprets_empty_strings_as_nulls)) old_field = Author._meta.get_field("name") new_field = TextField(null=True) new_field.set_attributes_from_name("name") with connection.schema_editor() as editor: editor.alter_field(Author, old_field, new_field, strict=True) columns = self.column_classes(Author) self.assertEqual(columns['name'][0], "TextField") self.assertEqual(columns['name'][1][6], True) new_field2 = TextField(null=False) new_field2.set_attributes_from_name("name") with connection.schema_editor() as editor: editor.alter_field(Author, new_field, new_field2, strict=True) columns = self.column_classes(Author) self.assertEqual(columns['name'][0], "TextField") self.assertEqual(bool(columns['name'][1][6]), bool(connection.features.interprets_empty_strings_as_nulls))
with connection.schema_editor() as editor: editor.create_model(Note) old_field = Note._meta.get_field("info") new_field = TextField(blank=True) new_field.set_attributes_from_name("info") with connection.schema_editor() as editor: editor.alter_field(Note, old_field, new_field, strict=True)
columns = self.column_classes(Note) self.assertFalse(columns['info'][1][6])
columns = self.column_classes(Note) self.assertFalse(columns['info'][1][6])
columns = self.column_classes(Note) self.assertFalse(columns['info'][1][6])
with connection.schema_editor() as editor: editor.create_model(Author) columns = self.column_classes(Author) self.assertTrue(columns['height'][1][6]) Author.objects.create(name='Not null author', height=12) Author.objects.create(name='Null author') self.assertEqual(Author.objects.get(name='Not null author').height, 12) self.assertIsNone(Author.objects.get(name='Null author').height) old_field = Author._meta.get_field("height") new_field = PositiveIntegerField(default=42) new_field.set_attributes_from_name("height") with connection.schema_editor() as editor: editor.alter_field(Author, old_field, new_field) columns = self.column_classes(Author) self.assertFalse(columns['height'][1][6]) self.assertEqual(Author.objects.get(name='Not null author').height, 12) self.assertEqual(Author.objects.get(name='Null author').height, 42)
with connection.schema_editor() as editor: editor.create_model(Author) old_field = Author._meta.get_field('name') new_field = copy(old_field) new_field.null = True with connection.schema_editor() as editor: editor.alter_field(Author, old_field, new_field)
with connection.schema_editor() as editor: editor.create_model(Note) old_field = Note._meta.get_field('info') new_field = copy(old_field) new_field.null = True with connection.schema_editor() as editor: editor.alter_field(Note, old_field, new_field)
with connection.schema_editor() as editor: editor.create_model(AuthorWithDefaultHeight) columns = self.column_classes(AuthorWithDefaultHeight) self.assertTrue(columns['height'][1][6]) old_field = AuthorWithDefaultHeight._meta.get_field("height") new_field = PositiveIntegerField(default=42) new_field.set_attributes_from_name("height") with connection.schema_editor() as editor: editor.alter_field(AuthorWithDefaultHeight, old_field, new_field) columns = self.column_classes(AuthorWithDefaultHeight) self.assertFalse(columns['height'][1][6])
with connection.schema_editor() as editor: editor.create_model(Author) editor.create_model(Book) columns = self.column_classes(Book) self.assertEqual(columns['author_id'][0], "IntegerField") constraints = self.get_constraints(Book._meta.db_table) for name, details in constraints.items(): if details['columns'] == ["author_id"] and details['foreign_key']: self.assertEqual(details['foreign_key'], ('schema_author', 'id')) break else: self.fail("No FK constraint for author_id found") old_field = Book._meta.get_field("author") new_field = ForeignKey(Author, CASCADE, editable=False) new_field.set_attributes_from_name("author") with connection.schema_editor() as editor: editor.alter_field(Book, old_field, new_field, strict=True) columns = self.column_classes(Book) self.assertEqual(columns['author_id'][0], "IntegerField") constraints = self.get_constraints(Book._meta.db_table) for name, details in constraints.items(): if details['columns'] == ["author_id"] and details['foreign_key']: self.assertEqual(details['foreign_key'], ('schema_author', 'id')) break else: self.fail("No FK constraint for author_id found")
with connection.schema_editor() as editor: editor.create_model(Author) editor.create_model(LocalBook) constraints = self.get_constraints(LocalBook._meta.db_table) for name, details in constraints.items(): if details['foreign_key']: self.fail('Found an unexpected FK constraint to %s' % details['columns']) old_field = LocalBook._meta.get_field("author") new_field = ForeignKey(Author, CASCADE) new_field.set_attributes_from_name("author") with connection.schema_editor() as editor: editor.alter_field(LocalBook, old_field, new_field, strict=True) constraints = self.get_constraints(LocalBook._meta.db_table) for name, details in constraints.items(): if details['foreign_key'] and details['columns'] == ["author_id"]: self.assertEqual(details['foreign_key'], ('schema_author', 'id')) break else: self.fail("No FK constraint for author_id found")
with connection.schema_editor() as editor: editor.create_model(Author) editor.create_model(BookWithO2O) columns = self.column_classes(BookWithO2O) self.assertEqual(columns['author_id'][0], "IntegerField") author = Author.objects.create(name="Joe") BookWithO2O.objects.create(author=author, title="Django 1", pub_date=datetime.datetime.now()) with self.assertRaises(IntegrityError): BookWithO2O.objects.create(author=author, title="Django 2", pub_date=datetime.datetime.now()) BookWithO2O.objects.all().delete() constraints = self.get_constraints(BookWithO2O._meta.db_table) author_is_fk = False for name, details in constraints.items(): if details['columns'] == ['author_id']: if details['foreign_key'] and details['foreign_key'] == ('schema_author', 'id'): author_is_fk = True self.assertTrue(author_is_fk, "No FK constraint for author_id found") old_field = BookWithO2O._meta.get_field("author") new_field = ForeignKey(Author, CASCADE) new_field.set_attributes_from_name("author") with connection.schema_editor() as editor: editor.alter_field(BookWithO2O, old_field, new_field, strict=True) columns = self.column_classes(Book) self.assertEqual(columns['author_id'][0], "IntegerField") Book.objects.create(author=author, title="Django 1", pub_date=datetime.datetime.now()) Book.objects.create(author=author, title="Django 2", pub_date=datetime.datetime.now()) constraints = self.get_constraints(Book._meta.db_table) author_is_fk = False for name, details in constraints.items(): if details['columns'] == ['author_id']: if details['foreign_key'] and details['foreign_key'] == ('schema_author', 'id'): author_is_fk = True self.assertTrue(author_is_fk, "No FK constraint for author_id found")
with connection.schema_editor() as editor: editor.create_model(Author) editor.create_model(Book) columns = self.column_classes(Book) self.assertEqual(columns['author_id'][0], "IntegerField") author = Author.objects.create(name="Joe") Book.objects.create(author=author, title="Django 1", pub_date=datetime.datetime.now()) Book.objects.create(author=author, title="Django 2", pub_date=datetime.datetime.now()) Book.objects.all().delete() constraints = self.get_constraints(Book._meta.db_table) author_is_fk = False for name, details in constraints.items(): if details['columns'] == ['author_id']: if details['foreign_key'] and details['foreign_key'] == ('schema_author', 'id'): author_is_fk = True self.assertTrue(author_is_fk, "No FK constraint for author_id found") old_field = Book._meta.get_field("author") new_field = OneToOneField(Author, CASCADE) new_field.set_attributes_from_name("author") with connection.schema_editor() as editor: editor.alter_field(Book, old_field, new_field, strict=True) columns = self.column_classes(BookWithO2O) self.assertEqual(columns['author_id'][0], "IntegerField") BookWithO2O.objects.create(author=author, title="Django 1", pub_date=datetime.datetime.now()) with self.assertRaises(IntegrityError): BookWithO2O.objects.create(author=author, title="Django 2", pub_date=datetime.datetime.now()) constraints = self.get_constraints(BookWithO2O._meta.db_table) author_is_fk = False for name, details in constraints.items(): if details['columns'] == ['author_id']: if details['foreign_key'] and details['foreign_key'] == ('schema_author', 'id'): author_is_fk = True self.assertTrue(author_is_fk, "No FK constraint for author_id found")
Author.objects.create(name='Foo') Author.objects.create(name='Bar')
old_field = IntegerPK._meta.get_field('j') new_field = IntegerField(primary_key=True) new_field.model = IntegerPK new_field.set_attributes_from_name('j')
IntegerUnique.objects.create(i=1, j=1) with self.assertRaises(IntegrityError): IntegerUnique.objects.create(i=1, j=2)
with connection.schema_editor() as editor: editor.create_model(Author) columns = self.column_classes(Author) self.assertEqual(columns['name'][0], "CharField") self.assertNotIn("display_name", columns) old_field = Author._meta.get_field("name") new_field = CharField(max_length=254) new_field.set_attributes_from_name("display_name") with connection.schema_editor() as editor: editor.alter_field(Author, old_field, new_field, strict=True) columns = self.column_classes(Author) self.assertEqual(columns['display_name'][0], "CharField") self.assertNotIn("name", columns)
with connection.schema_editor() as editor: editor.create_model(Author) editor.create_model(TagM2MTest) editor.create_model(LocalBookWithM2M) columns = self.column_classes(LocalBookWithM2M._meta.get_field("tags").remote_field.through) self.assertEqual(columns['tagm2mtest_id'][0], "IntegerField")
with connection.schema_editor() as editor: editor.create_model(LocalTagThrough) editor.create_model(TagM2MTest) editor.create_model(LocalBookWithM2MThrough) columns = self.column_classes(LocalTagThrough) self.assertEqual(columns['book_id'][0], "IntegerField") self.assertEqual(columns['tag_id'][0], "IntegerField")
with connection.schema_editor() as editor: editor.create_model(LocalAuthorWithM2M) editor.create_model(TagM2MTest) new_field = M2MFieldClass("schema.TagM2MTest", related_name="authors") new_field.contribute_to_class(LocalAuthorWithM2M, "tags") with self.assertRaises(DatabaseError): self.column_classes(new_field.remote_field.through) with connection.schema_editor() as editor: editor.add_field(LocalAuthorWithM2M, new_field) columns = self.column_classes(new_field.remote_field.through) self.assertEqual(columns['tagm2mtest_id'][0], "IntegerField")
with connection.schema_editor() as editor: editor.alter_field(LocalAuthorWithM2M, new_field, new_field)
with connection.schema_editor() as editor: editor.remove_field(LocalAuthorWithM2M, new_field) with self.assertRaises(DatabaseError): self.column_classes(new_field.remote_field.through)
opts = LocalAuthorWithM2M._meta opts.local_many_to_many.remove(new_field) del new_apps.all_models['schema'][new_field.remote_field.through._meta.model_name] opts._expire_cache()
with connection.schema_editor() as editor: editor.create_model(LocalAuthorTag) editor.create_model(LocalAuthorWithM2MThrough) editor.create_model(TagM2MTest) self.assertEqual(len(self.column_classes(LocalAuthorTag)), 3) old_field = LocalAuthorWithM2MThrough._meta.get_field("tags") new_field = M2MFieldClass("schema.TagM2MTest", related_name="authors", through=LocalAuthorTag) new_field.contribute_to_class(LocalAuthorWithM2MThrough, "tags") with connection.schema_editor() as editor: editor.alter_field(LocalAuthorWithM2MThrough, old_field, new_field) self.assertEqual(len(self.column_classes(LocalAuthorTag)), 3)
with connection.schema_editor() as editor: editor.create_model(Author) editor.create_model(LocalBookWithM2M) editor.create_model(TagM2MTest) editor.create_model(UniqueTest) constraints = self.get_constraints( LocalBookWithM2M._meta.get_field("tags").remote_field.through._meta.db_table ) if connection.features.supports_foreign_keys: for name, details in constraints.items(): if details['columns'] == ["tagm2mtest_id"] and details['foreign_key']: self.assertEqual(details['foreign_key'], ('schema_tagm2mtest', 'id')) break else: self.fail("No FK constraint for tagm2mtest_id found") old_field = LocalBookWithM2M._meta.get_field("tags") new_field = M2MFieldClass(UniqueTest) new_field.contribute_to_class(LocalBookWithM2M, "uniques") with connection.schema_editor() as editor: editor.alter_field(LocalBookWithM2M, old_field, new_field) with self.assertRaises(DatabaseError): self.column_classes(LocalBookWithM2M._meta.get_field("tags").remote_field.through)
opts = LocalBookWithM2M._meta opts.local_many_to_many.remove(old_field) constraints = self.get_constraints(new_field.remote_field.through._meta.db_table) if connection.features.supports_foreign_keys: for name, details in constraints.items(): if details['columns'] == ["uniquetest_id"] and details['foreign_key']: self.assertEqual(details['foreign_key'], ('schema_uniquetest', 'id')) break else: self.fail("No FK constraint for uniquetest_id found")
with connection.schema_editor() as editor: editor.create_model(Author) constraints = self.get_constraints(Author._meta.db_table) for name, details in constraints.items(): if details['columns'] == ["height"] and details['check']: break else: self.fail("No check constraint for height found") old_field = Author._meta.get_field("height") new_field = IntegerField(null=True, blank=True) new_field.set_attributes_from_name("height") with connection.schema_editor() as editor: editor.alter_field(Author, old_field, new_field, strict=True) constraints = self.get_constraints(Author._meta.db_table) for name, details in constraints.items(): if details['columns'] == ["height"] and details['check']: self.fail("Check constraint for height found") new_field2 = Author._meta.get_field("height") with connection.schema_editor() as editor: editor.alter_field(Author, new_field, new_field2, strict=True) constraints = self.get_constraints(Author._meta.db_table) for name, details in constraints.items(): if details['columns'] == ["height"] and details['check']: break else: self.fail("No check constraint for height found")
with connection.schema_editor() as editor: editor.create_model(Tag) Tag.objects.create(title="foo", slug="foo") with self.assertRaises(IntegrityError): Tag.objects.create(title="bar", slug="foo") Tag.objects.all().delete() old_field = Tag._meta.get_field("slug") new_field = SlugField(unique=False) new_field.set_attributes_from_name("slug") with connection.schema_editor() as editor: editor.alter_field(Tag, old_field, new_field, strict=True) Tag.objects.create(title="foo", slug="foo") Tag.objects.create(title="bar", slug="foo") Tag.objects.all().delete() new_field2 = SlugField(unique=True) new_field2.set_attributes_from_name("slug") with connection.schema_editor() as editor: editor.alter_field(Tag, new_field, new_field2, strict=True) Tag.objects.create(title="foo", slug="foo") with self.assertRaises(IntegrityError): Tag.objects.create(title="bar", slug="foo") Tag.objects.all().delete() new_field3 = SlugField(unique=True) new_field3.set_attributes_from_name("slug2") with connection.schema_editor() as editor: editor.alter_field(Tag, new_field2, new_field3, strict=True) TagUniqueRename.objects.create(title="foo", slug2="foo") with self.assertRaises(IntegrityError): TagUniqueRename.objects.create(title="bar", slug2="foo") Tag.objects.all().delete()
with connection.schema_editor() as editor: editor.create_model(UniqueTest) UniqueTest.objects.create(year=2012, slug="foo") UniqueTest.objects.create(year=2011, slug="foo") UniqueTest.objects.create(year=2011, slug="bar") with self.assertRaises(IntegrityError): UniqueTest.objects.create(year=2012, slug="foo") UniqueTest.objects.all().delete() with connection.schema_editor() as editor: editor.alter_unique_together(UniqueTest, UniqueTest._meta.unique_together, []) UniqueTest.objects.create(year=2012, slug="foo") UniqueTest.objects.create(year=2012, slug="foo") UniqueTest.objects.all().delete() new_field2 = SlugField(unique=True) new_field2.set_attributes_from_name("slug") with connection.schema_editor() as editor: editor.alter_unique_together(UniqueTest, [], UniqueTest._meta.unique_together) UniqueTest.objects.create(year=2012, slug="foo") with self.assertRaises(IntegrityError): UniqueTest.objects.create(year=2012, slug="foo") UniqueTest.objects.all().delete()
with connection.schema_editor() as editor: editor.create_model(Author) editor.create_model(Book) self.assertEqual(Book._meta.unique_together, ()) with connection.schema_editor() as editor: editor.alter_unique_together(Book, [], [['author', 'title']]) with connection.schema_editor() as editor: editor.alter_unique_together(Book, [['author', 'title']], [])
with connection.schema_editor() as editor: editor.create_model(Author) editor.create_model(BookWithoutAuthor) new_field = ForeignKey(Author, CASCADE) new_field.set_attributes_from_name('author') editor.add_field(BookWithoutAuthor, new_field) self.assertEqual(Book._meta.unique_together, ()) with connection.schema_editor() as editor: editor.alter_unique_together(Book, [], [['author', 'title']]) with connection.schema_editor() as editor: editor.alter_unique_together(Book, [['author', 'title']], [])
with connection.schema_editor() as editor: editor.create_model(Tag) self.assertEqual( False, any( c["index"] for c in self.get_constraints("schema_tag").values() if c['columns'] == ["slug", "title"] ), ) with connection.schema_editor() as editor: editor.alter_index_together(Tag, [], [("slug", "title")]) self.assertEqual( True, any( c["index"] for c in self.get_constraints("schema_tag").values() if c['columns'] == ["slug", "title"] ), ) new_field2 = SlugField(unique=True) new_field2.set_attributes_from_name("slug") with connection.schema_editor() as editor: editor.alter_index_together(Tag, [("slug", "title")], []) self.assertEqual( False, any( c["index"] for c in self.get_constraints("schema_tag").values() if c['columns'] == ["slug", "title"] ), )
with connection.schema_editor() as editor: editor.create_model(Author) editor.create_model(Book) self.assertEqual(Book._meta.index_together, ()) with connection.schema_editor() as editor: editor.alter_index_together(Book, [], [['author', 'title']]) with connection.schema_editor() as editor: editor.alter_index_together(Book, [['author', 'title']], [])
with connection.schema_editor() as editor: editor.create_model(TagIndexed) self.assertEqual( True, any( c["index"] for c in self.get_constraints("schema_tagindexed").values() if c['columns'] == ["slug", "title"] ), )
with connection.schema_editor() as editor: editor.create_model(Author) columns = self.column_classes(Author) self.assertEqual(columns['name'][0], "CharField") with connection.schema_editor() as editor: editor.alter_db_table(Author, "schema_author", "schema_otherauthor") Author._meta.db_table = "schema_otherauthor" columns = self.column_classes(Author) self.assertEqual(columns['name'][0], "CharField") with connection.schema_editor() as editor: editor.alter_db_table(Author, "schema_otherauthor", "schema_author") Author._meta.db_table = "schema_author" columns = self.column_classes(Author) self.assertEqual(columns['name'][0], "CharField")
with connection.schema_editor() as editor: editor.create_model(Author) editor.create_model(Book) self.assertIn( "title", self.get_indexes(Book._meta.db_table), ) old_field = Book._meta.get_field("title") new_field = CharField(max_length=100, db_index=False) new_field.set_attributes_from_name("title") with connection.schema_editor() as editor: editor.alter_field(Book, old_field, new_field, strict=True) self.assertNotIn( "title", self.get_indexes(Book._meta.db_table), ) new_field2 = Book._meta.get_field("title") with connection.schema_editor() as editor: editor.alter_field(Book, new_field, new_field2, strict=True) self.assertIn( "title", self.get_indexes(Book._meta.db_table), ) new_field3 = BookWithSlug._meta.get_field("slug") with connection.schema_editor() as editor: editor.add_field(Book, new_field3) self.assertIn( "slug", self.get_indexes(Book._meta.db_table), ) new_field4 = CharField(max_length=20, unique=False) new_field4.set_attributes_from_name("slug") with connection.schema_editor() as editor: editor.alter_field(BookWithSlug, new_field3, new_field4, strict=True) self.assertNotIn( "slug", self.get_indexes(Book._meta.db_table), )
with connection.schema_editor() as editor: editor.create_model(Tag) self.assertTrue( self.get_indexes(Tag._meta.db_table)['id']['primary_key'], ) id_field = Tag._meta.get_field("id") old_field = Tag._meta.get_field("slug") new_field = SlugField(primary_key=True) new_field.set_attributes_from_name("slug") new_field.model = Tag with connection.schema_editor() as editor: editor.remove_field(Tag, id_field) editor.alter_field(Tag, old_field, new_field) self.assertNotIn( 'id', self.get_indexes(Tag._meta.db_table), ) self.assertTrue( self.get_indexes(Tag._meta.db_table)['slug']['primary_key'], )
with connection.schema_editor() as editor: editor.create_model(AuthorWithEvenLongerName) editor.create_model(BookWithLongName) column_name = connection.ops.quote_name("author_foreign_key_with_really_long_field_name_id")
self.assertIn( column_name, self.get_indexes(BookWithLongName._meta.db_table), )
with connection.schema_editor() as editor: editor.create_model(AuthorWithEvenLongerName) editor.create_model(BookWithLongName) new_field = ForeignKey(AuthorWithEvenLongerName, CASCADE, related_name="something") new_field.set_attributes_from_name("author_other_really_long_named_i_mean_so_long_fk") with connection.schema_editor() as editor: editor.add_field(BookWithLongName, new_field)
with connection.schema_editor() as editor: try: editor.create_model(Thing) except OperationalError as e: self.fail("Errors when applying initial migration for a model " "with a table named after an SQL reserved word: %s" % e) list(Thing.objects.all()) with connection.schema_editor() as editor: editor.delete_model(Thing) with self.assertRaises(DatabaseError): list(Thing.objects.all())
with connection.schema_editor() as editor: editor.create_model(Author) columns = self.column_classes(Author) self.assertNotIn("surname", columns) Author.objects.create(name='Anonymous1') new_field = CharField(max_length=15, blank=True) new_field.set_attributes_from_name("surname") with connection.schema_editor() as editor: editor.add_field(Author, new_field) with connection.cursor() as cursor: cursor.execute("SELECT surname FROM schema_author;") item = cursor.fetchall()[0] self.assertEqual(item[0], None if connection.features.interprets_empty_strings_as_nulls else '')
with connection.schema_editor() as editor: editor.create_model(Author) columns = self.column_classes(Author) self.assertNotIn("surname", columns) Author.objects.create(name='Anonymous1') new_field = CharField(max_length=15, blank=True, default='surname default') new_field.set_attributes_from_name("surname") with connection.schema_editor() as editor: editor.add_field(Author, new_field) with connection.cursor() as cursor: cursor.execute("SELECT surname FROM schema_author;") item = cursor.fetchall()[0] self.assertEqual(item[0], 'surname default') field = next( f for f in connection.introspection.get_table_description(cursor, "schema_author") if f.name == "surname" ) if connection.features.can_introspect_default: self.assertIsNone(field.default)
with connection.schema_editor() as editor: editor.create_model(Author) Author.objects.create(name='Anonymous1') self.assertEqual(Author.objects.get().height, None) old_field = Author._meta.get_field('height') new_field = IntegerField(blank=True, default=42) new_field.set_attributes_from_name('height') with connection.schema_editor() as editor: editor.alter_field(Author, old_field, new_field) self.assertEqual(Author.objects.get().height, 42) with connection.cursor() as cursor: field = next( f for f in connection.introspection.get_table_description(cursor, "schema_author") if f.name == "height" ) if connection.features.can_introspect_default: self.assertIsNone(field.default)
with connection.schema_editor() as editor: editor.create_model(Author) Author.objects.create(name='Anonymous1') new_field = TextField(default={}) new_field.set_attributes_from_name("info") with connection.schema_editor() as editor: editor.add_field(Author, new_field)
with connection.schema_editor() as editor: editor.create_model(Author) self.assertEqual(self.get_constraints_for_column(Author, 'name'), []) old_field = Author._meta.get_field('name') new_field = CharField(max_length=255, db_index=True) new_field.set_attributes_from_name('name') with connection.schema_editor() as editor: editor.alter_field(Author, old_field, new_field, strict=True) self.assertEqual( self.get_constraints_for_column(Author, 'name'), ['schema_author_name_1fbc5617_like', 'schema_author_name_1fbc5617_uniq'] ) with connection.schema_editor() as editor: editor.alter_field(Author, new_field, old_field, strict=True) self.assertEqual(self.get_constraints_for_column(Author, 'name'), [])
with connection.schema_editor() as editor: editor.create_model(Note) self.assertEqual(self.get_constraints_for_column(Note, 'info'), []) old_field = Note._meta.get_field('info') new_field = TextField(db_index=True) new_field.set_attributes_from_name('info') with connection.schema_editor() as editor: editor.alter_field(Note, old_field, new_field, strict=True) self.assertEqual( self.get_constraints_for_column(Note, 'info'), ['schema_note_info_4b0ea695_like', 'schema_note_info_4b0ea695_uniq'] ) with connection.schema_editor() as editor: editor.alter_field(Note, new_field, old_field, strict=True) self.assertEqual(self.get_constraints_for_column(Note, 'info'), [])
with connection.schema_editor() as editor: editor.create_model(BookWithoutAuthor) self.assertEqual( self.get_constraints_for_column(BookWithoutAuthor, 'title'), ['schema_book_d5d3db17', 'schema_book_title_2dfb2dff_like'] ) old_field = BookWithoutAuthor._meta.get_field('title') new_field = CharField(max_length=100, db_index=True, unique=True) new_field.set_attributes_from_name('title') with connection.schema_editor() as editor: editor.alter_field(BookWithoutAuthor, old_field, new_field, strict=True) self.assertEqual( self.get_constraints_for_column(BookWithoutAuthor, 'title'), ['schema_book_d5d3db17', 'schema_book_title_2dfb2dff_like', 'schema_book_title_2dfb2dff_uniq'] ) old_field = BookWithoutAuthor._meta.get_field('title') new_field = CharField(max_length=100, db_index=True) new_field.set_attributes_from_name('title') with connection.schema_editor() as editor: editor.alter_field(BookWithoutAuthor, old_field, new_field, strict=True) self.assertEqual( self.get_constraints_for_column(BookWithoutAuthor, 'title'), ['schema_book_d5d3db17', 'schema_book_title_2dfb2dff_like', 'schema_book_title_2dfb2dff_uniq'] )
with connection.schema_editor() as editor: editor.create_model(Tag) self.assertEqual( self.get_constraints_for_column(Tag, 'slug'), ['schema_tag_slug_2c418ba3_like', 'schema_tag_slug_key'] ) old_field = Tag._meta.get_field('slug') new_field = SlugField(db_index=True, unique=True) new_field.set_attributes_from_name('slug') with connection.schema_editor() as editor: editor.alter_field(Tag, old_field, new_field, strict=True) self.assertEqual( self.get_constraints_for_column(Tag, 'slug'), ['schema_tag_slug_2c418ba3_like', 'schema_tag_slug_key'] ) old_field = Tag._meta.get_field('slug') new_field = SlugField(unique=True) new_field.set_attributes_from_name('slug') with connection.schema_editor() as editor: editor.alter_field(Tag, old_field, new_field, strict=True) self.assertEqual( self.get_constraints_for_column(Tag, 'slug'), ['schema_tag_slug_2c418ba3_like', 'schema_tag_slug_key'] )
with connection.schema_editor() as editor: editor.create_model(Author) columns = self.column_classes(Author) self.assertNotIn("dob_auto_now", columns) self.assertNotIn("dob_auto_now_add", columns) self.assertNotIn("dtob_auto_now", columns) self.assertNotIn("dtob_auto_now_add", columns) self.assertNotIn("tob_auto_now", columns) self.assertNotIn("tob_auto_now_add", columns) Author.objects.create(name='Anonymous1') dob_auto_now = DateField(auto_now=True) dob_auto_now.set_attributes_from_name('dob_auto_now') self.check_added_field_default( editor, Author, dob_auto_now, 'dob_auto_now', now.date(), cast_function=lambda x: x.date(), ) dob_auto_now_add = DateField(auto_now_add=True) dob_auto_now_add.set_attributes_from_name('dob_auto_now_add') self.check_added_field_default( editor, Author, dob_auto_now_add, 'dob_auto_now_add', now.date(), cast_function=lambda x: x.date(), ) dtob_auto_now = DateTimeField(auto_now=True) dtob_auto_now.set_attributes_from_name('dtob_auto_now') self.check_added_field_default( editor, Author, dtob_auto_now, 'dtob_auto_now', now, ) dt_tm_of_birth_auto_now_add = DateTimeField(auto_now_add=True) dt_tm_of_birth_auto_now_add.set_attributes_from_name('dtob_auto_now_add') self.check_added_field_default( editor, Author, dt_tm_of_birth_auto_now_add, 'dtob_auto_now_add', now, ) tob_auto_now = TimeField(auto_now=True) tob_auto_now.set_attributes_from_name('tob_auto_now') self.check_added_field_default( editor, Author, tob_auto_now, 'tob_auto_now', now.time(), cast_function=lambda x: x.time(), ) tob_auto_now_add = TimeField(auto_now_add=True) tob_auto_now_add.set_attributes_from_name('tob_auto_now_add') self.check_added_field_default( editor, Author, tob_auto_now_add, 'tob_auto_now_add', now.time(), cast_function=lambda x: x.time(), )
contribute_to_related_class = ManyToManyField.__dict__['contribute_to_related_class'] _get_m2m_attr = ManyToManyField.__dict__['_get_m2m_attr'] _get_m2m_reverse_attr = ManyToManyField.__dict__['_get_m2m_reverse_attr'] _get_m2m_db_table = ManyToManyField.__dict__['_get_m2m_db_table']
return self.headline
from __future__ import unicode_literals
self.assertEqual(str(a), b'Girl wins \xe2\x82\xac12.500 in lottery')
self.assertIsInstance(obj.__str__(), str) self.assertIsInstance(obj.__repr__(), str) self.assertEqual(str(obj), str('Default object')) self.assertEqual(repr(obj), str('<Default: Default object>'))
from __future__ import unicode_literals
(validate_integer, '42', None), (validate_integer, '-42', None), (validate_integer, -42, None),
(validate_email, '"\\\011"@here.com', None), (validate_email, '"\\\012"@here.com', ValidationError), (validate_email, 'trailingdot@shouldfail.com.', ValidationError), (validate_email, 'a@%s.us' % ('a' * 63), None), (validate_email, 'a@%s.us' % ('a' * 64), ValidationError), (validate_email, 'a@b.com\n', ValidationError), (validate_email, 'a\n@b.com', ValidationError), (validate_email, '"test@test"\n@example.com', ValidationError), (validate_email, 'a@[127.0.0.1]\n', ValidationError),
(validate_ipv6_address, 'fe80::1', None), (validate_ipv6_address, '::1', None), (validate_ipv6_address, '1:2:3:4:5:6:7:8', None),
(URLValidator(), 'http://www.djangoproject.com/\n', ValidationError), (URLValidator(), 'http://[::ffff:192.9.5.5]\n', ValidationError), (URLValidator(), 'http://www.asdasdasdasdsadfm.com.br ', ValidationError), (URLValidator(), 'http://www.asdasdasdasdsadfm.com.br z', ValidationError),
with io.open(create_path('valid_urls.txt'), encoding='utf8') as f: for url in f: TEST_DATA.append((URLValidator(), url.strip(), None)) with io.open(create_path('invalid_urls.txt'), encoding='utf8') as f: for url in f: TEST_DATA.append((URLValidator(), url.strip(), ValidationError))
try: validator(value) except expected: pass else: self.fail("%s not raised when validating '%s'" % ( expected.__name__, value))
Permission.objects.filter(content_type__app_label='swappable_models').delete() ContentType.objects.filter(app_label='swappable_models').delete()
new_io = StringIO() management.call_command('migrate', interactive=False, stdout=new_io)
apps_models = [(p.content_type.app_label, p.content_type.model) for p in Permission.objects.all()] self.assertIn(('swappable_models', 'alternatearticle'), apps_models) self.assertNotIn(('swappable_models', 'article'), apps_models)
if name == 'core': return "django.core" else: return "django.contrib-%s" % name
po_path = '%(path)s/en/LC_MESSAGES/django%(ext)s.po' % { 'path': base_path, 'ext': 'js' if cat_name.endswith('-js') else ''} p = Popen("git diff -U0 %s | egrep '^[-+]msgid' | wc -l" % po_path, stdout=PIPE, stderr=PIPE, shell=True) output, errors = p.communicate() num_changes = int(output.strip()) print("%d changed/added messages in '%s' catalog." % (num_changes, cat_name))
pass
self.visit_literal_block(node)
self.depart_literal_block(node)
pass
has_content = True optional_arguments = 1 option_spec = {'filename': directives.unchanged_required} def run(self): code = '\n'.join(self.content) literal = snippet_with_filename(code, code) if self.arguments: literal['language'] = self.arguments[0] literal['filename'] = self.options['filename'] set_source_info(self, literal) return [literal]
raise self.error(msg)
name = 'djangohtml' def finish(self): super(DjangoStandaloneHTMLBuilder, self).finish() self.info(bold("writing templatebuiltins.js...")) xrefs = self.env.domaindata["std"]["objects"] templatebuiltins = { "ttags": [n for ((t, n), (l, a)) in xrefs.items() if t == "templatetag" and l == "ref/templates/builtins"], "tfilters": [n for ((t, n), (l, a)) in xrefs.items() if t == "templatefilter" and l == "ref/templates/builtins"], } outfilename = os.path.join(self.outdir, "templatebuiltins.js") with open(outfilename, 'w') as fp: fp.write('var django_template_builtins = ') json.dump(templatebuiltins, fp) fp.write(';\n')
from docutils import nodes, utils from docutils.parsers.rst import roles def ticket_role(name, rawtext, text, lineno, inliner, options=None, content=None): if options is None: options = {} try: num = int(text.replace('#', '')) except ValueError: msg = inliner.reporter.error( "ticket number must be... a number, got '%s'" % text) prb = inliner.problematic(rawtext, rawtext, msg) return [prb], [msg] url_pattern = inliner.document.settings.env.app.config.ticket_url if url_pattern is None: msg = inliner.reporter.warning( "ticket not configured: please configure ticket_url in conf.py") prb = inliner.problematic(rawtext, rawtext, msg) return [prb], [msg] url = url_pattern % num roles.set_classes(options) node = nodes.reference(rawtext, '#' + utils.unescape(text), refuri=url, **options) return [node], [] def setup(app): app.add_config_value('ticket_url', None, 'env') app.add_role('ticket', ticket_role) return {'parallel_read_safe': True}
def __init__(self, convert_charrefs=False, **kwargs): _html_parser.HTMLParser.__init__(self, convert_charrefs=convert_charrefs, **kwargs)
def __init__(self): self.mutex = threading.RLock() self.can_read = threading.Semaphore(0) self.can_write = threading.Semaphore(0) self.active_readers = 0 self.active_writers = 0 self.waiting_readers = 0 self.waiting_writers = 0 def reader_enters(self): with self.mutex: if self.active_writers == 0 and self.waiting_writers == 0: self.active_readers += 1 self.can_read.release() else: self.waiting_readers += 1 self.can_read.acquire() def reader_leaves(self): with self.mutex: self.active_readers -= 1 if self.active_readers == 0 and self.waiting_writers != 0: self.active_writers += 1 self.waiting_writers -= 1 self.can_write.release() @contextlib.contextmanager def reader(self): self.reader_enters() try: yield finally: self.reader_leaves() def writer_enters(self): with self.mutex: if self.active_writers == 0 and self.waiting_writers == 0 and self.active_readers == 0: self.active_writers += 1 self.can_write.release() else: self.waiting_writers += 1 self.can_write.acquire() def writer_leaves(self): with self.mutex: self.active_writers -= 1 if self.waiting_writers != 0: self.active_writers += 1 self.waiting_writers -= 1 self.can_write.release() elif self.waiting_readers != 0: t = self.waiting_readers self.waiting_readers = 0 self.active_readers += t while t > 0: self.can_read.release() t -= 1 @contextlib.contextmanager def writer(self): self.writer_enters() try: yield finally: self.writer_leaves()
match = date_re.match(value) if match: kw = {k: int(v) for k, v in six.iteritems(match.groupdict())} return datetime.date(**kw)
match = time_re.match(value) if match: kw = match.groupdict() if kw['microsecond']: kw['microsecond'] = kw['microsecond'].ljust(6, '0') kw = {k: int(v) for k, v in six.iteritems(kw) if v is not None} return datetime.time(**kw)
match = datetime_re.match(value) if match: kw = match.groupdict() if kw['microsecond']: kw['microsecond'] = kw['microsecond'].ljust(6, '0') tzinfo = kw.pop('tzinfo') if tzinfo == 'Z': tzinfo = utc elif tzinfo is not None: offset_mins = int(tzinfo[-2:]) if len(tzinfo) > 3 else 0 offset = 60 * int(tzinfo[1:3]) + offset_mins if tzinfo[0] == '-': offset = -offset tzinfo = get_fixed_timezone(offset) kw = {k: int(v) for k, v in six.iteritems(kw) if v is not None} kw['tzinfo'] = tzinfo return datetime.datetime(**kw)
def is_iterable(x): "A implementation independent way of checking for iterables" try: iter(x) except TypeError: return False else: return True
if not response.has_header('Cache-Control'): return cc = dict(_to_tuple(el) for el in cc_delim_re.split(response['Cache-Control'])) if 'max-age' in cc: try: return int(cc['max-age']) except (ValueError, TypeError): pass
patch_response_headers(response, cache_timeout=-1) patch_cache_control(response, no_cache=True, no_store=True, must_revalidate=True)
if not response.has_header('Vary'): return False vary_headers = cc_delim_re.split(response['Vary']) existing_headers = set(header.lower() for header in vary_headers) return header_query.lower() in existing_headers
ctx = hashlib.md5() for header in headerlist: value = request.META.get(header) if value is not None: ctx.update(force_bytes(value)) url = hashlib.md5(force_bytes(iri_to_uri(request.build_absolute_uri()))) cache_key = 'views.decorators.cache.cache_page.%s.%s.%s.%s' % ( key_prefix, method, url.hexdigest(), ctx.hexdigest()) return _i18n_cache_key_suffix(request, cache_key)
url = hashlib.md5(force_bytes(iri_to_uri(request.build_absolute_uri()))) cache_key = 'views.decorators.cache.cache_header.%s.%s' % ( key_prefix, url.hexdigest()) return _i18n_cache_key_suffix(request, cache_key)
if key_prefix is None: key_prefix = settings.CACHE_MIDDLEWARE_KEY_PREFIX cache_key = _generate_cache_header_key(key_prefix, request) if cache is None: cache = caches[settings.CACHE_MIDDLEWARE_ALIAS] headerlist = cache.get(cache_key) if headerlist is not None: return _generate_cache_key(request, method, headerlist, key_prefix) else: return None
return subject.replace('\n', '\\n').replace('\r', '\\r')
def __init__(self, callback): self.callback = callback def filter(self, record): if self.callback(record): return 1 return 0
return mark_safe( force_text(text).replace('&', '&amp;').replace('<', '&lt;') .replace('>', '&gt;').replace('"', '&quot;').replace("'", '&#39;') )
return mark_safe(force_text(value).translate(_js_escapes))
if hasattr(text, '__html__'): return text.__html__() else: return escape(text)
args_safe = map(conditional_escape, args) kwargs_safe = {k: conditional_escape(v) for (k, v) in six.iteritems(kwargs)} return mark_safe(format_string.format(*args_safe, **kwargs_safe))
return mark_safe(conditional_escape(sep).join( format_html(format_string, *tuple(args)) for args in args_generator))
value = normalize_newlines(force_text(value)) paras = re.split('\n{2,}', value) if autoescape: paras = ['<p>%s</p>' % escape(p).replace('\n', '<br />') for p in paras] else: paras = ['<p>%s</p>' % p.replace('\n', '<br />') for p in paras] return '\n\n'.join(paras)
s = MLStripper() try: s.feed(value) except HTMLParseError: return value try: s.close() except HTMLParseError: return s.get_data() + s.rawdata else: return s.get_data()
return re.sub(r'>\s+<', '><', force_text(value))
return value.replace(" ", "\xa0")
if version is None: from django import VERSION as version else: assert len(version) == 5 assert version[3] in ('alpha', 'beta', 'rc', 'final') return version
if not isabs(path): path = join(os.getcwdu(), path) return normpath(path)
if six.PY2 and not isinstance(path, six.text_type): return path.decode(fs_encoding) return path
if six.PY2 and not isinstance(path, bytes): return path.encode(fs_encoding) return path
for ch in input_iter: if ch != '\\': yield ch, False continue ch = next(input_iter) representative = ESCAPE_MAPPINGS.get(ch, ch) if representative is None: continue yield representative, True
if ch == '(': nesting = 1 else: nesting = 0 for ch, escaped in input_iter: if escaped: continue elif ch == '(': nesting += 1 elif ch == ')': if not nesting: return nesting -= 1
if isinstance(source, inst): return True if isinstance(source, NonCapture): for elt in source: if contains(elt, inst): return True return False
if six.PY2: return inspect.getargspec(func)[1] is not None return any( p for p in inspect.signature(func).parameters.values() if p.kind == p.VAR_POSITIONAL )
return isinstance(obj, _PROTECTED_TYPES)
if uri is None: return uri uri = force_bytes(uri) iri = unquote_to_bytes(uri) if six.PY3 else unquote(uri) return repercent_broken_unicode(iri).decode('utf-8')
try: path.decode('utf-8') except UnicodeDecodeError as e: repercent = quote(path[e.start:e.end], safe=b"/#%[]=:;$&()+,!?*@'~") path = repercent_broken_unicode( path[:e.start] + force_bytes(repercent) + path[e.end:]) return path
try: encoding = locale.getdefaultlocale()[1] or 'ascii' codecs.lookup(encoding) except Exception: encoding = 'ascii' return encoding
try: list_ = super(MultiValueDict, self).__getitem__(key) except KeyError: raise MultiValueDictKeyError(repr(key)) try: return list_[-1] except IndexError: return []
try: val = self[key] except KeyError: return default if val == []: return default return val
try: return super(MultiValueDict, self).__getitem__(key) except KeyError: if default is None: return [] return default
self.setlistdefault(key).append(value)
for key in self: yield key, self[key]
return six.iteritems(super(MultiValueDict, self))
for key in self: yield self[key]
return copy.copy(self)
if len(args) > 1: raise TypeError("update expected at most 1 arguments, got %d" % len(args)) if args: other_dict = args[0] if isinstance(other_dict, MultiValueDict): for key, value_list in other_dict.lists(): self.setlistdefault(key).extend(value_list) else: try: for key, value in other_dict.items(): self.setlistdefault(key).append(value) except TypeError: raise ValueError("MultiValueDict.update() takes either a MultiValueDict or dictionary") for key, value in six.iteritems(kwargs): self.setlistdefault(key).append(value)
return {key: self[key] for key in self}
func.__doc__ = doc
__import__(name) return sys.modules[name]
return hasattr(self.__get_module(fullname), "__path__")
setattr(_MovedItems, move.name, move)
try: delattr(_MovedItems, name) except AttributeError: try: del moves.__dict__[name] except KeyError: raise AttributeError("no such move, %r" % (name,))
def wrapper(cls): orig_vars = cls.__dict__.copy() slots = orig_vars.get('__slots__') if slots is not None: if isinstance(slots, str): slots = [slots] for slots_var in slots: orig_vars.pop(slots_var) orig_vars.pop('__dict__', None) orig_vars.pop('__weakref__', None) return metaclass(cls.__name__, cls.__bases__, orig_vars) return wrapper
bits = urlparse(url) d = '' if date is not None: d = ',%s' % datetime_safe.new_datetime(date).strftime('%Y-%m-%d') return 'tag:%s%s:%s/%s' % (bits.hostname, d, bits.path, bits.fragment)
return {}
pass
return {}
pass
raise NotImplementedError('subclasses of SyndicationFeed must provide a write() method')
s = StringIO() self.write(s, encoding) return s.getvalue()
if self.data.minute == 0: return self.g() return '%s:%s' % (self.g(), self.i())
if not self.timezone: return "" seconds = self.Z() if seconds == "": return "" sign = '-' if seconds < 0 else '+' seconds = abs(seconds) return "%s%02d%02d" % (sign, seconds // 3600, (seconds // 60) % 60)
if self.data.minute == 0 and self.data.hour == 0: return _('midnight') if self.data.minute == 0 and self.data.hour == 12: return _('noon') return '%s %s' % (self.f(), self.a())
return self.data.isoformat()
global _format_cache, _format_modules_cache _format_cache = {} _format_modules_cache = {}
if not check_for_language(lang): return if format_module_path is None: format_module_path = settings.FORMAT_MODULE_PATH format_locations = [] if format_module_path: if isinstance(format_module_path, six.string_types): format_module_path = [format_module_path] for path in format_module_path: format_locations.append(path + '.%s') format_locations.append('django.conf.locale.%s') locale = to_locale(lang) locales = [locale] if '_' in locale: locales.append(locale.split('_')[0]) for location in format_locations: for loc in locales: try: yield import_module('%s.formats' % (location % loc)) except ImportError: pass
if lang is None: lang = get_language() if lang not in _format_modules_cache: _format_modules_cache[lang] = list(iter_format_modules(lang, settings.FORMAT_MODULE_PATH)) modules = _format_modules_cache[lang] if reverse: return list(reversed(modules)) return modules
return dateformat.format(value, get_format(format or 'DATE_FORMAT', use_l10n=use_l10n))
return dateformat.time_format(value, get_format(format or 'TIME_FORMAT', use_l10n=use_l10n))
if use_l10n or (use_l10n is None and settings.USE_L10N): lang = get_language() else: lang = None return numberformat.format( value, get_format('DECIMAL_SEPARATOR', lang, use_l10n=use_l10n), decimal_pos, get_format('NUMBER_GROUPING', lang, use_l10n=use_l10n), get_format('THOUSAND_SEPARATOR', lang, use_l10n=use_l10n), force_grouping=force_grouping )
def duration_string(duration): days = duration.days seconds = duration.seconds microseconds = duration.microseconds minutes = seconds // 60 seconds = seconds % 60 hours = minutes // 60 minutes = minutes % 60 string = '{:02d}:{:02d}:{:02d}'.format(hours, minutes, seconds) if days: string = '{} '.format(days) + string if microseconds: string += '.{:06d}'.format(microseconds) return string
def __repr__(self): return "<UTC>" def utcoffset(self, dt): return ZERO def tzname(self, dt): return "UTC" def dst(self, dt): return ZERO
def __init__(self, offset=None, name=None): if offset is not None: self.__offset = timedelta(minutes=offset) if name is not None: self.__name = name def utcoffset(self, dt): return self.__offset def tzname(self, dt): return self.__name def dst(self, dt): return ZERO
def __init__(self): self.STDOFFSET = timedelta(seconds=-_time.timezone) if _time.daylight: self.DSTOFFSET = timedelta(seconds=-_time.altzone) else: self.DSTOFFSET = self.STDOFFSET self.DSTDIFF = self.DSTOFFSET - self.STDOFFSET tzinfo.__init__(self) def utcoffset(self, dt): if self._isdst(dt): return self.DSTOFFSET else: return self.STDOFFSET def dst(self, dt): if self._isdst(dt): return self.DSTDIFF else: return ZERO def tzname(self, dt): return _time.tzname[self._isdst(dt)] def _isdst(self, dt): tt = (dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second, dt.weekday(), 0, 0) stamp = _time.mktime(tt) tt = _time.localtime(stamp) return tt.tm_isdst > 0
def tzname(self, dt): is_dst = False if dt is None else self._isdst(dt) return _time.tzname[is_dst] def _isdst(self, dt): try: return super(LocalTimezone, self)._isdst(dt) except (OverflowError, ValueError) as exc: exc_type = type(exc) exc_value = exc_type( "Unsupported value: %r. You should install pytz." % dt) exc_value.__cause__ = exc if not hasattr(exc, '__traceback__'): exc.__traceback__ = sys.exc_info()[2] six.reraise(exc_type, exc_value, sys.exc_info()[2])
return _get_timezone_name(get_default_timezone())
return getattr(_active, "value", get_default_timezone())
return _get_timezone_name(get_current_timezone())
if isinstance(timezone, tzinfo): _active.value = timezone elif isinstance(timezone, six.string_types) and pytz is not None: _active.value = pytz.timezone(timezone) else: raise ValueError("Invalid timezone: %r" % timezone)
if hasattr(_active, "value"): del _active.value
return value.utcoffset() is not None
return value.utcoffset() is None
return ' '.join(sentence() for i in range(random.randint(1, 4)))
paras = [] for i in range(count): if common and i == 0: paras.append(COMMON_P) else: paras.append(paragraph()) return paras
obj = Node(children, connector, negated) obj.__class__ = cls return obj
obj = Node(connector=self.connector, negated=self.negated) obj.__class__ = self.__class__ obj.children = copy.deepcopy(self.children, memodict) return obj
return len(self.children)
return other in self.children
try: module_path, class_name = dotted_path.rsplit('.', 1) except ValueError: msg = "%s doesn't look like a module path" % dotted_path six.reraise(ImportError, ImportError(msg), sys.exc_info()[2]) module = import_module(module_path) try: return getattr(module, class_name) except AttributeError: msg = 'Module "%s" does not define a "%s" attribute/class' % ( module_path, class_name) six.reraise(ImportError, ImportError(msg), sys.exc_info()[2])
self._setup() length = int(num) if html: return self._truncate_html(length, truncate, self._wrapped, length, True) return self._text_words(length, truncate)
words = self._wrapped.split() if len(words) > length: words = words[:length] return self.add_truncation_text(' '.join(words), truncate) return ' '.join(words)
s = force_text(s).strip().replace(' ', '_') return re.sub(r'(?u)[^-\w.]', '', s)
text = force_text(text) return re_newlines.sub('\n', text)
text = force_text(text) for bit in smart_split_re.finditer(text): yield bit.group(0)
if s[0] not in "\"'" or s[-1] != s[0]: raise ValueError("Not a string literal: %r" % s) quote = s[0] return s[1:-1].replace(r'\%s' % quote, quote).replace(r'\\', '\\')
value = force_text(value) if allow_unicode: value = unicodedata.normalize('NFKC', value) value = re.sub('[^\w\s-]', '', value, flags=re.U).strip().lower() return mark_safe(re.sub('[-\s]+', '-', value, flags=re.U)) value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii') value = re.sub('[^\w\s-]', '', value).strip().lower() return mark_safe(re.sub('[-\s]+', '-', value))
with Archive(path) as archive: archive.extract(to_path)
def __init__(self, file): self._archive = self._archive_cls(file)(file) @staticmethod def _archive_cls(file): cls = None if isinstance(file, six.string_types): filename = file else: try: filename = file.name except AttributeError: raise UnrecognizedArchiveFormat( "File object not a recognized archive format.") base, tail_ext = os.path.splitext(filename.lower()) cls = extension_map.get(tail_ext) if not cls: base, ext = os.path.splitext(base) cls = extension_map.get(ext) if not cls: raise UnrecognizedArchiveFormat( "Path not a recognized archive format: %s" % filename) return cls def __enter__(self): return self def __exit__(self, exc_type, exc_value, traceback): self.close() def extract(self, to_path=''): self._archive.extract(to_path) def list(self): self._archive.list() def close(self): self._archive.close()
common_prefix = None for path in paths: prefix, rest = self.split_leading_dir(path) if not prefix: return False elif common_prefix is None: common_prefix = prefix elif prefix != common_prefix: return False return True
if not ip_str.lower().startswith('0000:0000:0000:0000:0000:ffff:'): return None return ip_str.rsplit(':', 1)[1]
code_list = [] if text == '' and len(opts) == 1 and opts[0] == 'reset': return '\x1b[%sm' % RESET for k, v in six.iteritems(kwargs): if k == 'fg': code_list.append(foreground[v]) elif k == 'bg': code_list.append(background[v]) for o in opts: if o in opt_dict: code_list.append(opt_dict[o]) if 'noreset' not in opts: text = '%s\x1b[%sm' % (text or '', RESET) return '%s%s' % (('\x1b[%sm' % ';'.join(code_list)), text or '')
return lambda text: colorize(text, opts, **kwargs)
if hasattr(decorator, '__iter__'): for dec in decorator[::-1]: function = dec(function) return function return decorator(function)
def __call__(self, func): @wraps(func, assigned=available_attrs(func)) def inner(*args, **kwargs): with self: return func(*args, **kwargs) return inner
return force_text(quote(force_str(url), force_str(safe)))
return force_text(quote_plus(force_str(url), force_str(safe)))
return force_text(unquote(force_str(quoted_url)))
return force_text(unquote_plus(force_str(quoted_url)))
if isinstance(query, MultiValueDict): query = query.lists() elif hasattr(query, 'items'): query = query.items() return original_urlencode( [(force_str(k), [force_str(i) for i in v] if isinstance(v, (list, tuple)) else force_str(v)) for k, v in query], doseq)
rfcdate = formatdate(epoch_seconds) return '%s-%s-%s GMT' % (rfcdate[:7], rfcdate[8:11], rfcdate[12:25])
return formatdate(epoch_seconds, usegmt=True)
char_set = '0123456789abcdefghijklmnopqrstuvwxyz' if i < 0: raise ValueError("Negative base36 conversion input.") if six.PY2: if not isinstance(i, six.integer_types): raise TypeError("Non-integer base36 conversion input.") if i > sys.maxint: raise ValueError("Base36 conversion input too large.") if i < 36: return char_set[i] b36 = '' while i != 0: i, n = divmod(i, 36) b36 = char_set[n] + b36 return b36
return base64.urlsafe_b64encode(s).rstrip(b'\n=')
s = force_bytes(s) try: return base64.urlsafe_b64decode(s.ljust(len(s) + len(s) % 4, b'=')) except (LookupError, BinasciiError) as e: raise ValueError(e)
return '"%s"' % etag.replace('\\', '\\\\').replace('"', '\\"')
return etag.strip('"').replace('\\"', '"').replace('\\\\', '\\') if etag else etag
if not pattern: return False pattern = pattern.lower() return ( pattern[0] == '.' and (host.endswith(pattern) or host == pattern[1:]) or pattern == host )
def __getattr__(self, real_name): from django.conf import settings if settings.USE_I18N: from django.utils.translation import trans_real as trans else: from django.utils.translation import trans_null as trans setattr(self, real_name, getattr(trans, real_name)) return getattr(trans, real_name)
return ''.join(force_text(s) for s in strings)
if kwargs['setting'] in ('LANGUAGES', 'LANGUAGE_CODE'): check_for_language.cache_clear() get_languages.cache_clear() get_supported_language_variant.cache_clear()
p = locale.find('_') if p >= 0: return locale[:p].lower() + '-' + locale[p + 1:].lower() else: return locale.lower()
return gettext_module.translation( domain=self.domain, localedir=localedir, languages=[self.__locale], codeset='utf-8', fallback=use_null_fallback)
settingsfile = upath(sys.modules[settings.__module__].__file__) localedir = os.path.join(os.path.dirname(settingsfile), 'locale') translation = self._new_gnu_trans(localedir) self.merge(translation)
try: app_configs = reversed(list(apps.get_app_configs())) except AppRegistryNotReady: raise AppRegistryNotReady( "The translation infrastructure cannot be initialized before the " "apps registry is ready. Check that you don't make non-lazy " "gettext calls at import time.") for app_config in app_configs: localedir = os.path.join(app_config.path, 'locale') translation = self._new_gnu_trans(localedir) self.merge(translation)
for localedir in reversed(settings.LOCALE_PATHS): translation = self._new_gnu_trans(localedir) self.merge(translation)
return self.__language
return self.__to_language
global _translations if language not in _translations: _translations[language] = DjangoTranslation(language) return _translations[language]
if not language: return _active.value = translation(language)
if hasattr(_active, "value"): del _active.value
_active.value = gettext_module.NullTranslations() _active.value.to_language = lambda *args: None
lang = get_language() if lang is None: return False else: base_lang = get_language().split('-')[0] return base_lang in settings.LANGUAGES_BIDI
global _default t = getattr(_active, "value", None) if t is not None: return t if _default is None: _default = translation(settings.LANGUAGE_CODE) return _default
return do_translate(message, 'gettext')
return message
return do_ntranslate(singular, plural, number, 'ngettext')
return do_ntranslate(singular, plural, number, 'ungettext')
globalpath = os.path.join( os.path.dirname(upath(sys.modules[settings.__module__].__file__)), 'locale') return [globalpath] + list(settings.LOCALE_PATHS)
return OrderedDict(settings.LANGUAGES)
regex_match = language_code_prefix_re.match(path) if not regex_match: return None lang_code = regex_match.group(1) try: return get_supported_language_variant(lang_code, strict=strict) except LookupError: return None
if check_path: lang_code = get_language_from_path(request.path_info) if lang_code is not None: return lang_code supported_lang_codes = get_languages() if hasattr(request, 'session'): lang_code = request.session.get(LANGUAGE_SESSION_KEY) if lang_code in supported_lang_codes and lang_code is not None and check_for_language(lang_code): return lang_code lang_code = request.COOKIES.get(settings.LANGUAGE_COOKIE_NAME) try: return get_supported_language_variant(lang_code) except LookupError: pass accept = request.META.get('HTTP_ACCEPT_LANGUAGE', '') for accept_lang, unused in parse_accept_lang_header(accept): if accept_lang == '*': break if not language_code_re.search(accept_lang): continue try: return get_supported_language_variant(accept_lang) except LookupError: continue try: return get_supported_language_variant(settings.LANGUAGE_CODE) except LookupError: return settings.LANGUAGE_CODE
def __init__(self, func, name=None): self.func = func self.__doc__ = getattr(func, '__doc__') self.name = name or func.__name__ def __get__(self, instance, cls=None): if instance is None: return self res = instance.__dict__[self.name] = self.func(instance) return res
pass
if not resultclasses: raise TypeError("You must pass at least one argument to keep_lazy().") def decorator(func): lazy_func = lazy(func, *resultclasses) @wraps(func) def wrapper(*args, **kwargs): for arg in list(args) + list(six.itervalues(kwargs)): if isinstance(arg, Promise): break else: return func(*args, **kwargs) return lazy_func(*args, **kwargs) return wrapper return decorator
return keep_lazy(six.text_type)(func)
return wrapped
self.__dict__['_setupfunc'] = func super(SimpleLazyObject, self).__init__()
def __new__(cls, fget=None, fset=None, fdel=None, doc=None): if fget is not None: @wraps(fget) def fget(instance, instance_type=None, name=fget.__name__): return getattr(instance, name)() if fset is not None: @wraps(fset) def fset(instance, value, name=fset.__name__): return getattr(instance, name)(value) if fdel is not None: @wraps(fdel) def fdel(instance, name=fdel.__name__): return getattr(instance, name)() return property(fget, fset, fdel, doc)
if len(val1) != len(val2): return False result = 0 if six.PY3 and isinstance(val1, bytes) and isinstance(val2, bytes): for x, y in zip(val1, val2): result |= x ^ y else: for x, y in zip(val1, val2): result |= ord(x) ^ ord(y) return result == 0
return int(binascii.hexlify(x), 16)
return binascii.unhexlify((hex_format_string % x).encode('ascii'))
if digest is None: digest = hashlib.sha256 if not dklen: dklen = None password = force_bytes(password) salt = force_bytes(salt) return hashlib.pbkdf2_hmac( digest().name, password, salt, iterations, dklen)
assert iterations > 0 if not digest: digest = hashlib.sha256 password = force_bytes(password) salt = force_bytes(salt) hlen = digest().digest_size if not dklen: dklen = hlen if dklen > (2 ** 32 - 1) * hlen: raise OverflowError('dklen too big') l = -(-dklen // hlen) r = dklen - (l - 1) * hlen hex_format_string = "%%0%ix" % (hlen * 2) inner, outer = digest(), digest() if len(password) > inner.block_size: password = digest(password).digest() password += b'\x00' * (inner.block_size - len(password)) inner.update(password.translate(hmac.trans_36)) outer.update(password.translate(hmac.trans_5C)) def F(i): u = salt + struct.pack(b'>I', i) result = 0 for j in range(int(iterations)): dig1, dig2 = inner.copy(), outer.copy() dig1.update(u) dig2.update(dig1.digest()) u = dig2.digest() result ^= _bin_to_long(u) return _long_to_bin(result, hex_format_string) T = [F(x) for x in range(1, l)] return b''.join(T) + F(l)[:r]
num = 0 def __init__(self, name, regex, next=None): self.id = Tok.num Tok.num += 1 self.name = name self.regex = regex self.next = next
return "|".join(prefix + re.escape(c) + suffix for c in choices.split())
end = len(text) state = self.state regexes = self.regexes toks = self.toks start = 0 while start < end: for match in regexes[state].finditer(text, start): name = match.lastgroup tok = toks[name] toktext = match.group(name) start += len(toktext) yield (tok.name, toktext) if tok.next: state = tok.next break self.state = state
with lock: return _CacheInfo(stats[HITS], stats[MISSES], maxsize, len(cache))
pass
pass
return self
t = super(SafeBytes, self).__add__(rhs) if isinstance(rhs, SafeText): return SafeText(t) elif isinstance(rhs, SafeBytes): return SafeBytes(t) return t
method = kwargs.pop('method') data = method(self, *args, **kwargs) if isinstance(data, bytes): return SafeBytes(data) else: return SafeText(data)
t = super(SafeText, self).__add__(rhs) if isinstance(rhs, SafeData): return SafeText(t) return t
method = kwargs.pop('method') data = method(self, *args, **kwargs) if isinstance(data, bytes): return SafeBytes(data) else: return SafeText(data)
if hasattr(s, '__html__'): return s if isinstance(s, bytes) or (isinstance(s, Promise) and s._delegate_bytes): return SafeBytes(s) if isinstance(s, (six.text_type, Promise)): return SafeText(s) return SafeString(str(s))
language_code = get_language() if language_code not in self._regex_dict: regex = self._regex if isinstance(self._regex, six.string_types) else force_text(self._regex) try: compiled_regex = re.compile(regex, re.UNICODE) except re.error as e: raise ImproperlyConfigured( '"%s" is not a valid regular expression: %s' % (regex, six.text_type(e)) ) self._regex_dict[language_code] = compiled_regex return self._regex_dict[language_code]
def __init__( self, urlconf_name, default_kwargs=None, app_name=None, namespace=None, prefix_default_language=True, ): super(LocaleRegexURLResolver, self).__init__( None, urlconf_name, default_kwargs, app_name, namespace, ) self.prefix_default_language = prefix_default_language @property def regex(self): language_code = get_language() or settings.LANGUAGE_CODE if language_code not in self._regex_dict: if language_code == settings.LANGUAGE_CODE and not self.prefix_default_language: regex_string = '' else: regex_string = '^%s/' % language_code self._regex_dict[language_code] = re.compile(regex_string, re.UNICODE) return self._regex_dict[language_code]
if not prefix.endswith('/'): prefix += '/' _prefixes.value = prefix
return getattr(_prefixes, "value", '/')
try: del _prefixes.value except AttributeError: pass
if urlconf_name: _urlconfs.value = urlconf_name else: if hasattr(_urlconfs, "value"): del _urlconfs.value
return getattr(_urlconfs, "value", default)
try: resolve(path, urlconf) return True except Resolver404: return False
content = loader.render_to_string(template_name, context, using=using) return HttpResponse(content, content_type, status)
content = loader.render_to_string(template_name, context, request, using=using) return HttpResponse(content, content_type, status)
if kwargs.pop('permanent', False): redirect_class = HttpResponsePermanentRedirect else: redirect_class = HttpResponseRedirect return redirect_class(resolve_url(to, *args, **kwargs))
queryset = _get_queryset(klass) try: return queryset.get(*args, **kwargs) except AttributeError: klass__name = klass.__name__ if isinstance(klass, type) else klass.__class__.__name__ raise ValueError( "First argument to get_object_or_404() must be a Model, Manager, " "or QuerySet, not '%s'." % klass__name ) except queryset.model.DoesNotExist: raise Http404('No %s matches the given query.' % queryset.model._meta.object_name)
queryset = _get_queryset(klass) try: obj_list = list(queryset.filter(*args, **kwargs)) except AttributeError: klass__name = klass.__name__ if isinstance(klass, type) else klass.__class__.__name__ raise ValueError( "First argument to get_list_or_404() must be a Model, Manager, or " "QuerySet, not '%s'." % klass__name ) if not obj_list: raise Http404('No %s matches the given query.' % queryset.model._meta.object_name) return obj_list
pass
return filename and filename[filename.rfind("\\") + 1:].strip()
self._producer = producer self._empty = False self._leftover = b'' self.length = length self.position = 0 self._remaining = length self._unget_history = []
if self._leftover: output = self._leftover self._leftover = b'' else: output = next(self._producer) self._unget_history = [] self.position += len(output) return output
self._producer = []
if not bytes: return self._update_unget_history(len(bytes)) self.position -= len(bytes) self._leftover = b''.join([bytes, self._leftover])
self._unget_history = [num_bytes] + self._unget_history[:49] number_equal = len([current_number for current_number in self._unget_history if current_number == num_bytes]) if number_equal > 40: raise SuspiciousMultipartForm( "The multipart parser got stuck, which shouldn't happen with" " normal uploaded files. Check for malicious upload activity;" " if there is none, report this to the Django developers." )
def __init__(self, flo, chunk_size=64 * 1024): self.flo = flo self.chunk_size = chunk_size def __next__(self): try: data = self.flo.read(self.chunk_size) except InputStreamExhausted: raise StopIteration() if data: return data else: raise StopIteration() def __iter__(self): return self
def __init__(self, stream, boundary): self._stream = stream self._boundary = boundary def __iter__(self): return self def __next__(self): try: return LazyStream(BoundaryIter(self._stream, self._boundary)) except InputStreamExhausted: raise StopIteration()
iterator = None try: iterator = iter(stream_or_iterable) except TypeError: iterator = ChunkIter(stream_or_iterable, 16384) if iterator is None: raise MultiPartParserError('multipartparser.exhaust() was passed a non-iterable or stream parameter') for __ in iterator: pass
def to_bytes(val, encoding): return val if isinstance(val, bytes) else val.encode(encoding) headers = [ (b': '.join([to_bytes(key, 'ascii'), to_bytes(value, 'latin-1')])) for key, value in self._headers.values() ] return b'\r\n'.join(headers)
return header.lower() in self._headers
if key not in self: self[key] = value
return self.serialize_headers() + b'\r\n\r\n' + self.content
block_size = 4096 def _set_streaming_content(self, value): if hasattr(value, 'read'): self.file_to_stream = value filelike = value if hasattr(filelike, 'close'): self._closable_objects.append(filelike) value = iter(lambda: filelike.read(self.block_size), b'') else: self.file_to_stream = None super(FileResponse, self)._set_streaming_content(value)
def __init__(self, data, encoder=DjangoJSONEncoder, safe=True, json_dumps_params=None, **kwargs): if safe and not isinstance(data, dict): raise TypeError( 'In order to allow non-dict objects to be serialized set the ' 'safe parameter to False.' ) if json_dumps_params is None: json_dumps_params = {} kwargs.setdefault('content_type', 'application/json') data = json.dumps(data, cls=encoder, **json_dumps_params) super(JsonResponse, self).__init__(content=data, **kwargs)
pass
if settings.USE_X_FORWARDED_PORT and 'HTTP_X_FORWARDED_PORT' in self.META: port = self.META['HTTP_X_FORWARDED_PORT'] else: port = self.META['SERVER_PORT'] return str(port)
try: cookie_value = self.COOKIES[key] except KeyError: if default is not RAISE_ERROR: return default else: raise try: value = signing.get_cookie_signer(salt=key + salt).unsign( cookie_value, max_age=max_age) except signing.BadSignature: if default is not RAISE_ERROR: return default else: raise return value
return '{scheme}://{host}{path}'.format( scheme=self.scheme, host=self._get_raw_host(), path=self.get_full_path(), )
return 'http'
self._encoding = val if hasattr(self, '_get'): del self._get if hasattr(self, '_post'): del self._post
self.upload_handlers = ImmutableList( self.upload_handlers, warning="You cannot alter upload handlers after the upload has been processed." ) parser = MultiPartParser(META, post_data, self.upload_handlers, self.encoding) return parser.parse()
return self.__deepcopy__({})
if isinstance(s, bytes): return six.text_type(s, encoding, 'replace') else: return s
self.selenium.implicitly_wait(0) try: yield finally: self.selenium.implicitly_wait(self.implicit_wait)
resultclass = RemoteTestResult def __init__(self, failfast=False, resultclass=None): self.failfast = failfast if resultclass is not None: self.resultclass = resultclass def run(self, test): result = self.resultclass() unittest.registerResult(result) result.failfast = self.failfast test(result) return result
subsuite_index, subsuite, failfast = args runner = RemoteTestRunner(failfast=failfast) result = runner.run(subsuite) return subsuite_index, result.events
if tblib is not None: tblib.pickling_support.install() counter = multiprocessing.Value(ctypes.c_int, 0) pool = multiprocessing.Pool( processes=self.processes, initializer=self.init_worker.__func__, initargs=[counter]) args = [ (index, subsuite, self.failfast) for index, subsuite in enumerate(self.subsuites) ] test_results = pool.imap_unordered(self.run_subsuite.__func__, args) while True: if result.shouldStop: pool.terminate() break try: subsuite_index, events = test_results.next(timeout=0.1) except multiprocessing.TimeoutError: continue except StopIteration: pool.close() break tests = list(self.subsuites[subsuite_index]) for event in events: event_name = event[0] handler = getattr(result, event_name, None) if handler is None: continue test = tests[event[1]] args = event[2:] handler(test, *args) pool.join() return result
for connection, old_name, destroy in old_config: if destroy: if self.parallel > 1: for index in range(self.parallel): connection.creation.destroy_test_db( number=index + 1, verbosity=self.verbosity, keepdb=self.keepdb, ) connection.creation.destroy_test_db(old_name, self.verbosity, self.keepdb)
self.setup_test_environment() suite = self.build_suite(test_labels, extra_tests) old_config = self.setup_databases() result = self.run_suite(suite) self.teardown_databases(old_config) self.teardown_test_environment() return self.suite_result(suite, result)
try: mod = import_module(label) except (ImportError, TypeError): pass else: return hasattr(mod, '__path__') return os.path.isdir(os.path.abspath(label))
class_count = len(classes) suite_class = type(suite) bins = [OrderedSet() for i in range(class_count + 1)] partition_suite_by_type(suite, classes, bins, reverse=reverse) reordered_suite = suite_class() for i in range(class_count + 1): reordered_suite.addTests(bins[i]) return reordered_suite
suite_class = type(suite) if reverse: suite = reversed(tuple(suite)) for test in suite: if isinstance(test, suite_class): partition_suite_by_type(test, classes, bins, reverse=reverse) else: for i in range(len(classes)): if isinstance(test, classes[i]): bins[i].add(test) break else: bins[-1].add(test)
groups = [] suite_class = type(suite) for test_type, test_group in itertools.groupby(suite, type): if issubclass(test_type, unittest.TestCase): groups.append(suite_class(test_group)) else: for item in test_group: groups.extend(partition_suite_by_case(item)) return groups
def __init__(self, message, last_response): super(RedirectCycleError, self).__init__(message) self.last_response = last_response self.redirect_chain = last_response.redirect_chain
def __init__(self, content=None): self.__content = BytesIO() self.__len = 0 self.read_started = False if content is not None: self.write(content) def __len__(self): return self.__len def read(self, num_bytes=None): if not self.read_started: self.__content.seek(0) self.read_started = True if num_bytes is None: num_bytes = self.__len or 0 assert self.__len >= num_bytes, "Cannot read more than the available bytes from the HTTP incoming data." content = self.__content.read(num_bytes) self.__len -= num_bytes return content def write(self, content): if self.read_started: raise ValueError("Unable to write a payload after he's been read") content = force_bytes(content) self.__content.write(content) self.__len += len(content)
if 100 <= response.status_code < 200 or response.status_code in (204, 304): if response.streaming: response.streaming_content = [] else: response.content = b'' response['Content-Length'] = '0' if request.method == 'HEAD': if response.streaming: response.streaming_content = [] else: response.content = b'' return response
store.setdefault('templates', []).append(template) if 'context' not in store: store['context'] = ContextList() store['context'].append(copy(context))
self.exc_info = sys.exc_info()
engine = import_module(settings.SESSION_ENGINE) cookie = self.cookies.get(settings.SESSION_COOKIE_NAME) if cookie: return engine.SessionStore(cookie.value) session = engine.SessionStore() session.save() self.cookies[settings.SESSION_COOKIE_NAME] = session.session_key return session
response = super(Client, self).get(path, data=data, secure=secure, **extra) if follow: response = self._handle_redirects(response, **extra) return response
response = super(Client, self).post(path, data=data, content_type=content_type, secure=secure, **extra) if follow: response = self._handle_redirects(response, **extra) return response
response = super(Client, self).head(path, data=data, secure=secure, **extra) if follow: response = self._handle_redirects(response, **extra) return response
response = super(Client, self).options(path, data=data, content_type=content_type, secure=secure, **extra) if follow: response = self._handle_redirects(response, **extra) return response
response = super(Client, self).put(path, data=data, content_type=content_type, secure=secure, **extra) if follow: response = self._handle_redirects(response, **extra) return response
response = super(Client, self).patch(path, data=data, content_type=content_type, secure=secure, **extra) if follow: response = self._handle_redirects(response, **extra) return response
response = super(Client, self).delete(path, data=data, content_type=content_type, secure=secure, **extra) if follow: response = self._handle_redirects(response, **extra) return response
response = super(Client, self).trace(path, data=data, secure=secure, **extra) if follow: response = self._handle_redirects(response, **extra) return response
from django.contrib.auth import authenticate user = authenticate(**credentials) if user: self._login(user) return True else: return False
from django.contrib.auth import get_user, logout request = HttpRequest() engine = import_module(settings.SESSION_ENGINE) if self.session: request.session = self.session request.user = get_user(request) else: request.session = engine.SessionStore() logout(request) self.cookies = SimpleCookie()
keys = set() for subcontext in self: for dict in subcontext: keys |= set(dict.keys()) return keys
template_rendered.send(sender=self, template=self, context=context) return self.nodelist.render(context)
def __init__(self, attr_name=None, kwarg_name=None): self.attr_name = attr_name self.kwarg_name = kwarg_name def enable(self): raise NotImplementedError def disable(self): raise NotImplementedError def __enter__(self): return self.enable() def __exit__(self, exc_type, exc_value, traceback): self.disable() def decorate_class(self, cls): if issubclass(cls, TestCase): decorated_setUp = cls.setUp decorated_tearDown = cls.tearDown def setUp(inner_self): context = self.enable() if self.attr_name: setattr(inner_self, self.attr_name, context) decorated_setUp(inner_self) def tearDown(inner_self): decorated_tearDown(inner_self) self.disable() cls.setUp = setUp cls.tearDown = tearDown return cls raise TypeError('Can only decorate subclasses of unittest.TestCase') def decorate_callable(self, func): @wraps(func, assigned=available_attrs(func)) def inner(*args, **kwargs): with self as context: if self.kwarg_name: kwargs[self.kwarg_name] = context return func(*args, **kwargs) return inner def __call__(self, decorated): if isinstance(decorated, type): return self.decorate_class(decorated) elif callable(decorated): return self.decorate_callable(decorated) raise TypeError('Cannot decorate object of type %s' % type(decorated))
def __init__(self, new_checks, deployment_checks=None): from django.core.checks.registry import registry self.registry = registry self.new_checks = new_checks self.deployment_checks = deployment_checks super(override_system_checks, self).__init__() def enable(self): self.old_checks = self.registry.registered_checks self.registry.registered_checks = self.new_checks self.old_deployment_checks = self.registry.deployment_checks if self.deployment_checks is not None: self.registry.deployment_checks = self.deployment_checks def disable(self): self.registry.registered_checks = self.old_checks self.registry.deployment_checks = self.old_deployment_checks
def is_quoted_string(s): s = s.strip() return len(s) >= 2 and s[0] == s[-1] and s[0] in ('"', "'") def is_quoted_unicode(s): s = s.strip() return len(s) >= 3 and s[0] == 'u' and s[1] == s[-1] and s[1] in ('"', "'") if is_quoted_string(want) and is_quoted_string(got): want = want.strip()[1:-1] got = got.strip()[1:-1] elif is_quoted_unicode(want) and is_quoted_unicode(got): want = want.strip()[2:-1] got = got.strip()[2:-1] return want, got
def __init__(self, connection): self.connection = connection def __iter__(self): return iter(self.captured_queries) def __getitem__(self, index): return self.captured_queries[index] def __len__(self): return len(self.captured_queries) @property def captured_queries(self): return self.connection.queries[self.initial_queries:self.final_queries] def __enter__(self): self.force_debug_cursor = self.connection.force_debug_cursor self.connection.force_debug_cursor = True self.initial_queries = len(self.connection.queries_log) self.final_queries = None request_started.disconnect(reset_queries) return self def __exit__(self, exc_type, exc_value, traceback): self.connection.force_debug_cursor = self.force_debug_cursor request_started.connect(reset_queries) if exc_type is not None: return self.final_queries = len(self.connection.queries_log)
_orig_sys_path = sys.path[:] sys.path.extend(paths) try: yield finally: sys.path = _orig_sys_path
lru_cache_object.cache_clear() try: yield finally: lru_cache_object.cache_clear()
if value is None: value = [] elif not isinstance(value, list): value = [value] return value
testMethod = getattr(self, self._testMethodName) skipped = ( getattr(self.__class__, "__unittest_skip__", False) or getattr(testMethod, "__unittest_skip__", False) ) if not skipped: try: self._pre_setup() except Exception: result.addError(self, sys.exc_info()) return super(SimpleTestCase, self).__call__(result) if not skipped: try: self._post_teardown() except Exception: result.addError(self, sys.exc_info()) return
self.client = self.client_class() mail.outbox = []
pass
return override_settings(**kwargs)
return modify_settings(**kwargs)
text_repr, real_count, msg_prefix = self._assert_contains( response, text, status_code, msg_prefix, html) if count is not None: self.assertEqual( real_count, count, msg_prefix + "Found %d instances of %s in response (expected %d)" % (real_count, text_repr, count) ) else: self.assertTrue(real_count != 0, msg_prefix + "Couldn't find %s in response" % text_repr)
text_repr, real_count, msg_prefix = self._assert_contains( response, text, status_code, msg_prefix, html) self.assertEqual(real_count, 0, msg_prefix + "Response should not contain %s" % text_repr)
dom1 = assert_and_parse_html(self, html1, msg, 'First argument is not valid HTML:') dom2 = assert_and_parse_html(self, html2, msg, 'Second argument is not valid HTML:') if dom1 != dom2: standardMsg = '%s != %s' % ( safe_repr(dom1, True), safe_repr(dom2, True)) diff = ('\n' + '\n'.join(difflib.ndiff( six.text_type(dom1).splitlines(), six.text_type(dom2).splitlines(), ))) standardMsg = self._truncateMessage(standardMsg, diff) self.fail(self._formatMessage(msg, standardMsg))
dom1 = assert_and_parse_html(self, html1, msg, 'First argument is not valid HTML:') dom2 = assert_and_parse_html(self, html2, msg, 'Second argument is not valid HTML:') if dom1 == dom2: standardMsg = '%s == %s' % ( safe_repr(dom1, True), safe_repr(dom2, True)) self.fail(self._formatMessage(msg, standardMsg))
try: data = json.loads(raw) except ValueError: self.fail("First argument is not valid JSON: %r" % raw) if isinstance(expected_data, six.string_types): try: expected_data = json.loads(expected_data) except ValueError: self.fail("Second argument is not valid JSON: %r" % expected_data) self.assertEqual(data, expected_data, msg=msg)
try: data = json.loads(raw) except ValueError: self.fail("First argument is not valid JSON: %r" % raw) if isinstance(expected_data, six.string_types): try: expected_data = json.loads(expected_data) except ValueError: self.fail("Second argument is not valid JSON: %r" % expected_data) self.assertNotEqual(data, expected_data, msg=msg)
try: result = compare_xml(xml1, xml2) except Exception as e: standardMsg = 'First or second argument is not valid XML\n%s' % e self.fail(self._formatMessage(msg, standardMsg)) else: if not result: standardMsg = '%s != %s' % (safe_repr(xml1, True), safe_repr(xml2, True)) diff = ('\n' + '\n'.join( difflib.ndiff( six.text_type(xml1).splitlines(), six.text_type(xml2).splitlines(), ) )) standardMsg = self._truncateMessage(standardMsg, diff) self.fail(self._formatMessage(msg, standardMsg))
try: result = compare_xml(xml1, xml2) except Exception as e: standardMsg = 'First or second argument is not valid XML\n%s' % e self.fail(self._formatMessage(msg, standardMsg)) else: if result: standardMsg = '%s == %s' % (safe_repr(xml1, True), safe_repr(xml2, True)) self.fail(self._formatMessage(msg, standardMsg))
super(TransactionTestCase, self)._pre_setup() if self.available_apps is not None: apps.set_available_apps(self.available_apps) setting_changed.send( sender=settings._wrapped.__class__, setting='INSTALLED_APPS', value=self.available_apps, enter=True, ) for db_name in self._databases_names(include_mirrors=False): emit_post_migrate_signal(verbosity=0, interactive=False, db=db_name) try: self._fixture_setup() except Exception: if self.available_apps is not None: apps.unset_available_apps() setting_changed.send( sender=settings._wrapped.__class__, setting='INSTALLED_APPS', value=settings.INSTALLED_APPS, enter=False, ) raise
return all(conn.features.supports_transactions for conn in connections.all())
atomics = {} for db_name in cls._databases_names(): atomics[db_name] = transaction.atomic(using=db_name) atomics[db_name].__enter__() return atomics
for db_name in reversed(cls._databases_names()): transaction.set_rollback(True, using=db_name) atomics[db_name].__exit__(None, None, None)
pass
def __init__(self, cond_func): self.cond_func = cond_func def __get__(self, instance, cls=None): return self.cond_func()
return _deferredSkip( lambda: any(getattr(connection.features, feature, False) for feature in features), "Database has feature(s) %s" % ", ".join(features) )
return _deferredSkip( lambda: not all(getattr(connection.features, feature, False) for feature in features), "Database doesn't support feature(s): %s" % ", ".join(features) )
return _deferredSkip( lambda: not any(getattr(connection.features, feature, False) for feature in features), "Database doesn't support any of the feature(s): %s" % ", ".join(features) )
def log_message(*args): pass
return path.startswith(self.base_url[2]) and not self.base_url[1]
relative_url = url[len(self.base_url[2]):] return url2pathname(relative_url)
def get_base_dir(self): return settings.STATIC_ROOT def get_base_url(self): return settings.STATIC_URL
def get_base_dir(self): return settings.MEDIA_ROOT def get_base_url(self): return settings.MEDIA_URL
lockfile = None @classmethod def setUpClass(cls): if cls.lockfile is None: raise ValueError( "{}.lockfile isn't set. Set it to a unique value " "in the base class.".format(cls.__name__)) cls._lockfile = open(cls.lockfile) locks.lock(cls._lockfile, locks.LOCK_EX) super(SerializeMixin, cls).setUpClass() @classmethod def tearDownClass(cls): super(SerializeMixin, cls).tearDownClass() cls._lockfile.close()
opts = instance._meta data = {} for f in chain(opts.concrete_fields, opts.private_fields, opts.many_to_many): if not getattr(f, 'editable', False): continue if fields and f.name not in fields: continue if exclude and f.name in exclude: continue data[f.name] = f.value_from_object(instance) return data
exclude = self._get_validation_exclusions() try: self.instance.validate_unique(exclude=exclude) except ValidationError as e: self._update_errors(e)
if not (self.data or self.files): return len(self.get_queryset()) return super(BaseModelFormSet, self).initial_form_count()
while field.remote_field is not None: field = field.remote_field.get_related_field() return field.to_python
return form.save(commit=commit)
return form.save(commit=commit)
if commit: obj.delete()
if not commit: self.saved_forms = [] def save_m2m(): for form in self.saved_forms: form.save_m2m() self.save_m2m = save_m2m return self.save_existing_objects(commit) + self.save_new_objects(commit)
if callable(self.limit_choices_to): return self.limit_choices_to() return self.limit_choices_to
return smart_text(obj)
return iter(self.forms)
return self.forms[index]
if self.is_bound: form = ManagementForm(self.data, auto_id=self.auto_id, prefix=self.prefix) if not form.is_valid(): raise ValidationError( _('ManagementForm data is missing or has been tampered with'), code='missing_management_form', ) else: form = ManagementForm(auto_id=self.auto_id, prefix=self.prefix, initial={ TOTAL_FORM_COUNT: self.total_form_count(), INITIAL_FORM_COUNT: self.initial_form_count(), MIN_NUM_FORM_COUNT: self.min_num, MAX_NUM_FORM_COUNT: self.max_num }) return form
return self.form_kwargs.copy()
return self.forms[:self.initial_form_count()]
return self.forms[self.initial_form_count():]
if not self.is_valid(): raise AttributeError("'%s' object has no attribute 'cleaned_data'" % self.__class__.__name__) return [form.cleaned_data for form in self.forms]
if self._non_form_errors is None: self.full_clean() return self._non_form_errors
if self._errors is None: self.full_clean() return self._errors
return len(self.non_form_errors()) +\ sum(len(form_errors) for form_errors in self.errors)
return form.cleaned_data.get(DELETION_FIELD_NAME, False)
pass
return any(form.has_changed() for form in self)
if self.forms: return self.forms[0].is_multipart() else: return self.empty_form.is_multipart()
return self.is_bound and not self.errors
return '%s-%s' % (self.prefix, field_name) if self.prefix else field_name
return 'initial-%s' % self.add_prefix(field_name)
return self.errors.get(NON_FIELD_ERRORS, self.error_class(error_class='nonfield'))
pass
return self.cleaned_data
return bool(self.changed_data)
media = Media() for field in self.fields.values(): media = media + field.widget.media return media
for field in self.fields.values(): if field.widget.needs_multipart_form: return True return False
return [field for field in self if field.is_hidden]
return [field for field in self if not field.is_hidden]
if path.startswith(('http://', 'https://', '/')): return path return static(path)
def __new__(mcs, name, bases, attrs): new_class = super(MediaDefiningClass, mcs).__new__(mcs, name, bases, attrs) if 'media' not in attrs: new_class.media = media_property(new_class) return new_class
def __init__(self, parent_widget, name, value, attrs, choices): self.parent_widget = parent_widget self.name, self.value = name, value self.attrs, self.choices = attrs, choices def __str__(self): args = [self.name, self.value, self.attrs] if self.choices: args.append(self.choices) return self.parent_widget.render(*args)
yield SubWidget(self, name, value, attrs, choices)
raise NotImplementedError('subclasses of Widget must provide a render() method')
return data.get(name)
return id_
return name + '-clear'
return name + '_id'
return bool(value and getattr(value, 'url', False))
return { 'initial': conditional_escape(value), 'initial_url': conditional_escape(value.url), }
def __init__(self, attrs=None): choices = ( ('1', ugettext_lazy('Unknown')), ('2', ugettext_lazy('Yes')), ('3', ugettext_lazy('No')), ) super(NullBooleanSelect, self).__init__(attrs, choices) def render(self, name, value, attrs=None): try: value = {True: '2', False: '3', '2': '2', '3': '3'}[value] except KeyError: value = '1' return super(NullBooleanSelect, self).render(name, value, attrs) def value_from_datadict(self, data, files, name): value = data.get(name) return { '2': True, True: True, 'True': True, '3': False, 'False': False, False: False, }.get(value)
id_ = self.attrs.get('id') output = [] for i, choice in enumerate(self.choices): choice_value, choice_label = choice if isinstance(choice_label, (tuple, list)): attrs_plus = self.attrs.copy() if id_: attrs_plus['id'] += '_{}'.format(i) sub_ul_renderer = self.__class__( name=self.name, value=self.value, attrs=attrs_plus, choices=choice_label, ) sub_ul_renderer.choice_input_class = self.choice_input_class output.append(format_html( self.inner_html, choice_value=choice_value, sub_widgets=sub_ul_renderer.render(), )) else: w = self.choice_input_class(self.name, self.value, self.attrs.copy(), choice, i) output.append(format_html(self.inner_html, choice_value=force_text(w), sub_widgets='')) return format_html( self.outer_html, id_attr=format_html(' id="{}"', id_) if id_ else '', content=mark_safe('\n'.join(output)), )
if value is None: value = self._empty_value final_attrs = self.build_attrs(attrs) return self.renderer(name, value, final_attrs, self.choices)
return ''.join(rendered_widgets)
raise NotImplementedError('Subclasses must implement this method.')
supports_microseconds = False def __init__(self, attrs=None, date_format=None, time_format=None): widgets = ( DateInput(attrs=attrs, format=date_format), TimeInput(attrs=attrs, format=time_format), ) super(SplitDateTimeWidget, self).__init__(widgets, attrs) def decompress(self, value): if value: value = to_current_timezone(value) return [value.date(), value.time().replace(microsecond=0)] return [None, None]
def __init__(self, attrs=None, date_format=None, time_format=None): super(SplitHiddenDateTimeWidget, self).__init__(attrs, date_format, time_format) for widget in self.widgets: widget.input_type = 'hidden'
if not name: return '' return name.replace('_', ' ').capitalize()
key_value_attrs = [] boolean_attrs = [] for attr, value in attrs.items(): if isinstance(value, bool): if value: boolean_attrs.append((attr,)) else: key_value_attrs.append((attr, value)) return ( format_html_join('', ' {}="{}"', sorted(key_value_attrs)) + format_html_join('', ' {}', sorted(boolean_attrs)) )
def as_data(self): return {f: e.as_data() for f, e in self.items()} def as_json(self, escape_html=False): return json.dumps({f: e.get_json_data(escape_html) for f, e in self.items()}) def as_ul(self): if not self: return '' return format_html( '<ul class="errorlist">{}</ul>', format_html_join('', '<li>{}{}</li>', ((k, force_text(v)) for k, v in self.items())) ) def as_text(self): output = [] for field, errors in self.items(): output.append('* %s' % field) output.append('\n'.join(' * %s' % e for e in errors)) return '\n'.join(output) def __str__(self): return self.as_ul()
if settings.USE_TZ and value is not None and timezone.is_naive(value): current_timezone = timezone.get_current_timezone() try: return timezone.make_aware(value, current_timezone) except Exception: message = _( '%(datetime)s couldn\'t be interpreted ' 'in time zone %(current_timezone)s; it ' 'may be ambiguous or it may not exist.' ) params = {'datetime': value, 'current_timezone': current_timezone} six.reraise(ValidationError, ValidationError( message, code='ambiguous_timezone', params=params, ), sys.exc_info()[2]) return value
value = self.to_python(value) self.validate(value) self.run_validators(value) return value
if self.disabled: return initial return data
return {}
return BoundField(form, self, field_name)
value = super(IntegerField, self).to_python(value) if value in self.empty_values: return None if self.localize: value = formats.sanitize_separators(value) try: value = float(value) except (ValueError, TypeError): raise ValidationError(self.error_messages['invalid'], code='invalid') return value
if value in self.empty_values: return None if self.localize: value = formats.sanitize_separators(value) value = smart_text(value).strip() try: value = Decimal(value) except DecimalException: raise ValidationError(self.error_messages['invalid'], code='invalid') return value
if value in self.empty_values: return None if isinstance(value, datetime.datetime): return value.date() if isinstance(value, datetime.date): return value return super(DateField, self).to_python(value)
if value in self.empty_values: return None if isinstance(value, datetime.time): return value return super(TimeField, self).to_python(value)
if value in self.empty_values: return None if isinstance(value, datetime.datetime): return from_current_timezone(value) if isinstance(value, datetime.date): result = datetime.datetime(value.year, value.month, value.day) return from_current_timezone(result) result = super(DateTimeField, self).to_python(value) return from_current_timezone(result)
kwargs.setdefault('strip', False) super(RegexField, self).__init__(max_length, min_length, *args, **kwargs) self._set_regex(regex)
if value in (True, 'True', 'true', '1'): return True elif value in (False, 'False', 'false', '0'): return False else: return None
super(ChoiceField, self).validate(value) if value and not self.valid_value(value): raise ValidationError( self.error_messages['invalid_choice'], code='invalid_choice', params={'value': value}, )
if value == self.empty_value or value in self.empty_values: return self.empty_value try: value = self.coerce(value) except (ValueError, TypeError, ValidationError): raise ValidationError( self.error_messages['invalid_choice'], code='invalid_choice', params={'value': value}, ) return value
if value == self.empty_value or value in self.empty_values: return self.empty_value new_value = [] for choice in value: try: new_value.append(self.coerce(choice)) except (ValueError, TypeError, ValidationError): raise ValidationError( self.error_messages['invalid_choice'], code='invalid_choice', params={'value': choice}, ) return new_value
super(ComboField, self).clean(value) for field in self.fields: value = field.clean(value) return value
raise NotImplementedError('Subclasses must implement this method.')
if self.field.show_hidden_initial: return self.as_widget() + self.as_hidden(only_initial=True) return self.as_widget()
id_ = self.field.widget.attrs.get('id') or self.auto_id attrs = {'id': id_} if id_ else {} for subwidget in self.field.widget.subwidgets(self.html_name, self.value(), attrs): yield subwidget
return self.form.errors.get(self.name, self.form.error_class())
if not widget: widget = self.field.widget if self.field.localize: widget.is_localized = True attrs = attrs or {} if not widget.is_hidden and self.field.required and self.form.use_required_attribute: attrs['required'] = True if self.field.disabled: attrs['disabled'] = True auto_id = self.auto_id if auto_id and 'id' not in attrs and 'id' not in widget.attrs: if not only_initial: attrs['id'] = auto_id else: attrs['id'] = self.html_initial_id if not only_initial: name = self.html_name else: name = self.html_initial_name return force_text(widget.render(name, self.value(), attrs=attrs))
return self.as_widget(TextInput(), attrs, **kwargs)
return self.as_widget(self.field.hidden_widget(), attrs, **kwargs)
return self.field.widget.value_from_datadict(self.form.data, self.form.files, self.html_name)
if hasattr(extra_classes, 'split'): extra_classes = extra_classes.split() extra_classes = set(extra_classes or []) if self.errors and hasattr(self.form, 'error_css_class'): extra_classes.add(self.form.error_css_class) if self.field.required and hasattr(self.form, 'required_css_class'): extra_classes.add(self.form.required_css_class) return ' '.join(extra_classes)
auto_id = self.form.auto_id if auto_id and '%s' in smart_text(auto_id): return smart_text(auto_id) % self.html_name elif auto_id: return self.html_name return ''
return do_timezone(value, timezone.get_current_timezone())
return do_timezone(value, timezone.utc)
def __init__(self, nodelist, use_tz): self.nodelist = nodelist self.use_tz = use_tz def render(self, context): old_setting = context.use_tz context.use_tz = self.use_tz output = self.nodelist.render(context) context.use_tz = old_setting return output
def __init__(self, nodelist, tz): self.nodelist = nodelist self.tz = tz def render(self, context): with timezone.override(self.tz.resolve(context)): output = self.nodelist.render(context) return output
def __init__(self, variable): self.variable = variable def render(self, context): context[self.variable] = timezone.get_current_timezone_name() return ''
bits = token.split_contents() if len(bits) == 1: use_tz = True elif len(bits) > 2 or bits[1] not in ('on', 'off'): raise TemplateSyntaxError("%r argument should be 'on' or 'off'" % bits[0]) else: use_tz = bits[1] == 'on' nodelist = parser.parse(('endlocaltime',)) parser.delete_first_token() return LocalTimeNode(nodelist, use_tz)
bits = token.split_contents() if len(bits) != 2: raise TemplateSyntaxError("'%s' takes one argument (timezone)" % bits[0]) tz = parser.compile_filter(bits[1]) nodelist = parser.parse(('endtimezone',)) parser.delete_first_token() return TimezoneNode(nodelist, tz)
return force_text(formats.localize(value, use_l10n=True))
return force_text(value)
args = token.split_contents() if len(args) != 5 or args[1] != 'for' or args[3] != 'as': raise TemplateSyntaxError("'%s' requires 'for string as variable' (got %r)" % (args[0], args[1:])) return GetLanguageInfoNode(parser.compile_filter(args[2]), args[4])
args = token.split_contents() if len(args) != 5 or args[1] != 'for' or args[3] != 'as': raise TemplateSyntaxError("'%s' requires 'for sequence as variable' (got %r)" % (args[0], args[1:])) return GetLanguageInfoListNode(parser.compile_filter(args[2]), args[4])
bits = token.split_contents() if len(bits) < 2: raise TemplateSyntaxError("'%s' takes at least one argument" % bits[0]) message_string = parser.compile_filter(bits[1]) remaining = bits[2:] noop = False asvar = None message_context = None seen = set() invalid_context = {'as', 'noop'} while remaining: option = remaining.pop(0) if option in seen: raise TemplateSyntaxError( "The '%s' option was specified more than once." % option, ) elif option == 'noop': noop = True elif option == 'context': try: value = remaining.pop(0) except IndexError: msg = "No argument provided to the '%s' tag for the context option." % bits[0] six.reraise(TemplateSyntaxError, TemplateSyntaxError(msg), sys.exc_info()[2]) if value in invalid_context: raise TemplateSyntaxError( "Invalid argument '%s' provided to the '%s' tag for the context option" % (value, bits[0]), ) message_context = parser.compile_filter(value) elif option == 'as': try: value = remaining.pop(0) except IndexError: msg = "No argument provided to the '%s' tag for the as option." % bits[0] six.reraise(TemplateSyntaxError, TemplateSyntaxError(msg), sys.exc_info()[2]) asvar = value else: raise TemplateSyntaxError( "Unknown argument for '%s' tag: '%s'. The only options " "available are 'noop', 'context' \"xxx\", and 'as VAR'." % ( bits[0], option, ) ) seen.add(option) return TranslateNode(message_string, noop, asvar, message_context)
bits = token.split_contents() options = {} remaining_bits = bits[1:] asvar = None while remaining_bits: option = remaining_bits.pop(0) if option in options: raise TemplateSyntaxError('The %r option was specified more ' 'than once.' % option) if option == 'with': value = token_kwargs(remaining_bits, parser, support_legacy=True) if not value: raise TemplateSyntaxError('"with" in %r tag needs at least ' 'one keyword argument.' % bits[0]) elif option == 'count': value = token_kwargs(remaining_bits, parser, support_legacy=True) if len(value) != 1: raise TemplateSyntaxError('"count" in %r tag expected exactly ' 'one keyword argument.' % bits[0]) elif option == "context": try: value = remaining_bits.pop(0) value = parser.compile_filter(value) except Exception: msg = ( '"context" in %r tag expected ' 'exactly one argument.') % bits[0] six.reraise(TemplateSyntaxError, TemplateSyntaxError(msg), sys.exc_info()[2]) elif option == "trimmed": value = True elif option == "asvar": try: value = remaining_bits.pop(0) except IndexError: msg = "No argument provided to the '%s' tag for the asvar option." % bits[0] six.reraise(TemplateSyntaxError, TemplateSyntaxError(msg), sys.exc_info()[2]) asvar = value else: raise TemplateSyntaxError('Unknown argument for %r tag: %r.' % (bits[0], option)) options[option] = value if 'count' in options: countervar, counter = list(options['count'].items())[0] else: countervar, counter = None, None if 'context' in options: message_context = options['context'] else: message_context = None extra_context = options.get('with', {}) trimmed = options.get("trimmed", False) singular = [] plural = [] while parser.tokens: token = parser.next_token() if token.token_type in (TOKEN_VAR, TOKEN_TEXT): singular.append(token) else: break if countervar and counter: if token.contents.strip() != 'plural': raise TemplateSyntaxError("'blocktrans' doesn't allow other block tags inside it") while parser.tokens: token = parser.next_token() if token.token_type in (TOKEN_VAR, TOKEN_TEXT): plural.append(token) else: break if token.contents.strip() != 'endblocktrans': raise TemplateSyntaxError("'blocktrans' doesn't allow other block tags (seen %r) inside it" % token.contents) return BlockTranslateNode(extra_context, singular, plural, countervar, counter, message_context, trimmed=trimmed, asvar=asvar)
return PrefixNode.handle_token(parser, token, "STATIC_URL")
return PrefixNode.handle_token(parser, token, "MEDIA_URL")
bits = token.split_contents() if len(bits) < 2: raise template.TemplateSyntaxError( "'%s' takes at least one argument (path to file)" % bits[0]) path = parser.compile_filter(bits[1]) if len(bits) >= 2 and bits[-2] == 'as': varname = bits[3] else: varname = None return cls(varname, path)
return StaticNode.handle_token(parser, token)
if weak is not None: warnings.warn("Passing `weak` to disconnect has no effect.", RemovedInDjango20Warning, stacklevel=2) if dispatch_uid: lookup_key = (dispatch_uid, _make_id(sender)) else: lookup_key = (_make_id(receiver), _make_id(sender)) disconnected = False with self.lock: self._clear_dead_receivers() for index in range(len(self.receivers)): (r_key, _) = self.receivers[index] if r_key == lookup_key: disconnected = True del self.receivers[index] break self.sender_receivers_cache.clear() return disconnected
responses = [] if not self.receivers or self.sender_receivers_cache.get(sender) is NO_RECEIVERS: return responses for receiver in self._live_receivers(sender): response = receiver(signal=self, sender=sender, **named) responses.append((receiver, response)) return responses
def _decorator(func): if isinstance(signal, (list, tuple)): for s in signal: s.connect(func, **kwargs) else: signal.connect(func, **kwargs) return func return _decorator
def __getattr__(self, item): return getattr(connections[DEFAULT_DB_ALIAS], item) def __setattr__(self, name, value): return setattr(connections[DEFAULT_DB_ALIAS], name, value) def __delattr__(self, name): return delattr(connections[DEFAULT_DB_ALIAS], name) def __eq__(self, other): return connections[DEFAULT_DB_ALIAS] == other def __ne__(self, other): return connections[DEFAULT_DB_ALIAS] != other
if callable(self.upload_to): filename = self.upload_to(instance, filename) else: dirname = force_text(datetime.datetime.now().strftime(force_str(self.upload_to))) filename = posixpath.join(dirname, filename) return self.storage.generate_filename(filename)
model = self.model app = model._meta.app_label return '%s.%s.%s' % (app, model._meta.object_name, self.name)
path = '%s.%s' % (self.__class__.__module__, self.__class__.__name__) name = getattr(self, 'name', None) if name is not None: return '<%s: %s>' % (path, name) return '<%s>' % path
return sql, params
name, path, args, kwargs = self.deconstruct() return self.__class__(*args, **kwargs)
if self.default: return self.get_default() return None
return value
return list(itertools.chain(self.default_validators, self._validators))
value = self.to_python(value) self.validate(value, model_instance) self.run_validators(value) return value
data = DictWrapper(self.__dict__, connection.ops.quote_name, "qn_") try: return connection.data_type_check_constraints[self.get_internal_type()] % data except KeyError: return None
return self.db_type(connection)
type_string = self.db_type(connection) check_string = self.db_check(connection) return { "type": type_string, "check": check_string, }
return {self.name: getattr(obj, self.attname)}
return getattr(model_instance, self.attname)
if isinstance(value, Promise): value = value._proxy____cast() return value
if not prepared: value = self.get_prep_value(value) return value
return self.get_db_prep_value(value, connection=connection, prepared=False)
return self.default is not NOT_PROVIDED
if self.has_default(): if callable(self.default): return self.default() return self.default if not self.empty_strings_allowed or self.null and not connection.features.interprets_empty_strings_as_nulls: return None return ""
flat = [] for choice, value in self.choices: if isinstance(value, (list, tuple)): flat.extend(value) else: flat.append((choice, value)) return flat
return getattr(obj, self.attname)
if connection.features.related_fields_match_type: return self.db_type(connection) else: return IntegerField().db_type(connection=connection)
return b64encode(force_bytes(self.value_from_object(obj))).decode('ascii')
if instance is None: return self return self.related_manager_cls(instance)
warnings.warn( 'Direct assignment to the reverse side of a related set is ' 'deprecated due to the implicit save() that happens. Use %s.set() ' 'instead.' % self.rel.get_accessor_name(), RemovedInDjango20Warning, stacklevel=2, ) manager = self.__get__(instance) manager.set(value)
db = self._db or router.db_for_read(self.model, instance=self.instance) empty_strings_as_null = connections[db].features.interprets_empty_strings_as_nulls queryset._add_hints(instance=self.instance) if self._db: queryset = queryset.using(self._db) queryset = queryset.filter(**self.core_filters) for field in self.field.foreign_related_fields: val = getattr(self.instance, field.attname) if val is None or (val == '' and empty_strings_as_null): return queryset.none() queryset._known_related_objects = {self.field: {self.instance.pk: self.instance}} return queryset
queryset._add_hints(instance=self.instance) if self._db: queryset = queryset.using(self._db) return queryset._next_is_sticky().filter(**self.core_filters)
target_fields = self.get_path_info()[-1].target_fields if len(target_fields) > 1: raise exceptions.FieldError("Can't use target_field for multicolumn relations.") return target_fields[0]
return (blank_choice if include_blank else []) + [ (x._get_pk_val(), smart_text(x)) for x in self.related_model._default_manager.all() ]
field = self.model._meta.get_field(self.field_name) if not field.concrete: raise exceptions.FieldDoesNotExist("No related field named '%s'" % self.field_name) return field
def __init__(self, field, to, field_name, related_name=None, related_query_name=None, limit_choices_to=None, parent_link=False, on_delete=None): super(OneToOneRel, self).__init__( field, to, field_name, related_name=related_name, related_query_name=related_query_name, limit_choices_to=limit_choices_to, parent_link=parent_link, on_delete=on_delete, ) self.multiple = False
models = [model] + [resolve_relation(model, rel) for rel in related_models] model_keys = (make_model_tuple(m) for m in models) apps = model._meta.apps return apps.lazy_model_operation(partial(function, **kwargs), *model_keys)
return { '%s__%s' % (self.name, rh_field.name): getattr(obj, rh_field.attname) for _, rh_field in self.related_fields }
base_filter = { rh_field.attname: getattr(obj, lh_field.attname) for lh_field, rh_field in self.related_fields } descriptor_filter = self.get_extra_descriptor_filter(obj) base_q = Q(**base_filter) if isinstance(descriptor_filter, dict): return base_q & Q(**descriptor_filter) elif descriptor_filter: return base_q & descriptor_filter return base_q
if callable(self.remote_field.limit_choices_to): return self.remote_field.limit_choices_to() return self.remote_field.limit_choices_to
return self.remote_field.related_query_name or self.remote_field.related_name or self.opts.model_name
target_fields = self.get_path_info()[-1].target_fields if len(target_fields) > 1: raise exceptions.FieldError( "The relation has multiple target fields, but only single target field was asked for") return target_fields[0]
return {}
return None
opts = self.remote_field.model._meta from_opts = self.model._meta return [PathInfo(from_opts, opts, self.foreign_related_fields, self, False, True)]
opts = self.model._meta from_opts = self.remote_field.model._meta pathinfos = [PathInfo(from_opts, opts, (opts.pk,), self.remote_field, not self.unique, False)] return pathinfos
opts = self.model._meta from_opts = self.remote_field.model._meta pathinfos = [PathInfo(from_opts, opts, (opts.pk,), self.remote_field, not self.unique, False)] return pathinfos
pathinfos = [] int_model = self.remote_field.through linkfield1 = int_model._meta.get_field(self.m2m_field_name()) linkfield2 = int_model._meta.get_field(self.m2m_reverse_field_name()) if direct: join1infos = linkfield1.get_reverse_path_info() join2infos = linkfield2.get_path_info() else: join1infos = linkfield2.get_reverse_path_info() join2infos = linkfield1.get_path_info() pathinfos.extend(join1infos) pathinfos.extend(join2infos) return pathinfos
if self.remote_field.through is not None: return self.remote_field.through._meta.db_table elif self.db_table: return self.db_table else: return utils.truncate_name('%s_%s' % (opts.db_table, self.name), connection.ops.max_name_length())
cache_attr = '_m2m_%s_cache' % attr if hasattr(self, cache_attr): return getattr(self, cache_attr) if self.remote_field.through_fields is not None: link_field_name = self.remote_field.through_fields[0] else: link_field_name = None for f in self.remote_field.through._meta.fields: if (f.is_relation and f.remote_field.model == related.related_model and (link_field_name is None or link_field_name == f.name)): setattr(self, cache_attr, getattr(f, attr)) return getattr(self, cache_attr)
if obj.pk is None: return [] qs = getattr(obj, self.attname).all() if qs._result_cache is not None: return [item.pk for item in qs] return list(qs.values_list('pk', flat=True))
def __init__(self, *args, **kwargs): kwargs['name'] = '_order' kwargs['editable'] = False super(OrderWrt, self).__init__(*args, **kwargs) def deconstruct(self): name, path, args, kwargs = super(OrderWrt, self).deconstruct() del kwargs['editable'] return name, path, args, kwargs
lookup_name = 'week_day'
return super(Greatest, self).as_sql(compiler, connection, function='MAX')
return super(Least, self).as_sql(compiler, connection, function='MIN')
function = 'LENGTH' lookup_name = 'length' def __init__(self, expression, **extra): output_field = extra.pop('output_field', fields.IntegerField()) super(Length, self).__init__(expression, output_field=output_field, **extra) def as_mysql(self, compiler, connection): return super(Length, self).as_sql(compiler, connection, function='CHAR_LENGTH')
if not hasattr(pos, 'resolve_expression'): if pos < 1: raise ValueError("'pos' must be greater than 0") pos = Value(pos) expressions = [expression, pos] if length is not None: if not hasattr(length, 'resolve_expression'): length = Value(length) expressions.append(length) super(Substr, self).__init__(*expressions, **extra)
from django.urls import reverse @wraps(func) def inner(*args, **kwargs): bits = func(*args, **kwargs) return reverse(bits[0], None, *bits[1:3]) return inner
pass
contains_aggregate = False def __init__(self, sql, params): self.data = sql, list(params) def as_sql(self, compiler=None, connection=None): return self.data
opts = instance._meta f = opts.get_field(name) link_field = opts.get_ancestor_link(f.model) if f.primary_key and f != link_field: return getattr(instance, link_field.attname) return None
if lookup_name is None: lookup_name = lookup.lookup_name del cls.class_lookups[lookup_name]
if not field.remote_field: return False if field.remote_field.parent_link and not reverse: return False if restricted: if reverse and field.related_query_name() not in requested: return False if not reverse and field.name not in requested: return False if not restricted and field.null: return False if load_fields: if field.attname not in load_fields: if restricted and field.name in requested: raise InvalidQuery("Field %s.%s cannot be both deferred" " and traversed using select_related" " at the same time." % (field.model._meta.object_name, field.name)) return True
for n in range(len(lookup_parts) + 1): level_n_lookup = LOOKUP_SEP.join(lookup_parts[0:n]) if level_n_lookup in annotations and annotations[level_n_lookup]: return annotations[level_n_lookup], lookup_parts[n:] return False, ()
data = self.__dict__ data[DJANGO_VERSION_PICKLE_KEY] = get_version() class_id = self._meta.app_label, self._meta.object_name return model_unpickle, (class_id,), data
return { f.attname for f in self._meta.concrete_fields if f.attname not in self.__dict__ }
try: field = self._meta.get_field(field_name) except FieldDoesNotExist: return getattr(self, field_name) return getattr(self, field.attname)
return manager._insert([self], fields=fields, return_id=update_pk, using=using, raw=raw)
pass
unique_checks, date_checks = self._get_unique_checks(exclude=exclude) errors = self._perform_unique_checks(unique_checks) date_errors = self._perform_date_checks(date_checks) for k, v in date_errors.items(): errors.setdefault(k, []).extend(v) if errors: raise ValidationError(errors)
errors = [] if cls._meta.swapped: try: apps.get_model(cls._meta.swapped) except ValueError: errors.append( checks.Error( "'%s' is not of the form 'app_label.app_name'." % cls._meta.swappable, id='models.E001', ) ) except LookupError: app_label, model_name = cls._meta.swapped.split('.') errors.append( checks.Error( "'%s' references '%s.%s', which has not been " "installed, or is abstract." % ( cls._meta.swappable, app_label, model_name ), id='models.E002', ) ) return errors
errors = [] for manager in cls._meta.managers: errors.extend(manager.check(**kwargs)) return errors
errors = [] for field in cls._meta.local_fields: errors.extend(field.check(**kwargs)) for field in cls._meta.local_many_to_many: errors.extend(field.check(from_model=cls, **kwargs)) return errors
if not isinstance(cls._meta.index_together, (tuple, list)): return [ checks.Error( "'index_together' must be a list or tuple.", obj=cls, id='models.E008', ) ] elif any(not isinstance(fields, (tuple, list)) for fields in cls._meta.index_together): return [ checks.Error( "All 'index_together' elements must be lists or tuples.", obj=cls, id='models.E009', ) ] else: errors = [] for fields in cls._meta.index_together: errors.extend(cls._check_local_fields(fields, "index_together")) return errors
if not isinstance(cls._meta.unique_together, (tuple, list)): return [ checks.Error( "'unique_together' must be a list or tuple.", obj=cls, id='models.E010', ) ] elif any(not isinstance(fields, (tuple, list)) for fields in cls._meta.unique_together): return [ checks.Error( "All 'unique_together' elements must be lists or tuples.", obj=cls, id='models.E011', ) ] else: errors = [] for fields in cls._meta.unique_together: errors.extend(cls._check_local_fields(fields, "unique_together")) return errors
def __iter__(self): queryset = self.queryset compiler = queryset.query.get_compiler(queryset.db) for row in compiler.results_iter(): yield row[0]
obj = self.__class__() for k, v in self.__dict__.items(): if k == '_result_cache': obj.__dict__[k] = None else: obj.__dict__[k] = copy.deepcopy(v, memo) return obj
self._fetch_all() return iter(self._result_cache)
if not isinstance(k, (slice,) + six.integer_types): raise TypeError assert ((not isinstance(k, slice) and (k >= 0)) or (isinstance(k, slice) and (k.start is None or k.start >= 0) and (k.stop is None or k.stop >= 0))), \ "Negative indexing is not supported." if self._result_cache is not None: return self._result_cache[k] if isinstance(k, slice): qs = self._clone() if k.start is not None: start = int(k.start) else: start = None if k.stop is not None: stop = int(k.stop) else: stop = None qs.query.set_limits(start, stop) return list(qs)[::k.step] if k.step else qs qs = self._clone() qs.query.set_limits(k, k + 1) return list(qs)[0]
return iter(self._iterable_class(self))
if self._result_cache is not None: return len(self._result_cache) return self.query.get_count(using=self.db)
clone = self.filter(*args, **kwargs) if self.query.can_filter() and not self.query.distinct_fields: clone = clone.order_by() num = len(clone) if num == 1: return clone._result_cache[0] if not num: raise self.model.DoesNotExist( "%s matching query does not exist." % self.model._meta.object_name ) raise self.model.MultipleObjectsReturned( "get() returned more than one %s -- it returned %s!" % (self.model._meta.object_name, num) )
obj = self.model(**kwargs) self._for_write = True obj.save(force_insert=True, using=self.db) return obj
defaults = defaults or {} lookup, params = self._extract_model_params(defaults, **kwargs) self._for_write = True try: obj = self.get(**lookup) except self.model.DoesNotExist: obj, created = self._create_object_from_params(lookup, params) if created: return obj, created for k, v in six.iteritems(defaults): setattr(obj, k, v) obj.save(using=self.db) return obj, False
try: with transaction.atomic(using=self.db): obj = self.create(**params) return obj, True except IntegrityError: exc_info = sys.exc_info() try: return self.get(**lookup), False except self.model.DoesNotExist: pass six.reraise(*exc_info)
defaults = defaults or {} lookup = kwargs.copy() for f in self.model._meta.fields: if f.attname in lookup: lookup[f.name] = lookup.pop(f.attname) params = {k: v for k, v in kwargs.items() if LOOKUP_SEP not in k} params.update(defaults) return lookup, params
order_by = field_name or getattr(self.model._meta, 'get_latest_by') assert bool(order_by), "earliest() and latest() require either a "\ "field_name parameter or 'get_latest_by' in the model" assert self.query.can_filter(), \ "Cannot change a query once a slice has been taken." obj = self._clone() obj.query.set_limits(high=1) obj.query.clear_ordering(force_empty=True) obj.query.add_ordering('%s%s' % (direction, order_by)) return obj.get()
objects = list((self if self.ordered else self.order_by('pk'))[:1]) if objects: return objects[0] return None
objects = list((self.reverse() if self.ordered else self.order_by('-pk'))[:1]) if objects: return objects[0] return None
assert self.query.can_filter(), \ "Cannot use 'limit' or 'offset' with in_bulk" if id_list is not None: if not id_list: return {} qs = self.filter(pk__in=id_list).order_by() else: qs = self._clone() return {obj._get_pk_val(): obj for obj in qs}
return sql.DeleteQuery(self.model).delete_qs(self, using)
assert self.query.can_filter(), \ "Cannot update a query once a slice has been taken." self._for_write = True query = self.query.clone(sql.UpdateQuery) query.add_update_values(kwargs) with transaction.atomic(using=self.db, savepoint=False): rows = query.get_compiler(self.db).execute_sql(CURSOR) self._result_cache = None return rows
assert self.query.can_filter(), \ "Cannot update a query once a slice has been taken." query = self.query.clone(sql.UpdateQuery) query.add_update_fields(values) self._result_cache = None return query.get_compiler(self.db).execute_sql(CURSOR)
assert kind in ("year", "month", "day"), \ "'kind' must be one of 'year', 'month' or 'day'." assert order in ('ASC', 'DESC'), \ "'order' must be either 'ASC' or 'DESC'." return self.annotate( datefield=Trunc(field_name, kind, output_field=DateField()), plain_field=F(field_name) ).values_list( 'datefield', flat=True ).distinct().filter(plain_field__isnull=False).order_by(('-' if order == 'DESC' else '') + 'datefield')
assert kind in ("year", "month", "day", "hour", "minute", "second"), \ "'kind' must be one of 'year', 'month', 'day', 'hour', 'minute' or 'second'." assert order in ('ASC', 'DESC'), \ "'order' must be either 'ASC' or 'DESC'." if settings.USE_TZ: if tzinfo is None: tzinfo = timezone.get_current_timezone() else: tzinfo = None return self.annotate( datetimefield=Trunc(field_name, kind, output_field=DateTimeField(), tzinfo=tzinfo), plain_field=F(field_name) ).values_list( 'datetimefield', flat=True ).distinct().filter(plain_field__isnull=False).order_by(('-' if order == 'DESC' else '') + 'datetimefield')
clone = self._clone() clone.query.set_empty() return clone
return self._clone()
return self._filter_or_exclude(False, *args, **kwargs)
return self._filter_or_exclude(True, *args, **kwargs)
if isinstance(filter_obj, Q) or hasattr(filter_obj, 'add_to_query'): clone = self._clone() clone.query.add_q(filter_obj) return clone else: return self._filter_or_exclude(None, **filter_obj)
obj = self._clone() obj._for_write = True obj.query.select_for_update = True obj.query.select_for_update_nowait = nowait return obj
if self._fields is not None: raise TypeError("Cannot call select_related() after .values() or .values_list()") obj = self._clone() if fields == (None,): obj.query.select_related = False elif fields: obj.query.add_select_related(fields) else: obj.query.select_related = True return obj
clone = self._clone() if lookups == (None,): clone._prefetch_related_lookups = [] else: clone._prefetch_related_lookups.extend(lookups) return clone
assert self.query.can_filter(), \ "Cannot reorder a query once a slice has been taken." obj = self._clone() obj.query.clear_ordering(force_empty=False) obj.query.add_ordering(*field_names) return obj
assert self.query.can_filter(), \ "Cannot create distinct fields once a slice has been taken." obj = self._clone() obj.query.add_distinct_fields(*field_names) return obj
assert self.query.can_filter(), \ "Cannot change a query once a slice has been taken" clone = self._clone() clone.query.add_extra(select, select_params, where, params, tables, order_by) return clone
clone = self._clone() clone.query.standard_ordering = not clone.query.standard_ordering return clone
if self._fields is not None: raise TypeError("Cannot call defer() after .values() or .values_list()") clone = self._clone() if fields == (None,): clone.query.clear_deferred_loading() else: clone.query.add_deferred_loading(fields) return clone
clone = self._clone() clone._db = alias return clone
if self.query.extra_order_by or self.query.order_by: return True elif self.query.default_ordering and self.query.get_meta().ordering: return True else: return False
self._for_write = True if using is None: using = self.db query = sql.InsertQuery(self.model) query.insert_values(fields, objs, raw=raw) return query.get_compiler(using=using).execute_sql(return_id)
if not objs: return ops = connections[self.db].ops batch_size = (batch_size or max(ops.bulk_batch_size(fields, objs), 1)) inserted_ids = [] for item in [objs[i:i + batch_size] for i in range(0, len(objs), batch_size)]: if connections[self.db].features.can_return_ids_from_bulk_insert: inserted_id = self._insert(item, fields=fields, using=self.db, return_id=True) if len(objs) > 1: inserted_ids.extend(inserted_id) if len(objs) == 1: inserted_ids.append(inserted_id) else: self._insert(item, fields=fields, using=self.db) return inserted_ids
self._sticky_filter = True return self
if self._fields is not None and ( set(self.query.values_select) != set(other.query.values_select) or set(self.query.extra_select) != set(other.query.extra_select) or set(self.query.annotation_select) != set(other.query.annotation_select)): raise TypeError( "Merging '%s' classes must involve the same values in each case." % self.__class__.__name__ )
for field, objects in other._known_related_objects.items(): self._known_related_objects.setdefault(field, {}).update(objects)
return self.query.has_filters()
def __init__(self, *args, **kwargs): raise TypeError("EmptyQuerySet can't be instantiated")
model_init_fields = [f for f in self.model._meta.fields if f.column in self.columns] annotation_fields = [(column, pos) for pos, column in enumerate(self.columns) if column not in self.model_fields] model_init_order = [self.columns.index(f.column) for f in model_init_fields] model_init_names = [f.attname for f in model_init_fields] return model_init_names, model_init_order, annotation_fields
return RawQuerySet( self.raw_query, model=self.model, query=self.query.clone(using=alias), params=self.params, translations=self.translations, using=alias, )
if not hasattr(self, '_model_fields'): converter = connections[self.db].introspection.table_name_converter self._model_fields = {} for field in self.model._meta.fields: name, column = field.get_attname_column() self._model_fields[converter(column)] = field return self._model_fields
ret = [] for lookup in lookups: if not isinstance(lookup, Prefetch): lookup = Prefetch(lookup) if prefix: lookup.add_prefix(prefix) ret.append(lookup) return ret
pass
self.name = name
super(Value, self).__init__(output_field=output_field) self.value = value
def __init__(self, expression, output_field): super(ExpressionWrapper, self).__init__(output_field=output_field) self.expression = expression def set_source_expressions(self, exprs): self.expression = exprs[0] def get_source_expressions(self): return [self.expression] def as_sql(self, compiler, connection): return self.expression.as_sql(compiler, connection) def __repr__(self): return "{}({})".format(self.__class__.__name__, self.expression)
template = 'CASE %(cases)s ELSE %(default)s END' case_joiner = ' ' def __init__(self, *cases, **extra): if not all(isinstance(case, When) for case in cases): raise TypeError("Positional arguments must all be When objects.") default = extra.pop('default', None) output_field = extra.pop('output_field', None) super(Case, self).__init__(output_field) self.cases = list(cases) self.default = self._parse_expressions(default)[0] self.extra = extra def __str__(self): return "CASE %s, ELSE %r" % (', '.join(str(c) for c in self.cases), self.default) def __repr__(self): return "<%s: %s>" % (self.__class__.__name__, self) def get_source_expressions(self): return self.cases + [self.default] def set_source_expressions(self, exprs): self.cases = exprs[:-1] self.default = exprs[-1] def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False): c = self.copy() c.is_summary = summarize for pos, case in enumerate(c.cases): c.cases[pos] = case.resolve_expression(query, allow_joins, reuse, summarize, for_save) c.default = c.default.resolve_expression(query, allow_joins, reuse, summarize, for_save) return c def copy(self): c = super(Case, self).copy() c.cases = c.cases[:] return c def as_sql(self, compiler, connection, template=None, case_joiner=None, **extra_context): connection.ops.check_expression_support(self) if not self.cases: return compiler.compile(self.default) template_params = self.extra.copy() template_params.update(extra_context) case_parts = [] sql_params = [] for case in self.cases: case_sql, case_params = compiler.compile(case) case_parts.append(case_sql) sql_params.extend(case_params) case_joiner = case_joiner or self.case_joiner template_params['cases'] = case_joiner.join(case_parts) default_sql, default_params = compiler.compile(self.default) template_params['default'] = default_sql sql_params.extend(default_params) template = template or template_params.get('template', self.template) sql = template % template_params if self._output_field_or_none is not None: sql = connection.ops.unification_cast_sql(self.output_field) % sql return sql, sql_params
clone = self.__class__._new_instance( children=[], connector=self.connector, negated=self.negated) for child in self.children: if hasattr(child, 'clone'): clone.children.append(child.clone()) else: clone.children.append(child) return clone
contains_aggregate = False def as_sql(self, compiler=None, connection=None): raise EmptyResultSet
join_type = None parent_alias = None def __init__(self, table_name, alias): self.table_name = table_name self.table_alias = alias def as_sql(self, compiler, connection): alias_str = '' if self.table_alias == self.table_name else (' %s' % self.table_alias) base_sql = compiler.quote_name_unless_alias(self.table_name) return base_sql + alias_str, [] def relabeled_clone(self, change_map): return self.__class__(self.table_name, change_map.get(self.table_alias, self.table_alias))
sql, params = self.sql_with_params() return sql % params
return self.get_compiler(DEFAULT_DB_ALIAS).as_sql()
return self.model._meta
obj = self.clone() obj.add_annotation(Count('*'), alias='__count', is_summary=True) number = obj.get_aggregation(using, ['__count'])['__count'] if number is None: number = 0 return number
self.alias_refcount[alias] += 1
self.alias_refcount[alias] -= amount
aliases = list(aliases) while aliases: alias = aliases.pop(0) if self.alias_map[alias].join_type == LOUTER: self.alias_map[alias] = self.alias_map[alias].demote() parent_alias = self.alias_map[alias].parent_alias if self.alias_map[parent_alias].join_type == INNER: aliases.append(parent_alias)
for alias, cur_refcount in self.alias_refcount.copy().items(): unref_amount = cur_refcount - to_counts.get(alias, 0) self.unref_alias(alias, unref_amount)
alphabet = ascii_uppercase prefix = chr(ord(self.alias_prefix) + 1) yield prefix for n in count(1): seq = alphabet[alphabet.index(prefix):] if prefix else alphabet for s in product(seq, repeat=n): yield ''.join(s) prefix = None
if self.tables: alias = self.tables[0] self.ref_alias(alias) else: alias = self.join(BaseTable(self.get_meta().db_table, None)) return alias
return len([1 for count in self.alias_refcount.values() if count])
annotation = annotation.resolve_expression(self, allow_joins=True, reuse=None, summarize=is_summary) self.append_annotation_mask([alias]) self.annotations[alias] = annotation
lookup_splitted = lookup.split(LOOKUP_SEP) if self._annotations: expression, expression_lookups = refs_expression(lookup_splitted, self.annotations) if expression: return expression_lookups, (), expression _, field, _, lookup_parts = self.names_to_path(lookup_splitted, self.get_meta()) field_parts = lookup_splitted[0:len(lookup_splitted) - len(lookup_parts)] if len(lookup_parts) == 0: lookup_parts = ['exact'] elif len(lookup_parts) > 1: if not field_parts: raise FieldError( 'Invalid lookup "%s" for model %s".' % (lookup, self.get_meta().model.__name__)) return lookup_parts, field_parts, False
if hasattr(value, '_meta'): if not check_rel_lookup_compatibility(value._meta.model, opts, field): raise ValueError( 'Cannot query "%s": Must be "%s" instance.' % (value, opts.object_name))
transform_class = lhs.get_transform(name) if transform_class: return transform_class(lhs) else: raise FieldError( "Unsupported lookup '%s' for %s or join on the field not " "permitted." % (name, lhs.output_field.__class__.__name__))
connector = q_object.connector current_negated = current_negated ^ q_object.negated branch_negated = branch_negated or q_object.negated target_clause = self.where_class(connector=connector, negated=q_object.negated) joinpromoter = JoinPromoter(q_object.connector, len(q_object.children), current_negated) for child in q_object.children: if isinstance(child, Node): child_clause, needed_inner = self._add_q( child, used_aliases, branch_negated, current_negated, allow_joins, split_subq) joinpromoter.add_votes(needed_inner) else: child_clause, needed_inner = self.build_filter( child, can_reuse=used_aliases, branch_negated=branch_negated, current_negated=current_negated, connector=connector, allow_joins=allow_joins, split_subq=split_subq, ) joinpromoter.add_votes(needed_inner) if child_clause: target_clause.add(child_clause, connector) needed_inner = joinpromoter.update_join_types(self) return target_clause, needed_inner
joins = joins[:] for pos, info in enumerate(reversed(path)): if len(joins) == 1 or not info.direct: break join_targets = set(t.column for t in info.join_field.foreign_related_fields) cur_targets = set(t.column for t in targets) if not cur_targets.issubset(join_targets): break targets_dict = {r[1].column: r[0] for r in info.join_field.related_fields if r[1].column in cur_targets} targets = tuple(targets_dict[t.column] for t in targets) self.unref_alias(joins.pop()) return targets, joins[-1], joins
if high is not None: if self.high_mark is not None: self.high_mark = min(self.high_mark, self.low_mark + high) else: self.high_mark = self.low_mark + high if low is not None: if self.high_mark is not None: self.low_mark = min(self.high_mark, self.low_mark + low) else: self.low_mark = self.low_mark + low if self.low_mark == self.high_mark: self.set_empty()
self.low_mark, self.high_mark = 0, None
return not self.low_mark and self.high_mark is None
self.select = [] self.default_cols = False self.select_related = False self.set_extra_mask(()) self.set_annotation_mask(())
self.select = [] self.values_select = []
self.distinct_fields = field_names self.distinct = True
errors = [] for item in ordering: if not hasattr(item, 'resolve_expression') and not ORDER_PATTERN.match(item): errors.append(item) if getattr(item, 'contains_aggregate', False): raise FieldError( 'Using an aggregate in order_by() without also including ' 'it in annotate() is not allowed: %s' % item ) if errors: raise FieldError('Invalid order_by arguments: %s' % errors) if ordering: self.order_by.extend(ordering) else: self.default_ordering = False
self.order_by = [] self.extra_order_by = () if force_empty: self.default_ordering = False
self.group_by = [] for col in self.select: self.group_by.append(col) if self.annotation_select: for alias, annotation in six.iteritems(self.annotation_select): for col in annotation.get_group_by_cols(): self.group_by.append(col)
if isinstance(self.select_related, bool): field_dict = {} else: field_dict = self.select_related for field in fields: d = field_dict for part in field.split(LOOKUP_SEP): d = d.setdefault(part, {}) self.select_related = field_dict
self.deferred_loading = (set(), True)
target[model] = {f.attname for f in fields}
if names is None: self.extra_select_mask = None else: self.extra_select_mask = set(names) self._extra_select_cache = None
if self._annotation_select_cache is not None: return self._annotation_select_cache elif not self._annotations: return {} elif self.annotation_select_mask is not None: self._annotation_select_cache = OrderedDict( (k, v) for k, v in self.annotations.items() if k in self.annotation_select_mask ) return self._annotation_select_cache else: return self.annotations
dirn = ORDER_DIR[default] if field[0] == '-': return field[1:], dirn[1] return field, dirn[0]
if key in data: data[key].add(value) else: data[key] = {value}
return field.is_relation and field.one_to_one and not field.concrete
self.votes.update(votes)
self.setup_query() order_by = self.get_order_by() self.where, self.having = self.query.where.split_having() extra_select = self.get_extra_select(order_by, self.select) group_by = self.get_group_by(self.select + extra_select, order_by) return extra_select, order_by, group_by
if name in self.quote_cache: return self.quote_cache[name] if ((name in self.query.alias_map and name not in self.query.table_map) or name in self.query.extra_select or ( name in self.query.external_aliases and name not in self.query.table_map)): self.quote_cache[name] = name return name r = self.connection.ops.quote_name(name) self.quote_cache[name] = r return r
qn = self.quote_name_unless_alias qn2 = self.connection.ops.quote_name result = [] opts = self.query.get_meta() for name in self.query.distinct_fields: parts = name.split(LOOKUP_SEP) _, targets, alias, joins, path, _ = self._setup_joins(parts, opts, None) targets, alias, _ = self.query.trim_joins(targets, joins, path) for target in targets: if name in self.query.annotation_select: result.append(name) else: result.append("%s.%s" % (qn(alias), qn2(target.column))) return result
if not alias: alias = self.query.get_initial_alias() field, targets, opts, joins, path = self.query.setup_joins( pieces, opts, alias) alias = joins[-1] return field, targets, alias, joins, path, opts
columns = {} self.query.deferred_to_data(columns, self.query.get_loaded_field_names_cb) return columns
converters = None if results is None: results = self.execute_sql(MULTI) fields = [s[0] for s in self.select[0:self.col_count]] converters = self.get_converters(fields) for rows in results: for row in rows: if converters: row = self.apply_converters(row, converters) yield row
if self.query.raw: return getattr(obj, field.attname) return field.pre_save(obj, add=True)
assert len([t for t in self.query.tables if self.query.alias_refcount[t] > 0]) == 1, \ "Can only delete from one table at a time." qn = self.quote_name_unless_alias result = ['DELETE FROM %s' % qn(self.query.tables[0])] where, params = self.compile(self.query.where) if where: result.append('WHERE %s' % where) return ' '.join(result), tuple(params)
cursor = super(SQLUpdateCompiler, self).execute_sql(result_type) try: rows = cursor.rowcount if cursor else 0 is_empty = cursor is None finally: if cursor: cursor.close() for query in self.query.get_related_updates(): aux_rows = query.get_compiler(self.using).execute_sql(result_type) if is_empty and aux_rows: rows = aux_rows is_empty = False return rows
self.values = [] self.related_ids = None if not hasattr(self, 'related_updates'): self.related_updates = {}
values_seq = [] for name, val in six.iteritems(values): field = self.get_meta().get_field(name) direct = not (field.auto_created and not field.concrete) or not field.concrete model = field.model._meta.concrete_model if not direct or (field.is_relation and field.many_to_many): raise FieldError( 'Cannot update model field %r (only non-relations and ' 'foreign keys permitted).' % field ) if model is not self.get_meta().model: self.add_related_update(model, field, val) continue values_seq.append((field, model, val)) return self.add_update_fields(values_seq)
self.values.extend(values_seq)
self.related_updates.setdefault(model, []).append((field, None, value))
if not self.related_updates: return [] result = [] for model, values in six.iteritems(self.related_updates): query = UpdateQuery(model) query.values = values if self.related_ids is not None: query.add_filter(('pk__in', self.related_ids)) result.append(query) return result
self.fields = fields self.objs = objs self.raw = raw
compiler = 'SQLAggregateCompiler' def add_subquery(self, query, using): self.subquery, self.sub_params = query.get_compiler(using).as_sql( with_col_aliases=True, subquery=True, )
self.pk = target._meta.pk self.proxy_for_model = target self.db_table = target._meta.db_table
if self.proxy or self.swapped or not self.managed: return False if isinstance(connection, six.string_types): connection = connections[connection] if self.required_db_vendor: return self.required_db_vendor == connection.vendor if self.required_db_features: return all(getattr(connection.features, feat, False) for feat in self.required_db_features) return True
with override(None): return force_text(self.verbose_name)
return make_immutable_fields_list( "concrete_fields", (f for f in self.fields if f.concrete) )
return make_immutable_fields_list( "local_concrete_fields", (f for f in self.local_fields if f.concrete) )
return make_immutable_fields_list( "many_to_many", (f for f in self._get_fields(reverse=False) if f.is_relation and f.many_to_many) )
all_related_fields = self._get_fields(forward=False, reverse=True, include_hidden=True) return make_immutable_fields_list( "related_objects", (obj for obj in all_related_fields if not obj.hidden or obj.field.many_to_many) )
if not self.parents: return [] if model in self.parents: return [model] for parent in self.parents: res = parent._meta.get_base_chain(model) if res: res.insert(0, parent) return res return []
result = OrderedSet(self.parents) for parent in self.parents: for ancestor in parent._meta.get_parent_list(): result.add(ancestor) return list(result)
if include_parents is False: include_parents = PROXY_PARENTS return self._get_fields(include_parents=include_parents, include_hidden=include_hidden)
return '%s.%s' % (self.model._meta.label, self.name)
self.creation_counter = BaseManager.creation_counter BaseManager.creation_counter += 1
return self._queryset_class(model=self.model, using=self._db, hints=self._hints)
bilateral = False arity = 1 @property def lhs(self): return self.get_source_expressions()[0] def get_bilateral_transforms(self): if hasattr(self.lhs, 'get_bilateral_transforms'): bilateral_transforms = self.lhs.get_bilateral_transforms() else: bilateral_transforms = [] if self.bilateral: bilateral_transforms.append(self.__class__) return bilateral_transforms
get_db_prep_lookup_value_is_iterable = True
def get_prep_lookup(self): if isinstance(self.rhs, float): self.rhs = math.ceil(self.rhs) return super(IntegerFieldFloatRounding, self).get_prep_lookup()
if not objs: return model = objs[0].__class__ self.field_updates.setdefault( model, {}).setdefault( (field, value), set()).update(objs)
conn_batch_size = max( connections[self.using].ops.bulk_batch_size([field.name], objs), 1) if len(objs) > conn_batch_size: return [objs[i:i + conn_batch_size] for i in range(0, len(objs), conn_batch_size)] else: return [objs]
return related.related_model._base_manager.using(self.using).filter( **{"%s__in" % related.field.name: objs} )
cursor.execute("SHOW FULL TABLES") return [TableInfo(row[0], {'BASE TABLE': 't', 'VIEW': 'v'}.get(row[1])) for row in cursor.fetchall()]
constraints = self.get_key_columns(cursor, table_name) relations = {} for my_fieldname, other_table, other_field in constraints: relations[my_fieldname] = (other_field, other_table) return relations
cursor.execute( "SELECT engine " "FROM information_schema.tables " "WHERE table_name = %s", [table_name]) result = cursor.fetchone() if not result: return self.connection.features._mysql_storage_engine return result[0]
return [(None, ("NULL", [], False))]
if connector == '^': return 'POW(%s)' % ','.join(sub_expressions) return super(DatabaseOperations, self).combine_expression(connector, sub_expressions)
db_type = field.db_type(self.connection) return ( db_type is not None and db_type.lower() in { 'tinyblob', 'blob', 'mediumblob', 'longblob', 'tinytext', 'text', 'mediumtext', 'longtext', } )
first_field = model._meta.get_field(fields[0]) if first_field.get_internal_type() == 'ForeignKey': constraint_names = self._constraint_names(model, [first_field.column], index=True) if not constraint_names: self.execute(self._create_index_sql(model, [first_field], suffix="")) return super(DatabaseSchemaEditor, self)._delete_composed_index(model, fields, *args)
if field.null: new_type += " NULL" else: new_type += " NOT NULL" return new_type
self.cursor().execute('SET foreign_key_checks=0') return True
primary_key_column_name, column_name, table_name, referenced_table_name, column_name, referenced_column_name, column_name, referenced_column_name, )
return [item[0] for item in cursor.fetchall()]
return 63
if new_type.lower() in ("serial", "bigserial"): column = new_field.column sequence_name = "%s_%s_seq" % (table, column) col_type = "integer" if new_type.lower() == "serial" else "bigint" return ( ( self.sql_alter_column_type % { "column": self.quote_name(column), "type": col_type, }, [], ), [ ( self.sql_delete_sequence % { "sequence": self.quote_name(sequence_name), }, [], ), ( self.sql_create_sequence % { "sequence": self.quote_name(sequence_name), }, [], ), ( self.sql_alter_column % { "table": self.quote_name(table), "changes": self.sql_alter_column_default % { "column": self.quote_name(column), "default": "nextval('%s')" % self.quote_name(sequence_name), } }, [], ), ( self.sql_set_sequence_max % { "table": self.quote_name(table), "column": self.quote_name(column), "sequence": self.quote_name(sequence_name), }, [], ), ], ) else: return super(DatabaseSchemaEditor, self)._alter_column_type_sql( table, old_field, new_field, new_type )
self.cursor().execute('SET CONSTRAINTS ALL IMMEDIATE') self.cursor().execute('SET CONSTRAINTS ALL DEFERRED')
return txt.replace('\\', '\\\\').replace(':', '\\:')
cursor.execute("SELECT TABLE_NAME, 't' FROM USER_TABLES UNION ALL " "SELECT VIEW_NAME, 'v' FROM USER_VIEWS") return [TableInfo(row[0].lower(), row[1]) for row in cursor.fetchall()]
return {d[0]: i for i, d in enumerate(self.get_table_description(cursor, table_name))}
minutes, seconds = divmod(timedelta.seconds, 60) hours, minutes = divmod(minutes, 60) days = str(timedelta.days) day_precision = len(days) fmt = "INTERVAL '%s %02d:%02d:%02d.%06d' DAY(%d) TO SECOND(6)" return fmt % (days, hours, minutes, seconds, timedelta.microseconds, day_precision), []
return value
nn = self.quote_name(name) if nn[0] == '"' and nn[-1] == '"': nn = nn[1:-1] return nn
suffix = hex(hash(for_name)).upper()[1:] return self.normalize_name(for_name + "_" + suffix)
settings_dict = settings.DATABASES[self.connection.alias] user = settings_dict.get('SAVED_USER') or settings_dict['USER'] password = settings_dict.get('SAVED_PASSWORD') or settings_dict['PASSWORD'] settings_dict = settings_dict.copy() settings_dict.update(USER=user, PASSWORD=password) DatabaseWrapper = type(self.connection) return DatabaseWrapper(settings_dict, alias=self.connection.alias)
real_settings = settings.DATABASES[self.connection.alias] real_settings['SAVED_USER'] = self.connection.settings_dict['SAVED_USER'] = \ self.connection.settings_dict['USER'] real_settings['SAVED_PASSWORD'] = self.connection.settings_dict['SAVED_PASSWORD'] = \ self.connection.settings_dict['PASSWORD'] real_test_settings = real_settings['TEST'] test_settings = self.connection.settings_dict['TEST'] real_test_settings['USER'] = real_settings['USER'] = test_settings['USER'] = \ self.connection.settings_dict['USER'] = parameters['user'] real_settings['PASSWORD'] = self.connection.settings_dict['PASSWORD'] = parameters['password']
self.connection.settings_dict['USER'] = primary_settings_dict['USER'] self.connection.settings_dict['PASSWORD'] = primary_settings_dict['PASSWORD']
settings_dict = self.connection.settings_dict val = settings_dict['TEST'].get(key, default) if val is None: val = TEST_DATABASE_PREFIX + settings_dict[prefixed] return val
return self.connection.settings_dict['NAME']
def __init__(self, expression, **extra): output_field = extra.pop('output_field', DecimalField()) super(IntervalToSeconds, self).__init__(expression, output_field=output_field, **extra)
self.cursor().execute('SET CONSTRAINTS ALL IMMEDIATE') self.cursor().execute('SET CONSTRAINTS ALL DEFERRED')
def __init__(self, var): self.var = var def bind_parameter(self, cursor): return self.var def __getattr__(self, key): return getattr(self.var, key) def __setattr__(self, key, value): if key == 'var': self.__dict__[key] = value else: setattr(self.var, key, value)
def __init__(self, cursor): self.cursor = cursor self.iter = iter(cursor) def __iter__(self): return self def __next__(self): return _rowfactory(next(self.iter), self.cursor)
if self.connection.oracle_full_version < '11.2.0.2' and field and field.has_default() and created_separately: return 'IntegerField' return super(DatabaseFeatures, self).introspected_boolean_field_type(field, created_separately)
def bind_parameter(self, cursor): param = cursor.cursor.var(Database.NUMBER) cursor._insert_id_var = param return param
input_size = Database.TIMESTAMP @classmethod def from_datetime(cls, dt): return Oracle_datetime( dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second, dt.microsecond, )
def __init__(self, connection): self.connection = connection def check(self, **kwargs): return [] def check_field(self, field, **kwargs): return []
return self.data_types_reverse[data_type]
return name
return self.table_name_converter(name)
def get_names(cursor): return sorted(ti.name for ti in self.get_table_list(cursor) if include_views or ti.type == 't') if cursor is None: with self.connection.cursor() as cursor: return get_names(cursor) return get_names(cursor)
raise NotImplementedError('subclasses of BaseDatabaseIntrospection may require a get_table_list() method')
from django.apps import apps from django.db import router tables = set() for app_config in apps.get_app_configs(): for model in router.get_migratable_models(app_config, self.connection.alias): if not model._meta.managed: continue tables.add(model._meta.db_table) tables.update( f.m2m_db_table() for f in model._meta.local_many_to_many if f.remote_field.through._meta.managed ) tables = list(tables) if only_existing: existing_tables = self.table_names(include_views=include_views) tables = [ t for t in tables if self.table_name_converter(t) in existing_tables ] return tables
raise NotImplementedError('subclasses of BaseDatabaseIntrospection may require a get_key_columns() method')
for column in six.iteritems(self.get_indexes(cursor, table_name)): if column[1]['primary_key']: return column[0] return None
raise NotImplementedError('subclasses of BaseDatabaseIntrospection may require a get_indexes() method')
return None
return len(objs)
return "SELECT cache_key FROM %s ORDER BY cache_key LIMIT 1 OFFSET %%s"
return '%s'
raise NotImplementedError('subclasses of BaseDatabaseOperations may require a date_extract_sql() method')
raise NotImplementedError('subclasses of BaseDatabaseOperations may require a date_interval_sql() method')
raise NotImplementedError('subclasses of BaseDatabaseOperations may require a datetrunc_sql() method')
raise NotImplementedError('subclasses of BaseDatabaseOperations may require a datetime_cast_date() method')
raise NotImplementedError('subclasses of BaseDatabaseOperations may require a datetime_extract_sql() method')
raise NotImplementedError('subclasses of BaseDatabaseOperations may require a datetime_trunk_sql() method')
return self.date_extract_sql(lookup_type, field_name)
return ''
if fields: raise NotImplementedError('DISTINCT ON fields is not supported by this database backend') else: return 'DISTINCT'
return "DROP CONSTRAINT"
return None
return cursor.fetchone()[0]
return '%s'
return []
if nowait: return 'FOR UPDATE NOWAIT' else: return 'FOR UPDATE'
return cursor.lastrowid
return "%s"
return None
return None
raise NotImplementedError('subclasses of BaseDatabaseOperations may require a no_limit_value() method')
return 'DEFAULT'
try: import sqlparse except ImportError: raise ImproperlyConfigured( "sqlparse is required if you don't split your SQL " "statements manually." ) else: return [sqlparse.format(statement, strip_comments=True) for statement in sqlparse.split(sql) if statement]
return value
pass
if self._cache is None: self._cache = import_module(self.compiler_module) return getattr(self._cache, compiler_name)
raise NotImplementedError('subclasses of BaseDatabaseOperations may require a quote_name() method')
return 'RANDOM()'
raise NotImplementedError('subclasses of BaseDatabaseOperations may require a regex_lookup() method')
return "SAVEPOINT %s" % self.quote_name(sid)
return "RELEASE SAVEPOINT %s" % self.quote_name(sid)
return "ROLLBACK TO SAVEPOINT %s" % self.quote_name(sid)
return ''
raise NotImplementedError('subclasses of BaseDatabaseOperations must provide an sql_flush() method')
return []
return "BEGIN;"
if not success: return "ROLLBACK;" return "COMMIT;"
return ''
return value
if value is None: return None return six.text_type(value)
if value is None: return None return six.text_type(value)
if value is None: return None if timezone.is_aware(value): raise ValueError("Django does not support timezone-aware times.") return six.text_type(value)
return utils.format_number(value, max_digits, decimal_places)
return value or None
first = datetime.date(value, 1, 1) second = datetime.date(value, 12, 31) first = self.adapt_datefield_value(first) second = self.adapt_datefield_value(second) return [first, second]
first = datetime.datetime(value, 1, 1) second = datetime.datetime(value, 12, 31, 23, 59, 59, 999999) if settings.USE_TZ: tz = timezone.get_current_timezone() first = timezone.make_aware(first, tz) second = timezone.make_aware(second, tz) first = self.adapt_datetimefield_value(first) second = self.adapt_datetimefield_value(second) return [first, second]
return []
pass
conn = ' %s ' % connector return conn.join(sub_expressions)
return '%s'
return params
return self.integer_field_ranges[internal_type]
return False
raise NotImplementedError( 'subclasses of BaseDatabaseSchemaEditor for backends which have ' 'requires_literal_defaults must provide a prepare_default() method' )
if old_db_table == new_db_table: return self.execute(self.sql_rename_table % { "old_table": self.quote_name(old_db_table), "new_table": self.quote_name(new_db_table), })
self.execute(self.sql_retablespace_table % { "table": self.quote_name(model._meta.db_table), "old_tablespace": self.quote_name(old_db_tablespace), "new_tablespace": self.quote_name(new_db_tablespace), })
return ( ( self.sql_alter_column_type % { "column": self.quote_name(new_field.column), "type": new_type, }, [], ), [], )
if len(fields) == 1 and fields[0].db_tablespace: tablespace_sql = self.connection.ops.tablespace_sql(fields[0].db_tablespace) elif model._meta.db_tablespace: tablespace_sql = self.connection.ops.tablespace_sql(model._meta.db_tablespace) else: tablespace_sql = "" if tablespace_sql: tablespace_sql = " " + tablespace_sql columns = [field.column for field in fields] sql_create_index = sql or self.sql_create_index return sql_create_index % { "table": self.quote_name(model._meta.db_table), "name": self.quote_name(self._create_index_name(model, columns, suffix=suffix)), "columns": ", ".join(self.quote_name(column) for column in columns), "extra": tablespace_sql, }
if not model._meta.managed or model._meta.proxy or model._meta.swapped: return [] output = [] for field in model._meta.local_fields: if field.db_index and not field.unique: output.append(self._create_index_sql(model, [field], suffix="")) for field_names in model._meta.index_together: fields = [model._meta.get_field(field) for field in field_names] output.append(self._create_index_sql(model, fields, suffix="_idx")) return output
return self.connection._nodb_connection
self.connection.settings_dict['NAME'] = primary_settings_dict['NAME']
data = StringIO(data) for obj in serializers.deserialize("json", data, using=self.connection.alias): obj.save()
return "'%s'%s" % ( self.connection.alias, (" ('%s')" % database_name) if verbosity >= 2 else '', )
if self.connection.settings_dict['TEST']['NAME']: return self.connection.settings_dict['TEST']['NAME'] return TEST_DATABASE_PREFIX + self.connection.settings_dict['NAME']
raise NotImplementedError( "The database backend doesn't support cloning databases. " "Disable the option to run tests in parallel processes.")
return ''
if not settings.USE_TZ: return settings.TIME_ZONE elif self.settings_dict['TIME_ZONE'] is None: return 'UTC' else: return self.settings_dict['TIME_ZONE']
raise NotImplementedError('subclasses of BaseDatabaseWrapper may require a get_connection_params() method')
raise NotImplementedError('subclasses of BaseDatabaseWrapper may require a get_new_connection() method')
raise NotImplementedError('subclasses of BaseDatabaseWrapper may require an init_connection_state() method')
self.validate_thread_sharing() if self.queries_logged: cursor = self.make_debug_cursor(self._cursor()) else: cursor = self.make_cursor(self._cursor()) return cursor
if not self._savepoint_allowed(): return thread_ident = thread.get_ident() tid = str(thread_ident).replace('-', '') self.savepoint_state += 1 sid = "s%s_x%d" % (tid, self.savepoint_state) self.validate_thread_sharing() self._savepoint(sid) return sid
if not self._savepoint_allowed(): return self.validate_thread_sharing() self._savepoint_commit(sid)
self.ensure_connection() return self.autocommit
self.validate_no_atomic_block() self.ensure_connection() start_transaction_under_autocommit = ( force_begin_transaction_with_broken_autocommit and not autocommit and self.features.autocommits_when_autocommit_is_off ) if start_transaction_under_autocommit: self._start_transaction_under_autocommit() else: self._set_autocommit(autocommit) self.autocommit = autocommit if autocommit and self.run_commit_hooks_on_set_autocommit_on: self.run_and_clear_commit_hooks() self.run_commit_hooks_on_set_autocommit_on = False
if not self.in_atomic_block: raise TransactionManagementError( "The rollback flag doesn't work outside of an 'atomic' block.") return self.needs_rollback
if not self.in_atomic_block: raise TransactionManagementError( "The rollback flag doesn't work outside of an 'atomic' block.") self.needs_rollback = rollback
if self.in_atomic_block: raise TransactionManagementError( "This is forbidden when an 'atomic' block is active.")
disabled = self.disable_constraint_checking() try: yield finally: if disabled: self.enable_constraint_checking()
return False
pass
raise NotImplementedError( "subclasses of BaseDatabaseWrapper may require an is_usable() method")
pass
return DatabaseErrorWrapper(self)
return utils.CursorDebugWrapper(cursor, self)
return utils.CursorWrapper(cursor, self)
must_close = self.connection is None cursor = self.cursor() try: yield cursor finally: cursor.close() if must_close: self.close()
settings_dict = self.settings_dict.copy() settings_dict['NAME'] = None nodb_connection = self.__class__( settings_dict, alias=NO_DB_ALIAS, allow_thread_sharing=False) return nodb_connection
raise NotImplementedError( 'subclasses of BaseDatabaseWrapper may require a ' '_start_transaction_under_autocommit() method' )
if self.SchemaEditorClass is None: raise NotImplementedError( 'The SchemaEditorClass attribute of this database wrapper is still None') return self.SchemaEditorClass(self, *args, **kwargs)
with self.connection.cursor() as cursor: cursor.execute('CREATE TABLE ROLLBACK_TEST (X INT)') self.connection.set_autocommit(False) cursor.execute('INSERT INTO ROLLBACK_TEST (X) VALUES (8)') self.connection.rollback() self.connection.set_autocommit(True) cursor.execute('SELECT COUNT(X) FROM ROLLBACK_TEST') count, = cursor.fetchone() cursor.execute('DROP TABLE ROLLBACK_TEST') return count == 0
try: self.connection.ops.check_expression_support(StdDev(1)) return True except NotImplementedError: return False
if self.can_introspect_null and field and field.null: return 'NullBooleanField' return 'BooleanField'
limit = 999 if len(fields) > 1 else 500 return (limit // len(fields)) if len(fields) > 0 else len(objs)
return sql
self._remake_table(model, override_indexes=new_index_together)
self._remake_table(model, override_uniques=new_unique_together)
% ( primary_key_column_name, column_name, table_name, referenced_table_name, column_name, referenced_column_name, column_name, referenced_column_name, )
self.cursor().execute("BEGIN")
def execute(self, query, params=None): if params is None: return Database.Cursor.execute(self, query) query = self.convert_query(query) return Database.Cursor.execute(self, query, params) def executemany(self, query, param_list): query = self.convert_query(query) return Database.Cursor.executemany(self, query, param_list) def convert_query(self, query): return FORMAT_QMARK_REGEX.sub('?', query).replace('%%', '%')
with self.connection.cursor() as cursor: cursor.execute('CREATE TABLE STDDEV_TEST (X INT)') try: cursor.execute('SELECT STDDEV(*) FROM STDDEV_TEST') has_support = True except utils.DatabaseError: has_support = False cursor.execute('DROP TABLE STDDEV_TEST') return has_support
if isinstance(model, six.string_types): return model.split(".", 1) else: return model._meta.app_label, model._meta.object_name
def deconstruct(self): kwargs = { 'name': self.name, } return ( self.__class__.__name__, [], kwargs ) def state_forwards(self, app_label, state): state.remove_model(app_label, self.name_lower) def database_forwards(self, app_label, schema_editor, from_state, to_state): model = from_state.apps.get_model(app_label, self.name) if self.allow_migrate_model(schema_editor.connection.alias, model): schema_editor.delete_model(model) def database_backwards(self, app_label, schema_editor, from_state, to_state): model = to_state.apps.get_model(app_label, self.name) if self.allow_migrate_model(schema_editor.connection.alias, model): schema_editor.create_model(model) def describe(self): return "Delete model %s" % (self.name, )
option_name = "unique_together" def __init__(self, name, unique_together): unique_together = normalize_together(unique_together) self.unique_together = set(tuple(cons) for cons in unique_together) super(AlterUniqueTogether, self).__init__(name) def deconstruct(self): kwargs = { 'name': self.name, 'unique_together': self.unique_together, } return ( self.__class__.__name__, [], kwargs ) def state_forwards(self, app_label, state): model_state = state.models[app_label, self.name_lower] model_state.options[self.option_name] = self.unique_together state.reload_model(app_label, self.name_lower) def database_forwards(self, app_label, schema_editor, from_state, to_state): new_model = to_state.apps.get_model(app_label, self.name) if self.allow_migrate_model(schema_editor.connection.alias, new_model): old_model = from_state.apps.get_model(app_label, self.name) schema_editor.alter_unique_together( new_model, getattr(old_model._meta, self.option_name, set()), getattr(new_model._meta, self.option_name, set()), ) def database_backwards(self, app_label, schema_editor, from_state, to_state): return self.database_forwards(app_label, schema_editor, from_state, to_state) def references_field(self, model_name, name, app_label=None): return ( self.references_model(model_name, app_label) and ( not self.unique_together or any((name in together) for together in self.unique_together) ) ) def describe(self): return "Alter %s for %s (%s constraint(s))" % (self.option_name, self.name, len(self.unique_together or ''))
option_name = "index_together" def __init__(self, name, index_together): index_together = normalize_together(index_together) self.index_together = set(tuple(cons) for cons in index_together) super(AlterIndexTogether, self).__init__(name) def deconstruct(self): kwargs = { 'name': self.name, 'index_together': self.index_together, } return ( self.__class__.__name__, [], kwargs ) def state_forwards(self, app_label, state): model_state = state.models[app_label, self.name_lower] model_state.options[self.option_name] = self.index_together state.reload_model(app_label, self.name_lower) def database_forwards(self, app_label, schema_editor, from_state, to_state): new_model = to_state.apps.get_model(app_label, self.name) if self.allow_migrate_model(schema_editor.connection.alias, new_model): old_model = from_state.apps.get_model(app_label, self.name) schema_editor.alter_index_together( new_model, getattr(old_model._meta, self.option_name, set()), getattr(new_model._meta, self.option_name, set()), ) def database_backwards(self, app_label, schema_editor, from_state, to_state): return self.database_forwards(app_label, schema_editor, from_state, to_state) def references_field(self, model_name, name, app_label=None): return ( self.references_model(model_name, app_label) and ( not self.index_together or any((name in together) for together in self.index_together) ) ) def describe(self): return "Alter %s for %s (%s constraint(s))" % (self.option_name, self.name, len(self.index_together or ''))
serialization_expand_args = ['managers'] def __init__(self, name, managers): self.managers = managers super(AlterModelManagers, self).__init__(name) def deconstruct(self): return ( self.__class__.__name__, [self.name, self.managers], {} ) def state_forwards(self, app_label, state): model_state = state.models[app_label, self.name_lower] model_state.managers = list(self.managers) state.reload_model(app_label, self.name_lower) def database_forwards(self, app_label, schema_editor, from_state, to_state): pass def database_backwards(self, app_label, schema_editor, from_state, to_state): pass def describe(self): return "Change managers on %s" % (self.name, )
return ( self.__class__.__name__, self._constructor_args[0], self._constructor_args[1], )
raise NotImplementedError('subclasses of Operation must provide a state_forwards() method')
raise NotImplementedError('subclasses of Operation must provide a database_forwards() method')
raise NotImplementedError('subclasses of Operation must provide a database_backwards() method')
return "%s: %s" % (self.__class__.__name__, self._constructor_args)
return True
return self.references_model(model_name, app_label)
if not model._meta.can_migrate(connection_alias): return False return router.allow_migrate_model(connection_alias, model)
if self.elidable: return [operation] elif operation.elidable: return [self] return False
noop = '' def __init__(self, sql, reverse_sql=None, state_operations=None, hints=None, elidable=False): self.sql = sql self.reverse_sql = reverse_sql self.state_operations = state_operations or [] self.hints = hints or {} self.elidable = elidable def deconstruct(self): kwargs = { 'sql': self.sql, } if self.reverse_sql is not None: kwargs['reverse_sql'] = self.reverse_sql if self.state_operations: kwargs['state_operations'] = self.state_operations if self.hints: kwargs['hints'] = self.hints return ( self.__class__.__name__, [], kwargs ) @property def reversible(self): return self.reverse_sql is not None def state_forwards(self, app_label, state): for state_operation in self.state_operations: state_operation.state_forwards(app_label, state) def database_forwards(self, app_label, schema_editor, from_state, to_state): if router.allow_migrate(schema_editor.connection.alias, app_label, **self.hints): self._run_sql(schema_editor, self.sql) def database_backwards(self, app_label, schema_editor, from_state, to_state): if self.reverse_sql is None: raise NotImplementedError("You cannot reverse this operation") if router.allow_migrate(schema_editor.connection.alias, app_label, **self.hints): self._run_sql(schema_editor, self.reverse_sql) def describe(self): return "Raw SQL operation" def _run_sql(self, schema_editor, sqls): if isinstance(sqls, (list, tuple)): for sql in sqls: params = None if isinstance(sql, (list, tuple)): elements = len(sql) if elements == 2: sql, params = sql else: raise ValueError("Expected a 2-tuple but got %d" % elements) schema_editor.execute(sql, params=params) elif sqls != RunSQL.noop: statements = schema_editor.connection.ops.prepare_sql_script(sqls) for statement in statements: schema_editor.execute(statement, params=None)
def deconstruct(self): kwargs = { 'model_name': self.model_name, 'name': self.name, } return ( self.__class__.__name__, [], kwargs ) def state_forwards(self, app_label, state): new_fields = [] for name, instance in state.models[app_label, self.model_name_lower].fields: if name != self.name: new_fields.append((name, instance)) state.models[app_label, self.model_name_lower].fields = new_fields state.reload_model(app_label, self.model_name_lower) def database_forwards(self, app_label, schema_editor, from_state, to_state): from_model = from_state.apps.get_model(app_label, self.model_name) if self.allow_migrate_model(schema_editor.connection.alias, from_model): schema_editor.remove_field(from_model, from_model._meta.get_field(self.name)) def database_backwards(self, app_label, schema_editor, from_state, to_state): to_model = to_state.apps.get_model(app_label, self.model_name) if self.allow_migrate_model(schema_editor.connection.alias, to_model): from_model = from_state.apps.get_model(app_label, self.model_name) schema_editor.add_field(from_model, to_model._meta.get_field(self.name)) def describe(self): return "Remove field %s from %s" % (self.name, self.model_name)
def __init__(self, model_name, name, field, preserve_default=True): self.field = field self.preserve_default = preserve_default super(AlterField, self).__init__(model_name, name) def deconstruct(self): kwargs = { 'model_name': self.model_name, 'name': self.name, 'field': self.field, } if self.preserve_default is not True: kwargs['preserve_default'] = self.preserve_default return ( self.__class__.__name__, [], kwargs ) def state_forwards(self, app_label, state): if not self.preserve_default: field = self.field.clone() field.default = NOT_PROVIDED else: field = self.field state.models[app_label, self.model_name_lower].fields = [ (n, field if n == self.name else f) for n, f in state.models[app_label, self.model_name_lower].fields ] state.reload_model(app_label, self.model_name_lower) def database_forwards(self, app_label, schema_editor, from_state, to_state): to_model = to_state.apps.get_model(app_label, self.model_name) if self.allow_migrate_model(schema_editor.connection.alias, to_model): from_model = from_state.apps.get_model(app_label, self.model_name) from_field = from_model._meta.get_field(self.name) to_field = to_model._meta.get_field(self.name) if not self.preserve_default: to_field.default = self.field.default schema_editor.alter_field(from_model, from_field, to_field) if not self.preserve_default: to_field.default = NOT_PROVIDED def database_backwards(self, app_label, schema_editor, from_state, to_state): self.database_forwards(app_label, schema_editor, from_state, to_state) def describe(self): return "Alter field %s on %s" % (self.name, self.model_name) def reduce(self, operation, in_between, app_label=None): if isinstance(operation, RemoveField) and self.is_same_field_operation(operation): return [operation] elif isinstance(operation, RenameField) and self.is_same_field_operation(operation): return [ operation, AlterField( model_name=self.model_name, name=operation.new_name, field=self.field, ), ] return super(AlterField, self).reduce(operation, in_between, app_label=app_label)
def __new__(self, value, setting_name): return str.__new__(self, value) def __init__(self, value, setting_name): self.setting_name = setting_name
seen_apps = {} conflicting_apps = set() for app_label, migration_name in self.graph.leaf_nodes(): if app_label in seen_apps: conflicting_apps.add(app_label) seen_apps.setdefault(app_label, set()).add(migration_name) return {app_label: seen_apps[app_label] for app_label in conflicting_apps}
self.ensure_schema() return set(tuple(x) for x in self.migration_qs.values_list("app", "name"))
self.ensure_schema() self.migration_qs.create(app=app, name=name)
self.ensure_schema() self.migration_qs.filter(app=app, name=name).delete()
del self.origin del self.error_message self.__class__ = Node
if child not in self.nodes: error_message = ( "Migration %s dependencies reference nonexistent" " child node %r" % (migration, child) ) self.add_dummy_node(child, migration, error_message) if parent not in self.nodes: error_message = ( "Migration %s dependencies reference nonexistent" " parent node %r" % (migration, parent) ) self.add_dummy_node(parent, migration, error_message) self.node_map[child].add_parent(self.node_map[parent]) self.node_map[parent].add_child(self.node_map[child]) if not skip_validation: self.validate_consistency() self.clear_cache()
[n.raise_error() for n in self.node_map.values() if isinstance(n, DummyNode)]
roots = set() for node in self.nodes: if not any(key[0] == node[0] for key in self.node_map[node].parents) and (not app or app == node[0]): roots.add(node) return sorted(roots)
leaves = set() for node in self.nodes: if not any(key[0] == node[0] for key in self.node_map[node].children) and (not app or app == node[0]): leaves.add(node) return sorted(leaves)
if nodes is None: nodes = list(self.leaf_nodes()) if len(nodes) == 0: return ProjectState() if not isinstance(nodes[0], tuple): nodes = [nodes] plan = [] for node in nodes: for migration in self.forwards_plan(node): if migration not in plan: if not at_end and migration in nodes: continue plan.append(migration) project_state = ProjectState(real_apps=real_apps) for node in plan: project_state = self.nodes[node].mutate_state(project_state, preserve=False) return project_state
new_state = project_state if preserve: new_state = project_state.clone() for operation in self.operations: operation.state_forwards(self.app_label, new_state) return new_state
def __new__(cls, value, setting): self = tuple.__new__(cls, value) self.setting = setting return self
pass
pass
pass
pass
pass
pass
def __init__(self, message, node, origin=None): self.message = message self.origin = origin self.node = node def __str__(self): return self.message def __repr__(self): return "NodeNotFoundError(%r)" % (self.node, )
statements = [] state = None for migration, backwards in plan: with self.connection.schema_editor(collect_sql=True, atomic=migration.atomic) as schema_editor: if state is None: state = self.loader.project_state((migration.app_label, migration.name), at_end=False) if not backwards: state = migration.apply(state, schema_editor, collect_sql=True) else: state = migration.unapply(state, schema_editor, collect_sql=True) statements.extend(schema_editor.collected_sql) return statements
applied = self.recorder.applied_migrations() for key, migration in self.loader.replacements.items(): all_applied = all(m in applied for m in migration.replaces) if all_applied and key not in applied: self.recorder.record_applied(*key)
seen = set() queue = _get_related_models(model) for rel_mod in queue: rel_app_label, rel_model_name = rel_mod._meta.app_label, rel_mod._meta.model_name if (rel_app_label, rel_model_name) in seen: continue seen.add((rel_app_label, rel_model_name)) queue.extend(_get_related_models(rel_mod)) return seen - {(model._meta.app_label, model._meta.model_name)}
changes = self._detect_changes(convert_apps, graph) changes = self.arrange_for_graph(changes, graph, migration_name) if trim_to_apps: changes = self._trim_to_apps(changes, trim_to_apps) return changes
fields_def = [] for name, field in sorted(fields): deconstruction = self.deep_deconstruct(field) if field.remote_field and field.remote_field.model: del deconstruction[2]['to'] fields_def.append(deconstruction) return fields_def
self.kept_model_keys = set(self.old_model_keys).intersection(self.new_model_keys) self.kept_proxy_keys = set(self.old_proxy_keys).intersection(self.new_proxy_keys) self.kept_unmanaged_keys = set(self.old_unmanaged_keys).intersection(self.new_unmanaged_keys) self.through_users = {} self.old_field_keys = set() self.new_field_keys = set() for app_label, model_name in sorted(self.kept_model_keys): old_model_name = self.renamed_models.get((app_label, model_name), model_name) old_model_state = self.from_state.models[app_label, old_model_name] new_model_state = self.to_state.models[app_label, model_name] self.old_field_keys.update((app_label, model_name, x) for x, y in old_model_state.fields) self.new_field_keys.update((app_label, model_name, x) for x, y in new_model_state.fields)
for app_label, model_name in sorted(self.old_model_keys): old_model_name = self.renamed_models.get((app_label, model_name), model_name) old_model_state = self.from_state.models[app_label, old_model_name] for field_name, field in old_model_state.fields: old_field = self.old_apps.get_model(app_label, old_model_name)._meta.get_field(field_name) if (hasattr(old_field, "remote_field") and getattr(old_field.remote_field, "through", None) and not old_field.remote_field.through._meta.auto_created): through_key = ( old_field.remote_field.through._meta.app_label, old_field.remote_field.through._meta.model_name, ) self.through_users[through_key] = (app_label, old_model_name, field_name)
try: model = self.new_apps.get_model(item[0], item[1]) base_names = [base.__name__ for base in model.__bases__] string_version = "%s.%s" % (item[0], item[1]) if ( model._meta.swappable or "AbstractUser" in base_names or "AbstractBaseUser" in base_names or settings.AUTH_USER_MODEL.lower() == string_version.lower() ): return ("___" + item[0], "___" + item[1]) except LookupError: pass return item
self.renamed_models = {} self.renamed_models_rel = {} added_models = set(self.new_model_keys) - set(self.old_model_keys) for app_label, model_name in sorted(added_models): model_state = self.to_state.models[app_label, model_name] model_fields_def = self.only_relation_agnostic_fields(model_state.fields) removed_models = set(self.old_model_keys) - set(self.new_model_keys) for rem_app_label, rem_model_name in removed_models: if rem_app_label == app_label: rem_model_state = self.from_state.models[rem_app_label, rem_model_name] rem_model_fields_def = self.only_relation_agnostic_fields(rem_model_state.fields) if model_fields_def == rem_model_fields_def: if self.questioner.ask_rename_model(rem_model_state, model_state): self.add_operation( app_label, operations.RenameModel( old_name=rem_model_state.name, new_name=model_state.name, ) ) self.renamed_models[app_label, model_name] = rem_model_name renamed_models_rel_key = '%s.%s' % (rem_model_state.app_label, rem_model_state.name) self.renamed_models_rel[renamed_models_rel_key] = '%s.%s' % ( model_state.app_label, model_state.name, ) self.old_model_keys.remove((rem_app_label, rem_model_name)) self.old_model_keys.append((app_label, model_name)) break
deleted = set(self.old_proxy_keys) - set(self.new_proxy_keys) for app_label, model_name in sorted(deleted): model_state = self.from_state.models[app_label, model_name] assert model_state.options.get("proxy") self.add_operation( app_label, operations.DeleteModel( name=model_state.name, ), )
for app_label, model_name, field_name in sorted(self.new_field_keys - self.old_field_keys): self._generate_added_field(app_label, model_name, field_name)
for app_label, model_name, field_name in sorted(self.old_field_keys - self.new_field_keys): self._generate_removed_field(app_label, model_name, field_name)
if len(ops) == 1: if isinstance(ops[0], operations.CreateModel): return ops[0].name_lower elif isinstance(ops[0], operations.DeleteModel): return "delete_%s" % ops[0].name_lower elif isinstance(ops[0], operations.AddField): return "%s_%s" % (ops[0].model_name_lower, ops[0].name_lower) elif isinstance(ops[0], operations.RemoveField): return "remove_%s_%s" % (ops[0].model_name_lower, ops[0].name_lower) elif len(ops) > 1: if all(isinstance(o, operations.CreateModel) for o in ops): return "_".join(sorted(o.name_lower for o in ops)) return "auto_%s" % get_migration_name_timestamp()
pass
if using is None: using = DEFAULT_DB_ALIAS return connections[using]
return get_connection(using).get_autocommit()
return get_connection(using).set_autocommit(autocommit)
get_connection(using).commit()
get_connection(using).rollback()
return get_connection(using).savepoint()
get_connection(using).savepoint_rollback(sid)
get_connection(using).savepoint_commit(sid)
get_connection(using).clean_savepoints()
return get_connection(using).get_rollback()
return get_connection(using).set_rollback(rollback)
get_connection(using).on_commit(func)
self.wrapper = wrapper
self._databases = databases self._connections = local()
try: conn = self.databases[alias] except KeyError: raise ConnectionDoesNotExist("The connection %s doesn't exist" % alias) conn.setdefault('ATOMIC_REQUESTS', False) conn.setdefault('AUTOCOMMIT', True) conn.setdefault('ENGINE', 'django.db.backends.dummy') if conn['ENGINE'] == 'django.db.backends.' or not conn['ENGINE']: conn['ENGINE'] = 'django.db.backends.dummy' conn.setdefault('CONN_MAX_AGE', 0) conn.setdefault('OPTIONS', {}) conn.setdefault('TIME_ZONE', None) for setting in ['NAME', 'USER', 'PASSWORD', 'HOST', 'PORT']: conn.setdefault(setting, '')
try: conn = self.databases[alias] except KeyError: raise ConnectionDoesNotExist("The connection %s doesn't exist" % alias) test_settings = conn.setdefault('TEST', {}) for key in ['CHARSET', 'COLLATION', 'NAME', 'MIRROR']: test_settings.setdefault(key, None)
self._routers = routers
if not (self.inverse_match is not bool(self.regex.search( force_text(value)))): raise ValidationError(self.message, code=self.code)
if protocol != 'both' and unpack_ipv4: raise ValueError( "You can only use `unpack_ipv4` if `protocol` is set to 'both'") try: return ip_address_validator_map[protocol.lower()] except KeyError: raise ValueError("The protocol '%s' is unknown. Supported: %s" % (protocol, list(ip_address_validator_map)))
return self._open(name, mode)
return get_valid_filename(name)
raise NotImplementedError('subclasses of Storage must provide a delete() method')
raise NotImplementedError('subclasses of Storage must provide an exists() method')
raise NotImplementedError('subclasses of Storage must provide a listdir() method')
raise NotImplementedError('subclasses of Storage must provide a size() method')
raise NotImplementedError('subclasses of Storage must provide a url() method')
warnings.warn( 'Storage.accessed_time() is deprecated in favor of get_accessed_time().', RemovedInDjango20Warning, stacklevel=2, ) raise NotImplementedError('subclasses of Storage must provide an accessed_time() method')
warnings.warn( 'Storage.created_time() is deprecated in favor of get_created_time().', RemovedInDjango20Warning, stacklevel=2, ) raise NotImplementedError('subclasses of Storage must provide a created_time() method')
warnings.warn( 'Storage.modified_time() is deprecated in favor of get_modified_time().', RemovedInDjango20Warning, stacklevel=2, ) raise NotImplementedError('subclasses of Storage must provide a modified_time() method')
if setting == 'MEDIA_ROOT': self.__dict__.pop('base_location', None) self.__dict__.pop('location', None) elif setting == 'MEDIA_URL': self.__dict__.pop('base_url', None) elif setting == 'FILE_UPLOAD_PERMISSIONS': self.__dict__.pop('file_permissions_mode', None) elif setting == 'FILE_UPLOAD_DIRECTORY_PERMISSIONS': self.__dict__.pop('directory_permissions_mode', None)
return self.file.name
def _get_width(self): return self._get_image_dimensions()[0] width = property(_get_width) def _get_height(self): return self._get_image_dimensions()[1] height = property(_get_height) def _get_image_dimensions(self): if not hasattr(self, '_dimensions_cache'): close = self.closed self.open() self._dimensions_cache = get_image_dimensions(self, close=close) return self._dimensions_cache
return f.fileno() if hasattr(f, 'fileno') else f
if not chunk_size: chunk_size = self.DEFAULT_CHUNK_SIZE try: self.seek(0) except (AttributeError, UnsupportedOperation): pass while True: data = self.read(chunk_size) if not data: break yield data
if not chunk_size: chunk_size = self.DEFAULT_CHUNK_SIZE return self.size > chunk_size
return line.endswith('\r' if isinstance(line, six.text_type) else b'\r')
return line.endswith('\n' if isinstance(line, six.text_type) else b'\n')
encoding = property(lambda self: self.file.encoding) fileno = property(lambda self: self.file.fileno) flush = property(lambda self: self.file.flush) isatty = property(lambda self: self.file.isatty) newlines = property(lambda self: self.file.newlines) read = property(lambda self: self.file.read) readinto = property(lambda self: self.file.readinto) readline = property(lambda self: self.file.readline) readlines = property(lambda self: self.file.readlines) seek = property(lambda self: self.file.seek) softspace = property(lambda self: self.file.softspace) tell = property(lambda self: self.file.tell) truncate = property(lambda self: self.file.truncate) write = property(lambda self: self.file.write) writelines = property(lambda self: self.file.writelines) xreadlines = property(lambda self: self.file.xreadlines) @property def closed(self): return not self.file or self.file.closed def readable(self): if self.closed: return False if hasattr(self.file, 'readable'): return self.file.readable() return True def writable(self): if self.closed: return False if hasattr(self.file, 'writable'): return self.file.writable() return 'w' in getattr(self.file, 'mode', '') def seekable(self): if self.closed: return False if hasattr(self.file, 'seekable'): return self.file.seekable() return True def __iter__(self): return iter(self.file)
pass
self.connection_reset = connection_reset
pass
pass
pass
self.field_name = field_name self.file_name = file_name self.content_type = content_type self.content_length = content_length self.charset = charset self.content_type_extra = content_type_extra
raise NotImplementedError('subclasses of FileUploadHandler must provide a receive_data_chunk() method')
raise NotImplementedError('subclasses of FileUploadHandler must provide a file_complete() method')
pass
super(TemporaryFileUploadHandler, self).new_file(*args, **kwargs) self.file = TemporaryUploadedFile(self.file_name, self.content_type, 0, self.charset, self.content_type_extra)
if self.activated: self.file.write(raw_data) else: return raw_data
if not self.activated: return self.file.seek(0) return InMemoryUploadedFile( file=self.file, field_name=self.field_name, name=self.file_name, content_type=self.content_type, size=file_size, charset=self.charset, content_type_extra=self.content_type_extra )
pass
pass
def dumps(self, obj): return json.dumps(obj, separators=(',', ':')).encode('latin-1') def loads(self, data): return json.loads(data.decode('latin-1'))
admin = 'admin' caches = 'caches' compatibility = 'compatibility' database = 'database' models = 'models' security = 'security' signals = 'signals' templates = 'templates' urls = 'urls'
if isinstance(pattern, six.string_types): hint = ( "Try removing the string '{}'. The list of urlpatterns should not " "have a prefix string as the first element.".format(pattern) ) elif isinstance(pattern, tuple): hint = "Try using url() instead of a tuple." else: hint = None return [Error( "Your URL pattern {!r} is invalid. Ensure that urlpatterns is a list " "of url() instances.".format(pattern), hint=hint, id="urls.E004", )]
description = "'{}'".format(pattern.regex.pattern) if getattr(pattern, 'name', False): description += " [name='{}']".format(pattern.name) return description
regex_pattern = pattern.regex.pattern if regex_pattern.endswith('$') and not regex_pattern.endswith('\$'): warning = Warning( "Your URL pattern {} uses include with a regex ending with a '$'. " "Remove the dollar from the regex to avoid problems including " "URLs.".format(describe_pattern(pattern)), id="urls.W001", ) return [warning] else: return []
regex_pattern = pattern.regex.pattern if regex_pattern.startswith('/') or regex_pattern.startswith('^/'): warning = Warning( "Your URL pattern {} has a regex beginning with a '/'. " "Remove this slash as it is unnecessary.".format(describe_pattern(pattern)), id="urls.W002", ) return [warning] else: return []
models = serializers.sort_dependencies(app_list.items()) for model in models: if model in excluded_models: continue if model._meta.proxy and model._meta.proxy_for_model not in models: warnings.warn( "%s is a proxy model and won't be serialized." % model._meta.label, category=ProxyModelWarning, ) if not model._meta.proxy and router.allow_migrate_model(using, model): if use_base_manager: objects = model._base_manager else: objects = model._default_manager queryset = objects.using(using).order_by(model._meta.pk.name) if primary_keys: queryset = queryset.filter(pk__in=primary_keys) if count_only: yield queryset.order_by().count() else: for obj in queryset.iterator(): yield obj
dirs = [] fixture_dirs = settings.FIXTURE_DIRS if len(fixture_dirs) != len(set(fixture_dirs)): raise ImproperlyConfigured("settings.FIXTURE_DIRS contains duplicates.") for app_config in apps.get_app_configs(): app_label = app_config.label app_dir = os.path.join(app_config.path, 'fixtures') if app_dir in fixture_dirs: raise ImproperlyConfigured( "'%s' is a default fixture directory for the '%s' app " "and cannot be listed in settings.FIXTURE_DIRS." % (app_dir, app_label) ) if self.app_label and app_label != self.app_label: continue if os.path.isdir(app_dir): dirs.append(app_dir) dirs.extend(list(fixture_dirs)) dirs.append('') dirs = [upath(os.path.abspath(os.path.realpath(d))) for d in dirs] return dirs
parts = fixture_name.rsplit('.', 2) if len(parts) > 1 and parts[-1] in self.compression_formats: cmp_fmt = parts[-1] parts = parts[:-1] else: cmp_fmt = None if len(parts) > 1: if parts[-1] in self.serialization_formats: ser_fmt = parts[-1] parts = parts[:-1] else: raise CommandError( "Problem installing fixture '%s': %s is not a known " "serialization format." % (''.join(parts[:-1]), parts[-1])) else: ser_fmt = None name = '.'.join(parts) return name, ser_fmt, cmp_fmt
return get_internal_wsgi_application()
use_reloader = options['use_reloader'] if use_reloader: autoreload.main(self.inner_run, None, options) else: self.inner_run(None, **options)
return {k: repr(v) for k, v in module.__dict__.items() if not omittable(k)}
if not self.is_templatized: return self.path extension = { 'djangojs': 'c', 'django': 'py', }.get(self.domain) filename = '%s.%s' % (self.translatable.file, extension) return os.path.join(self.translatable.dirpath, filename)
from django.utils.translation import templatize if not self.is_templatized: return with io.open(self.path, 'r', encoding=settings.FILE_CHARSET) as fp: src_data = fp.read() if self.domain == 'djangojs': content = prepare_js_for_gettext(src_data) elif self.domain == 'django': content = templatize(src_data, self.path[2:]) with io.open(self.work_path, 'w', encoding='utf-8') as fp: fp.write(content)
file_list = self.find_files(".") self.remove_potfiles() self.process_files(file_list) potfiles = [] for path in self.locale_paths: potfile = os.path.join(path, '%s.pot' % str(self.domain)) if not os.path.exists(potfile): continue args = ['msguniq'] + self.msguniq_options + [potfile] msgs, errors, status = popen_wrapper(args) if errors: if status != STATUS_OK: raise CommandError( "errors happened while running msguniq\n%s" % errors) elif self.verbosity > 0: self.stdout.write(errors) msgs = normalize_eols(msgs) with io.open(potfile, 'w', encoding='utf-8') as fp: fp.write(msgs) potfiles.append(potfile) return potfiles
filename = os.path.basename(path) def ignore(pattern): return fnmatch.fnmatchcase(filename, pattern) or fnmatch.fnmatchcase(path, pattern) return any(ignore(pattern) for pattern in ignore_patterns)
file_groups = {} for translatable in file_list: file_group = file_groups.setdefault(translatable.locale_dir, []) file_group.append(translatable) for locale_dir, files in file_groups.items(): self.process_locale_dir(locale_dir, files)
option = '--testrunner=' for arg in argv[2:]: if arg.startswith(option): self.test_runner = arg[len(option):] break super(Command, self).run_from_argv(argv)
from IPython.Shell import IPShell shell = IPShell(argv=[]) shell.mainloop()
from IPython.frontend.terminal.ipapp import TerminalIPythonApp app = TerminalIPythonApp.instance() app.initialize(argv=[]) app.start()
from IPython import start_ipython start_ipython(argv=[])
command_dir = os.path.join(management_dir, 'commands') return [name for _, name, is_pkg in pkgutil.iter_modules([npath(command_dir)]) if not is_pkg and not name.startswith('_')]
module = import_module('%s.management.commands.%s' % (app_name, name)) return module.Command()
commands = {name: 'django.core' for name in find_commands(upath(__path__[0]))} if not settings.configured: return commands for app_config in reversed(list(apps.get_app_configs())): path = os.path.join(app_config.path, 'management') commands.update({name: app_config.name for name in find_commands(path)}) return commands
base, ext = posixpath.splitext(the_path) if base.lower().endswith('.tar'): ext = base[-4:] + ext base = base[:-4] return base, ext
prefix = 'django_%s_template_' % self.app_or_project tempdir = tempfile.mkdtemp(prefix=prefix, suffix='_extract') self.paths_to_remove.append(tempdir) if self.verbosity >= 2: self.stdout.write("Extracting %s\n" % filename) try: archive.extract(filename, tempdir) return tempdir except (archive.ArchiveException, IOError) as e: raise CommandError("couldn't extract file %s to %s: %s" % (filename, tempdir, e))
if ':' not in template: return False scheme = template.split(':', 1)[0].lower() return scheme in self.url_schemes
pass
pass
if options.settings: os.environ['DJANGO_SETTINGS_MODULE'] = options.settings if options.pythonpath: sys.path.insert(0, options.pythonpath)
@property def style_func(self): return self._style_func @style_func.setter def style_func(self, style_func): if style_func and self.isatty(): self._style_func = style_func else: self._style_func = lambda x: x def __init__(self, out, style_func=None, ending='\n'): self._out = out self.style_func = None self.ending = ending def __getattr__(self, name): return getattr(self._out, name) def isatty(self): return hasattr(self._out, 'isatty') and self._out.isatty() def write(self, msg, style_func=None, ending=None): ending = self.ending if ending is None else ending if ending and not msg.endswith(ending): msg += ending style_func = style_func or self.style_func self._out.write(force_str(style_func(msg)))
return django.get_version()
usage = '%%prog %s [options] %s' % (subcommand, self.args) if self.help: return '%s\n\n%s' % (usage, self.help) else: return usage
parser = CommandParser( self, prog="%s %s" % (os.path.basename(prog_name), subcommand), description=self.help or None, ) parser.add_argument('--version', action='version', version=self.get_version()) parser.add_argument( '-v', '--verbosity', action='store', dest='verbosity', default=1, type=int, choices=[0, 1, 2, 3], help='Verbosity level; 0=minimal output, 1=normal output, 2=verbose output, 3=very verbose output', ) parser.add_argument( '--settings', help=( 'The Python path to a settings module, e.g. ' '"myproject.settings.main". If this isn\'t provided, the ' 'DJANGO_SETTINGS_MODULE environment variable will be used.' ), ) parser.add_argument( '--pythonpath', help='A directory to add to the Python path, e.g. "/home/djangoprojects/myproject".', ) parser.add_argument('--traceback', action='store_true', help='Raise on CommandError exceptions') parser.add_argument( '--no-color', action='store_true', dest='no_color', default=False, help="Don't colorize the command output.", ) self.add_arguments(parser) return parser
pass
parser = self.create_parser(prog_name, subcommand) parser.print_help()
raise NotImplementedError('subclasses of BaseCommand must provide a handle() method')
raise NotImplementedError( "Subclasses of AppCommand must provide" "a handle_app_config() method.")
return make_style('nocolor')
try: p = Popen(args, shell=False, stdout=PIPE, stderr=PIPE, close_fds=os.name != 'nt') except OSError as e: strerror = force_text(e.strerror, DEFAULT_LOCALE_ENCODING, strings_only=True) six.reraise(os_err_exc_type, os_err_exc_type('Error executing %s: %s' % (args[0], strerror)), sys.exc_info()[2]) output, errors = p.communicate() return ( force_text(output, stdout_encoding, strings_only=True, errors='strict'), force_text(errors, DEFAULT_LOCALE_ENCODING, strings_only=True, errors='replace'), p.returncode )
ext_list = [] for ext in extensions: ext_list.extend(ext.replace(' ', '').split(',')) for i, ext in enumerate(ext_list): if not ext.startswith('.'): ext_list[i] = '.%s' % ext_list[i] return set(ext_list)
chars = 'abcdefghijklmnopqrstuvwxyz0123456789!@#$%^&*(-_=+)' return get_random_string(50, chars)
if only_django: tables = connection.introspection.django_table_names(only_existing=True, include_views=False) else: tables = connection.introspection.table_names(include_views=False) seqs = connection.introspection.sequence_list() if reset_sequences else () statements = connection.ops.sql_flush(style, tables, seqs, allow_cascade) return statements
def __init__(self): self._caches = local() def __getitem__(self, alias): try: return self._caches.caches[alias] except AttributeError: self._caches.caches = {} except KeyError: pass if alias not in settings.CACHES: raise InvalidCacheBackendError( "Could not find config for '%s' in settings.CACHES" % alias ) cache = _create_cache(alias) self._caches.caches[alias] = cache return cache def all(self): return getattr(self._caches, 'caches', {}).values()
def __getattr__(self, name): return getattr(caches[DEFAULT_CACHE_ALIAS], name) def __setattr__(self, name, value): return setattr(caches[DEFAULT_CACHE_ALIAS], name, value) def __delattr__(self, name): return delattr(caches[DEFAULT_CACHE_ALIAS], name) def __contains__(self, key): return key in caches[DEFAULT_CACHE_ALIAS] def __eq__(self, other): return caches[DEFAULT_CACHE_ALIAS] == other def __ne__(self, other): return caches[DEFAULT_CACHE_ALIAS] != other
key = self.make_key(key, version=version) self.validate_key(key) return os.path.join(self._dir, ''.join( [hashlib.md5(force_bytes(key)).hexdigest(), self.cache_suffix]))
if not os.path.exists(self._dir): return for fname in self._list_cache_files(): self._delete(fname)
if getattr(self, '_client', None) is None: self._client = self._lib.Client(self._servers) return self._client
yield
def __init__(self, table): self.db_table = table self.app_label = 'django_cache' self.model_name = 'cacheentry' self.verbose_name = 'cache entry' self.verbose_name_plural = 'cache entries' self.object_name = 'CacheEntry' self.abstract = False self.managed = True self.proxy = False self.swapped = False
return '%s:%s:%s' % (key_prefix, version, key)
if key_func is not None: if callable(key_func): return key_func else: return import_string(key_func) return default_key_func
if version is None: version = self.version new_key = self.key_func(key, self.key_prefix, version) return new_key
raise NotImplementedError('subclasses of BaseCache must provide an add() method')
raise NotImplementedError('subclasses of BaseCache must provide a get() method')
raise NotImplementedError('subclasses of BaseCache must provide a set() method')
raise NotImplementedError('subclasses of BaseCache must provide a delete() method')
d = {} for k in keys: val = self.get(k, version=version) if val is not None: d[k] = val return d
return self.get(key, version=version) is not None
value = self.get(key, version=version) if value is None: raise ValueError("Key '%s' not found" % key) new_value = value + delta self.set(key, new_value, version=version) return new_value
return self.incr(key, -delta, version=version)
for key, value in data.items(): self.set(key, value, timeout=timeout, version=version)
for key in keys: self.delete(key, version=version)
raise NotImplementedError('subclasses of BaseCache must provide a clear() method')
if len(key) > MEMCACHE_MAX_KEY_LENGTH: warnings.warn( 'Cache key will cause errors if used with memcached: %r ' '(longer than %s)' % (key, MEMCACHE_MAX_KEY_LENGTH), CacheKeyWarning ) for char in key: if ord(char) < 33 or ord(char) == 127: warnings.warn( 'Cache key contains characters that will cause errors if ' 'used with memcached: %r' % key, CacheKeyWarning ) break
if version is None: version = self.version value = self.get(key, version=version) if value is None: raise ValueError("Key '%s' not found" % key) self.set(key, value, version=version + delta) self.delete(key, version=version) return version + delta
return self.incr_version(key, -delta, version)
try: number = int(number) except (TypeError, ValueError): raise PageNotAnInteger('That page number is not an integer') if number < 1: raise EmptyPage('That page number is less than 1') if number > self.num_pages: if number == 1 and self.allow_empty_first_page: pass else: raise EmptyPage('That page contains no results') return number
number = self.validate_number(number) bottom = (number - 1) * self.per_page top = bottom + self.per_page if top + self.orphans >= self.count: top = self.count return self._get_page(self.object_list[bottom:top], number, self)
return Page(*args, **kwargs)
if self.count == 0 and not self.allow_empty_first_page: return 0 hits = max(1, self.count - self.orphans) return int(ceil(hits / float(self.per_page)))
pass
pass
silent_variable_failure = True
pass
pass
pass
pass
pass
pass
pass
pass
pass
pass
pass
pass
path_info = get_bytes_from_wsgi(environ, 'PATH_INFO', '/') return path_info.decode(UTF_8)
value = get_bytes_from_wsgi(environ, key, default) return value.decode(UTF_8, errors='replace') if six.PY3 else value
for middleware_method in self._exception_middleware: response = middleware_method(request, exception) if response: return response raise
klass = import_string(backend or settings.EMAIL_BACKEND) return klass(fail_silently=fail_silently, **kwds)
connection = connection or get_connection( username=auth_user, password=auth_password, fail_silently=fail_silently, ) mail = EmailMultiAlternatives(subject, message, from_email, recipient_list, connection=connection) if html_message: mail.attach_alternative(html_message, 'text/html') return mail.send()
connection = connection or get_connection( username=auth_user, password=auth_password, fail_silently=fail_silently, ) messages = [ EmailMessage(subject, message, sender, recipient, connection=connection) for subject, message, sender, recipient in datatuple ] return connection.send_messages(messages)
if not settings.ADMINS: return mail = EmailMultiAlternatives( '%s%s' % (settings.EMAIL_SUBJECT_PREFIX, subject), message, settings.SERVER_EMAIL, [a[1] for a in settings.ADMINS], connection=connection, ) if html_message: mail.attach_alternative(html_message, 'text/html') mail.send(fail_silently=fail_silently)
if not settings.MANAGERS: return mail = EmailMultiAlternatives( '%s%s' % (settings.EMAIL_SUBJECT_PREFIX, subject), message, settings.SERVER_EMAIL, [a[1] for a in settings.MANAGERS], connection=connection, ) if html_message: mail.attach_alternative(html_message, 'text/html') mail.send(fail_silently=fail_silently)
if self._fname is None: timestamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S") fname = "%s-%s.log" % (timestamp, abs(id(self))) self._fname = os.path.join(self.file_path, fname) return self._fname
from django.core.mail.backends.base import BaseEmailBackend class EmailBackend(BaseEmailBackend): def send_messages(self, email_messages): return len(list(email_messages))
pass
pass
encoding = encoding or settings.DEFAULT_CHARSET val = force_text(val) if '\n' in val or '\r' in val: raise BadHeaderError("Header values can't contain newlines (got %r for header %r)" % (val, name)) try: val.encode('ascii') except UnicodeEncodeError: if name.lower() in ADDRESS_HEADERS: val = ', '.join(sanitize_address(addr, encoding) for addr in getaddresses((val,))) else: val = Header(val, encoding).encode() else: if name.lower() == 'subject': val = Header(val).encode() return str(name), val
fp = six.StringIO() g = generator.Generator(fp, mangle_from_=False) if six.PY2: g.flatten(self, unixfrom=unixfrom) else: g.flatten(self, unixfrom=unixfrom, linesep=linesep) return fp.getvalue()
fp = BytesIO() g = generator.BytesGenerator(fp, mangle_from_=False) g.flatten(self, unixfrom=unixfrom, linesep=linesep) return fp.getvalue()
if to: if isinstance(to, six.string_types): raise TypeError('"to" argument must be a list or tuple') self.to = list(to) else: self.to = [] if cc: if isinstance(cc, six.string_types): raise TypeError('"cc" argument must be a list or tuple') self.cc = list(cc) else: self.cc = [] if bcc: if isinstance(bcc, six.string_types): raise TypeError('"bcc" argument must be a list or tuple') self.bcc = list(bcc) else: self.bcc = [] if reply_to: if isinstance(reply_to, six.string_types): raise TypeError('"reply_to" argument must be a list or tuple') self.reply_to = list(reply_to) else: self.reply_to = [] self.from_email = from_email or settings.DEFAULT_FROM_EMAIL self.subject = subject self.body = body self.attachments = attachments or [] self.extra_headers = headers or {} self.connection = connection
return self.to + self.cc + self.bcc
if isinstance(filename, MIMEBase): assert content is None assert mimetype is None self.attachments.append(filename) else: assert content is not None self.attachments.append((filename, content, mimetype))
if mimetype is None: mimetype, _ = mimetypes.guess_type(filename) if mimetype is None: mimetype = DEFAULT_ATTACHMENT_MIME_TYPE attachment = self._create_mime_attachment(content, mimetype) if filename: try: filename.encode('ascii') except UnicodeEncodeError: if six.PY2: filename = filename.encode('utf-8') filename = ('utf-8', '', filename) attachment.add_header('Content-Disposition', 'attachment', filename=filename) return attachment
super(EmailMultiAlternatives, self).__init__( subject, body, from_email, to, bcc, connection, attachments, headers, cc, reply_to, ) self.alternatives = alternatives or []
assert content is not None assert mimetype is not None self.alternatives.append((content, mimetype))
from django.conf import settings app_path = getattr(settings, 'WSGI_APPLICATION') if app_path is None: return get_wsgi_application() try: return import_string(app_path) except ImportError as e: msg = ( "WSGI application '%(app_path)s' could not be loaded; " "Error importing module: '%(exception)s'" % ({ 'app_path': app_path, 'exception': e, }) ) six.reraise(ImproperlyConfigured, ImproperlyConfigured(msg), sys.exc_info()[2])
super(WSGIServer, self).server_bind() self.setup_environ()
self.xml = SimplerXMLGenerator(self.stream, self.options.get("encoding", settings.DEFAULT_CHARSET)) self.xml.startDocument() self.xml.startElement("django-objects", {"version": "1.0"})
self.indent(0) self.xml.endElement("django-objects") self.xml.endDocument()
if not hasattr(obj, "_meta"): raise base.SerializationError("Non-model object (%s) encountered during serialization" % type(obj)) self.indent(1) attrs = OrderedDict([("model", smart_text(obj._meta))]) if not self.use_natural_primary_keys or not hasattr(obj, 'natural_key'): obj_pk = obj._get_pk_val() if obj_pk is not None: attrs['pk'] = smart_text(obj_pk) self.xml.startElement("object", attrs)
self.indent(1) self.xml.endElement("object")
self.indent(2) self.xml.startElement("field", OrderedDict([ ("name", field.name), ("rel", field.remote_field.__class__.__name__), ("to", smart_text(field.remote_field.model._meta)), ]))
return DefusedExpatParser()
model_identifier = node.getAttribute(attr) if not model_identifier: raise base.DeserializationError( "<%s> node is missing the required '%s' attribute" % (node.nodeName, attr)) try: return apps.get_model(model_identifier) except (LookupError, TypeError): raise base.DeserializationError( "<%s> node has invalid model identifier: '%s'" % (node.nodeName, model_identifier))
def __repr__(self): return str(self)
def __init__(self, name, sysid, pubid): super(DTDForbidden, self).__init__() self.name = name self.sysid = sysid self.pubid = pubid def __str__(self): tpl = "DTDForbidden(name='{}', system_id={!r}, public_id={!r})" return tpl.format(self.name, self.sysid, self.pubid)
def __init__(self, name, value, base, sysid, pubid, notation_name): super(EntitiesForbidden, self).__init__() self.name = name self.value = value self.base = base self.sysid = sysid self.pubid = pubid self.notation_name = notation_name def __str__(self): tpl = "EntitiesForbidden(name='{}', system_id={!r}, public_id={!r})" return tpl.format(self.name, self.sysid, self.pubid)
def __init__(self, context, base, sysid, pubid): super(ExternalReferenceForbidden, self).__init__() self.context = context self.base = base self.sysid = sysid self.pubid = pubid def __str__(self): tpl = "ExternalReferenceForbidden(system_id='{}', public_id={})" return tpl.format(self.sysid, self.pubid)
internal_use_only = False def __init__(self, exception): self.exception = exception def __call__(self, *args, **kwargs): raise self.exception
if serializers is None and not _serializers: _load_serializers() try: module = importlib.import_module(serializer_module) except ImportError as exc: bad_serializer = BadSerializer(exc) module = type('BadSerializerModule', (object,), { 'Deserializer': bad_serializer, 'Serializer': bad_serializer, }) if serializers is None: _serializers[format] = module else: serializers[format] = module
s = get_serializer(format)() s.serialize(queryset, **options) return s.getvalue()
d = get_deserializer(format) return d(stream_or_string, **options)
global _serializers serializers = {} for format in BUILTIN_SERIALIZERS: register_serializer(format, BUILTIN_SERIALIZERS[format], serializers) if hasattr(settings, "SERIALIZATION_MODULES"): for format in settings.SERIALIZATION_MODULES: register_serializer(format, settings.SERIALIZATION_MODULES[format], serializers) _serializers = serializers
pass
pass
return cls("%s: (%s:pk=%s) field_value was '%s'" % (original_exc, model, fk, field_value))
raise NotImplementedError('subclasses of Serializer must provide a start_serialization() method')
pass
raise NotImplementedError('subclasses of Serializer must provide a start_object() method')
pass
raise NotImplementedError('subclasses of Serializer must provide an handle_field() method')
raise NotImplementedError('subclasses of Serializer must provide an handle_fk_field() method')
raise NotImplementedError('subclasses of Serializer must provide an handle_m2m_field() method')
if callable(getattr(self.stream, 'getvalue', None)): return self.stream.getvalue()
self.options = options if isinstance(stream_or_string, six.string_types): self.stream = six.StringIO(stream_or_string) else: self.stream = stream_or_string
raise NotImplementedError('subclasses of Deserializer must provide a __next__() method')
obj = Model(**data) if (obj.pk is None and hasattr(Model, 'natural_key') and hasattr(Model._default_manager, 'get_by_natural_key')): natural_key = obj.natural_key() try: obj.pk = Model._default_manager.db_manager(db).get_by_natural_key(*natural_key).pk except Model.DoesNotExist: pass return obj
chain = [] engines = _engine_list(using) for engine in engines: try: return engine.get_template(template_name) except TemplateDoesNotExist as e: chain.append(e) raise TemplateDoesNotExist(template_name, chain=chain)
if isinstance(template_name_list, six.string_types): raise TypeError( 'select_template() takes an iterable of template names but got a ' 'string: %r. Use get_template() if you want to load a single ' 'template by name.' % template_name_list ) chain = [] engines = _engine_list(using) for template_name in template_name_list: for engine in engines: try: return engine.get_template(template_name) except TemplateDoesNotExist as e: chain.append(e) if template_name_list: raise TemplateDoesNotExist(', '.join(template_name_list), chain=chain) else: raise TemplateDoesNotExist("No template names provided")
if isinstance(template_name, (list, tuple)): template = select_template(template_name, using=using) else: template = get_template(template_name, using=using) return template.render(context, request)
return Template(template_code, engine=self)
return value.replace('\\', '\\\\').replace('"', '\\"').replace("'", "\\'")
return value and value[0].upper() + value[1:]
return force_text(iri_to_uri(value))
return value.lower()
return list(value)
return _slugify(value)
try: return ("%" + six.text_type(arg)) % value except (ValueError, TypeError): return ""
t = re.sub("([a-z])'([A-Z])", lambda m: m.group(0).lower(), value.title()) return re.sub("\d([A-Z])", lambda m: m.group(0).lower(), t)
return value.upper()
kwargs = {} if safe is not None: kwargs['safe'] = safe return urlquote(value, **kwargs)
return mark_safe(_urlize(value, nofollow=True, autoescape=autoescape))
return mark_safe(_urlize(value, trim_url_limit=int(limit), nofollow=True, autoescape=autoescape))
return len(value.split())
return wrap(value, int(arg))
return value.ljust(int(arg))
return value.rjust(int(arg))
return value.center(int(arg))
safe = isinstance(value, SafeData) value = value.replace(arg, '') if safe and arg != ';': return mark_safe(value) return value
return escape(value)
autoescape = autoescape and not isinstance(value, SafeData) return mark_safe(linebreaks(value, autoescape))
autoescape = autoescape and not isinstance(value, SafeData) value = normalize_newlines(value) if autoescape: value = escape(value) return mark_safe(value.replace('\n', '<br />'))
return mark_safe(value)
return [mark_safe(force_text(obj)) for obj in value]
return strip_tags(value)
try: float(arg) except ValueError: return Variable(arg).resolve else: return itemgetter(arg)
try: return sorted(value, key=_property_resolver(arg)) except (TypeError, VariableDoesNotExist): return ''
try: return sorted(value, key=_property_resolver(arg), reverse=True) except (TypeError, VariableDoesNotExist): return ''
try: return value[0] except IndexError: return ''
try: return len(value) except (ValueError, TypeError): return 0
try: return len(value) == int(arg) except (ValueError, TypeError): return ''
return random_module.choice(value)
if autoescape: escaper = conditional_escape else: def escaper(x): return x def walk_items(item_list): item_iterator = iter(item_list) try: item = next(item_iterator) while True: try: next_item = next(item_iterator) except StopIteration: yield item, None break if not isinstance(next_item, six.string_types): try: iter(next_item) except TypeError: pass else: yield item, next_item item = next(item_iterator) continue yield item, None item = next_item except StopIteration: pass def list_formatter(item_list, tabs=1): indent = '\t' * tabs output = [] for item, children in walk_items(item_list): sublist = '' if children: sublist = '\n%s<ul>\n%s\n%s</ul>\n%s' % ( indent, list_formatter(children, tabs + 1), indent, indent) output.append('%s<li>%s%s</li>' % ( indent, escaper(force_text(item)), sublist)) return '\n'.join(output) return mark_safe(list_formatter(value))
try: return int(value) + int(arg) except (ValueError, TypeError): try: return value + arg except Exception: return ''
if value in (None, ''): return '' try: return formats.date_format(value, arg) except AttributeError: try: return format(value, arg) except AttributeError: return ''
if value in (None, ''): return '' try: return formats.time_format(value, arg) except (AttributeError, TypeError): try: return time_format(value, arg) except (AttributeError, TypeError): return ''
if not value: return '' try: if arg: return timesince(value, arg) return timesince(value) except (ValueError, TypeError): return ''
if not value: return '' try: return timeuntil(value, arg) except (ValueError, TypeError): return ''
return value or arg
if value is None: return arg return value
return int(value) % int(arg) == 0
return phone2numeric(value)
libraries = get_installed_libraries() libraries.update(custom_libraries) return libraries
backend = backend or exc.backend new = exc.__class__(*exc.args, tried=exc.tried, backend=backend, chain=exc.chain) if hasattr(exc, 'template_debug'): new.template_debug = exc.template_debug return new
new = copy_exception(exc, backend) six.reraise(exc.__class__, new, sys.exc_info()[2])
for entry in walk_packages(pkg.__path__, pkg.__name__ + '.'): try: module = import_module(entry[1]) except ImportError as e: raise InvalidTemplateLibrary( "Invalid template library specified. ImportError raised when " "trying to load '%s': %s" % (entry[1], e) ) if hasattr(module, 'register'): yield entry[1]
params = params.copy() self.name = params.pop('NAME') self.dirs = list(params.pop('DIRS')) self.app_dirs = bool(params.pop('APP_DIRS')) if params: raise ImproperlyConfigured( "Unknown parameters: {}".format(", ".join(params)))
raise NotImplementedError( "subclasses of BaseEngine should provide " "a from_string() method")
def __init__(self, name, template_name): self.name = name self.template_name = template_name
return self.id
def __init__(self, setting, nodelist): self.setting, self.nodelist = setting, nodelist def render(self, context): old_setting = context.autoescape context.autoescape = self.setting output = self.nodelist.render(context) context.autoescape = old_setting if self.setting: return mark_safe(output) else: return output
parser.skip_past('endcomment') return CommentNode()
return DebugNode()
bits = token.split_contents()[1:] asvar = None if len(bits) < 1: raise TemplateSyntaxError("'firstof' statement requires at least one argument") if len(bits) >= 2 and bits[-2] == 'as': asvar = bits[-1] bits = bits[:-2] return FirstOfNode([parser.compile_filter(bit) for bit in bits], asvar)
bits = token.split_contents() if len(bits) < 4: raise TemplateSyntaxError("'for' statements should have at least four" " words: %s" % token.contents) is_reversed = bits[-1] == 'reversed' in_index = -3 if is_reversed else -2 if bits[in_index] != 'in': raise TemplateSyntaxError("'for' statements should use the format" " 'for x in y': %s" % token.contents) loopvars = re.split(r' *, *', ' '.join(bits[1:in_index])) for var in loopvars: if not var or ' ' in var: raise TemplateSyntaxError("'for' tag received an invalid argument:" " %s" % token.contents) sequence = parser.compile_filter(bits[in_index + 1]) nodelist_loop = parser.parse(('empty', 'endfor',)) token = parser.next_token() if token.contents == 'empty': nodelist_empty = parser.parse(('endfor',)) parser.delete_first_token() else: nodelist_empty = None return ForNode(loopvars, sequence, is_reversed, nodelist_loop, nodelist_empty)
return do_ifequal(parser, token, False)
return do_ifequal(parser, token, True)
bits = token.split_contents() nodelist_true = parser.parse(('else', 'endifchanged')) token = parser.next_token() if token.contents == 'else': nodelist_false = parser.parse(('endifchanged',)) parser.delete_first_token() else: nodelist_false = NodeList() values = [parser.compile_filter(bit) for bit in bits[1:]] return IfChangedNode(nodelist_true, nodelist_false, *values)
subset = Library() for name in names: found = False if name in library.tags: found = True subset.tags[name] = library.tags[name] if name in library.filters: found = True subset.filters[name] = library.filters[name] if found is False: raise TemplateSyntaxError( "'%s' is not a valid tag or filter in tag library '%s'" % ( name, label, ), ) return subset
bits = token.split_contents() asvar = None if len(bits) == 4 and bits[-2] == 'as': asvar = bits[-1] bits = bits[:-2] if len(bits) != 2: raise TemplateSyntaxError("'now' statement takes one argument") format_string = bits[1][1:-1] return NowNode(format_string, asvar)
nodelist = parser.parse(('endspaceless',)) parser.delete_first_token() return SpacelessNode(nodelist)
bits = token.split_contents() if len(bits) < 2: raise TemplateSyntaxError("'%s' takes at least one argument, the name of a url()." % bits[0]) viewname = parser.compile_filter(bits[1]) args = [] kwargs = {} asvar = None bits = bits[2:] if len(bits) >= 2 and bits[-2] == 'as': asvar = bits[-1] bits = bits[:-2] if len(bits): for bit in bits: match = kwarg_re.match(bit) if not match: raise TemplateSyntaxError("Malformed arguments to url tag") name, value = match.groups() if name: kwargs[name] = parser.compile_filter(value) else: args.append(parser.compile_filter(value)) return URLNode(viewname, args, kwargs, asvar)
nodelist = parser.parse(('endverbatim',)) parser.delete_first_token() return VerbatimNode(nodelist.render(Context()))
bits = token.split_contents() if len(bits) == 4: tag, this_value_expr, max_value_expr, max_width = bits asvar = None elif len(bits) == 6: tag, this_value_expr, max_value_expr, max_width, as_, asvar = bits if as_ != 'as': raise TemplateSyntaxError("Invalid syntax in widthratio tag. Expecting 'as' keyword") else: raise TemplateSyntaxError("widthratio takes at least three arguments") return WidthRatioNode(parser.compile_filter(this_value_expr), parser.compile_filter(max_value_expr), parser.compile_filter(max_width), asvar=asvar)
def __init__(self, msg, tried=None, backend=None, chain=None): self.backend = backend if tried is None: tried = [] self.tried = tried if chain is None: chain = [] self.chain = chain super(TemplateDoesNotExist, self).__init__(msg)
new_context = copy(self) new_context._reset_dicts(values) return new_context
flat = {} for d in self.dicts: flat.update(d) return flat
def __iter__(self): for d in self.dicts[-1]: yield d def __contains__(self, key): return key in self.dicts[-1] def get(self, key, otherwise=None): return self.dicts[-1].get(key, otherwise) def __getitem__(self, key): return self.dicts[-1][key]
if self.engine.debug: lexer = DebugLexer(self.source) else: lexer = Lexer(self.source) tokens = lexer.tokenize() parser = Parser( tokens, self.engine.template_libraries, self.engine.template_builtins, self.origin, ) try: return parser.parse() except Exception as e: if self.engine.debug: e.template_debug = self.get_exception_info(e, e.token) raise
self.token_type, self.contents = token_type, contents self.lineno = lineno self.position = position
in_tag = False lineno = 1 result = [] for bit in tag_re.split(self.template_string): if bit: result.append(self.create_token(bit, None, lineno, in_tag)) in_tag = not in_tag lineno += bit.count('\n') return result
lineno = 1 result = [] upto = 0 for match in tag_re.finditer(self.template_string): start, end = match.span() if start > upto: token_string = self.template_string[upto:start] result.append(self.create_token(token_string, (upto, start), lineno, in_tag=False)) lineno += token_string.count('\n') upto = start token_string = self.template_string[start:end] result.append(self.create_token(token_string, (start, end), lineno, in_tag=True)) lineno += token_string.count('\n') upto = end last_bit = self.template_string[upto:] if last_bit: result.append(self.create_token(last_bit, (upto, upto + len(last_bit)), lineno, in_tag=False)) return result
if not isinstance(e, Exception): e = TemplateSyntaxError(e) if not hasattr(e, 'token'): e.token = token return e
return FilterExpression(token, self)
pass
try: return self.render(context) except Exception as e: if context.template.engine.debug and not hasattr(e, 'template_debug'): e.template_debug = context.template.get_exception_info(e, self.token) raise
nodes = [] if isinstance(self, nodetype): nodes.append(self) for attr in self.child_nodelists: nodelist = getattr(self, attr, None) if nodelist: nodes.extend(nodelist.get_nodes_by_type(nodetype)) return nodes
value = template_localtime(value, use_tz=context.use_tz) value = localize(value, use_l10n=context.use_l10n) value = force_text(value) if context.autoescape or isinstance(value, EscapeData): return conditional_escape(value) else: return value
key = self.cache_key(template_name, template_dirs, skip) cached = self.get_template_cache.get(key) if cached: if isinstance(cached, type) and issubclass(cached, TemplateDoesNotExist): raise cached(template_name) elif isinstance(cached, TemplateDoesNotExist): raise copy_exception(cached) return cached try: template = super(Loader, self).get_template( template_name, template_dirs, skip, ) except TemplateDoesNotExist as e: self.get_template_cache[key] = copy_exception(e) if self.engine.debug else TemplateDoesNotExist raise else: self.get_template_cache[key] = template return template
dirs_prefix = '' skip_prefix = '' if skip: matching = [origin.name for origin in skip if origin.template_name == template_name] if matching: skip_prefix = self.generate_hash(matching) if template_dirs: dirs_prefix = self.generate_hash(template_dirs) return '-'.join(filter(bool, [force_text(template_name), skip_prefix, dirs_prefix]))
return all(hasattr(loader, 'get_contents') for loader in self.loaders)
key = self.cache_key(name, dirs) try: result = self.find_template_cache[key] except KeyError: result = None for loader in self.loaders: try: template, display_name = loader(name, dirs) except TemplateDoesNotExist: pass else: origin = Origin( name=display_name, template_name=name, loader=loader, ) result = template, origin break self.find_template_cache[key] = result if result: return result else: self.template_cache[key] = TemplateDoesNotExist raise TemplateDoesNotExist(name)
import warnings from django.template import Origin, TemplateDoesNotExist from django.utils.deprecation import RemovedInDjango20Warning from .base import Loader as BaseLoader class Loader(BaseLoader): def __init__(self, engine, templates_dict): self.templates_dict = templates_dict super(Loader, self).__init__(engine) def get_contents(self, origin): try: return self.templates_dict[origin.name] except KeyError: raise TemplateDoesNotExist(origin) def get_template_sources(self, template_name): yield Origin( name=template_name, template_name=template_name, loader=self, ) def load_template_source(self, template_name, template_dirs=None): warnings.warn( 'The load_template_sources() method is deprecated. Use ' 'get_template() or get_contents() instead.', RemovedInDjango20Warning, ) try: return self.templates_dict[template_name], template_name except KeyError: raise TemplateDoesNotExist(template_name)
from django.template.utils import get_app_template_dirs from .filesystem import Loader as FilesystemLoader class Loader(FilesystemLoader): def get_dirs(self): return get_app_template_dirs('templates')
raise NotImplementedError( 'subclasses of Loader must provide a get_template_sources() method' )
raise NotImplementedError( 'subclasses of Loader must provide a load_template_source() method' )
pass
self._templates = templates self._engines = {}
bits = token.split_contents() if len(bits) != 2: raise TemplateSyntaxError("'%s' takes one argument" % bits[0]) bits[1] = construct_relative_path(parser.origin.template_name, bits[1]) parent_name = parser.compile_filter(bits[1]) nodelist = parser.parse() if nodelist.get_nodes_by_type(ExtendsNode): raise TemplateSyntaxError("'%s' cannot appear more than once in the same template" % bits[0]) return ExtendsNode(nodelist, parent_name)
def dec(func): params, varargs, varkw, defaults = getargspec(func) function_name = (name or getattr(func, '_decorated_function', func).__name__) @functools.wraps(func) def compile_func(parser, token): bits = token.split_contents()[1:] args, kwargs = parse_bits( parser, bits, params, varargs, varkw, defaults, takes_context, function_name, ) return InclusionNode( func, takes_context, args, kwargs, filename, ) self.tag(function_name, compile_func) return func return dec
def __init__(self, func, takes_context, args, kwargs): self.func = func self.takes_context = takes_context self.args = args self.kwargs = kwargs def get_resolved_arguments(self, context): resolved_args = [var.resolve(context) for var in self.args] if self.takes_context: resolved_args = [context] + resolved_args resolved_kwargs = {k: v.resolve(context) for k, v in self.kwargs.items()} return resolved_args, resolved_kwargs
obj_dict = self.__dict__.copy() if not self._is_rendered: raise ContentNotRenderedError('The response content must be ' 'rendered before it can be pickled.') for attr in self.rendering_attrs: if attr in obj_dict: del obj_dict[attr] return obj_dict
template = self.resolve_template(self.template_name) context = self.resolve_context(self.context_data) content = template.render(context, self._request) return content
if self._is_rendered: callback(self) else: self._post_render_callbacks.append(callback)
retval = self if not self._is_rendered: self.content = self.rendered_content for post_callback in self._post_render_callbacks: newretval = post_callback(retval) if newretval is not None: retval = newretval return retval
return {'STATIC_URL': settings.STATIC_URL}
return {'MEDIA_URL': settings.MEDIA_URL}
return {}
return {}
return {'obj': kwargs.get('item'), 'site': kwargs.get('site')}
current_site = get_current_site(request) link = self._get_dynamic_attr('link', obj) link = add_domain(current_site.domain, link, request.is_secure()) feed = self.feed_type( title=self._get_dynamic_attr('title', obj), subtitle=self._get_dynamic_attr('subtitle', obj), link=link, description=self._get_dynamic_attr('description', obj), language=settings.LANGUAGE_CODE, feed_url=add_domain( current_site.domain, self._get_dynamic_attr('feed_url', obj) or request.path, request.is_secure(), ), author_name=self._get_dynamic_attr('author_name', obj), author_link=self._get_dynamic_attr('author_link', obj), author_email=self._get_dynamic_attr('author_email', obj), categories=self._get_dynamic_attr('categories', obj), feed_copyright=self._get_dynamic_attr('feed_copyright', obj), feed_guid=self._get_dynamic_attr('feed_guid', obj), ttl=self._get_dynamic_attr('ttl', obj), **self.feed_extra_kwargs(obj) ) title_tmp = None if self.title_template is not None: try: title_tmp = loader.get_template(self.title_template) except TemplateDoesNotExist: pass description_tmp = None if self.description_template is not None: try: description_tmp = loader.get_template(self.description_template) except TemplateDoesNotExist: pass for item in self._get_dynamic_attr('items', obj): context = self.get_context_data(item=item, site=current_site, obj=obj, request=request) if title_tmp is not None: title = title_tmp.render(context, request) else: title = self._get_dynamic_attr('item_title', item) if description_tmp is not None: description = description_tmp.render(context, request) else: description = self._get_dynamic_attr('item_description', item) link = add_domain( current_site.domain, self._get_dynamic_attr('item_link', item), request.is_secure(), ) enclosures = self._get_dynamic_attr('item_enclosures', item) author_name = self._get_dynamic_attr('item_author_name', item) if author_name is not None: author_email = self._get_dynamic_attr('item_author_email', item) author_link = self._get_dynamic_attr('item_author_link', item) else: author_email = author_link = None tz = get_default_timezone() pubdate = self._get_dynamic_attr('item_pubdate', item) if pubdate and is_naive(pubdate): pubdate = make_aware(pubdate, tz) updateddate = self._get_dynamic_attr('item_updateddate', item) if updateddate and is_naive(updateddate): updateddate = make_aware(updateddate, tz) feed.add_item( title=title, link=link, description=description, unique_id=self._get_dynamic_attr('item_guid', item, link), unique_id_is_permalink=self._get_dynamic_attr( 'item_guid_is_permalink', item), enclosures=enclosures, pubdate=pubdate, updateddate=updateddate, author_name=author_name, author_email=author_email, author_link=author_link, categories=self._get_dynamic_attr('item_categories', item), item_copyright=self._get_dynamic_attr('item_copyright', item), **self.item_extra_kwargs(item) ) return feed
return (geom_type.num in self.MULTI_TYPES and model_field.__class__.__name__ == 'Multi%s' % geom_type.django)
kml_sources = [] if sources is None: sources = apps.get_models() for source in sources: if isinstance(source, models.base.ModelBase): for field in source._meta.fields: if isinstance(field, GeometryField): kml_sources.append((source._meta.app_label, source._meta.model_name, field.name)) elif isinstance(source, (list, tuple)): if len(source) != 3: raise ValueError('Must specify a 3-tuple of (app_label, module_name, field_name).') kml_sources.append(source) else: raise TypeError('KML Sources must be a model or a 3-tuple.') return kml_sources
urls = Sitemap.get_urls(self, page=page, site=site, protocol=protocol) for url in urls: url['geo_format'] = self.geo_format return urls
enc_query = self._check_query(query, city=True) return City(self._city.city(enc_query))
return HttpResponse( compress_kml(loader.render_to_string(*args, **kwargs)), content_type='application/vnd.google-earth.kmz', )
def __call__(self, parser, namespace, value, option_string=None): try: setattr(namespace, self.dest, int(value)) except ValueError: setattr(namespace, self.dest, value)
def __call__(self, parser, namespace, value, option_string=None): if value.lower() == 'true': setattr(namespace, self.dest, True) else: setattr(namespace, self.dest, value.split(','))
self.event = event self.action = action
params = {'calc_zoom': self.calc_zoom, 'center': self.center, 'dom_id': self.dom_id, 'js_module': self.js_module, 'kml_urls': self.kml_urls, 'zoom': self.zoom, 'polygons': self.polygons, 'polylines': self.polylines, 'icons': self.icons, 'markers': self.markers, } params.update(self.extra_context) return render_to_string(self.template, params)
params = {'js_module': self.js_module, 'dom_ids': self.dom_ids, 'load_map_js': self.load_map_js(), 'icons': self.icons, } params.update(self.extra_context) return render_to_string(self.template, params)
def as_sqlite(self, compiler, connection): for expr in self.get_source_expressions(): if hasattr(expr, 'value') and isinstance(expr.value, Decimal): expr.value = float(expr.value) return super(SQLiteDecimalToFloatMixin, self).as_sql(compiler, connection)
return self._geom_attribute('centroid', **kwargs)
return self._geomset_attribute('difference', geom, **kwargs)
return self._distance_attribute('distance', geom, **kwargs)
return self._geom_attribute('envelope', **kwargs)
return self._geom_attribute('force_rhr', **kwargs)
backend = connections[self.db].ops if not backend.geojson: raise NotImplementedError('Only PostGIS and SpatiaLite support GeoJSON serialization.') if not isinstance(precision, six.integer_types): raise TypeError('Precision keyword must be set with an integer.') options = 0 if crs and bbox: options = 3 elif bbox: options = 1 elif crs: options = 2 s = {'desc': 'GeoJSON', 'procedure_args': {'precision': precision, 'options': options}, 'procedure_fmt': '%(geo_col)s,%(precision)s,%(options)s', } return self._spatial_attribute('geojson', s, **kwargs)
s = {'desc': 'GeoHash', 'procedure_args': {'precision': precision}, 'procedure_fmt': '%(geo_col)s,%(precision)s', } return self._spatial_attribute('geohash', s, **kwargs)
backend = connections[self.db].ops s = {'desc': 'GML', 'procedure_args': {'precision': precision}} if backend.postgis: s['procedure_fmt'] = '%(version)s,%(geo_col)s,%(precision)s' s['procedure_args'] = {'precision': precision, 'version': version} if backend.oracle: s['select_field'] = GMLField() return self._spatial_attribute('gml', s, **kwargs)
return self._geomset_attribute('intersection', geom, **kwargs)
s = {'desc': 'KML', 'procedure_fmt': '%(geo_col)s,%(precision)s', 'procedure_args': {'precision': kwargs.pop('precision', 8)}, } return self._spatial_attribute('kml', s, **kwargs)
return self._distance_attribute('length', None, **kwargs)
return self._spatial_attribute('mem_size', {}, **kwargs)
return self._spatial_attribute('num_geom', {}, **kwargs)
return self._spatial_attribute('num_points', {}, **kwargs)
return self._distance_attribute('perimeter', None, **kwargs)
return self._geom_attribute('point_on_surface', **kwargs)
s = {'select_field': GeomField()} kwargs.setdefault('model_att', 'reverse_geom') if connections[self.db].ops.oracle: s['geo_field_type'] = LineStringField return self._spatial_attribute('reverse', s, **kwargs)
if connections[self.db].ops.spatialite: if z != 0.0: raise NotImplementedError('SpatiaLite does not support 3D scaling.') s = {'procedure_fmt': '%(geo_col)s,%(x)s,%(y)s', 'procedure_args': {'x': x, 'y': y}, 'select_field': GeomField(), } else: s = {'procedure_fmt': '%(geo_col)s,%(x)s,%(y)s,%(z)s', 'procedure_args': {'x': x, 'y': y, 'z': z}, 'select_field': GeomField(), } return self._spatial_attribute('scale', s, **kwargs)
if False in [isinstance(arg, (float,) + six.integer_types) for arg in args]: raise TypeError('Size argument(s) for the grid must be a float or integer values.') nargs = len(args) if nargs == 1: size = args[0] procedure_fmt = '%(geo_col)s,%(size)s' procedure_args = {'size': size} elif nargs == 2: xsize, ysize = args procedure_fmt = '%(geo_col)s,%(xsize)s,%(ysize)s' procedure_args = {'xsize': xsize, 'ysize': ysize} elif nargs == 4: xsize, ysize, xorigin, yorigin = args procedure_fmt = '%(geo_col)s,%(xorigin)s,%(yorigin)s,%(xsize)s,%(ysize)s' procedure_args = {'xsize': xsize, 'ysize': ysize, 'xorigin': xorigin, 'yorigin': yorigin} else: raise ValueError('Must provide 1, 2, or 4 arguments to `snap_to_grid`.') s = {'procedure_fmt': procedure_fmt, 'procedure_args': procedure_args, 'select_field': GeomField(), } return self._spatial_attribute('snap_to_grid', s, **kwargs)
relative = int(bool(relative)) if not isinstance(precision, six.integer_types): raise TypeError('SVG precision keyword argument must be an integer.') s = { 'desc': 'SVG', 'procedure_fmt': '%(geo_col)s,%(rel)s,%(precision)s', 'procedure_args': { 'rel': relative, 'precision': precision, } } return self._spatial_attribute('svg', s, **kwargs)
return self._geomset_attribute('sym_difference', geom, **kwargs)
if connections[self.db].ops.spatialite: if z != 0.0: raise NotImplementedError('SpatiaLite does not support 3D translation.') s = {'procedure_fmt': '%(geo_col)s,%(x)s,%(y)s', 'procedure_args': {'x': x, 'y': y}, 'select_field': GeomField(), } else: s = {'procedure_fmt': '%(geo_col)s,%(x)s,%(y)s,%(z)s', 'procedure_args': {'x': x, 'y': y, 'z': z}, 'select_field': GeomField(), } return self._spatial_attribute('translate', s, **kwargs)
if not isinstance(srid, six.integer_types): raise TypeError('An integer SRID must be provided.') field_name = kwargs.get('field_name') self._spatial_setup('transform', field_name=field_name) self.query.add_context('transformed_srid', srid) return self._clone()
s = {'select_field': GeomField()} if connections[self.db].ops.oracle: s['procedure_fmt'] = '%(geo_col)s,%(tolerance)s' s['procedure_args'] = {'tolerance': tolerance} return self._spatial_attribute(func, s, **kwargs)
s = { 'geom_args': ('geom',), 'select_field': GeomField(), 'procedure_fmt': '%(geo_col)s,%(geom)s', 'procedure_args': {'geom': geom}, } if connections[self.db].ops.oracle: s['procedure_fmt'] += ',%(tolerance)s' s['procedure_args']['tolerance'] = tolerance return self._spatial_attribute(func, s, **kwargs)
def get_internal_type(self): return 'GMLField' def from_db_value(self, value, expression, connection, context): return value
return connection.ops.get_geom_placeholder(self, value, compiler)
if not value: return None else: return connection.ops.Adapter(self.get_prep_value(value))
from django.contrib.gis.gdal import GDALRaster if isinstance(value, GDALRaster): return value elif is_candidate: try: return GDALRaster(value) except GDALException: pass elif isinstance(value, dict): try: return GDALRaster(value) except GDALException: raise ValueError("Couldn't create spatial object from lookup value '%s'." % value)
return connection.ops.get_distance(self, value, lookup_type)
lookup_name = 'overlaps_left'
lookup_name = 'overlaps_right'
lookup_name = 'overlaps_below'
lookup_name = 'overlaps_above'
lookup_name = 'left'
lookup_name = 'right'
lookup_name = 'strictly_below'
lookup_name = 'strictly_above'
lookup_name = 'same_as'
lookup_name = 'bbcontains'
lookup_name = 'bboverlaps'
lookup_name = 'contained'
self._field = field self._klass = klass super(SpatialProxy, self).__init__(field.attname, klass)
return 'f_table_name'
return 'f_geometry_column'
srid = models.IntegerField(primary_key=True) auth_name = models.CharField(max_length=256) auth_srid = models.IntegerField() srtext = models.CharField(max_length=2048) proj4text = models.CharField(max_length=2048) class Meta: app_label = 'gis' db_table = 'spatial_ref_sys' managed = False @property def wkt(self): return self.srtext
if self.is_geometry: self._adapter.prepare(conn)
if box is None: return None ll, ur = box[4:-1].split(',') xmin, ymin = map(float, ll.split()) xmax, ymax = map(float, ur.split()) return (xmin, ymin, xmax, ymax)
if box3d is None: return None ll, ur = box3d[6:-1].split(',') xmin, ymin, zmin = map(float, ll.split()) xmax, ymax, zmax = map(float, ur.split()) return (xmin, ymin, zmin, xmax, ymax, zmax)
if hex: return Geometry(hex, srid=geo_field.srid) else: return None
proj_regex = re.compile(r'(\d+)\.(\d+)\.(\d+)') proj_ver_str = self.postgis_proj_version() m = proj_regex.search(proj_ver_str) if m: return tuple(map(int, [m.group(1), m.group(2), m.group(3)])) else: raise Exception('Could not determine PROJ.4 version from PostGIS.')
return binascii.hexlify(struct.pack('<' + structure, *data)).upper()
return struct.unpack('<' + structure, binascii.unhexlify(data))
return data[:index], data[index:]
return 'table_name'
return 'column_name'
if isinstance(geom, Polygon): self._fix_polygon(geom) elif isinstance(geom, GeometryCollection): self._fix_geometry_collection(geom) self.wkt = geom.wkt self.srid = geom.srid
return 'MDSYS.SDO_GEOMETRY'
if gdal.HAS_GDAL: return self.srs.ellipsoid else: m = self.spheroid_regex.match(self.wkt) if m: return (float(m.group('major')), float(m.group('flattening'))) else: return None
if gdal.HAS_GDAL: return gdal.SpatialReference(wkt).units else: m = cls.units_regex.match(wkt) return float(m.group('unit')), m.group('unit_name')
def __init__(self, geom): self.wkt = geom.wkt self.srid = geom.srid def __eq__(self, other): if not isinstance(other, WKTAdapter): return False return self.wkt == other.wkt and self.srid == other.srid def __hash__(self): return hash((self.wkt, self.srid)) def __str__(self): return self.wkt
raise NotImplementedError('subclasses of BaseSpatialOperations must provide a geo_db_type() method')
raise NotImplementedError('Distance operations not available on this spatial backend.')
raise NotImplementedError('subclasses of BaseSpatialOperations must provide a geo_db_placeholder() method')
sql_template = None def __init__(self, op=None, func=None): self.op = op self.func = func @property def default_template(self): if self.func: return '%(func)s(%(lhs)s, %(rhs)s)' else: return '%(lhs)s %(op)s %(rhs)s' def as_sql(self, connection, lookup, template_params, sql_params): sql_template = self.sql_template or lookup.sql_template or self.default_template template_params.update({'op': self.op, 'func': self.func}) return sql_template % template_params, sql_params
return 'f_table_name'
return 'f_geometry_column'
srid = models.IntegerField(primary_key=True) auth_name = models.CharField(max_length=256) auth_srid = models.IntegerField() ref_sys_name = models.CharField(max_length=256) proj4text = models.CharField(max_length=2048) srtext = models.CharField(max_length=2048) @property def wkt(self): if hasattr(self, 'srtext'): return self.srtext from django.contrib.gis.gdal import SpatialReference return SpatialReference(self.proj4text).wkt class Meta: app_label = 'gis' db_table = 'spatial_ref_sys' managed = False
base_data_types_reverse = FlexibleFieldLookupDict.base_data_types_reverse.copy() base_data_types_reverse.update( {'point': 'GeometryField', 'linestring': 'GeometryField', 'polygon': 'GeometryField', 'multipoint': 'GeometryField', 'multilinestring': 'GeometryField', 'multipolygon': 'GeometryField', 'geometrycollection': 'GeometryField', })
try: version = self.spatialite_version_tuple()[1:] except Exception as msg: new_msg = ( 'Cannot determine the SpatiaLite version for the "%s" ' 'database (error was "%s"). Was the SpatiaLite initialization ' 'SQL loaded on this database?') % (self.connection.settings_dict['NAME'], msg) six.reraise(ImproperlyConfigured, ImproperlyConfigured(new_msg), sys.exc_info()[2]) if version < (4, 0, 0): raise ImproperlyConfigured('GeoDjango only supports SpatiaLite versions 4.0.0 and above.') return version
if box is None: return None shell = Geometry(box, srid).shell xmin, ymin = shell[0][:2] xmax, ymax = shell[2][:2] return (xmin, ymin, xmax, ymax)
if wkt: return Geometry(wkt, geo_field.srid) else: return None
return None
if not value: return [] value = value[0] if isinstance(value, Distance): if f.geodetic(self.connection): raise ValueError('SpatiaLite does not support distance queries on ' 'geometry fields with a geodetic coordinate system. ' 'Distance objects; use a numeric value of your ' 'distance in degrees instead.') else: dist_param = getattr(value, Distance.unit_attname(f.units_name(self.connection))) else: dist_param = value return [dist_param]
cursor = self.connection._cursor() try: cursor.execute('SELECT %s' % func) row = cursor.fetchone() finally: cursor.close() return row[0]
return self._get_spatialite_func('lwgeom_version()')
version = self.spatialite_version() m = self.version_regex.match(version) if m: major = int(m.group('major')) minor1 = int(m.group('minor1')) minor2 = int(m.group('minor2')) else: raise Exception('Could not parse SpatiaLite version string: %s' % version) return (version, major, minor1, minor2)
val = 0.0 default_unit = self.STANDARD_UNIT for unit, value in six.iteritems(kwargs): if not isinstance(value, float): value = float(value) if unit in self.UNITS: val += self.UNITS[unit] * value default_unit = unit elif unit in self.ALIAS: u = self.ALIAS[unit] val += self.UNITS[u] * value default_unit = u else: lower = unit.lower() if lower in self.UNITS: val += self.UNITS[lower] * value default_unit = lower elif lower in self.LALIAS: u = self.LALIAS[lower] val += self.UNITS[u] * value default_unit = u else: raise AttributeError('Unknown unit type: %s' % unit) return val, default_unit
lower = unit_str.lower() if unit_str in cls.UNITS: return unit_str elif lower in cls.UNITS: return lower elif lower in cls.LALIAS: return cls.LALIAS[lower] else: raise Exception('Could not find a unit keyword associated with "%s"' % unit_str)
if not ndim: return capi.create_point(None) if ndim < 2 or ndim > 3: raise TypeError('Invalid point dimension: %s' % str(ndim)) cs = capi.create_cs(c_uint(1), c_uint(ndim)) i = iter(coords) capi.cs_setx(cs, 0, next(i)) capi.cs_sety(cs, 0, next(i)) if ndim == 3: capi.cs_setz(cs, 0, next(i)) return capi.create_point(cs)
return self.clone()
return self.clone()
if isinstance(other, six.string_types): return self.wkt == other elif isinstance(other, GEOSGeometry): return self.equals_exact(other) else: return False
return capi.geos_isempty(self.ptr)
return capi.geos_covers(self.ptr, other.ptr)
return capi.geos_crosses(self.ptr, other.ptr)
return capi.geos_disjoint(self.ptr, other.ptr)
return capi.geos_equals(self.ptr, other.ptr)
return capi.geos_equalsexact(self.ptr, other.ptr, float(tolerance))
return capi.geos_overlaps(self.ptr, other.ptr)
if not isinstance(pattern, six.string_types) or len(pattern) > 9: raise GEOSException('invalid intersection matrix pattern') return capi.geos_relatepattern(self.ptr, other.ptr, force_bytes(pattern))
return capi.geos_touches(self.ptr, other.ptr)
srid = self.srid return 'SRID=%s;%s' % (srid, self.wkt) if srid else self.wkt
return ewkb_w(dim=3 if self.hasz else 2).write_hex(self)
return json.dumps({'type': self.__class__.__name__, 'coordinates': self.coords})
return wkb_w(3 if self.hasz else 2).write(self)
return ewkb_w(3 if self.hasz else 2).write(self)
return self._topology(capi.geos_buffer(self.ptr, width, quadsegs))
return self._topology(capi.geos_centroid(self.ptr))
return self._topology(capi.geos_convexhull(self.ptr))
return self._topology(capi.geos_difference(self.ptr, other.ptr))
if preserve_topology: return self._topology(capi.geos_preservesimplify(self.ptr, tolerance)) else: return self._topology(capi.geos_simplify(self.ptr, tolerance))
return self._topology(capi.geos_symdifference(self.ptr, other.ptr))
if not isinstance(other, GEOSGeometry): raise TypeError('distance() works only on other GEOS Geometries.') return capi.geos_distance(self.ptr, other.ptr, byref(c_double()))
from .point import Point env = self.envelope if isinstance(env, Point): xmin, ymin = env.tuple xmax, ymax = xmin, ymin else: xmin, ymin = env[0][0] xmax, ymax = env[0][2] return (xmin, ymin, xmax, ymax)
return capi.geos_length(self.ptr, byref(c_double()))
return self._topology(capi.geos_linemerge(self.ptr))
return ' '.join('%f %f' % (coord[1], coord[0]) for coord in coords)
if w3c_geo: lon, lat = coords[:2] handler.addQuickElement('geo:lat', '%f' % lat) handler.addQuickElement('geo:lon', '%f' % lon) else: handler.addQuickElement('georss:point', self.georss_coords((coords,)))
feed_type = GeoRSSFeed def feed_extra_kwargs(self, obj): return {'geometry': self._get_dynamic_attr('geometry', obj)} def item_extra_kwargs(self, item): return {'geometry': self._get_dynamic_attr('item_geometry', item)}
self.source._flush() self._stats_refresh = True
return force_text(capi.get_band_description(self._ptr))
return capi.get_band_xsize(self._ptr)
return capi.get_band_ysize(self._ptr)
return self.width * self.height
return self.statistics()[0]
return self.statistics()[1]
return self.statistics()[2]
return self.statistics()[3]
if value is None: if not capi.delete_band_nodata_value: raise ValueError('GDAL >= 2.1 required to delete nodata values.') capi.delete_band_nodata_value(self._ptr) elif not isinstance(value, (int, float)): raise ValueError('Nodata value must be numeric or None.') else: capi.set_band_nodata_value(self._ptr, value) self._flush()
dtype = capi.get_band_datatype(self._ptr) if as_string: dtype = GDAL_PIXEL_TYPES[dtype] return dtype
return '<Raster object at %s>' % hex(addressof(self._ptr))
return force_text(capi.get_ds_description(self._ptr))
ds_driver = capi.get_ds_driver(self._ptr) return Driver(ds_driver)
return capi.get_ds_xsize(self._ptr)
return capi.get_ds_ysize(self._ptr)
try: wkt = capi.get_ds_projection_ref(self._ptr) if not wkt: return None return SpatialReference(wkt, srs_type='wkt') except SRSException: return None
if isinstance(value, SpatialReference): srs = value elif isinstance(value, six.integer_types + six.string_types): srs = SpatialReference(value) else: raise ValueError('Could not create a SpatialReference from input.') capi.set_ds_projection_ref(self._ptr, srs.wkt.encode()) self._flush()
return self.srs.srid
self.srs = value
return TransformPoint(self, 'origin')
return TransformPoint(self, 'scale')
return TransformPoint(self, 'skew')
if not isinstance(target, six.string_types) or not isinstance(index, int): raise TypeError return capi.get_attr_value(self.ptr, force_bytes(target), index)
capi.identify_epsg(self.ptr)
return (self.semi_major, self.semi_minor, self.inverse_flattening)
return bool(capi.isgeographic(self.ptr))
return vcapi.get_driver_count() + rcapi.get_driver_count()
return 0
if offset: check_err(result, cpl=cpl) ptr = ptr_byref(cargs, offset) return ptr.value else: return result
check_err(arg_byref(cargs), cpl=cpl) return result
check_err(result, cpl=cpl)
return double_output(f, [c_void_p, POINTER(c_int)], errcheck=True)
func.argtypes = argtypes func.restype = c_void_p func.errcheck = check_srs return func
if isinstance(other, OGRGeomType): return self.num == other.num elif isinstance(other, six.string_types): return self.name.lower() == other.lower() elif isinstance(other, int): return self.num == other else: return False
if isinstance(other, Envelope): return (self.min_x == other.min_x) and (self.min_y == other.min_y) and \ (self.max_x == other.max_x) and (self.max_y == other.max_y) elif isinstance(other, tuple) and len(other) == 4: return (self.min_x == other[0]) and (self.min_y == other[1]) and \ (self.max_x == other[2]) and (self.max_y == other[3]) else: raise GDALException('Equivalence testing only works with other Envelopes.')
return [force_text(capi.get_field_name(capi.get_field_defn(self._ldefn, i)), self._ds.encoding, strings_only=True) for i in range(self.num_fields)]
return [OGRFieldTypes[capi.get_field_type(capi.get_field_defn(self._ldefn, i))] for i in range(self.num_fields)]
if field_name not in self.fields: raise GDALException('invalid field name: %s' % field_name) return [feat.get(field_name) for feat in self]
if geos: from django.contrib.gis.geos import GEOSGeometry return [GEOSGeometry(feat.geom.wkb) for feat in self] else: return [feat.geom for feat in self]
return capi.to_json(self.ptr)
return self._geomgen(capi.geom_convex_hull)
return self._geomgen(capi.geom_diff, other)
return self._geomgen(capi.geom_intersection, other)
return self._geomgen(capi.geom_sym_diff, other)
return [func(self.ptr, i) for i in range(len(self))]
if not feat: raise GDALException('Cannot create OGR Feature, invalid pointer given.') self.ptr = feat self._layer = layer
if isinstance(index, six.string_types): i = self.index(index) else: if index < 0 or index > self.num_fields: raise OGRIndexError('index out of range') i = index return Field(self, i)
field_name = getattr(field, 'name', field) return self[field_name].value
return import_string(settings.MESSAGE_STORAGE)(request)
if encoded_data: response.set_cookie( self.cookie_name, encoded_data, domain=settings.SESSION_COOKIE_DOMAIN, secure=settings.SESSION_COOKIE_SECURE or None, httponly=settings.SESSION_COOKIE_HTTPONLY or None, ) else: response.delete_cookie(self.cookie_name, domain=settings.SESSION_COOKIE_DOMAIN)
key_salt = 'django.contrib.messages' return salted_hmac(key_salt, value).hexdigest()
if messages or encode_empty: encoder = MessageEncoder(separators=(',', ':')) value = encoder.encode(messages) return '%s$%s' % (self._hash(value), value)
self.message = force_text(self.message, strings_only=True) self.extra_tags = force_text(self.extra_tags, strings_only=True)
if not hasattr(self, '_loaded_data'): messages, all_retrieved = self._get() self._loaded_data = messages or [] return self._loaded_data
raise NotImplementedError('subclasses of BaseStorage must provide a _get() method')
raise NotImplementedError('subclasses of BaseStorage must provide a _store() method')
for message in messages: message._prepare()
self._prepare_messages(self._queued_messages) if self.used: return self._store(self._queued_messages, response) elif self.added_new: messages = self._loaded_messages + self._queued_messages return self._store(messages, response)
if not hasattr(self, '_level'): self._level = getattr(settings, 'MESSAGE_LEVEL', constants.INFO) return self._level
if value is None and hasattr(self, '_level'): del self._level else: self._level = int(value)
return self.deserialize_messages(self.request.session.get(self.session_key)), True
if messages: self.request.session[self.session_key] = self.serialize_messages(messages) else: self.request.session.pop(self.session_key, None) return []
success_message = '' def form_valid(self, form): response = super(SuccessMessageMixin, self).form_valid(form) success_message = self.get_success_message(form.cleaned_data) if success_message: messages.success(self.request, success_message) return response def get_success_message(self, cleaned_data): return self.success_message % cleaned_data
if not isinstance(request, HttpRequest): raise TypeError("add_message() argument must be an HttpRequest object, " "not '%s'." % request.__class__.__name__) if hasattr(request, '_messages'): return request._messages.add(level, message, extra_tags) if not fail_silently: raise MessageFailure( 'You cannot add messages without installing ' 'django.contrib.messages.middleware.MessageMiddleware' )
return getattr(request, '_messages', [])
storage = getattr(request, '_messages', default_storage(request)) return storage.level
if not hasattr(request, '_messages'): return False request._messages.level = level return True
add_message(request, constants.DEBUG, message, extra_tags=extra_tags, fail_silently=fail_silently)
add_message(request, constants.INFO, message, extra_tags=extra_tags, fail_silently=fail_silently)
add_message(request, constants.SUCCESS, message, extra_tags=extra_tags, fail_silently=fail_silently)
add_message(request, constants.WARNING, message, extra_tags=extra_tags, fail_silently=fail_silently)
if self.change_message and self.change_message[0] == '[': try: change_message = json.loads(self.change_message) except ValueError: return self.change_message messages = [] for sub_message in change_message: if 'added' in sub_message: if sub_message['added']: sub_message['added']['name'] = ugettext(sub_message['added']['name']) messages.append(ugettext('Added {name} "{object}".').format(**sub_message['added'])) else: messages.append(ugettext('Added.')) elif 'changed' in sub_message: sub_message['changed']['fields'] = get_text_list( sub_message['changed']['fields'], ugettext('and') ) if 'name' in sub_message['changed']: sub_message['changed']['name'] = ugettext(sub_message['changed']['name']) messages.append(ugettext('Changed {fields} for {name} "{object}".').format( **sub_message['changed'] )) else: messages.append(ugettext('Changed {fields}.').format(**sub_message['changed'])) elif 'deleted' in sub_message: sub_message['deleted']['name'] = ugettext(sub_message['deleted']['name']) messages.append(ugettext('Deleted {name} "{object}".').format(**sub_message['deleted'])) change_message = ' '.join(msg[0].upper() + msg[1:] for msg in messages) return change_message or ugettext('No fields changed.') else: return self.change_message
def process_response(self, request, response): response['Content-Security-Policy'] = "default-src 'self'" return response
from selenium.webdriver.support.wait import WebDriverWait WebDriverWait(self.selenium, timeout).until(callback)
self.wait_until(lambda d: len(d.window_handles) == num_windows, timeout)
from selenium.webdriver.common.by import By from selenium.webdriver.support import expected_conditions as ec self.wait_until( ec.presence_of_element_located((By.CSS_SELECTOR, css_selector)), timeout )
from selenium.webdriver.common.by import By from selenium.webdriver.support import expected_conditions as ec self.wait_until( ec.text_to_be_present_in_element( (By.CSS_SELECTOR, css_selector), text), timeout )
from selenium.webdriver.common.by import By from selenium.webdriver.support import expected_conditions as ec self.wait_until( ec.text_to_be_present_in_element_value( (By.CSS_SELECTOR, css_selector), text), timeout )
from selenium.webdriver.common.by import By from selenium.webdriver.support import expected_conditions as ec self.wait_until( ec.visibility_of_element_located((By.CSS_SELECTOR, css_selector)), timeout )
from selenium.webdriver.common.by import By from selenium.webdriver.support import expected_conditions as ec self.wait_until( ec.invisibility_of_element_located((By.CSS_SELECTOR, css_selector)), timeout )
self.selenium.get('%s%s' % (self.live_server_url, login_url)) username_input = self.selenium.find_element_by_name('username') username_input.send_keys(username) password_input = self.selenium.find_element_by_name('password') password_input.send_keys(password) login_text = _('Log in') self.selenium.find_element_by_xpath( '//input[@value="%s"]' % login_text).click() self.wait_page_loaded()
return self.selenium.execute_script( 'return django.jQuery("%s").css("%s")' % (selector, attribute))
from selenium.common.exceptions import NoSuchElementException options = self.selenium.find_elements_by_css_selector('%s > option' % selector) for option in options: if option.get_attribute('value') == value: return option raise NoSuchElementException('Option "%s" not found in "%s"' % (value, selector))
self._assertOptionsValues("%s > option" % selector, values)
self._assertOptionsValues("%s > option:checked" % selector, values)
parser = argparse.ArgumentParser(description=description) parser.add_argument('file', nargs='*') parser.add_argument( "-c", dest="compiler", default="~/bin/compiler.jar", help="path to Closure Compiler jar file", ) parser.add_argument("-v", "--verbose", action="store_true", dest="verbose") parser.add_argument("-q", "--quiet", action="store_false", dest="verbose") options = parser.parse_args() compiler = closure_compiler if closure_compiler else os.path.expanduser(options.compiler) if not os.path.exists(compiler): sys.exit( "Google Closure compiler jar file %s not found. Please use the -c " "option to specify the path." % compiler ) if not options.file: if options.verbose: sys.stdout.write("No filenames given; defaulting to admin scripts\n") files = [ os.path.join(js_path, f) for f in ["actions.js", "collapse.js", "inlines.js", "prepopulate.js"] ] else: files = options.file for file_name in files: if not file_name.endswith(".js"): file_name = file_name + ".js" to_compress = os.path.expanduser(file_name) if os.path.exists(to_compress): to_compress_min = "%s.min.js" % "".join(file_name.rsplit(".js")) cmd = "java -jar %s --js %s --js_output_file %s" % (compiler, to_compress, to_compress_min) if options.verbose: sys.stdout.write("Running: %s\n" % cmd) subprocess.call(cmd.split()) else: sys.stdout.write("File %s not found. Sure it exists?\n" % to_compress) if __name__ == '__main__': main()
name = 'django.contrib.admin' verbose_name = _("Administration") def ready(self): checks.register(check_dependencies, checks.Tags.admin) checks.register(check_admin_app, checks.Tags.admin)
def ready(self): super(AdminConfig, self).ready() self.module.autodiscover()
raise NotImplementedError('subclasses of ListFilter must provide a has_output() method')
raise NotImplementedError('subclasses of ListFilter must provide a choices() method')
raise NotImplementedError('subclasses of ListFilter must provide a queryset() method')
raise NotImplementedError('subclasses of ListFilter must provide an expected_parameters() method')
return self.used_parameters.get(self.parameter_name)
raise NotImplementedError( 'The SimpleListFilter.lookups() method must be overridden to ' 'return a list of tuples (value, verbose value)')
return self.field.null or (self.field.is_relation and self.field.many_to_many)
error_messages = { 'invalid_login': _( "Please enter the correct %(username)s and password for a staff " "account. Note that both fields may be case-sensitive." ), } required_css_class = 'required' def confirm_login_allowed(self, user): if not user.is_active or not user.is_staff: raise forms.ValidationError( self.error_messages['invalid_login'], code='invalid_login', params={'username': self.username_field.verbose_name} )
def __init__(self, inline, formset, fieldsets, prepopulated_fields=None, readonly_fields=None, model_admin=None): self.opts = inline self.formset = formset self.fieldsets = fieldsets self.model_admin = model_admin if readonly_fields is None: readonly_fields = () self.readonly_fields = readonly_fields if prepopulated_fields is None: prepopulated_fields = {} self.prepopulated_fields = prepopulated_fields self.classes = ' '.join(inline.classes) if inline.classes else '' def __iter__(self): for form, original in zip(self.formset.initial_forms, self.formset.get_queryset()): view_on_site_url = self.opts.get_view_on_site_url(original) yield InlineAdminForm( self.formset, form, self.fieldsets, self.prepopulated_fields, original, self.readonly_fields, model_admin=self.opts, view_on_site_url=view_on_site_url, ) for form in self.formset.extra_forms: yield InlineAdminForm( self.formset, form, self.fieldsets, self.prepopulated_fields, None, self.readonly_fields, model_admin=self.opts, ) yield InlineAdminForm( self.formset, self.formset.empty_form, self.fieldsets, self.prepopulated_fields, None, self.readonly_fields, model_admin=self.opts, ) def fields(self): fk = getattr(self.formset, "fk", None) for i, field_name in enumerate(flatten_fieldsets(self.fieldsets)): if fk and fk.name == field_name: continue if field_name in self.readonly_fields: yield { 'label': label_for_field(field_name, self.opts.model, self.opts), 'widget': {'is_hidden': False}, 'required': False, 'help_text': help_text_for_field(field_name, self.opts.model), } else: form_field = self.formset.form.base_fields[field_name] label = form_field.label if label is None: label = label_for_field(field_name, self.opts.model, self.opts) yield { 'label': label, 'widget': form_field.widget, 'required': form_field.required, 'help_text': form_field.help_text, } def inline_formset_data(self): verbose_name = self.opts.verbose_name return json.dumps({ 'name': '#%s' % self.formset.prefix, 'options': { 'prefix': self.formset.prefix, 'addText': ugettext('Add another %(verbose_name)s') % { 'verbose_name': capfirst(verbose_name), }, 'deleteText': ugettext('Remove'), } }) def _media(self): media = self.opts.media + self.formset.media for fs in self: media = media + fs.media return media media = property(_media)
def __init__(self, form, inline_formsets): super(AdminErrorList, self).__init__() if form.is_bound: self.extend(form.errors.values()) for inline_formset in inline_formsets: self.extend(inline_formset.non_form_errors()) for errors_in_inline_form in inline_formset.errors: self.extend(errors_in_inline_form.values())
prepopulated_fields = [] if 'adminform' in context: prepopulated_fields.extend(context['adminform'].prepopulated_fields) if 'inline_admin_formsets' in context: for inline_admin_formset in context['inline_admin_formsets']: for inline_admin_form in inline_admin_formset: if inline_admin_form.original is None: prepopulated_fields.extend(inline_admin_form.prepopulated_fields) prepopulated_fields_json = [] for field in prepopulated_fields: prepopulated_fields_json.append({ "id": "#%s" % field["field"].auto_id, "name": field["field"].name, "dependency_ids": ["#%s" % dependency.auto_id for dependency in field["dependencies"]], "dependency_list": [dependency.name for dependency in field["dependencies"]], "maxLength": field["field"].field.max_length or 50, "allowUnicode": getattr(field["field"].field, "allow_unicode", False) }) context.update({ 'prepopulated_fields': prepopulated_fields, 'prepopulated_fields_json': json.dumps(prepopulated_fields_json), }) return context
change = context['change'] is_popup = context['is_popup'] save_as = context['save_as'] show_save = context.get('show_save', True) show_save_and_continue = context.get('show_save_and_continue', True) ctx = Context(context) ctx.update({ 'show_delete_link': ( not is_popup and context['has_delete_permission'] and change and context.get('show_delete', True) ), 'show_save_as_new': not is_popup and change and save_as, 'show_save_and_add_another': ( context['has_add_permission'] and not is_popup and (not save_as or context['add']) ), 'show_save_and_continue': not is_popup and context['has_change_permission'] and show_save_and_continue, 'show_save': show_save, }) return ctx
if i == DOT: return '... ' elif i == cl.page_num: return format_html('<span class="this-page">{}</span> ', i + 1) else: return format_html('<a href="{}"{}>{}</a> ', cl.get_query_string({PAGE_VAR: i}), mark_safe(' class="end"' if i == cl.paginator.num_pages - 1 else ''), i + 1)
if callable(field_name): if field_name.__name__ == '<lambda>': return 'lambda' + str(field_index) else: return field_name.__name__ return field_name
headers = list(result_headers(cl)) num_sorted_fields = 0 for h in headers: if h['sortable'] and h['sorted']: num_sorted_fields += 1 return {'cl': cl, 'result_hidden_fields': list(result_hidden_fields(cl)), 'result_headers': headers, 'num_sorted_fields': num_sorted_fields, 'results': list(results(cl))}
return { 'cl': cl, 'show_result_count': cl.result_count != cl.full_result_count, 'search_var': SEARCH_VAR }
if isinstance(model_or_iterable, ModelBase): model_or_iterable = [model_or_iterable] for model in model_or_iterable: if model not in self._registry: raise NotRegistered('The model %s is not registered' % model.__name__) del self._registry[model]
return model in self._registry
name = name or action.__name__ self._actions[name] = action self._global_actions[name] = action
del self._actions[name]
return self._global_actions[name]
return six.iteritems(self._actions)
return request.user.is_active and request.user.is_staff
script_name = request.META['SCRIPT_NAME'] site_url = script_name if self.site_url == '/' and script_name else self.site_url return { 'site_title': self.site_title, 'site_header': self.site_header, 'site_url': site_url, 'has_permission': self.has_permission(request), 'available_apps': self.get_app_list(request), }
from django.contrib.admin.forms import AdminPasswordChangeForm from django.contrib.auth.views import password_change url = reverse('admin:password_change_done', current_app=self.name) defaults = { 'password_change_form': AdminPasswordChangeForm, 'post_change_redirect': url, 'extra_context': dict(self.each_context(request), **(extra_context or {})), } if self.password_change_template is not None: defaults['template_name'] = self.password_change_template request.current_app = self.name return password_change(request, **defaults)
from django.contrib.auth.views import password_change_done defaults = { 'extra_context': dict(self.each_context(request), **(extra_context or {})), } if self.password_change_done_template is not None: defaults['template_name'] = self.password_change_done_template request.current_app = self.name return password_change_done(request, **defaults)
return JavaScriptCatalog.as_view(packages=['django.contrib.admin'])(request)
app_list = self.get_app_list(request) context = dict( self.each_context(request), title=self.index_title, app_list=app_list, ) context.update(extra_context or {}) request.current_app = self.name return TemplateResponse(request, self.index_template or 'admin/index.html', context)
@property def media(self): js = ["core.js", "SelectBox.js", "SelectFilter2.js"] return forms.Media(js=["admin/js/%s" % path for path in js]) def __init__(self, verbose_name, is_stacked, attrs=None, choices=()): self.verbose_name = verbose_name self.is_stacked = is_stacked super(FilteredSelectMultiple, self).__init__(attrs, choices) def render(self, name, value, attrs=None): if attrs is None: attrs = {} attrs['class'] = 'selectfilter' if self.is_stacked: attrs['class'] += 'stacked' attrs['data-field-name'] = self.verbose_name attrs['data-is-stacked'] = int(self.is_stacked) output = super(FilteredSelectMultiple, self).render(name, value, attrs) return mark_safe(output)
return format_html('<ul{}>\n{}\n</ul>', flatatt(self.attrs), format_html_join('\n', '<li>{}</li>', ((force_text(w),) for w in self)))
params = {} if lookups and hasattr(lookups, 'items'): items = [] for k, v in lookups.items(): if callable(v): v = v() if isinstance(v, (tuple, list)): v = ','.join(str(x) for x in v) elif isinstance(v, bool): v = ('0', '1')[v] else: v = six.text_type(v) items.append((k, v)) params.update(dict(items)) return params
from django.contrib.admin import ModelAdmin from django.contrib.admin.sites import site, AdminSite def _model_admin_wrapper(admin_class): if not models: raise ValueError('At least one model must be passed to register.') admin_site = kwargs.pop('site', site) if not isinstance(admin_site, AdminSite): raise ValueError('site must subclass AdminSite') if not issubclass(admin_class, ModelAdmin): raise ValueError('Wrapped class must subclass ModelAdmin.') admin_site.register(models, admin_class=admin_class) return admin_class return _model_admin_wrapper
related_admin = self.admin_site._registry.get(db_field.remote_field.model) if related_admin is not None: ordering = related_admin.get_ordering(request) if ordering is not None and ordering != (): return db_field.remote_field.model._default_manager.using(db).order_by(*ordering) return None
db = kwargs.get('using') if db_field.name in self.raw_id_fields: kwargs['widget'] = widgets.ForeignKeyRawIdWidget(db_field.remote_field, self.admin_site, using=db) elif db_field.name in self.radio_fields: kwargs['widget'] = widgets.AdminRadioSelect(attrs={ 'class': get_ul_class(self.radio_fields[db_field.name]), }) kwargs['empty_label'] = _('None') if db_field.blank else None if 'queryset' not in kwargs: queryset = self.get_field_queryset(db, db_field, request) if queryset is not None: kwargs['queryset'] = queryset return db_field.formfield(**kwargs)
try: return mark_safe(self.empty_value_display) except AttributeError: return mark_safe(self.admin_site.empty_value_display)
return self.fields
if self.fieldsets: return self.fieldsets return [(None, {'fields': self.get_fields(request, obj)})]
return self.readonly_fields
return self.prepopulated_fields
opts = self.opts codename = get_permission_codename('add', opts) return request.user.has_perm("%s.%s" % (opts.app_label, codename))
opts = self.opts codename = get_permission_codename('change', opts) return request.user.has_perm("%s.%s" % (opts.app_label, codename))
opts = self.opts codename = get_permission_codename('delete', opts) return request.user.has_perm("%s.%s" % (opts.app_label, codename))
return request.user.has_module_perms(self.opts.app_label)
return { 'add': self.has_add_permission(request), 'change': self.has_change_permission(request), 'delete': self.has_delete_permission(request), }
from django.contrib.admin.views.main import ChangeList return ChangeList
queryset = self.get_queryset(request) model = queryset.model field = model._meta.pk if from_field is None else model._meta.get_field(from_field) try: object_id = field.to_python(object_id) return queryset.get(**{field.name: object_id}) except (model.DoesNotExist, ValidationError, ValueError): return None
defaults = { "formfield_callback": partial(self.formfield_for_dbfield, request=request), } defaults.update(kwargs) if defaults.get('fields') is None and not modelform_defines_fields(defaults.get('form')): defaults['fields'] = forms.ALL_FIELDS return modelform_factory(self.model, **defaults)
defaults = { "formfield_callback": partial(self.formfield_for_dbfield, request=request), } defaults.update(kwargs) return modelformset_factory( self.model, self.get_changelist_form(request), extra=0, fields=self.list_editable, **defaults )
for inline in self.get_inline_instances(request, obj): yield inline.get_formset(request, obj), inline
from django.contrib.admin.models import LogEntry, ADDITION LogEntry.objects.log_action( user_id=request.user.pk, content_type_id=get_content_type_for_model(object).pk, object_id=object.pk, object_repr=force_text(object), action_flag=ADDITION, change_message=message, )
from django.contrib.admin.models import LogEntry, CHANGE LogEntry.objects.log_action( user_id=request.user.pk, content_type_id=get_content_type_for_model(object).pk, object_id=object.pk, object_repr=force_text(object), action_flag=CHANGE, change_message=message, )
from django.contrib.admin.models import LogEntry, DELETION LogEntry.objects.log_action( user_id=request.user.pk, content_type_id=get_content_type_for_model(object).pk, object_id=object.pk, object_repr=object_repr, action_flag=DELETION, )
return helpers.checkbox.render(helpers.ACTION_CHECKBOX_NAME, force_text(obj.pk))
choices = [] + default_choices for func, name, description in six.itervalues(self.get_actions(request)): choice = (name, description % model_format_dict(self.opts)) choices.append(choice) return choices
return self.list_display
return self.list_filter
return self.list_select_related
return self.search_fields
match = request.resolver_match if self.preserve_filters and match: opts = self.model._meta current_url = '%s:%s' % (match.app_name, match.url_name) changelist_url = 'admin:%s_%s_changelist' % (opts.app_label, opts.model_name) if current_url == changelist_url: preserved_filters = request.GET.urlencode() else: preserved_filters = request.GET.get('_changelist_filters') if preserved_filters: return urlencode({'_changelist_filters': preserved_filters}) return ''
change_message = [] if add: change_message.append({'added': {}}) elif form.changed_data: change_message.append({'changed': {'fields': form.changed_data}}) if formsets: for formset in formsets: for added_object in formset.new_objects: change_message.append({ 'added': { 'name': force_text(added_object._meta.verbose_name), 'object': force_text(added_object), } }) for changed_object, changed_fields in formset.changed_objects: change_message.append({ 'changed': { 'name': force_text(changed_object._meta.verbose_name), 'object': force_text(changed_object), 'fields': changed_fields, } }) for deleted_object in formset.deleted_objects: change_message.append({ 'deleted': { 'name': force_text(deleted_object._meta.verbose_name), 'object': force_text(deleted_object), } }) return change_message
return form.save(commit=False)
obj.save()
obj.delete()
formset.save()
form.save_m2m() for formset in formsets: self.save_formset(request, form, formset, change=change)
opts = self.model._meta if self.has_change_permission(request, None): post_url = reverse('admin:%s_%s_changelist' % (opts.app_label, opts.model_name), current_app=self.admin_site.name) preserved_filters = self.get_preserved_filters(request) post_url = add_preserved_filters({'preserved_filters': preserved_filters, 'opts': opts}, post_url) else: post_url = reverse('admin:index', current_app=self.admin_site.name) return HttpResponseRedirect(post_url)
opts = self.model._meta if self.has_change_permission(request, None): post_url = reverse('admin:%s_%s_changelist' % (opts.app_label, opts.model_name), current_app=self.admin_site.name) preserved_filters = self.get_preserved_filters(request) post_url = add_preserved_filters({'preserved_filters': preserved_filters, 'opts': opts}, post_url) else: post_url = reverse('admin:index', current_app=self.admin_site.name) return HttpResponseRedirect(post_url)
opts = self.model._meta if IS_POPUP_VAR in request.POST: popup_response_data = json.dumps({ 'action': 'delete', 'value': str(obj_id), }) return SimpleTemplateResponse('admin/popup_response.html', { 'popup_response_data': popup_response_data, }) self.message_user( request, _('The %(name)s "%(obj)s" was deleted successfully.') % { 'name': force_text(opts.verbose_name), 'obj': force_text(obj_display), }, messages.SUCCESS, ) if self.has_change_permission(request, None): post_url = reverse( 'admin:%s_%s_changelist' % (opts.app_label, opts.model_name), current_app=self.admin_site.name, ) preserved_filters = self.get_preserved_filters(request) post_url = add_preserved_filters( {'preserved_filters': preserved_filters, 'opts': opts}, post_url ) else: post_url = reverse('admin:index', current_app=self.admin_site.name) return HttpResponseRedirect(post_url)
return self.extra
return self.min_num
return self.max_num
res[i] = '_%02X' % ord(c)
mychr = chr myatoi = int list = s.split('_') res = [list[0]] myappend = res.append del list[0] for item in list: if item[1:2]: try: myappend(mychr(myatoi(item[:2], 16)) + item[2:]) except ValueError: myappend('_' + item) else: myappend('_' + item) return "".join(res)
field_names = [] for name, opts in fieldsets: field_names.extend( flatten(opts['fields']) ) return field_names
seen = set() roots = [] for root in self.edges.get(None, ()): roots.extend(self._nested(root, seen, format_callback)) return roots
return False
if isinstance(obj, (models.Model, models.base.ModelBase)): opts = obj._meta elif isinstance(obj, models.query.QuerySet): opts = obj.model._meta else: opts = obj return { 'verbose_name': force_text(opts.verbose_name), 'verbose_name_plural': force_text(opts.verbose_name_plural) }
if isinstance(obj, models.query.QuerySet): if n is None: n = obj.count() obj = obj.model d = model_format_dict(obj) singular, plural = d["verbose_name"], d["verbose_name_plural"] return ungettext(singular, plural, n or 0)
pieces = path.split(LOOKUP_SEP) fields = [] for piece in pieces: if fields: parent = get_model_from_relation(fields[-1]) else: parent = model fields.append(parent._meta.get_field(piece)) return fields
if hasattr(obj, 'form') and not issubclass(obj.form, BaseModelForm): return must_inherit_from(parent='BaseModelForm', option='form', obj=obj, id='admin.E016') else: return []
if not hasattr(obj, 'filter_vertical'): return [] elif not isinstance(obj.filter_vertical, (list, tuple)): return must_be('a list or tuple', option='filter_vertical', obj=obj, id='admin.E017') else: return list(chain(*[ self._check_filter_item(obj, obj.model, field_name, "filter_vertical[%d]" % index) for index, field_name in enumerate(obj.filter_vertical) ]))
if not hasattr(obj, 'filter_horizontal'): return [] elif not isinstance(obj.filter_horizontal, (list, tuple)): return must_be('a list or tuple', option='filter_horizontal', obj=obj, id='admin.E018') else: return list(chain(*[ self._check_filter_item(obj, obj.model, field_name, "filter_horizontal[%d]" % index) for index, field_name in enumerate(obj.filter_horizontal) ]))
if not hasattr(obj, 'radio_fields'): return [] elif not isinstance(obj.radio_fields, dict): return must_be('a dictionary', option='radio_fields', obj=obj, id='admin.E021') else: return list(chain(*[ self._check_radio_fields_key(obj, obj.model, field_name, 'radio_fields') + self._check_radio_fields_value(obj, val, 'radio_fields["%s"]' % field_name) for field_name, val in obj.radio_fields.items() ]))
from django.contrib.admin.options import HORIZONTAL, VERTICAL if val not in (HORIZONTAL, VERTICAL): return [ checks.Error( "The value of '%s' must be either admin.HORIZONTAL or admin.VERTICAL." % label, obj=obj.__class__, id='admin.E024', ) ] else: return []
if obj.readonly_fields == (): return [] elif not isinstance(obj.readonly_fields, (list, tuple)): return must_be('a list or tuple', option='readonly_fields', obj=obj, id='admin.E034') else: return list(chain(*[ self._check_readonly_fields_item(obj, obj.model, field_name, "readonly_fields[%d]" % index) for index, field_name in enumerate(obj.readonly_fields) ]))
if not isinstance(obj.save_as, bool): return must_be('a boolean', option='save_as', obj=obj, id='admin.E101') else: return []
if not isinstance(obj.save_on_top, bool): return must_be('a boolean', option='save_on_top', obj=obj, id='admin.E102') else: return []
if not isinstance(obj.inlines, (list, tuple)): return must_be('a list or tuple', option='inlines', obj=obj, id='admin.E103') else: return list(chain(*[ self._check_inlines_item(obj, obj.model, item, "inlines[%d]" % index) for index, item in enumerate(obj.inlines) ]))
inline_label = '.'.join([inline.__module__, inline.__name__]) from django.contrib.admin.options import BaseModelAdmin if not issubclass(inline, BaseModelAdmin): return [ checks.Error( "'%s' must inherit from 'BaseModelAdmin'." % inline_label, obj=obj.__class__, id='admin.E104', ) ] elif not inline.model: return [ checks.Error( "'%s' must have a 'model' attribute." % inline_label, obj=obj.__class__, id='admin.E105', ) ] elif not issubclass(inline.model, models.Model): return must_be('a Model', option='%s.model' % inline_label, obj=obj, id='admin.E106') else: return inline(model, obj.admin_site).check()
if not isinstance(obj.list_select_related, (bool, list, tuple)): return must_be('a boolean, tuple or list', option='list_select_related', obj=obj, id='admin.E117') else: return []
if not isinstance(obj.list_per_page, int): return must_be('an integer', option='list_per_page', obj=obj, id='admin.E118') else: return []
if not isinstance(obj.list_max_show_all, int): return must_be('an integer', option='list_max_show_all', obj=obj, id='admin.E119') else: return []
if not isinstance(obj.search_fields, (list, tuple)): return must_be('a list or tuple', option='search_fields', obj=obj, id='admin.E126') else: return []
if obj.date_hierarchy is None: return [] else: try: field = obj.model._meta.get_field(obj.date_hierarchy) except FieldDoesNotExist: return refer_to_missing_field( option='date_hierarchy', field=obj.date_hierarchy, model=obj.model, obj=obj, id='admin.E127', ) else: if not isinstance(field, (models.DateField, models.DateTimeField)): return must_be('a DateField or DateTimeField', option='date_hierarchy', obj=obj, id='admin.E128') else: return []
if not isinstance(obj.extra, int): return must_be('an integer', option='extra', obj=obj, id='admin.E203') else: return []
if obj.max_num is None: return [] elif not isinstance(obj.max_num, int): return must_be('an integer', option='max_num', obj=obj, id='admin.E204') else: return []
if obj.min_num is None: return [] elif not isinstance(obj.min_num, int): return must_be('an integer', option='min_num', obj=obj, id='admin.E205') else: return []
if not issubclass(obj.formset, BaseModelFormSet): return must_inherit_from(parent='BaseModelFormSet', option='formset', obj=obj, id='admin.E206') else: return []
if func_name.startswith('get_'): if func_name.endswith('_list'): return 'List' elif func_name.endswith('_count'): return 'Integer' return ''
return field.description % field.__dict__
views = [] for p in urlpatterns: if hasattr(p, 'url_patterns'): try: patterns = p.url_patterns except ImportError: continue views.extend(extract_views_from_urlpatterns( patterns, base + p.regex.pattern, (namespace or []) + (p.namespace and [p.namespace] or []) )) elif hasattr(p, 'callback'): try: views.append((p.callback, base + p.regex.pattern, namespace, p.name)) except ViewDoesNotExist: continue else: raise TypeError(_("%s does not appear to be a urlpattern object") % p) return views
docstring = trim_docstring(docstring) parts = re.split(r'\n{2,}', docstring) title = parts[0] if len(parts) == 1: body = '' metadata = {} else: parser = HeaderParser() try: metadata = parser.parsestr(parts[-1]) except HeaderParseError: metadata = {} body = "\n\n".join(parts[1:]) else: metadata = dict(metadata.items()) if metadata: body = "\n\n".join(parts[1:-1]) else: body = "\n\n".join(parts[1:]) return title, body, metadata
session_store_class = self.model.get_session_store_class() return session_store_class().encode(session_dict)
objects = SessionManager() @classmethod def get_session_store_class(cls): from django.contrib.sessions.backends.db import SessionStore return SessionStore class Meta(AbstractBaseSession.Meta): db_table = 'django_session'
self.modified = True
self._session_key = self._get_session_key() self.modified = True
return False
self._session_key = '' self._session_cache = {} self.modified = True
self.save()
session_cache = getattr(self, '_session_cache', {}) return signing.dumps( session_cache, compress=True, salt='django.contrib.sessions.backends.signed_cookies', serializer=self.serializer, )
return self.model( session_key=self._get_or_create_session_key(), session_data=self.encode(data), expire_date=self.get_expiry_date(), )
if self.session_key is None: return self.create() data = self._get_session(no_load=must_create) obj = self.create_model_instance(data) using = router.db_for_write(self.model, instance=obj) try: with transaction.atomic(using=using): obj.save(force_insert=must_create, force_update=not must_create, using=using) except IntegrityError: if must_create: raise CreateError raise except DatabaseError: if not must_create: raise UpdateError raise
modification = os.stat(self._key_to_file()).st_mtime if settings.USE_TZ: modification = datetime.datetime.utcfromtimestamp(modification) modification = modification.replace(tzinfo=timezone.utc) else: modification = datetime.datetime.fromtimestamp(modification) return modification
expiry = session_data.get('_session_expiry') if not expiry: expiry = self._last_modification() + datetime.timedelta(seconds=settings.SESSION_COOKIE_AGE) return expiry
pass
pass
return key and len(key) >= 8
if self._validate_session_key(value): self.__session_key = value else: self.__session_key = None
self.accessed = True try: return self._session_cache except AttributeError: if self.session_key is None or no_load: self._session_cache = {} else: self._session_cache = self.load() return self._session_cache
if self.get('_session_expiry') is None: return settings.SESSION_EXPIRE_AT_BROWSER_CLOSE return self.get('_session_expiry') == 0
self.clear() self.delete() self._session_key = None
raise NotImplementedError('subclasses of SessionBase must provide an exists() method')
raise NotImplementedError('subclasses of SessionBase must provide a create() method')
raise NotImplementedError('subclasses of SessionBase must provide a save() method')
raise NotImplementedError('subclasses of SessionBase must provide a delete() method')
raise NotImplementedError('subclasses of SessionBase must provide a load() method')
def dumps(self, obj): return pickle.dumps(obj, pickle.HIGHEST_PROTOCOL) def loads(self, data): return pickle.loads(data)
if settings.USE_L10N: value = defaultfilters.floatformat(value, 1) template = string_formatted else: template = float_formatted return template % {'value': value}
messages = { 'missing_keys': _('Some keys were missing: %(keys)s'), 'extra_keys': _('Some unknown keys were provided: %(keys)s'), } strict = False def __init__(self, keys, strict=False, messages=None): self.keys = set(keys) self.strict = strict if messages is not None: self.messages = copy.copy(self.messages) self.messages.update(messages) def __call__(self, value): keys = set(value.keys()) missing_keys = self.keys - keys if missing_keys: raise ValidationError( self.messages['missing_keys'], code='missing_keys', params={'keys': ', '.join(missing_keys)}, ) if self.strict: extra_keys = keys - self.keys if extra_keys: raise ValidationError( self.messages['extra_keys'], code='extra_keys', params={'keys': ', '.join(extra_keys)}, ) def __eq__(self, other): return ( isinstance(other, self.__class__) and self.keys == other.keys and self.messages == other.messages and self.strict == other.strict ) def __ne__(self, other): return not (self == other)
def __init__(self, cache): self.cache = cache def __setitem__(self, key, value): self.cache.set(key, value) def __getitem__(self, key): value = self.cache.get(key) if value is None: raise KeyError("Couldn't find a file name '%s'" % key) return value def clear(self): self.cache.clear() def update(self, data): self.cache.set_many(data) def get(self, key, default=None): try: return self[key] except KeyError: return default
pass
pass
self.interactive = options['interactive'] self.verbosity = options['verbosity'] self.symlink = options['link'] self.clear = options['clear'] self.dry_run = options['dry_run'] ignore_patterns = options['ignore_patterns'] if options['use_default_ignore_patterns']: ignore_patterns += apps.get_app_config('staticfiles').ignore_patterns self.ignore_patterns = list(set(ignore_patterns)) self.post_process = options['post_process']
if self.verbosity >= level: self.stdout.write(msg)
handler = super(Command, self).get_handler(*args, **options) use_static_handler = options['use_static_handler'] insecure_serving = options['insecure_serving'] if use_static_handler and (settings.DEBUG or insecure_serving): return StaticFilesHandler(handler) return handler
return path.startswith(self.base_url[2]) and not self.base_url[1]
relative_url = url[len(self.base_url[2]):] return url2pathname(relative_url)
return serve(request, self.file_path(request.path), insecure=True)
if patterns is None: patterns = [] for pattern in patterns: if fnmatch.fnmatchcase(path, pattern): return True return False
if ignore_patterns is None: ignore_patterns = [] directories, files = storage.listdir(location) for fn in files: if matches_patterns(fn, ignore_patterns): continue if location: fn = os.path.join(location, fn) yield fn for dir in directories: if matches_patterns(dir, ignore_patterns): continue if location: dir = os.path.join(location, dir) for fn in get_files(storage, ignore_patterns, dir): yield fn
raise NotImplementedError('subclasses of BaseFinder must provide a find() method')
raise NotImplementedError('subclasses of BaseFinder must provide a list() method')
matches = [] for prefix, root in self.locations: if root not in searched_locations: searched_locations.append(root) matched_path = self.find_location(root, path, prefix) if matched_path: if not all: return matched_path matches.append(matched_path) return matches
if prefix: prefix = '%s%s' % (prefix, os.sep) if not path.startswith(prefix): return None path = path[len(prefix):] path = safe_join(root, path) if os.path.exists(path): return path
for prefix, root in self.locations: storage = self.storages[root] for path in utils.get_files(storage, ignore_patterns): yield path, storage
matches = [] for app in self.apps: app_location = self.storages[app].location if app_location not in searched_locations: searched_locations.append(app_location) match = self.find_in_app(app, path) if match: if not all: return match matches.append(match) return matches
try: self.storage.path('') except NotImplementedError: pass else: if self.storage.location not in searched_locations: searched_locations.append(self.storage.location) if self.storage.exists(path): match = self.storage.path(path) if all: match = [match] return match return []
for path in utils.get_files(self.storage, ignore_patterns): yield path, self.storage
storage = default_storage def __init__(self, *args, **kwargs): super(DefaultStorageFinder, self).__init__(*args, **kwargs) base_location = getattr(self.storage, 'base_location', empty) if not base_location: raise ImproperlyConfigured("The storage backend of the " "staticfiles finder %r doesn't have " "a valid location." % self.__class__)
if not value: return checks = ((s in value) for s in string.whitespace) if any(checks): raise ValidationError( _("The domain name cannot contain any spaces or tabs."), code='invalid', )
from django.conf import settings if getattr(settings, 'SITE_ID', ''): site_id = settings.SITE_ID return self._get_site_by_id(site_id) elif request: return self._get_site_by_request(request) raise ImproperlyConfigured( "You're using the Django \"sites framework\" without having " "set the SITE_ID setting. Create a site in your database and " "set the SITE_ID setting or pass a request to " "Site.objects.get_current() to fix this error." )
global SITE_CACHE SITE_CACHE = {}
def __init__(self, request): self.domain = self.name = request.get_host() def __str__(self): return self.domain def save(self, force_insert=False, force_update=False): raise NotImplementedError('RequestSite cannot be saved.') def delete(self): raise NotImplementedError('RequestSite cannot be deleted.')
if not self.__field_name: try: self.model._meta.get_field('site') except FieldDoesNotExist: self.__field_name = 'sites' else: self.__field_name = 'site' return self.__field_name
def process_request(self, request): request.site = get_current_site(request)
self._cache.clear()
return self.model_class()._base_manager.using(self._state.db).get(**kwargs)
return self.model_class()._base_manager.using(self._state.db).filter(**kwargs)
def __init__(self, data=None, files=None, instance=None, save_as_new=None, prefix=None, queryset=None, **kwargs): opts = self.model._meta self.instance = instance self.rel_name = '-'.join(( opts.app_label, opts.model_name, self.ct_field.name, self.ct_fk_field.name, )) if self.instance is None or self.instance.pk is None: qs = self.model._default_manager.none() else: if queryset is None: queryset = self.model._default_manager qs = queryset.filter(**{ self.ct_field.name: ContentType.objects.get_for_model( self.instance, for_concrete_model=self.for_concrete_model), self.ct_fk_field.name: self.instance.pk, }) super(BaseGenericInlineFormSet, self).__init__( queryset=qs, data=data, files=files, prefix=prefix, **kwargs ) @classmethod def get_default_prefix(cls): opts = cls.model._meta return '-'.join((opts.app_label, opts.model_name, cls.ct_field.name, cls.ct_fk_field.name)) def save_new(self, form, commit=True): setattr(form.instance, self.ct_field.get_attname(), ContentType.objects.get_for_model(self.instance).pk) setattr(form.instance, self.ct_fk_field.get_attname(), self.instance.pk) return form.save(commit=commit)
return { self.fk_field: getattr(obj, self.fk_field), self.ct_field: getattr(obj, self.ct_field), }
return { self.fk_field: obj.pk, self.ct_field: ContentType.objects.get_for_model(obj).pk, }
try: field = self.model._meta.get_field(self.ct_field) except FieldDoesNotExist: return [ checks.Error( "The GenericForeignKey content type references the non-existent field '%s.%s'." % ( self.model._meta.object_name, self.ct_field ), obj=self, id='contenttypes.E002', ) ] else: if not isinstance(field, models.ForeignKey): return [ checks.Error( "'%s.%s' is not a ForeignKey." % ( self.model._meta.object_name, self.ct_field ), hint=( "GenericForeignKeys must use a ForeignKey to " "'contenttypes.ContentType' as the 'content_type' field." ), obj=self, id='contenttypes.E003', ) ] elif field.remote_field.model != ContentType: return [ checks.Error( "'%s.%s' is not a ForeignKey to 'contenttypes.ContentType'." % ( self.model._meta.object_name, self.ct_field ), hint=( "GenericForeignKeys must use a ForeignKey to " "'contenttypes.ContentType' as the 'content_type' field." ), obj=self, id='contenttypes.E004', ) ] else: return []
def __init__(self, field, to, related_name=None, related_query_name=None, limit_choices_to=None): super(GenericRel, self).__init__( field, to, related_name=related_query_name or '+', related_query_name=related_query_name, limit_choices_to=limit_choices_to, on_delete=DO_NOTHING, )
return ( isinstance(field, GenericForeignKey) and field.ct_field == self.content_type_field_name and field.fk_field == self.object_id_field_name )
return ContentType.objects.get_for_model(self.model, for_concrete_model=self.for_concrete_model)
return self.remote_field.model._base_manager.db_manager(using).filter(**{ "%s__pk" % self.content_type_field_name: ContentType.objects.db_manager(using).get_for_model( self.model, for_concrete_model=self.for_concrete_model).pk, "%s__in" % self.object_id_field_name: [obj.pk for obj in objs] })
@cached_property def related_manager_cls(self): return create_generic_related_manager( self.rel.model._default_manager.__class__, self.rel, )
db = self._db or router.db_for_read(self.model, instance=self.instance) return queryset.using(db).filter(**self.core_filters)
if not url.startswith('/'): url = '/' + url site_id = get_current_site(request).id try: f = get_object_or_404(FlatPage, url=url, sites=site_id) except Http404: if not url.endswith('/') and settings.APPEND_SLASH: url += '/' f = get_object_or_404(FlatPage, url=url, sites=site_id) return HttpResponsePermanentRedirect('%s/' % request.path) else: raise return render_flatpage(request, f)
return self._make_token_with_timestamp(user, self._num_days(self._today()))
user.last_login = timezone.now() user.save(update_fields=['last_login'])
name = models.CharField(_('name'), max_length=255) content_type = models.ForeignKey( ContentType, models.CASCADE, verbose_name=_('content type'), ) codename = models.CharField(_('codename'), max_length=100) objects = PermissionManager() class Meta: verbose_name = _('permission') verbose_name_plural = _('permissions') unique_together = (('content_type', 'codename'),) ordering = ('content_type__app_label', 'content_type__model', 'codename') def __str__(self): return "%s | %s | %s" % ( six.text_type(self.content_type.app_label), six.text_type(self.content_type), six.text_type(self.name)) def natural_key(self): return (self.codename,) + self.content_type.natural_key() natural_key.dependencies = ['contenttypes.contenttype']
use_in_migrations = True def get_by_natural_key(self, name): return self.get(name=name)
name = models.CharField(_('name'), max_length=80, unique=True) permissions = models.ManyToManyField( Permission, verbose_name=_('permissions'), blank=True, ) objects = GroupManager() class Meta: verbose_name = _('group') verbose_name_plural = _('groups') def __str__(self): return self.name def natural_key(self): return (self.name,)
if not username: raise ValueError('The given username must be set') email = self.normalize_email(email) username = self.normalize_username(username) user = self.model(username=username, email=email, **extra_fields) user.set_password(password) user.save(using=self._db) return user
for backend in auth.get_backends(): if not hasattr(backend, 'has_perm'): continue try: if backend.has_perm(user, perm, obj): return True except PermissionDenied: return False return False
for backend in auth.get_backends(): if not hasattr(backend, 'has_module_perms'): continue try: if backend.has_module_perms(user, app_label): return True except PermissionDenied: return False return False
permissions = set() for backend in auth.get_backends(): if hasattr(backend, "get_group_permissions"): permissions.update(backend.get_group_permissions(self, obj)) return permissions
for perm in perm_list: if not self.has_perm(perm, obj): return False return True
full_name = '%s %s' % (self.first_name, self.last_name) return full_name.strip()
send_mail(subject, message, from_email, [self.email], **kwargs)
class Meta(AbstractUser.Meta): swappable = 'AUTH_USER_MODEL'
errors = [] if password_validators is None: password_validators = get_default_password_validators() for validator in password_validators: try: validator.validate(password, user) except ValidationError as error: errors.append(error) if errors: raise ValidationError(errors)
if password_validators is None: password_validators = get_default_password_validators() for validator in password_validators: password_changed = getattr(validator, 'password_changed', lambda *a: None) password_changed(password, user)
help_texts = [] if password_validators is None: password_validators = get_default_password_validators() for validator in password_validators: help_texts.append(validator.get_help_text()) return help_texts
help_texts = password_validators_help_texts(password_validators) help_items = [format_html('<li>{}</li>', help_text) for help_text in help_texts] return '<ul>%s</ul>' % ''.join(help_items) if help_items else ''
def __init__(self, min_length=8): self.min_length = min_length def validate(self, password, user=None): if len(password) < self.min_length: raise ValidationError( ungettext( "This password is too short. It must contain at least %(min_length)d character.", "This password is too short. It must contain at least %(min_length)d characters.", self.min_length ), code='password_too_short', params={'min_length': self.min_length}, ) def get_help_text(self): return ungettext( "Your password must contain at least %(min_length)d character.", "Your password must contain at least %(min_length)d characters.", self.min_length ) % {'min_length': self.min_length}
DEFAULT_USER_ATTRIBUTES = ('username', 'first_name', 'last_name', 'email') def __init__(self, user_attributes=DEFAULT_USER_ATTRIBUTES, max_similarity=0.7): self.user_attributes = user_attributes self.max_similarity = max_similarity def validate(self, password, user=None): if not user: return for attribute_name in self.user_attributes: value = getattr(user, attribute_name, None) if not value or not isinstance(value, string_types): continue value_parts = re.split('\W+', value) + [value] for value_part in value_parts: if SequenceMatcher(a=password.lower(), b=value_part.lower()).quick_ratio() > self.max_similarity: verbose_name = force_text(user._meta.get_field(attribute_name).verbose_name) raise ValidationError( _("The password is too similar to the %(verbose_name)s."), code='password_too_similar', params={'verbose_name': verbose_name}, ) def get_help_text(self): return _("Your password can't be too similar to your other personal information.")
DEFAULT_PASSWORD_LIST_PATH = os.path.join( os.path.dirname(os.path.realpath(upath(__file__))), 'common-passwords.txt.gz' ) def __init__(self, password_list_path=DEFAULT_PASSWORD_LIST_PATH): try: common_passwords_lines = gzip.open(password_list_path).read().decode('utf-8').splitlines() except IOError: with open(password_list_path) as f: common_passwords_lines = f.readlines() self.passwords = {p.strip() for p in common_passwords_lines} def validate(self, password, user=None): if password.lower().strip() in self.passwords: raise ValidationError( _("This password is too common."), code='password_too_common', ) def get_help_text(self): return _("Your password can't be a commonly used password.")
def validate(self, password, user=None): if password.isdigit(): raise ValidationError( _("This password is entirely numeric."), code='password_entirely_numeric', ) def get_help_text(self): return _("Your password can't be entirely numeric.")
login_url = self.login_url or settings.LOGIN_URL if not login_url: raise ImproperlyConfigured( '{0} is missing the login_url attribute. Define {0}.login_url, settings.LOGIN_URL, or override ' '{0}.get_login_url().'.format(self.__class__.__name__) ) return force_text(login_url)
return self.permission_denied_message
return self.redirect_field_name
def dispatch(self, request, *args, **kwargs): if not request.user.is_authenticated: return self.handle_no_permission() return super(LoginRequiredMixin, self).dispatch(request, *args, **kwargs)
if self.permission_required is None: raise ImproperlyConfigured( '{0} is missing the permission_required attribute. Define {0}.permission_required, or override ' '{0}.get_permission_required().'.format(self.__class__.__name__) ) if isinstance(self.permission_required, six.string_types): perms = (self.permission_required, ) else: perms = self.permission_required return perms
perms = self.get_permission_required() return self.request.user.has_perms(perms)
return self.test_func
SENSITIVE_CREDENTIALS = re.compile('api|token|key|secret|password|signature', re.I) CLEANSED_SUBSTITUTE = '********************' for key in credentials: if SENSITIVE_CREDENTIALS.search(key): credentials[key] = CLEANSED_SUBSTITUTE return credentials
try: return django_apps.get_model(settings.AUTH_USER_MODEL) except ValueError: raise ImproperlyConfigured("AUTH_USER_MODEL must be of the form 'app_label.model_name'") except LookupError: raise ImproperlyConfigured( "AUTH_USER_MODEL refers to model '%s' that has not been installed" % settings.AUTH_USER_MODEL )
return '%s_%s' % (action, opts.model_name)
if hasattr(user, 'get_session_auth_hash') and request.user == user: request.session[HASH_SESSION_KEY] = user.get_session_auth_hash()
email = email or '' try: email_name, domain_part = email.strip().rsplit('@', 1) except ValueError: pass else: email = '@'.join([email_name, domain_part.lower()]) return email
return get_random_string(length, allowed_chars)
return CallableFalse
return CallableTrue
@functools.wraps(func) def inner(*args, **kwargs): if 'current_app' in kwargs: warnings.warn( "Passing `current_app` as a keyword argument is deprecated. " "Instead the caller of `{0}` should set " "`request.current_app`.".format(func.__name__), RemovedInDjango20Warning ) current_app = kwargs.pop('current_app') request = kwargs.get('request', None) if request and current_app is not None: request.current_app = current_app return func(*args, **kwargs) return inner
redirect_to = request.POST.get(redirect_field_name, request.GET.get(redirect_field_name, '')) if redirect_authenticated_user and request.user.is_authenticated: redirect_to = _get_login_redirect_url(request, redirect_to) if redirect_to == request.path: raise ValueError( "Redirection loop for authenticated user detected. Check that " "your LOGIN_REDIRECT_URL doesn't point to a login page." ) return HttpResponseRedirect(redirect_to) elif request.method == "POST": form = authentication_form(request, data=request.POST) if form.is_valid(): auth_login(request, form.get_user()) return HttpResponseRedirect(_get_login_redirect_url(request, redirect_to)) else: form = authentication_form(request) current_site = get_current_site(request) context = { 'form': form, redirect_field_name: redirect_to, 'site': current_site, 'site_name': current_site.name, } if extra_context is not None: context.update(extra_context) return TemplateResponse(request, template_name, context)
if not login_url: login_url = settings.LOGIN_URL login_url = resolve_url(login_url) return logout(request, login_url, extra_context=extra_context)
defaults = {} if obj is None: defaults['form'] = self.add_form defaults.update(kwargs) return super(UserAdmin, self).get_form(request, obj, **defaults)
error_messages = { 'password_mismatch': _("The two password fields didn't match."), } password1 = forms.CharField( label=_("Password"), strip=False, widget=forms.PasswordInput, ) password2 = forms.CharField( label=_("Password confirmation"), widget=forms.PasswordInput, strip=False, help_text=_("Enter the same password as before, for verification."), ) class Meta: model = User fields = ("username",) field_classes = {'username': UsernameField} def __init__(self, *args, **kwargs): super(UserCreationForm, self).__init__(*args, **kwargs) self.fields[self._meta.model.USERNAME_FIELD].widget.attrs.update({'autofocus': ''}) def clean_password2(self): password1 = self.cleaned_data.get("password1") password2 = self.cleaned_data.get("password2") if password1 and password2 and password1 != password2: raise forms.ValidationError( self.error_messages['password_mismatch'], code='password_mismatch', ) self.instance.username = self.cleaned_data.get('username') password_validation.validate_password(self.cleaned_data.get('password2'), self.instance) return password2 def save(self, commit=True): user = super(UserCreationForm, self).save(commit=False) user.set_password(self.cleaned_data["password1"]) if commit: user.save() return user
if not user.is_active: raise forms.ValidationError( self.error_messages['inactive'], code='inactive', )
active_users = get_user_model()._default_manager.filter( email__iexact=email, is_active=True) return (u for u in active_users if u.has_usable_password())
email = self.cleaned_data["email"] for user in self.get_users(email): if not domain_override: current_site = get_current_site(request) site_name = current_site.name domain = current_site.domain else: site_name = domain = domain_override context = { 'email': user.email, 'domain': domain, 'site_name': site_name, 'uid': urlsafe_base64_encode(force_bytes(user.pk)), 'user': user, 'token': token_generator.make_token(user), 'protocol': 'https' if use_https else 'http', } if extra_email_context is not None: context.update(extra_email_context) self.send_mail( subject_template_name, email_template_name, context, from_email, user.email, html_email_template_name=html_email_template_name, )
error_messages = { 'password_mismatch': _("The two password fields didn't match."), } new_password1 = forms.CharField( label=_("New password"), widget=forms.PasswordInput, strip=False, help_text=password_validation.password_validators_help_text_html(), ) new_password2 = forms.CharField( label=_("New password confirmation"), strip=False, widget=forms.PasswordInput, ) def __init__(self, user, *args, **kwargs): self.user = user super(SetPasswordForm, self).__init__(*args, **kwargs) def clean_new_password2(self): password1 = self.cleaned_data.get('new_password1') password2 = self.cleaned_data.get('new_password2') if password1 and password2: if password1 != password2: raise forms.ValidationError( self.error_messages['password_mismatch'], code='password_mismatch', ) password_validation.validate_password(password2, self.user) return password2 def save(self, commit=True): password = self.cleaned_data["new_password1"] self.user.set_password(password) if commit: self.user.save() return self.user
old_password = self.cleaned_data["old_password"] if not self.user.check_password(old_password): raise forms.ValidationError( self.error_messages['password_incorrect'], code='password_incorrect', ) return old_password
password = self.cleaned_data["password1"] self.user.set_password(password) if commit: self.user.save() return self.user
raw_value = input(message) if default and raw_value == '': raw_value = default try: val = field.clean(raw_value, None) except exceptions.ValidationError as e: self.stderr.write("Error: %s" % '; '.join(e.messages)) val = None return val
builtin = _get_builtin_permissions(opts) custom = list(opts.permissions) return builtin + custom
perms = [] for action in opts.default_permissions: perms.append(( get_permission_codename(action, opts), 'Can %s %s' % (action, opts.verbose_name_raw) )) return perms
is_active = getattr(user, 'is_active', None) return is_active or is_active is None
if not user_obj.is_active or user_obj.is_anonymous or obj is not None: return set() perm_cache_name = '_%s_perm_cache' % from_name if not hasattr(user_obj, perm_cache_name): if user_obj.is_superuser: perms = Permission.objects.all() else: perms = getattr(self, '_get_%s_permissions' % from_name)(user_obj) perms = perms.values_list('content_type__app_label', 'codename').order_by() setattr(user_obj, perm_cache_name, set("%s.%s" % (ct, name) for ct, name in perms)) return getattr(user_obj, perm_cache_name)
return self._get_permissions(user_obj, obj, 'user')
return self._get_permissions(user_obj, obj, 'group')
if not user_obj.is_active: return False for perm in self.get_all_permissions(user_obj): if perm[:perm.index('.')] == app_label: return True return False
return username
return user
UserModel = auth.get_user_model() db.reset_queries() try: try: user = UserModel._default_manager.get_by_natural_key(username) except UserModel.DoesNotExist: return [] if not user.is_active: return [] return [force_bytes(group.name) for group in user.groups.all()] finally: db.close_old_connections()
if password is None: return UNUSABLE_PASSWORD_PREFIX + get_random_string(UNUSABLE_PASSWORD_SUFFIX_LENGTH) hasher = get_hasher(hasher) if not salt: salt = hasher.salt() return hasher.encode(password, salt)
if hasattr(algorithm, 'algorithm'): return algorithm elif algorithm == 'default': return get_hashers()[0] else: hashers = get_hashers_by_algorithm() try: return hashers[algorithm] except KeyError: raise ValueError("Unknown password hashing algorithm '%s'. " "Did you specify it in the PASSWORD_HASHERS " "setting?" % algorithm)
masked = hash[:show] masked += char * len(hash[show:]) return masked
return get_random_string()
raise NotImplementedError('subclasses of BasePasswordHasher must provide a verify() method')
raise NotImplementedError('subclasses of BasePasswordHasher must provide an encode() method')
raise NotImplementedError('subclasses of BasePasswordHasher must provide a safe_summary() method')
warnings.warn('subclasses of BasePasswordHasher should provide a harden_runtime() method')
algorithm = "pbkdf2_sha256" iterations = 36000 digest = hashlib.sha256 def encode(self, password, salt, iterations=None): assert password is not None assert salt and '$' not in salt if not iterations: iterations = self.iterations hash = pbkdf2(password, salt, iterations, digest=self.digest) hash = base64.b64encode(hash).decode('ascii').strip() return "%s$%d$%s$%s" % (self.algorithm, iterations, salt, hash) def verify(self, password, encoded): algorithm, iterations, salt, hash = encoded.split('$', 3) assert algorithm == self.algorithm encoded_2 = self.encode(password, salt, int(iterations)) return constant_time_compare(encoded, encoded_2) def safe_summary(self, encoded): algorithm, iterations, salt, hash = encoded.split('$', 3) assert algorithm == self.algorithm return OrderedDict([ (_('algorithm'), algorithm), (_('iterations'), iterations), (_('salt'), mask_hash(salt)), (_('hash'), mask_hash(hash)), ]) def must_update(self, encoded): algorithm, iterations, salt, hash = encoded.split('$', 3) return int(iterations) != self.iterations def harden_runtime(self, password, encoded): algorithm, iterations, salt, hash = encoded.split('$', 3) extra_iterations = self.iterations - int(iterations) if extra_iterations > 0: self.encode(password, salt, extra_iterations)
algorithm = "pbkdf2_sha1" digest = hashlib.sha1
algorithm = "bcrypt" digest = None
algorithm = "sha1" def encode(self, password, salt): assert password is not None assert salt and '$' not in salt hash = hashlib.sha1(force_bytes(salt + password)).hexdigest() return "%s$%s$%s" % (self.algorithm, salt, hash) def verify(self, password, encoded): algorithm, salt, hash = encoded.split('$', 2) assert algorithm == self.algorithm encoded_2 = self.encode(password, salt) return constant_time_compare(encoded, encoded_2) def safe_summary(self, encoded): algorithm, salt, hash = encoded.split('$', 2) assert algorithm == self.algorithm return OrderedDict([ (_('algorithm'), algorithm), (_('salt'), mask_hash(salt, show=2)), (_('hash'), mask_hash(hash)), ]) def harden_runtime(self, password, encoded): pass
algorithm = "md5" def encode(self, password, salt): assert password is not None assert salt and '$' not in salt hash = hashlib.md5(force_bytes(salt + password)).hexdigest() return "%s$%s$%s" % (self.algorithm, salt, hash) def verify(self, password, encoded): algorithm, salt, hash = encoded.split('$', 2) assert algorithm == self.algorithm encoded_2 = self.encode(password, salt) return constant_time_compare(encoded, encoded_2) def safe_summary(self, encoded): algorithm, salt, hash = encoded.split('$', 2) assert algorithm == self.algorithm return OrderedDict([ (_('algorithm'), algorithm), (_('salt'), mask_hash(salt, show=2)), (_('hash'), mask_hash(hash)), ]) def harden_runtime(self, password, encoded): pass
algorithm = "unsalted_sha1" def salt(self): return '' def encode(self, password, salt): assert salt == '' hash = hashlib.sha1(force_bytes(password)).hexdigest() return 'sha1$$%s' % hash def verify(self, password, encoded): encoded_2 = self.encode(password, '') return constant_time_compare(encoded, encoded_2) def safe_summary(self, encoded): assert encoded.startswith('sha1$$') hash = encoded[6:] return OrderedDict([ (_('algorithm'), self.algorithm), (_('hash'), mask_hash(hash)), ]) def harden_runtime(self, password, encoded): pass
algorithm = "unsalted_md5" def salt(self): return '' def encode(self, password, salt): assert salt == '' return hashlib.md5(force_bytes(password)).hexdigest() def verify(self, password, encoded): if len(encoded) == 37 and encoded.startswith('md5$$'): encoded = encoded[5:] encoded_2 = self.encode(password, '') return constant_time_compare(encoded, encoded_2) def safe_summary(self, encoded): return OrderedDict([ (_('algorithm'), self.algorithm), (_('hash'), mask_hash(encoded, show=3)), ]) def harden_runtime(self, password, encoded): pass
actual_decorator = user_passes_test( lambda u: u.is_authenticated, login_url=login_url, redirect_field_name=redirect_field_name ) if function: return actual_decorator(function) return actual_decorator
def process_request(self, request): pass
if not settings.USE_I18N: return urls prefix_default_language = kwargs.pop('prefix_default_language', True) assert not kwargs, 'Unexpected kwargs for i18n_patterns(): %s' % kwargs return [LocaleRegexURLResolver(list(urls), prefix_default_language=prefix_default_language)]
for url_pattern in get_resolver(urlconf).url_patterns: if isinstance(url_pattern, LocaleRegexURLResolver): return True, url_pattern.prefix_default_language return False, False
settings_module = os.environ.get(ENVIRONMENT_VARIABLE) if not settings_module: desc = ("setting %s" % name) if name else "settings" raise ImproperlyConfigured( "Requested %s, but settings are not configured. " "You must either define the environment variable %s " "or call settings.configure() before accessing settings." % (desc, ENVIRONMENT_VARIABLE)) self._wrapped = Settings(settings_module)
if self._wrapped is not empty: raise RuntimeError('Settings already configured.') holder = UserSettingsHolder(default_settings) for name, value in options.items(): setattr(holder, name, value) self._wrapped = holder
return self._wrapped is not empty
def __setattr__(self, name, value): if name in ("MEDIA_URL", "STATIC_URL") and value and not value.endswith('/'): raise ImproperlyConfigured("If set, %s must end with a slash" % name) object.__setattr__(self, name, value)
self.__dict__['_deleted'] = set() self.default_settings = default_settings
@wraps(view_func, assigned=available_attrs(view_func)) def _wrapped_view_func(request, *args, **kwargs): response = view_func(request, *args, **kwargs) add_never_cache_headers(response) return response return _wrapped_view_func
def wrapped_view(*args, **kwargs): resp = view_func(*args, **kwargs) if resp.get('X-Frame-Options') is None: resp['X-Frame-Options'] = 'DENY' return resp return wraps(view_func, assigned=available_attrs(view_func))(wrapped_view)
def wrapped_view(*args, **kwargs): resp = view_func(*args, **kwargs) if resp.get('X-Frame-Options') is None: resp['X-Frame-Options'] = 'SAMEORIGIN' return resp return wraps(view_func, assigned=available_attrs(view_func))(wrapped_view)
def wrapped_view(*args, **kwargs): resp = view_func(*args, **kwargs) resp.xframe_options_exempt = True return resp return wraps(view_func, assigned=available_attrs(view_func))(wrapped_view)
def decorator(func): @wraps(func, assigned=available_attrs(func)) def inner_func(*args, **kwargs): response = func(*args, **kwargs) patch_vary_headers(response, headers) return response return inner_func return decorator
@wraps(func, assigned=available_attrs(func)) def inner_func(*args, **kwargs): response = func(*args, **kwargs) patch_vary_headers(response, ('Cookie',)) return response return inner_func
def decorator(func): @functools.wraps(func) def sensitive_variables_wrapper(*func_args, **func_kwargs): if variables: sensitive_variables_wrapper.sensitive_variables = variables else: sensitive_variables_wrapper.sensitive_variables = '__ALL__' return func(*func_args, **func_kwargs) return sensitive_variables_wrapper return decorator
def decorator(view): @functools.wraps(view) def sensitive_post_parameters_wrapper(request, *args, **kwargs): assert isinstance(request, HttpRequest), ( "sensitive_post_parameters didn't receive an HttpRequest. " "If you are decorating a classmethod, be sure to use " "@method_decorator." ) if parameters: request.sensitive_post_parameters = parameters else: request.sensitive_post_parameters = '__ALL__' return view(request, *args, **kwargs) return sensitive_post_parameters_wrapper return decorator
if self.queryset is not None: queryset = self.queryset if isinstance(queryset, QuerySet): queryset = queryset.all() elif self.model is not None: queryset = self.model._default_manager.all() else: raise ImproperlyConfigured( "%(cls)s is missing a QuerySet. Define " "%(cls)s.model, %(cls)s.queryset, or override " "%(cls)s.get_queryset()." % { 'cls': self.__class__.__name__ } ) ordering = self.get_ordering() if ordering: if isinstance(ordering, six.string_types): ordering = (ordering,) queryset = queryset.order_by(*ordering) return queryset
return self.ordering
paginator = self.get_paginator( queryset, page_size, orphans=self.get_paginate_orphans(), allow_empty_first_page=self.get_allow_empty()) page_kwarg = self.page_kwarg page = self.kwargs.get(page_kwarg) or self.request.GET.get(page_kwarg) or 1 try: page_number = int(page) except ValueError: if page == 'last': page_number = paginator.num_pages else: raise Http404(_("Page is not 'last', nor can it be converted to an int.")) try: page = paginator.page(page_number) return (paginator, page, page.object_list, page.has_other_pages()) except InvalidPage as e: raise Http404(_('Invalid page (%(page_number)s): %(message)s') % { 'page_number': page_number, 'message': str(e) })
return self.paginate_by
return self.paginator_class( queryset, per_page, orphans=orphans, allow_empty_first_page=allow_empty_first_page, **kwargs)
return self.paginate_orphans
return self.allow_empty
if self.context_object_name: return self.context_object_name elif hasattr(object_list, 'model'): return '%s_list' % object_list.model._meta.model_name else: return None
queryset = kwargs.pop('object_list', self.object_list) page_size = self.get_paginate_by(queryset) context_object_name = self.get_context_object_name(queryset) if page_size: paginator, page, queryset, is_paginated = self.paginate_queryset(queryset, page_size) context = { 'paginator': paginator, 'page_obj': page, 'is_paginated': is_paginated, 'object_list': queryset } else: context = { 'paginator': None, 'page_obj': None, 'is_paginated': False, 'object_list': queryset } if context_object_name is not None: context[context_object_name] = queryset context.update(kwargs) return super(MultipleObjectMixin, self).get_context_data(**context)
return self.initial.copy()
return self.prefix
return self.form_class
if form_class is None: form_class = self.get_form_class() return form_class(**self.get_form_kwargs())
kwargs = { 'initial': self.get_initial(), 'prefix': self.get_prefix(), } if self.request.method in ('POST', 'PUT'): kwargs.update({ 'data': self.request.POST, 'files': self.request.FILES, }) return kwargs
return HttpResponseRedirect(self.get_success_url())
return self.render_to_response(self.get_context_data(form=form))
if 'form' not in kwargs: kwargs['form'] = self.get_form() return super(FormMixin, self).get_context_data(**kwargs)
kwargs = super(ModelFormMixin, self).get_form_kwargs() if hasattr(self, 'object'): kwargs.update({'instance': self.object}) return kwargs
if self.success_url: url = self.success_url.format(**self.object.__dict__) else: try: url = self.object.get_absolute_url() except AttributeError: raise ImproperlyConfigured( "No URL to redirect to. Either provide a url or define" " a get_absolute_url method on the Model.") return url
self.object = form.save() return super(ModelFormMixin, self).form_valid(form)
return self.render_to_response(self.get_context_data())
def get(self, request, *args, **kwargs): self.object = None return super(BaseCreateView, self).get(request, *args, **kwargs) def post(self, request, *args, **kwargs): self.object = None return super(BaseCreateView, self).post(request, *args, **kwargs)
template_name_suffix = '_form'
def get(self, request, *args, **kwargs): self.object = self.get_object() return super(BaseUpdateView, self).get(request, *args, **kwargs) def post(self, request, *args, **kwargs): self.object = self.get_object() return super(BaseUpdateView, self).post(request, *args, **kwargs)
template_name_suffix = '_form'
return self.year_format
year = self.year if year is None: try: year = self.kwargs['year'] except KeyError: try: year = self.request.GET['year'] except KeyError: raise Http404(_("No year specified")) return year
return _get_next_prev(self, date, is_previous=False, period='year')
return _get_next_prev(self, date, is_previous=True, period='year')
return date.replace(year=date.year + 1, month=1, day=1)
return date.replace(month=1, day=1)
return self.month_format
month = self.month if month is None: try: month = self.kwargs['month'] except KeyError: try: month = self.request.GET['month'] except KeyError: raise Http404(_("No month specified")) return month
return _get_next_prev(self, date, is_previous=False, period='month')
return _get_next_prev(self, date, is_previous=True, period='month')
if date.month == 12: return date.replace(year=date.year + 1, month=1, day=1) else: return date.replace(month=date.month + 1, day=1)
return date.replace(day=1)
return self.day_format
day = self.day if day is None: try: day = self.kwargs['day'] except KeyError: try: day = self.request.GET['day'] except KeyError: raise Http404(_("No day specified")) return day
return _get_next_prev(self, date, is_previous=False, period='day')
return _get_next_prev(self, date, is_previous=True, period='day')
return date + datetime.timedelta(days=1)
return date
return self.week_format
week = self.week if week is None: try: week = self.kwargs['week'] except KeyError: try: week = self.request.GET['week'] except KeyError: raise Http404(_("No week specified")) return week
return _get_next_prev(self, date, is_previous=False, period='week')
return _get_next_prev(self, date, is_previous=True, period='week')
return date + datetime.timedelta(days=7 - self._get_weekday(date))
return date - datetime.timedelta(self._get_weekday(date))
if self.date_field is None: raise ImproperlyConfigured("%s.date_field is required." % self.__class__.__name__) return self.date_field
model = self.get_queryset().model if self.model is None else self.model field = model._meta.get_field(self.get_date_field()) return isinstance(field, models.DateTimeField)
if self.uses_datetime_field: value = datetime.datetime.combine(value, datetime.time.min) if settings.USE_TZ: value = timezone.make_aware(value, timezone.get_current_timezone()) return value
raise NotImplementedError('A DateView must provide an implementation of get_dated_items()')
return '-%s' % self.get_date_field() if self.ordering is None else self.ordering
return self.date_list_period
date_field = self.get_date_field() allow_empty = self.get_allow_empty() if date_type is None: date_type = self.get_date_list_period() if self.uses_datetime_field: date_list = queryset.datetimes(date_field, date_type, ordering) else: date_list = queryset.dates(date_field, date_type, ordering) if date_list is not None and not date_list and not allow_empty: name = force_text(queryset.model._meta.verbose_name_plural) raise Http404(_("No %(verbose_name_plural)s available") % {'verbose_name_plural': name}) return date_list
qs = self.get_dated_queryset() date_list = self.get_date_list(qs, ordering='DESC') if not date_list: qs = qs.none() return (date_list, qs, {})
template_name_suffix = '_archive'
return self.make_object_list
template_name_suffix = '_archive_year'
year = self.get_year() month = self.get_month() date_field = self.get_date_field() date = _date_from_string(year, self.get_year_format(), month, self.get_month_format()) since = self._make_date_lookup_arg(date) until = self._make_date_lookup_arg(self._get_next_month(date)) lookup_kwargs = { '%s__gte' % date_field: since, '%s__lt' % date_field: until, } qs = self.get_dated_queryset(**lookup_kwargs) date_list = self.get_date_list(qs) return (date_list, qs, { 'month': date, 'next_month': self.get_next_month(date), 'previous_month': self.get_previous_month(date), })
template_name_suffix = '_archive_month'
year = self.get_year() week = self.get_week() date_field = self.get_date_field() week_format = self.get_week_format() week_start = { '%W': '1', '%U': '0', }[week_format] date = _date_from_string(year, self.get_year_format(), week_start, '%w', week, week_format) since = self._make_date_lookup_arg(date) until = self._make_date_lookup_arg(self._get_next_week(date)) lookup_kwargs = { '%s__gte' % date_field: since, '%s__lt' % date_field: until, } qs = self.get_dated_queryset(**lookup_kwargs) return (None, qs, { 'week': date, 'next_week': self.get_next_week(date), 'previous_week': self.get_previous_week(date), })
template_name_suffix = '_archive_week'
year = self.get_year() month = self.get_month() day = self.get_day() date = _date_from_string(year, self.get_year_format(), month, self.get_month_format(), day, self.get_day_format()) return self._get_dated_items(date)
lookup_kwargs = self._make_single_date_lookup(date) qs = self.get_dated_queryset(**lookup_kwargs) return (None, qs, { 'day': date, 'previous_day': self.get_previous_day(date), 'next_day': self.get_next_day(date), 'previous_month': self.get_previous_month(date), 'next_month': self.get_next_month(date) })
template_name_suffix = "_archive_day"
return self._get_dated_items(datetime.date.today())
template_name_suffix = "_archive_day"
template_name_suffix = '_detail'
format = delim.join((year_format, month_format, day_format)) datestr = delim.join((year, month, day)) try: return datetime.datetime.strptime(force_str(datestr), format).date() except ValueError: raise Http404(_("Invalid date string '%(datestr)s' given format '%(format)s'") % { 'datestr': datestr, 'format': format, })
def get_context_data(self, **kwargs): if 'view' not in kwargs: kwargs['view'] = self return kwargs
response = http.HttpResponse() response['Allow'] = ', '.join(self._allowed_methods()) response['Content-Length'] = '0' return response
response_kwargs.setdefault('content_type', self.content_type) return self.response_class( request=self.request, template=self.get_template_names(), context=context, using=self.template_engine, **response_kwargs )
if self.template_name is None: raise ImproperlyConfigured( "TemplateResponseMixin requires either a definition of " "'template_name' or an implementation of 'get_template_names()'") else: return [self.template_name]
def get(self, request, *args, **kwargs): context = self.get_context_data(**kwargs) return self.render_to_response(context)
if self.url: url = self.url % kwargs elif self.pattern_name: try: url = reverse(self.pattern_name, args=args, kwargs=kwargs) except NoReverseMatch: return None else: return None args = self.request.META.get('QUERY_STRING', '') if args and self.query_string: url = "%s?%s" % (url, args) return url
if self.queryset is None: if self.model: return self.model._default_manager.all() else: raise ImproperlyConfigured( "%(cls)s is missing a QuerySet. Define " "%(cls)s.model, %(cls)s.queryset, or override " "%(cls)s.get_queryset()." % { 'cls': self.__class__.__name__ } ) return self.queryset.all()
return self.slug_field
if self.context_object_name: return self.context_object_name elif isinstance(obj, models.Model): return obj._meta.model_name else: return None
context = {} if self.object: context['object'] = self.object context_object_name = self.get_context_object_name(self.object) if context_object_name: context[context_object_name] = self.object context.update(kwargs) return super(SingleObjectMixin, self).get_context_data(**context)
def get(self, request, *args, **kwargs): self.object = self.get_object() context = self.get_context_data(object=self.object) return self.render_to_response(context)
return render_javascript_catalog()
warnings.warn( "The javascript_catalog() view is deprecated in favor of the " "JavaScriptCatalog view.", RemovedInDjango20Warning, stacklevel=2 ) locale = _get_locale(request) packages = _parse_packages(packages) catalog, plural = get_javascript_catalog(locale, domain, packages) return render_javascript_catalog(catalog, plural)
def __init__(self, callable_setting): self._wrapped = callable_setting def __repr__(self): return repr(self._wrapped)
reporter = ExceptionReporter(request, exc_type, exc_value, tb) if request.is_ajax(): text = reporter.get_traceback_text() return HttpResponse(text, status=status_code, content_type='text/plain') else: html = reporter.get_traceback_html() return HttpResponse(html, status=status_code, content_type='text/html')
def get_post_parameters(self, request): if request is None: return {} else: return request.POST def get_traceback_frame_variables(self, request, tb_frame): return list(tb_frame.f_locals.items())
return settings.DEBUG is False
sensitive_post_parameters = getattr(request, 'sensitive_post_parameters', []) if self.is_active(request) and sensitive_post_parameters: multivaluedict = multivaluedict.copy() for param in sensitive_post_parameters: if param in multivaluedict: multivaluedict[param] = CLEANSED_SUBSTITUTE return multivaluedict
import traceback frames = self.get_traceback_frames() tb = [(f['filename'], f['lineno'], f['function'], f['context_line']) for f in frames] list = ['Traceback (most recent call last):\n'] list += traceback.format_list(tb) list += traceback.format_exception_only(self.exc_type, self.exc_value) return list
{% if frame.post_context and not is_email %} <ol start='{{ frame.lineno|add:"1" }}' class="post-context" id="post{{ frame.id }}"> {% for line in frame.post_context %} <li onclick="toggle('pre{{ frame.id }}', 'post{{ frame.id }}')"><pre>{{ line|escape }}</pre></li> {% endfor %} </ol> {% endif %}
if not self.apps_ready: raise AppRegistryNotReady("Apps aren't loaded yet.")
if not self.models_ready: raise AppRegistryNotReady("Models aren't loaded yet.")
self.check_apps_ready() return self.app_configs.values()
self.check_models_ready() result = [] for app_config in self.app_configs.values(): result.extend(list(app_config.get_models(include_auto_created, include_swapped))) return result
self.check_models_ready() if model_name is None: app_label, model_name = app_label.split('.') return self.get_app_config(app_label).get_model(model_name.lower())
self.check_apps_ready() return any(ac.name == app_name for ac in self.app_configs.values())
self.check_apps_ready() candidates = [] for app_config in self.app_configs.values(): if object_name.startswith(app_config.name): subpath = object_name[len(app_config.name):] if subpath == '' or subpath[0] == '.': candidates.append(app_config) if candidates: return sorted(candidates, key=lambda ac: -len(ac.name))[0]
model = self.all_models[app_label].get(model_name.lower()) if model is None: raise LookupError( "Model '%s.%s' not registered." % (app_label, model_name)) return model
available = set(available) installed = set(app_config.name for app_config in self.get_app_configs()) if not available.issubset(installed): raise ValueError( "Available apps isn't a subset of installed apps, extra apps: %s" % ", ".join(available - installed) ) self.stored_app_configs.append(self.app_configs) self.app_configs = OrderedDict( (label, app_config) for label, app_config in self.app_configs.items() if app_config.name in available) self.clear_cache()
self.app_configs = self.stored_app_configs.pop() self.clear_cache()
if not self.ready: raise AppRegistryNotReady("App registry isn't ready yet.") self.stored_app_configs.append(self.app_configs) self.app_configs = OrderedDict() self.apps_ready = self.models_ready = self.ready = False self.clear_cache() self.populate(installed)
self.app_configs = self.stored_app_configs.pop() self.apps_ready = self.models_ready = self.ready = True self.clear_cache()
if self.models is None: raise AppRegistryNotReady( "Models for app '%s' haven't been imported yet." % self.label)
self.check_models_ready() try: return self.models[model_name.lower()] except KeyError: raise LookupError( "App '%s' doesn't have a '%s' model." % (self.label, model_name))
self.check_models_ready() for model in self.models.values(): if model._meta.auto_created and not include_auto_created: continue if model._meta.swapped and not include_swapped: continue yield model
return get_callable(settings.CSRF_FAILURE_VIEW)
salt = _get_new_csrf_string() chars = CSRF_ALLOWED_CHARS pairs = zip((chars.index(x) for x in secret), (chars.index(x) for x in salt)) cipher = ''.join(chars[(x + y) % len(chars)] for x, y in pairs) return salt + cipher
if "CSRF_COOKIE" not in request.META: csrf_secret = _get_new_csrf_string() request.META["CSRF_COOKIE"] = _salt_cipher_secret(csrf_secret) else: csrf_secret = _unsalt_cipher_token(request.META["CSRF_COOKIE"]) request.META["CSRF_COOKIE_USED"] = True return _salt_cipher_secret(csrf_secret)
request.META.update({ "CSRF_COOKIE_USED": True, "CSRF_COOKIE": _get_new_csrf_token(), }) request.csrf_cookie_needs_reset = True
return getattr(settings, 'X_FRAME_OPTIONS', 'SAMEORIGIN').upper()
if settings.APPEND_SLASH and not request.get_full_path().endswith('/'): urlconf = getattr(request, 'urlconf', None) return ( not is_valid_path(request.path_info, urlconf) and is_valid_path('%s/' % request.path_info, urlconf) ) return False
new_path = request.get_full_path(force_append_slash=True) if settings.DEBUG and request.method in ('POST', 'PUT', 'PATCH'): raise RuntimeError( "You called this URL via %(method)s, but the URL doesn't end " "in a slash and you have APPEND_SLASH set. Django can't " "redirect to the slash URL while maintaining %(method)s data. " "Change your form to point to %(url)s (note the trailing " "slash), or set APPEND_SLASH=False in your Django settings." % { 'method': request.method, 'url': request.get_host() + new_path, } ) return new_path
if response.status_code == 404 and not settings.DEBUG: domain = request.get_host() path = request.get_full_path() referer = force_text(request.META.get('HTTP_REFERER', ''), errors='replace') if not self.is_ignorable_request(request, path, domain, referer): ua = force_text(request.META.get('HTTP_USER_AGENT', '<none>'), errors='replace') ip = request.META.get('REMOTE_ADDR', '<none>') mail_managers( "Broken %slink on %s" % ( ('INTERNAL ' if self.is_internal_request(domain, referer) else ''), domain ), "Referrer: %s\nRequested URL: %s\nUser agent: %s\n" "IP address: %s\n" % (referer, path, ua, ip), fail_silently=True) return response
def process_response(self, request, response): response['Date'] = http_date() if not response.streaming and not response.has_header('Content-Length'): response['Content-Length'] = str(len(response.content)) etag = response.get('ETag') last_modified = response.get('Last-Modified') if last_modified: last_modified = parse_http_date_safe(last_modified) if etag or last_modified: return get_conditional_response( request, etag=unquote_etag(etag), last_modified=last_modified, response=response, ) return response
from django.db import models from django.utils.encoding import python_2_unicode_compatible @python_2_unicode_compatible class User(models.Model): name = models.CharField(max_length=200) def __str__(self): return self.name @python_2_unicode_compatible class Poll(models.Model): question = models.CharField(max_length=200) creator = models.ForeignKey(User, models.CASCADE) def __str__(self): return self.question @python_2_unicode_compatible class Choice(models.Model): name = models.CharField(max_length=100) poll = models.ForeignKey(Poll, models.CASCADE, related_name="poll_choice") related_poll = models.ForeignKey(Poll, models.CASCADE, related_name="related_choice") def __str__(self): return self.name
Worker.objects.filter(department__gte=0)
Worker.objects.filter(department__lte=0)
class MissingDjangoVersion(models.Model): title = models.CharField(max_length=10) def __reduce__(self): reduce_list = super(MissingDjangoVersion, self).__reduce__() data = reduce_list[-1] del data[DJANGO_VERSION_PICKLE_KEY] return reduce_list p = MissingDjangoVersion(title="FooBar") msg = "Pickled model instance's Django version is not specified." with self.assertRaisesMessage(RuntimeWarning, msg): pickle.loads(pickle.dumps(p))
class DifferentDjangoVersion(models.Model): title = models.CharField(max_length=10) def __reduce__(self): reduce_list = super(DifferentDjangoVersion, self).__reduce__() data = reduce_list[-1] data[DJANGO_VERSION_PICKLE_KEY] = '1.0' return reduce_list p = DifferentDjangoVersion(title="FooBar") msg = "Pickled model instance's Django version 1.0 does not match the current version %s." % get_version() with self.assertRaisesMessage(RuntimeWarning, msg): pickle.loads(pickle.dumps(p))
self.assertEqual( (User.objects .extra(select={"alpha": "%s"}, select_params=(1,)) .extra(select={"beta": "%s"}, select_params=(2,))[0].alpha), 1 ) self.assertEqual( (User.objects .extra(select={"beta": "%s"}, select_params=(1,)) .extra(select={"alpha": "%s"}, select_params=(2,))[0].alpha), 2 )
self.assertEqual( list(User.objects.extra(select={"alpha": "%s"}, select_params=(-6,)) .filter(id=self.u.id).values_list('id', flat=True)), [self.u.id] )
qs = User.objects.all().extra(where=['id=%s'], params=[self.u.id]) self.assertQuerysetEqual(qs, ['<User: fred>']) self.assertQuerysetEqual(qs[:1], ['<User: fred>'])
self.assertQuerysetEqual( (Order.objects .extra(where=["username=%s"], params=["fred"], tables=["auth_user"]) .order_by('created_by')), [] )
self.assertQuerysetEqual( User.objects.filter(pk=self.u.id).extra(select={'extra_field': 1}).distinct(), ['<User: fred>'] ) self.assertQuerysetEqual( User.objects.filter(pk=self.u.id).extra(select={'extra_field': 1}, order_by=['extra_field']), ['<User: fred>'] ) self.assertQuerysetEqual( User.objects.filter(pk=self.u.id).extra(select={'extra_field': 1}, order_by=['extra_field']).distinct(), ['<User: fred>'] )
RevisionableModel.objects.create( title='First Revision', when=datetime.datetime(2008, 9, 28, 10, 30, 0) ) self.assertQuerysetEqual( RevisionableModel.objects.extra(select={"the_answer": 'id'}).datetimes('when', 'month'), [datetime.datetime(2008, 9, 1, 0, 0)], transform=lambda d: d, )
obj = TestObject(first='first', second='second', third='third') obj.save() self.assertEqual( list(TestObject.objects.extra(select={'extra': 1}).values('pk')), [{'pk': obj.pk}] ) self.assertQuerysetEqual( TestObject.objects.filter( pk__in=TestObject.objects.extra(select={'extra': 1}).values('pk') ), ['<TestObject: TestObject: first,second,third>'] ) self.assertEqual( list(TestObject.objects.values('pk').extra(select={'extra': 1})), [{'pk': obj.pk}] ) self.assertQuerysetEqual( TestObject.objects.filter( pk__in=TestObject.objects.values('pk').extra(select={'extra': 1}) ), ['<TestObject: TestObject: first,second,third>'] ) self.assertQuerysetEqual( TestObject.objects.filter(pk=obj.pk) | TestObject.objects.extra(where=["id > %s"], params=[obj.pk]), ['<TestObject: TestObject: first,second,third>'] )
paths = [] first_package_re = re.compile(r'(^[^\.]+)\.') for backend in settings.DATABASES.values(): result = first_package_re.findall(backend['ENGINE']) if result and result != ['django']: backend_pkg = __import__(result[0]) backend_dir = os.path.dirname(backend_pkg.__file__) paths.append(os.path.dirname(backend_dir)) return paths
def setUp(self): self.write_settings('settings.py') def tearDown(self): self.remove_settings('settings.py') def test_builtin_command(self): "default: django-admin builtin commands fail with an error when no settings provided" args = ['check', 'admin_scripts'] out, err = self.run_django_admin(args) self.assertNoOutput(out) self.assertOutput(err, 'settings are not configured') def test_builtin_with_settings(self): "default: django-admin builtin commands succeed if settings are provided as argument" args = ['check', '--settings=test_project.settings', 'admin_scripts'] out, err = self.run_django_admin(args) self.assertNoOutput(err) self.assertOutput(out, SYSTEM_CHECK_MSG) def test_builtin_with_environment(self): "default: django-admin builtin commands succeed if settings are provided in the environment" args = ['check', 'admin_scripts'] out, err = self.run_django_admin(args, 'test_project.settings') self.assertNoOutput(err) self.assertOutput(out, SYSTEM_CHECK_MSG) def test_builtin_with_bad_settings(self): "default: django-admin builtin commands fail if settings file (from argument) doesn't exist" args = ['check', '--settings=bad_settings', 'admin_scripts'] out, err = self.run_django_admin(args) self.assertNoOutput(out) self.assertOutput(err, "No module named '?bad_settings'?", regex=True) def test_builtin_with_bad_environment(self): "default: django-admin builtin commands fail if settings file (from environment) doesn't exist" args = ['check', 'admin_scripts'] out, err = self.run_django_admin(args, 'bad_settings') self.assertNoOutput(out) self.assertOutput(err, "No module named '?bad_settings'?", regex=True) def test_custom_command(self): "default: django-admin can't execute user commands if it isn't provided settings" args = ['noargs_command'] out, err = self.run_django_admin(args) self.assertNoOutput(out) self.assertOutput(err, "No Django settings specified") self.assertOutput(err, "Unknown command: 'noargs_command'") def test_custom_command_with_settings(self): "default: django-admin can execute user commands if settings are provided as argument" args = ['noargs_command', '--settings=test_project.settings'] out, err = self.run_django_admin(args) self.assertNoOutput(err) self.assertOutput(out, "EXECUTE: noargs_command") def test_custom_command_with_environment(self): "default: django-admin can execute user commands if settings are provided in environment" args = ['noargs_command'] out, err = self.run_django_admin(args, 'test_project.settings') self.assertNoOutput(err) self.assertOutput(out, "EXECUTE: noargs_command")
def setUp(self): self.write_settings('settings.py', ['django.contrib.auth', 'django.contrib.contenttypes', 'admin_scripts', 'admin_scripts.complex_app']) def tearDown(self): self.remove_settings('settings.py') def test_builtin_command(self): "fulldefault: django-admin builtin commands fail with an error when no settings provided" args = ['check', 'admin_scripts'] out, err = self.run_django_admin(args) self.assertNoOutput(out) self.assertOutput(err, 'settings are not configured') def test_builtin_with_settings(self): "fulldefault: django-admin builtin commands succeed if a settings file is provided" args = ['check', '--settings=test_project.settings', 'admin_scripts'] out, err = self.run_django_admin(args) self.assertNoOutput(err) self.assertOutput(out, SYSTEM_CHECK_MSG) def test_builtin_with_environment(self): "fulldefault: django-admin builtin commands succeed if the environment contains settings" args = ['check', 'admin_scripts'] out, err = self.run_django_admin(args, 'test_project.settings') self.assertNoOutput(err) self.assertOutput(out, SYSTEM_CHECK_MSG) def test_builtin_with_bad_settings(self): "fulldefault: django-admin builtin commands fail if settings file (from argument) doesn't exist" args = ['check', '--settings=bad_settings', 'admin_scripts'] out, err = self.run_django_admin(args) self.assertNoOutput(out) self.assertOutput(err, "No module named '?bad_settings'?", regex=True) def test_builtin_with_bad_environment(self): "fulldefault: django-admin builtin commands fail if settings file (from environment) doesn't exist" args = ['check', 'admin_scripts'] out, err = self.run_django_admin(args, 'bad_settings') self.assertNoOutput(out) self.assertOutput(err, "No module named '?bad_settings'?", regex=True) def test_custom_command(self): "fulldefault: django-admin can't execute user commands unless settings are provided" args = ['noargs_command'] out, err = self.run_django_admin(args) self.assertNoOutput(out) self.assertOutput(err, "No Django settings specified") self.assertOutput(err, "Unknown command: 'noargs_command'") def test_custom_command_with_settings(self): "fulldefault: django-admin can execute user commands if settings are provided as argument" args = ['noargs_command', '--settings=test_project.settings'] out, err = self.run_django_admin(args) self.assertNoOutput(err) self.assertOutput(out, "EXECUTE: noargs_command") def test_custom_command_with_environment(self): "fulldefault: django-admin can execute user commands if settings are provided in environment" args = ['noargs_command'] out, err = self.run_django_admin(args, 'test_project.settings') self.assertNoOutput(err) self.assertOutput(out, "EXECUTE: noargs_command")
def setUp(self): self.write_settings('settings.py', apps=['django.contrib.auth', 'django.contrib.contenttypes']) def tearDown(self): self.remove_settings('settings.py') def test_builtin_command(self): "minimal: django-admin builtin commands fail with an error when no settings provided" args = ['check', 'admin_scripts'] out, err = self.run_django_admin(args) self.assertNoOutput(out) self.assertOutput(err, 'settings are not configured') def test_builtin_with_settings(self): "minimal: django-admin builtin commands fail if settings are provided as argument" args = ['check', '--settings=test_project.settings', 'admin_scripts'] out, err = self.run_django_admin(args) self.assertNoOutput(out) self.assertOutput(err, "No installed app with label 'admin_scripts'.") def test_builtin_with_environment(self): "minimal: django-admin builtin commands fail if settings are provided in the environment" args = ['check', 'admin_scripts'] out, err = self.run_django_admin(args, 'test_project.settings') self.assertNoOutput(out) self.assertOutput(err, "No installed app with label 'admin_scripts'.") def test_builtin_with_bad_settings(self): "minimal: django-admin builtin commands fail if settings file (from argument) doesn't exist" args = ['check', '--settings=bad_settings', 'admin_scripts'] out, err = self.run_django_admin(args) self.assertNoOutput(out) self.assertOutput(err, "No module named '?bad_settings'?", regex=True) def test_builtin_with_bad_environment(self): "minimal: django-admin builtin commands fail if settings file (from environment) doesn't exist" args = ['check', 'admin_scripts'] out, err = self.run_django_admin(args, 'bad_settings') self.assertNoOutput(out) self.assertOutput(err, "No module named '?bad_settings'?", regex=True) def test_custom_command(self): "minimal: django-admin can't execute user commands unless settings are provided" args = ['noargs_command'] out, err = self.run_django_admin(args) self.assertNoOutput(out) self.assertOutput(err, "No Django settings specified") self.assertOutput(err, "Unknown command: 'noargs_command'") def test_custom_command_with_settings(self): "minimal: django-admin can't execute user commands, even if settings are provided as argument" args = ['noargs_command', '--settings=test_project.settings'] out, err = self.run_django_admin(args) self.assertNoOutput(out) self.assertOutput(err, "Unknown command: 'noargs_command'") def test_custom_command_with_environment(self): "minimal: django-admin can't execute user commands, even if settings are provided in environment" args = ['noargs_command'] out, err = self.run_django_admin(args, 'test_project.settings') self.assertNoOutput(out) self.assertOutput(err, "Unknown command: 'noargs_command'")
def setUp(self): self.write_settings('alternate_settings.py') def tearDown(self): self.remove_settings('alternate_settings.py') def test_builtin_command(self): "alternate: django-admin builtin commands fail with an error when no settings provided" args = ['check', 'admin_scripts'] out, err = self.run_django_admin(args) self.assertNoOutput(out) self.assertOutput(err, 'settings are not configured') def test_builtin_with_settings(self): "alternate: django-admin builtin commands succeed if settings are provided as argument" args = ['check', '--settings=test_project.alternate_settings', 'admin_scripts'] out, err = self.run_django_admin(args) self.assertNoOutput(err) self.assertOutput(out, SYSTEM_CHECK_MSG) def test_builtin_with_environment(self): "alternate: django-admin builtin commands succeed if settings are provided in the environment" args = ['check', 'admin_scripts'] out, err = self.run_django_admin(args, 'test_project.alternate_settings') self.assertNoOutput(err) self.assertOutput(out, SYSTEM_CHECK_MSG) def test_builtin_with_bad_settings(self): "alternate: django-admin builtin commands fail if settings file (from argument) doesn't exist" args = ['check', '--settings=bad_settings', 'admin_scripts'] out, err = self.run_django_admin(args) self.assertNoOutput(out) self.assertOutput(err, "No module named '?bad_settings'?", regex=True) def test_builtin_with_bad_environment(self): "alternate: django-admin builtin commands fail if settings file (from environment) doesn't exist" args = ['check', 'admin_scripts'] out, err = self.run_django_admin(args, 'bad_settings') self.assertNoOutput(out) self.assertOutput(err, "No module named '?bad_settings'?", regex=True) def test_custom_command(self): "alternate: django-admin can't execute user commands unless settings are provided" args = ['noargs_command'] out, err = self.run_django_admin(args) self.assertNoOutput(out) self.assertOutput(err, "No Django settings specified") self.assertOutput(err, "Unknown command: 'noargs_command'") def test_custom_command_with_settings(self): "alternate: django-admin can execute user commands if settings are provided as argument" args = ['noargs_command', '--settings=test_project.alternate_settings'] out, err = self.run_django_admin(args) self.assertNoOutput(err) self.assertOutput(out, "EXECUTE: noargs_command") def test_custom_command_with_environment(self): "alternate: django-admin can execute user commands if settings are provided in environment" args = ['noargs_command'] out, err = self.run_django_admin(args, 'test_project.alternate_settings') self.assertNoOutput(err) self.assertOutput(out, "EXECUTE: noargs_command")
def setUp(self): self.write_settings('settings.py', apps=['django.contrib.auth', 'django.contrib.contenttypes']) self.write_settings('alternate_settings.py') def tearDown(self): self.remove_settings('settings.py') self.remove_settings('alternate_settings.py') def test_builtin_command(self): "alternate: django-admin builtin commands fail with an error when no settings provided" args = ['check', 'admin_scripts'] out, err = self.run_django_admin(args) self.assertNoOutput(out) self.assertOutput(err, 'settings are not configured') def test_builtin_with_settings(self): "alternate: django-admin builtin commands succeed if settings are provided as argument" args = ['check', '--settings=test_project.alternate_settings', 'admin_scripts'] out, err = self.run_django_admin(args) self.assertNoOutput(err) self.assertOutput(out, SYSTEM_CHECK_MSG) def test_builtin_with_environment(self): "alternate: django-admin builtin commands succeed if settings are provided in the environment" args = ['check', 'admin_scripts'] out, err = self.run_django_admin(args, 'test_project.alternate_settings') self.assertNoOutput(err) self.assertOutput(out, SYSTEM_CHECK_MSG) def test_builtin_with_bad_settings(self): "alternate: django-admin builtin commands fail if settings file (from argument) doesn't exist" args = ['check', '--settings=bad_settings', 'admin_scripts'] out, err = self.run_django_admin(args) self.assertOutput(err, "No module named '?bad_settings'?", regex=True) def test_builtin_with_bad_environment(self): "alternate: django-admin builtin commands fail if settings file (from environment) doesn't exist" args = ['check', 'admin_scripts'] out, err = self.run_django_admin(args, 'bad_settings') self.assertNoOutput(out) self.assertOutput(err, "No module named '?bad_settings'?", regex=True) def test_custom_command(self): "alternate: django-admin can't execute user commands unless settings are provided" args = ['noargs_command'] out, err = self.run_django_admin(args) self.assertNoOutput(out) self.assertOutput(err, "No Django settings specified") self.assertOutput(err, "Unknown command: 'noargs_command'") def test_custom_command_with_settings(self): "alternate: django-admin can execute user commands if settings are provided as argument" args = ['noargs_command', '--settings=test_project.alternate_settings'] out, err = self.run_django_admin(args) self.assertNoOutput(err) self.assertOutput(out, "EXECUTE: noargs_command") def test_custom_command_with_environment(self): "alternate: django-admin can execute user commands if settings are provided in environment" args = ['noargs_command'] out, err = self.run_django_admin(args, 'test_project.alternate_settings') self.assertNoOutput(err) self.assertOutput(out, "EXECUTE: noargs_command")
def setUp(self): self.write_settings('settings', is_dir=True) def tearDown(self): self.remove_settings('settings', is_dir=True) def test_setup_environ(self): "directory: startapp creates the correct directory" args = ['startapp', 'settings_test'] app_path = os.path.join(self.test_dir, 'settings_test') out, err = self.run_django_admin(args, 'test_project.settings') self.addCleanup(shutil.rmtree, app_path) self.assertNoOutput(err) self.assertTrue(os.path.exists(app_path)) unicode_literals_import = "from __future__ import unicode_literals\n" with open(os.path.join(app_path, 'apps.py'), 'r') as f: content = f.read() self.assertIn("class SettingsTestConfig(AppConfig)", content) self.assertIn("name = 'settings_test'", content) if not PY3: self.assertIn(unicode_literals_import, content) if not PY3: with open(os.path.join(app_path, 'models.py'), 'r') as fp: content = fp.read() self.assertIn(unicode_literals_import, content) def test_setup_environ_custom_template(self): "directory: startapp creates the correct directory with a custom template" template_path = os.path.join(custom_templates_dir, 'app_template') args = ['startapp', '--template', template_path, 'custom_settings_test'] app_path = os.path.join(self.test_dir, 'custom_settings_test') out, err = self.run_django_admin(args, 'test_project.settings') self.addCleanup(shutil.rmtree, app_path) self.assertNoOutput(err) self.assertTrue(os.path.exists(app_path)) self.assertTrue(os.path.exists(os.path.join(app_path, 'api.py'))) @unittest.skipIf(PY2, "Python 2 doesn't support Unicode package names.") def test_startapp_unicode_name(self): "directory: startapp creates the correct directory with unicode characters" args = ['startapp', ''] app_path = os.path.join(self.test_dir, '') out, err = self.run_django_admin(args, 'test_project.settings') self.addCleanup(shutil.rmtree, app_path) self.assertNoOutput(err) self.assertTrue(os.path.exists(app_path)) with open(os.path.join(app_path, 'apps.py'), 'r', encoding='utf8') as f: content = f.read() self.assertIn("class Config(AppConfig)", content) self.assertIn("name = ''", content) def test_builtin_command(self): "directory: django-admin builtin commands fail with an error when no settings provided" args = ['check', 'admin_scripts'] out, err = self.run_django_admin(args) self.assertNoOutput(out) self.assertOutput(err, 'settings are not configured') def test_builtin_with_bad_settings(self): "directory: django-admin builtin commands fail if settings file (from argument) doesn't exist" args = ['check', '--settings=bad_settings', 'admin_scripts'] out, err = self.run_django_admin(args) self.assertOutput(err, "No module named '?bad_settings'?", regex=True) def test_builtin_with_bad_environment(self): "directory: django-admin builtin commands fail if settings file (from environment) doesn't exist" args = ['check', 'admin_scripts'] out, err = self.run_django_admin(args, 'bad_settings') self.assertNoOutput(out) self.assertOutput(err, "No module named '?bad_settings'?", regex=True) def test_custom_command(self): "directory: django-admin can't execute user commands unless settings are provided" args = ['noargs_command'] out, err = self.run_django_admin(args) self.assertNoOutput(out) self.assertOutput(err, "No Django settings specified") self.assertOutput(err, "Unknown command: 'noargs_command'") def test_builtin_with_settings(self): "directory: django-admin builtin commands succeed if settings are provided as argument" args = ['check', '--settings=test_project.settings', 'admin_scripts'] out, err = self.run_django_admin(args) self.assertNoOutput(err) self.assertOutput(out, SYSTEM_CHECK_MSG) def test_builtin_with_environment(self): "directory: django-admin builtin commands succeed if settings are provided in the environment" args = ['check', 'admin_scripts'] out, err = self.run_django_admin(args, 'test_project.settings') self.assertNoOutput(err) self.assertOutput(out, SYSTEM_CHECK_MSG)
def setUp(self): self.write_settings('settings.py') def tearDown(self): self.remove_settings('settings.py') def test_builtin_command(self): "default: manage.py builtin commands succeed when default settings are appropriate" args = ['check', 'admin_scripts'] out, err = self.run_manage(args) self.assertNoOutput(err) self.assertOutput(out, SYSTEM_CHECK_MSG) def test_builtin_with_settings(self): "default: manage.py builtin commands succeed if settings are provided as argument" args = ['check', '--settings=test_project.settings', 'admin_scripts'] out, err = self.run_manage(args) self.assertNoOutput(err) self.assertOutput(out, SYSTEM_CHECK_MSG) def test_builtin_with_environment(self): "default: manage.py builtin commands succeed if settings are provided in the environment" args = ['check', 'admin_scripts'] out, err = self.run_manage(args, 'test_project.settings') self.assertNoOutput(err) self.assertOutput(out, SYSTEM_CHECK_MSG) def test_builtin_with_bad_settings(self): "default: manage.py builtin commands succeed if settings file (from argument) doesn't exist" args = ['check', '--settings=bad_settings', 'admin_scripts'] out, err = self.run_manage(args) self.assertNoOutput(out) self.assertOutput(err, "No module named '?bad_settings'?", regex=True) def test_builtin_with_bad_environment(self): "default: manage.py builtin commands fail if settings file (from environment) doesn't exist" args = ['check', 'admin_scripts'] out, err = self.run_manage(args, 'bad_settings') self.assertNoOutput(out) self.assertOutput(err, "No module named '?bad_settings'?", regex=True) def test_custom_command(self): "default: manage.py can execute user commands when default settings are appropriate" args = ['noargs_command'] out, err = self.run_manage(args) self.assertNoOutput(err) self.assertOutput(out, "EXECUTE: noargs_command") def test_custom_command_with_settings(self): "default: manage.py can execute user commands when settings are provided as argument" args = ['noargs_command', '--settings=test_project.settings'] out, err = self.run_manage(args) self.assertNoOutput(err) self.assertOutput(out, "EXECUTE: noargs_command") def test_custom_command_with_environment(self): "default: manage.py can execute user commands when settings are provided in environment" args = ['noargs_command'] out, err = self.run_manage(args, 'test_project.settings') self.assertNoOutput(err) self.assertOutput(out, "EXECUTE: noargs_command")
def setUp(self): self.write_settings('settings.py', ['django.contrib.auth', 'django.contrib.contenttypes', 'admin_scripts']) def tearDown(self): self.remove_settings('settings.py') def test_builtin_command(self): "fulldefault: manage.py builtin commands succeed when default settings are appropriate" args = ['check', 'admin_scripts'] out, err = self.run_manage(args) self.assertNoOutput(err) self.assertOutput(out, SYSTEM_CHECK_MSG) def test_builtin_with_settings(self): "fulldefault: manage.py builtin commands succeed if settings are provided as argument" args = ['check', '--settings=test_project.settings', 'admin_scripts'] out, err = self.run_manage(args) self.assertNoOutput(err) self.assertOutput(out, SYSTEM_CHECK_MSG) def test_builtin_with_environment(self): "fulldefault: manage.py builtin commands succeed if settings are provided in the environment" args = ['check', 'admin_scripts'] out, err = self.run_manage(args, 'test_project.settings') self.assertNoOutput(err) self.assertOutput(out, SYSTEM_CHECK_MSG) def test_builtin_with_bad_settings(self): "fulldefault: manage.py builtin commands succeed if settings file (from argument) doesn't exist" args = ['check', '--settings=bad_settings', 'admin_scripts'] out, err = self.run_manage(args) self.assertNoOutput(out) self.assertOutput(err, "No module named '?bad_settings'?", regex=True) def test_builtin_with_bad_environment(self): "fulldefault: manage.py builtin commands fail if settings file (from environment) doesn't exist" args = ['check', 'admin_scripts'] out, err = self.run_manage(args, 'bad_settings') self.assertNoOutput(out) self.assertOutput(err, "No module named '?bad_settings'?", regex=True) def test_custom_command(self): "fulldefault: manage.py can execute user commands when default settings are appropriate" args = ['noargs_command'] out, err = self.run_manage(args) self.assertNoOutput(err) self.assertOutput(out, "EXECUTE: noargs_command") def test_custom_command_with_settings(self): "fulldefault: manage.py can execute user commands when settings are provided as argument" args = ['noargs_command', '--settings=test_project.settings'] out, err = self.run_manage(args) self.assertNoOutput(err) self.assertOutput(out, "EXECUTE: noargs_command") def test_custom_command_with_environment(self): "fulldefault: manage.py can execute user commands when settings are provided in environment" args = ['noargs_command'] out, err = self.run_manage(args, 'test_project.settings') self.assertNoOutput(err) self.assertOutput(out, "EXECUTE: noargs_command")
def setUp(self): self.write_settings('settings.py', apps=['django.contrib.auth', 'django.contrib.contenttypes']) def tearDown(self): self.remove_settings('settings.py') def test_builtin_command(self): "minimal: manage.py builtin commands fail with an error when no settings provided" args = ['check', 'admin_scripts'] out, err = self.run_manage(args) self.assertNoOutput(out) self.assertOutput(err, "No installed app with label 'admin_scripts'.") def test_builtin_with_settings(self): "minimal: manage.py builtin commands fail if settings are provided as argument" args = ['check', '--settings=test_project.settings', 'admin_scripts'] out, err = self.run_manage(args) self.assertNoOutput(out) self.assertOutput(err, "No installed app with label 'admin_scripts'.") def test_builtin_with_environment(self): "minimal: manage.py builtin commands fail if settings are provided in the environment" args = ['check', 'admin_scripts'] out, err = self.run_manage(args, 'test_project.settings') self.assertNoOutput(out) self.assertOutput(err, "No installed app with label 'admin_scripts'.") def test_builtin_with_bad_settings(self): "minimal: manage.py builtin commands fail if settings file (from argument) doesn't exist" args = ['check', '--settings=bad_settings', 'admin_scripts'] out, err = self.run_manage(args) self.assertNoOutput(out) self.assertOutput(err, "No module named '?bad_settings'?", regex=True) def test_builtin_with_bad_environment(self): "minimal: manage.py builtin commands fail if settings file (from environment) doesn't exist" args = ['check', 'admin_scripts'] out, err = self.run_manage(args, 'bad_settings') self.assertNoOutput(out) self.assertOutput(err, "No module named '?bad_settings'?", regex=True) def test_custom_command(self): "minimal: manage.py can't execute user commands without appropriate settings" args = ['noargs_command'] out, err = self.run_manage(args) self.assertNoOutput(out) self.assertOutput(err, "Unknown command: 'noargs_command'") def test_custom_command_with_settings(self): "minimal: manage.py can't execute user commands, even if settings are provided as argument" args = ['noargs_command', '--settings=test_project.settings'] out, err = self.run_manage(args) self.assertNoOutput(out) self.assertOutput(err, "Unknown command: 'noargs_command'") def test_custom_command_with_environment(self): "minimal: manage.py can't execute user commands, even if settings are provided in environment" args = ['noargs_command'] out, err = self.run_manage(args, 'test_project.settings') self.assertNoOutput(out) self.assertOutput(err, "Unknown command: 'noargs_command'")
def setUp(self): self.write_settings('alternate_settings.py') def tearDown(self): self.remove_settings('alternate_settings.py') def test_builtin_command(self): "alternate: manage.py builtin commands fail with an error when no default settings provided" args = ['check', 'admin_scripts'] out, err = self.run_manage(args) self.assertNoOutput(out) self.assertOutput(err, "No module named '?(test_project\.)?settings'?", regex=True) def test_builtin_with_settings(self): "alternate: manage.py builtin commands work with settings provided as argument" args = ['check', '--settings=alternate_settings', 'admin_scripts'] out, err = self.run_manage(args) self.assertOutput(out, SYSTEM_CHECK_MSG) self.assertNoOutput(err) def test_builtin_with_environment(self): "alternate: manage.py builtin commands work if settings are provided in the environment" args = ['check', 'admin_scripts'] out, err = self.run_manage(args, 'alternate_settings') self.assertOutput(out, SYSTEM_CHECK_MSG) self.assertNoOutput(err) def test_builtin_with_bad_settings(self): "alternate: manage.py builtin commands fail if settings file (from argument) doesn't exist" args = ['check', '--settings=bad_settings', 'admin_scripts'] out, err = self.run_manage(args) self.assertNoOutput(out) self.assertOutput(err, "No module named '?bad_settings'?", regex=True) def test_builtin_with_bad_environment(self): "alternate: manage.py builtin commands fail if settings file (from environment) doesn't exist" args = ['check', 'admin_scripts'] out, err = self.run_manage(args, 'bad_settings') self.assertNoOutput(out) self.assertOutput(err, "No module named '?bad_settings'?", regex=True) def test_custom_command(self): "alternate: manage.py can't execute user commands without settings" args = ['noargs_command'] out, err = self.run_manage(args) self.assertNoOutput(out) self.assertOutput(err, "No module named '?(test_project\.)?settings'?", regex=True) def test_custom_command_with_settings(self): "alternate: manage.py can execute user commands if settings are provided as argument" args = ['noargs_command', '--settings=alternate_settings'] out, err = self.run_manage(args) self.assertOutput( out, "EXECUTE: noargs_command options=[('no_color', False), " "('pythonpath', None), ('settings', 'alternate_settings'), " "('traceback', False), ('verbosity', 1)]" ) self.assertNoOutput(err) def test_custom_command_with_environment(self): "alternate: manage.py can execute user commands if settings are provided in environment" args = ['noargs_command'] out, err = self.run_manage(args, 'alternate_settings') self.assertOutput( out, "EXECUTE: noargs_command options=[('no_color', False), " "('pythonpath', None), ('settings', None), ('traceback', False), " "('verbosity', 1)]" ) self.assertNoOutput(err) def test_custom_command_output_color(self): "alternate: manage.py output syntax color can be deactivated with the `--no-color` option" args = ['noargs_command', '--no-color', '--settings=alternate_settings'] out, err = self.run_manage(args) self.assertOutput( out, "EXECUTE: noargs_command options=[('no_color', True), " "('pythonpath', None), ('settings', 'alternate_settings'), " "('traceback', False), ('verbosity', 1)]" ) self.assertNoOutput(err)
def setUp(self): self.write_settings('settings.py', apps=['django.contrib.auth', 'django.contrib.contenttypes']) self.write_settings('alternate_settings.py') def tearDown(self): self.remove_settings('settings.py') self.remove_settings('alternate_settings.py') def test_builtin_command(self): "multiple: manage.py builtin commands fail with an error when no settings provided" args = ['check', 'admin_scripts'] out, err = self.run_manage(args) self.assertNoOutput(out) self.assertOutput(err, "No installed app with label 'admin_scripts'.") def test_builtin_with_settings(self): "multiple: manage.py builtin commands succeed if settings are provided as argument" args = ['check', '--settings=alternate_settings', 'admin_scripts'] out, err = self.run_manage(args) self.assertNoOutput(err) self.assertOutput(out, SYSTEM_CHECK_MSG) def test_builtin_with_environment(self): "multiple: manage.py can execute builtin commands if settings are provided in the environment" args = ['check', 'admin_scripts'] out, err = self.run_manage(args, 'alternate_settings') self.assertNoOutput(err) self.assertOutput(out, SYSTEM_CHECK_MSG) def test_builtin_with_bad_settings(self): "multiple: manage.py builtin commands fail if settings file (from argument) doesn't exist" args = ['check', '--settings=bad_settings', 'admin_scripts'] out, err = self.run_manage(args) self.assertNoOutput(out) self.assertOutput(err, "No module named '?bad_settings'?", regex=True) def test_builtin_with_bad_environment(self): "multiple: manage.py builtin commands fail if settings file (from environment) doesn't exist" args = ['check', 'admin_scripts'] out, err = self.run_manage(args, 'bad_settings') self.assertNoOutput(out) self.assertOutput(err, "No module named '?bad_settings'?", regex=True) def test_custom_command(self): "multiple: manage.py can't execute user commands using default settings" args = ['noargs_command'] out, err = self.run_manage(args) self.assertNoOutput(out) self.assertOutput(err, "Unknown command: 'noargs_command'") def test_custom_command_with_settings(self): "multiple: manage.py can execute user commands if settings are provided as argument" args = ['noargs_command', '--settings=alternate_settings'] out, err = self.run_manage(args) self.assertNoOutput(err) self.assertOutput(out, "EXECUTE: noargs_command") def test_custom_command_with_environment(self): "multiple: manage.py can execute user commands if settings are provided in environment" args = ['noargs_command'] out, err = self.run_manage(args, 'alternate_settings') self.assertNoOutput(err) self.assertOutput(out, "EXECUTE: noargs_command")
self.write_settings_with_import_error('settings.py') args = ['check', 'admin_scripts'] out, err = self.run_manage(args) self.assertNoOutput(out) self.assertOutput(err, "No module named") self.assertOutput(err, "foo42bar")
self.write_settings('settings.py', sdict={'BAD_VAR': 'INSTALLED_APPS.crash'}) args = ['collectstatic', 'admin_scripts'] out, err = self.run_manage(args) self.assertNoOutput(out) self.assertOutput(err, "AttributeError: 'list' object has no attribute 'crash'")
self.write_settings('settings.py', sdict={'MEDIA_URL': '"/no_ending_slash"'}) args = ['help'] out, err = self.run_manage(args) self.assertOutput(out, 'only Django core commands are listed') self.assertNoOutput(err)
self.write_settings( 'settings.py', apps=[ 'admin_scripts.app_raising_messages', 'django.contrib.auth', 'django.contrib.contenttypes', ], sdict={'DEBUG': True}, ) args = ['check'] out, err = self.run_manage(args) expected_err = ( "SystemCheckError: System check identified some issues:\n" "\n" "ERRORS:\n" "?: An error\n" "\tHINT: Error hint\n" "\n" "WARNINGS:\n" "a: Second warning\n" "obj: First warning\n" "\tHINT: Hint\n" "\n" "System check identified 3 issues (0 silenced).\n" ) self.assertEqual(err, expected_err) self.assertNoOutput(out)
tested_connections = ConnectionHandler({}) with mock.patch('django.core.management.base.connections', new=tested_connections): self.cmd.check_migrations()
def raise_command_error(*args, **kwargs): raise CommandError("Erreur personnalise") command = BaseCommand(stderr=StringIO()) command.execute = raise_command_error with self.assertRaises(SystemExit): command.run_from_argv(['', ''])
with self.settings(INSTALLED_APPS=['admin_scripts.complex_app', 'admin_scripts.simple_app', 'django.contrib.auth', 'django.contrib.contenttypes']): out = StringIO() call_command('duplicate', stdout=out) self.assertEqual(out.getvalue().strip(), 'complex_app') with self.settings(INSTALLED_APPS=['admin_scripts.simple_app', 'admin_scripts.complex_app', 'django.contrib.auth', 'django.contrib.contenttypes']): out = StringIO() call_command('duplicate', stdout=out) self.assertEqual(out.getvalue().strip(), 'simple_app')
args = ['base_command', 'testlabel', '--settings=alternate_settings', '--option_a=x'] self._test(args)
args = ['base_command', 'testlabel', '--settings=alternate_settings', '-a', 'x'] self._test(args)
args = ['base_command', 'testlabel', '--option_a=x', '--settings=alternate_settings'] self._test(args)
args = ['base_command', 'testlabel', '-a', 'x', '--settings=alternate_settings'] self._test(args)
template_url = '%s/custom_templates/project_template.tgz' % self.live_server_url args = ['startproject', '--template', template_url, 'urltestproject'] testproject_dir = os.path.join(self.test_dir, 'urltestproject') self.addCleanup(shutil.rmtree, testproject_dir, True) out, err = self.run_django_admin(args) self.assertNoOutput(err) self.assertTrue(os.path.isdir(testproject_dir)) self.assertTrue(os.path.exists(os.path.join(testproject_dir, 'run.py')))
template_path = os.path.join(custom_templates_dir, 'project_template') args = ['startproject', '--template', template_path, 'yet_another_project', 'project_dir2'] testproject_dir = os.path.join(self.test_dir, 'project_dir2') out, err = self.run_django_admin(args) self.assertNoOutput(out) self.assertOutput(err, "Destination directory '%s' does not exist, please create it first." % testproject_dir) self.assertFalse(os.path.exists(testproject_dir))
template_path = os.path.join(custom_templates_dir, 'project_template') args = ['startproject', '--template', template_path, '--extension=txt', 'customtestproject'] testproject_dir = os.path.join(self.test_dir, 'customtestproject') self.addCleanup(shutil.rmtree, testproject_dir, True) out, err = self.run_django_admin(args) self.assertNoOutput(err) self.assertTrue(os.path.isdir(testproject_dir)) path = os.path.join(testproject_dir, 'ticket-18091-non-ascii-template.txt') with codecs.open(path, 'r', encoding='utf-8') as f: self.assertEqual(f.read().splitlines(False), [ 'Some non-ASCII text for testing ticket #18091:', ' '])
self.write_settings('settings_to_diff.py', sdict={'FOO': '"bar"'}) self.addCleanup(self.remove_settings, 'settings_to_diff.py') args = ['diffsettings', '--settings=settings_to_diff'] out, err = self.run_manage(args) self.assertNoOutput(err) self.assertOutput(out, "FOO = 'bar' ###")
args = ['dumpdata', '--pks=1'] out, err = self.run_manage(args) self.assertOutput(err, "You can only use --pks option with one model") self.assertNoOutput(out)
def test_runs_django_admin(self): cmd_out, _ = self.run_django_admin(['--version']) mod_out, _ = self.run_test('-m', ['django', '--version']) self.assertEqual(mod_out, cmd_out)
from django.db import models from django.utils.encoding import python_2_unicode_compatible @python_2_unicode_compatible class Item(models.Model): name = models.CharField(max_length=15) text = models.TextField(default="xyzzy") value = models.IntegerField() other_value = models.IntegerField(default=0) def __str__(self): return self.name class RelatedItem(models.Model): item = models.ForeignKey(Item, models.CASCADE) class ProxyRelated(RelatedItem): class Meta: proxy = True class Child(models.Model): name = models.CharField(max_length=10) value = models.IntegerField() @python_2_unicode_compatible class Leaf(models.Model): name = models.CharField(max_length=10) child = models.ForeignKey(Child, models.CASCADE) second_child = models.ForeignKey(Child, models.SET_NULL, related_name="other", null=True) value = models.IntegerField(default=42) def __str__(self): return self.name class ResolveThis(models.Model): num = models.FloatField() name = models.CharField(max_length=16) class Proxy(Item): class Meta: proxy = True @python_2_unicode_compatible class SimpleItem(models.Model): name = models.CharField(max_length=15) value = models.IntegerField() def __str__(self): return self.name class Feature(models.Model): item = models.ForeignKey(SimpleItem, models.CASCADE) class SpecialFeature(models.Model): feature = models.ForeignKey(Feature, models.CASCADE) class OneToOneItem(models.Model): item = models.OneToOneField(Item, models.CASCADE, related_name="one_to_one_item") name = models.CharField(max_length=15) class ItemAndSimpleItem(models.Model): item = models.ForeignKey(Item, models.CASCADE) simple = models.ForeignKey(SimpleItem, models.CASCADE) class Profile(models.Model): profile1 = models.CharField(max_length=1000, default='profile1') class Location(models.Model): location1 = models.CharField(max_length=1000, default='location1') class Request(models.Model): profile = models.ForeignKey(Profile, models.SET_NULL, null=True, blank=True) location = models.ForeignKey(Location, models.CASCADE) items = models.ManyToManyField(Item) request1 = models.CharField(default='request1', max_length=1000) request2 = models.CharField(default='request2', max_length=1000) request3 = models.CharField(default='request3', max_length=1000) request4 = models.CharField(default='request4', max_length=1000) class Base(models.Model): text = models.TextField() class Derived(Base): other_text = models.TextField()
from __future__ import unicode_literals from django.db import models from django.utils.encoding import python_2_unicode_compatible @python_2_unicode_compatible class Reporter(models.Model): first_name = models.CharField(max_length=30) last_name = models.CharField(max_length=30) def __str__(self): return "%s %s" % (self.first_name, self.last_name) @python_2_unicode_compatible class Article(models.Model): headline = models.CharField(max_length=100) pub_date = models.DateField() def __str__(self): return self.headline @python_2_unicode_compatible class Writer(models.Model): reporter = models.ForeignKey(Reporter, models.CASCADE) article = models.ForeignKey(Article, models.CASCADE) position = models.CharField(max_length=100) def __str__(self): return '%s (%s)' % (self.reporter, self.position)
data = models.CharField(max_length=20, unique=True) objects = NKManager() class Meta: abstract = True def __str__(self): return self.data def natural_key(self): return (self.data,)
with self.assertRaises(DeserializationError): management.call_command( 'loaddata', 'sequence_extra', verbosity=0, )
management.call_command( 'loaddata', 'sequence_extra', ignore=True, verbosity=0, ) self.assertEqual(Animal.specimens.all()[0].name, 'Lion')
management.call_command( 'loaddata', 'sequence_extra_xml', ignore=True, verbosity=0, ) self.assertEqual(Animal.specimens.all()[0].name, 'Wolf')
load_absolute_path = os.path.join( os.path.dirname(upath(__file__)), 'fixtures', 'absolute.json' ) management.call_command( 'loaddata', load_absolute_path, verbosity=0, ) self.assertEqual(Absolute.objects.count(), 1)
msg = "Problem installing fixture 'bad_fixture1': unkn is not a known serialization format." with self.assertRaisesMessage(management.CommandError, msg): management.call_command( 'loaddata', 'bad_fixture1.unkn', verbosity=0, )
with six.assertRaisesRegex(self, ImportError, r"No module named.*unexistent"): management.call_command( 'loaddata', 'bad_fixture1.unkn', verbosity=0, )
with warnings.catch_warnings(record=True) as warning_list: warnings.simplefilter("always") management.call_command( 'loaddata', 'bad_fixture2.xml', verbosity=0, ) warning = warning_list.pop() self.assertEqual(warning.category, RuntimeWarning) self.assertEqual( str(warning.message), "No fixture data found for 'bad_fixture2'. (File format may be invalid.)" )
with warnings.catch_warnings(record=True) as warning_list: warnings.simplefilter("always") management.call_command( 'loaddata', 'bad_fixture2', verbosity=0, ) warning = warning_list.pop() self.assertEqual(warning.category, RuntimeWarning) self.assertEqual( str(warning.message), "No fixture data found for 'bad_fixture2'. (File format may be invalid.)" )
with warnings.catch_warnings(record=True) as warning_list: warnings.simplefilter("always") management.call_command( 'loaddata', 'empty', verbosity=0, ) warning = warning_list.pop() self.assertEqual(warning.category, RuntimeWarning) self.assertEqual(str(warning.message), "No fixture data found for 'empty'. (File format may be invalid.)")
with warnings.catch_warnings(record=True) as warning_list: warnings.simplefilter("always") management.call_command( 'loaddata', 'bad_fixture2', 'animal', verbosity=0, ) warning = warning_list.pop() self.assertEqual(warning.category, RuntimeWarning) self.assertEqual( str(warning.message), "No fixture data found for 'bad_fixture2'. (File format may be invalid.)" )
management.call_command( 'loaddata', 'model-inheritance.json', verbosity=0, ) self.assertEqual(Parent.objects.all()[0].id, 1) self.assertEqual(Child.objects.all()[0].id, 1)
self.pre_save_checks = [] signals.pre_save.connect(self.animal_pre_save_check) try: management.call_command( 'loaddata', 'animal.xml', verbosity=0, ) self.assertEqual( self.pre_save_checks, [ ("Count = 42 (<%s 'int'>)" % ('class' if PY3 else 'type'), "Weight = 1.2 (<%s 'float'>)" % ('class' if PY3 else 'type')) ] ) finally: signals.pre_save.disconnect(self.animal_pre_save_check)
% widget.pk
management.call_command( 'loaddata', 'forward_ref.json', verbosity=0, ) self.assertEqual(Book.objects.all()[0].id, 1) self.assertEqual(Person.objects.all()[0].id, 4)
with self.assertRaisesMessage(IntegrityError, "Problem installing fixture"): management.call_command( 'loaddata', 'forward_ref_bad_data.json', verbosity=0, )
management.call_command( 'loaddata', 'forward_ref_1.json', 'forward_ref_2.json', verbosity=0, ) self.assertEqual(Book.objects.all()[0].id, 1) self.assertEqual(Person.objects.all()[0].id, 4)
msg = "No database fixture specified. Please provide the path of at least one fixture in the command line." with self.assertRaisesMessage(management.CommandError, msg): management.call_command( 'loaddata', verbosity=0, )
management.call_command( 'loaddata', 'special-article.json', verbosity=0, )
management.call_command( 'loaddata', 'feature.json', verbosity=0, )
management.call_command( 'loaddata', 'm2mtoself.json', verbosity=0, )
with self.assertRaisesMessage(ImproperlyConfigured, "settings.FIXTURE_DIRS contains duplicates."): management.call_command('loaddata', 'absolute.json', verbosity=0)
msg = ( "'%s' is a default fixture directory for the '%s' app " "and cannot be listed in settings.FIXTURE_DIRS." % (os.path.join(_cur_dir, 'fixtures'), 'fixtures_regress') ) with self.assertRaisesMessage(ImproperlyConfigured, msg): management.call_command('loaddata', 'absolute.json', verbosity=0)
management.call_command( 'loaddata', 'model-inheritance.json', verbosity=0, ) management.call_command( 'loaddata', 'nk-inheritance.json', verbosity=0, ) self.assertEqual( NKChild.objects.get(pk=1).data, 'apple' ) self.assertEqual( RefToNKChild.objects.get(pk=1).nk_fk.data, 'apple' )
management.call_command( 'loaddata', 'model-inheritance.json', verbosity=0, ) management.call_command( 'loaddata', 'nk-inheritance.json', verbosity=0, ) management.call_command( 'loaddata', 'nk-inheritance2.xml', verbosity=0, ) self.assertEqual( NKChild.objects.get(pk=2).data, 'banana' ) self.assertEqual( RefToNKChild.objects.get(pk=2).nk_fk.data, 'apple' )
sorted_deps = serializers.sort_dependencies( [('fixtures_regress', [Book, Person, Store])] ) self.assertEqual( sorted_deps, [Store, Person, Book] )
management.call_command( 'loaddata', 'non_natural_1.json', verbosity=0, ) management.call_command( 'loaddata', 'forward_ref_lookup.json', verbosity=0, ) management.call_command( 'loaddata', 'non_natural_2.xml', verbosity=0, ) books = Book.objects.all() self.assertQuerysetEqual( books, [ "<Book: Cryptonomicon by Neal Stephenson (available at Amazon, Borders)>", "<Book: Ender's Game by Orson Scott Card (available at Collins Bookstore)>", "<Book: Permutation City by Greg Egan (available at Angus and Robertson)>", ] )
sorted_deps = serializers.sort_dependencies( [('fixtures_regress', [M2MSimpleA, M2MSimpleB])] ) self.assertEqual(sorted_deps, [M2MSimpleB, M2MSimpleA])
with self.assertRaisesMessage( RuntimeError, "Can't resolve dependencies for fixtures_regress.M2MSimpleCircularA, " "fixtures_regress.M2MSimpleCircularB in serialized app list." ): serializers.sort_dependencies([('fixtures_regress', [M2MSimpleCircularA, M2MSimpleCircularB])])
try: sorted_deps = serializers.sort_dependencies([ ('fixtures_regress', [ M2MComplexCircular2A, M2MComplexCircular2B, M2MCircular2ThroughAB]) ]) except CommandError: self.fail("Serialization dependency solving algorithm isn't " "capable of handling circular M2M setups with " "intermediate models plus natural key dependency hints.") self.assertEqual(sorted_deps[:2], [M2MComplexCircular2A, M2MComplexCircular2B]) self.assertEqual(sorted_deps[2:], [M2MCircular2ThroughAB])
a = M2MSimpleA.objects.create(data="a") b1 = M2MSimpleB.objects.create(data="b1") b2 = M2MSimpleB.objects.create(data="b2") a.b_set.add(b1) a.b_set.add(b2) out = StringIO() management.call_command( 'dumpdata', 'fixtures_regress.M2MSimpleA', 'fixtures_regress.M2MSimpleB', use_natural_foreign_keys=True, stdout=out, ) for model in [M2MSimpleA, M2MSimpleB]: model.objects.all().delete() objects = serializers.deserialize("json", out.getvalue()) for obj in objects: obj.save() new_a = M2MSimpleA.objects.get_by_natural_key("a") self.assertQuerysetEqual(new_a.b_set.all(), [ "<M2MSimpleB: b1>", "<M2MSimpleB: b2>" ], ordered=False)
with transaction.atomic(): management.call_command( 'loaddata', 'thingy.json', verbosity=0, ) self.assertEqual(Thingy.objects.count(), 1) transaction.set_rollback(True) self.assertEqual(Thingy.objects.count(), 0)
with self.assertRaisesMessage( InvalidTemplateLibrary, "ImportError raised when trying to load " "'template_backends.apps.importerror.templatetags.broken_tags'" ): DjangoTemplates({ 'DIRS': [], 'APP_DIRS': False, 'NAME': 'django', 'OPTIONS': {}, })
with self.assertRaises(ImportError): engines.all() with self.assertRaises(ImportError): engines.all()
with self.assertRaises(ImproperlyConfigured): engines.all() with self.assertRaises(ImproperlyConfigured): engines.all()
count = len(obj.get_deferred_fields()) self.assertEqual(count, num)
related = Secondary.objects.create(first='x1', second='x2') ChildProxy.objects.create(name='p1', value='xx', related=related) children = ChildProxy.objects.all().select_related().only('id', 'name') self.assertEqual(len(children), 1) child = children[0] self.assert_delayed(child, 2) self.assertEqual(child.name, 'p1') self.assertEqual(child.value, 'xx')
s1 = Secondary.objects.create(first="x1", second="y1") bc = BigChild.objects.create(name="b1", value="foo", related=s1, other="bar") bc_deferred = BigChild.objects.only('name').get(pk=bc.pk) with self.assertNumQueries(0): bc_deferred.id self.assertEqual(bc_deferred.pk, bc_deferred.id)
Thing.objects.create(num=num) transaction.on_commit(lambda: self.notify(num))
try: with transaction.atomic(): with transaction.atomic(): self.do(1) raise ForcedError() except ForcedError: pass self.assertDone([])
count, num_pages, page_range = output paginator = Paginator(*params) self.check_attribute('count', paginator, count, params) self.check_attribute('num_pages', paginator, num_pages, params) self.check_attribute('page_range', paginator, page_range, params, coerce=list)
got = getattr(paginator, name) if coerce is not None: got = coerce(got) self.assertEqual( expected, got, "For '%s', expected %s but got %s. Paginator parameters were: %s" % (name, expected, got, params) )
paginator = Paginator(*params) if page_num == 'first': page_num = 1 elif page_num == 'last': page_num = paginator.num_pages page = paginator.page(page_num) start, end = indexes msg = ("For %s of page %s, expected %s but got %s. Paginator parameters were: %s") self.assertEqual(start, page.start_index(), msg % ('start index', page_num, start, page.start_index(), params)) self.assertEqual(end, page.end_index(), msg % ('end index', page_num, end, page.end_index(), params))
eleven = 'abcdefghijk' page2 = Paginator(eleven, per_page=5, orphans=1).page(2) self.assertEqual(len(page2), 6) self.assertIn('k', page2) self.assertNotIn('a', page2) self.assertEqual(''.join(page2), 'fghijk') self.assertEqual(''.join(reversed(page2)), 'kjihgf')
eleven = 'abcdefghijk' paginator = ValidAdjacentNumsPaginator(eleven, per_page=6) page1 = paginator.page(1) page2 = paginator.page(2) self.assertIsNone(page1.previous_page_number()) self.assertEqual(page1.next_page_number(), 2) self.assertEqual(page2.previous_page_number(), 1) self.assertIsNone(page2.next_page_number())
self.assertIsInstance(Paginator([1, 2, 3], 2).page_range, type(six.moves.range(0)))
names = stringtree.split() models = [Domain, Kingdom, Phylum, Klass, Order, Family, Genus, Species] assert len(names) == len(models), (names, models) parent = None for name, model in zip(names, models): try: obj = model.objects.get(name=name) except model.DoesNotExist: obj = model(name=name) if parent: setattr(obj, parent.__class__.__name__.lower(), parent) obj.save() parent = obj
with self.assertNumQueries(8): fly = Species.objects.get(name="melanogaster") domain = fly.genus.family.order.klass.phylum.kingdom.domain self.assertEqual(domain.name, 'Eukaryota')
with self.assertNumQueries(1): person = ( Species.objects .select_related('genus__family__order__klass__phylum__kingdom__domain') .get(name="sapiens") ) domain = person.genus.family.order.klass.phylum.kingdom.domain self.assertEqual(domain.name, 'Eukaryota')
with self.assertNumQueries(9): world = Species.objects.all() families = [o.genus.family.name for o in world] self.assertEqual(sorted(families), [ 'Amanitacae', 'Drosophilidae', 'Fabaceae', 'Hominidae', ])
with self.assertNumQueries(1): world = Species.objects.all().select_related() families = [o.genus.family.name for o in world] self.assertEqual(sorted(families), [ 'Amanitacae', 'Drosophilidae', 'Fabaceae', 'Hominidae', ])
with self.assertNumQueries(5): world = Species.objects.all().select_related('genus__family') orders = [o.genus.family.order.name for o in world] self.assertEqual(sorted(orders), ['Agaricales', 'Diptera', 'Fabales', 'Primates'])
with self.assertNumQueries(1): world = Species.objects.select_related('genus__family') families = [o.genus.family.name for o in world] self.assertEqual(sorted(families), ['Amanitacae', 'Drosophilidae', 'Fabaceae', 'Hominidae'])
with self.assertNumQueries(2): world = Species.objects.filter(genus__name='Amanita')\ .select_related('genus__family') orders = [o.genus.family.order.name for o in world] self.assertEqual(orders, ['Agaricales'])
message = "Cannot call select_related() after .values() or .values_list()" with self.assertRaisesMessage(TypeError, message): list(Species.objects.values('name').select_related('genus'))
message = "Cannot call select_related() after .values() or .values_list()" with self.assertRaisesMessage(TypeError, message): list(Species.objects.values_list('name').select_related('genus'))
non_relational_error = "Non-relational field given in select_related: '%s'. Choices are: %s" invalid_error = "Invalid field name(s) given in select_related: '%s'. Choices are: %s" def test_non_relational_field(self): with self.assertRaisesMessage(FieldError, self.non_relational_error % ('name', 'genus')): list(Species.objects.select_related('name__some_field')) with self.assertRaisesMessage(FieldError, self.non_relational_error % ('name', 'genus')): list(Species.objects.select_related('name')) with self.assertRaisesMessage(FieldError, self.non_relational_error % ('name', '(none)')): list(Domain.objects.select_related('name')) def test_non_relational_field_nested(self): with self.assertRaisesMessage(FieldError, self.non_relational_error % ('name', 'family')): list(Species.objects.select_related('genus__name')) def test_many_to_many_field(self): with self.assertRaisesMessage(FieldError, self.invalid_error % ('toppings', '(none)')): list(Pizza.objects.select_related('toppings')) def test_reverse_relational_field(self): with self.assertRaisesMessage(FieldError, self.invalid_error % ('child_1', 'genus')): list(Species.objects.select_related('child_1')) def test_invalid_field(self): with self.assertRaisesMessage(FieldError, self.invalid_error % ('invalid_field', 'genus')): list(Species.objects.select_related('invalid_field')) with self.assertRaisesMessage(FieldError, self.invalid_error % ('related_invalid_field', 'family')): list(Species.objects.select_related('genus__related_invalid_field')) with self.assertRaisesMessage(FieldError, self.invalid_error % ('invalid_field', '(none)')): list(Domain.objects.select_related('invalid_field')) def test_generic_relations(self): with self.assertRaisesMessage(FieldError, self.invalid_error % ('tags', '')): list(Bookmark.objects.select_related('tags')) with self.assertRaisesMessage(FieldError, self.invalid_error % ('content_object', 'content_type')): list(TaggedItem.objects.select_related('content_object'))
from django.db import models from django.utils import six from django.utils.encoding import python_2_unicode_compatible @python_2_unicode_compatible class DataPoint(models.Model): name = models.CharField(max_length=20) value = models.CharField(max_length=20) another_value = models.CharField(max_length=20, blank=True) def __str__(self): return six.text_type(self.name) @python_2_unicode_compatible class RelatedPoint(models.Model): name = models.CharField(max_length=20) data = models.ForeignKey(DataPoint, models.CASCADE) def __str__(self): return six.text_type(self.name) class A(models.Model): x = models.IntegerField(default=10) class B(models.Model): a = models.ForeignKey(A, models.CASCADE) y = models.IntegerField(default=10) class C(models.Model): y = models.IntegerField(default=10) class D(C): a = models.ForeignKey(A, models.CASCADE) class Foo(models.Model): target = models.CharField(max_length=10, unique=True) class Bar(models.Model): foo = models.ForeignKey(Foo, models.CASCADE, to_field='target')
num_updated = self.a1.b_set.update(y=100) self.assertEqual(num_updated, 20) cnt = B.objects.filter(y=100).count() self.assertEqual(cnt, 20)
num_updated = self.a2.b_set.update(y=100) self.assertEqual(num_updated, 0) cnt = B.objects.filter(y=100).count() self.assertEqual(cnt, 0)
num_updated = self.a1.d_set.update(y=100) self.assertEqual(num_updated, 20) cnt = D.objects.filter(y=100).count() self.assertEqual(cnt, 20)
num_updated = self.a2.d_set.update(y=100) self.assertEqual(num_updated, 0) cnt = D.objects.filter(y=100).count() self.assertEqual(cnt, 0)
num_updated = self.a1.d_set.update(a_id=self.a2) self.assertEqual(num_updated, 20) self.assertEqual(self.a2.d_set.count(), 20)
resp = DataPoint.objects.filter(value="apple").update(name="d1") self.assertEqual(resp, 1) resp = DataPoint.objects.filter(value="apple") self.assertEqual(list(resp), [self.d0])
resp = DataPoint.objects.filter(value="banana").update( value="pineapple") self.assertEqual(resp, 2) self.assertEqual(DataPoint.objects.get(name="d2").value, 'pineapple')
resp = RelatedPoint.objects.filter(name="r1").update(data=self.d0) self.assertEqual(resp, 1) resp = RelatedPoint.objects.filter(data__name="d0") self.assertEqual(list(resp), [self.r1])
resp = DataPoint.objects.filter(value="apple").update( value="fruit", another_value="peach") self.assertEqual(resp, 1) d = DataPoint.objects.get(name="d0") self.assertEqual(d.value, 'fruit') self.assertEqual(d.another_value, 'peach')
self.assertEqual(DataPoint.objects.update(value='thing'), 3) resp = DataPoint.objects.values('value').distinct() self.assertEqual(list(resp), [{'value': 'thing'}])
method = DataPoint.objects.all()[:2].update with self.assertRaises(AssertionError): method(another_value='another thing')
egg_name = '%s/modelapp.egg' % self.egg_dir with extend_sys_path(egg_name): with self.settings(INSTALLED_APPS=['app_with_models']): models_module = apps.get_app_config('app_with_models').models_module self.assertIsNotNone(models_module) del apps.all_models['app_with_models']
egg_name = '%s/nomodelapp.egg' % self.egg_dir with extend_sys_path(egg_name): with self.settings(INSTALLED_APPS=['app_no_models']): models_module = apps.get_app_config('app_no_models').models_module self.assertIsNone(models_module) del apps.all_models['app_no_models']
egg_name = '%s/omelet.egg' % self.egg_dir with extend_sys_path(egg_name): with self.settings(INSTALLED_APPS=['omelet.app_with_models']): models_module = apps.get_app_config('app_with_models').models_module self.assertIsNotNone(models_module) del apps.all_models['app_with_models']
egg_name = '%s/omelet.egg' % self.egg_dir with extend_sys_path(egg_name): with self.settings(INSTALLED_APPS=['omelet.app_no_models']): models_module = apps.get_app_config('app_no_models').models_module self.assertIsNone(models_module) del apps.all_models['app_no_models']
egg_name = '%s/brokenapp.egg' % self.egg_dir with extend_sys_path(egg_name): with self.assertRaisesMessage(ImportError, 'modelz'): with self.settings(INSTALLED_APPS=['broken_app']): pass
class BookmarkChoicesAdmin(ModelAdmin): list_display = ['none_or_null'] list_filter = ['none_or_null'] modeladmin = BookmarkChoicesAdmin(Bookmark, site) request = self.request_factory.get('/', {}) changelist = self.get_changelist(request, Bookmark, modeladmin) filterspec = changelist.get_filters(request)[0][0] choices = list(filterspec.choices(changelist)) self.assertEqual(choices[-1]['display'], 'None') self.assertEqual(choices[-1]['query_string'], '?none_or_null__isnull=True')
modeladmin = DecadeFilterBookAdminWithoutTitle(Book, site) request = self.request_factory.get('/', {}) msg = "The list filter 'DecadeListFilterWithoutTitle' does not specify a 'title'." with self.assertRaisesMessage(ImproperlyConfigured, msg): self.get_changelist(request, Book, modeladmin)
modeladmin = DecadeFilterBookAdminWithoutParameter(Book, site) request = self.request_factory.get('/', {}) msg = "The list filter 'DecadeListFilterWithoutParameter' does not specify a 'parameter_name'." with self.assertRaisesMessage(ImproperlyConfigured, msg): self.get_changelist(request, Book, modeladmin)
modeladmin = DecadeFilterBookAdminWithNoneReturningLookups(Book, site) request = self.request_factory.get('/', {}) changelist = self.get_changelist(request, Book, modeladmin) filterspec = changelist.get_filters(request)[0] self.assertEqual(len(filterspec), 0)
modeladmin = DecadeFilterBookAdminWithFailingQueryset(Book, site) request = self.request_factory.get('/', {}) with self.assertRaises(ZeroDivisionError): self.get_changelist(request, Book, modeladmin)
modeladmin = DepartmentFilterEmployeeAdmin(Employee, site) request = self.request_factory.get('/', {'department': self.john.department.pk}) changelist = self.get_changelist(request, Employee, modeladmin) queryset = changelist.get_queryset(request) self.assertEqual(list(queryset), [self.john]) filterspec = changelist.get_filters(request)[0][-1] self.assertEqual(force_text(filterspec.title), 'department') choices = list(filterspec.choices(changelist)) self.assertEqual(choices[1]['display'], 'DEV') self.assertEqual(choices[1]['selected'], True) self.assertEqual(choices[1]['query_string'], '?department=%s' % self.john.department.pk)
modeladmin = DepartmentFilterUnderscoredEmployeeAdmin(Employee, site) request = self.request_factory.get('/', {'department__whatever': self.john.department.pk}) changelist = self.get_changelist(request, Employee, modeladmin) queryset = changelist.get_queryset(request) self.assertEqual(list(queryset), [self.john]) filterspec = changelist.get_filters(request)[0][-1] self.assertEqual(force_text(filterspec.title), 'department') choices = list(filterspec.choices(changelist)) self.assertEqual(choices[1]['display'], 'DEV') self.assertEqual(choices[1]['selected'], True) self.assertEqual(choices[1]['query_string'], '?department__whatever=%s' % self.john.department.pk)
modeladmin = DepartmentFilterDynamicValueBookAdmin(Book, site) def _test_choices(request, expected_displays): changelist = self.get_changelist(request, Book, modeladmin) filterspec = changelist.get_filters(request)[0][0] self.assertEqual(force_text(filterspec.title), 'publication decade') choices = tuple(c['display'] for c in filterspec.choices(changelist)) self.assertEqual(choices, expected_displays) _test_choices(self.request_factory.get('/', {}), ("All", "the 1980's", "the 1990's")) _test_choices(self.request_factory.get('/', {'publication-decade': 'the 80s'}), ("All", "the 1990's")) _test_choices(self.request_factory.get('/', {'publication-decade': 'the 90s'}), ("All", "the 1980's"))
modeladmin = NotNinetiesListFilterAdmin(Book, site) request = self.request_factory.get('/', {}) changelist = self.get_changelist(request, Book, modeladmin) changelist.get_results(request) self.assertEqual(changelist.full_result_count, 4)
return [url for url in super(ActionAdmin, self).get_urls() if url.name != name]
add_url = reverse('admin_custom_urls:admin_custom_urls_action_add') self.assertTrue(add_url.endswith('/!add/')) response = self.client.get(add_url) self.assertIsInstance(response, TemplateResponse) self.assertEqual(response.status_code, 200)
response = self.client.get(reverse('admin_custom_urls:admin_custom_urls_action_add'), {'name': 'My Action'}) self.assertContains(response, 'value="My Action"')
post_data = { '_popup': '1', "name": 'Action added through a popup', "description": "Description of added action", } response = self.client.post(reverse('admin_custom_urls:admin_custom_urls_action_add'), post_data) self.assertContains(response, 'Action added through a popup')
post_data = {'name': 'John Doe'} self.assertEqual(Person.objects.count(), 0) response = self.client.post(reverse('admin_custom_urls:admin_custom_urls_person_add'), post_data) persons = Person.objects.all() self.assertEqual(len(persons), 1) redirect_url = reverse('admin_custom_urls:admin_custom_urls_person_history', args=[persons[0].pk]) self.assertRedirects(response, redirect_url)
Person.objects.create(name='John Doe') self.assertEqual(Person.objects.count(), 1) person = Person.objects.all()[0] post_url = reverse('admin_custom_urls:admin_custom_urls_person_change', args=[person.pk]) response = self.client.post(post_url, {'name': 'Jack Doe'}) self.assertRedirects(response, reverse('admin_custom_urls:admin_custom_urls_person_delete', args=[person.pk]))
from django.db import models from django.utils.encoding import python_2_unicode_compatible @python_2_unicode_compatible class Person(models.Model): name = models.CharField(max_length=20) friends = models.ManyToManyField('self') idols = models.ManyToManyField('self', symmetrical=False, related_name='stalkers') def __str__(self): return self.name
from django.db import models class Person(models.Model): first_name = models.CharField(max_length=30) last_name = models.CharField(max_length=30) def _get_full_name(self): return "%s %s" % (self.first_name, self.last_name) def _set_full_name(self, combined_name): self.first_name, self.last_name = combined_name.split(' ', 1) full_name = property(_get_full_name) full_name_2 = property(_get_full_name, _set_full_name)
m1 = M2MModel.objects.create() g1 = Group.objects.create(name='foof') m1.groups.add(g1) m2m_through = M2MModel._meta.get_field('groups').remote_field.through original = m2m_through.objects.get() dumped = pickle.dumps(original) reloaded = pickle.loads(dumped) self.assertEqual(original, reloaded)
g = Group.objects.create(name='foo') m2m = M2MModel.objects.create() m2m.groups.add(g) Group.objects.all().delete() m2ms = M2MModel.objects.prefetch_related('groups') m2ms = pickle.loads(pickle.dumps(m2ms)) self.assertQuerysetEqual(m2ms, [m2m], lambda x: x)
qs = Group.missing_django_version_objects.all() msg = "Pickled queryset instance's Django version is not specified." with self.assertRaisesMessage(RuntimeWarning, msg): pickle.loads(pickle.dumps(qs))
self.assertEqual(ungettext("%d year", "%d years", 0) % 0, "0 anne") self.assertEqual(ungettext("%d year", "%d years", 2) % 2, "2 annes") self.assertEqual(ungettext("%(size)d byte", "%(size)d bytes", 0) % {'size': 0}, "0 octet") self.assertEqual(ungettext("%(size)d byte", "%(size)d bytes", 2) % {'size': 2}, "2 octets")
activate('fr') @translation.override('pl') def func_pl(): pass deactivate() try: activate('en') func_pl() self.assertEqual(get_language(), 'en') finally: deactivate()
self.assertEqual('django', six.text_type(string_concat("dja", "ngo")))
with translation.override('de'): self.assertEqual("", ugettext("")) self.assertEqual(str(""), gettext(str(""))) s = mark_safe("") self.assertEqual(s, ugettext(s))
s = mark_safe(str('Password')) self.assertEqual(SafeString, type(s)) with translation.override('de', deactivate=True): self.assertEqual(SafeText, type(ugettext(s))) self.assertEqual('aPassword', SafeText('a') + s) self.assertEqual('Passworda', s + SafeText('a')) self.assertEqual('Passworda', s + mark_safe('a')) self.assertEqual('aPassword', mark_safe('a') + s) self.assertEqual('as', mark_safe('a') + mark_safe('s'))
ca_translation = trans_real.translation('ca') ca_translation._catalog['Mac\nEOF\n'] = 'Catalan Mac\nEOF\n' ca_translation._catalog['Win\nEOF\n'] = 'Catalan Win\nEOF\n' with translation.override('ca', deactivate=True): self.assertEqual('Catalan Mac\nEOF\n', ugettext('Mac\rEOF\r')) self.assertEqual('Catalan Win\nEOF\n', ugettext('Win\r\nEOF\r\n'))
self.assertEqual(to_locale('en-us'), 'en_US') self.assertEqual(to_locale('sr-lat'), 'sr_Lat')
self.assertEqual(trans_real.to_language('en_US'), 'en-us') self.assertEqual(trans_real.to_language('sr_Lat'), 'sr-lat')
with translation.override('fr'): t = Template('{% load i18n %}{% blocktrans %}My name is {{ person }}.{% endblocktrans %}') rendered = t.render(Context({'person': 'James'})) self.assertEqual(rendered, 'My name is James.')
with translation.override('fr'): t = Template('{% load i18n %}{% blocktrans %}My other name is {{ person }}.{% endblocktrans %}') rendered = t.render(Context({'person': 'James'})) self.assertEqual(rendered, 'My other name is James.')
with self.settings(USE_THOUSAND_SEPARATOR=True): with translation.override('de-at', deactivate=True): self.assertEqual('66.666,666', Template('{{ n }}').render(self.ctxt)) with translation.override('es-us', deactivate=True): self.assertEqual('31 de Diciembre de 2009', date_format(self.d))
en_format_mod = import_module('django.conf.locale.en.formats') en_gb_format_mod = import_module('django.conf.locale.en_GB.formats') self.assertEqual(list(iter_format_modules('en-gb')), [en_gb_format_mod, en_format_mod])
context = Context({'value': 3.14}) template1 = Template( '{% load l10n %}{% localize %}{{ value }}{% endlocalize %};' '{% localize on %}{{ value }}{% endlocalize %}' ) template2 = Template("{% load l10n %}{{ value }};{% localize off %}{{ value }};{% endlocalize %}{{ value }}") template3 = Template('{% load l10n %}{{ value }};{{ value|unlocalize }}') template4 = Template('{% load l10n %}{{ value }};{{ value|localize }}') output1 = '3,14;3,14' output2 = '3,14;3.14;3,14' output3 = '3,14;3.14' output4 = '3.14;3,14' with translation.override('de', deactivate=True): with self.settings(USE_L10N=False): self.assertEqual(template1.render(context), output1) self.assertEqual(template4.render(context), output4) with self.settings(USE_L10N=True): self.assertEqual(template1.render(context), output1) self.assertEqual(template2.render(context), output2) self.assertEqual(template3.render(context), output3)
self.maxDiff = 1200 with translation.override('de-at', deactivate=True): template = Template('{% load l10n %}{{ form.date_added }}; {{ form.cents_paid }}') template_as_text = Template('{% load l10n %}{{ form.date_added.as_text }}; {{ form.cents_paid.as_text }}') template_as_hidden = Template( '{% load l10n %}{{ form.date_added.as_hidden }}; {{ form.cents_paid.as_hidden }}' ) form = CompanyForm({ 'name': 'acme', 'date_added': datetime.datetime(2009, 12, 31, 6, 0, 0), 'cents_paid': decimal.Decimal('59.47'), 'products_delivered': 12000, }) context = Context({'form': form}) self.assertTrue(form.is_valid()) self.assertHTMLEqual( template.render(context), '<input id="id_date_added" name="date_added" type="text" value="31.12.2009 06:00:00" required />;' '<input id="id_cents_paid" name="cents_paid" type="text" value="59,47" required />' ) self.assertHTMLEqual( template_as_text.render(context), '<input id="id_date_added" name="date_added" type="text" value="31.12.2009 06:00:00" required />;' ' <input id="id_cents_paid" name="cents_paid" type="text" value="59,47" required />' ) self.assertHTMLEqual( template_as_hidden.render(context), '<input id="id_date_added" name="date_added" type="hidden" value="31.12.2009 06:00:00" />;' '<input id="id_cents_paid" name="cents_paid" type="hidden" value="59,47" />' )
self.assertEqual(ugettext("Image"), "Bild") with translation.override('en'): self.assertEqual(ugettext("Image"), "Image") with translation.override('en-us'): self.assertEqual(ugettext("Image"), "Image") with translation.override('en-ca'): self.assertEqual(ugettext("Image"), "Image")
g = get_language_from_request r = self.rf.get('/') r.COOKIES = {} r.META = {'HTTP_ACCEPT_LANGUAGE': 'zh-cn,en'} self.assertEqual(g(r), 'zh-hans') r.META = {'HTTP_ACCEPT_LANGUAGE': 'zh-tw,en'} self.assertEqual(g(r), 'zh-hant')
r = self.rf.get('/') r.COOKIES = {} r.META = {'HTTP_ACCEPT_LANGUAGE': 'zh-my,en'} self.assertEqual(get_language_from_request(r), 'zh-hans')
g = get_language_from_request r = self.rf.get('/') r.COOKIES = {} r.META = {'HTTP_ACCEPT_LANGUAGE': 'pt-br'} self.assertEqual('pt-br', g(r)) with self.settings(LANGUAGES=[('en', 'English')]): self.assertNotEqual('pt-br', g(r))
li = get_language_info('zh-my') self.assertEqual(li['code'], 'zh-hans') li = get_language_info('zh-hans') self.assertEqual(li['code'], 'zh-hans')
response = self.client.get('/simple/') self.assertEqual(response.content, b'Yes')
@override_settings( USE_I18N=True, LANGUAGES=[ ('en-us', 'English'), ('xxx', 'Somelanguage'), ], LANGUAGE_CODE='xxx', LOCALE_PATHS=[os.path.join(here, 'commands', 'locale')], ) def test_non_django_language(self): self.assertEqual(get_language(), 'xxx') self.assertEqual(ugettext("year"), "reay")
def test_not_prefixed(self): with translation.override('en'): self.assertEqual(reverse('not-prefixed'), '/not-prefixed/') self.assertEqual(reverse('not-prefixed-included-url'), '/not-prefixed-include/foo/') with translation.override('nl'): self.assertEqual(reverse('not-prefixed'), '/not-prefixed/') self.assertEqual(reverse('not-prefixed-included-url'), '/not-prefixed-include/foo/') def test_prefixed(self): with translation.override('en'): self.assertEqual(reverse('prefixed'), '/en/prefixed/') with translation.override('nl'): self.assertEqual(reverse('prefixed'), '/nl/prefixed/') with translation.override(None): self.assertEqual(reverse('prefixed'), '/%s/prefixed/' % settings.LANGUAGE_CODE) @override_settings(ROOT_URLCONF='i18n.patterns.urls.wrong') def test_invalid_prefix_use(self): with self.assertRaises(ImproperlyConfigured): reverse('account:register')
def test_no_lang_activate(self): response = self.client.get('/nl/foo/') self.assertEqual(response.status_code, 200) self.assertEqual(response['content-language'], 'en') self.assertEqual(response.context['LANGUAGE_CODE'], 'en')
def test_account_register(self): with translation.override('en'): self.assertEqual(reverse('account:register'), '/en/account/register/') with translation.override('nl'): self.assertEqual(reverse('account:register'), '/nl/profiel/registeren/')
def test_no_prefix_response(self): response = self.client.get('/not-prefixed/') self.assertEqual(response.status_code, 200) self.assertEqual(response.get('Vary'), 'Accept-Language') def test_en_redirect(self): response = self.client.get('/account/register/', HTTP_ACCEPT_LANGUAGE='en') self.assertRedirects(response, '/en/account/register/') self.assertFalse(response.get('Vary')) response = self.client.get(response['location']) self.assertEqual(response.status_code, 200) self.assertFalse(response.get('Vary'))
@override_settings(APPEND_SLASH=False) def test_not_prefixed_redirect(self): response = self.client.get('/not-prefixed', HTTP_ACCEPT_LANGUAGE='en') self.assertEqual(response.status_code, 404) @override_settings(APPEND_SLASH=False) def test_en_redirect(self): response = self.client.get('/account/register-without-slash', HTTP_ACCEPT_LANGUAGE='en') self.assertRedirects(response, '/en/account/register-without-slash', 302) response = self.client.get(response['location']) self.assertEqual(response.status_code, 200)
def test_not_prefixed_with_prefix(self): response = self.client.get('/en/not-prefixed/') self.assertEqual(response.status_code, 404) def test_en_url(self): response = self.client.get('/en/account/register/') self.assertEqual(response.status_code, 200) self.assertEqual(response['content-language'], 'en') self.assertEqual(response.context['LANGUAGE_CODE'], 'en') def test_nl_url(self): response = self.client.get('/nl/profiel/registeren/') self.assertEqual(response.status_code, 200) self.assertEqual(response['content-language'], 'nl') self.assertEqual(response.context['LANGUAGE_CODE'], 'nl') def test_wrong_en_prefix(self): response = self.client.get('/en/profiel/registeren/') self.assertEqual(response.status_code, 404) def test_wrong_nl_prefix(self): response = self.client.get('/nl/account/register/') self.assertEqual(response.status_code, 404) def test_pt_br_url(self): response = self.client.get('/pt-br/conta/registre-se/') self.assertEqual(response.status_code, 200) self.assertEqual(response['content-language'], 'pt-br') self.assertEqual(response.context['LANGUAGE_CODE'], 'pt-br')
def test_language_prefix_with_script_prefix(self): prefix = '/script_prefix' with override_script_prefix(prefix): response = self.client.get('/prefixed/', HTTP_ACCEPT_LANGUAGE='en', SCRIPT_NAME=prefix) self.assertRedirects(response, '%s/en/prefixed/' % prefix, target_status_code=404)
PO_FILE = os.path.join(SAMPLEPROJECT_LOCALE, 'fr', 'LC_MESSAGES', 'django.po') def setUp(self): self._language = get_language() self._translations = trans_real._translations activate('fr') def tearDown(self): trans_real._translations = self._translations activate(self._language)
def setUp(self): super(ExtractingStringsWithPercentSigns, self).setUp() with open(self.PO_FILE, 'r') as fp: self.po_contents = force_text(fp.read()) def test_trans_tag_with_percent_symbol_at_the_end(self): self.assertMsgId('Literal with a percent symbol at the end %%', self.po_contents) def test_trans_tag_with_percent_symbol_in_the_middle(self): self.assertMsgId('Literal with a percent %% symbol in the middle', self.po_contents) self.assertMsgId('It is 100%%', self.po_contents) def test_trans_tag_with_string_that_look_like_fmt_spec(self): self.assertMsgId('Looks like a str fmt spec %%s but should not be interpreted as such', self.po_contents) self.assertMsgId('Looks like a str fmt spec %% o but should not be interpreted as such', self.po_contents) def test_adds_python_format_to_all_percent_signs(self): self.assertMsgId('1 percent sign %%, 2 percent signs %%%%, 3 percent signs %%%%%%', self.po_contents) self.assertMsgId('%(name)s says: 1 percent sign %%, 2 percent signs %%%%', self.po_contents)
return self._assertPoLocComment(True, po_filename, line_number, *comment_parts)
return self._assertPoLocComment(False, po_filename, line_number, *comment_parts)
delta = time.time() - os.stat(path).st_mtime self.assertLess(delta, 10, "%s was recently modified" % path)
delta = time.time() - os.stat(path).st_mtime self.assertGreater(delta, 10, "%s wasn't recently modified" % path)
self.assertTrue(MakeMessagesCommand.leave_locale_alone)
os.chdir(self.test_dir) shutil.copyfile('./code.sample', './code_sample.py') self.addCleanup(self.rmfile, os.path.join(self.test_dir, 'code_sample.py')) out = StringIO() management.call_command('makemessages', locale=[LOCALE], stdout=out) self.assertIn("code_sample.py:4", force_text(out.getvalue()))
cmd = MakeMessagesCommand() cmd.ignore_patterns = ['CVS', '.*', '*~', '*.pyc'] cmd.symlinks = False cmd.domain = 'django' cmd.extensions = ['html', 'txt', 'py'] cmd.verbosity = 0 cmd.locale_paths = [] cmd.default_locale_path = os.path.join(self.test_dir, 'locale') found_files = cmd.find_files(self.test_dir) found_exts = set([os.path.splitext(tfile.file)[1] for tfile in found_files]) self.assertEqual(found_exts.difference({'.py', '.html', '.txt'}), set()) cmd.extensions = ['js'] cmd.domain = 'djangojs' found_files = cmd.find_files(self.test_dir) found_exts = set([os.path.splitext(tfile.file)[1] for tfile in found_files]) self.assertEqual(found_exts.difference({'.js'}), set())
BR_PO_BASE = 'locale/pt_BR/LC_MESSAGES/django' os.chdir(self.test_dir) shutil.copyfile(BR_PO_BASE + '.pristine', BR_PO_BASE + '.po') self.addCleanup(self.rmfile, os.path.join(self.test_dir, 'locale', 'pt_BR', 'LC_MESSAGES', 'django.po')) management.call_command('makemessages', locale=['pt_BR'], verbosity=0) self.assertTrue(os.path.exists(BR_PO_BASE + '.po')) with io.open(BR_PO_BASE + '.po', 'r', encoding='utf-8') as fp: po_contents = force_text(fp.read()) self.assertMsgStr("Gre", po_contents)
_, po_contents = self._run_makemessages(domain='djangojs') self.assertMsgId("Static content inside app should be included.", po_contents) self.assertNotMsgId("Content from STATIC_ROOT should not be included", po_contents)
_, po_contents = self._run_makemessages(domain='djangojs') self.assertMsgId("Static content inside app should be included.", po_contents)
os.chdir(self.test_dir) management.call_command('makemessages', locale=['es'], extensions=['djtpl'], verbosity=0) self.assertTrue(os.path.exists(self.PO_FILE_ES)) with io.open(self.PO_FILE_ES, 'r', encoding='utf-8') as fp: po_contents = fp.read() found = re.findall(r'^(?P<value>"Plural-Forms.+?\\n")\s*$', po_contents, re.MULTILINE | re.DOTALL) self.assertEqual(1, len(found))
os.chdir(self.test_dir) management.call_command('makemessages', locale=[LOCALE], verbosity=0, no_location=True) self.assertTrue(os.path.exists(self.PO_FILE)) self.assertLocationCommentNotPresent(self.PO_FILE, None, 'test.html')
os.chdir(self.test_dir) management.call_command('makemessages', locale=[LOCALE], verbosity=0) self.assertTrue(os.path.exists(self.PO_FILE)) with open(self.PO_FILE, 'r') as fp: po_contents = force_text(fp.read()) self.assertMsgId('#: templates/test.html.py', po_contents) self.assertLocationCommentNotPresent(self.PO_FILE, None, '.html.py') self.assertLocationCommentPresent(self.PO_FILE, 5, 'templates', 'test.html')
for locale in self.LOCALES: os.utime(self.PO_FILE % locale, (0, 0))
CHOICES = [ ('', 'No Preference'), ('f', 'Foo'), ('b', 'Bar'), ] INTEGER_CHOICES = [ (None, 'No Preference'), (1, 'Foo'), (2, 'Bar'), ] STRING_CHOICES_WITH_NONE = [ (None, 'No Preference'), ('f', 'Foo'), ('b', 'Bar'), ] name = models.CharField(max_length=10) choice = models.CharField(max_length=2, blank=True, choices=CHOICES) choice_string_w_none = models.CharField( max_length=2, blank=True, null=True, choices=STRING_CHOICES_WITH_NONE) choice_integer = models.IntegerField(choices=INTEGER_CHOICES, blank=True, null=True)
def coerce_func(val): return decimal.Decimal('1.%s' % val) f = TypedMultipleChoiceField( choices=[(1, "1"), (2, "2")], coerce=coerce_func, required=True) self.assertEqual([decimal.Decimal('1.2')], f.clean(['2'])) with self.assertRaisesMessage(ValidationError, "'This field is required.'"): f.clean([]) msg = "'Select a valid choice. 3 is not one of the available choices.'" with self.assertRaisesMessage(ValidationError, msg): f.clean(['3'])
f = URLField() urls = ( 'http://[12:34::3a53]/', 'http://[a34:9238::]:8080/', ) for url in urls: self.assertEqual(url, f.clean(url))
with self.assertRaises(ValueError): CharField(min_length='a') with self.assertRaises(ValueError): CharField(max_length='a') with self.assertRaises(ValueError): CharField('a')
f = CharField() self.assertEqual(f.clean(' 1'), '1') self.assertEqual(f.clean('1 '), '1') f = CharField(strip=False) self.assertEqual(f.clean(' 1'), ' 1') self.assertEqual(f.clean('1 '), '1 ')
f1 = IntegerField(localize=True) self.assertWidgetRendersTo(f1, '<input id="id_f" name="f" type="text" required />')
class MyIntegerField(IntegerField): widget = Textarea f = MyIntegerField() self.assertEqual(f.widget.__class__, Textarea) f = MyIntegerField(localize=True) self.assertEqual(f.widget.__class__, Textarea)
def coerce_func(val): return decimal.Decimal('1.%s' % val) f = TypedChoiceField(choices=[(1, "1"), (2, "2")], coerce=coerce_func, required=True) self.assertEqual(decimal.Decimal('1.2'), f.clean('2')) with self.assertRaisesMessage(ValidationError, "'This field is required.'"): f.clean('') msg = "'Select a valid choice. 3 is not one of the available choices.'" with self.assertRaisesMessage(ValidationError, msg): f.clean('3')
f = DecimalField(localize=True) self.assertWidgetRendersTo(f, '<input id="id_f" name="f" type="text" required />')
f = FloatField(localize=True) self.assertWidgetRendersTo(f, '<input id="id_f" name="f" type="text" required />')
msg = "'This field is required.'" with self.assertRaisesMessage(ValidationError, msg): self.field.clean(['some text', ['JP']])
self.assertTrue(self.field.has_changed( 'some text,JP,2007-04-25 06:24:00', ['other text', ['J', 'P'], ['2007-04-25', '6:24:00']], ))
self.assertTrue(self.field.has_changed( 'some text,JP,2007-04-25 06:24:00', ['some text', ['J', 'P'], ['2009-04-25', '11:44:00']], ))
url = 'something' def __str__(self): return self.url
self.check_html(self.widget, 'myfile', None, html='<input type="file" name="myfile" />')
value = self.widget.value_from_datadict( data={'myfile-clear': True}, files={}, name='myfile', ) self.assertEqual(value, False)
widget = ClearableFileInput() widget.is_required = True field = SimpleUploadedFile('something.txt', b'content') value = widget.value_from_datadict( data={'myfile-clear': True}, files={'myfile': field}, name='myfile', ) self.assertEqual(value, field)
@python_2_unicode_compatible class FailingURLFieldFile(object): @property def url(self): raise ValueError('Canary') def __str__(self): return 'value' with self.assertRaisesMessage(ValueError, 'Canary'): self.widget.render('myfile', FailingURLFieldFile())
self.check_html(self.widget, 'get_spam', False, html=( '<input type="text" name="get_spam" value="False" />' )) self.check_html(self.widget, 'get_spam', True, html=( '<input type="text" name="get_spam" value="True" />' ))
widget = TextInput(attrs={'class': 'pretty'}) self.check_html( widget, 'email', '', attrs={'class': 'special'}, html='<input type="text" class="special" name="email" />', )
self.assertHTMLEqual( self.widget.render('mydate', None), self.widget.render('mydate', ''), )
self.check_html( self.widget, 'is_cool', 'foo', html='<input checked="checked" type="checkbox" name="is_cool" value="foo" />', )
self.check_html( self.widget, 'is_cool', 0, html='<input checked="checked" type="checkbox" name="is_cool" value="0" />', ) self.check_html( self.widget, 'is_cool', 1, html='<input checked="checked" type="checkbox" name="is_cool" value="1" />', )
widget = CheckboxInput(check_test=lambda value: value.startswith('hello')) self.check_html(widget, 'greeting', '', html=( '<input type="checkbox" name="greeting" />' )) self.check_html(widget, 'greeting', 'hello', html=( '<input checked="checked" type="checkbox" name="greeting" value="hello" />' )) self.check_html(widget, 'greeting', 'hello there', html=( '<input checked="checked" type="checkbox" name="greeting" value="hello there" />' )) self.check_html(widget, 'greeting', 'hello & goodbye', html=( '<input checked="checked" type="checkbox" name="greeting" value="hello &amp; goodbye" />' ))
widget = CheckboxInput( check_test=lambda value: value.startswith('hello'), ) with self.assertRaises(AttributeError): widget.render('greeting', True)
self.assertFalse(self.widget.value_from_datadict({}, {}, 'testing'))
self.widgets[0].choices = choices
return self.widgets[0].choices
widget = MyMultiWidget(widgets=(TextInput(), FileInput())) self.assertTrue(widget.needs_multipart_form)
widget = MyMultiWidget(widgets=(TextInput(), TextInput())) self.assertFalse(widget.needs_multipart_form)
self.check_html( self.widget(choices=nested_choices), 'nestchoice', ('vinyl', 'dvd'), attrs={'id': 'media'}, html=html, )
self.check_html(self.widget(choices=choices), 'letters', ['a', 'c'], attrs={'id': 'abc'}, html=html)
self.check_html(self.widget, 'date', '2007-09-17', html=( '<input type="text" name="date" value="2007-09-17" />' ))
d = date(2007, 9, 17) widget = DateInput(format='%d/%m/%Y', attrs={'type': 'date'}) self.check_html(widget, 'date', d, html='<input type="date" name="date" value="17/09/2007" />')
t = time(12, 51, 34, 482548) self.assertEqual(str(t), '12:51:34.482548') self.check_html(self.widget, 'time', t, html='<input type="text" name="time" value="12:51:34" />') self.check_html(self.widget, 'time', time(12, 51, 34), html=( '<input type="text" name="time" value="12:51:34" />' )) self.check_html(self.widget, 'time', time(12, 51), html=( '<input type="text" name="time" value="12:51:00" />' ))
self.check_html(self.widget, 'time', '13:12:11', html=( '<input type="text" name="time" value="13:12:11" />' ))
t = time(12, 51, 34, 482548) widget = TimeInput(format='%H:%M', attrs={'type': 'time'}) self.check_html(widget, 'time', t, html='<input type="time" name="time" value="12:51" />')
self.check_html( self.widget(choices=nested_choices), 'nestchoice', 'dvd', attrs={'id': 'media'}, html=html, )
self.check_html(widget, 'beatle', 'J', html=html)
widget = PasswordInput(render_value=True) self.check_html(widget, 'password', '', html='<input type="password" name="password" />') self.check_html(widget, 'password', None, html='<input type="password" name="password" />') self.check_html( widget, 'password', 'test@example.com', html='<input type="password" name="password" value="test@example.com" />', )
d = datetime(2007, 9, 17, 12, 51, 34, 482548) self.assertEqual(str(d), '2007-09-17 12:51:34.482548') self.check_html(self.widget, 'date', d, html=( '<input type="text" name="date" value="2007-09-17 12:51:34" />' )) self.check_html(self.widget, 'date', datetime(2007, 9, 17, 12, 51, 34), html=( '<input type="text" name="date" value="2007-09-17 12:51:34" />' )) self.check_html(self.widget, 'date', datetime(2007, 9, 17, 12, 51), html=( '<input type="text" name="date" value="2007-09-17 12:51:00" />' ))
widget = DateTimeInput( format='%d/%m/%Y %H:%M', attrs={'type': 'datetime'}, ) d = datetime(2007, 9, 17, 12, 51, 34, 482548) self.check_html(widget, 'date', d, html='<input type="datetime" name="date" value="17/09/2007 12:51" />')
class A(models.Model): ref = models.ForeignKey("B", models.CASCADE) class Meta: model = A fields = '__all__' with self.assertRaises(ValueError): ModelFormMetaclass(str('Form'), (ModelForm,), {'Meta': Meta}) class B(models.Model): pass
class C(models.Model): ref = models.ForeignKey("D", models.CASCADE) class D(models.Model): pass class Meta: model = C fields = '__all__' self.assertTrue(issubclass(ModelFormMetaclass(str('Form'), (ModelForm,), {'Meta': Meta}), ModelForm))
kwargs.setdefault('prefix', 'choices') kwargs.setdefault('auto_id', False) if formset_data is None: return formset_class(**kwargs) if total_forms is None: total_forms = len(formset_data) def prefixed(*args): args = (kwargs['prefix'],) + args return '-'.join(args) data = { prefixed('TOTAL_FORMS'): str(total_forms), prefixed('INITIAL_FORMS'): str(initial_forms), prefixed('MAX_NUM_FORMS'): str(max_num_forms), prefixed('MIN_NUM_FORMS'): str(min_num_forms), } for i, (choice, votes) in enumerate(formset_data): data[prefixed(str(i), 'choice')] = choice data[prefixed(str(i), 'votes')] = votes return formset_class(data, **kwargs)
FormSet = formset_factory(CustomKwargForm, extra=2) formset = FormSet(form_kwargs={'custom_kwarg': 1}) for form in formset: self.assertTrue(hasattr(form, 'custom_kwarg')) self.assertEqual(form.custom_kwarg, 1)
class DynamicBaseFormSet(BaseFormSet): def get_form_kwargs(self, index): return {'custom_kwarg': index} DynamicFormSet = formset_factory(CustomKwargForm, formset=DynamicBaseFormSet, extra=2) formset = DynamicFormSet(form_kwargs={'custom_kwarg': 'ignored'}) for i, form in enumerate(formset): self.assertTrue(hasattr(form, 'custom_kwarg')) self.assertEqual(form.custom_kwarg, i)
ChoiceFormset = formset_factory(Choice, extra=0) formset = ChoiceFormset() self.assertEqual(len(formset.forms), 0) self.assertTrue(formset)
data = { 'form-TOTAL_FORMS': '1', 'form-INITIAL_FORMS': '0', 'form-0-when_0': '1904-06-16', 'form-0-when_1': '15:51:33', } formset = SplitDateTimeFormSet(data) self.assertTrue(formset.is_valid())
EmptyFsetWontValidateFormset = formset_factory(FavoriteDrinkForm, extra=0, formset=EmptyFsetWontValidate) formset = EmptyFsetWontValidateFormset( data={'form-INITIAL_FORMS': '0', 'form-TOTAL_FORMS': '0'}, prefix="form", ) formset2 = EmptyFsetWontValidateFormset( data={'form-INITIAL_FORMS': '0', 'form-TOTAL_FORMS': '1', 'form-0-name': 'bah'}, prefix="form", ) self.assertFalse(formset.is_valid()) self.assertFalse(formset2.is_valid())
class MediaForm(Form): class Media: js = ('some-file.js',) self.assertIn('some-file.js', str(formset_factory(MediaForm, extra=0)().media))
url = 'something' def __str__(self): return self.url
class CustomWidget(TextInput): def render(self, name, value, attrs=None): return format_html(str('<input{} required />'), ' id=custom') class SampleForm(Form): name = CharField(widget=CustomWidget) f = SampleForm(data={'name': 'bar'}) self.assertIsInstance(force_text(f['name']), SafeData)
class SomeForm(Form): required_css_class = 'required' field = CharField(max_length=10) field2 = IntegerField(required=False) f = SomeForm({'field': 'test'}) self.assertHTMLEqual(f['field'].label_tag(), '<label for="id_field" class="required">Field:</label>') self.assertHTMLEqual( f['field'].label_tag(attrs={'class': 'foo'}), '<label for="id_field" class="foo required">Field:</label>' ) self.assertHTMLEqual(f['field2'].label_tag(), '<label for="id_field2">Field2:</label>')
class ChoicesField(MultiValueField): def __init__(self, fields=(), *args, **kwargs): fields = ( ChoiceField(label='Rank', choices=((1, 1), (2, 2))), CharField(label='Name', max_length=10), ) super(ChoicesField, self).__init__(fields=fields, *args, **kwargs) field = ChoicesField() field2 = copy.deepcopy(field) self.assertIsInstance(field2, ChoicesField) self.assertIsNot(field2.fields, field.fields) self.assertIsNot(field2.fields[0].choices, field.fields[0].choices)
class DateAgeField(MultiValueField): def __init__(self, fields=(), *args, **kwargs): fields = (DateField(label="Date"), IntegerField(label="Age")) super(DateAgeField, self).__init__(fields=fields, *args, **kwargs) class DateAgeForm(Form): date_age = DateAgeField() data = {"date_age": ["1998-12-06", 16]} form = DateAgeForm(data, initial={"date_age": ["200-10-10", 14]}) self.assertTrue(form.has_changed())
class SomeForm(Form): field = CharField() boundfield = SomeForm(auto_id='')['field'] self.assertHTMLEqual(boundfield.label_tag(), 'Field:') self.assertHTMLEqual(boundfield.label_tag('Custom&'), 'Custom&amp;:')
class SomeForm(Form): field = CharField(widget=TextInput(attrs={'id': 'myCustomID'})) field_none = CharField(widget=TextInput(attrs={'id': None})) form = SomeForm() self.assertEqual(form['field'].id_for_label, 'myCustomID') self.assertEqual(form['field_none'].id_for_label, 'id_field_none')
class SomeForm(Form): field = CharField() boundfield = SomeForm(label_suffix='!')['field'] self.assertHTMLEqual(boundfield.label_tag(label_suffix='$'), '<label for="id_field">Field$</label>')
class SomeForm(Form): some_field = CharField() def as_p(self): return self._html_output( normal_row='<p id="p_%(field_name)s"></p>', error_row='%s', row_ender='</p>', help_text_html=' %s', errors_on_separate_row=True, ) form = SomeForm() self.assertHTMLEqual(form.as_p(), '<p id="p_some_field"></p>')
class SomeForm(Form): some_field = CharField() def as_p(self): return self._html_output( normal_row='<p class="%(css_classes)s"></p>', error_row='%s', row_ender='</p>', help_text_html=' %s', errors_on_separate_row=True, ) form = SomeForm() self.assertHTMLEqual(form.as_p(), '<p class=""></p>')
class SomeForm(Form): some_field = CharField() required_css_class = 'foo' def as_p(self): return self._html_output( normal_row='<p class="%(css_classes)s"></p>', error_row='%s', row_ender='</p>', help_text_html=' %s', errors_on_separate_row=True, ) form = SomeForm() self.assertHTMLEqual(form.as_p(), '<p class="foo"></p>')
class SomeForm(Form): hidden1 = CharField(widget=HiddenInput) custom = CharField() hidden2 = CharField(widget=HiddenInput) def as_p(self): return self._html_output( normal_row='<p%(html_class_attr)s>%(field)s %(field_name)s</p>', error_row='%s', row_ender='</p>', help_text_html=' %s', errors_on_separate_row=True, ) form = SomeForm() self.assertHTMLEqual( form.as_p(), '<p><input id="id_custom" name="custom" type="text" required /> custom' '<input id="id_hidden1" name="hidden1" type="hidden" />' '<input id="id_hidden2" name="hidden2" type="hidden" /></p>' )
class SomeForm(Form): hidden1 = CharField(widget=HiddenInput) custom = CharField() hidden2 = CharField(widget=HiddenInput) def as_p(self): return self._html_output( normal_row='<p%(html_class_attr)s>%(field)s %(field_name)s</p>', error_row='%s', row_ender='<hr /><hr />', help_text_html=' %s', errors_on_separate_row=True ) form = SomeForm() self.assertHTMLEqual( form.as_p(), '<p><input id="id_custom" name="custom" type="text" required /> custom</p>\n' '<input id="id_hidden1" name="hidden1" type="hidden" />' '<input id="id_hidden2" name="hidden2" type="hidden" /><hr /><hr />' )
class MyForm(Form): foo = CharField() bar = CharField() def clean(self): raise ValidationError('<p>Non-field error.</p>', code='secret', params={'a': 1, 'b': 2}) control = { 'foo': [{'code': 'required', 'message': 'This field is required.'}], 'bar': [{'code': 'required', 'message': 'This field is required.'}], '__all__': [{'code': 'secret', 'message': '<p>Non-field error.</p>'}] } form = MyForm({}) self.assertFalse(form.is_valid()) errors = json.loads(form.errors.as_json()) self.assertEqual(errors, control) errors = json.loads(form.errors.as_json(escape_html=True)) control['__all__'][0]['message'] = '&lt;p&gt;Non-field error.&lt;/p&gt;' self.assertEqual(errors, control)
p = Person() self.assertEqual(repr(p), "<Person bound=False, valid=Unknown, fields=(first_name;last_name;birthday)>") p = Person({'first_name': 'John', 'last_name': 'Lennon', 'birthday': '1940-10-9'}) self.assertEqual(repr(p), "<Person bound=True, valid=Unknown, fields=(first_name;last_name;birthday)>") p.is_valid() self.assertEqual(repr(p), "<Person bound=True, valid=True, fields=(first_name;last_name;birthday)>") p = Person({'first_name': 'John', 'last_name': 'Lennon', 'birthday': 'fakedate'}) p.is_valid() self.assertEqual(repr(p), "<Person bound=True, valid=False, fields=(first_name;last_name;birthday)>")
p = Person({'first_name': 'John', 'last_name': 'Lennon', 'birthday': 'fakedate'}) repr(p) with self.assertRaises(AttributeError): p.cleaned_data self.assertFalse(p.is_valid()) self.assertEqual(p.cleaned_data, {'first_name': 'John', 'last_name': 'Lennon'})
attrs = {'foo': 'bar', 'true': True, 'false': False} attrs_copy = copy.copy(attrs) self.assertEqual(attrs, attrs_copy) first_run = flatatt(attrs) self.assertEqual(attrs, attrs_copy) self.assertEqual(first_run, ' foo="bar" true') second_run = flatatt(attrs) self.assertEqual(attrs, attrs_copy) self.assertEqual(first_run, second_run)
) def test_html_safe(self): media = Media(css={'all': ['/path/to/css']}, js=['/path/to/js']) self.assertTrue(hasattr(Media, '__html__')) self.assertEqual(force_text(media), media.__html__())
Person.objects.get_or_create( first_name='George', last_name='Harrison', defaults={ 'birthday': date(1943, 2, 25) } ) created = Person.objects.get_or_create( first_name='George', last_name='Harrison', defaults={ 'birthday': date(1943, 2, 25) } )[1] self.assertFalse(created) self.assertEqual(Person.objects.count(), 2)
with self.assertRaises(IntegrityError): Person.objects.get_or_create(first_name="Tom", last_name="Smith")
obj, created = Person.objects.get_or_create( first_name='George', last_name='Harrison', defaults__exact='testing', defaults={ 'birthday': date(1943, 2, 25), 'defaults': 'testing', } ) self.assertTrue(created) self.assertEqual(obj.defaults, 'testing') obj2, created = Person.objects.get_or_create( first_name='George', last_name='Harrison', defaults__exact='testing', defaults={ 'birthday': date(1943, 2, 25), 'defaults': 'testing', } ) self.assertFalse(created) self.assertEqual(obj, obj2)
with self.assertRaises(IntegrityError): ManualPrimaryKeyTest.objects.get_or_create(id=1, data="Different") self.assertEqual(ManualPrimaryKeyTest.objects.get(id=1).data, "Original")
try: Person.objects.get_or_create( birthday=date(1970, 1, 1), defaults={'first_name': b"\xff", 'last_name': b"\xff"}) except (DatabaseError, DjangoUnicodeDecodeError): Person.objects.create( first_name="Bob", last_name="Ross", birthday=date(1950, 1, 1)) else: self.skipTest("This backend accepts broken utf-8.")
try: DefaultPerson.objects.get_or_create() except AssertionError: self.fail("If all the attributes on a model have defaults, we " "shouldn't need to pass any arguments.")
try: Profile.objects.get_or_create(person=Person(id=1)) except IntegrityError: pass else: self.skipTest("This backend does not support integrity checks.")
with self.assertRaises(IntegrityError): Person.objects.update_or_create(first_name="Tom", last_name="Smith")
ManualPrimaryKeyTest.objects.create(id=1, data="Original") with self.assertRaises(IntegrityError): ManualPrimaryKeyTest.objects.update_or_create(id=1, data="Different") self.assertEqual(ManualPrimaryKeyTest.objects.get(id=1).data, "Original")
try: ManualPrimaryKeyTest.objects.update_or_create(id=1, data="Different") except IntegrityError: formatted_traceback = traceback.format_exc() self.assertIn('obj.save', formatted_traceback)
p = Publisher.objects.create(name="Acme Publishing") book, created = p.books.update_or_create(name="The Book of Ed & Fred") self.assertTrue(created) self.assertEqual(p.books.count(), 1)
p = Publisher.objects.create(name="Acme Publishing") book = Book.objects.create(name="The Book of Ed & Fred", publisher=p) self.assertEqual(p.books.count(), 1) name = "The Book of Django" book, created = p.books.update_or_create(defaults={'name': name}, id=book.id) self.assertFalse(created) self.assertEqual(book.name, name) self.assertEqual(p.books.count(), 1)
p = Publisher.objects.create(name="Acme Publishing") author = Author.objects.create(name="Ted") book, created = author.books.update_or_create(name="The Book of Ed & Fred", publisher=p) self.assertTrue(created) self.assertEqual(author.books.count(), 1)
p = Publisher.objects.create(name="Acme Publishing") author = Author.objects.create(name="Ted") book = Book.objects.create(name="The Book of Ed & Fred", publisher=p) book.authors.add(author) self.assertEqual(author.books.count(), 1) name = "The Book of Django" book, created = author.books.update_or_create(defaults={'name': name}, id=book.id) self.assertFalse(created) self.assertEqual(book.name, name) self.assertEqual(author.books.count(), 1)
obj, created = Person.objects.update_or_create( first_name='George', last_name='Harrison', defaults__exact='testing', defaults={ 'birthday': date(1943, 2, 25), 'defaults': 'testing', } ) self.assertTrue(created) self.assertEqual(obj.defaults, 'testing') obj, created = Person.objects.update_or_create( first_name='George', last_name='Harrison', defaults__exact='testing', defaults={ 'birthday': date(1943, 2, 25), 'defaults': 'another testing', } ) self.assertFalse(created) self.assertEqual(obj.defaults, 'another testing')
self.assertEqual(self.func(None), [sessions.W010])
self.assertEqual(self.func(None), [sessions.W011])
self.assertEqual(self.func(None), [sessions.W012])
self.assertEqual(self.func(None), [])
self.assertEqual(self.func(None), [sessions.W013])
self.assertEqual(self.func(None), [sessions.W014])
self.assertEqual(self.func(None), [sessions.W015])
self.assertEqual(self.func(None), [])
self.assertEqual(self.func(None), [csrf.W003])
self.assertEqual(self.func(None), [csrf.W016])
self.assertEqual(self.func(None), [])
self.assertEqual(self.func(None), [csrf.W017])
self.assertEqual(self.func(None), [])
self.assertEqual(self.func(None), [base.W001])
self.assertEqual(self.func(None), [base.W004])
self.assertEqual(self.func(None), [])
self.assertEqual(self.func(None), [base.W005])
self.assertEqual(self.func(None), [])
self.assertEqual(self.func(None), [])
self.assertEqual(self.func(None), [base.W002])
self.assertEqual(self.func(None), [base.W019])
self.assertEqual(self.func(None), [])
self.assertEqual(self.func(None), [base.W006])
self.assertEqual(self.func(None), [])
self.assertEqual(self.func(None), [base.W007])
self.assertEqual(self.func(None), [])
self.assertEqual(self.func(None), [base.W008])
self.assertEqual(self.func(None), [])
self.assertEqual(self.func(None), [base.W018])
def f1(**kwargs): return [5] registry = CheckRegistry() registry.register(Tags.database)(f1) errors = registry.run_checks() self.assertEqual(errors, []) errors2 = registry.run_checks(tags=[Tags.database]) self.assertEqual(errors2, [5])
self.assertEqual(self.func(None), [E001])
self.assertEqual(self.func(None), [])
self.assertEqual(self.func(None), [E001])
def allow_migrate(self, db, app_label, model_name=None, **hints): return db == ('other' if model_name.startswith('other') else 'default')
qs = ( Book.objects.annotate(xprice=F('price')).filter(rating=4.0).values('rating') .annotate(count=Count('publisher_id', distinct=True)).values('count', 'rating').order_by('count') ) self.assertEqual( list(qs), [ {'rating': 4.0, 'count': 2}, ] )
qs = ( Book.objects.annotate(xprice=F('price')).filter(rating=4.0).values('rating', 'xprice') .annotate(count=Count('publisher_id', distinct=True)).values('count', 'rating').order_by('count') ) self.assertEqual( list(qs), [ {'rating': 4.0, 'count': 1}, {'rating': 4.0, 'count': 2}, ] )
dates = Book.objects.annotate(num_authors=Count("authors")).dates('pubdate', 'year') self.assertQuerysetEqual( dates, [ "datetime.date(1991, 1, 1)", "datetime.date(1995, 1, 1)", "datetime.date(2007, 1, 1)", "datetime.date(2008, 1, 1)" ] )
qs = Book.objects.all().order_by('-rating')[0:3] vals = qs.aggregate(average_top3_rating=Avg('rating'))['average_top3_rating'] self.assertAlmostEqual(vals, 4.5, places=2)
UserFormSet = modelformset_factory(User, fields=()) formset = UserFormSet() for form in formset.forms: self.assertIn('id', form.fields) self.assertEqual(len(form.fields), 1)
def test_inlineformset_factory_default(self): Formset = inlineformset_factory(User, UserSite, form=UserSiteForm, fields="__all__") form = Formset().forms[0] self.assertIsInstance(form['id'].field.widget, CustomWidget) self.assertIsInstance(form['data'].field.widget, CustomWidget) self.assertFalse(form.fields['id'].localize) self.assertTrue(form.fields['data'].localize) def test_modelformset_factory_default(self): Formset = modelformset_factory(UserSite, form=UserSiteForm) form = Formset().forms[0] self.assertIsInstance(form['id'].field.widget, CustomWidget) self.assertIsInstance(form['data'].field.widget, CustomWidget) self.assertFalse(form.fields['id'].localize) self.assertTrue(form.fields['data'].localize) def assertCallbackCalled(self, callback): id_field, user_field, data_field = UserSite._meta.fields expected_log = [ (id_field, {'widget': CustomWidget}), (user_field, {}), (data_field, {'widget': CustomWidget, 'localize': True}), ] self.assertEqual(callback.log, expected_log) def test_inlineformset_custom_callback(self): callback = Callback() inlineformset_factory(User, UserSite, form=UserSiteForm, formfield_callback=callback, fields="__all__") self.assertCallbackCalled(callback) def test_modelformset_custom_callback(self): callback = Callback() modelformset_factory(UserSite, form=UserSiteForm, formfield_callback=callback) self.assertCallbackCalled(callback)
def add_fields(self, form, index): super(BaseCustomDeleteFormSet, self).add_fields(form, index) self.can_delete = True if DELETION_FIELD_NAME in form.fields: del form.fields[DELETION_FIELD_NAME] def _should_delete_form(self, form): return hasattr(form, 'should_delete') and form.should_delete()
return self.instance.pk % 2 != 0
formset = self.NormalFormset(self.data) self.assertTrue(formset.is_valid()) self.assertEqual(len(formset.save()), 4)
msg = 'Unsafe Signer separator: %r (cannot be empty or consist of only A-z0-9-_=)' separators = ['', '-', 'abc'] for sep in separators: with self.assertRaisesMessage(ValueError, msg % sep): signing.Signer(sep=sep)
tempfile = NamedTemporaryFile() self.assertTrue(hasattr(tempfile, "closed")) self.assertFalse(tempfile.closed) tempfile.close() self.assertTrue(tempfile.closed)
file = File(BytesIO(b'one\ntwo\nthree')) self.assertEqual(list(file), [b'one\n', b'two\n', b'three'])
f = File(BytesIO(b'one\r\ntwo\r\nthree')) self.assertEqual(list(f), [b'one\r\n', b'two\r\n', b'three'])
f = File(BytesIO(b'one\rtwo\rthree')) self.assertEqual(list(f), [b'one\r', b'two\r', b'three'])
def test_noname_file_default_name(self): self.assertEqual(File(BytesIO(b'A file with no name')).name, None) def test_noname_file_get_size(self): self.assertEqual(File(BytesIO(b'A file with no name')).size, 19)
name = "I can have a name too!" self.assertEqual(ContentFile(b"content", name=name).name, name)
self.assertIsInstance(ContentFile(b"content").read(), bytes) if six.PY3: self.assertIsInstance(ContentFile("espaol").read(), six.text_type) else: self.assertIsInstance(ContentFile("espaol").read(), bytes)
empty_io = BytesIO() try: images.get_image_dimensions(empty_io) finally: self.assertTrue(not empty_io.closed)
img_path = os.path.join(os.path.dirname(upath(__file__)), "test.png") with open(img_path, 'rb') as fh: image = images.ImageFile(fh) image_pil = Image.open(fh) size_1 = images.get_image_dimensions(image) size_2 = images.get_image_dimensions(image) self.assertEqual(image_pil.size, size_1) self.assertEqual(size_1, size_2)
img_path = os.path.join(os.path.dirname(upath(__file__)), "magic.png") size = images.get_image_dimensions(img_path) with open(img_path, 'rb') as fh: self.assertEqual(size, Image.open(fh).size)
img_path = os.path.join(os.path.dirname(upath(__file__)), "brokenimg.png") with open(img_path, 'rb') as fh: size = images.get_image_dimensions(fh) self.assertEqual(size, (None, None))
img_path = os.path.join(os.path.dirname(upath(__file__)), "test.png") with mock.patch('PIL.ImageFile.Parser.feed', side_effect=struct.error): with open(img_path, 'rb') as fh: size = images.get_image_dimensions(fh) self.assertEqual(size, (None, None))
Redirect.objects.create(site=self.site, old_path='/initial', new_path='') response = self.client.get('/initial') self.assertEqual(response.status_code, 410)
holder = Holder.objects.get(dummy=13) response = self.client.get( reverse('admin:admin_inlines_holder_change', args=(holder.id,)) ) inner_formset = response.context['inline_admin_formsets'][0].formset expected = InnerInline.can_delete actual = inner_formset.can_delete self.assertEqual(expected, actual, 'can_delete must be equal')
holder = Holder.objects.create(dummy=42) Inner.objects.create(holder=holder, dummy=42, readonly='') response = self.client.get( reverse('admin:admin_inlines_holder_change', args=(holder.id,)) ) self.assertContains(response, '<label>Inner readonly label:</label>')
response = self.client.get(reverse('admin:admin_inlines_titlecollection_add')) self.assertContains(response, '<th class="required">Title1</th>', html=True)
parent = SomeParentModel.objects.create(name='a') SomeChildModel.objects.create(name='b', position='0', parent=parent) SomeChildModel.objects.create(name='c', position='1', parent=parent) response = self.client.get(reverse('admin:admin_inlines_someparentmodel_change', args=(parent.pk,))) self.assertNotContains(response, '<td class="field-position">') self.assertContains(response, ( '<input id="id_somechildmodel_set-1-position" ' 'name="somechildmodel_set-1-position" type="hidden" value="1" />'))
response = self.client.get(reverse('admin:admin_inlines_capofamiglia_add')) self.assertContains(response, '<input type="hidden" name="-1-0-id" id="id_-1-0-id" />', html=True) self.assertContains( response, '<input type="hidden" name="-1-0-capo_famiglia" id="id_-1-0-capo_famiglia" />', html=True ) self.assertContains( response, '<input id="id_-1-0-name" type="text" class="vTextField" name="-1-0-name" maxlength="100" />', html=True ) self.assertContains(response, '<input type="hidden" name="-2-0-id" id="id_-2-0-id" />', html=True) self.assertContains( response, '<input type="hidden" name="-2-0-capo_famiglia" id="id_-2-0-capo_famiglia" />', html=True ) self.assertContains( response, '<input id="id_-2-0-name" type="text" class="vTextField" name="-2-0-name" maxlength="100" />', html=True )
holder = Holder.objects.create(pk=123456789, dummy=42) inner = Inner.objects.create(pk=987654321, holder=holder, dummy=42, readonly='') response = self.client.get(reverse('admin:admin_inlines_holder_change', args=(holder.id,))) inner_shortcut = 'r/%s/%s/' % (ContentType.objects.get_for_model(inner).pk, inner.pk) self.assertContains(response, inner_shortcut)
parent = ParentModelWithCustomPk.objects.create(my_own_pk="foo", name="Foo") child1 = ChildModel1.objects.create(my_own_pk="bar", name="Bar", parent=parent) child2 = ChildModel2.objects.create(my_own_pk="baz", name="Baz", parent=parent) response = self.client.get(reverse('admin:admin_inlines_parentmodelwithcustompk_change', args=('foo',))) child1_shortcut = 'r/%s/%s/' % (ContentType.objects.get_for_model(child1).pk, child1.pk) child2_shortcut = 'r/%s/%s/' % (ContentType.objects.get_for_model(child2).pk, child2.pk) self.assertContains(response, child1_shortcut) self.assertContains(response, child2_shortcut)
data = { 'name': 'Martian', 'sighting_set-TOTAL_FORMS': 1, 'sighting_set-INITIAL_FORMS': 0, 'sighting_set-MAX_NUM_FORMS': 0, 'sighting_set-0-place': 'Zone 51', '_save': 'Save', } response = self.client.post(reverse('admin:admin_inlines_extraterrestrial_add'), data) self.assertEqual(response.status_code, 302) self.assertEqual(Sighting.objects.filter(et__name='Martian').count(), 1)
class MinNumInline(TabularInline): model = BinaryTree min_num = 2 extra = 3 modeladmin = ModelAdmin(BinaryTree, admin_site) modeladmin.inlines = [MinNumInline] min_forms = ( '<input id="id_binarytree_set-MIN_NUM_FORMS" ' 'name="binarytree_set-MIN_NUM_FORMS" type="hidden" value="2" />' ) total_forms = ( '<input id="id_binarytree_set-TOTAL_FORMS" ' 'name="binarytree_set-TOTAL_FORMS" type="hidden" value="5" />' ) request = self.factory.get(reverse('admin:admin_inlines_binarytree_add')) request.user = User(username='super', is_superuser=True) response = modeladmin.changeform_view(request) self.assertContains(response, min_forms) self.assertContains(response, total_forms)
bt_head = BinaryTree.objects.create(name="Tree Head") BinaryTree.objects.create(name="First Child", parent=bt_head) class MinNumInline(TabularInline): model = BinaryTree extra = 3 def get_min_num(self, request, obj=None, **kwargs): if obj: return 5 return 2 modeladmin = ModelAdmin(BinaryTree, admin_site) modeladmin.inlines = [MinNumInline] min_forms = ( '<input id="id_binarytree_set-MIN_NUM_FORMS" ' 'name="binarytree_set-MIN_NUM_FORMS" type="hidden" value="%d" />' ) total_forms = ( '<input id="id_binarytree_set-TOTAL_FORMS" ' 'name="binarytree_set-TOTAL_FORMS" type="hidden" value="%d" />' ) request = self.factory.get(reverse('admin:admin_inlines_binarytree_add')) request.user = User(username='super', is_superuser=True) response = modeladmin.changeform_view(request) self.assertContains(response, min_forms % 2) self.assertContains(response, total_forms % 5) request = self.factory.get(reverse('admin:admin_inlines_binarytree_change', args=(bt_head.id,))) request.user = User(username='super', is_superuser=True) response = modeladmin.changeform_view(request, object_id=str(bt_head.id)) self.assertContains(response, min_forms % 5) self.assertContains(response, total_forms % 8)
sally = Teacher.objects.create(name='Sally') john = Parent.objects.create(name='John') joe = Child.objects.create(name='Joe', teacher=sally, parent=john) iaf = InlineAdminForm(None, None, {}, {}, joe) parent_ct = ContentType.objects.get_for_model(Parent) self.assertEqual(iaf.original.content_type, parent_ct)
self.admin_login(username='super', password='secret') self.selenium.get(self.live_server_url + reverse('admin:admin_inlines_holder4_add')) inline_id = '#inner4stacked_set-group' def rows_length(): return len(self.selenium.find_elements_by_css_selector('%s .dynamic-inner4stacked_set' % inline_id)) self.assertEqual(rows_length(), 3) add_button = self.selenium.find_element_by_link_text( 'Add another Inner4 stacked') add_button.click() self.assertEqual(rows_length(), 4)
resolver = RegexURLResolver(r'^$', settings.ROOT_URLCONF) with self.assertRaisesMessage( ImproperlyConfigured, "The included URLconf 'urlpatterns_reverse.no_urls' does not " "appear to have any patterns in it. If you see valid patterns in " "the file then the issue is probably caused by a circular import." ): getattr(resolver, 'url_patterns')
urls = 'urlpatterns_reverse.named_urls' proxy_url = reverse_lazy('named-url1', urlconf=urls) resolver = get_resolver(urls) try: resolver.resolve(proxy_url) except TypeError: self.fail('Failed to coerce lazy object to text')
with self.assertRaises(Resolver404): resolve('') with self.assertRaises(Resolver404): resolve('a') with self.assertRaises(Resolver404): resolve('\\') with self.assertRaises(Resolver404): resolve('.')
response = self.client.get('/test/me/') self.assertEqual(response.status_code, 200) self.assertEqual(response.content, b'outer:/test/me/,inner:/inner_urlconf/second_test/') response = self.client.get('/inner_urlconf/second_test/') self.assertEqual(response.status_code, 200) response = self.client.get('/second_test/') self.assertEqual(response.status_code, 404)
response = self.client.get('/second_test/') self.assertEqual(response.status_code, 200) self.assertEqual(response.content, b'/second_test/')
message = "Reverse for 'outer' with arguments '()' and keyword arguments '{}' not found." with self.assertRaisesMessage(NoReverseMatch, message): self.client.get('/second_test/')
response = self.client.get('/second_test/') self.assertEqual(response.status_code, 200) self.assertEqual(b''.join(response), b'/second_test/')
message = "Reverse for 'outer' with arguments '()' and keyword arguments '{}' not found." with self.assertRaisesMessage(NoReverseMatch, message): self.client.get('/second_test/') b''.join(self.client.get('/second_test/'))
def setUp(self): urlconf = 'urlpatterns_reverse.urls_error_handlers' urlconf_callables = 'urlpatterns_reverse.urls_error_handlers_callables' self.resolver = RegexURLResolver(r'^$', urlconf) self.callable_resolver = RegexURLResolver(r'^$', urlconf_callables) def test_named_handlers(self): handler = (empty_view, {}) self.assertEqual(self.resolver.resolve_error_handler(400), handler) self.assertEqual(self.resolver.resolve_error_handler(404), handler) self.assertEqual(self.resolver.resolve_error_handler(500), handler) def test_callable_handlers(self): handler = (empty_view, {}) self.assertEqual(self.callable_resolver.resolve_error_handler(400), handler) self.assertEqual(self.callable_resolver.resolve_error_handler(404), handler) self.assertEqual(self.callable_resolver.resolve_error_handler(500), handler)
def test_no_handler_exception(self): with self.assertRaises(ImproperlyConfigured): self.client.get('/test/me/')
q = QueryDict(str('foo=bar')) self.assertEqual(q['foo'], 'bar') with self.assertRaises(KeyError): q.__getitem__('bar') with self.assertRaises(AttributeError): q.__setitem__('something', 'bar') self.assertEqual(q.get('foo', 'default'), 'bar') self.assertEqual(q.get('bar', 'default'), 'default') self.assertEqual(q.getlist('foo'), ['bar']) self.assertEqual(q.getlist('bar'), []) with self.assertRaises(AttributeError): q.setlist('foo', ['bar']) with self.assertRaises(AttributeError): q.appendlist('foo', ['bar']) if six.PY2: self.assertTrue(q.has_key('foo')) self.assertIn('foo', q) if six.PY2: self.assertFalse(q.has_key('bar')) self.assertNotIn('bar', q) self.assertEqual(list(six.iteritems(q)), [('foo', 'bar')]) self.assertEqual(list(six.iterlists(q)), [('foo', ['bar'])]) self.assertEqual(list(six.iterkeys(q)), ['foo']) self.assertEqual(list(six.itervalues(q)), ['bar']) self.assertEqual(len(q), 1) with self.assertRaises(AttributeError): q.update({'foo': 'bar'}) with self.assertRaises(AttributeError): q.pop('foo') with self.assertRaises(AttributeError): q.popitem() with self.assertRaises(AttributeError): q.clear() with self.assertRaises(AttributeError): q.setdefault('foo', 'bar') self.assertEqual(q.urlencode(), 'foo=bar')
q = QueryDict().copy() with self.assertRaises(KeyError): q.__getitem__("foo") q['name'] = 'john' self.assertEqual(q['name'], 'john')
q = QueryDict(str('vote=yes&vote=no')) self.assertEqual(q['vote'], 'no') with self.assertRaises(AttributeError): q.__setitem__('something', 'bar') self.assertEqual(q.get('vote', 'default'), 'no') self.assertEqual(q.get('foo', 'default'), 'default') self.assertEqual(q.getlist('vote'), ['yes', 'no']) self.assertEqual(q.getlist('foo'), []) with self.assertRaises(AttributeError): q.setlist('foo', ['bar', 'baz']) with self.assertRaises(AttributeError): q.setlist('foo', ['bar', 'baz']) with self.assertRaises(AttributeError): q.appendlist('foo', ['bar']) if six.PY2: self.assertEqual(q.has_key('vote'), True) self.assertEqual('vote' in q, True) if six.PY2: self.assertEqual(q.has_key('foo'), False) self.assertEqual('foo' in q, False) self.assertEqual(list(six.iteritems(q)), [('vote', 'no')]) self.assertEqual(list(six.iterlists(q)), [('vote', ['yes', 'no'])]) self.assertEqual(list(six.iterkeys(q)), ['vote']) self.assertEqual(list(six.itervalues(q)), ['no']) self.assertEqual(len(q), 1) with self.assertRaises(AttributeError): q.update({'foo': 'bar'}) with self.assertRaises(AttributeError): q.pop('foo') with self.assertRaises(AttributeError): q.popitem() with self.assertRaises(AttributeError): q.clear() with self.assertRaises(AttributeError): q.setdefault('foo', 'bar') with self.assertRaises(AttributeError): q.__delitem__('vote')
q = QueryDict(str(b'foo=bar&foo=\xff')) self.assertEqual(q['foo'], '\xff') self.assertEqual(q.getlist('foo'), ['bar', '\xff'])
x = QueryDict(str("a=1&a=2"), mutable=True) y = QueryDict(str("a=3&a=4")) x.update(y) self.assertEqual(x.getlist('a'), ['1', '2', '3', '4'])
q = QueryDict(str('cur=%A4'), encoding='iso-8859-15') self.assertEqual(q.encoding, 'iso-8859-15') self.assertEqual(list(six.iteritems(q)), [('cur', '')]) self.assertEqual(q.urlencode(), 'cur=%A4') q = q.copy() self.assertEqual(q.encoding, 'iso-8859-15') self.assertEqual(list(six.iteritems(q)), [('cur', '')]) self.assertEqual(q.urlencode(), 'cur=%A4') self.assertEqual(copy.copy(q).encoding, 'iso-8859-15') self.assertEqual(copy.deepcopy(q).encoding, 'iso-8859-15')
r = HttpResponse() self.assertEqual(r.get('test'), None)
r = HttpResponseRedirect(lazystr('/redirected/')) self.assertEqual(r.url, '/redirected/')
c = SimpleCookie() c['test'] = "An,awkward;value" c2 = SimpleCookie() c2.load(c.output()[12:]) self.assertEqual(c['test'].value, c2['test'].value) c3 = parse_cookie(c.output()[12:]) self.assertEqual(c['test'].value, c3['test'])
c = SimpleCookie() c['test'] = b"\xf0" c2 = SimpleCookie() c2.load(c.output()[12:]) self.assertEqual(c['test'].value, c2['test'].value) c3 = parse_cookie(c.output()[12:]) self.assertEqual(c['test'].value, c3['test'])
self.assertIn('good_cookie', parse_cookie('good_cookie=yes;bad:cookie=yes').keys())
self.assertIn('good_cookie', parse_cookie('a:=b; a:=c; good_cookie=yes').keys())
c = SimpleCookie() c.load("name=val") c['name']['httponly'] = True self.assertTrue(c['name']['httponly'])
r = HttpResponse() r.set_cookie("a:.b/", 1) self.assertEqual(len(r.cookies.bad_cookies), 1)
available_apps = [] def test_table_exists(self): with extend_sys_path(os.path.dirname(os.path.abspath(upath(__file__)))): with self.modify_settings(INSTALLED_APPS={'append': ['app1', 'app2']}): call_command('migrate', verbosity=0, run_syncdb=True) from app1.models import ProxyModel from app2.models import NiceModel self.assertEqual(NiceModel.objects.all().count(), 0) self.assertEqual(ProxyModel.objects.all().count(), 0)
instance = ConcreteModelSubclassProxy.objects.create() instance.delete() self.assertEqual(0, ConcreteModelSubclassProxy.objects.count()) self.assertEqual(0, ConcreteModelSubclass.objects.count()) self.assertEqual(0, ConcreteModel.objects.count())
from unittest import expectedFailure from django.db import connection return expectedFailure(func) if connection.vendor == 'oracle' and six.PY3 else func
qs = Book.objects.defer('rating').annotate(other_rating=F('rating') - 1) with self.assertNumQueries(2): book = qs.get(other_rating=4) self.assertEqual(book.rating, 5) self.assertEqual(book.other_rating, 4) with six.assertRaisesRegex(self, FieldDoesNotExist, "\w has no field named u?'other_rating'"): book = qs.defer('other_rating').get(other_rating=4)
d = DepartmentStore.objects.create( name='Angus & Robinson', original_opening=datetime.date(2014, 3, 8), friday_night_closing=datetime.time(21, 00, 00), chain='Westfield' ) books = Book.objects.filter(rating__gt=4) for b in books: d.books.add(b) qs = DepartmentStore.objects.annotate( other_name=F('name'), other_chain=F('chain'), is_open=Value(True, BooleanField()), book_isbn=F('books__isbn') ).order_by('book_isbn').filter(chain='Westfield') self.assertQuerysetEqual( qs, [ ('Angus & Robinson', 'Westfield', True, '155860191'), ('Angus & Robinson', 'Westfield', True, '159059725') ], lambda d: (d.other_name, d.other_chain, d.is_open, d.book_isbn) )
book = Book.objects.annotate(no_value=Value(None, output_field=IntegerField())).first() self.assertIsNone(book.no_value)
store = Store.objects.first() Employee.objects.create(id=1, first_name='Max', manager=True, last_name='Paine', store=store, age=23, salary=Decimal(50000.00)) Employee.objects.create(id=2, first_name='Buffy', manager=False, last_name='Summers', store=store, age=18, salary=Decimal(40000.00)) qs = Employee.objects.extra( select={'random_value': '42'} ).select_related('store').annotate( annotated_value=Value(17, output_field=IntegerField()) ) rows = [ (1, 'Max', True, 42, 'Paine', 23, Decimal(50000.00), store.name, 17), (2, 'Buffy', False, 42, 'Summers', 18, Decimal(40000.00), store.name, 17) ] self.assertQuerysetEqual( qs.order_by('id'), rows, lambda e: ( e.id, e.first_name, e.manager, e.random_value, e.last_name, e.age, e.salary, e.store.name, e.annotated_value))
error = Error('an error') class Model(models.Model): field = models.IntegerField() field = Model._meta.get_field('field') with mock.patch.object(connections['default'].validation, 'check_field', return_value=[error]): errors = field.check() self.assertEqual(errors, [error])
class OtherModel(models.Model): pass class Model(models.Model): foreign_key = models.ForeignKey('OtherModel', models.CASCADE) field = Model._meta.get_field('foreign_key') self.assertEqual(field.check(from_model=Model), [])
class OtherModel(models.Model): pass class Model(models.Model): m2m = models.ManyToManyField('OtherModel') field = Model._meta.get_field('m2m') self.assertEqual(field.check(from_model=Model), [])
class GroupMember(models.Model): person = models.ForeignKey('Person', models.CASCADE) group = models.ForeignKey('Group', models.CASCADE) class Person(models.Model): pass class Group(models.Model): members = models.ManyToManyField('Person', through='GroupMember') field = Group._meta.get_field('members') self.assertEqual(field.check(from_model=Group), [])
class Target(models.Model): pass class Model(models.Model): children = models.ManyToManyField('Child', related_name="m2m_clash", related_query_name="no_clash") class Parent(models.Model): m2m_clash = models.ManyToManyField('Target') class Child(Parent): pass errors = Model.check() expected = [ Error( "Reverse accessor for 'Model.children' clashes with field name 'Child.m2m_clash'.", hint=( "Rename field 'Child.m2m_clash', or add/change a related_name " "argument to the definition for field 'Model.children'." ), obj=Model._meta.get_field('children'), id='fields.E302', ) ] self.assertEqual(errors, expected)
class Fan(models.Model): pass with self.assertRaisesMessage(ValueError, 'Cannot specify through_fields without a through model'): models.ManyToManyField(Fan, through_fields=('f1', 'f2'))
class Fan(models.Model): pass class Event(models.Model): invitees = models.ManyToManyField(Fan, through='Invitation', through_fields=('invitee', 'event')) class Invitation(models.Model): event = models.ForeignKey(Event, models.CASCADE) invitee = models.ForeignKey(Fan, models.CASCADE) inviter = models.ForeignKey(Fan, models.CASCADE, related_name='+') field = Event._meta.get_field('invitees') errors = field.check(from_model=Event) expected = [ Error( "'Invitation.invitee' is not a foreign key to 'Event'.", hint="Did you mean one of the following foreign keys to 'Event': event?", obj=field, id='fields.E339', ), Error( "'Invitation.event' is not a foreign key to 'Fan'.", hint="Did you mean one of the following foreign keys to 'Fan': invitee, inviter?", obj=field, id='fields.E339', ), ] self.assertEqual(expected, errors)
class Fan(models.Model): pass class Event(models.Model): invitees = models.ManyToManyField( Fan, through='Invitation', through_fields=('invalid_field_1', 'invalid_field_2'), ) class Invitation(models.Model): event = models.ForeignKey(Event, models.CASCADE) invitee = models.ForeignKey(Fan, models.CASCADE) inviter = models.ForeignKey(Fan, models.CASCADE, related_name='+') field = Event._meta.get_field('invitees') errors = field.check(from_model=Event) expected = [ Error( "The intermediary model 'invalid_models_tests.Invitation' has no field 'invalid_field_1'.", hint="Did you mean one of the following foreign keys to 'Event': event?", obj=field, id='fields.E338', ), Error( "The intermediary model 'invalid_models_tests.Invitation' has no field 'invalid_field_2'.", hint="Did you mean one of the following foreign keys to 'Fan': invitee, inviter?", obj=field, id='fields.E338', ), ] self.assertEqual(expected, errors)
class Fan(models.Model): pass class Event(models.Model): invitees = models.ManyToManyField(Fan, through='Invitation', through_fields=(None, 'invitee')) class Invitation(models.Model): event = models.ForeignKey(Event, models.CASCADE) invitee = models.ForeignKey(Fan, models.CASCADE) inviter = models.ForeignKey(Fan, models.CASCADE, related_name='+') field = Event._meta.get_field('invitees') errors = field.check(from_model=Event) expected = [ Error( "Field specifies 'through_fields' but does not provide the names " "of the two link fields that should be used for the relation " "through model 'invalid_models_tests.Invitation'.", hint="Make sure you specify 'through_fields' as through_fields=('field1', 'field2')", obj=field, id='fields.E337')] self.assertEqual(expected, errors)
class BandAdmin(ModelAdmin): fields = ['name'] ma = BandAdmin(Band, self.site) self.assertTrue(ma.lookup_allowed('name__nonexistent', 'test_value'))
class AdminBandForm(forms.ModelForm): class Meta: model = Band exclude = ['name'] class BandAdmin(ModelAdmin): exclude = ['sign_date'] form = AdminBandForm def get_form(self, request, obj=None, **kwargs): kwargs['exclude'] = ['bio'] return super(BandAdmin, self).get_form(request, obj, **kwargs) ma = BandAdmin(Band, self.site) self.assertEqual(list(ma.get_form(request).base_fields), ['name', 'sign_date'])
class AdminConcertForm(forms.ModelForm): class Meta: model = Concert exclude = ['day'] class ConcertInline(TabularInline): exclude = ['transport'] form = AdminConcertForm fk_name = 'main_band' model = Concert def get_formset(self, request, obj=None, **kwargs): kwargs['exclude'] = ['opening_band'] return super(ConcertInline, self).get_formset(request, obj, **kwargs) class BandAdmin(ModelAdmin): inlines = [ ConcertInline ] ma = BandAdmin(Band, self.site) self.assertEqual( list(list(ma.get_formsets_with_inlines(request))[0][0]().forms[0].fields), ['main_band', 'day', 'transport', 'id', 'DELETE'])
invalid_obj = invalid_obj or model_admin admin_obj = model_admin(model, AdminSite()) errors = admin_obj.check() self.assertEqual(len(errors), 1) error = errors[0] self.assertEqual(error.hint, hint) self.assertEqual(error.obj, invalid_obj) self.assertEqual(error.id, id) six.assertRegex(self, error.msg, msg)
def __call__(self, parser, namespace, values, option_string=None): browsers = values.split(',') for browser in browsers: try: SeleniumTestCaseBase.import_webdriver(browser) except ImportError: raise argparse.ArgumentError(self, "Selenium browser specification '%s' is not valid." % browser) setattr(namespace, self.dest, browsers)
process_view(self.rf.get('/'))
class_process_view(self.rf.get('/'))
django_dir = os.path.join(os.path.dirname(conf.__file__), 'locale') django_mo = os.path.join(django_dir, 'nl', 'LC_MESSAGES', 'django.mo') self.assertFileFound(django_mo)
locale_paths_mo = os.path.join(LOCALE_PATH, 'nl', 'LC_MESSAGES', 'django.mo') self.assertFileFound(locale_paths_mo)
old_cwd = os.getcwd() os.chdir(os.path.dirname(__file__)) current_dir = os.path.join(os.path.dirname(__file__), 'locale') current_dir_mo = os.path.join(current_dir, 'nl', 'LC_MESSAGES', 'django.mo') try: self.assertFileFound(current_dir_mo) finally: os.chdir(old_cwd)
admin_dir = os.path.join(os.path.dirname(admin.__file__), 'locale') admin_mo = os.path.join(admin_dir, 'nl', 'LC_MESSAGES', 'django.mo') self.assertFileFound(admin_mo)
django_dir = os.path.join(os.path.dirname(conf.__file__), 'locale') django_mo = os.path.join(django_dir, 'nl', 'LC_MESSAGES', 'django.mo') self.assertFileNotFound(django_mo)
dirname = tempfile.mkdtemp() filename = os.path.join(dirname, 'test_deleted_removed_module.py') self.addCleanup(shutil.rmtree, dirname) with open(filename, 'w'): pass with extend_sys_path(dirname): import_module('test_deleted_removed_module') self.assertFileFound(filename) os.unlink(filename) self.assertFileNotFound(filename)
dirname = tempfile.mkdtemp() filename = os.path.join(dirname, 'test_syntax_error.py') self.addCleanup(shutil.rmtree, dirname) with open(filename, 'w') as f: f.write("Ceci n'est pas du Python.") with extend_sys_path(dirname): with self.assertRaises(SyntaxError): autoreload.check_errors(import_module)('test_syntax_error') self.assertFileFound(filename)
dirname = tempfile.mkdtemp() filename = os.path.join(dirname, 'test_syntax_error.py') self.addCleanup(shutil.rmtree, dirname) with open(filename, 'w') as f: f.write("Ceci n'est pas du Python.") with extend_sys_path(dirname): with self.assertRaises(SyntaxError): autoreload.check_errors(import_module)('test_syntax_error') self.assertFileFoundOnlyNew(filename)
error_msg = "This is an exception, voil" exc = ValueError(error_msg) result = force_bytes(exc) self.assertEqual(result, error_msg.encode('utf-8'))
self.assertEqual( feedgenerator.get_tag_uri('http://example.org/foo/bar#headline', datetime.date(2004, 10, 25)), 'tag:example.org,2004-10-25:/foo/bar/headline')
self.assertEqual( feedgenerator.get_tag_uri( 'http://www.example.org:8000/2008/11/14/django#headline', datetime.datetime(2008, 11, 14, 13, 37, 0), ), 'tag:www.example.org,2008-11-14:/2008/11/14/django/headline')
self.assertEqual( feedgenerator.rfc2822_date(datetime.datetime(2008, 11, 14, 13, 37, 0)), "Fri, 14 Nov 2008 13:37:00 -0000" )
self.assertEqual( feedgenerator.rfc2822_date(datetime.datetime(2008, 11, 14, 13, 37, 0, tzinfo=get_fixed_timezone(60))), "Fri, 14 Nov 2008 13:37:00 +0100" )
self.assertEqual( feedgenerator.rfc2822_date(datetime.date(2008, 11, 14)), "Fri, 14 Nov 2008 00:00:00 -0000" )
self.assertEqual( feedgenerator.rfc3339_date(datetime.datetime(2008, 11, 14, 13, 37, 0)), "2008-11-14T13:37:00Z" )
self.assertEqual( feedgenerator.rfc3339_date(datetime.datetime(2008, 11, 14, 13, 37, 0, tzinfo=get_fixed_timezone(120))), "2008-11-14T13:37:00+02:00" )
self.assertEqual( feedgenerator.rfc3339_date(datetime.date(2008, 11, 14)), "2008-11-14T00:00:00Z" )
atom_feed = feedgenerator.Atom1Feed("title", "link", "description") self.assertEqual( atom_feed.content_type, "application/atom+xml; charset=utf-8" )
def setUp(self): super(CustomLoader, self).setUp() sys.path_hooks.insert(0, TestFinder) sys.path_importer_cache.clear() def tearDown(self): super(CustomLoader, self).tearDown() sys.path_hooks.pop(0)
foo = 'bar' def __eq__(self, other): return self.foo == other.foo
class AdHocLazyObject(LazyObject): def _setup(self): self._wrapped = wrapped_object return AdHocLazyObject()
def __init__(self): self.baz = 'wrong' def __reduce__(self): self.baz = 'right' return super(BaseBaz, self).__reduce__() def __eq__(self, other): if self.__class__ != other.__class__: return False for attr in ['bar', 'baz', 'quux']: if hasattr(self, attr) != hasattr(other, attr): return False elif getattr(self, attr, None) != getattr(other, attr, None): return False return True
def __init__(self, bar): self.bar = bar super(Baz, self).__init__() def __reduce_ex__(self, proto): self.quux = 'quux' return super(Baz, self).__reduce_ex__(proto)
def __init__(self, baz): self.__dict__ = baz.__dict__ self._baz = baz super(BaseBaz, self).__init__()
class Base(object): def base_method(self): pass class Klazz(Base): pass t = lazy(lambda: Klazz(), Klazz)() self.assertIn('base_method', dir(t))
class Base(object): def method(self): return 'Base' class Klazz(Base): def method(self): return 'Klazz' t = lazy(lambda: Klazz(), Base)() self.assertEqual(t.method(), 'Klazz')
return 1, object()
self.assertEqual(timesince(self.t, self.t + self.onemicrosecond), '0\xa0minutes') self.assertEqual(timesince(self.t, self.t + self.onesecond), '0\xa0minutes')
self.assertEqual(timesince(self.t, self.t + self.oneminute), '1\xa0minute') self.assertEqual(timesince(self.t, self.t + self.onehour), '1\xa0hour') self.assertEqual(timesince(self.t, self.t + self.oneday), '1\xa0day') self.assertEqual(timesince(self.t, self.t + self.oneweek), '1\xa0week') self.assertEqual(timesince(self.t, self.t + self.onemonth), '1\xa0month') self.assertEqual(timesince(self.t, self.t + self.oneyear), '1\xa0year')
self.assertEqual(timesince(self.t, self.t + 2 * self.oneday + 6 * self.onehour), '2\xa0days, 6\xa0hours') self.assertEqual(timesince(self.t, self.t + 2 * self.oneweek + 2 * self.oneday), '2\xa0weeks, 2\xa0days')
self.assertEqual( timesince(self.t, self.t + 2 * self.oneweek + 3 * self.onehour + 4 * self.oneminute), '2\xa0weeks' ) self.assertEqual(timesince(self.t, self.t + 4 * self.oneday + 5 * self.oneminute), '4\xa0days')
self.assertEqual(timesince(self.t, self.t - self.onemicrosecond), '0\xa0minutes') self.assertEqual(timesince(self.t, self.t - self.onesecond), '0\xa0minutes') self.assertEqual(timesince(self.t, self.t - self.oneminute), '0\xa0minutes') self.assertEqual(timesince(self.t, self.t - self.onehour), '0\xa0minutes') self.assertEqual(timesince(self.t, self.t - self.oneday), '0\xa0minutes') self.assertEqual(timesince(self.t, self.t - self.oneweek), '0\xa0minutes') self.assertEqual(timesince(self.t, self.t - self.onemonth), '0\xa0minutes') self.assertEqual(timesince(self.t, self.t - self.oneyear), '0\xa0minutes') self.assertEqual(timesince(self.t, self.t - 2 * self.oneday - 6 * self.onehour), '0\xa0minutes') self.assertEqual(timesince(self.t, self.t - 2 * self.oneweek - 2 * self.oneday), '0\xa0minutes') self.assertEqual( timesince(self.t, self.t - 2 * self.oneweek - 3 * self.onehour - 4 * self.oneminute), '0\xa0minutes' ) self.assertEqual(timesince(self.t, self.t - 4 * self.oneday - 5 * self.oneminute), '0\xa0minutes')
now = datetime.datetime.now() now_tz = timezone.make_aware(now, timezone.get_default_timezone()) now_tz_i = timezone.localtime(now_tz, timezone.get_fixed_timezone(195)) self.assertEqual(timesince(now), '0\xa0minutes') self.assertEqual(timesince(now_tz), '0\xa0minutes') self.assertEqual(timesince(now_tz_i), '0\xa0minutes') self.assertEqual(timesince(now_tz, now_tz_i), '0\xa0minutes') self.assertEqual(timeuntil(now), '0\xa0minutes') self.assertEqual(timeuntil(now_tz), '0\xa0minutes') self.assertEqual(timeuntil(now_tz_i), '0\xa0minutes') self.assertEqual(timeuntil(now_tz, now_tz_i), '0\xa0minutes')
today = datetime.date.today() self.assertEqual(timesince(today + self.oneday), '0\xa0minutes') self.assertEqual(timeuntil(today - self.oneday), '0\xa0minutes')
today = datetime.date.today() self.assertEqual(timeuntil(today + self.oneday, today), '1\xa0day') self.assertEqual(timeuntil(today - self.oneday, today), '0\xa0minutes') self.assertEqual(timeuntil(today + self.oneweek, today), '1\xa0week')
if output is None: output = value self.assertEqual(function(value), output)
def __format__(self, specifier, **kwargs): amount = super(EuroDecimal, self).__format__(specifier, **kwargs) return ' {}'.format(amount)
normalized = text.normalize_newlines(b"abc\ndef\rghi\r\n") self.assertEqual(normalized, "abc\ndef\nghi\n") self.assertIsInstance(normalized, six.text_type)
with captured_stdout() as stdout: create_default_site(self.app_config) self.assertEqual(Site.objects.count(), 1) self.assertIn("Creating example.com", stdout.getvalue()) with captured_stdout() as stdout: create_default_site(self.app_config) self.assertEqual(Site.objects.count(), 1) self.assertEqual("", stdout.getvalue())
create_default_site(self.app_config, using='default', verbosity=0) create_default_site(self.app_config, using='other', verbosity=0) self.assertFalse(Site.objects.using('default').exists()) self.assertTrue(Site.objects.using('other').exists())
create_default_site(self.app_config, verbosity=0) Site(domain='example2.com', name='example2.com').save()
post_migrate.send(sender=self.app_config, app_config=self.app_config, verbosity=0) self.assertTrue(Site.objects.exists())
del settings.SITE_ID create_default_site(self.app_config, verbosity=0) self.assertEqual(Site.objects.get().pk, 1)
apps = Apps() create_default_site(self.app_config, verbosity=0, apps=apps) self.assertFalse(Site.objects.exists())
class ExcludedFields1(admin.ModelAdmin): exclude = 'foo' errors = ExcludedFields1(Book, AdminSite()).check() expected = [ checks.Error( "The value of 'exclude' must be a list or tuple.", obj=ExcludedFields1, id='admin.E014', ) ] self.assertEqual(errors, expected)
class SongInline(admin.StackedInline): model = Song exclude = ['album'] class AlbumAdmin(admin.ModelAdmin): model = Album inlines = [SongInline] errors = AlbumAdmin(Album, AdminSite()).check() expected = [ checks.Error( "Cannot exclude the field 'album', because it is the foreign key " "to the parent model 'admin_checks.Album'.", obj=SongInline, id='admin.E201', ) ] self.assertEqual(errors, expected)
class InfluenceInline(GenericStackedInline): model = Influence class SongAdmin(admin.ModelAdmin): inlines = [InfluenceInline] errors = SongAdmin(Song, AdminSite()).check() self.assertEqual(errors, [])
class BookInline(GenericStackedInline): model = Book class SongAdmin(admin.ModelAdmin): inlines = [BookInline] errors = SongAdmin(Song, AdminSite()).check() expected = [ checks.Error( "'admin_checks.Book' has no GenericForeignKey.", obj=BookInline, id='admin.E301', ) ] self.assertEqual(errors, expected)
class InfluenceInline(GenericStackedInline): model = Influence ct_field = 'name' class SongAdmin(admin.ModelAdmin): inlines = [InfluenceInline] errors = SongAdmin(Song, AdminSite()).check() expected = [ checks.Error( "'admin_checks.Influence' has no GenericForeignKey using " "content type field 'name' and object ID field 'object_id'.", obj=InfluenceInline, id='admin.E304', ) ] self.assertEqual(errors, expected)
class InfluenceInline(GenericStackedInline): model = Influence ct_fk_field = 'name' class SongAdmin(admin.ModelAdmin): inlines = [InfluenceInline] errors = SongAdmin(Song, AdminSite()).check() expected = [ checks.Error( "'admin_checks.Influence' has no GenericForeignKey using " "content type field 'content_type' and object ID field 'name'.", obj=InfluenceInline, id='admin.E304', ) ] self.assertEqual(errors, expected)
class RawIdNonexistingAdmin(admin.ModelAdmin): raw_id_fields = ('nonexisting',) errors = RawIdNonexistingAdmin(Album, AdminSite()).check() expected = [ checks.Error( "The value of 'raw_id_fields[0]' refers to 'nonexisting', " "which is not an attribute of 'admin_checks.Album'.", obj=RawIdNonexistingAdmin, id='admin.E002', ) ] self.assertEqual(errors, expected)
class TwoAlbumFKAndAnEInline(admin.TabularInline): model = TwoAlbumFKAndAnE exclude = ("e",) fk_name = "album1" class MyAdmin(admin.ModelAdmin): inlines = [TwoAlbumFKAndAnEInline] errors = MyAdmin(Album, AdminSite()).check() self.assertEqual(errors, [])
class BookAdmin(admin.ModelAdmin): fields = ['authors'] errors = BookAdmin(Book, AdminSite()).check() expected = [ checks.Error( "The value of 'fields' cannot include the many-to-many field 'authors' " "because that field manually specifies a relationship model.", obj=BookAdmin, id='admin.E013', ) ] self.assertEqual(errors, expected)
class AuthorsInline(admin.TabularInline): model = Book.authors.through class BookAdmin(admin.ModelAdmin): inlines = [AuthorsInline] errors = BookAdmin(Book, AdminSite()).check() self.assertEqual(errors, [])
class SongForm(forms.ModelForm): extra_data = forms.CharField() class FieldsOnFormOnlyAdmin(admin.ModelAdmin): form = SongForm fields = ['title', 'extra_data'] errors = FieldsOnFormOnlyAdmin(Song, AdminSite()).check() self.assertEqual(errors, [])
class SongForm(forms.ModelForm): extra_data = forms.CharField() class Meta: model = Song fields = '__all__' class FieldsOnFormOnlyAdmin(admin.ModelAdmin): form = SongForm fields = ['extra_data', 'title'] errors = FieldsOnFormOnlyAdmin(Song, AdminSite()).check() self.assertEqual(errors, [])
response = self.client.trace('/trace_view/') self.assertEqual(response.status_code, 200) self.assertEqual(response.context['method'], 'TRACE') self.assertEqual(response.templates[0].name, 'TRACE Template')
response = self.client.get("/header_view/") self.assertTrue(hasattr(response, 'request')) self.assertTrue(hasattr(response, 'wsgi_request')) for key, value in response.request.items(): self.assertIn(key, response.wsgi_request.environ) self.assertEqual(response.wsgi_request.environ[key], value)
response = self.client.get('/header_view/') self.assertTrue(hasattr(response, 'resolver_match'))
response = self.client.get('/redirect_view/', follow=True) self.assertEqual(response.resolver_match.url_name, 'get_view')
response = self.client.get('/get_view/') self.assertEqual(response.resolver_match.url_name, 'get_view')
response = self.client.post("/raw_post_view/", test_doc, content_type="text/xml") self.assertEqual(response.status_code, 200) self.assertEqual(response.templates[0].name, "Book template") self.assertEqual(response.content, b"Blink - Malcolm Gladwell")
credentials = {'username': 'inactive', 'password': 'password'} self.assertFalse(self.client.login(**credentials)) with self.settings(AUTHENTICATION_BACKENDS=['django.contrib.auth.backends.AllowAllUsersModelBackend']): self.assertTrue(self.client.login(**credentials))
with self.assertRaisesMessage(Exception, 'exception message'): self.client.get('/nesting_exception_view/')
self.assertEqual(hasattr(self.client, "i_am_customized"), True)
for method_name, view in self.http_methods_and_views: method = getattr(self.request_factory, method_name) request = method('/somewhere/') response = view(request) self.assertEqual(response.status_code, 200)
request = self.request_factory.get('/somewhere/') response = get_view(request) self.assertContains(response, 'This is a test')
if request.method.upper() != "TRACE": return HttpResponseNotAllowed("TRACE") elif request.body: return HttpResponseBadRequest("TRACE requests MUST NOT include an entity") else: protocol = request.META["SERVER_PROTOCOL"] t = Template( '{{ method }} {{ uri }} {{ version }}', name="TRACE Template", ) c = Context({ 'method': request.method, 'uri': request.path, 'version': protocol, }) return HttpResponse(t.render(c))
if request.method == 'POST': if request.POST: t = Template('Data received: {{ data }} is the value.', name='POST Template') c = Context({'data': request.POST['value']}) else: t = Template('Viewing POST page.', name='Empty POST Template') c = Context() else: t = Template('Viewing GET page.', name='Empty GET Template') c = Context() return HttpResponse(t.render(c))
raise KeyError("Oops! Looks like you wrote some bad code.")
client = Client() client.get('/get_view/') raise Exception('exception message')
with self.assertRaises(CommandError): management.call_command(('explode',))
current_path = os.environ.pop('PATH', None) try: self.assertIsNone(find_command('_missing_')) finally: if current_path is not None: os.environ['PATH'] = current_path
egg_dir = '%s/eggs' % os.path.dirname(upath(__file__)) egg_name = '%s/basic.egg' % egg_dir with extend_sys_path(egg_name): with self.settings(INSTALLED_APPS=['commandegg']): cmds = find_commands(os.path.join(apps.get_app_config('commandegg').path, 'management')) self.assertEqual(cmds, ['eggcommand'])
out = StringIO() management.call_command('dance', stdout=out, opt_3=True) self.assertIn("option3", out.getvalue()) self.assertNotIn("opt_3", out.getvalue()) self.assertNotIn("opt-3", out.getvalue())
out = StringIO() management.call_command('dance', 1, verbosity=0, stdout=out) self.assertIn("You passed 1 as a positional argument.", out.getvalue())
self.counter = 0 def patched_check(self_, **kwargs): self.counter = self.counter + 1 saved_check = BaseCommand.check BaseCommand.check = patched_check try: management.call_command("dance", verbosity=0) self.assertEqual(self.counter, 0) management.call_command("dance", verbosity=0, skip_checks=False) self.assertEqual(self.counter, 1) finally: BaseCommand.check = saved_check
def tearDown(self): self.remove_settings('settings.py') def test_script_prefix_set_in_commands(self): self.write_settings('settings.py', apps=['user_commands'], sdict={ 'ROOT_URLCONF': '"user_commands.urls"', 'FORCE_SCRIPT_NAME': '"/PREFIX/"', }) out, err = self.run_manage(['reverse_url']) self.assertNoOutput(err) self.assertEqual(out.strip(), '/PREFIX/some/url/')
def handle(self, *args, **options): return reverse('some_url')
from __future__ import unicode_literals from django.db import models from django.utils.encoding import python_2_unicode_compatible @python_2_unicode_compatible class Reporter(models.Model): first_name = models.CharField(max_length=30) last_name = models.CharField(max_length=30) email = models.EmailField() class Meta: ordering = ('first_name', 'last_name') def __str__(self): return ("%s %s" % (self.first_name, self.last_name)).strip()
def setUp(self): self.atomic = transaction.atomic() self.atomic.__enter__() def tearDown(self): self.atomic.__exit__(*sys.exc_info())
from django.conf.project_template.project_name.settings import MIDDLEWARE with self.settings( MIDDLEWARE=MIDDLEWARE, ROOT_URLCONF='project_template.urls', ): response = self.client.get('/empty/') headers = sorted(response.serialize_headers().split(b'\r\n')) self.assertEqual(headers, [ b'Content-Type: text/html; charset=utf-8', b'X-Frame-Options: SAMEORIGIN', ])
class CallableView(object): def __call__(self, *args, **kwargs): pass login_required(CallableView())
def normal_view(request): pass login_required(normal_view)
if login_url is None: login_url = settings.LOGIN_URL response = self.client.get(view_url) self.assertEqual(response.status_code, 302) self.assertIn(login_url, response.url) self.login() response = self.client.get(view_url) self.assertEqual(response.status_code, 200)
self.testLoginRequired(view_url='/login_required_login_url/', login_url='/somewhere/')
class AView(LoginRequiredMixin, EmptyResponseView): pass view = AView.as_view() request = self.factory.get('/rand') request.user = AnonymousUser() response = view(request) self.assertEqual(response.status_code, 302) self.assertEqual('/accounts/login/?next=/rand', response.url) request = self.factory.get('/rand') request.user = self.user response = view(request) self.assertEqual(response.status_code, 200)
user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw') p0 = PasswordResetTokenGenerator() tk1 = p0.make_token(user) self.assertTrue(p0.check_token(user, tk1))
num_users = User.objects.count() response = self.client.get('/remote_user/') self.assertTrue(response.context['user'].is_anonymous) self.assertEqual(User.objects.count(), num_users) response = self.client.get('/remote_user/', **{self.header: None}) self.assertTrue(response.context['user'].is_anonymous) self.assertEqual(User.objects.count(), num_users) response = self.client.get('/remote_user/', **{self.header: ''}) self.assertTrue(response.context['user'].is_anonymous) self.assertEqual(User.objects.count(), num_users)
create_unknown_user = False
backend = 'auth_tests.test_remote_user.RemoteUserNoCreateBackend' def test_unknown_user(self): num_users = User.objects.count() response = self.client.get('/remote_user/', **{self.header: 'newuser'}) self.assertTrue(response.context['user'].is_anonymous) self.assertEqual(User.objects.count(), num_users)
backend = 'django.contrib.auth.backends.AllowAllUsersRemoteUserBackend' def test_inactive_user(self): user = User.objects.create(username='knownuser', is_active=False) response = self.client.get('/remote_user/', **{self.header: self.known_user}) self.assertEqual(response.context['user'].username, user.username)
return username.split('@')[0]
user.email = 'user@example.com' user.save() return user
super(RemoteUserCustomTest, self).test_known_user() self.assertEqual(User.objects.get(username='knownuser').email, '') self.assertEqual(User.objects.get(username='knownuser2').email, '')
super(RemoteUserCustomTest, self).test_unknown_user() newuser = User.objects.get(username='newuser') self.assertEqual(newuser.email, 'user@example.com')
header = 'HTTP_AUTHUSER'
middleware = ( 'auth_tests.test_remote_user.CustomHeaderMiddleware' ) header = 'HTTP_AUTHUSER'
calls = 0 def encode(self, *args, **kwargs): type(self).calls += 1 return super(CountingMD5PasswordHasher, self).encode(*args, **kwargs)
user = self.UserModel._default_manager.get(pk=self.user.pk) content_type = ContentType.objects.get_for_model(Group) perm = Permission.objects.create(name='test', content_type=content_type, codename='test') user.user_permissions.add(perm) self.assertEqual(user.has_perm('auth.test', 'object'), False) self.assertEqual(user.get_all_permissions('object'), set()) self.assertEqual(user.has_perm('auth.test'), True) self.assertEqual(user.get_all_permissions(), {'auth.test'})
backend = ModelBackend() user = self.UserModel._default_manager.get(pk=self.user.pk) content_type = ContentType.objects.get_for_model(Group) user_perm = Permission.objects.create(name='test', content_type=content_type, codename='test_user') group_perm = Permission.objects.create(name='test2', content_type=content_type, codename='test_group') user.user_permissions.add(user_perm) group = Group.objects.create(name='test_group') user.groups.add(group) group.permissions.add(group_perm) self.assertEqual(backend.get_all_permissions(user), {'auth.test_user', 'auth.test_group'}) self.assertEqual(backend.get_user_permissions(user), {'auth.test_user', 'auth.test_group'}) self.assertEqual(backend.get_group_permissions(user), {'auth.test_group'}) with mock.patch.object(self.UserModel, 'is_anonymous', True): self.assertEqual(backend.get_all_permissions(user), set()) self.assertEqual(backend.get_user_permissions(user), set()) self.assertEqual(backend.get_group_permissions(user), set())
backend = ModelBackend() user = self.UserModel._default_manager.get(pk=self.user.pk) content_type = ContentType.objects.get_for_model(Group) user_perm = Permission.objects.create(name='test', content_type=content_type, codename='test_user') group_perm = Permission.objects.create(name='test2', content_type=content_type, codename='test_group') user.user_permissions.add(user_perm) group = Group.objects.create(name='test_group') user.groups.add(group) group.permissions.add(group_perm) self.assertEqual(backend.get_all_permissions(user), {'auth.test_user', 'auth.test_group'}) self.assertEqual(backend.get_user_permissions(user), {'auth.test_user', 'auth.test_group'}) self.assertEqual(backend.get_group_permissions(user), {'auth.test_group'}) user.is_active = False user.save() self.assertEqual(backend.get_all_permissions(user), set()) self.assertEqual(backend.get_user_permissions(user), set()) self.assertEqual(backend.get_group_permissions(user), set())
user = self.UserModel._default_manager.get(pk=self.superuser.pk) self.assertEqual(len(user.get_all_permissions()), len(Permission.objects.all()))
self.assertEqual(authenticate(**self.user_credentials), self.user) self.user.is_active = False self.user.save() self.assertIsNone(authenticate(**self.user_credentials))
user = CustomUserWithoutIsActiveField.objects._create_user( username='test', email='test@example.com', password='test', ) self.assertEqual(authenticate(username='test', password='test'), user)
UserModel = ExtensionUser def create_users(self): self.user = ExtensionUser._default_manager.create_user( username='test', email='test@example.com', password='test', date_of_birth=date(2006, 4, 25) ) self.superuser = ExtensionUser._default_manager.create_superuser( username='test2', email='test2@example.com', password='test', date_of_birth=date(1976, 11, 8) )
UserModel = CustomPermissionsUser def create_users(self): self.user = CustomPermissionsUser._default_manager.create_user( email='test@example.com', password='test', date_of_birth=date(2006, 4, 25) ) self.superuser = CustomPermissionsUser._default_manager.create_superuser( email='test2@example.com', password='test', date_of_birth=date(1976, 11, 8) )
def test_authenticate(self): test_user = CustomUser._default_manager.create_user( email='test@example.com', password='test', date_of_birth=date(2006, 4, 25) ) authenticated_user = authenticate(email='test@example.com', password='test') self.assertEqual(test_user, authenticated_user)
user = UUIDUser.objects.create_user(username='uuid', password='test') self.assertTrue(self.client.login(username='uuid', password='test')) self.assertEqual(UUIDUser.objects.get(pk=self.client.session[SESSION_KEY]), user)
def setUp(self): self.user1 = AnonymousUser() def test_has_perm(self): self.assertEqual(self.user1.has_perm('perm', TestObj()), False) self.assertEqual(self.user1.has_perm('anon', TestObj()), True) def test_has_perms(self): self.assertEqual(self.user1.has_perms(['anon'], TestObj()), True) self.assertEqual(self.user1.has_perms(['anon', 'perm'], TestObj()), False) def test_has_module_perms(self): self.assertEqual(self.user1.has_module_perms("app1"), True) self.assertEqual(self.user1.has_module_perms("app2"), False) def test_get_all_permissions(self): self.assertEqual(self.user1.get_all_permissions(TestObj()), {'anon'})
def setUp(self): self.user = User.objects.create_user('test', 'test@example.com', 'test') def test_raises_exception(self): with self.assertRaises(ImproperlyConfigured): self.user.has_perm(('perm', TestObj()))
def setUp(self): self.user1 = User.objects.create_user('test', 'test@example.com', 'test') self.user1.is_active = False self.user1.save() def test_has_perm(self): self.assertEqual(self.user1.has_perm('perm', TestObj()), False) self.assertEqual(self.user1.has_perm('inactive', TestObj()), True) def test_has_module_perms(self): self.assertEqual(self.user1.has_module_perms("app1"), False) self.assertEqual(self.user1.has_module_perms("app2"), False)
def authenticate(self, username=None, password=None): raise PermissionDenied def has_perm(self, user_obj, perm, obj=None): raise PermissionDenied def has_module_perms(self, user_obj, app_label): raise PermissionDenied
def authenticate(self, username=None, password=None): raise TypeError
backend = 'auth_tests.test_auth_backends.TypeErrorBackend' def setUp(self): self.user1 = User.objects.create_user('test', 'test@example.com', 'test') @override_settings(AUTHENTICATION_BACKENDS=[backend]) def test_type_error_raised(self): with self.assertRaises(TypeError): authenticate(username='test', password='test')
backend = 'auth_tests.backend_alias.ImportedModelBackend' @override_settings(AUTHENTICATION_BACKENDS=[backend]) def test_backend_path(self): username = 'username' password = 'password' User.objects.create_user(username, 'email', password) self.assertTrue(self.client.login(username=username, password=password)) request = HttpRequest() request.session = self.client.session self.assertEqual(request.session[BACKEND_SESSION_KEY], self.backend)
user_credentials = {'username': 'test', 'password': 'test'} @classmethod def setUpTestData(cls): cls.user = User.objects.create_user( email='test@example.com', is_active=False, **cls.user_credentials ) def test_authenticate(self): self.assertFalse(self.user.is_active) self.assertEqual(authenticate(**self.user_credentials), self.user) def test_get_user(self): self.client.force_login(self.user) request = HttpRequest() request.session = self.client.session user = get_user(request) self.assertEqual(user, self.user)
username = 'jsmith' email = 'jsmith@example.com' user = User.objects.create_user(username, email, 'test123') return (user, username, email)
data = {'email': 'foo@bar.com'} form = PasswordResetForm(data) self.assertTrue(form.is_valid()) self.assertEqual(len(mail.outbox), 0)
user = User.objects.create_user('forms_test2', 'tesT@EXAMple.com', 'test') self.assertEqual(user.email, 'tesT@example.com') user = User.objects.create_user('forms_test3', 'tesT', 'test') self.assertEqual(user.email, 'tesT')
(user, username, email) = self.create_dummy_user() user.is_active = False user.save() form = PasswordResetForm({'email': email}) self.assertTrue(form.is_valid()) form.save() self.assertEqual(len(mail.outbox), 0)
(user, username, email) = self.create_dummy_user() form = PasswordResetForm({"email": email}) self.assertTrue(form.is_valid()) form.save() self.assertEqual(len(mail.outbox), 1) message = mail.outbox[0].message() self.assertFalse(message.is_multipart()) self.assertEqual(message.get_content_type(), 'text/plain') self.assertEqual(message.get('subject'), 'Custom password reset on example.com') self.assertEqual(len(mail.outbox[0].alternatives), 0) self.assertEqual(message.get_all('to'), [email]) self.assertTrue(re.match(r'^http://example.com/reset/[\w+/-]', message.get_payload()))
(user, username, email) = self.create_dummy_user() form = PasswordResetForm({"email": email}) self.assertTrue(form.is_valid()) form.save(html_email_template_name='registration/html_password_reset_email.html') self.assertEqual(len(mail.outbox), 1) self.assertEqual(len(mail.outbox[0].alternatives), 1) message = mail.outbox[0].message() self.assertEqual(message.get('subject'), 'Custom password reset on example.com') self.assertEqual(len(message.get_payload()), 2) self.assertTrue(message.is_multipart()) self.assertEqual(message.get_payload(0).get_content_type(), 'text/plain') self.assertEqual(message.get_payload(1).get_content_type(), 'text/html') self.assertEqual(message.get_all('to'), [email]) self.assertTrue(re.match(r'^http://example.com/reset/[\w/-]+', message.get_payload(0).get_payload())) self.assertTrue(re.match( r'^<html><a href="http://example.com/reset/[\w/-]+/">Link</a></html>$', message.get_payload(1).get_payload() ))
self.assertFalse(check_password(None, make_password('ltmein')))
username = models.CharField(max_length=30) email = models.EmailField(blank=True) is_staff = models.BooleanField(default=False) is_superuser = models.BooleanField(default=False) USERNAME_FIELD = 'username' REQUIRED_FIELDS = ['email'] objects = UserManager()
from django.contrib.auth.models import AbstractBaseUser, PermissionsMixin from django.db import models from django.utils.encoding import python_2_unicode_compatible from .custom_user import CustomUserManager, RemoveGroupsAndPermissions class CustomPermissionsUserManager(CustomUserManager): def create_superuser(self, email, password, date_of_birth): u = self.create_user(email, password=password, date_of_birth=date_of_birth) u.is_superuser = True u.save(using=self._db) return u with RemoveGroupsAndPermissions(): @python_2_unicode_compatible class CustomPermissionsUser(AbstractBaseUser, PermissionsMixin): email = models.EmailField(verbose_name='email address', max_length=255, unique=True) date_of_birth = models.DateField() custom_objects = CustomPermissionsUserManager() USERNAME_FIELD = 'email' REQUIRED_FIELDS = ['date_of_birth'] def get_full_name(self): return self.email def get_short_name(self): return self.email def __str__(self): return self.email
id = models.UUIDField(default=uuid.uuid4, primary_key=True)
if not email: raise ValueError('Users must have an email address') user = self.model( email=self.normalize_email(email), date_of_birth=date_of_birth, ) user.set_password(password) user.save(using=self._db) return user
def __enter__(self): self._old_au_local_m2m = AbstractUser._meta.local_many_to_many self._old_pm_local_m2m = PermissionsMixin._meta.local_many_to_many groups = models.ManyToManyField(Group, blank=True) groups.contribute_to_class(PermissionsMixin, "groups") user_permissions = models.ManyToManyField(Permission, blank=True) user_permissions.contribute_to_class(PermissionsMixin, "user_permissions") PermissionsMixin._meta.local_many_to_many = [groups, user_permissions] AbstractUser._meta.local_many_to_many = [groups, user_permissions] def __exit__(self, exc_type, exc_value, traceback): AbstractUser._meta.local_many_to_many = self._old_au_local_m2m PermissionsMixin._meta.local_many_to_many = self._old_pm_local_m2m
form_errors = list(itertools.chain(*response.context['form'].errors.values())) self.assertIn(force_text(error), form_errors)
fields = ParseResult._fields for attr, x, y in zip(fields, urlparse(url), urlparse(expected)): if parse_qs and attr == 'query': x, y = QueryDict(x), QueryDict(y) if x and y and x != y: self.fail("%r != %r (%s doesn't match)" % (url, expected, attr))
response = self.client.post( '/password_reset_extra_email_context/', {'email': 'staffmember@example.com'}, ) self.assertEqual(response.status_code, 302) self.assertEqual(len(mail.outbox), 1) self.assertIn('Email email context: "Hello!"', mail.outbox[0].body)
response = self.client.post('/password_reset/html_email_template/', {'email': 'staffmember@example.com'}) self.assertEqual(response.status_code, 302) self.assertEqual(len(mail.outbox), 1) message = mail.outbox[0].message() self.assertEqual(len(message.get_payload()), 2) self.assertTrue(message.is_multipart()) self.assertEqual(message.get_payload(0).get_content_type(), 'text/plain') self.assertEqual(message.get_payload(1).get_content_type(), 'text/html') self.assertNotIn('<html>', message.get_payload(0).get_payload()) self.assertIn('<html>', message.get_payload(1).get_payload())
self.login() original_session_key = self.client.session.session_key self.login(username='staff') self.assertNotEqual(original_session_key, self.client.session.session_key)
user = User.objects.get(username='testclient') engine = import_module(settings.SESSION_ENGINE) session = engine.SessionStore() session[SESSION_KEY] = user.id session.save() original_session_key = session.session_key self.client.cookies[settings.SESSION_COOKIE_NAME] = original_session_key self.login() self.assertNotEqual(original_session_key, self.client.session.session_key)
def assertLoginURLEquals(self, url, parse_qs=False): response = self.client.get('/login_required/') self.assertEqual(response.status_code, 302) self.assertURLEqual(response.url, url, parse_qs=parse_qs) @override_settings(LOGIN_URL='/login/') def test_standard_login_url(self): self.assertLoginURLEquals('/login/?next=/login_required/') @override_settings(LOGIN_URL='login') def test_named_login_url(self): self.assertLoginURLEquals('/login/?next=/login_required/') @override_settings(LOGIN_URL='http://remote.example.com/login') def test_remote_login_url(self): quoted_next = urlquote('http://testserver/login_required/') expected = 'http://remote.example.com/login?next=%s' % quoted_next self.assertLoginURLEquals(expected) @override_settings(LOGIN_URL='https:///login/') def test_https_login_url(self): quoted_next = urlquote('http://testserver/login_required/') expected = 'https:///login/?next=%s' % quoted_next self.assertLoginURLEquals(expected) @override_settings(LOGIN_URL='/login/?pretty=1') def test_login_url_with_querystring(self): self.assertLoginURLEquals('/login/?pretty=1&next=/login_required/', parse_qs=True) @override_settings(LOGIN_URL='http://remote.example.com/login/?next=/default/') def test_remote_login_url_with_next_querystring(self): quoted_next = urlquote('http://testserver/login_required/') expected = 'http://remote.example.com/login/?next=%s' % quoted_next self.assertLoginURLEquals(expected) @override_settings(LOGIN_URL=reverse_lazy('login')) def test_lazy_login_url(self): self.assertLoginURLEquals('/login/?next=/login_required/')
def assertLoginRedirectURLEqual(self, url): response = self.login() self.assertEqual(response.status_code, 302) self.assertURLEqual(response.url, url) def test_default(self): self.assertLoginRedirectURLEqual('/accounts/profile/') @override_settings(LOGIN_REDIRECT_URL='/custom/') def test_custom(self): self.assertLoginRedirectURLEqual('/custom/') @override_settings(LOGIN_REDIRECT_URL='password_reset') def test_named(self): self.assertLoginRedirectURLEqual('/password_reset/') @override_settings(LOGIN_REDIRECT_URL='http://remote.example.com/welcome/') def test_remote(self): self.assertLoginRedirectURLEqual('http://remote.example.com/welcome/')
@override_settings(LOGIN_URL=reverse_lazy('login')) def test_redirect_to_login_with_lazy(self): login_redirect_response = redirect_to_login(next='/else/where/') expected = '/login/?next=/else/where/' self.assertEqual(expected, login_redirect_response.url) @override_settings(LOGIN_URL=reverse_lazy('login')) def test_redirect_to_login_with_lazy_and_unicode(self): login_redirect_response = redirect_to_login(next='/else/where//') expected = '/login/?next=/else/where/%E0%A4%9D/' self.assertEqual(expected, login_redirect_response.url)
self.login() response = self.client.get(self.dont_redirect_url) self.assertEqual(response.status_code, 200)
response = self.client.get(self.do_redirect_url) self.assertEqual(response.status_code, 200)
self.login() response = self.client.get(self.do_redirect_url) self.assertRedirects(response, '/accounts/profile/', fetch_redirect_response=False)
self.login() response = self.client.get(self.do_redirect_url) self.assertRedirects(response, '/custom/', fetch_redirect_response=False)
self.login() url = self.do_redirect_url + '?next=/custom_next/' response = self.client.get(url) self.assertRedirects(response, '/custom_next/', fetch_redirect_response=False)
self.login() msg = ( "Redirection loop for authenticated user detected. Check that " "your LOGIN_REDIRECT_URL doesn't point to a login page" ) with self.settings(LOGIN_REDIRECT_URL=self.do_redirect_url): with self.assertRaisesMessage(ValueError, msg): self.client.get(self.do_redirect_url) url = self.do_redirect_url + '?bla=2' with self.assertRaisesMessage(ValueError, msg): self.client.get(url)
response = self.client.get('/logout/') self.assertIn('no-store', response['Cache-Control'])
def isatty(self): return True
with self.assertRaises(CommandError): call_command('changepassword', username='joe', stdout=self.stdout, stderr=self.stderr)
abort_msg = "Aborting password change for user 'joe' after 3 attempts" with self.assertRaisesMessage(CommandError, abort_msg): call_command('changepassword', username='joe', stdout=self.stdout, stderr=self.stderr) self.assertIn('This password is entirely numeric.', self.stderr.getvalue())
user = User.objects.db_manager('other').create_user(username='joe', password='qwerty') self.assertTrue(user.check_password('qwerty')) out = six.StringIO() call_command('changepassword', username='joe', database='other', stdout=out) command_output = out.getvalue().strip() self.assertEqual( command_output, "Changing password for user 'joe'\nPassword changed successfully for user 'joe'" ) self.assertTrue(User.objects.using('other').get(username="joe").check_password('not qwerty'))
def isatty(self): return False
sentinel = object() command = createsuperuser.Command() call_command( command, stdin=sentinel, stdout=six.StringIO(), stderr=six.StringIO(), interactive=False, verbosity=0, username='janet', email='janet@example.com', ) self.assertIs(command.stdin, sentinel) command = createsuperuser.Command() call_command( command, stdout=six.StringIO(), stderr=six.StringIO(), interactive=False, verbosity=0, username='joe', email='joe@example.com', ) self.assertIs(command.stdin, sys.stdin)
new_io = six.StringIO() call_command( 'createsuperuser', interactive=False, username='joe', email='joe@somewhere.org', database='other', stdout=new_io, ) command_output = new_io.getvalue().strip() self.assertEqual(command_output, 'Superuser created successfully.') user = User.objects.using('other').get(username='joe') self.assertEqual(user.email, 'joe@somewhere.org')
user = User.objects.create_user(username='user', password='foo') user.set_password('bar') with mock.patch('django.contrib.auth.password_validation.password_changed') as pw_changed: user.save() self.assertEqual(pw_changed.call_count, 1) user.save() self.assertEqual(pw_changed.call_count, 1)
def post_save_listener(self, *args, **kwargs): self.signals_count += 1 def setUp(self): self.signals_count = 0 post_save.connect(self.post_save_listener, sender=User) def tearDown(self): post_save.disconnect(self.post_save_listener, sender=User) def test_create_user(self): User.objects.create_user("JohnDoe") self.assertEqual(self.signals_count, 1) def test_create_superuser(self): User.objects.create_superuser("JohnDoe", "mail@example.com", "1") self.assertEqual(self.signals_count, 1)
def __init__(self): self.eq_calls = 0 def __eq__(self, other): if self.eq_calls > 0: return True self.eq_calls += 1 return False
pldict = PermLookupDict(MockUser(), 'mockapp') with self.assertRaises(TypeError): self.EQLimiterObject() in pldict
response = self.client.get('/auth_processor_no_attr_access/') self.assertContains(response, "Session not accessed")
response = self.client.get('/auth_processor_attr_access/') self.assertContains(response, "Session accessed")
class CustomUserNonListRequiredFields(AbstractBaseUser): username = models.CharField(max_length=30, unique=True) date_of_birth = models.DateField() USERNAME_FIELD = 'username' REQUIRED_FIELDS = 'date_of_birth' errors = checks.run_checks(app_configs=self.apps.get_app_configs()) self.assertEqual(errors, [ checks.Error( "'REQUIRED_FIELDS' must be a list or tuple.", obj=CustomUserNonListRequiredFields, id='auth.E001', ), ])
class CustomUserBadRequiredFields(AbstractBaseUser): username = models.CharField(max_length=30, unique=True) date_of_birth = models.DateField() USERNAME_FIELD = 'username' REQUIRED_FIELDS = ['username', 'date_of_birth'] errors = checks.run_checks(self.apps.get_app_configs()) self.assertEqual(errors, [ checks.Error( "The field named as the 'USERNAME_FIELD' for a custom user model " "must not be included in 'REQUIRED_FIELDS'.", obj=CustomUserBadRequiredFields, id='auth.E002', ), ])
errors = checks.run_checks() self.assertEqual(errors, [ checks.Error( "'CustomUserNonUniqueUsername.username' must be " "unique because it is named as the 'USERNAME_FIELD'.", obj=CustomUserNonUniqueUsername, id='auth.E003', ), ]) with self.settings(AUTHENTICATION_BACKENDS=['my.custom.backend']): errors = checks.run_checks() self.assertEqual(errors, [ checks.Warning( "'CustomUserNonUniqueUsername.username' is named as " "the 'USERNAME_FIELD', but it is not unique.", hint='Ensure that your authentication backend(s) can handle non-unique usernames.', obj=CustomUserNonUniqueUsername, id='auth.W004', ), ])
class BadUser(AbstractBaseUser): username = models.CharField(max_length=30, unique=True) USERNAME_FIELD = 'username' def is_anonymous(self): return True def is_authenticated(self): return True errors = checks.run_checks(app_configs=self.apps.get_app_configs()) self.assertEqual(errors, [ checks.Critical( '%s.is_anonymous must be an attribute or property rather than ' 'a method. Ignoring this is a security issue as anonymous ' 'users will be treated as authenticated!' % BadUser, obj=BadUser, id='auth.C009', ), checks.Critical( '%s.is_authenticated must be an attribute or property rather ' 'than a method. Ignoring this is a security issue as anonymous ' 'users will be treated as authenticated!' % BadUser, obj=BadUser, id='auth.C010', ), ])
self.logged_in = [] self.logged_out = [] self.login_failed = [] signals.user_logged_in.connect(self.listener_login) signals.user_logged_out.connect(self.listener_logout) signals.user_login_failed.connect(self.listener_login_failed)
signals.user_logged_in.disconnect(self.listener_login) signals.user_logged_out.disconnect(self.listener_logout) signals.user_login_failed.disconnect(self.listener_login_failed)
with connection.cursor() as cursor: cursor.fetchone = mock.Mock( return_value=[ "CREATE TABLE track(id, art_id INTEGER, FOREIGN KEY(art_id) REFERENCES {}(id));".format( Article._meta.db_table ) ] ) relations = connection.introspection.get_relations(cursor, 'mocked_table') self.assertEqual(relations, {'art_id': ('id', Article._meta.db_table)})
with connection.cursor() as cursor: indexes = connection.introspection.get_indexes(cursor, Reporter._meta.db_table) self.assertNotIn('first_name', indexes) self.assertIn('id', indexes)
filter_ = RequireDebugFalse() with self.settings(DEBUG=True): self.assertEqual(filter_.filter("record is not used"), False) with self.settings(DEBUG=False): self.assertEqual(filter_.filter("record is not used"), True)
filter_ = RequireDebugTrue() with self.settings(DEBUG=True): self.assertEqual(filter_.filter("record is not used"), True) with self.settings(DEBUG=False): self.assertEqual(filter_.filter("record is not used"), False)
self.logger.error("Hey, this is an error.") self.assertEqual(self.logger_output.getvalue(), '') with self.settings(DEBUG=True): self.logger.error("Hey, this is an error.") self.assertEqual(self.logger_output.getvalue(), 'Hey, this is an error.\n')
message = 'Message \r\n with newlines' expected_subject = 'ERROR: Message \\r\\n with newlines' self.assertEqual(len(mail.outbox), 0) self.logger.error(message) self.assertEqual(len(mail.outbox), 1) self.assertNotIn('\n', mail.outbox[0].subject) self.assertNotIn('\r', mail.outbox[0].subject) self.assertEqual(mail.outbox[0].subject, expected_subject)
handler = self.get_admin_email_handler(self.logger) record = self.logger.makeRecord('name', logging.ERROR, 'function', 'lno', 'message', None, None) rf = RequestFactory() url_path = '/' record.request = rf.get(url_path) handler.emit(record) self.assertEqual(len(mail.outbox), 1) msg = mail.outbox[0] self.assertEqual(msg.to, ['admin@example.com']) self.assertEqual(msg.subject, "[Django] ERROR (EXTERNAL IP): message") self.assertIn("Report at %s" % url_path, msg.body)
@override_settings(LOGGING_CONFIG='logging_tests.tests.dictConfig', LOGGING=OLD_LOGGING) def test_configure_initializes_logging(self): from django import setup setup() self.assertTrue(dictConfig.called)
self.temp_file = NamedTemporaryFile() self.temp_file.write(logging_conf.encode('utf-8')) self.temp_file.flush() sdict = {'LOGGING_CONFIG': '"logging.config.fileConfig"', 'LOGGING': 'r"%s"' % self.temp_file.name} self.write_settings('settings.py', sdict=sdict) def tearDown(self): self.temp_file.close() self.remove_settings('settings.py') def test_custom_logging(self): out, err = self.run_manage(['check']) self.assertNoOutput(err) self.assertOutput(out, "System check identified no issues (0 silenced).") class SchemaLoggerTests(SimpleTestCase): def test_extra_args(self): editor = connection.schema_editor(collect_sql=True) sql = "SELECT * FROM foo WHERE id in (%s, %s)" params = [42, 1337] with patch_logger('django.db.backends.schema', 'debug', log_kwargs=True) as logger: editor.execute(sql, params) self.assertEqual( logger, [( 'SELECT * FROM foo WHERE id in (%s, %s); (params [42, 1337])', {'extra': { 'sql': 'SELECT * FROM foo WHERE id in (%s, %s)', 'params': [42, 1337], }}, )] )
from __future__ import unicode_literals from django.db import models from django.utils import six from django.utils.encoding import python_2_unicode_compatible class User(models.Model): username = models.CharField(max_length=20) @python_2_unicode_compatible class Issue(models.Model): num = models.IntegerField() cc = models.ManyToManyField(User, blank=True, related_name='test_issue_cc') client = models.ForeignKey(User, models.CASCADE, related_name='test_issue_client') def __str__(self): return six.text_type(self.num) class Meta: ordering = ('num',) class UnicodeReferenceModel(models.Model): others = models.ManyToManyField("UnicodeReferenceModel")
r = Restaurant(serves_pizza=False, serves_hot_dogs=False) r.save() self.assertEqual(r.id, r.place_ptr_id) orig_id = r.id r = Restaurant(place_ptr_id=orig_id, serves_pizza=True, serves_hot_dogs=False) r.save() self.assertEqual(r.id, orig_id) self.assertEqual(r.id, r.place_ptr_id)
wholesalers = list(Wholesaler.objects.all().select_related()) self.assertEqual(wholesalers, [])
obj = SelfRefChild.objects.create(child_data=37, parent_data=42) obj.delete()
c1 = ArticleWithAuthor( headline='ArticleWithAuthor 1', author="Person 1", pub_date=datetime.datetime(2005, 8, 1, 3, 0)) c1.save() c2 = ArticleWithAuthor( headline='ArticleWithAuthor 2', author="Person 2", pub_date=datetime.datetime(2005, 8, 1, 10, 0)) c2.save() c3 = ArticleWithAuthor( headline='ArticleWithAuthor 3', author="Person 3", pub_date=datetime.datetime(2005, 8, 2)) c3.save() self.assertEqual(c1.get_next_by_pub_date(), c2) self.assertEqual(c2.get_next_by_pub_date(), c3) with self.assertRaises(ArticleWithAuthor.DoesNotExist): c3.get_next_by_pub_date() self.assertEqual(c3.get_previous_by_pub_date(), c2) self.assertEqual(c2.get_previous_by_pub_date(), c1) with self.assertRaises(ArticleWithAuthor.DoesNotExist): c1.get_previous_by_pub_date()
article = ArticleWithAuthor.objects.create( author="fred", headline="Hey there!", pub_date=datetime.datetime(2009, 3, 1, 8, 0, 0)) update = ArticleWithAuthor.objects.filter( author="fred").update(headline="Oh, no!") self.assertEqual(update, 1) update = ArticleWithAuthor.objects.filter( pk=article.pk).update(headline="Oh, no!") self.assertEqual(update, 1) derivedm1 = DerivedM.objects.create( customPK=44, base_name="b1", derived_name="d1") self.assertEqual(derivedm1.customPK, 44) self.assertEqual(derivedm1.base_name, 'b1') self.assertEqual(derivedm1.derived_name, 'd1') derivedms = list(DerivedM.objects.all()) self.assertEqual(derivedms, [derivedm1])
class ProfileForm(forms.ModelForm): class Meta: model = Profile fields = '__all__' User.objects.create(username="user_only") p = Profile.objects.create(username="user_with_profile") form = ProfileForm({'username': "user_with_profile", 'extra': "hello"}, instance=p) self.assertTrue(form.is_valid())
request = WSGIRequest({ 'SCRIPT_URL': '/mst/milestones//accounts/login//help', 'PATH_INFO': '/milestones/accounts/login/help', 'REQUEST_METHOD': 'get', 'wsgi.input': BytesIO(b''), }) self.assertEqual(request.path, '/mst/milestones/accounts/login/help') self.assertEqual(request.META['SCRIPT_NAME'], '/mst')
with override_settings(FORCE_SCRIPT_NAME='/FORCED_PREFIX/'): request = WSGIRequest({ 'PATH_INFO': '/somepath/', 'SCRIPT_NAME': '/PREFIX/', 'REQUEST_METHOD': 'get', 'wsgi.input': BytesIO(b''), }) self.assertEqual(request.path, '/FORCED_PREFIX/somepath/')
response = HttpResponse() response.set_cookie('c', 'old-value') self.assertEqual(response.cookies['c']['expires'], '') response.delete_cookie('c') self.assertEqual(response.cookies['c']['expires'], 'Thu, 01-Jan-1970 00:00:00 GMT') response.set_cookie('c', 'new-value') self.assertEqual(response.cookies['c']['expires'], '')
payload = FakePayload('name=value') request = WSGIRequest({'REQUEST_METHOD': 'POST', 'CONTENT_TYPE': 'application/x-www-form-urlencoded', 'CONTENT_LENGTH': len(payload), 'wsgi.input': payload}) self.assertEqual(request.POST, {'name': ['value']}) self.assertEqual(request.body, b'name=value') self.assertEqual(request.read(), b'name=value')
payload = FakePayload('name=value') request = WSGIRequest({'REQUEST_METHOD': 'POST', 'CONTENT_TYPE': 'application/x-www-form-urlencoded', 'CONTENT_LENGTH': len(payload), 'wsgi.input': payload}) self.assertEqual(request.read(2), b'na') with self.assertRaises(RawPostDataException): request.body self.assertEqual(request.POST, {})
payload = FakePayload(original_urlencode({'key': 'Espaa'.encode('latin-1')})) request = WSGIRequest({ 'REQUEST_METHOD': 'POST', 'CONTENT_LENGTH': len(payload), 'CONTENT_TYPE': 'application/x-www-form-urlencoded; charset=iso-8859-1', 'wsgi.input': payload, }) self.assertEqual(request.POST, {'key': ['Espaa']})
class ExplodingBytesIO(BytesIO): def read(self, len=0): raise IOError("kaboom!") payload = b'name=value' request = WSGIRequest({'REQUEST_METHOD': 'POST', 'CONTENT_TYPE': 'application/x-www-form-urlencoded', 'CONTENT_LENGTH': len(payload), 'wsgi.input': ExplodingBytesIO(payload)}) with self.assertRaises(UnreadablePostError): request.body
class ExplodingBytesIO(BytesIO): def read(self, len=0): raise IOError("kaboom!") payload = b'x' request = WSGIRequest({'REQUEST_METHOD': 'POST', 'CONTENT_TYPE': 'multipart/form-data; boundary=foo_', 'CONTENT_LENGTH': len(payload), 'wsgi.input': ExplodingBytesIO(payload)}) with self.assertRaises(UnreadablePostError): request.FILES
with connection.schema_editor() as editor: index_name = editor._create_index_name( model=Article, column_names=("c1", "c2", "c3"), suffix="123", ) self.assertEqual(index_name, "indexes_article_c1_7ce4cc86123")
index_sql = connection.schema_editor()._model_indexes_sql(Article) self.assertEqual(len(index_sql), 1)
def _save(self, name, content): return 'dummy' def delete(self, name): pass def exists(self, name): pass def get_modified_time(self, name): return datetime.datetime(1970, 1, 1, tzinfo=timezone.utc)
def test_find_first(self): src, dst = self.find_first found = self.finder.find(src) self.assertEqual(os.path.normcase(found), os.path.normcase(dst)) def test_find_all(self): src, dst = self.find_all found = self.finder.find(src, all=True) found = [os.path.normcase(f) for f in found] dst = [os.path.normcase(d) for d in dst] self.assertEqual(found, dst)
def setUp(self): super(TestFileSystemFinder, self).setUp() self.finder = finders.FileSystemFinder() test_file_path = os.path.join(TEST_ROOT, 'project', 'documents', 'test', 'file.txt') self.find_first = (os.path.join('test', 'file.txt'), test_file_path) self.find_all = (os.path.join('test', 'file.txt'), [test_file_path])
def setUp(self): super(TestAppDirectoriesFinder, self).setUp() self.finder = finders.AppDirectoriesFinder() test_file_path = os.path.join(TEST_ROOT, 'apps', 'test', 'static', 'test', 'file1.txt') self.find_first = (os.path.join('test', 'file1.txt'), test_file_path) self.find_all = (os.path.join('test', 'file1.txt'), [test_file_path])
def setUp(self): super(TestDefaultStorageFinder, self).setUp() self.finder = finders.DefaultStorageFinder( storage=storage.StaticFilesStorage(location=settings.MEDIA_ROOT)) test_file_path = os.path.join(settings.MEDIA_ROOT, 'media-file.txt') self.find_first = ('media-file.txt', test_file_path) self.find_all = ('media-file.txt', [test_file_path])
with self.assertRaises(ImproperlyConfigured): finders.FileSystemFinder()
def assertFileContains(self, filepath, text): self.assertIn( text, self._get_file(force_text(filepath)), "'%s' not in '%s'" % (text, filepath), ) def assertFileNotFound(self, filepath): with self.assertRaises(IOError): self._get_file(filepath) def render_template(self, template, **kwargs): if isinstance(template, six.string_types): template = Template(template) return template.render(Context(kwargs)).strip() def static_template_snippet(self, path, asvar=False): if asvar: return "{%% load static from staticfiles %%}{%% static '%s' as var %%}{{ var }}" % path return "{%% load static from staticfiles %%}{%% static '%s' %%}" % path def assertStaticRenders(self, path, result, asvar=False, **kwargs): template = self.static_template_snippet(path, asvar) self.assertEqual(self.render_template(template, **kwargs), result) def assertStaticRaises(self, exc, path, result, asvar=False, **kwargs): with self.assertRaises(exc): self.assertStaticRenders(path, result, **kwargs)
self.assertFileContains('test.txt', 'Can we find') self.assertFileContains(os.path.join('prefix', 'test.txt'), 'Prefix')
self.assertFileContains('subdir/test.txt', 'Can we find')
self.assertFileContains('test/file.txt', 'STATICFILES_DIRS')
self.assertFileContains('test/file1.txt', 'file1 in the app dir')
self.assertFileContains('test/.txt', ' in the app dir')
def _response(self, filepath): return self.client.get( posixpath.join(settings.STATIC_URL, filepath)) def assertFileContains(self, filepath, text): self.assertContains(self._response(filepath), text) def assertFileNotFound(self, filepath): self.assertEqual(self._response(filepath).status_code, 404)
def test_disabled_serving(self): self.assertFileNotFound('test.txt')
self.assertEqual(os.listdir(settings.STATIC_ROOT), [])
result = call_command('findstatic', 'test/file.txt', verbosity=0, stdout=six.StringIO()) lines = [l.strip() for l in result.split('\n')] self.assertEqual(len(lines), 2) self.assertIn('project', force_text(lines[0])) self.assertIn('apps', force_text(lines[1]))
self.write_settings('settings.py', apps=['django.contrib.staticfiles']) out, err = self.run_manage(['help', 'collectstatic']) self.assertNoOutput(err)
self.assertFileNotFound('test/test.ignoreme')
self.assertFileNotFound('test/.hidden') self.assertFileNotFound('test/backup~') self.assertFileNotFound('test/CVS')
def run_collectstatic(self, **kwargs): clear_filepath = os.path.join(settings.STATIC_ROOT, 'cleared.txt') with open(clear_filepath, 'w') as f: f.write('should be cleared') super(TestCollectionClear, self).run_collectstatic(clear=True) def test_cleared_not_found(self): self.assertFileNotFound('cleared.txt') def test_dir_not_exists(self, **kwargs): shutil.rmtree(six.text_type(settings.STATIC_ROOT)) super(TestCollectionClear, self).run_collectstatic(clear=True) @override_settings(STATICFILES_STORAGE='staticfiles_tests.storage.PathNotImplementedStorage') def test_handle_path_notimplemented(self): self.run_collectstatic() self.assertFileNotFound('cleared.txt')
self.assertFileContains('test/.hidden', 'should be ignored') self.assertFileContains('test/backup~', 'should be ignored') self.assertFileContains('test/CVS', 'should be ignored')
self.assertFileNotFound('test/nonascii.css') self.assertFileContains('test/.hidden', 'should be ignored')
def run_collectstatic(self): super(TestCollectionDryRun, self).run_collectstatic(dry_run=True)
out = six.StringIO() call_command('collectstatic', interactive=False, verbosity=3, stdout=out, **kwargs) return force_text(out.getvalue())
output = self._collectstatic_output(clear=True) self.assertNotIn(self.warning_string, output)
pass
self.assertTrue(os.path.islink(os.path.join(settings.STATIC_ROOT, 'test.txt')))
path = os.path.join(settings.STATIC_ROOT, 'test.txt') os.unlink(path) self.run_collectstatic() self.assertTrue(os.path.islink(path))
self.assertStaticRaises(ValueError, "does/not/exist.png", "/static/does/not/exist.png") self.assertStaticRenders("test/file.txt", "/static/test/file.dad0999e4f8f.txt") self.assertStaticRenders("test/file.txt", "/static/test/file.dad0999e4f8f.txt", asvar=True) self.assertStaticRenders("cached/styles.css", "/static/cached/styles.bb84a0240107.css") self.assertStaticRenders("path/", "/static/path/") self.assertStaticRenders("path/?query", "/static/path/?query")
relpath = self.hashed_file_path("absolute_root.css") self.assertEqual(relpath, "absolute_root.f864a4d7f083.css") with storage.staticfiles_storage.open(relpath) as relfile: content = relfile.read() self.assertNotIn(b"/static/styles_root.css", content) self.assertIn(b"/static/styles_root.401f2509a628.css", content)
collectstatic_args = { 'interactive': False, 'verbosity': 0, 'link': False, 'clear': False, 'dry_run': False, 'post_process': True, 'use_default_ignore_patterns': True, 'ignore_patterns': ['*.ignoreme'], } collectstatic_cmd = CollectstaticCommand() collectstatic_cmd.set_options(**collectstatic_args) stats = collectstatic_cmd.collect() self.assertIn(os.path.join('cached', 'css', 'window.css'), stats['post_processed']) self.assertIn(os.path.join('cached', 'css', 'img', 'window.png'), stats['unmodified']) self.assertIn(os.path.join('test', 'nonascii.css'), stats['post_processed'])
finders.get_finder.cache_clear() err = six.StringIO() with self.assertRaises(Exception): call_command('collectstatic', interactive=False, verbosity=0, stderr=err) self.assertEqual("Post-processing 'faulty.css' failed!\n\n", err.getvalue())
name = ( "/some crazy/long filename/ with spaces Here and ?#%#$/other/stuff" "/some crazy/long filename/ with spaces Here and ?#%#$/other/stuff" "/some crazy/long filename/ with spaces Here and ?#%#$/other/stuff" "/some crazy/long filename/ with spaces Here and ?#%#$/other/stuff" "/some crazy/long filename/ with spaces Here and ?#%#$/other/stuff" "/some crazy/\x16\xb4" ) cache_key = storage.staticfiles_storage.hash_key(name) cache_validator = BaseCache({}) cache_validator.validate_key(cache_key) self.assertEqual(cache_key, 'staticfiles:821ea71ef36f95b3922a77f7364670e7')
self.assertStaticRaises(ValueError, "does/not/exist.png", "/static/does/not/exist.png") self.assertStaticRenders("test/file.txt", "/static/test/file.deploy12345.txt") self.assertStaticRenders("cached/styles.css", "/static/cached/styles.deploy12345.css") self.assertStaticRenders("path/", "/static/path/") self.assertStaticRenders("path/?query", "/static/path/?query")
def __init__(self, *args, **kwargs): kwargs['file_permissions_mode'] = 0o640 kwargs['directory_permissions_mode'] = 0o740 super(CustomStaticFilesStorage, self).__init__(*args, **kwargs)
def test_get_version(self): expect = '1.0.0' ops = FakePostGISOperations(expect) actual = ops.postgis_lib_version() self.assertEqual(expect, actual) def test_version_classic_tuple(self): expect = ('1.2.3', 1, 2, 3) ops = FakePostGISOperations(expect[0]) actual = ops.postgis_version_tuple() self.assertEqual(expect, actual) def test_version_dev_tuple(self): expect = ('1.2.3dev', 1, 2, 3) ops = FakePostGISOperations(expect[0]) actual = ops.postgis_version_tuple() self.assertEqual(expect, actual) def test_valid_version_numbers(self): versions = [ ('1.3.0', 1, 3, 0), ('2.1.1', 2, 1, 1), ('2.2.0dev', 2, 2, 0), ] for version in versions: ops = FakePostGISOperations(version[0]) actual = ops.spatial_version self.assertEqual(version[1:], actual) def test_invalid_version_numbers(self): versions = ['nope', '123'] for version in versions: ops = FakePostGISOperations(version) with self.assertRaises(Exception): ops.spatial_version def test_no_version_number(self): ops = FakePostGISOperations() with self.assertRaises(ImproperlyConfigured): ops.spatial_version
msg = 'Raster fields require backends with raster support.' with self.assertRaisesMessage(ImproperlyConfigured, msg): self.set_up_test_model(True)
msg = 'Raster fields require backends with raster support.' with self.assertRaisesMessage(ImproperlyConfigured, msg): self.alter_gis_model( migrations.AddField, 'Neighborhood', 'heatmap', False, fields.RasterField )
self.alter_gis_model(migrations.RemoveField, 'Neighborhood', 'rast') self.assertColumnNotExists('gis_neighborhood', 'rast')
cities = City.objects.annotate(points_extent=Extent('location__point')).order_by('name') tol = 4 self.assertAlmostEqual( cities[0].points_extent, (-97.516111, 33.058333, -97.516111, 33.058333), tol )
self._load_interstate_data() for name, line, exp_z in interstate_data: interstate = Interstate3D.objects.get(name=name) interstate_proj = InterstateProj3D.objects.get(name=name) for i in [interstate, interstate_proj]: self.assertTrue(i.line.hasz) self.assertEqual(exp_z, tuple(i.line.z)) self._load_city_data() for name, pnt_data in city_data: city = City3D.objects.get(name=name) z = pnt_data[2] self.assertTrue(city.point.hasz) self.assertEqual(z, city.point.z)
self._load_polygon_data() p3d = Polygon3D.objects.get(name='3D BBox') self.assertTrue(p3d.poly.hasz) self.assertIsInstance(p3d.poly, Polygon) self.assertEqual(p3d.poly.srid, 32140)
self._load_city_data() ztranslations = (5.23, 23, -17) for ztrans in ztranslations: for city in City3D.objects.translate(0, 0, ztrans): self.assertEqual(city_dict[city.name][2] + ztrans, city.translate.z)
def __init__(self, **kwargs): for key, value in kwargs.items(): setattr(self, key, value)
def __init__(self, **kwargs): for key, value in kwargs.items(): setattr(self, key, [TestGeom(**strconvert(kw)) for kw in value])
city_shp = os.path.join(shp_path, 'ch-city', 'ch-city.shp') lm = LayerMapping(City, city_shp, city_mapping) lm.save(silent=True, strict=True) self.assertEqual(City.objects.count(), 1) self.assertEqual(City.objects.all()[0].name, "Zrich")
out = StringIO() call_command( 'inspectdb', table_name_filter=lambda tn: tn == 'inspectapp_allogrfields', stdout=out ) output = out.getvalue() if connection.features.supports_geometry_field_introspection: self.assertIn('geom = models.PolygonField()', output) self.assertIn('point = models.PointField()', output) else: self.assertIn('geom = models.GeometryField(', output) self.assertIn('point = models.GeometryField(', output)
extent1 = City.objects.all().aggregate(Extent('point'))['point__extent'] extent2 = City.objects.all()[:3].aggregate(Extent('point'))['point__extent'] self.assertNotEqual(extent1, extent2)
tex_cities = City.objects.filter( point__within=Country.objects.filter(name='Texas').values('mpoly')).order_by('name') expected = ['Dallas', 'Houston'] if not connection.features.supports_real_shape_operations: expected.append('Oklahoma City') self.assertEqual( list(tex_cities.values_list('name', flat=True)), expected )
all_formats = set(serializers.get_serializer_formats()) public_formats = set(serializers.get_public_serializer_formats()) self.assertIn('geojson', all_formats), self.assertIn('geojson', public_formats)
PennsylvaniaCity.objects.create(name='Mansfield', county='Tioga', point='POINT(-77.071445 41.823881)') geojson = serializers.serialize( 'geojson', PennsylvaniaCity.objects.all(), fields=('county', 'point'), ) geodata = json.loads(geojson) self.assertIn('county', geodata['features'][0]['properties']) self.assertNotIn('founded', geodata['features'][0]['properties']) self.assertNotIn('pk', geodata['features'][0]['properties'])
from django.contrib.gis.maps.google.gmap import GoogleMap google_map = GoogleMap() scripts = google_map.scripts self.assertIn(GOOGLE_MAPS_API_KEY, scripts) self.assertIn("new GMap2", scripts)
from django.contrib.gis.geos import Point from django.contrib.gis.maps.google.gmap import GoogleMap, GMarker center = Point(6.146805, 46.227574) marker = GMarker(center, title='En franais!') google_map = GoogleMap(center=center, zoom=18, markers=[marker]) self.assertIn("En franais", google_map.scripts)
g = GEOSGeometry('POINT (-104.609 38.255)', srid=None) with self.assertRaises(GEOSException): g.transform(2774) g = GEOSGeometry('POINT (-104.609 38.255)', srid=None) with self.assertRaises(GEOSException): g.transform(2774, clone=True) g = GEOSGeometry('POINT (-104.609 38.255)', srid=-1) with self.assertRaises(GEOSException): g.transform(2774) g = GEOSGeometry('POINT (-104.609 38.255)', srid=-1) with self.assertRaises(GEOSException): g.transform(2774, clone=True)
g = GEOSGeometry('POINT (-104.609 38.255)', 4326) with self.assertRaises(GEOSException): g.transform(2774) g = GEOSGeometry('POINT (-104.609 38.255)', 4326) with self.assertRaises(GEOSException): g.transform(2774, clone=True)
point = Point(4.337844, 50.827537, srid=4326) path, args, kwargs = point.deconstruct() self.assertEqual(path, 'django.contrib.gis.geos.point.Point') self.assertEqual(args, (4.337844, 50.827537)) self.assertEqual(kwargs, {'srid': 4326}) ls = LineString(((0, 0), (1, 1))) path, args, kwargs = ls.deconstruct() self.assertEqual(path, 'django.contrib.gis.geos.linestring.LineString') self.assertEqual(args, (((0, 0), (1, 1)),)) self.assertEqual(kwargs, {}) ls2 = LineString([Point(0, 0), Point(1, 1)], srid=4326) path, args, kwargs = ls2.deconstruct() self.assertEqual(path, 'django.contrib.gis.geos.linestring.LineString') self.assertEqual(args, ([Point(0, 0), Point(1, 1)],)) self.assertEqual(kwargs, {'srid': 4326}) ext_coords = ((0, 0), (0, 1), (1, 1), (1, 0), (0, 0)) int_coords = ((0.4, 0.4), (0.4, 0.6), (0.6, 0.6), (0.6, 0.4), (0.4, 0.4)) poly = Polygon(ext_coords, int_coords) path, args, kwargs = poly.deconstruct() self.assertEqual(path, 'django.contrib.gis.geos.polygon.Polygon') self.assertEqual(args, (ext_coords, int_coords)) self.assertEqual(kwargs, {}) lr = LinearRing((0, 0), (0, 1), (1, 1), (0, 0)) path, args, kwargs = lr.deconstruct() self.assertEqual(path, 'django.contrib.gis.geos.linestring.LinearRing') self.assertEqual(args, ((0, 0), (0, 1), (1, 1), (0, 0))) self.assertEqual(kwargs, {}) mp = MultiPoint(Point(0, 0), Point(1, 1)) path, args, kwargs = mp.deconstruct() self.assertEqual(path, 'django.contrib.gis.geos.collections.MultiPoint') self.assertEqual(args, (Point(0, 0), Point(1, 1))) self.assertEqual(kwargs, {}) ls1 = LineString((0, 0), (1, 1)) ls2 = LineString((2, 2), (3, 3)) mls = MultiLineString(ls1, ls2) path, args, kwargs = mls.deconstruct() self.assertEqual(path, 'django.contrib.gis.geos.collections.MultiLineString') self.assertEqual(args, (ls1, ls2)) self.assertEqual(kwargs, {}) p1 = Polygon(((0, 0), (0, 1), (1, 1), (0, 0))) p2 = Polygon(((1, 1), (1, 2), (2, 2), (1, 1))) mp = MultiPolygon(p1, p2) path, args, kwargs = mp.deconstruct() self.assertEqual(path, 'django.contrib.gis.geos.collections.MultiPolygon') self.assertEqual(args, (p1, p2, )) self.assertEqual(kwargs, {}) poly = Polygon(((0, 0), (0, 1), (1, 1), (0, 0))) gc = GeometryCollection(Point(0, 0), MultiPoint(Point(0, 0), Point(1, 1)), poly) path, args, kwargs = gc.deconstruct() self.assertEqual(path, 'django.contrib.gis.geos.collections.GeometryCollection') self.assertEqual(args, (Point(0, 0), MultiPoint(Point(0, 0), Point(1, 1)), poly)) self.assertEqual(kwargs, {})
from django.contrib.gis.geos.libgeos import version_regex versions = [('3.0.0rc4-CAPI-1.3.3', '3.0.0', '1.3.3'), ('3.0.0-CAPI-1.4.1', '3.0.0', '1.4.1'), ('3.4.0dev-CAPI-1.8.0', '3.4.0', '1.8.0'), ('3.4.0dev-CAPI-1.8.0 r0', '3.4.0', '1.8.0')] for v_init, v_geos, v_capi in versions: m = version_regex.match(v_init) self.assertTrue(m, msg="Unable to parse the version string '%s'" % v_init) self.assertEqual(m.group('version'), v_geos) self.assertEqual(m.group('capi_version'), v_capi)
import unittest from django.contrib.gis.measure import A, Area, D, Distance class DistanceTest(unittest.TestCase): "Testing the Distance object" def testInit(self): "Testing initialization from valid units" d = Distance(m=100) self.assertEqual(d.m, 100) d1, d2, d3 = D(m=100), D(meter=100), D(metre=100) for d in (d1, d2, d3): self.assertEqual(d.m, 100) d = D(nm=100) self.assertEqual(d.m, 185200) y1, y2, y3 = D(yd=100), D(yard=100), D(Yard=100) for d in (y1, y2, y3): self.assertEqual(d.yd, 100) mm1, mm2 = D(millimeter=1000), D(MiLLiMeTeR=1000) for d in (mm1, mm2): self.assertEqual(d.m, 1.0) self.assertEqual(d.mm, 1000.0) def testInitInvalid(self): "Testing initialization from invalid units" with self.assertRaises(AttributeError): D(banana=100) def testAccess(self): "Testing access in different units" d = D(m=100) self.assertEqual(d.km, 0.1) self.assertAlmostEqual(d.ft, 328.084, 3) def testAccessInvalid(self): "Testing access in invalid units" d = D(m=100) self.assertFalse(hasattr(d, 'banana')) def testAddition(self): "Test addition & subtraction" d1 = D(m=100) d2 = D(m=200) d3 = d1 + d2 self.assertEqual(d3.m, 300) d3 += d1 self.assertEqual(d3.m, 400) d4 = d1 - d2 self.assertEqual(d4.m, -100) d4 -= d1 self.assertEqual(d4.m, -200) with self.assertRaises(TypeError): d1 + 1 with self.assertRaises(TypeError): d1 - 1 with self.assertRaises(TypeError): d1 += 1 with self.assertRaises(TypeError): d1 -= 1 def testMultiplication(self): "Test multiplication & division" d1 = D(m=100) d3 = d1 * 2 self.assertEqual(d3.m, 200) d3 = 2 * d1 self.assertEqual(d3.m, 200) d3 *= 5 self.assertEqual(d3.m, 1000) d4 = d1 / 2 self.assertEqual(d4.m, 50) d4 /= 5 self.assertEqual(d4.m, 10) d5 = d1 / D(m=2) self.assertEqual(d5, 50) a5 = d1 * D(m=10) self.assertIsInstance(a5, Area) self.assertEqual(a5.sq_m, 100 * 10) with self.assertRaises(TypeError): d1 *= D(m=1) with self.assertRaises(TypeError): d1 /= D(m=1) def testUnitConversions(self): "Testing default units during maths" d1 = D(m=100) d2 = D(km=1) d3 = d1 + d2 self.assertEqual(d3._default_unit, 'm') d4 = d2 + d1 self.assertEqual(d4._default_unit, 'km') d5 = d1 * 2 self.assertEqual(d5._default_unit, 'm') d6 = d1 / 2 self.assertEqual(d6._default_unit, 'm') def testComparisons(self): "Testing comparisons" d1 = D(m=100) d2 = D(km=1) d3 = D(km=0) self.assertGreater(d2, d1) self.assertEqual(d1, d1) self.assertLess(d1, d2) self.assertFalse(d3) def testUnitsStr(self): "Testing conversion to strings" d1 = D(m=100) d2 = D(km=3.5) self.assertEqual(str(d1), '100.0 m') self.assertEqual(str(d2), '3.5 km') self.assertEqual(repr(d1), 'Distance(m=100.0)') self.assertEqual(repr(d2), 'Distance(km=3.5)') def testUnitAttName(self): "Testing the `unit_attname` class method" unit_tuple = [('Yard', 'yd'), ('Nautical Mile', 'nm'), ('German legal metre', 'german_m'), ('Indian yard', 'indian_yd'), ('Chain (Sears)', 'chain_sears'), ('Chain', 'chain')] for nm, att in unit_tuple: self.assertEqual(att, D.unit_attname(nm)) class AreaTest(unittest.TestCase): "Testing the Area object" def testInit(self): "Testing initialization from valid units" a = Area(sq_m=100) self.assertEqual(a.sq_m, 100) a = A(sq_m=100) self.assertEqual(a.sq_m, 100) a = A(sq_mi=100) self.assertEqual(a.sq_m, 258998811.0336) def testInitInvaliA(self): "Testing initialization from invalid units" with self.assertRaises(AttributeError): A(banana=100) def testAccess(self): "Testing access in different units" a = A(sq_m=100) self.assertEqual(a.sq_km, 0.0001) self.assertAlmostEqual(a.sq_ft, 1076.391, 3) def testAccessInvaliA(self): "Testing access in invalid units" a = A(sq_m=100) self.assertFalse(hasattr(a, 'banana')) def testAddition(self): "Test addition & subtraction" a1 = A(sq_m=100) a2 = A(sq_m=200) a3 = a1 + a2 self.assertEqual(a3.sq_m, 300) a3 += a1 self.assertEqual(a3.sq_m, 400) a4 = a1 - a2 self.assertEqual(a4.sq_m, -100) a4 -= a1 self.assertEqual(a4.sq_m, -200) with self.assertRaises(TypeError): a1 + 1 with self.assertRaises(TypeError): a1 - 1 with self.assertRaises(TypeError): a1 += 1 with self.assertRaises(TypeError): a1 -= 1 def testMultiplication(self): "Test multiplication & division" a1 = A(sq_m=100) a3 = a1 * 2 self.assertEqual(a3.sq_m, 200) a3 = 2 * a1 self.assertEqual(a3.sq_m, 200) a3 *= 5 self.assertEqual(a3.sq_m, 1000) a4 = a1 / 2 self.assertEqual(a4.sq_m, 50) a4 /= 5 self.assertEqual(a4.sq_m, 10) with self.assertRaises(TypeError): a1 * A(sq_m=1) with self.assertRaises(TypeError): a1 *= A(sq_m=1) with self.assertRaises(TypeError): a1 / A(sq_m=1) with self.assertRaises(TypeError): a1 /= A(sq_m=1) def testUnitConversions(self): "Testing default units during maths" a1 = A(sq_m=100) a2 = A(sq_km=1) a3 = a1 + a2 self.assertEqual(a3._default_unit, 'sq_m') a4 = a2 + a1 self.assertEqual(a4._default_unit, 'sq_km') a5 = a1 * 2 self.assertEqual(a5._default_unit, 'sq_m') a6 = a1 / 2 self.assertEqual(a6._default_unit, 'sq_m') def testComparisons(self): "Testing comparisons" a1 = A(sq_m=100) a2 = A(sq_km=1) a3 = A(sq_km=0) self.assertGreater(a2, a1) self.assertEqual(a1, a1) self.assertLess(a1, a2) self.assertFalse(a3) def testUnitsStr(self): "Testing conversion to strings" a1 = A(sq_m=100) a2 = A(sq_km=3.5) self.assertEqual(str(a1), '100.0 sq_m') self.assertEqual(str(a2), '3.5 sq_km') self.assertEqual(repr(a1), 'Area(sq_m=100.0)') self.assertEqual(repr(a2), 'Area(sq_km=3.5)') def suite(): s = unittest.TestSuite() s.addTest(unittest.makeSuite(DistanceTest)) s.addTest(unittest.makeSuite(AreaTest)) return s def run(verbosity=2): unittest.TextTestRunner(verbosity=verbosity).run(suite()) if __name__ == "__main__": run()
r = RasterModel.objects.create(rast=None) r.refresh_from_db() self.assertIsNone(r.rast)
self.assertEqual( RasterModel._meta.get_field('rast').verbose_name, 'A Verbose Raster Name' )
if not connection.ops.geography: self.skipTest("This test needs geography support") expected = (-96.8016128540039, 29.7633724212646, -95.3631439208984, 32.782058715820) res = City.objects.filter( name__in=('Houston', 'Dallas') ).aggregate(extent=models.Extent(Cast('point', models.PointField()))) for val, exp in zip(res['extent'], expected): self.assertAlmostEqual(exp, val, 4)
if oracle: ref_dists = [0, 4899.68, 8081.30, 9115.15] else: ref_dists = [0, 4891.20, 8071.64, 9123.95] htown = City.objects.get(name='Houston') qs = Zipcode.objects.annotate(distance=Distance('poly', htown.point)) for z, ref in zip(qs, ref_dists): self.assertAlmostEqual(z.distance.m, ref, 2)
result)
result)
def decorator(test_func): @wraps(test_func) def skip_wrapper(*args, **kwargs): if any(key not in connection.ops.gis_operators for key in gis_lookups): raise unittest.SkipTest( "Database doesn't support all the lookups: %s" % ", ".join(gis_lookups) ) return test_func(*args, **kwargs) return skip_wrapper return decorator
self.assertEqual(9, SouthTexasCity.objects.count()) self.assertEqual(9, SouthTexasCityFt.objects.count()) self.assertEqual(11, AustraliaCity.objects.count()) self.assertEqual(4, SouthTexasZipcode.objects.count()) self.assertEqual(4, CensusZipcode.objects.count()) self.assertEqual(1, Interstate.objects.count()) self.assertEqual(1, SouthTexasInterstate.objects.count())
lagrange = GEOSGeometry('POINT(805066.295722839 4231496.29461335)', 32140) houston = SouthTexasCity.objects.annotate(dist=Distance('point', lagrange)).order_by('id').first() tol = 2 if oracle else 5 self.assertAlmostEqual( houston.dist.m if hasattr(houston.dist, 'm') else houston.dist, 147075.069813, tol )
self.assertTrue(form_instance.is_valid()) rendered = form_instance.as_p() self.assertIn('new MapWidget(options);', rendered) self.assertIn('map_srid: 4326,', rendered) self.assertIn('gis/js/OLMapWidget.js', str(form_instance.media))
self.assertEqual( get_storage_class('django.core.files.storage.FileSystemStorage'), FileSystemStorage)
with six.assertRaisesRegex(self, ImportError, "No module named '?storage'?"): get_storage_class('storage.NonExistingStorage')
with self.assertRaises(ImportError): get_storage_class('django.core.files.storage.NonExistingStorage')
storage = self.storage_class(location='') self.assertEqual(storage.base_location, '') self.assertEqual(storage.location, upath(os.getcwd()))
self.assertFalse(self.storage.exists('storage_test')) f = self.storage.open('storage_test', 'w') f.write('storage contents') f.close() self.assertTrue(self.storage.exists('storage_test')) f = self.storage.open('storage_test', 'r') self.assertEqual(f.read(), 'storage contents') f.close() self.storage.delete('storage_test') self.assertFalse(self.storage.exists('storage_test'))
self.assertFalse(self.storage.exists('test.file')) f = ContentFile('custom contents') f_name = self.storage.save('test.file', f) self.addCleanup(self.storage.delete, f_name) atime = self.storage.get_accessed_time(f_name) self.assertEqual(atime, datetime.fromtimestamp(os.path.getatime(self.storage.path(f_name)))) self.assertLess(timezone.now() - self.storage.get_accessed_time(f_name), timedelta(seconds=2))
self.assertFalse(self.storage.exists('test.file')) f = ContentFile('custom contents') f_name = self.storage.save('test.file', f) self.addCleanup(self.storage.delete, f_name) atime = self.storage.accessed_time(f_name) self.assertEqual(atime, datetime.fromtimestamp(os.path.getatime(self.storage.path(f_name)))) self.assertLess(datetime.now() - self.storage.accessed_time(f_name), timedelta(seconds=2))
self.assertFalse(self.storage.exists('test.file')) f = ContentFile('custom contents') f_name = self.storage.save('test.file', f) self.addCleanup(self.storage.delete, f_name) ctime = self.storage.get_created_time(f_name) self.assertEqual(ctime, datetime.fromtimestamp(os.path.getctime(self.storage.path(f_name)))) self.assertLess(timezone.now() - self.storage.get_created_time(f_name), timedelta(seconds=2))
self.assertFalse(self.storage.exists('test.file')) f = ContentFile('custom contents') f_name = self.storage.save('test.file', f) ctime = self.storage.created_time(f_name) self.addCleanup(self.storage.delete, f_name) self.assertEqual(ctime, datetime.fromtimestamp(os.path.getctime(self.storage.path(f_name)))) self.assertLess(datetime.now() - self.storage.created_time(f_name), timedelta(seconds=2))
self.assertFalse(self.storage.exists('test.file')) f = ContentFile('custom contents') f_name = self.storage.save('test.file', f) self.addCleanup(self.storage.delete, f_name) mtime = self.storage.get_modified_time(f_name) self.assertEqual(mtime, datetime.fromtimestamp(os.path.getmtime(self.storage.path(f_name)))) self.assertLess(timezone.now() - self.storage.get_modified_time(f_name), timedelta(seconds=2))
self.assertFalse(self.storage.exists('test.file')) f = ContentFile('custom contents') f_name = self.storage.save('test.file', f) self.addCleanup(self.storage.delete, f_name) mtime = self.storage.modified_time(f_name) self.assertEqual(mtime, datetime.fromtimestamp(os.path.getmtime(self.storage.path(f_name)))) self.assertLess(datetime.now() - self.storage.modified_time(f_name), timedelta(seconds=2))
self.assertFalse(self.storage.exists('test.file')) f = ContentFile('custom contents') f.name = 'test.file' storage_f_name = self.storage.save(None, f) self.assertEqual(storage_f_name, f.name) self.assertTrue(os.path.exists(os.path.join(self.temp_dir, f.name))) self.storage.delete(storage_f_name)
self.assertFalse(self.storage.exists('path/to')) self.storage.save('path/to/test.file', ContentFile('file saved with path')) self.assertTrue(self.storage.exists('path/to')) with self.storage.open('path/to/test.file') as f: self.assertEqual(f.read(), b'file saved with path') self.assertTrue(os.path.exists( os.path.join(self.temp_dir, 'path', 'to', 'test.file'))) self.storage.delete('path/to/test.file')
self.assertFalse(self.storage.exists('test.file')) f = ContentFile('custom contents') f_name = self.storage.save('test.file', f) self.assertEqual(self.storage.path(f_name), os.path.join(self.temp_dir, f_name)) self.storage.delete(f_name)
self.assertFalse(self.storage.exists('storage_test_1')) self.assertFalse(self.storage.exists('storage_test_2')) self.assertFalse(self.storage.exists('storage_dir_1')) self.storage.save('storage_test_1', ContentFile('custom content')) self.storage.save('storage_test_2', ContentFile('custom content')) os.mkdir(os.path.join(self.temp_dir, 'storage_dir_1')) dirs, files = self.storage.listdir('') self.assertEqual(set(dirs), {'storage_dir_1'}) self.assertEqual(set(files), {'storage_test_1', 'storage_test_2'}) self.storage.delete('storage_test_1') self.storage.delete('storage_test_2') os.rmdir(os.path.join(self.temp_dir, 'storage_dir_1'))
with self.assertRaises(SuspiciousOperation): self.storage.exists('..') with self.assertRaises(SuspiciousOperation): self.storage.exists('/etc/passwd')
f1 = ContentFile('chunks fails') def failing_chunks(): raise IOError f1.chunks = failing_chunks with self.assertRaises(IOError): self.storage.save('error.file', f1)
with self.assertRaises(AssertionError): self.storage.delete('')
storage = self.storage_class( location='explicit_location', base_url='explicit_base_url/', file_permissions_mode=0o666, directory_permissions_mode=0o666, ) defaults_storage = self.storage_class() settings = { 'MEDIA_ROOT': 'overriden_media_root', 'MEDIA_URL': 'overriden_media_url/', 'FILE_UPLOAD_PERMISSIONS': 0o333, 'FILE_UPLOAD_DIRECTORY_PERMISSIONS': 0o333, } with self.settings(**settings): self.assertEqual(storage.base_location, 'explicit_location') self.assertIn('explicit_location', storage.location) self.assertEqual(storage.base_url, 'explicit_base_url/') self.assertEqual(storage.file_permissions_mode, 0o666) self.assertEqual(storage.directory_permissions_mode, 0o666) self.assertEqual(defaults_storage.base_location, settings['MEDIA_ROOT']) self.assertIn(settings['MEDIA_ROOT'], defaults_storage.location) self.assertEqual(defaults_storage.base_url, settings['MEDIA_URL']) self.assertEqual(defaults_storage.file_permissions_mode, settings['FILE_UPLOAD_PERMISSIONS']) self.assertEqual( defaults_storage.directory_permissions_mode, settings['FILE_UPLOAD_DIRECTORY_PERMISSIONS'] )
parts = name.split('.') basename, ext = parts[0], parts[1:] number = 2 while self.exists(name): name = '.'.join([basename, str(number)] + ext) number += 1 return name
output = six.StringIO('content') self.storage.save('tests/stringio', output) self.assertTrue(self.storage.exists('tests/stringio')) with self.storage.open('tests/stringio') as f: self.assertEqual(f.read(), b'content')
self.storage.save('dotted.path/test', ContentFile("1")) self.storage.save('dotted.path/test', ContentFile("2")) files = sorted(os.listdir(os.path.join(self.storage_dir, 'dotted.path'))) self.assertFalse(os.path.exists(os.path.join(self.storage_dir, 'dotted_.path'))) self.assertEqual(files[0], 'test') six.assertRegex(self, files[1], 'test_%s' % FILE_SUFFIX_REGEX)
self.storage.save('dotted.path/.test', ContentFile("1")) self.storage.save('dotted.path/.test', ContentFile("2")) files = sorted(os.listdir(os.path.join(self.storage_dir, 'dotted.path'))) self.assertFalse(os.path.exists(os.path.join(self.storage_dir, 'dotted_.path'))) self.assertEqual(files[0], '.test') six.assertRegex(self, files[1], '.test_%s' % FILE_SUFFIX_REGEX)
self.storage.save('bytes.txt', ContentFile(b"content")) self.storage.save('unicode.txt', ContentFile("espaol"))
return name
return self.prefix + self.get_valid_name(filename)
objs = [Person(name="abcd_%s" % i, person_country=self.usa) for i in range(0, 5)] Person.objects.bulk_create(objs, 10)
a = SlugPage.objects.get(slug='a') self.assertListEqual( [p.slug for p in SlugPage.objects.filter(ascendants=a)], ['a', 'a/a', 'a/b', 'a/b/a'], ) self.assertEqual( [p.slug for p in a.descendants.all()], ['a', 'a/a', 'a/b', 'a/b/a'], ) aba = SlugPage.objects.get(slug='a/b/a') self.assertListEqual( [p.slug for p in SlugPage.objects.filter(descendants__in=[aba])], ['a', 'a/b', 'a/b/a'], ) self.assertListEqual( [p.slug for p in aba.ascendants.all()], ['a', 'a/b', 'a/b/a'], )
@property def foreign_related_fields(self): return tuple(lhs_field for lhs_field, rhs_field in self.field.related_fields) def get_attname(self): return self.name
return self.remote_field
def get_extra_restriction(self, where_class, alias, related_alias): return None
def __set__(self, instance, value): if instance is None: raise AttributeError("%s must be accessed via instance" % self.field.name) setattr(instance, self.cache_name, value) if value is not None and not self.field.remote_field.multiple: setattr(value, self.field.related.get_cache_name(), instance)
requires_unique_target = False def get_extra_restriction(self, where_class, alias, related_alias): return ColConstraint(alias, 'lang', get_language()) def get_extra_descriptor_filter(self, instance): return {'lang': get_language()} def contribute_to_class(self, cls, name): super(ActiveTranslationField, self).contribute_to_class(cls, name) setattr(cls, self.name, ArticleTranslationDescriptor(self))
Season.objects.create(year=2012, gt=None) self.assertQuerysetEqual(Season.objects.filter(gt__regex=r'^$'), [])
Season.objects.create(year=2013, gt=444) self.assertQuerysetEqual(Season.objects.filter(gt__regex=r'^444$'), ['<Season: 2013>'])
Player.objects.create(name='\u2660') Player.objects.get(name__regex='\u2660')
with self.assertRaises(FieldError): Article.objects.filter(headline__blahblah=99) with self.assertRaises(FieldError): Article.objects.filter(headline__blahblah__exact=99) with self.assertRaises(FieldError): Article.objects.filter(blahblah=99)
context = RequestContext(request, processors=[csrf]) template = Template("{% csrf_token %}") return HttpResponse(template.render(context))
context = RequestContext(request, processors=[csrf]) template = Template("") return HttpResponse(template.render(context))
def is_secure(self): return getattr(self, '_is_secure_override', False)
req = self._get_GET_no_csrf_cookie_request() req.COOKIES[settings.CSRF_COOKIE_NAME] = 'x' * 100000 CsrfViewMiddleware().process_view(req, token_view, (), {}) resp = token_view(req) resp2 = CsrfViewMiddleware().process_response(req, resp) csrf_cookie = resp2.cookies.get(settings.CSRF_COOKIE_NAME, False) self.assertEqual(len(csrf_cookie.value), CSRF_TOKEN_LENGTH)
token = ('!@#' + self._csrf_id)[:CSRF_TOKEN_LENGTH] req = self._get_GET_no_csrf_cookie_request() req.COOKIES[settings.CSRF_COOKIE_NAME] = token CsrfViewMiddleware().process_view(req, token_view, (), {}) resp = token_view(req) resp2 = CsrfViewMiddleware().process_response(req, resp) csrf_cookie = resp2.cookies.get(settings.CSRF_COOKIE_NAME, False) self.assertEqual(len(csrf_cookie.value), CSRF_TOKEN_LENGTH) self.assertNotEqual(csrf_cookie.value, token)
req = self._get_POST_no_csrf_cookie_request() req2 = CsrfViewMiddleware().process_view(req, post_form_view, (), {}) self.assertEqual(403, req2.status_code)
req = self._get_POST_csrf_cookie_request() req2 = CsrfViewMiddleware().process_view(req, post_form_view, (), {}) self.assertEqual(403, req2.status_code)
req = self._get_POST_request_with_token() req2 = CsrfViewMiddleware().process_view(req, post_form_view, (), {}) self.assertIsNone(req2)
req = self._get_POST_csrf_cookie_request() req2 = CsrfViewMiddleware().process_view(req, csrf_exempt(post_form_view), (), {}) self.assertIsNone(req2)
req = self._get_POST_csrf_cookie_request() req.META['HTTP_X_CSRFTOKEN'] = self._csrf_id req2 = CsrfViewMiddleware().process_view(req, post_form_view, (), {}) self.assertIsNone(req2)
req = self._get_POST_csrf_cookie_request() req.META['HTTP_X_CSRFTOKEN_CUSTOMIZED'] = self._csrf_id req2 = CsrfViewMiddleware().process_view(req, post_form_view, (), {}) self.assertIsNone(req2)
req = TestingHttpRequest() req.method = 'PUT' req2 = CsrfViewMiddleware().process_view(req, post_form_view, (), {}) self.assertEqual(403, req2.status_code) req = TestingHttpRequest() req.method = 'DELETE' req2 = CsrfViewMiddleware().process_view(req, post_form_view, (), {}) self.assertEqual(403, req2.status_code)
req = self._get_GET_no_csrf_cookie_request() resp = token_view(req) token = get_token(req) self.assertIsNotNone(token) self._check_token_present(resp, token)
req = self._get_GET_no_csrf_cookie_request() req.COOKIES[settings.CSRF_COOKIE_NAME] = b"" CsrfViewMiddleware().process_view(req, token_view, (), {}) resp = token_view(req) token = get_token(req) self.assertIsNotNone(token) self._check_token_present(resp, token)
req = self._get_GET_csrf_cookie_request() CsrfViewMiddleware().process_view(req, token_view, (), {}) resp = token_view(req) self._check_token_present(resp)
req = self._get_GET_csrf_cookie_request() CsrfViewMiddleware().process_view(req, csrf_exempt(token_view), (), {}) resp = token_view(req) self._check_token_present(resp)
req = self._get_GET_csrf_cookie_request() resp = requires_csrf_token(token_view)(req) self._check_token_present(resp)
req = self._get_GET_no_csrf_cookie_request() CsrfViewMiddleware().process_view(req, token_view, (), {}) resp = token_view(req) resp2 = CsrfViewMiddleware().process_response(req, resp) csrf_cookie = resp2.cookies[settings.CSRF_COOKIE_NAME] self._check_token_present(resp, csrf_id=csrf_cookie.value)
req = self._get_POST_request_with_token() CsrfViewMiddleware().process_view(req, token_view, (), {}) resp = token_view(req) resp = CsrfViewMiddleware().process_response(req, resp) csrf_cookie = resp.cookies.get(settings.CSRF_COOKIE_NAME, None) if csrf_cookie: self.assertEqual( csrf_cookie.value, self._csrf_id_cookie, "CSRF cookie was changed on an accepted request" )
req = self._get_POST_bare_secret_csrf_cookie_request_with_token() req2 = CsrfViewMiddleware().process_view(req, token_view, (), {}) self.assertIsNone(req2) resp = token_view(req) resp = CsrfViewMiddleware().process_response(req, resp) self.assertIn(settings.CSRF_COOKIE_NAME, resp.cookies, "Cookie was not reset from bare secret") csrf_cookie = resp.cookies[settings.CSRF_COOKIE_NAME] self.assertEqual(len(csrf_cookie.value), CSRF_TOKEN_LENGTH) self._check_token_present(resp, csrf_id=csrf_cookie.value)
req = self._get_POST_request_with_token() req._is_secure_override = True req.META['HTTP_HOST'] = 'www.example.com' req.META['HTTP_REFERER'] = 'https://www.evil.org/somepage' req.META['SERVER_PORT'] = '443' response = CsrfViewMiddleware().process_view(req, post_form_view, (), {}) self.assertContains( response, 'Referer checking failed - https://www.evil.org/somepage does not ' 'match any trusted origins.', status_code=403, )
req = self._get_POST_request_with_token() req._is_secure_override = True req.META['HTTP_HOST'] = 'www.example.com' req.META['HTTP_REFERER'] = 'https://www.example.com/somepage' req2 = CsrfViewMiddleware().process_view(req, post_form_view, (), {}) self.assertIsNone(req2)
req = self._get_POST_request_with_token() req._is_secure_override = True req.META.update({ 'HTTP_HOST': '10.0.0.2', 'HTTP_REFERER': 'https://www.example.com/somepage', 'SERVER_PORT': '8080', 'HTTP_X_FORWARDED_HOST': 'www.example.com', 'HTTP_X_FORWARDED_PORT': '443', }) req2 = CsrfViewMiddleware().process_view(req, post_form_view, (), {}) self.assertIsNone(req2)
req = self._get_POST_request_with_token() req._is_secure_override = True req.META['HTTP_HOST'] = 'www.example.com' req.META['HTTP_REFERER'] = 'https://dashboard.example.com' req2 = CsrfViewMiddleware().process_view(req, post_form_view, (), {}) self.assertIsNone(req2)
req = self._get_POST_request_with_token() req._is_secure_override = True req.META['HTTP_HOST'] = 'www.example.com' req.META['HTTP_REFERER'] = 'https://dashboard.example.com' response = CsrfViewMiddleware().process_view(req, post_form_view, (), {}) self.assertIsNone(response)
req = self._get_POST_request_with_token() req._is_secure_override = True req.META['HTTP_REFERER'] = 'https://foo.example.com/' req.META['SERVER_PORT'] = '443' response = CsrfViewMiddleware().process_view(req, post_form_view, (), {}) self.assertIsNone(response)
req = self._get_POST_request_with_token() req._is_secure_override = True req.META['HTTP_HOST'] = 'www.example.com' req.META['HTTP_REFERER'] = 'https://foo.example.com:4443/' req.META['SERVER_PORT'] = '4443' response = CsrfViewMiddleware().process_view(req, post_form_view, (), {}) self.assertIsNone(response)
req = self._get_POST_request_with_token() req._is_secure_override = True req.META['HTTP_REFERER'] = 'http://example.com/' req.META['SERVER_PORT'] = '443' response = CsrfViewMiddleware().process_view(req, post_form_view, (), {}) self.assertContains( response, 'Referer checking failed - Referer is insecure while host is secure.', status_code=403, )
def __init__(self, token, raise_error): super(CsrfPostRequest, self).__init__() self.method = 'POST' self.raise_error = False self.COOKIES[settings.CSRF_COOKIE_NAME] = token self.POST['csrfmiddlewaretoken'] = token self.raise_error = raise_error def _load_post_and_files(self): raise IOError('error reading input data') def _get_post(self): if self.raise_error: self._load_post_and_files() return self._post def _set_post(self, post): self._post = post POST = property(_get_post, _set_post)
@skipIfDBFeature("__class__") def test_func(): raise ValueError @skipIfDBFeature("notprovided") def test_func2(): raise ValueError @skipIfDBFeature("__class__", "__class__") def test_func3(): raise ValueError @skipIfDBFeature("__class__", "notprovided") def test_func4(): raise ValueError @skipIfDBFeature("notprovided", "notprovided") def test_func5(): raise ValueError self._assert_skipping(test_func, unittest.SkipTest) self._assert_skipping(test_func2, ValueError) self._assert_skipping(test_func3, unittest.SkipTest) self._assert_skipping(test_func4, unittest.SkipTest) self._assert_skipping(test_func5, ValueError)
batmobile = Car.objects.create(name='Batmobile') k2000 = Car.objects.create(name='K 2000') PossessedCar.objects.bulk_create([ PossessedCar(car=batmobile, belongs_to=self.p1), PossessedCar(car=batmobile, belongs_to=self.p1), PossessedCar(car=k2000, belongs_to=self.p1), PossessedCar(car=k2000, belongs_to=self.p1), PossessedCar(car=k2000, belongs_to=self.p1), PossessedCar(car=k2000, belongs_to=self.p1), ]) with self.assertRaises(AssertionError): self.assertQuerysetEqual( self.p1.cars.all(), [repr(batmobile), repr(k2000)], ordered=False ) self.assertQuerysetEqual( self.p1.cars.all(), [repr(batmobile)] * 2 + [repr(k2000)] * 4, ordered=False )
def func1(): raise ValueError("[.*x+]y?") with self.assertRaisesMessage(ValueError, "[.*x+]y?"): func1()
self.assertEqual(default_storage.base_location, '') with self.settings(MEDIA_ROOT='test_value'): self.assertEqual(default_storage.base_location, 'test_value')
self.assertEqual(default_storage.base_location, '') with self.settings(MEDIA_URL='/test_value/'): self.assertEqual(default_storage.base_url, '/test_value/')
self.assertIsNone(default_storage.file_permissions_mode) with self.settings(FILE_UPLOAD_PERMISSIONS=0o777): self.assertEqual(default_storage.file_permissions_mode, 0o777)
self.assertIsNone(default_storage.directory_permissions_mode) with self.settings(FILE_UPLOAD_DIRECTORY_PERMISSIONS=0o777): self.assertEqual(default_storage.directory_permissions_mode, 0o777)
test_routers = (object(),) with self.settings(DATABASE_ROUTERS=test_routers): self.assertSequenceEqual(router.routers, test_routers)
with self.settings(STATIC_URL='/test/'): self.assertEqual(staticfiles_storage.base_url, '/test/')
with self.settings(STATIC_ROOT='/tmp/test'): self.assertEqual(staticfiles_storage.location, abspathu('/tmp/test'))
new_class = 'CachedStaticFilesStorage' new_storage = 'django.contrib.staticfiles.storage.' + new_class with self.settings(STATICFILES_STORAGE=new_storage): self.assertEqual(staticfiles_storage.__class__.__name__, new_class)
current = get_finders() self.assertGreater(len(list(current)), 1) finders = ['django.contrib.staticfiles.finders.FileSystemFinder'] with self.settings(STATICFILES_FINDERS=finders): self.assertEqual(len(list(get_finders())), len(finders))
finder = get_finder('django.contrib.staticfiles.finders.FileSystemFinder') test_path = '/tmp/test' expected_location = ('', test_path) self.assertNotIn(expected_location, finder.locations) with self.settings(STATICFILES_DIRS=[test_path]): finder = get_finder('django.contrib.staticfiles.finders.FileSystemFinder') self.assertIn(expected_location, finder.locations)
args = ['help', 'test'] out, err = self.run_manage(args) self.assertNoOutput(err)
tested_connections = db.ConnectionHandler({}) with mock.patch('django.test.runner.connections', new=tested_connections): runner_instance = DiscoverRunner(verbosity=0) try: old_config = runner_instance.setup_databases() runner_instance.teardown_databases(old_config) except Exception as e: self.fail("setup_databases/teardown_databases unexpectedly raised " "an error: %s" % e)
tested_connections = db.ConnectionHandler({ 'default': { 'NAME': 'dummy' }, 'aliased': { 'NAME': 'dummy' } }) with mock.patch('django.test.runner.connections', new=tested_connections): runner_instance = DiscoverRunner(verbosity=0) try: old_config = runner_instance.setup_databases() runner_instance.teardown_databases(old_config) except Exception as e: self.fail("setup_databases/teardown_databases unexpectedly raised " "an error: %s" % e)
available_apps = ['test_runner'] reset_sequences = True @skipUnlessDBFeature('supports_sequence_reset') def test_autoincrement_reset1(self): p = Person.objects.create(first_name='Jack', last_name='Smith') self.assertEqual(p.pk, 1) @skipUnlessDBFeature('supports_sequence_reset') def test_autoincrement_reset2(self): p = Person.objects.create(first_name='Jack', last_name='Smith') self.assertEqual(p.pk, 1)
testcases.connections = db.ConnectionHandler({'default': {}}) connection = testcases.connections[db.utils.DEFAULT_DB_ALIAS] self.assertEqual(connection.settings_dict['ENGINE'], 'django.db.backends.dummy') try: connections_support_transactions() except Exception as e: self.fail("connections_support_transactions() unexpectedly raised an error: %s" % e)
with change_cwd("."): suite = DiscoverRunner().build_suite([]) self.assertEqual( suite._tests[0].id().split(".")[0], os.path.basename(os.getcwd()), )
count = DiscoverRunner().build_suite( ["test_discovery_sample.empty"], ).countTestCases() self.assertEqual(count, 0)
base_app = 'gis_tests' sub_app = 'gis_tests.geo3d' with self.modify_settings(INSTALLED_APPS={'append': sub_app}): single = DiscoverRunner().build_suite([base_app]).countTestCases() dups = DiscoverRunner().build_suite([base_app, sub_app]).countTestCases() self.assertEqual(single, dups)
runner = DiscoverRunner(reverse=True) suite = runner.build_suite( test_labels=('test_discovery_sample', 'test_discovery_sample2')) self.assertIn('test_discovery_sample2', next(iter(suite)).id(), msg="Test labels should be reversed.") suite = runner.build_suite(test_labels=('test_discovery_sample2',)) suite = tuple(suite) self.assertIn('DjangoCase', suite[0].id(), msg="Test groups should not be reversed.") self.assertIn('SimpleCase', suite[4].id(), msg="Test groups order should be preserved.") self.assertIn('DjangoCase2', suite[0].id(), msg="Django test cases should be reversed.") self.assertIn('SimpleCase2', suite[4].id(), msg="Simple test cases should be reversed.") self.assertIn('UnittestCase2', suite[8].id(), msg="Unittest test cases should be reversed.") self.assertIn('test_2', suite[0].id(), msg="Methods of Django cases should be reversed.") self.assertIn('test_2', suite[4].id(), msg="Methods of simple cases should be reversed.") self.assertIn('test_2', suite[8].id(), msg="Methods of unittest cases should be reversed.")
p = Publication.objects.create(title="FooBar") site = Site.objects.create(name="example.com") a = Article.objects.create(headline="a foo headline") a.publications.add(p) a.sites.add(site) a = Article.objects.get(id=a.pk) self.assertEqual(a.id, a.pk) self.assertEqual(a.sites.count(), 1)
p = Publication.objects.create(title="FooBar") ad = Advertisement.objects.create(customer="Lawrence Journal-World") ad.publications.add(p) ad = Advertisement.objects.get(id=ad.pk) self.assertEqual(ad.publications.count(), 1)
content_type = models.ForeignKey(ContentType, models.CASCADE) object_id = models.PositiveIntegerField() content_object = GenericForeignKey() url = models.URLField() description = models.CharField(max_length=100, blank=True) keywords = models.CharField(max_length=100, blank=True) def __str__(self): return self.url
response = self.client.get(reverse('admin:generic_inline_admin_episode_add')) self.assertEqual(response.status_code, 200)
response = self.client.get( reverse('admin:generic_inline_admin_episode_change', args=(self.episode_pk,)) ) self.assertEqual(response.status_code, 200)
e = model.objects.create(name='This Week in Django') Media.objects.create(content_object=e, url='http://example.com/podcast.mp3') return e
e = self._create_object(Episode) response = self.client.get(reverse('admin:generic_inline_admin_episode_change', args=(e.pk,))) formset = response.context['inline_admin_formsets'][0].formset self.assertEqual(formset.total_form_count(), 4) self.assertEqual(formset.initial_form_count(), 1)
class ExtraInline(GenericTabularInline): model = Media extra = 0 modeladmin = admin.ModelAdmin(Episode, admin_site) modeladmin.inlines = [ExtraInline] e = self._create_object(Episode) request = self.factory.get(reverse('admin:generic_inline_admin_episode_change', args=(e.pk,))) request.user = User(username='super', is_superuser=True) response = modeladmin.changeform_view(request, object_id=str(e.pk)) formset = response.context_data['inline_admin_formsets'][0].formset self.assertEqual(formset.total_form_count(), 1) self.assertEqual(formset.initial_form_count(), 1)
class MaxNumInline(GenericTabularInline): model = Media extra = 5 max_num = 2 modeladmin = admin.ModelAdmin(Episode, admin_site) modeladmin.inlines = [MaxNumInline] e = self._create_object(Episode) request = self.factory.get(reverse('admin:generic_inline_admin_episode_change', args=(e.pk,))) request.user = User(username='super', is_superuser=True) response = modeladmin.changeform_view(request, object_id=str(e.pk)) formset = response.context_data['inline_admin_formsets'][0].formset self.assertEqual(formset.total_form_count(), 2) self.assertEqual(formset.initial_form_count(), 1)
class MinNumInline(GenericTabularInline): model = Media extra = 3 min_num = 2 modeladmin = admin.ModelAdmin(Episode, admin_site) modeladmin.inlines = [MinNumInline] e = self._create_object(Episode) request = self.factory.get(reverse('admin:generic_inline_admin_episode_change', args=(e.pk,))) request.user = User(username='super', is_superuser=True) response = modeladmin.changeform_view(request, object_id=str(e.pk)) formset = response.context_data['inline_admin_formsets'][0].formset self.assertEqual(formset.total_form_count(), 5) self.assertEqual(formset.initial_form_count(), 1)
class MediaForm(ModelForm): class Meta: model = Media exclude = ['url'] class MediaInline(GenericTabularInline): readonly_fields = ['description'] form = MediaForm model = Media class EpisodeAdmin(admin.ModelAdmin): inlines = [ MediaInline ] ma = EpisodeAdmin(Episode, self.site) self.assertEqual( list(list(ma.get_formsets_with_inlines(request))[0][0]().forms[0].fields), ['keywords', 'id', 'DELETE'])
message = ( "Calling modelformset_factory without defining 'fields' or 'exclude' " "explicitly is prohibited." ) with self.assertRaisesMessage(ImproperlyConfigured, message): modelformset_factory(Author)
message = "fk_name 'title' is not a ForeignKey to 'model_formsets.Author'." with self.assertRaisesMessage(ValueError, message): inlineformset_factory(Author, Book, fields="__all__", fk_name='title')
FormSet = inlineformset_factory(UUIDPKParent, UUIDPKChild, fields='__all__') formset = FormSet() self.assertIsNone(formset.forms[0].fields['parent'].initial)
FormSet = inlineformset_factory(UUIDPKParent, UUIDPKChild, fields='__all__') formset = FormSet({ 'uuidpkchild_set-TOTAL_FORMS': 3, 'uuidpkchild_set-INITIAL_FORMS': 0, 'uuidpkchild_set-MAX_NUM_FORMS': '', 'uuidpkchild_set-0-name': 'Foo', 'uuidpkchild_set-1-name': '', 'uuidpkchild_set-2-name': '', }) self.assertTrue(formset.is_valid())
FormSet = inlineformset_factory(UUIDPKParent, AutoPKChildOfUUIDPKParent, fields='__all__') formset = FormSet() self.assertIsNone(formset.forms[0].fields['parent'].initial)
FormSet = inlineformset_factory(AutoPKParent, UUIDPKChildOfAutoPKParent, fields='__all__') formset = FormSet() self.assertIsNone(formset.forms[0].fields['parent'].initial)
FormSet = inlineformset_factory(UUIDPKParent, ChildWithEditablePK, fields='__all__') formset = FormSet() self.assertIsNone(formset.forms[0].fields['parent'].initial)
FormSet = inlineformset_factory(ParentWithUUIDAlternateKey, ChildRelatedViaAK, fields='__all__') formset = FormSet() self.assertIsNone(formset.forms[0].fields['parent'].initial)
out = StringIO() call_command('inspectdb', 'inspectdb_people', stdout=out) output = out.getvalue() self.assertIn('class InspectdbPeople(models.Model):', output) self.assertNotIn("InspectdbPeopledata", output)
out = StringIO() call_command('inspectdb', table_name_filter=lambda tn: tn.startswith('inspectdb_columntypes'), stdout=out) output = out.getvalue() def assertFieldType(name, definition): out_def = re.search(r'^\s*%s = (models.*)$' % name, output, re.MULTILINE).groups()[0] self.assertEqual(definition, out_def) return assertFieldType
out = StringIO() call_command('inspectdb', table_name_filter=lambda tn: tn.startswith('inspectdb_'), stdout=out) output = out.getvalue() self.assertIn("class InspectdbSpecialTableName(models.Model):", output)
out = StringIO() call_command('inspectdb', table_name_filter=lambda tn: tn.startswith('inspectdb_columntypes'), stdout=out) output = out.getvalue() self.longMessage = False self.assertIn(" managed = False", output, msg='inspectdb should generate unmanaged models.')
out = StringIO() orig_data_types_reverse = connection.introspection.data_types_reverse try: connection.introspection.data_types_reverse = { 'text': 'myfields.TextField', 'bigint': 'BigIntegerField', } call_command('inspectdb', table_name_filter=lambda tn: tn.startswith('inspectdb_columntypes'), stdout=out) output = out.getvalue() self.assertIn("text_field = myfields.TextField()", output) self.assertIn("big_int_field = models.BigIntegerField()", output) finally: connection.introspection.data_types_reverse = orig_data_types_reverse
DATABASES = {} conns = ConnectionHandler(DATABASES) self.assertEqual(conns[DEFAULT_DB_ALIAS].settings_dict['ENGINE'], 'django.db.backends.dummy') with self.assertRaises(ImproperlyConfigured): conns[DEFAULT_DB_ALIAS].ensure_connection()
with connection.schema_editor(collect_sql=True) as editor: editor.create_model(models.Square) statements = editor.collected_sql match = re.search('"id" ([^,]+),', statements[0]) self.assertIsNotNone(match) self.assertEqual( 'integer NOT NULL PRIMARY KEY AUTOINCREMENT', match.group(1), "Wrong SQL used to create an auto-increment column on SQLite" )
for aggregate in (Sum, Avg, Variance, StdDev): with self.assertRaises(NotImplementedError): models.Item.objects.all().aggregate(aggregate('time')) with self.assertRaises(NotImplementedError): models.Item.objects.all().aggregate(aggregate('date')) with self.assertRaises(NotImplementedError): models.Item.objects.all().aggregate(aggregate('last_modified')) with self.assertRaises(NotImplementedError): models.Item.objects.all().aggregate( **{'complex': aggregate('last_modified') + aggregate('last_modified')} )
from django.db.backends.sqlite3.base import DatabaseWrapper settings_dict = { 'TEST': { 'NAME': 'file:memorydb_test?mode=memory&cache=shared', } } wrapper = DatabaseWrapper(settings_dict) creation = wrapper.creation if creation.connection.features.can_share_in_memory_db: expected = creation.connection.settings_dict['TEST']['NAME'] self.assertEqual(creation._get_test_db_name(), expected) else: msg = ( "Using a shared memory database with `mode=memory` in the " "database name is not supported in your environment, " "use `:memory:` instead." ) with self.assertRaisesMessage(ImproperlyConfigured, msg): creation._get_test_db_name()
self.assert_parses("PostgreSQL 9.3 beta4", 90300) self.assert_parses("PostgreSQL 9.3", 90300) self.assert_parses("EnterpriseDB 9.3", 90300) self.assert_parses("PostgreSQL 9.3.6", 90306) self.assert_parses("PostgreSQL 9.4beta1", 90400) self.assert_parses( "PostgreSQL 9.3.1 on i386-apple-darwin9.2.2, compiled by GCC " "i686-apple-darwin9-gcc-4.0.1 (GCC) 4.0.1 (Apple Inc. build 5478)", 90301 )
updated = datetime.datetime(2010, 2, 20) models.SchoolClass.objects.create(year=2009, last_updated=updated) years = models.SchoolClass.objects.dates('last_updated', 'year') self.assertEqual(list(years), [datetime.date(2010, 1, 1)])
updated = datetime.datetime(2010, 2, 20) models.SchoolClass.objects.create(year=2009, last_updated=updated) classes = models.SchoolClass.objects.filter(last_updated__day=20) self.assertEqual(len(classes), 1)
cursor = connection.cursor() connection.ops.last_executed_query(cursor, '', ())
data = models.RawData.objects.filter(raw_data=b'\x00\x46 \xFE').extra(select={'f': 1}) sql, params = data.query.sql_with_params() cursor = data.query.get_compiler('default').execute_sql(CURSOR) last_sql = cursor.db.ops.last_executed_query(cursor, sql, params) self.assertIsInstance(last_sql, six.text_type)
models.VeryLongModelNameZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZ.objects.create()
obj = models.VeryLongModelNameZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZ.objects.create() rel_obj = models.Person.objects.create(first_name='Django', last_name='Reinhardt') obj.m2m_also_quite_long_zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz.add(rel_obj)
with self.assertNumQueries(0): connection.ops.__class__(connection)
cursor = connection.cursor() query = 'CREATE TABLE %s (id INTEGER);' % models.Article._meta.db_table with self.assertRaises(DatabaseError): cursor.execute(query)
@skipIfDBFeature('allows_auto_pk_0') def test_zero_as_autoval(self): with self.assertRaises(ValueError): models.Square.objects.create(id=0, root=0, square=1)
def equal(value, max_d, places, result): self.assertEqual(format_number(Decimal(value), max_d, places), result) equal('0', 12, 3, '0.000') equal('0', 12, 8, '0.00000000') equal('1', 12, 9, '1.000000000') equal('0.00000000', 12, 8, '0.00000000') equal('0.000000004', 12, 8, '0.00000000') equal('0.000000008', 12, 8, '0.00000001') equal('0.000000000000000000999', 10, 8, '0.00000000') equal('0.1234567890', 12, 10, '0.1234567890') equal('0.1234567890', 12, 9, '0.123456789') equal('0.1234567890', 12, 8, '0.12345679') equal('0.1234567890', 12, 5, '0.12346') equal('0.1234567890', 12, 3, '0.123') equal('0.1234567890', 12, 1, '0.1') equal('0.1234567890', 12, 0, '0') equal('0.1234567890', None, 0, '0') equal('1234567890.1234567890', None, 0, '1234567890') equal('1234567890.1234567890', None, 2, '1234567890.12') equal('0.1234', 5, None, '0.1234') equal('123.12', 5, None, '123.12') with self.assertRaises(Rounded): equal('0.1234567890', 5, None, '0.12346') with self.assertRaises(Rounded): equal('1234567890.1234', 5, None, '1234600000')
def __call__(self, signal, sender, **kwargs): self._database = kwargs['using']
def db_for_write(self, model, **hints): return "other"
cts = ContentType.objects.using('other').filter(app_label='multiple_database') count = cts.count() self.assertGreater(count, 0) cts.delete() management.call_command('migrate', verbosity=0, interactive=False, database='other') self.assertEqual(cts.count(), count)
cts = ContentType.objects.using('other').filter(app_label='multiple_database') cts.delete() with override_settings(DATABASE_ROUTERS=[SyncOnlyDefaultDatabaseRouter()]): management.call_command('migrate', verbosity=0, interactive=False, database='other') self.assertEqual(cts.count(), 0)
def db_for_read(self, model, instance=None, **hints): if instance: return instance._state.db or 'other' return 'other' def db_for_write(self, model, **hints): return DEFAULT_DB_ALIAS def allow_relation(self, obj1, obj2, **hints): return obj1._state.db in ('default', 'other') and obj2._state.db in ('default', 'other') def allow_migrate(self, db, app_label, **hints): return True
ma = ModelAdmin(Band, site) names = [b.name for b in ma.get_queryset(request)] self.assertListEqual(['Aerosmith', 'Radiohead', 'Van Halen'], names)
super_user = User.objects.create(username='admin', is_superuser=True) other_user = User.objects.create(username='other') request = self.request_factory.get('/') request.user = super_user ma = DynOrderingBandAdmin(Band, site) names = [b.name for b in ma.get_queryset(request)] self.assertListEqual(['Radiohead', 'Van Halen', 'Aerosmith'], names) request.user = other_user names = [b.name for b in ma.get_queryset(request)] self.assertListEqual(['Aerosmith', 'Radiohead', 'Van Halen'], names)
inline = SongInlineDefaultOrdering(self.band, site) names = [s.name for s in inline.get_queryset(request)] self.assertListEqual(['Dude (Looks Like a Lady)', 'Jaded', 'Pink'], names)
inline = SongInlineNewOrdering(self.band, site) names = [s.name for s in inline.get_queryset(request)] self.assertListEqual(['Jaded', 'Pink', 'Dude (Looks Like a Lady)'], names)
from django.db import models from django.utils.encoding import python_2_unicode_compatible @python_2_unicode_compatible class Author(models.Model): name = models.CharField(max_length=50) def __str__(self): return self.name class ArticleManager(models.Manager): def get_queryset(self): return super(ArticleManager, self).get_queryset().filter(authors__name__icontains='sir') @python_2_unicode_compatible class Article(models.Model): authors = models.ManyToManyField(Author) title = models.CharField(max_length=50) objects = models.Manager() by_a_sir = ArticleManager() def __str__(self): return self.title
from __future__ import unicode_literals from django.db import models from django.utils.encoding import python_2_unicode_compatible @python_2_unicode_compatible class Person(models.Model): first_name = models.CharField(max_length=20) last_name = models.CharField(max_length=20) def __str__(self): return "%s %s" % (self.first_name, self.last_name) @python_2_unicode_compatible class Car(models.Model): make = models.CharField(max_length=20) model = models.CharField(max_length=20) def __str__(self): return "%s %s" % (self.make, self.model) @python_2_unicode_compatible class Author(models.Model): name = models.CharField(max_length=20) def __str__(self): return self.name @python_2_unicode_compatible class Book(models.Model): name = models.CharField(max_length=20) authors = models.ManyToManyField(Author) def __str__(self): return self.name
class Handler(object): def __init__(self, param): self.param = param self._run = False def __call__(self, signal, sender, **kwargs): self._run = True signal.disconnect(receiver=self, sender=sender) a, b = Handler(1), Handler(2) signals.post_save.connect(a, sender=Person, weak=False) signals.post_save.connect(b, sender=Person, weak=False) Person.objects.create(first_name='John', last_name='Smith') self.assertTrue(a._run) self.assertTrue(b._run) self.assertEqual(signals.post_save.receivers, [])
self.assertEqual( len(Author.objects.annotate(sum=Sum('book_contact_set__price')).filter(sum__gt=Decimal(40))), 1 ) self.assertEqual( len(Author.objects.annotate(sum=Sum('book_contact_set__price')).filter(sum__lte=Decimal(40))), 4 )
books = Book.objects.values_list("publisher__name").annotate( Count("id"), Avg("price"), Avg("authors__age"), avg_pgs=Avg("pages") ).order_by("-publisher__name") self.assertEqual(books[0], ('Sams', 1, 23.09, 45.0, 528.0))
q1 = Q(isbn='') q2 = Q(authors__count__gt=1) query = Book.objects.annotate(Count('authors')) query.filter(q1 | q2) self.assertEqual(len(q2.children), 1)
qs = Book.objects.annotate( account=Count('authors') ).filter( account=F('publisher__num_awards') ) self.assertQuerysetEqual( qs, ['Sams Teach Yourself Django in 24 Hours'], lambda b: b.name)
vals = Book.objects.annotate(select=Count('authors__id')).aggregate(Sum('select'), Avg('select')) self.assertEqual(vals, { 'select__sum': 10, 'select__avg': Approximate(1.666, places=2), })
r = HttpResponseBase() r['Header'] = 'Value' r.setdefault('header', 'changed') self.assertEqual(r['header'], 'Value') r.setdefault('x-header', 'DefaultValue') self.assertEqual(r['X-Header'], 'DefaultValue')
response = HttpResponse('ok') self.assertEqual(response.charset, settings.DEFAULT_CHARSET) response = HttpResponse(charset=ISO88591) self.assertEqual(response.charset, ISO88591) self.assertEqual(response['Content-Type'], 'text/html; charset=%s' % ISO88591) response = HttpResponse(content_type='text/plain; charset=%s' % UTF8, charset=ISO88591) self.assertEqual(response.charset, ISO88591) response = HttpResponse(content_type='text/plain; charset=%s' % ISO88591) self.assertEqual(response.charset, ISO88591) response = HttpResponse(content_type='text/plain; charset="%s"' % ISO88591) self.assertEqual(response.charset, ISO88591) response = HttpResponse(content_type='text/plain; charset=') self.assertEqual(response.charset, settings.DEFAULT_CHARSET) response = HttpResponse(content_type='text/plain') self.assertEqual(response.charset, settings.DEFAULT_CHARSET)
content = "Caf :)" utf8_content = content.encode(UTF8) iso_content = content.encode(ISO88591) response = HttpResponse(utf8_content) self.assertContains(response, utf8_content) response = HttpResponse(iso_content, content_type='text/plain; charset=%s' % ISO88591) self.assertContains(response, iso_content) response = HttpResponse(iso_content) self.assertContains(response, iso_content) response = HttpResponse(iso_content, content_type='text/plain') self.assertContains(response, iso_content)
field = models.DecimalField(max_digits=5, decimal_places=0) name, path, args, kwargs = field.deconstruct() self.assertEqual(path, "django.db.models.DecimalField") self.assertEqual(args, []) self.assertEqual(kwargs, {"max_digits": 5, "decimal_places": 0})
pass
pass
executor = MigrationExecutor(connection) with self.assertRaisesMessage(RuntimeError, "Abort migration"): executor.migrate([("migrations", "0001_initial")]) self.assertTableExists("migrations_publisher") migrations_apps = executor.loader.project_state(("migrations", "0001_initial")).apps Publisher = migrations_apps.get_model("migrations", "Publisher") self.assertTrue(Publisher.objects.exists()) self.assertTableNotExists("migrations_book")
executor = MigrationExecutor(connection) with self.assertRaisesMessage(RuntimeError, "Abort migration"): executor.migrate([("migrations", "0001_initial")]) migrations_apps = executor.loader.project_state(("migrations", "0001_initial")).apps Editor = migrations_apps.get_model("migrations", "Editor") self.assertFalse(Editor.objects.exists())
def __init__(self, name): self.name = name def __repr__(self): return 'M<%s>' % self.name
a1_impl = FakeMigration('a1') a1 = ('a', '1') a2_impl = FakeMigration('a2') a2 = ('a', '2') b1_impl = FakeMigration('b1') b1 = ('b', '1') graph = MigrationGraph() graph.add_node(a1, a1_impl) graph.add_node(a2, a2_impl) graph.add_node(b1, b1_impl) graph.add_dependency(None, b1, a1) graph.add_dependency(None, a2, a1) executor = MigrationExecutor(None) executor.loader = FakeLoader(graph, {a1, b1, a2}) plan = executor.migration_plan({a1}) self.assertEqual(plan, [(a2_impl, True)])
a1_impl = FakeMigration('a1') a1 = ('a', '1') a2_impl = FakeMigration('a2') a2 = ('a', '2') a3_impl = FakeMigration('a3') a3 = ('a', '3') a4_impl = FakeMigration('a4') a4 = ('a', '4') b1_impl = FakeMigration('b1') b1 = ('b', '1') b2_impl = FakeMigration('b2') b2 = ('b', '2') graph = MigrationGraph() graph.add_node(a1, a1_impl) graph.add_node(a2, a2_impl) graph.add_node(a3, a3_impl) graph.add_node(a4, a4_impl) graph.add_node(b1, b1_impl) graph.add_node(b2, b2_impl) graph.add_dependency(None, a2, a1) graph.add_dependency(None, a3, a1) graph.add_dependency(None, a4, a2) graph.add_dependency(None, a4, a3) graph.add_dependency(None, b2, b1) graph.add_dependency(None, b1, a1) graph.add_dependency(None, b2, a2) executor = MigrationExecutor(None) executor.loader = FakeLoader(graph, {a1, b1, a2, b2, a3, a4}) plan = executor.migration_plan({a1}) should_be_rolled_back = [b2_impl, a4_impl, a2_impl, a3_impl] exp = [(m, True) for m in should_be_rolled_back] self.assertEqual(plan, exp)
regex = re.compile(r'^\w+$', re.U) self.assertSerializedEqual(regex)
empty_tuple = () one_item_tuple = ('a',) many_items_tuple = ('a', 'b', 'c') self.assertSerializedEqual(empty_tuple) self.assertSerializedEqual(one_item_tuple) self.assertSerializedEqual(many_items_tuple)
with self.assertRaises(ValueError): self.serialize_round_trip(TestModel1.thing)
class TestModel2(object): def upload_to(self): return "somewhere dynamic" thing = models.FileField(upload_to=upload_to) with self.assertRaises(ValueError): self.serialize_round_trip(TestModel2.thing)
class TestModel2(object): def upload_to(self): return "somewhere dynamic" thing = models.FileField(upload_to=upload_to) with self.assertRaisesMessage(ValueError, 'Could not find function upload_to in migrations.test_writer'): self.serialize_round_trip(TestModel2.thing)
migration = type(str("Migration"), (migrations.Migration,), { "operations": [ migrations.AddField("mymodel", "myfield", models.DateTimeField( default=datetime.datetime(2012, 1, 1, 1, 1, tzinfo=utc), )), ] }) writer = MigrationWriter(migration) output = writer.as_string().decode('utf-8') self.assertIn( "import datetime\n" "from django.db import migrations, models\n" "from django.utils.timezone import utc\n", output )
migration = type(str("Migration"), (migrations.Migration,), { "operations": [ migrations.AlterModelOptions( name='model', options={'verbose_name': 'model', 'verbose_name_plural': 'models'}, ), ] }) writer = MigrationWriter(migration) output = writer.as_string().decode('utf-8') self.assertIn("from django.db import migrations\n", output)
new_apps = Apps(['migrations']) custom_manager = models.Manager() class Author(models.Model): objects = models.TextField() authors = custom_manager class Meta: app_label = 'migrations' apps = new_apps project_state = ProjectState.from_apps(new_apps) author_state = project_state.models['migrations', 'author'] self.assertEqual(author_state.managers, [('authors', custom_manager)])
project_state = ProjectState() apps = project_state.apps with apps.bulk_update(): self.assertFalse(apps.ready) self.assertTrue(apps.ready) with self.assertRaises(ValueError): with apps.bulk_update(): self.assertFalse(apps.ready) raise ValueError() self.assertTrue(apps.ready)
project_state = ProjectState() project_state.add_model(ModelState( app_label="migrations", name="Tag", fields=[ ("id", models.AutoField(primary_key=True)), ("hidden", models.BooleanField()), ], managers=[ ('food_mgr', FoodManager('a', 'b')), ('food_qs', FoodQuerySet.as_manager()), ] )) old_model = project_state.apps.get_model('migrations', 'tag') new_state = project_state.clone() operation = RemoveField("tag", "hidden") operation.state_forwards("migrations", new_state) new_model = new_state.apps.get_model('migrations', 'tag') self.assertIsNot(old_model, new_model) self.assertIs(old_model, old_model.food_mgr.model) self.assertIs(old_model, old_model.food_qs.model) self.assertIs(new_model, new_model.food_mgr.model) self.assertIs(new_model, new_model.food_qs.model) self.assertIsNot(old_model.food_mgr, new_model.food_mgr) self.assertIsNot(old_model.food_qs, new_model.food_qs) self.assertIsNot(old_model.food_mgr.model, new_model.food_mgr.model) self.assertIsNot(old_model.food_qs.model, new_model.food_qs.model)
new_apps = Apps(["migrations"]) choices = [('a', 'A'), ('b', 'B')] class Author(models.Model): name = models.CharField(max_length=255) choice = models.CharField(max_length=255, choices=iter(choices)) class Meta: app_label = "migrations" apps = new_apps ProjectState.from_apps(new_apps) choices_field = Author._meta.get_field('choice') self.assertEqual(list(choices_field.choices), choices)
apps = Apps() field = models.CharField(max_length=1) state = ModelState('app', 'Model', [('name', field)]) Model = state.render(apps) self.assertNotEqual(Model._meta.get_field('name'), field)
new_apps = Apps(['migrations']) class Author(models.Model): name = models.CharField(max_length=255) bio = models.TextField() age = models.IntegerField(blank=True, null=True) class Meta: app_label = 'migrations' apps = new_apps swappable = 'TEST_SWAPPABLE_MODEL' author_state = ModelState.from_model(Author) self.assertEqual(author_state.app_label, 'migrations') self.assertEqual(author_state.name, 'Author') self.assertEqual([x for x, y in author_state.fields], ['id', 'name', 'bio', 'age']) self.assertEqual(author_state.fields[1][1].max_length, 255) self.assertEqual(author_state.fields[2][1].null, False) self.assertEqual(author_state.fields[3][1].null, True) self.assertEqual(author_state.options, {'swappable': 'TEST_SWAPPABLE_MODEL'}) self.assertEqual(author_state.bases, (models.Model, )) self.assertEqual(author_state.managers, [])
def allow_migrate(self, db, app_label, **hints): return None
def allow_migrate(self, db, app_label, **hints): return False
def allow_migrate(self, db, app_label, **hints): return True
def allow_migrate(self, db, app_label, **hints): return hints.get('foo', False)
self._test_create_model("test_mltdb_crmo", should_run=True)
self._test_create_model("test_mltdb_crmo2", should_run=False)
self._test_create_model("test_mltdb_crmo3", should_run=True)
with override_settings(DATABASE_ROUTERS=[AgnosticRouter(), AgnosticRouter()]): self._test_create_model("test_mltdb_crmo4", should_run=True) with override_settings(DATABASE_ROUTERS=[MigrateNothingRouter(), MigrateEverythingRouter()]): self._test_create_model("test_mltdb_crmo4", should_run=False) with override_settings(DATABASE_ROUTERS=[MigrateEverythingRouter(), MigrateNothingRouter()]): self._test_create_model("test_mltdb_crmo4", should_run=True)
def __init__(self, *args, **kwargs): self.args = args self.kwargs = kwargs def deconstruct(self): return ( self.__module__ + '.' + self.__class__.__name__, self.args, self.kwargs )
before = self.make_project_state([ ModelState("testapp", "EntityA", [ ("id", models.AutoField(primary_key=True)), ]), ModelState("testapp", "EntityB", [ ("id", models.AutoField(primary_key=True)), ("some_label", models.CharField(max_length=255)), ("entity_a", models.ForeignKey("testapp.EntityA", models.CASCADE)), ]), ]) after = self.make_project_state([ ModelState("testapp", "EntityA", [ ("id", models.AutoField(primary_key=True)), ]), ModelState("testapp", "RenamedEntityB", [ ("id", models.AutoField(primary_key=True)), ("entity_a", models.ForeignKey("testapp.EntityA", models.CASCADE)), ("some_label", models.CharField(max_length=255)), ]), ]) autodetector = MigrationAutodetector(before, after, MigrationQuestioner({"ask_rename_model": True})) changes = autodetector._detect_changes() self.assertNumberMigrations(changes, "testapp", 1) self.assertOperationTypes(changes, "testapp", 0, ["RenameModel"]) self.assertOperationAttributes(changes, "testapp", 0, 0, old_name="EntityB", new_name="RenamedEntityB")
before = self.make_project_state([self.author_name_deconstructible_3]) after = self.make_project_state([self.author_name_deconstructible_4]) autodetector = MigrationAutodetector(before, after) changes = autodetector._detect_changes() self.assertEqual(changes, {})
dependencies = [ ("migrations", "0001_initial"), ] run_before = [ ("migrations", "0002_second"), ] operations = [ migrations.CreateModel( "Author", [ ("id", models.AutoField(primary_key=True)), ("name", models.CharField(max_length=255)), ("slug", models.SlugField(null=True)), ("age", models.IntegerField(default=0)), ], ) ]
project_state = self.set_up_test_model(app_label, **kwargs) new_state = project_state.clone() operation.state_forwards(app_label, new_state) return project_state, new_state
project_state = self.set_up_test_model("test_regr22168") operation = migrations.AddField( "Pony", "order", models.IntegerField(default=0), ) new_state = project_state.clone() operation.state_forwards("test_regr22168", new_state) with connection.schema_editor() as editor: operation.database_forwards("test_regr22168", editor, project_state, new_state) self.assertColumnExists("test_regr22168_pony", "order")
project_state = self.set_up_test_model("test_rfk", related_model=True) self.assertColumnExists("test_rfk_rider", "pony_id") operation = migrations.RemoveField("Rider", "pony") new_state = project_state.clone() operation.state_forwards("test_rfk", new_state) with connection.schema_editor() as editor: operation.database_forwards("test_rfk", editor, project_state, new_state) self.assertColumnNotExists("test_rfk_rider", "pony_id") with connection.schema_editor() as editor: operation.database_backwards("test_rfk", editor, new_state, project_state) self.assertColumnExists("test_rfk_rider", "pony_id")
operation = migrations.RunSQL(migrations.RunSQL.noop, migrations.RunSQL.noop) with connection.schema_editor() as editor: operation.database_forwards("test_runsql", editor, None, None) operation.database_backwards("test_runsql", editor, None, None)
def inner_method(models, schema_editor): Author = models.get_model("test_authors", "Author") Book = models.get_model("test_books", "Book") author = Author.objects.create(name="Hemingway") Book.objects.create(title="Old Man and The Sea", author=author) create_author = migrations.CreateModel( "Author", [ ("id", models.AutoField(primary_key=True)), ("name", models.CharField(max_length=100)), ], options={}, ) create_book = migrations.CreateModel( "Book", [ ("id", models.AutoField(primary_key=True)), ("title", models.CharField(max_length=100)), ("author", models.ForeignKey("test_authors.Author", models.CASCADE)) ], options={}, ) add_hometown = migrations.AddField( "Author", "hometown", models.CharField(max_length=100), ) create_old_man = migrations.RunPython(inner_method, inner_method) project_state = ProjectState() new_state = project_state.clone() with connection.schema_editor() as editor: create_author.state_forwards("test_authors", new_state) create_author.database_forwards("test_authors", editor, project_state, new_state) project_state = new_state new_state = new_state.clone() with connection.schema_editor() as editor: create_book.state_forwards("test_books", new_state) create_book.database_forwards("test_books", editor, project_state, new_state) project_state = new_state new_state = new_state.clone() with connection.schema_editor() as editor: add_hometown.state_forwards("test_authors", new_state) add_hometown.database_forwards("test_authors", editor, project_state, new_state) project_state = new_state new_state = new_state.clone() with connection.schema_editor() as editor: create_old_man.state_forwards("test_books", new_state) create_old_man.database_forwards("test_books", editor, project_state, new_state)
def create_data(models, schema_editor): Author = models.get_model("test_author", "Author") Book = models.get_model("test_book", "Book") author1 = Author.objects.create(name="Hemingway") Book.objects.create(title="Old Man and The Sea", author=author1) Book.objects.create(id=2 ** 33, title="A farewell to arms", author=author1) author2 = Author.objects.create(id=2 ** 33, name="Remarque") Book.objects.create(title="All quiet on the western front", author=author2) Book.objects.create(title="Arc de Triomphe", author=author2) create_author = migrations.CreateModel( "Author", [ ("id", models.BigAutoField(primary_key=True)), ("name", models.CharField(max_length=100)), ], options={}, ) create_book = migrations.CreateModel( "Book", [ ("id", models.BigAutoField(primary_key=True)), ("title", models.CharField(max_length=100)), ("author", models.ForeignKey(to="test_author.Author", on_delete=models.CASCADE)) ], options={}, ) fill_data = migrations.RunPython(create_data) project_state = ProjectState() new_state = project_state.clone() with connection.schema_editor() as editor: create_author.state_forwards("test_author", new_state) create_author.database_forwards("test_author", editor, project_state, new_state) project_state = new_state new_state = new_state.clone() with connection.schema_editor() as editor: create_book.state_forwards("test_book", new_state) create_book.database_forwards("test_book", editor, project_state, new_state) project_state = new_state new_state = new_state.clone() with connection.schema_editor() as editor: fill_data.state_forwards("fill_data", new_state) fill_data.database_forwards("fill_data", editor, project_state, new_state)
def create_initial_data(models, schema_editor): Article = models.get_model("test_article", "Article") Blog = models.get_model("test_blog", "Blog") blog = Blog.objects.create(name="web development done right") Article.objects.create(name="Frameworks", blog=blog) Article.objects.create(name="Programming Languages", blog=blog) def create_big_data(models, schema_editor): Article = models.get_model("test_article", "Article") Blog = models.get_model("test_blog", "Blog") blog2 = Blog.objects.create(name="Frameworks", id=2 ** 33) Article.objects.create(name="Django", blog=blog2) Article.objects.create(id=2 ** 33, name="Django2", blog=blog2) create_blog = migrations.CreateModel( "Blog", [ ("id", models.AutoField(primary_key=True)), ("name", models.CharField(max_length=100)), ], options={}, ) create_article = migrations.CreateModel( "Article", [ ("id", models.AutoField(primary_key=True)), ("blog", models.ForeignKey(to="test_blog.Blog", on_delete=models.CASCADE)), ("name", models.CharField(max_length=100)), ("data", models.TextField(default="")), ], options={}, ) fill_initial_data = migrations.RunPython(create_initial_data, create_initial_data) fill_big_data = migrations.RunPython(create_big_data, create_big_data) grow_article_id = migrations.AlterField("Article", "id", models.BigAutoField(primary_key=True)) grow_blog_id = migrations.AlterField("Blog", "id", models.BigAutoField(primary_key=True)) project_state = ProjectState() new_state = project_state.clone() with connection.schema_editor() as editor: create_blog.state_forwards("test_blog", new_state) create_blog.database_forwards("test_blog", editor, project_state, new_state) project_state = new_state new_state = new_state.clone() with connection.schema_editor() as editor: create_article.state_forwards("test_article", new_state) create_article.database_forwards("test_article", editor, project_state, new_state) project_state = new_state new_state = new_state.clone() with connection.schema_editor() as editor: fill_initial_data.state_forwards("fill_initial_data", new_state) fill_initial_data.database_forwards("fill_initial_data", editor, project_state, new_state) project_state = new_state new_state = new_state.clone() with connection.schema_editor() as editor: grow_article_id.state_forwards("test_article", new_state) grow_article_id.database_forwards("test_article", editor, project_state, new_state) state = new_state.clone() article = state.apps.get_model("test_article.Article") self.assertIsInstance(article._meta.pk, models.BigAutoField) project_state = new_state new_state = new_state.clone() with connection.schema_editor() as editor: grow_blog_id.state_forwards("test_blog", new_state) grow_blog_id.database_forwards("test_blog", editor, project_state, new_state) state = new_state.clone() blog = state.apps.get_model("test_blog.Blog") self.assertTrue(isinstance(blog._meta.pk, models.BigAutoField)) project_state = new_state new_state = new_state.clone() with connection.schema_editor() as editor: fill_big_data.state_forwards("fill_big_data", new_state) fill_big_data.database_forwards("fill_big_data", editor, project_state, new_state)
project_state = ProjectState() new_state = project_state.clone() operation = migrations.RunPython(migrations.RunPython.noop, migrations.RunPython.noop) with connection.schema_editor() as editor: operation.database_forwards("test_runpython", editor, project_state, new_state) operation.database_backwards("test_runpython", editor, new_state, project_state)
optimizer = MigrationOptimizer() return optimizer.optimize(operations), optimizer._iterations
self.assertOptimizesTo( [migrations.DeleteModel("Foo")], [migrations.DeleteModel("Foo")], exact=1, )
self.assertOptimizesTo( [ migrations.CreateModel("Foo", [("name", models.CharField(max_length=255))]), migrations.DeleteModel("Foo"), ], [], )
managers = [('objects', EmptyManager())] self.assertOptimizesTo( [ migrations.CreateModel( name="Foo", fields=[("name", models.CharField(max_length=255))], options={'verbose_name': 'Foo'}, bases=(UnicodeModel,), managers=managers, ), migrations.RenameModel("Foo", "Bar"), ], [ migrations.CreateModel( "Bar", [("name", models.CharField(max_length=255))], options={'verbose_name': 'Foo'}, bases=(UnicodeModel,), managers=managers, ) ], )
self.assertOptimizesTo( [ migrations.RenameModel("Foo", "Baa"), migrations.RenameModel("Baa", "Bar"), ], [ migrations.RenameModel("Foo", "Bar"), ], )
self.assertOptimizesTo( [ migrations.CreateModel("Foo", [("name", models.CharField(max_length=255))]), migrations.AlterModelTable("Foo", "woohoo"), alter_foo, migrations.DeleteModel("Foo"), ], [], )
self.assertOptimizesTo( [ alter_foo, alter_bar, ], [ alter_bar, ], )
managers = [('objects', EmptyManager())] self.assertOptimizesTo( [ migrations.CreateModel( name="Foo", fields=[("name", models.CharField(max_length=255))], options={'verbose_name': 'Foo'}, bases=(UnicodeModel,), managers=managers, ), migrations.AddField("Foo", "age", models.IntegerField()), ], [ migrations.CreateModel( name="Foo", fields=[ ("name", models.CharField(max_length=255)), ("age", models.IntegerField()), ], options={'verbose_name': 'Foo'}, bases=(UnicodeModel,), managers=managers, ), ], )
self.assertOptimizesTo( [ migrations.CreateModel("Foo", [("name", models.CharField(max_length=255))]), migrations.CreateModel("Link", [("url", models.TextField())]), migrations.AddField("Foo", "link", models.ForeignKey("migrations.Link", models.CASCADE)), ], [ migrations.CreateModel("Foo", [("name", models.CharField(max_length=255))]), migrations.CreateModel("Link", [("url", models.TextField())]), migrations.AddField("Foo", "link", models.ForeignKey("migrations.Link", models.CASCADE)), ], )
managers = [('objects', EmptyManager())] self.assertOptimizesTo( [ migrations.CreateModel( name="Foo", fields=[("name", models.CharField(max_length=255))], options={'verbose_name': 'Foo'}, bases=(UnicodeModel,), managers=managers, ), migrations.AlterField("Foo", "name", models.IntegerField()), ], [ migrations.CreateModel( name="Foo", fields=[ ("name", models.IntegerField()), ], options={'verbose_name': 'Foo'}, bases=(UnicodeModel,), managers=managers, ), ], )
managers = [('objects', EmptyManager())] self.assertOptimizesTo( [ migrations.CreateModel( name="Foo", fields=[("name", models.CharField(max_length=255))], options={'verbose_name': 'Foo'}, bases=(UnicodeModel,), managers=managers, ), migrations.RenameField("Foo", "name", "title"), ], [ migrations.CreateModel( name="Foo", fields=[ ("title", models.CharField(max_length=255)), ], options={'verbose_name': 'Foo'}, bases=(UnicodeModel,), managers=managers, ), ], )
self.assertOptimizesTo( [ migrations.AddField("Foo", "name", models.CharField(max_length=255)), migrations.RenameField("Foo", "name", "title"), ], [ migrations.AddField("Foo", "title", models.CharField(max_length=255)), ], )
self.assertOptimizesTo( [ migrations.AlterField("Foo", "name", models.CharField(max_length=255)), migrations.RenameField("Foo", "name", "title"), migrations.RenameField("Foo", "title", "nom"), ], [ migrations.RenameField("Foo", "name", "nom"), migrations.AlterField("Foo", "nom", models.CharField(max_length=255)), ], )
managers = [('objects', EmptyManager())] self.assertOptimizesTo( [ migrations.CreateModel( name="Foo", fields=[ ("name", models.CharField(max_length=255)), ("age", models.IntegerField()), ], options={'verbose_name': 'Foo'}, bases=(UnicodeModel,), managers=managers, ), migrations.RemoveField("Foo", "age"), ], [ migrations.CreateModel( name="Foo", fields=[ ("name", models.CharField(max_length=255)), ], options={'verbose_name': 'Foo'}, bases=(UnicodeModel,), managers=managers, ), ], )
self.assertOptimizesTo( [ migrations.AddField("Foo", "age", models.IntegerField()), migrations.AlterField("Foo", "age", models.FloatField(default=2.4)), ], [ migrations.AddField("Foo", name="age", field=models.FloatField(default=2.4)), ], )
self.assertOptimizesTo( [ migrations.AddField("Foo", "age", models.IntegerField()), migrations.RemoveField("Foo", "age"), ], [], )
self.assertOptimizesTo( [ migrations.AlterField("Foo", "age", models.IntegerField()), migrations.RemoveField("Foo", "age"), ], [ migrations.RemoveField("Foo", "age"), ], )
self.assertOptimizesTo( [ migrations.CreateModel("Foo", [("name", models.CharField(max_length=255))]), migrations.CreateModel("Bar", [("size", models.IntegerField())]), migrations.AddField("Foo", "age", models.IntegerField()), migrations.AddField("Bar", "width", models.IntegerField()), migrations.AlterField("Foo", "age", models.IntegerField()), migrations.RenameField("Bar", "size", "dimensions"), migrations.RemoveField("Foo", "age"), migrations.RenameModel("Foo", "Phou"), migrations.RemoveField("Bar", "dimensions"), migrations.RenameModel("Phou", "Fou"), migrations.DeleteModel("Fou"), ], [ migrations.CreateModel("Bar", [("width", models.IntegerField())]), ], )
migration_loader = MigrationLoader(connection) self.assertEqual( migration_loader.graph.forwards_plan(("migrations", "second")), [ ("migrations", "thefirst"), ("migrations2", "0001_initial"), ("migrations2", "0002_second"), ("migrations", "second"), ], )
migration_loader = MigrationLoader(connection) self.assertEqual(migration_loader.migrated_apps, {'migrated_app'}) self.assertEqual(migration_loader.unmigrated_apps, set())
migration_loader = MigrationLoader(connection) self.assertEqual(migration_loader.migrated_apps, set()) self.assertEqual(migration_loader.unmigrated_apps, {'migrated_app'})
with self.assertRaisesMessage(CommandError, "Conflicting migrations detected"): call_command("migrate", "migrations")
out = six.StringIO() call_command("showmigrations", format='plan', stdout=out) self.assertEqual("", out.getvalue().lower()) out = six.StringIO() call_command("showmigrations", format='plan', stdout=out, verbosity=2) self.assertEqual("", out.getvalue().lower())
out = six.StringIO() call_command("showmigrations", format='plan', stdout=out) self.assertEqual( "[ ] migrations.1_auto\n" "[ ] migrations.2_auto\n" "[ ] migrations.3_squashed_5\n" "[ ] migrations.6_auto\n" "[ ] migrations.7_auto\n", out.getvalue().lower() ) out = six.StringIO() call_command("showmigrations", format='plan', stdout=out, verbosity=2) self.assertEqual( "[ ] migrations.1_auto\n" "[ ] migrations.2_auto ... (migrations.1_auto)\n" "[ ] migrations.3_squashed_5 ... (migrations.2_auto)\n" "[ ] migrations.6_auto ... (migrations.3_squashed_5)\n" "[ ] migrations.7_auto ... (migrations.6_auto)\n", out.getvalue().lower() ) call_command("migrate", "migrations", "3_squashed_5", verbosity=0) out = six.StringIO() call_command("showmigrations", format='plan', stdout=out) self.assertEqual( "[x] migrations.1_auto\n" "[x] migrations.2_auto\n" "[x] migrations.3_squashed_5\n" "[ ] migrations.6_auto\n" "[ ] migrations.7_auto\n", out.getvalue().lower() ) out = six.StringIO() call_command("showmigrations", format='plan', stdout=out, verbosity=2) self.assertEqual( "[x] migrations.1_auto\n" "[x] migrations.2_auto ... (migrations.1_auto)\n" "[x] migrations.3_squashed_5 ... (migrations.2_auto)\n" "[ ] migrations.6_auto ... (migrations.3_squashed_5)\n" "[ ] migrations.7_auto ... (migrations.6_auto)\n", out.getvalue().lower() )
out = six.StringIO() call_command("sqlmigrate", "migrations", "0001", stdout=out) output = out.getvalue().lower() index_tx_start = output.find(connection.ops.start_transaction_sql().lower()) index_op_desc_author = output.find('-- create model author') index_create_table = output.find('create table') index_op_desc_tribble = output.find('-- create model tribble') index_op_desc_unique_together = output.find('-- alter unique_together') index_tx_end = output.find(connection.ops.end_transaction_sql().lower()) self.assertGreater(index_tx_start, -1, "Transaction start not found") self.assertGreater( index_op_desc_author, index_tx_start, "Operation description (author) not found or found before transaction start" ) self.assertGreater( index_create_table, index_op_desc_author, "CREATE TABLE not found or found before operation description (author)" ) self.assertGreater( index_op_desc_tribble, index_create_table, "Operation description (tribble) not found or found before CREATE TABLE (author)" ) self.assertGreater( index_op_desc_unique_together, index_op_desc_tribble, "Operation description (unique_together) not found or found before operation description (tribble)" ) self.assertGreater( index_tx_end, index_op_desc_unique_together, "Transaction end not found or found before operation description (unique_together)" )
out = six.StringIO() call_command("sqlmigrate", "migrations", "0001", stdout=out) output = out.getvalue().lower() queries = [q.strip() for q in output.splitlines()] if connection.ops.start_transaction_sql(): self.assertNotIn(connection.ops.start_transaction_sql().lower(), queries) self.assertNotIn(connection.ops.end_transaction_sql().lower(), queries)
recorder = MigrationRecorder(connection) recorder.record_applied("migrations", "0002_second") msg = "Migration migrations.0002_second is applied before its dependency migrations.0001_initial" with self.assertRaisesMessage(InconsistentMigrationHistory, msg): call_command("migrate") applied_migrations = recorder.applied_migrations() self.assertNotIn(("migrations", "0001_initial"), applied_migrations)
with self.temporary_migration_module(module="migrations.test_migrations_conflict"): with self.assertRaises(CommandError): call_command("makemigrations")
out = six.StringIO() with self.temporary_migration_module(module="migrations.test_migrations"): call_command("makemigrations", merge=True, stdout=out) self.assertIn("No conflicts detected to merge.", out.getvalue())
err = six.StringIO() with self.assertRaises(SystemExit): call_command("makemigrations", "this_app_does_not_exist", stderr=err) self.assertIn("'this_app_does_not_exist' could not be found.", err.getvalue())
with self.assertRaises(CommandError): call_command("makemigrations", empty=True)
msg = ( "Django can't create migrations for app 'migrations' because migrations " "have been disabled via the MIGRATION_MODULES setting." ) with self.assertRaisesMessage(ValueError, msg): call_command("makemigrations", "migrations", empty=True, verbosity=0)
out = six.StringIO() call_command("makemigrations", stdout=out) self.assertIn("No changes detected", out.getvalue())
out = six.StringIO() with self.temporary_migration_module(module="migrations.test_migrations_no_changes"): call_command("makemigrations", "migrations", stdout=out) self.assertIn("No changes detected in app 'migrations'", out.getvalue())
out = six.StringIO() with self.temporary_migration_module(module="migrations.test_migrations_empty"): call_command("makemigrations", stdout=out) self.assertIn("0001_initial.py", out.getvalue())
out = six.StringIO() with self.temporary_migration_module(): call_command("makemigrations", "migrations", stdout=out) self.assertIn("Migrations for 'migrations'", out.getvalue())
with self.assertRaises(ValueError) as context: with self.temporary_migration_module(module="migrations.test_migrations_no_ancestor"): call_command("makemigrations", "migrations", merge=True) exception_message = str(context.exception) self.assertIn("Could not find common ancestor of", exception_message) self.assertIn("0002_second", exception_message) self.assertIn("0002_conflicting_second", exception_message)
class SillyModel(models.Model): silly_field = models.BooleanField(default=False) silly_int = models.IntegerField() class Meta: app_label = "migrations" out = six.StringIO() with self.assertRaises(SystemExit): with self.temporary_migration_module(module="migrations.test_migrations_no_default"): call_command("makemigrations", "migrations", interactive=False, stdout=out)
class Author(models.Model): name = models.CharField(max_length=255) slug = models.SlugField() age = models.IntegerField(default=0) class Meta: app_label = "migrations" out = six.StringIO() with self.temporary_migration_module(module="migrations.test_migrations"): call_command("makemigrations", "migrations", interactive=False, stdout=out) self.assertIn("Alter field slug on author", force_text(out.getvalue()))
class RenamedModel(models.Model): silly_field = models.BooleanField(default=False) class Meta: app_label = "migrations" out = six.StringIO() with self.temporary_migration_module(module="migrations.test_migrations_no_default"): call_command("makemigrations", "migrations", interactive=False, stdout=out) self.assertIn("Delete model SillyModel", force_text(out.getvalue())) self.assertIn("Create model RenamedModel", force_text(out.getvalue()))
class SillyModel(models.Model): silly_rename = models.BooleanField(default=False) class Meta: app_label = "migrations" out = six.StringIO() with self.temporary_migration_module(module="migrations.test_migrations_no_default"): call_command("makemigrations", "migrations", interactive=False, stdout=out) self.assertIn("Remove field silly_field from sillymodel", force_text(out.getvalue())) self.assertIn("Add field silly_rename to sillymodel", force_text(out.getvalue()))
out = six.StringIO() with self.temporary_migration_module(module="migrations.test_migrations_conflict") as migration_dir: call_command("makemigrations", "migrations", name="merge", merge=True, interactive=False, stdout=out) merge_file = os.path.join(migration_dir, '0003_merge.py') self.assertTrue(os.path.exists(merge_file)) output = force_text(out.getvalue()) self.assertIn("Merging migrations", output) self.assertIn("Branch 0002_second", output) self.assertIn("Branch 0002_conflicting_second", output) self.assertIn("Created new merge migration", output)
out = six.StringIO() with self.temporary_migration_module(module="migrations.test_migrations_conflict") as migration_dir: call_command( "makemigrations", "migrations", name="merge", dry_run=True, merge=True, interactive=False, stdout=out, ) merge_file = os.path.join(migration_dir, '0003_merge.py') self.assertFalse(os.path.exists(merge_file)) output = force_text(out.getvalue()) self.assertIn("Merging migrations", output) self.assertIn("Branch 0002_second", output) self.assertIn("Branch 0002_conflicting_second", output) self.assertNotIn("Created new merge migration", output)
with self.temporary_migration_module(module="migrations.test_migrations_no_changes"): call_command("makemigrations", "migrations", merge=False, verbosity=0)
with self.temporary_migration_module(): call_command("makemigrations", "--exit", "migrations", verbosity=0) with self.temporary_migration_module(module="migrations.test_migrations_no_changes"): with self.assertRaises(SystemExit): call_command("makemigrations", "--exit", "migrations", verbosity=0)
with self.temporary_migration_module(): with self.assertRaises(SystemExit): call_command("makemigrations", "--check", "migrations", verbosity=0) with self.temporary_migration_module(module="migrations.test_migrations_no_changes"): call_command("makemigrations", "--check", "migrations", verbosity=0)
out = six.StringIO() apps.register_model('migrations', UnicodeModel) with self.temporary_migration_module() as migration_dir: call_command("makemigrations", "migrations", stdout=out) self.assertIn(os.path.join(migration_dir, '0001_initial.py'), out.getvalue())
recorder = MigrationRecorder(connection) recorder.record_applied('migrations', '0002_second') msg = "Migration migrations.0002_second is applied before its dependency migrations.0001_initial" with self.temporary_migration_module(module="migrations.test_migrations"): with self.assertRaisesMessage(InconsistentMigrationHistory, msg): call_command("makemigrations")
with self.temporary_migration_module(module="migrations.test_migrations") as migration_dir: call_command("squashmigrations", "migrations", "0002", interactive=False, verbosity=0) squashed_migration_file = os.path.join(migration_dir, "0001_squashed_0002_second.py") self.assertTrue(os.path.exists(squashed_migration_file))
out = six.StringIO() with self.temporary_migration_module(module="migrations.test_migrations"): call_command("squashmigrations", "migrations", "0002", interactive=False, verbosity=1, stdout=out) self.assertIn("Optimized from 8 operations to 3 operations.", force_text(out.getvalue()))
out = six.StringIO() with self.temporary_migration_module(module="migrations.test_migrations"): call_command("squashmigrations", "migrations", "0002", interactive=False, verbosity=1, no_optimize=True, stdout=out) self.assertIn("Skipping optimization", force_text(out.getvalue()))
out = six.StringIO() with self.temporary_migration_module(module="migrations.test_migrations_no_changes") as migration_dir: call_command("squashmigrations", "migrations", "0002", "0003", interactive=False, verbosity=1, stdout=out) squashed_migration_file = os.path.join(migration_dir, "0002_second_squashed_0003_third.py") with codecs.open(squashed_migration_file, "r", encoding="utf-8") as fp: content = fp.read() self.assertIn(" ('migrations', '0001_initial')", content) self.assertNotIn("initial = True", content) out = force_text(out.getvalue()) self.assertNotIn(" - 0001_initial", out) self.assertIn(" - 0002_second", out) self.assertIn(" - 0003_third", out)
graph = MigrationGraph() message = "Node ('app_b', '0001') not a valid node" with self.assertRaisesMessage(NodeNotFoundError, message): graph.forwards_plan(("app_b", "0001")) with self.assertRaisesMessage(NodeNotFoundError, message): graph.backwards_plan(("app_b", "0001"))
graph = MigrationGraph() graph.add_node(("app_a", "0001"), None) graph.add_node(("app_b", "0001"), None) graph.add_node(("app_b", "0002"), None) graph.add_node(("app_c", "0001_squashed_0002"), None) graph.add_dependency("app_b.0001", ("app_b", "0001"), ("app_c", "0001_squashed_0002")) graph.add_dependency("app_b.0002", ("app_b", "0002"), ("app_a", "0001")) graph.add_dependency("app_b.0002", ("app_b", "0002"), ("app_b", "0001")) graph.add_dependency("app_c.0001_squashed_0002", ("app_c", "0001_squashed_0002"), ("app_b", "0002")) with self.assertRaises(CircularDependencyError): graph.forwards_plan(("app_c", "0001_squashed_0002"))
with self.assertRaises(ImproperlyConfigured): self.site.register(Location)
def setUp(self): self.default_site = site self.custom_site = CustomSite() def test_basic_registration(self): register(Person)(NameAdmin) self.assertIsInstance(self.default_site._registry[Person], admin.ModelAdmin) self.default_site.unregister(Person) def test_custom_site_registration(self): register(Person, site=self.custom_site)(NameAdmin) self.assertIsInstance(self.custom_site._registry[Person], admin.ModelAdmin) def test_multiple_registration(self): register(Traveler, Place)(NameAdmin) self.assertIsInstance(self.default_site._registry[Traveler], admin.ModelAdmin) self.default_site.unregister(Traveler) self.assertIsInstance(self.default_site._registry[Place], admin.ModelAdmin) self.default_site.unregister(Place) def test_wrapped_class_not_a_model_admin(self): with self.assertRaisesMessage(ValueError, 'Wrapped class must subclass ModelAdmin.'): register(Person)(CustomSite) def test_custom_site_not_an_admin_site(self): with self.assertRaisesMessage(ValueError, 'site must subclass AdminSite'): register(Person, site=Traveler)(NameAdmin) def test_empty_models_list_registration_fails(self): with self.assertRaisesMessage(ValueError, 'At least one model must be passed to register.'): register()(NameAdmin)
self.drop_table() out = six.StringIO() management.call_command( 'createcachetable', 'test cache table', verbosity=2, stdout=out, ) self.assertEqual(out.getvalue(), "Cache table 'test cache table' created.\n")
def db_for_read(self, model, **hints): if model._meta.app_label == 'django_cache': return 'other' return None def db_for_write(self, model, **hints): if model._meta.app_label == 'django_cache': return 'other' return None def allow_migrate(self, db, app_label, **hints): if app_label == 'django_cache': return db == 'other' return None
bad_obj = PicklingSideEffect(cache) cache.set('set', bad_obj) self.assertFalse(bad_obj.locked, "Cache was locked during pickling") cache.add('add', bad_obj) self.assertFalse(bad_obj.locked, "Cache was locked during pickling")
self.assertEqual(300, self.DEFAULT_TIMEOUT)
cache = caches[DEFAULT_CACHE_ALIAS] self.assertEqual(self.DEFAULT_TIMEOUT, cache.default_timeout)
cache = caches[DEFAULT_CACHE_ALIAS] self.assertIsNone(cache.default_timeout) self.assertIsNone(cache.get_backend_timeout())
key = "my-key" value = "my-value" cache = caches[DEFAULT_CACHE_ALIAS] cache.set(key, value) cache_key = cache.make_key(key) self.assertIsNotNone(cache._expire_info[cache_key])
key = "another-key" value = "another-value" cache = caches[DEFAULT_CACHE_ALIAS] cache.set(key, value) cache_key = cache.make_key(key) self.assertIsNone(cache._expire_info[cache_key])
request1 = self.factory.get(self.path, HTTP_HOST='sub-1.example.com') learn_cache_key(request1, HttpResponse()) request2 = self.factory.get(self.path, HTTP_HOST='sub-2.example.com') learn_cache_key(request2, HttpResponse()) self.assertNotEqual(get_cache_key(request1), get_cache_key(request2))
cache1 = caches['default'] cache2 = caches['default'] self.assertIs(cache1, cache2)
c = [] def runner(): c.append(caches['default']) for x in range(2): t = threading.Thread(target=runner) t.start() t.join() self.assertIsNot(c[0], c[1])
site = models.ForeignKey(Site, models.CASCADE, related_name="admin_articles") title = models.CharField(max_length=100) hist = models.CharField(max_length=100, verbose_name=_("History")) created = models.DateTimeField(null=True) def test_from_model(self): return "nothing" def test_from_model_with_override(self): return "nothing" test_from_model_with_override.short_description = "not What you Expect"
n = NestedObjects(using=DEFAULT_DB_ALIAS) Car.objects.create() n.collect([Vehicle.objects.first()])
SITE_NAME = 'example.com' TITLE_TEXT = 'Some title' CREATED_DATE = datetime.min ADMIN_METHOD = 'admin method' SIMPLE_FUNCTION = 'function' INSTANCE_ATTRIBUTE = 'attr' class MockModelAdmin(object): def get_admin_value(self, obj): return ADMIN_METHOD def simple_function(obj): return SIMPLE_FUNCTION site_obj = Site(domain=SITE_NAME) article = Article( site=site_obj, title=TITLE_TEXT, created=CREATED_DATE, ) article.non_field = INSTANCE_ATTRIBUTE verifications = ( ('site', SITE_NAME), ('created', localize(CREATED_DATE)), ('title', TITLE_TEXT), ('get_admin_value', ADMIN_METHOD), (simple_function, SIMPLE_FUNCTION), ('test_from_model', article.test_from_model()), ('non_field', INSTANCE_ATTRIBUTE) ) mock_admin = MockModelAdmin() for name, value in verifications: field, attr, resolved_value = lookup_field(name, article, mock_admin) if field is not None: resolved_value = display_for_field(resolved_value, field, self.empty_value) self.assertEqual(value, resolved_value)
self.assertEqual( label_for_field("title", Article), "title" ) self.assertEqual( label_for_field("hist", Article), "History" ) self.assertEqual( label_for_field("hist", Article, return_attr=True), ("History", None) ) self.assertEqual( label_for_field("__unicode__", Article), "article" ) self.assertEqual( label_for_field("__str__", Article), str("article") ) with self.assertRaises(AttributeError): label_for_field("unknown", Article) def test_callable(obj): return "nothing" self.assertEqual( label_for_field(test_callable, Article), "Test callable" ) self.assertEqual( label_for_field(test_callable, Article, return_attr=True), ("Test callable", test_callable) ) self.assertEqual( label_for_field("test_from_model", Article), "Test from model" ) self.assertEqual( label_for_field("test_from_model", Article, return_attr=True), ("Test from model", Article.test_from_model) ) self.assertEqual( label_for_field("test_from_model_with_override", Article), "not What you Expect" ) self.assertEqual( label_for_field(lambda x: "nothing", Article), "--" ) class MockModelAdmin(object): def test_from_model(self, obj): return "nothing" test_from_model.short_description = "not Really the Model" self.assertEqual( label_for_field("test_from_model", Article, model_admin=MockModelAdmin), "not Really the Model" ) self.assertEqual( label_for_field("test_from_model", Article, model_admin=MockModelAdmin, return_attr=True), ("not Really the Model", MockModelAdmin.test_from_model) )
self.assertEqual( label_for_field('location', Event, return_attr=True), ('location', None), ) self.assertEqual( label_for_field('event', Location, return_attr=True), ('awesome event', None), ) self.assertEqual( label_for_field('guest', Event, return_attr=True), ('awesome guest', None), )
fieldsets = ( (None, { 'fields': ('url', 'title', ('content', 'sites')) }), ) self.assertEqual(flatten_fieldsets(fieldsets), ['url', 'title', 'content', 'sites']) fieldsets = ( (None, { 'fields': ('url', 'title', ['content', 'sites']) }), ) self.assertEqual(flatten_fieldsets(fieldsets), ['url', 'title', 'content', 'sites'])
logentry = LogEntry.objects.get(content_type__model__iexact="article") action_time = logentry.action_time logentry.save() self.assertEqual(logentry.action_time, action_time)
post_data = { 'site': self.site.pk, 'title': 'Changed', 'hist': 'Some content', 'created_0': '2008-03-18', 'created_1': '11:54', } change_url = reverse('admin:admin_utils_article_change', args=[quote(self.a1.pk)]) response = self.client.post(change_url, post_data) self.assertRedirects(response, reverse('admin:admin_utils_article_changelist')) logentry = LogEntry.objects.filter(content_type__model__iexact='article').latest('id') self.assertEqual(logentry.get_change_message(), 'Changed title and hist.') with translation.override('fr'): self.assertEqual(logentry.get_change_message(), 'Modification de title et hist.') add_url = reverse('admin:admin_utils_article_add') post_data['title'] = 'New' response = self.client.post(add_url, post_data) self.assertRedirects(response, reverse('admin:admin_utils_article_changelist')) logentry = LogEntry.objects.filter(content_type__model__iexact='article').latest('id') self.assertEqual(logentry.get_change_message(), 'Added.') with translation.override('fr'): self.assertEqual(logentry.get_change_message(), 'Ajout.')
logentry = LogEntry.objects.get(content_type__model__iexact="article") edited_obj = logentry.get_edited_object() self.assertEqual(logentry.object_id, str(edited_obj.pk))
logentry = LogEntry.objects.get(content_type__model__iexact='article') expected_url = reverse('admin:admin_utils_article_change', args=(quote(self.a1.pk),)) self.assertEqual(logentry.get_admin_url(), expected_url) self.assertIn('article/%d/change/' % self.a1.pk, logentry.get_admin_url()) logentry.content_type.model = "non-existent" self.assertIsNone(logentry.get_admin_url())
def fails(val, **kwargs): raise ValueError('this') a_signal.connect(fails) result = a_signal.send_robust(sender=self, val="test") err = result[0][1] self.assertIsInstance(err, ValueError) self.assertEqual(err.args, ('this',)) self.assertTrue(hasattr(err, '__traceback__')) self.assertIsInstance(err.__traceback__, TracebackType) a_signal.disconnect(fails) self.assertTestIsClean(a_signal)
def test_receiver_single_signal(self): @receiver(a_signal) def f(val, **kwargs): self.state = val self.state = False a_signal.send(sender=self, val=True) self.assertTrue(self.state) def test_receiver_signal_list(self): @receiver([a_signal, b_signal, c_signal]) def f(val, **kwargs): self.state.append(val) self.state = [] a_signal.send(sender=self, val='a') c_signal.send(sender=self, val='c') b_signal.send(sender=self, val='b') self.assertIn('a', self.state) self.assertIn('b', self.state) self.assertIn('c', self.state)
from django.db import models class UnimportantThing(models.Model): importance = models.IntegerField() def get_absolute_url(self): return '/importance/%d/' % (self.importance,)
self.assertEqual('/something/', resolve_url('/something/'))
self.assertEqual('../', resolve_url('../')) self.assertEqual('../relative/', resolve_url('../relative/')) self.assertEqual('./', resolve_url('./')) self.assertEqual('./relative/', resolve_url('./relative/'))
url = 'http://example.com/' self.assertEqual(url, resolve_url(url))
m = UnimportantThing(importance=1) self.assertEqual(m.get_absolute_url(), resolve_url(m))
resolved_url = resolve_url(logout) self.assertEqual('/accounts/logout/', resolved_url)
resolved_url = resolve_url(reverse_lazy('logout')) self.assertIsInstance(resolved_url, six.text_type) self.assertEqual('/accounts/logout/', resolved_url)
resolved_url = resolve_url('logout') self.assertEqual('/accounts/logout/', resolved_url)
self.assertEqual(resolve_url('example.com'), 'example.com')
name = models.CharField(max_length=50) objects = PersonManager() def __str__(self): return self.name
data = models.CharField(max_length=10) class Meta: abstract = True
class Meta: proxy = True ordering = ["name"] permissions = ( ("display_users", "May display users information"), ) objects = SubManager() other = PersonManager() def has_special_name(self): return self.name.lower() == "special"
class Meta: proxy = True ordering = ["name"]
my_person_sql = MyPerson.other.all().query.get_compiler( DEFAULT_DB_ALIAS).as_sql() person_sql = Person.objects.order_by("name").query.get_compiler( DEFAULT_DB_ALIAS).as_sql() self.assertEqual(my_person_sql, person_sql)
sp_sql = StatusPerson.objects.all().query.get_compiler( DEFAULT_DB_ALIAS).as_sql() p_sql = Person.objects.all().query.get_compiler( DEFAULT_DB_ALIAS).as_sql() self.assertNotEqual(sp_sql, p_sql)
person = Person.objects.create(name="Foo McBar") self.assertEqual(len(Person.objects.all()), 1) self.assertEqual(len(MyPerson.objects.all()), 1) self.assertEqual(MyPerson.objects.get(name="Foo McBar").id, person.id) self.assertFalse(MyPerson.objects.get(id=person.id).has_special_name())
Person.objects.create(name="Foo McBar") self.assertEqual(list(StatusPerson.objects.all()), [])
MyPerson.objects.create(name="Bazza del Frob") self.assertEqual(len(MyPerson.objects.all()), 1) self.assertEqual(len(Person.objects.all()), 1) LowerStatusPerson.objects.create(status="low", name="homer") lsps = [lsp.name for lsp in LowerStatusPerson.objects.all()] self.assertEqual(lsps, ["homer"])
Person.objects.create(name="Foo McBar") MyPerson.objects.create(name="Bazza del Frob") LowerStatusPerson.objects.create(status="low", name="homer") pp = sorted(mpp.name for mpp in MyPersonProxy.objects.all()) self.assertEqual(pp, ['Bazza del Frob', 'Foo McBar', 'homer'])
Person.objects.create(name="Foo McBar") MyPerson.objects.create(name="Bazza del Frob") LowerStatusPerson.objects.create(status="low", name="homer") max_id = Person.objects.aggregate(max_id=models.Max('id'))['max_id'] with self.assertRaises(Person.DoesNotExist): MyPersonProxy.objects.get(name='Zathras') with self.assertRaises(Person.MultipleObjectsReturned): MyPersonProxy.objects.get(id__lt=max_id + 1) with self.assertRaises(Person.DoesNotExist): StatusPerson.objects.get(name='Zathras') StatusPerson.objects.create(name='Bazza Jr.') StatusPerson.objects.create(name='Foo Jr.') max_id = Person.objects.aggregate(max_id=models.Max('id'))['max_id'] with self.assertRaises(Person.MultipleObjectsReturned): StatusPerson.objects.get(id__lt=max_id + 1)
output = [] def make_handler(model, event): def _handler(*args, **kwargs): output.append('%s %s save' % (model, event)) return _handler h1 = make_handler('MyPerson', 'pre') h2 = make_handler('MyPerson', 'post') h3 = make_handler('Person', 'pre') h4 = make_handler('Person', 'post') signals.pre_save.connect(h1, sender=MyPerson) signals.post_save.connect(h2, sender=MyPerson) signals.pre_save.connect(h3, sender=Person) signals.post_save.connect(h4, sender=Person) MyPerson.objects.create(name="dino") self.assertEqual(output, [ 'MyPerson pre save', 'MyPerson post save' ]) output = [] h5 = make_handler('MyPersonProxy', 'pre') h6 = make_handler('MyPersonProxy', 'post') signals.pre_save.connect(h5, sender=MyPersonProxy) signals.post_save.connect(h6, sender=MyPersonProxy) MyPersonProxy.objects.create(name="pebbles") self.assertEqual(output, [ 'MyPersonProxy pre save', 'MyPersonProxy post save' ]) signals.pre_save.disconnect(h1, sender=MyPerson) signals.post_save.disconnect(h2, sender=MyPerson) signals.pre_save.disconnect(h3, sender=Person) signals.post_save.disconnect(h4, sender=Person) signals.pre_save.disconnect(h5, sender=MyPersonProxy) signals.post_save.disconnect(h6, sender=MyPersonProxy)
User.objects.create(name='Bruce') u2 = UserProxy.objects.create(name='George') resp = [u.name for u in UserProxy.objects.all()] self.assertEqual(resp, ['Bruce', 'George']) u2.delete() resp = [u.name for u in UserProxy.objects.all()] self.assertEqual(resp, ['Bruce'])
country = Country.objects.create(name='Australia') State.objects.create(name='New South Wales', country=country) resp = [s.name for s in State.objects.select_related()] self.assertEqual(resp, ['New South Wales']) resp = [s.name for s in StateProxy.objects.select_related()] self.assertEqual(resp, ['New South Wales']) self.assertEqual(StateProxy.objects.get(name='New South Wales').name, 'New South Wales') resp = StateProxy.objects.select_related().get(name='New South Wales') self.assertEqual(resp.name, 'New South Wales')
tracker_user = TrackerUser.objects.all()[0] base_user = BaseUser.objects.all()[0] issue = Issue.objects.all()[0] with self.assertNumQueries(7): collector = admin.utils.NestedObjects('default') collector.collect(ProxyTrackerUser.objects.all()) self.assertIn(tracker_user, collector.edges.get(None, ())) self.assertIn(base_user, collector.edges.get(None, ())) self.assertIn(issue, collector.edges.get(tracker_user, ()))
with transaction.atomic(): list(Person.objects.all().select_for_update()) self.assertTrue(self.has_for_update_sql(connection))
with transaction.atomic(): list(Person.objects.all().select_for_update(nowait=True)) self.assertTrue(self.has_for_update_sql(connection, nowait=True))
self.start_blocking_transaction() status = [] thread = threading.Thread( target=self.run_select_for_update, args=(status,), kwargs={'nowait': True}, ) thread.start() time.sleep(1) thread.join() self.end_blocking_transaction() self.assertIsInstance(status[-1], DatabaseError)
with self.assertRaises(DatabaseError): list(Person.objects.all().select_for_update(nowait=True))
with self.assertRaises(transaction.TransactionManagementError): list(Person.objects.all().select_for_update())
people = Person.objects.all().select_for_update() with self.assertRaises(transaction.TransactionManagementError): list(people)
field_dict = fields_for_model(Person, fields=()) self.assertEqual(len(field_dict), 0)
class EmptyPersonForm(forms.ModelForm): class Meta: model = Person fields = () form = EmptyPersonForm() self.assertEqual(len(form.fields), 0)
form = modelform_factory(Person, fields="__all__")({'name': 'John Doe'}) self.assertTrue(form.is_valid()) instance = construct_instance(form, Person(), fields=()) self.assertEqual(instance.name, '')
obj = Writer.objects.create(name='test') form = CustomWriterForm(data={'name': ''}, instance=obj) self.assertTrue(form.is_valid()) obj = form.save() self.assertEqual(obj.name, '')
age = forms.IntegerField() class Meta: model = Person fields = ('name', 'no-field')
age = forms.IntegerField() class Meta: model = Person fields = ('name', 'age')
class Meta: model = Category fields = ['name', 'url'] exclude = ['url']
pass
class Meta(SomeCategoryForm.Meta): exclude = ['url']
url = forms.CharField(required=False) class Meta: fields = ('name', 'slug') model = Category
url = forms.CharField(required=False) class Meta: exclude = ['url'] model = Category
form = PriceForm({'price': '6.00', 'quantity': '1'}) self.assertTrue(form.is_valid()) form.save() form = PriceForm({'price': '6.00', 'quantity': '1'}) self.assertFalse(form.is_valid()) self.assertEqual(len(form.errors), 1) self.assertEqual(form.errors['__all__'], ['Price with this Price and Quantity already exists.'])
class TripleForm(forms.ModelForm): class Meta: model = Triple fields = '__all__' Triple.objects.create(left=1, middle=2, right=3) form = TripleForm({'left': '1', 'middle': '2', 'right': '3'}) self.assertFalse(form.is_valid()) form = TripleForm({'left': '1', 'middle': '3', 'right': '1'}) self.assertTrue(form.is_valid())
form = ExplicitPKForm({'key': '', 'desc': ''}) self.assertFalse(form.is_valid())
form = ExplicitPKForm({'key': 'key1', 'desc': ''}) self.assertTrue(form.is_valid()) form.save() form = ExplicitPKForm({'key': 'key1', 'desc': ''}) self.assertFalse(form.is_valid()) self.assertEqual(len(form.errors), 3) self.assertEqual(form.errors['__all__'], ['Explicit pk with this Key and Desc already exists.']) self.assertEqual(form.errors['desc'], ['Explicit pk with this Desc already exists.']) self.assertEqual(form.errors['key'], ['Explicit pk with this Key already exists.'])
persons = [Writer.objects.create(name="Person %s" % i) for i in range(30)] f = forms.ModelMultipleChoiceField(queryset=Writer.objects.all()) self.assertNumQueries(1, f.clean, [p.pk for p in persons[1:11:2]])
for i in range(30): Writer.objects.create(name="Person %s" % i) self._validator_run = False def my_validator(value): self._validator_run = True f = forms.ModelMultipleChoiceField(queryset=Writer.objects.all(), validators=[my_validator]) f.clean([p.pk for p in Writer.objects.all()[8:9]]) self.assertTrue(self._validator_run)
class WriterForm(forms.Form): persons = forms.ModelMultipleChoiceField(show_hidden_initial=True, queryset=Writer.objects.all()) person1 = Writer.objects.create(name="Person 1") person2 = Writer.objects.create(name="Person 2") form = WriterForm(initial={'persons': [person1, person2]}, data={'initial-persons': [str(person1.pk), str(person2.pk)], 'persons': [str(person1.pk), str(person2.pk)]}) self.assertTrue(form.is_valid()) self.assertFalse(form.has_changed()) form = WriterForm(initial={'persons': [person1, person2]}, data={'initial-persons': [str(person1.pk), str(person2.pk)], 'persons': [str(person2.pk)]}) self.assertTrue(form.is_valid()) self.assertTrue(form.has_changed())
f = forms.FileField(required=False) self.assertEqual(f.clean(False), False) self.assertEqual(f.clean(False, 'initial'), False)
f = forms.FileField(required=True) self.assertEqual(f.clean(False, 'initial'), 'initial') with self.assertRaises(ValidationError): f.clean(False)
class DocumentForm(forms.ModelForm): class Meta: model = Document fields = '__all__' form = DocumentForm() self.assertIn('name="myfile"', six.text_type(form)) self.assertNotIn('myfile-clear', six.text_type(form)) form = DocumentForm(files={'myfile': SimpleUploadedFile('something.txt', b'content')}) self.assertTrue(form.is_valid()) doc = form.save(commit=False) self.assertEqual(doc.myfile.name, 'something.txt') form = DocumentForm(instance=doc) self.assertIn('myfile-clear', six.text_type(form)) form = DocumentForm(instance=doc, data={'myfile-clear': 'true'}) doc = form.save(commit=False) self.assertEqual(bool(doc.myfile), False)
class DocumentForm(forms.ModelForm): class Meta: model = Document fields = '__all__' form = DocumentForm(files={'myfile': SimpleUploadedFile('something.txt', b'content')}) self.assertTrue(form.is_valid()) doc = form.save(commit=False) form = DocumentForm(instance=doc, files={'myfile': SimpleUploadedFile('something.txt', b'content')}, data={'myfile-clear': 'true'}) self.assertTrue(not form.is_valid()) self.assertEqual(form.errors['myfile'], ['Please either submit a file or check the clear checkbox, not both.']) rendered = six.text_type(form) self.assertIn('something.txt', rendered) self.assertIn('myfile-clear', rendered)
class FPForm(forms.ModelForm): class Meta: model = FilePathModel fields = '__all__' form = FPForm() names = [p[1] for p in form['path'].field.choices] names.sort() self.assertEqual(names, ['---------', '__init__.py', 'models.py', 'test_uuid.py', 'tests.py'])
class HomepageForm(forms.ModelForm): class Meta: model = Homepage fields = '__all__' form = HomepageForm({'url': 'example.com'}) self.assertTrue(form.is_valid()) self.assertEqual(form.cleaned_data['url'], 'http://example.com') form = HomepageForm({'url': 'example.com/test'}) self.assertTrue(form.is_valid()) self.assertEqual(form.cleaned_data['url'], 'http://example.com/test')
% {'blue_pk': colour.pk})
class CategoryForm(forms.ModelForm): class Meta: model = Category fields = '__all__' def clean(self): self.cleaned_data['name'] = self.cleaned_data['name'].upper() return self.cleaned_data data = {'name': 'Test', 'slug': 'test', 'url': '/test'} form = CategoryForm(data) category = form.save() self.assertEqual(category.name, 'TEST')
class MyForm(forms.ModelForm): media = forms.CharField() class Meta: model = Writer fields = '__all__' class SubForm(MyForm): media = None self.assertIn('media', MyForm().fields) self.assertNotIn('media', SubForm().fields) self.assertTrue(hasattr(MyForm, 'media')) self.assertTrue(hasattr(SubForm, 'media'))
stumpjokeform = StumpJokeForm() self.assertIn(self.threepwood, stumpjokeform.fields['most_recently_fooled'].queryset) self.assertNotIn(self.marley, stumpjokeform.fields['most_recently_fooled'].queryset)
stumpjokeform = StumpJokeForm() self.assertIn(self.threepwood, stumpjokeform.fields['has_fooled_today'].queryset) self.assertNotIn(self.marley, stumpjokeform.fields['has_fooled_today'].queryset)
f = StumpJokeWithCustomFieldForm() self.assertEqual(f.fields['custom'].queryset, 42)
widget = forms.Textarea() class BaseForm(forms.ModelForm): class Meta: model = Person widgets = {'name': widget} fields = "__all__" Form = modelform_factory(Person, form=BaseForm) self.assertIs(Form.base_fields['name'].widget, widget)
message = ( "Calling modelform_factory without defining 'fields' or 'exclude' " "explicitly is prohibited." ) with self.assertRaisesMessage(ImproperlyConfigured, message): modelform_factory(Person)
form = modelform_factory(Person, fields="__all__") self.assertEqual(list(form.base_fields), ["name"])
callback_args = [] def callback(db_field, **kwargs): callback_args.append((db_field, kwargs)) return db_field.formfield(**kwargs) widget = forms.Textarea() class BaseForm(forms.ModelForm): class Meta: model = Person widgets = {'name': widget} fields = "__all__" modelform_factory(Person, form=BaseForm, formfield_callback=callback) id_field, name_field = Person._meta.fields self.assertEqual(callback_args, [(id_field, {}), (name_field, {'widget': widget})])
return HttpResponse('<html><body>dummy</body></html>')
self.assertEqual(fully_decorated.__name__, 'fully_decorated') self.assertEqual(fully_decorated.__doc__, 'Expected __doc__') self.assertEqual(fully_decorated.__dict__['anything'], 'Expected __dict__')
def test1(user): user.decorators_applied.append('test1') return True def test2(user): user.decorators_applied.append('test2') return True def callback(request): return request.user.decorators_applied callback = user_passes_test(test1)(callback) callback = user_passes_test(test2)(callback) class DummyUser(object): pass class DummyRequest(object): pass request = DummyRequest() request.user = DummyUser() request.user.decorators_applied = [] response = callback(request) self.assertEqual(response, ['test2', 'test1'])
def my_view(request): return "response" my_view_cached = cache_page(123)(my_view) self.assertEqual(my_view_cached(HttpRequest()), "response") my_view_cached2 = cache_page(123, key_prefix="test")(my_view) self.assertEqual(my_view_cached2(HttpRequest()), "response")
def my_view(request): return HttpResponse("OK") my_safe_view = require_safe(my_view) request = HttpRequest() request.method = 'GET' self.assertIsInstance(my_safe_view(request), HttpResponse) request.method = 'HEAD' self.assertIsInstance(my_safe_view(request), HttpResponse) request.method = 'POST' self.assertIsInstance(my_safe_view(request), HttpResponseNotAllowed) request.method = 'PUT' self.assertIsInstance(my_safe_view(request), HttpResponseNotAllowed) request.method = 'DELETE' self.assertIsInstance(my_safe_view(request), HttpResponseNotAllowed)
def deco(func): def _wrapper(*args, **kwargs): return True return _wrapper @method_decorator(deco, name="method") class Test(object): def method(self): return False self.assertTrue(Test().method())
msg = ( "Cannot decorate 'prop' as it isn't a callable attribute of " "<class 'Test'> (1)" ) with self.assertRaisesMessage(TypeError, msg): @method_decorator(lambda: None, name="prop") class Test(object): prop = 1 @classmethod def __module__(cls): return "tests"
msg = ( "The keyword argument `name` must be the name of a method of the " "decorated class: <class 'Test'>. Got 'non_existing_method' instead" ) with self.assertRaisesMessage(ValueError, msg): @method_decorator(lambda: None, name="non_existing_method") class Test(object): @classmethod def __module__(cls): return "tests"
@xframe_options_deny def a_view(request): return HttpResponse() r = a_view(HttpRequest()) self.assertEqual(r['X-Frame-Options'], 'DENY')
@xframe_options_sameorigin def a_view(request): return HttpResponse() r = a_view(HttpRequest()) self.assertEqual(r['X-Frame-Options'], 'SAMEORIGIN')
from datetime import datetime from django.db import models from django.utils.encoding import python_2_unicode_compatible @python_2_unicode_compatible class Article(models.Model): headline = models.CharField(max_length=100, default='Default headline') pub_date = models.DateTimeField(default=datetime.now) def __str__(self): return self.headline
from django.db import models from django.utils.encoding import python_2_unicode_compatible class Author(models.Model): class Meta: ordering = ('-pk',) @python_2_unicode_compatible class Article(models.Model): author = models.ForeignKey(Author, models.SET_NULL, null=True) second_author = models.ForeignKey(Author, models.SET_NULL, null=True) headline = models.CharField(max_length=100) pub_date = models.DateTimeField() class Meta: ordering = ('-pub_date', 'headline') def __str__(self): return self.headline class OrderedByAuthorArticle(Article): class Meta: proxy = True ordering = ('author', 'second_author') class Reference(models.Model): article = models.ForeignKey(OrderedByAuthorArticle, models.CASCADE) class Meta: ordering = ('article',)
self.assertQuerysetEqual( Article.objects.order_by("headline"), [ "Article 1", "Article 2", "Article 3", "Article 4", ], attrgetter("headline") ) self.assertQuerysetEqual( Article.objects.order_by("pub_date", "-headline"), [ "Article 1", "Article 3", "Article 2", "Article 4", ], attrgetter("headline") )
self.assertQuerysetEqual( Article.objects.order_by("id"), [ "Article 1", "Article 2", "Article 3", "Article 4", ], attrgetter("headline") ) self.assertQuerysetEqual( Article.objects.order_by("id").order_by("-headline"), [ "Article 4", "Article 3", "Article 2", "Article 1", ], attrgetter("headline") )
self.assertQuerysetEqual( Article.objects.order_by("headline")[:2], [ "Article 1", "Article 2", ], attrgetter("headline") )
self.assertQuerysetEqual( Article.objects.order_by("headline")[1:3], [ "Article 2", "Article 3", ], attrgetter("headline") )
self.assertEqual( len(list(Article.objects.order_by("?"))), 4 )
self.assertQuerysetEqual( Article.objects.all().reverse()[:2], [ "Article 1", "Article 3", ], attrgetter("headline") )
self.assertQuerysetEqual( Article.objects.extra(select={"foo": "pub_date"}, order_by=["foo", "headline"]), [ "Article 1", "Article 2", "Article 3", "Article 4", ], attrgetter("headline") )
self.assertQuerysetEqual( Article.objects.extra(select={"order": "pub_date"}, order_by=["order", "headline"]), [ "Article 1", "Article 2", "Article 3", "Article 4", ], attrgetter("headline") )
Author.objects.create(pk=1) Author.objects.create(pk=2) Author.objects.create(pk=3) Author.objects.create(pk=4) self.assertQuerysetEqual( Author.objects.all(), [ 4, 3, 2, 1 ], attrgetter("pk") )
for i in range(1, 5): author = Author.objects.create(pk=i) article = getattr(self, "a%d" % (5 - i)) article.author = author article.save(update_fields={'author'}) self.assertQuerysetEqual( Article.objects.order_by('author_id'), [ "Article 4", "Article 3", "Article 2", "Article 1", ], attrgetter("headline") )
qs = Article.objects.order_by(F('headline').asc(), F('headline').desc()) sql = str(qs.query).upper() fragment = sql[sql.find('ORDER BY'):] self.assertEqual(fragment.count('HEADLINE'), 1) self.assertQuerysetEqual( qs, [ "Article 1", "Article 2", "Article 3", "Article 4", ], attrgetter("headline") ) qs = Article.objects.order_by(F('headline').desc(), F('headline').asc()) sql = str(qs.query).upper() fragment = sql[sql.find('ORDER BY'):] self.assertEqual(fragment.count('HEADLINE'), 1) self.assertQuerysetEqual( qs, [ "Article 4", "Article 3", "Article 2", "Article 1", ], attrgetter("headline") )
us = TUser.objects.create(name="std") usp = Person.objects.create(user=us) uo = TUser.objects.create(name="org") uop = Person.objects.create(user=uo) s = Student.objects.create(person=usp) o = Organizer.objects.create(person=uop) c = Class.objects.create(org=o) Enrollment.objects.create(std=s, cls=c) e_related = Enrollment.objects.all().select_related()[0] self.assertEqual(e_related.std.person.user.name, "std") self.assertEqual(e_related.cls.org.person.user.name, "org")
Country.objects.create(name='Australia') active = ClientStatus.objects.create(name='active') client = Client.objects.create(name='client', status=active) self.assertEqual(client.status, active) self.assertEqual(Client.objects.select_related()[0].status, active) self.assertEqual(Client.objects.select_related('state')[0].status, active) self.assertEqual(Client.objects.select_related('state', 'status')[0].status, active) self.assertEqual(Client.objects.select_related('state__country')[0].status, active) self.assertEqual(Client.objects.select_related('state__country', 'status')[0].status, active) self.assertEqual(Client.objects.select_related('status')[0].status, active)
c1 = Child.objects.create(name="child1", value=42) Item.objects.create(name="item1", child=c1) Item.objects.create(name="item2") self.assertQuerysetEqual( Item.objects.select_related("child").order_by("name"), ["<Item: item1>", "<Item: item2>"] )
f1 = Foo(name="Foo1") f1.save() f2 = Foo(name="Foo2") f2.save() w1 = Whiz(name="Whiz1") w1.save() b1 = Bar(name="Bar1", normal=f1, fwd=w1, back=f2) b1.save() self.assertEqual(b1.normal, f1) self.assertEqual(b1.fwd, w1) self.assertEqual(b1.back, f2) base1 = Base(name="Base1") base1.save() child1 = Child(name="Child1", parent=base1) child1.save() self.assertEqual(child1.parent, base1)
a = Article(name='Test', text='The quick brown fox jumps over the lazy dog.') a.save() self.assertEqual(Article.objects.get(text__exact='The quick brown fox jumps over the lazy dog.'), a) self.assertEqual(Article.objects.get(text__contains='quick brown fox'), a)
p = Place.objects.create(name="South Park") r = Restaurant.objects.create(name="Chubby's") l1 = Link.objects.create(content_object=p) l2 = Link.objects.create(content_object=r) self.assertEqual(list(p.links.all()), [l1]) self.assertEqual(list(r.links.all()), [l2])
p = Person.objects.create(account=23, name='Chef') Address.objects.create(street='123 Anywhere Place', city='Conifer', state='CO', zipcode='80433', content_object=p) qs = Person.objects.filter(addresses__zipcode='80433') self.assertEqual(1, qs.count()) self.assertEqual('Chef', qs[0].name)
p1 = Place.objects.create(name="South Park") p2 = Place.objects.create(name="The City") c = Company.objects.create(name="Chubby's Intl.") Link.objects.create(content_object=p1) Link.objects.create(content_object=c) places = list(Place.objects.order_by('links__id')) def count_places(place): return len([p for p in places if p.id == place.id]) self.assertEqual(len(places), 2) self.assertEqual(count_places(p1), 1) self.assertEqual(count_places(p2), 1)
team1 = Team.objects.create(name='Backend devs') try: note = Note(note='Deserve a bonus', content_object=team1) except Exception as e: if (issubclass(type(e), Exception) and str(e) == 'Impossible arguments to GFK.get_content_type!'): self.fail("Saving model with GenericForeignKey to model instance whose " "__len__ method returns 0 shouldn't fail.") raise e note.save()
car = models.ForeignKey(Car, models.CASCADE)
honeycomb = models.ForeignKey(Honeycomb, models.CASCADE)
name = models.CharField(max_length=20) parent = models.ForeignKey('self', models.SET_NULL, null=True) soulmate = models.ForeignKey('self', models.CASCADE, null=True, related_name='soulmates')
name = models.CharField(max_length=20) companies = models.ManyToManyField(Company)
class BandAdmin(admin.ModelAdmin): formfield_overrides = { CharField: {'widget': forms.TextInput(attrs={'size': '10'})} } ma = BandAdmin(models.Band, admin.site) f1 = ma.formfield_for_dbfield(models.Band._meta.get_field('name'), request=None) f2 = ma.formfield_for_dbfield(models.Band._meta.get_field('style'), request=None) self.assertNotEqual(f1.widget, f2.widget) self.assertEqual(f1.widget.attrs['maxlength'], '100') self.assertEqual(f2.widget.attrs['maxlength'], '20') self.assertEqual(f2.widget.attrs['size'], '10')
class MemberAdmin(admin.ModelAdmin): formfield_overrides = {DateTimeField: {'widget': widgets.AdminSplitDateTime}} ma = MemberAdmin(models.Member, admin.site) f1 = ma.formfield_for_dbfield(models.Member._meta.get_field('birthdate'), request=None) self.assertIsInstance(f1.widget, widgets.AdminSplitDateTime) self.assertIsInstance(f1, forms.SplitDateTimeField)
class AlbumAdmin(admin.ModelAdmin): formfield_overrides = {models.MyFileField: {'widget': forms.TextInput()}} ma = AlbumAdmin(models.Member, admin.site) f1 = ma.formfield_for_dbfield(models.Album._meta.get_field('backside_art'), request=None) self.assertIsInstance(f1.widget, forms.TextInput)
class AdvisorAdmin(admin.ModelAdmin): filter_vertical = ['companies'] self.assertFormfield(models.Advisor, 'companies', widgets.FilteredSelectMultiple, filter_vertical=['companies']) ma = AdvisorAdmin(models.Advisor, admin.site) f = ma.formfield_for_dbfield(models.Advisor._meta.get_field('companies'), request=None) self.assertEqual( six.text_type(f.help_text), 'Hold down "Control", or "Command" on a Mac, to select more than one.' )
self.client.force_login(self.superuser) response = self.client.get(reverse('admin:admin_widgets_cartire_add')) self.assertNotContains(response, "BMW M3") self.assertContains(response, "Volkswagen Passat")
self.client.force_login(self.superuser) response = self.client.get(reverse('admin:admin_widgets_album_change', args=(self.album.id,))) self.assertContains( response, '<p><a href="%(STORAGE_URL)salbums/hybrid_theory.jpg">' 'albums\hybrid_theory.jpg</a></p>' % {'STORAGE_URL': default_storage.url('')}, html=True, ) self.assertNotContains( response, '<input type="file" name="cover_art" id="id_cover_art" />', html=True, ) response = self.client.get(reverse('admin:admin_widgets_album_add')) self.assertContains( response, '<p></p>', html=True, )
from django.db import models from django.utils.encoding import python_2_unicode_compatible @python_2_unicode_compatible class Donut(models.Model): name = models.CharField(max_length=100) is_frosted = models.BooleanField(default=False) has_sprinkles = models.NullBooleanField() baked_date = models.DateField(null=True) baked_time = models.TimeField(null=True) consumed_at = models.DateTimeField(null=True) review = models.TextField() class Meta: ordering = ('consumed_at',) def __str__(self): return self.name class RumBaba(models.Model): baked_date = models.DateField(auto_now_add=True) baked_timestamp = models.DateTimeField(auto_now_add=True)
Donut.objects.create( name='Date Test 2007', baked_date=datetime.datetime(year=2007, month=12, day=31), consumed_at=datetime.datetime(year=2007, month=12, day=31, hour=23, minute=59, second=59), ) Donut.objects.create( name='Date Test 2006', baked_date=datetime.datetime(year=2006, month=1, day=1), consumed_at=datetime.datetime(year=2006, month=1, day=1), ) self.assertEqual("Date Test 2007", Donut.objects.filter(baked_date__year=2007)[0].name) self.assertEqual("Date Test 2006", Donut.objects.filter(baked_date__year=2006)[0].name) Donut.objects.create( name='Apple Fritter', consumed_at=datetime.datetime(year=2007, month=4, day=20, hour=16, minute=19, second=59), ) self.assertEqual( ['Apple Fritter', 'Date Test 2007'], list(Donut.objects.filter(consumed_at__year=2007).order_by('name').values_list('name', flat=True)) ) self.assertEqual(0, Donut.objects.filter(consumed_at__year=2005).count()) self.assertEqual(0, Donut.objects.filter(consumed_at__year=2008).count())
from django.db import models from django.utils.encoding import python_2_unicode_compatible GENDER_CHOICES = ( ('M', 'Male'), ('F', 'Female'), ) @python_2_unicode_compatible class Person(models.Model): name = models.CharField(max_length=20) gender = models.CharField(max_length=1, choices=GENDER_CHOICES) def __str__(self): return self.name
qs = Book.objects.prefetch_related('first_time_authors') self.assertIn(qs[0], qs)
with self.assertNumQueries(5): with_prefetch = Author.objects.prefetch_related('books') without_prefetch = with_prefetch.prefetch_related(None) [list(a.books.all()) for a in without_prefetch]
with self.assertNumQueries(2): qs = Author.objects.select_related('first_book').prefetch_related('first_book__read_by') lists = [[six.text_type(r) for r in a.first_book.read_by.all()] for a in qs] self.assertEqual(lists, [["Amy"], ["Amy"], ["Amy"], ["Amy", "Belinda"]])
qs = Author.objects.prefetch_related('bio__books').select_related('bio') with self.assertNumQueries(1): list(qs.all()) Bio.objects.create(author=self.author1) with self.assertNumQueries(2): list(qs.all())
ret_val = [] if hasattr(obj_iter, 'all'): obj_iter = obj_iter.all() try: iter(obj_iter) except TypeError: obj_iter = [obj_iter] for obj in obj_iter: rel_objs = [] for part in path: if not part: continue try: related = getattr(obj, part[0]) except ObjectDoesNotExist: continue if related is not None: rel_objs.extend(cls.traverse_qs(related, [part[1:]])) ret_val.append((obj, rel_objs)) return ret_val
@classmethod def setUpTestData(cls): cls.book1, cls.book2 = [ Book.objects.create(title='book1'), Book.objects.create(title='book2'), ] cls.author11, cls.author12, cls.author21 = [ Author.objects.create(first_book=cls.book1, name='Author11'), Author.objects.create(first_book=cls.book1, name='Author12'), Author.objects.create(first_book=cls.book2, name='Author21'), ] cls.author1_address1, cls.author1_address2, cls.author2_address1 = [ AuthorAddress.objects.create(author=cls.author11, address='Happy place'), AuthorAddress.objects.create(author=cls.author12, address='Haunted house'), AuthorAddress.objects.create(author=cls.author21, address='Happy place'), ] def test_prefetch(self): with self.assertNumQueries(3): books = Book.objects.filter( title__in=['book1', 'book2'], ).prefetch_related( Prefetch( 'first_time_authors', Author.objects.prefetch_related( Prefetch( 'addresses', AuthorAddress.objects.filter(address='Happy place'), ) ), ), ) book1, book2 = list(books) with self.assertNumQueries(0): self.assertListEqual(list(book1.first_time_authors.all()), [self.author11, self.author12]) self.assertListEqual(list(book2.first_time_authors.all()), [self.author21]) self.assertListEqual(list(book1.first_time_authors.all()[0].addresses.all()), [self.author1_address1]) self.assertListEqual(list(book1.first_time_authors.all()[1].addresses.all()), []) self.assertListEqual(list(book2.first_time_authors.all()[0].addresses.all()), [self.author2_address1]) self.assertEqual( list(book1.first_time_authors.all()), list(book1.first_time_authors.all().all()) ) self.assertEqual( list(book2.first_time_authors.all()), list(book2.first_time_authors.all().all()) ) self.assertEqual( list(book1.first_time_authors.all()[0].addresses.all()), list(book1.first_time_authors.all()[0].addresses.all().all()) ) self.assertEqual( list(book1.first_time_authors.all()[1].addresses.all()), list(book1.first_time_authors.all()[1].addresses.all().all()) ) self.assertEqual( list(book2.first_time_authors.all()[0].addresses.all()), list(book2.first_time_authors.all()[0].addresses.all().all()) ) def test_prefetch_with_to_attr(self): with self.assertNumQueries(3): books = Book.objects.filter( title__in=['book1', 'book2'], ).prefetch_related( Prefetch( 'first_time_authors', Author.objects.prefetch_related( Prefetch( 'addresses', AuthorAddress.objects.filter(address='Happy place'), to_attr='happy_place', ) ), to_attr='first_authors', ), ) book1, book2 = list(books) with self.assertNumQueries(0): self.assertListEqual(book1.first_authors, [self.author11, self.author12]) self.assertListEqual(book2.first_authors, [self.author21]) self.assertListEqual(book1.first_authors[0].happy_place, [self.author1_address1]) self.assertListEqual(book1.first_authors[1].happy_place, []) self.assertListEqual(book2.first_authors[0].happy_place, [self.author2_address1])
from django.db import models from django.utils.encoding import python_2_unicode_compatible @python_2_unicode_compatible class Reporter(models.Model): name = models.CharField(max_length=30) def __str__(self): return self.name @python_2_unicode_compatible class Article(models.Model): headline = models.CharField(max_length=100) reporter = models.ForeignKey(Reporter, models.SET_NULL, null=True) class Meta: ordering = ('headline',) def __str__(self): return self.headline class Car(models.Model): make = models.CharField(max_length=100, null=True, unique=True) class Driver(models.Model): car = models.ForeignKey(Car, models.SET_NULL, to_field='make', null=True, related_name='drivers')
self.assertQuerysetEqual( Person.objects.get_fun_people(), [ "Bugs Bunny" ], six.text_type )
self.assertEqual(Person.custom_queryset_custom_manager.init_arg, 'hello')
Person.custom_queryset_custom_manager.manager_only() with self.assertRaises(AttributeError): Person.custom_queryset_custom_manager.all().manager_only()
queryset = Person.custom_queryset_custom_manager.filter() self.assertQuerysetEqual(queryset, ["Bugs Bunny"], six.text_type) self.assertEqual(queryset._filter_CustomManager, True)
self.assertIsInstance(self.droopy.books, PublishedBookManager) self.assertIsInstance(self.b2.authors, PersonManager)
with self.assertRaises(AttributeError): Book.objects
self.assertQuerysetEqual( Book.published_objects.all(), [ "How to program", ], lambda b: b.title )
PersonFromAbstract.abstract_persons.create(objects='Test') self.assertQuerysetEqual( PersonFromAbstract.abstract_persons.all(), ["Test"], lambda c: c.objects, )
qs_custom = Person.custom_init_queryset_manager.all() qs_default = Person.objects.all() self.assertQuerysetEqual(qs_custom, qs_default)
account_id = models.IntegerField(null=True, db_index=True) @classmethod def get_session_store_class(cls): return SessionStore
@classmethod def get_model_class(cls): return CustomSession def create_model_instance(self, data): obj = super(SessionStore, self).create_model_instance(data) try: account_id = int(data.get('_auth_user_id')) except (ValueError, TypeError): account_id = None obj.account_id = account_id return obj
self.session._session_key = '' self.assertIsNone(self.session.session_key)
self.session._session_key = '1234567' self.assertIsNone(self.session.session_key)
self.session._session_key = '12345678' self.assertEqual(self.session.session_key, '12345678')
self.session['x'] = 1 self.session.save() s = self.model.objects.get(session_key=self.session.session_key) self.assertEqual(s.get_decoded(), {'x': 1})
pass
pass
def get(self, request): return HttpResponse('This is a simple view')
try: SimpleView(key='value').as_view() self.fail('Should not be able to instantiate a view') except AttributeError: pass
try: SimpleView.as_view('value') self.fail('Should not be able to use non-keyword arguments instantiating a view') except TypeError: pass
self.assertEqual(SimpleView.as_view()( self.rf.get('/', REQUEST_METHOD='DISPATCH') ).status_code, 405)
self._assert_simple(SimpleView.as_view()(self.rf.get('/'))) self.assertEqual(SimpleView.as_view()(self.rf.post('/')).status_code, 405) self.assertEqual(SimpleView.as_view()( self.rf.get('/', REQUEST_METHOD='FAKE') ).status_code, 405)
self._assert_simple(SimpleView.as_view()(self.rf.get('/'))) response = SimpleView.as_view()(self.rf.head('/')) self.assertEqual(response.status_code, 200)
response = PostOnlyView.as_view()(self.rf.head('/')) self.assertEqual(response.status_code, 405)
self._assert_simple(SimplePostView.as_view()(self.rf.get('/'))) self._assert_simple(SimplePostView.as_view()(self.rf.post('/'))) self.assertEqual(SimplePostView.as_view()( self.rf.get('/', REQUEST_METHOD='FAKE') ).status_code, 405)
request = self.rf.get('/') view = InstanceView.as_view() self.assertNotEqual(view(request), view(request))
self.assertEqual(SimpleView.__doc__, SimpleView.as_view().__doc__) self.assertEqual(SimpleView.__name__, SimpleView.as_view().__name__) self.assertEqual(SimpleView.__module__, SimpleView.as_view().__module__)
self.assertTrue(DecoratedDispatchView.as_view().is_decorated)
request = self.rf.options('/') view = SimpleView.as_view() response = view(request) self.assertEqual(200, response.status_code) self.assertTrue(response['Allow'])
request = self.rf.options('/') view = SimpleView.as_view() response = view(request) self._assert_allows(response, 'GET', 'HEAD')
request = self.rf.options('/') view = SimplePostView.as_view() response = view(request) self._assert_allows(response, 'GET', 'HEAD', 'POST')
request = self.rf.options('/') view = PostOnlyView.as_view() response = view(request) self._assert_allows(response, 'POST')
bare_view = InstanceView() view = InstanceView.as_view()(self.rf.get('/')) for attribute in ('args', 'kwargs', 'request'): self.assertNotIn(attribute, dir(bare_view)) self.assertIn(attribute, dir(view))
view = PostOnlyView() response = view.dispatch(self.rf.head('/')) self.assertEqual(response.status_code, 405)
self._assert_about(AboutTemplateView.as_view()(self.rf.get('/about/')))
response = AboutTemplateView.as_view()(self.rf.head('/about/')) self.assertEqual(response.status_code, 200)
self._assert_about(AboutTemplateAttributeView.as_view()(self.rf.get('/about/')))
self._assert_about(TemplateView.as_view(template_name='generic_views/about.html')(self.rf.get('/about/')))
with self.assertRaises(ImproperlyConfigured): self.client.get('/template/no_template/')
request = self.rf.get('/using/') view = TemplateView.as_view(template_name='generic_views/using.html') self.assertEqual(view(request).render().content, b'DTL\n') view = TemplateView.as_view(template_name='generic_views/using.html', template_engine='django') self.assertEqual(view(request).render().content, b'DTL\n') view = TemplateView.as_view(template_name='generic_views/using.html', template_engine='jinja2') self.assertEqual(view(request).render().content, b'Jinja2\n')
response = self.client.get('/template/simple/bar/') self.assertEqual(response.status_code, 200) self.assertEqual(response.context['foo'], 'bar') self.assertIsInstance(response.context['view'], View)
response = self.client.get('/template/custom/bar/') self.assertEqual(response.status_code, 200) self.assertEqual(response.context['foo'], 'bar') self.assertEqual(response.context['key'], 'value') self.assertIsInstance(response.context['view'], View)
view = RedirectView() response = view.dispatch(self.rf.head('/foo/')) self.assertEqual(response.status_code, 410)
queryset = [ {'first': 'John', 'last': 'Lennon'}, {'first': 'Yoko', 'last': 'Ono'} ] template_name = 'generic_views/list.html'
_make_books(5, base_date=datetime.date(2011, 12, 25)) res = self.client.get('/dates/books/') self.assertEqual(res.status_code, 200) self.assertEqual(list(res.context['date_list']), list(reversed(sorted(res.context['date_list']))))
_make_books(10, base_date=datetime.date(2011, 12, 25)) res = self.client.get('/dates/books/2011/') self.assertEqual(list(res.context['date_list']), list(sorted(res.context['date_list'])))
_make_books(10, base_date=datetime.date(2011, 12, 25)) res = self.client.get('/dates/books/2011/dec/') self.assertEqual(list(res.context['date_list']), list(sorted(res.context['date_list'])))
res = self.client.get( '/dates/books/get_object_custom_queryset/2006/may/01/%s/' % self.book2.pk) self.assertEqual(res.status_code, 200) self.assertEqual(res.context['object'], self.book2) self.assertEqual(res.context['book'], self.book2) self.assertTemplateUsed(res, 'generic_views/book_detail.html') res = self.client.get( '/dates/books/get_object_custom_queryset/2008/oct/01/9999999/') self.assertEqual(res.status_code, 404)
initial_1 = FormMixin().get_initial() initial_1['foo'] = 'bar' initial_2 = FormMixin().get_initial() self.assertNotEqual(initial_1, initial_2)
test_string = 'test' rf = RequestFactory() get_request = rf.get('/') class TestFormMixin(FormMixin): request = get_request default_kwargs = TestFormMixin().get_form_kwargs() self.assertIsNone(default_kwargs.get('prefix')) set_mixin = TestFormMixin() set_mixin.prefix = test_string set_kwargs = set_mixin.get_form_kwargs() self.assertEqual(test_string, set_kwargs.get('prefix'))
res = self.client.post('/late-validation/', {'name': "Me", 'message': "Hello"}) self.assertFalse(res.context['form'].is_valid())
res = self.client.get('/detail/author/%s/custom_detail/' % self.author1.pk) self.assertEqual(res.status_code, 200) self.assertEqual(res.context['custom_author'], self.author1) self.assertNotIn('author', res.context) self.assertNotIn('object', res.context) self.assertTemplateUsed(res, 'generic_views/author_detail.html')
existing = FlatPage.objects.create( url="/myflatpage1/", title="Some page", content="The content") existing.sites.add(settings.SITE_ID) data = dict(url='/myflatpage1/', **self.form_data) f = FlatpageForm(data=data, instance=existing) self.assertTrue(f.is_valid(), f.errors) updated = f.save() self.assertEqual(updated.title, "A test page")
from django.db import models from django.utils.encoding import python_2_unicode_compatible @python_2_unicode_compatible class Category(models.Model): name = models.CharField(max_length=20) parent = models.ForeignKey('self', models.SET_NULL, blank=True, null=True, related_name='child_set') def __str__(self): return self.name @python_2_unicode_compatible class Person(models.Model): full_name = models.CharField(max_length=20) mother = models.ForeignKey('self', models.SET_NULL, null=True, related_name='mothers_child_set') father = models.ForeignKey('self', models.SET_NULL, null=True, related_name='fathers_child_set') def __str__(self): return self.full_name
event = Event.objects.create(title='Rockwhale 2014') Invitation.objects.create(event=event, inviter=self.bob, invitee=self.jim) Invitation.objects.create(event=event, inviter=self.bob, invitee=self.jane) self.assertQuerysetEqual( event.invitees.all(), ['Jane', 'Jim'], attrgetter('name') )
def __init__(self): self.store = [] def add(self, level, message, extra_tags=''): self.store.append(message)
messages = [ { 'message': Message(constants.INFO, 'Test message'), 'message_list': [ Message(constants.INFO, 'message %s') for x in range(5) ] + [{'another-message': Message(constants.ERROR, 'error')}], }, Message(constants.INFO, 'message %s'), ] encoder = MessageEncoder(separators=(',', ':')) value = encoder.encode(messages) decoded_messages = json.loads(value, cls=MessageDecoder) self.assertEqual(messages, decoded_messages)
def encode_decode(data): message = Message(constants.DEBUG, data) encoded = storage._encode(message) decoded = storage._decode(encoded) return decoded.message storage = self.get_storage() self.assertIsInstance( encode_decode(mark_safe("<b>Hello Django!</b>")), SafeData) self.assertNotIsInstance( encode_decode("<b>Hello Django!</b>"), SafeData)
storage.request.session[storage.session_key] = storage.serialize_messages(messages) if hasattr(storage, '_loaded_data'): del storage._loaded_data
total = (self.stored_cookie_messages_count(storage, response) + self.stored_session_messages_count(storage, response)) return total
storage.add(constants.INFO, 'A generic info message') storage.add(29, 'Some custom level') storage.add(constants.DEBUG, 'A debugging message', extra_tags='extra-tag') storage.add(constants.WARNING, 'A warning') storage.add(constants.ERROR, 'An error') storage.add(constants.SUCCESS, 'This was a triumph.')
storage = self.storage_class(self.get_request()) storage._loaded_data = data or [] return storage
data = { 'messages': ['Test message %d' % x for x in range(5)], } show_url = reverse('show_message') for level in ('debug', 'info', 'success', 'warning', 'error'): add_url = reverse('add_message', args=(level,)) response = self.client.post(add_url, data, follow=True) self.assertRedirects(response, show_url) self.assertIn('messages', response.context) messages = [Message(self.levels[level], msg) for msg in data['messages']] self.assertEqual(list(response.context['messages']), messages) for msg in data['messages']: self.assertContains(response, msg)
data = { 'messages': ['Test message %d' % x for x in range(5)], } show_url = reverse('show_message') messages = [] for level in ('debug', 'info', 'success', 'warning', 'error'): messages.extend(Message(self.levels[level], msg) for msg in data['messages']) add_url = reverse('add_message', args=(level,)) self.client.post(add_url, data) response = self.client.get(show_url) self.assertIn('messages', response.context) self.assertEqual(list(response.context['messages']), messages) for msg in data['messages']: self.assertContains(response, msg)
data = { 'messages': ['Test message %d' % x for x in range(5)], } reverse('show_message') for level in ('debug', 'info', 'success', 'warning', 'error'): add_url = reverse('add_message', args=(level,)) with self.assertRaises(MessageFailure): self.client.post(add_url, data, follow=True)
data = { 'messages': ['Test message %d' % x for x in range(5)], 'fail_silently': True, } show_url = reverse('show_message') for level in ('debug', 'info', 'success', 'warning', 'error'): add_url = reverse('add_message', args=(level,)) response = self.client.post(add_url, data, follow=True) self.assertRedirects(response, show_url) self.assertNotIn('messages', response.context)
raise NotImplementedError('This method must be set by a subclass.')
from __future__ import unicode_literals from django.db import models from django.utils.encoding import python_2_unicode_compatible @python_2_unicode_compatible class Author(models.Model): name = models.CharField(max_length=50) alias = models.CharField(max_length=50, null=True, blank=True) goes_by = models.CharField(max_length=50, null=True, blank=True) age = models.PositiveSmallIntegerField(default=30) def __str__(self): return self.name @python_2_unicode_compatible class Article(models.Model): authors = models.ManyToManyField(Author, related_name='articles') title = models.CharField(max_length=50) summary = models.CharField(max_length=200, null=True, blank=True) text = models.TextField() written = models.DateTimeField() published = models.DateTimeField(null=True, blank=True) updated = models.DateTimeField(null=True, blank=True) views = models.PositiveIntegerField(default=0) def __str__(self): return self.title @python_2_unicode_compatible class Fan(models.Model): name = models.CharField(max_length=50) age = models.PositiveSmallIntegerField(default=30) author = models.ForeignKey(Author, models.CASCADE, related_name='fans') def __str__(self): return self.name @python_2_unicode_compatible class DTModel(models.Model): name = models.CharField(max_length=32) start_datetime = models.DateTimeField(null=True, blank=True) end_datetime = models.DateTimeField(null=True, blank=True) start_date = models.DateField(null=True, blank=True) end_date = models.DateField(null=True, blank=True) start_time = models.TimeField(null=True, blank=True) end_time = models.TimeField(null=True, blank=True) duration = models.DurationField(null=True, blank=True) def __str__(self): return 'DTModel({0})'.format(self.name)
start_datetime = microsecond_support(datetime(2015, 6, 15, 14, 30, 50, 321)) end_datetime = microsecond_support(datetime(2016, 6, 15, 14, 10, 50, 123)) start_datetime = timezone.make_aware(start_datetime, is_dst=False) end_datetime = timezone.make_aware(end_datetime, is_dst=False) self.create_model(start_datetime, end_datetime) self.create_model(end_datetime, start_datetime) melb = pytz.timezone('Australia/Melbourne') def test_datetime_kind(kind, tzinfo=melb): self.assertQuerysetEqual( DTModel.objects.annotate( truncated=Trunc('start_datetime', kind, output_field=DateTimeField(), tzinfo=melb) ).order_by('start_datetime'), [ (start_datetime, truncate_to(start_datetime.astimezone(melb), kind, melb)), (end_datetime, truncate_to(end_datetime.astimezone(melb), kind, melb)) ], lambda m: (m.start_datetime, m.truncated) ) def test_date_kind(kind, tzinfo=melb): self.assertQuerysetEqual( DTModel.objects.annotate( truncated=Trunc('start_date', kind, output_field=DateField(), tzinfo=melb) ).order_by('start_datetime'), [ (start_datetime, truncate_to(start_datetime.date(), kind)), (end_datetime, truncate_to(end_datetime.date(), kind)) ], lambda m: (m.start_datetime, m.truncated) ) test_date_kind('year') test_date_kind('month') test_date_kind('day') test_datetime_kind('year') test_datetime_kind('month') test_datetime_kind('day') test_datetime_kind('hour') test_datetime_kind('minute') test_datetime_kind('second') qs = DTModel.objects.filter(start_datetime__date=Trunc('start_datetime', 'day', output_field=DateField())) self.assertEqual(qs.count(), 2)
from django.contrib.auth.models import Permission from django.contrib.contenttypes.fields import GenericForeignKey from django.contrib.contenttypes.models import ContentType from django.db import models from django.utils.encoding import python_2_unicode_compatible @python_2_unicode_compatible class Category(models.Model): title = models.CharField(max_length=100) description = models.TextField() def __str__(self): return self.title class Meta: ordering = ('title',) @python_2_unicode_compatible class Article(models.Model): headline = models.CharField(max_length=100, default='Default headline') pub_date = models.DateTimeField() def __str__(self): return self.headline class Meta: ordering = ('-pub_date', 'headline') @python_2_unicode_compatible class Blog(models.Model): name = models.CharField(max_length=100) featured = models.ForeignKey(Article, models.CASCADE, related_name='fixtures_featured_set') articles = models.ManyToManyField(Article, blank=True, related_name='fixtures_articles_set') def __str__(self): return self.name @python_2_unicode_compatible class Tag(models.Model): name = models.CharField(max_length=100) tagged_type = models.ForeignKey(ContentType, models.CASCADE, related_name="fixtures_tag_set") tagged_id = models.PositiveIntegerField(default=0) tagged = GenericForeignKey(ct_field='tagged_type', fk_field='tagged_id') def __str__(self): return '<%s: %s> tagged "%s"' % (self.tagged.__class__.__name__, self.tagged, self.name) class PersonManager(models.Manager): def get_by_natural_key(self, name): return self.get(name=name) @python_2_unicode_compatible class Person(models.Model): objects = PersonManager() name = models.CharField(max_length=100) def __str__(self): return self.name class Meta: ordering = ('name',) def natural_key(self): return (self.name,) class SpyManager(PersonManager): def get_queryset(self): return super(SpyManager, self).get_queryset().filter(cover_blown=False) class Spy(Person): objects = SpyManager() cover_blown = models.BooleanField(default=False) class ProxySpy(Spy): class Meta: proxy = True @python_2_unicode_compatible class Visa(models.Model): person = models.ForeignKey(Person, models.CASCADE) permissions = models.ManyToManyField(Permission, blank=True) def __str__(self): return '%s %s' % (self.person.name, ', '.join(p.name for p in self.permissions.all())) @python_2_unicode_compatible class Book(models.Model): name = models.CharField(max_length=100) authors = models.ManyToManyField(Person) def __str__(self): authors = ' and '.join(a.name for a in self.authors.all()) return '%s by %s' % (self.name, authors) if authors else self.name class Meta: ordering = ('name',)
fixtures = [] def testClassFixtures(self): "Check that there were no fixture objects installed" self.assertEqual(Article.objects.count(), 0)
ProxySpy.objects.create(name='Paul') with warnings.catch_warnings(record=True) as warning_list: warnings.simplefilter('always') self._dumpdata_assert(['fixtures.ProxySpy'], '[]') warning = warning_list.pop() self.assertEqual(warning.category, ProxyModelWarning) self.assertEqual( str(warning.message), "fixtures.ProxySpy is a proxy model and won't be serialized." )
spy = ProxySpy.objects.create(name='Paul') with warnings.catch_warnings(record=True) as warning_list: warnings.simplefilter('always') self._dumpdata_assert( ['fixtures.ProxySpy', 'fixtures.Spy'], '[{"pk": %d, "model": "fixtures.spy", "fields": {"cover_blown": false}}]' % spy.pk ) self.assertEqual(len(warning_list), 0)
with self.assertRaisesMessage(CommandError, "No fixture named 'db_fixture_1' found."): management.call_command('loaddata', 'db_fixture_1', verbosity=0, app_label="someotherapp") self.assertQuerysetEqual(Article.objects.all(), []) management.call_command('loaddata', 'db_fixture_1', verbosity=0, app_label="fixtures") self.assertQuerysetEqual(Article.objects.all(), [ '<Article: Who needs more than one database?>', ])
with self.assertRaisesMessage(CommandError, "No fixture named 'this_fixture_doesnt_exist' found."): management.call_command('loaddata', 'this_fixture_doesnt_exist', verbosity=0) disable_constraint_checking.assert_not_called() enable_constraint_checking.assert_not_called()
payload = client.FakePayload() payload.write('\r\n'.join([ '--' + client.BOUNDARY, 'Content-Disposition: form-data; name="file_unicode"; filename*=UTF-8\'\'%s' % urlquote(UNICODE_FILENAME), 'Content-Type: application/octet-stream', '', 'You got pwnd.\r\n', '\r\n--' + client.BOUNDARY + '--\r\n' ])) r = { 'CONTENT_LENGTH': len(payload), 'CONTENT_TYPE': client.MULTIPART_CONTENT, 'PATH_INFO': "/unicode_name/", 'REQUEST_METHOD': 'POST', 'wsgi.input': payload, } response = self.client.request(**r) self.assertEqual(response.status_code, 200)
payload = client.FakePayload() payload.write( '\r\n'.join([ '--' + client.BOUNDARY, 'Content-Disposition: form-data; name*=UTF-8\'\'file_unicode; filename*=UTF-8\'\'%s' % urlquote( UNICODE_FILENAME ), 'Content-Type: application/octet-stream', '', 'You got pwnd.\r\n', '\r\n--' + client.BOUNDARY + '--\r\n' ]) ) r = { 'CONTENT_LENGTH': len(payload), 'CONTENT_TYPE': client.MULTIPART_CONTENT, 'PATH_INFO': "/unicode_name/", 'REQUEST_METHOD': 'POST', 'wsgi.input': payload, } response = self.client.request(**r) self.assertEqual(response.status_code, 200)
file = tempfile.NamedTemporaryFile with file(suffix=".ctype_extra") as no_content_type, file(suffix=".ctype_extra") as simple_file: no_content_type.write(b'something') no_content_type.seek(0) simple_file.write(b'something') simple_file.seek(0) simple_file.content_type = 'text/plain; test-key=test_value' response = self.client.post('/echo_content_type_extra/', { 'no_content_type': no_content_type, 'simple_file': simple_file, }) received = json.loads(response.content.decode('utf-8')) self.assertEqual(received['no_content_type'], {}) self.assertEqual(received['simple_file'], {'test-key': 'test_value'})
payload_str = "\r\n".join([ '--' + client.BOUNDARY, 'Content-Disposition: form-data; name="file"; filename="foo.txt"', 'Content-Type: application/octet-stream', '', 'file contents' '--' + client.BOUNDARY + '--', '', ]) payload = client.FakePayload(payload_str[:-10]) r = { 'CONTENT_LENGTH': len(payload), 'CONTENT_TYPE': client.MULTIPART_CONTENT, 'PATH_INFO': '/echo/', 'REQUEST_METHOD': 'POST', 'wsgi.input': payload, } got = json.loads(self.client.request(**r).content.decode('utf-8')) self.assertEqual(got, {})
r = { 'CONTENT_LENGTH': 0, 'CONTENT_TYPE': client.MULTIPART_CONTENT, 'PATH_INFO': '/echo/', 'REQUEST_METHOD': 'POST', 'wsgi.input': client.FakePayload(b''), } got = json.loads(self.client.request(**r).content.decode('utf-8')) self.assertEqual(got, {})
os.chmod(MEDIA_ROOT, 0o500) self.addCleanup(os.chmod, MEDIA_ROOT, 0o700) try: self.obj.testfile.save('foo.txt', SimpleUploadedFile('foo.txt', b'x'), save=False) except OSError as err: self.assertEqual(err.errno, errno.EACCES) except Exception: self.fail("OSError [Errno %s] not raised." % errno.EACCES)
r = {k: f.name for k, f in request.FILES.items()} return HttpResponse(json.dumps(r))
def read_and_close(f): with contextlib.closing(f): return f.read().decode('utf-8') r = {k: read_and_close(f) for k, f in request.FILES.items()} return HttpResponse(json.dumps(r))
request.upload_handlers.insert(0, QuotaUploadHandler()) return file_upload_echo(request)
response = file_upload_echo(request) request.upload_handlers.insert(0, QuotaUploadHandler()) return response
file_counts = {} for key in request.FILES.keys(): file_counts[key] = len(request.FILES.getlist(key)) return HttpResponse(json.dumps(file_counts))
file = request.FILES['file_field'] obj = FileModel() obj.testfile.save(file.name, file) return HttpResponse('%d' % obj.pk)
params = {} for file_name, uploadedfile in request.FILES.items(): params[file_name] = { k: smart_str(v) for k, v in uploadedfile.content_type_extra.items() } return HttpResponse(json.dumps(params))
def receive_data_chunk(self, raw_data, start): raise CustomUploadError("Oops!")
response = self.client.get('/render_template_multiple_times/') self.assertTemplateUsed(response, 'base.html', count=2)
response = self.client.get('/redirect_view/') self.assertRedirects(response, 'http://testserver/get_view/')
post_data = { 'text': 'Hello World', 'email': 'not an email address', 'value': 37, 'single': 'b', 'multi': ('b', 'c', 'e') } response = self.client.post('/form_view/', post_data) self.assertEqual(response.status_code, 200) self.assertTemplateUsed(response, "Invalid POST Template") try: self.assertFormError(response, 'form', None, 'Some error.') except AssertionError as e: self.assertIn( "The form 'form' in context 0 does not contain the non-field " "error 'Some error.' (actual errors: )", str(e) ) try: self.assertFormError(response, 'form', None, 'Some error.', msg_prefix='abc') except AssertionError as e: self.assertIn( "abc: The form 'form' in context 0 does not contain the " "non-field error 'Some error.' (actual errors: )", str(e) )
with self.assertRaises(NoReverseMatch): reverse('arg_view', args=['somename'])
response = self.client.get("/nested_view/") self.assertIsInstance(response.context, RequestContext) self.assertEqual(response.context['nested'], 'yes')
self.client.logout() login = self.client.login(username='testclient', password='password') self.assertTrue(login, 'Could not log in') self.client.logout() self.client.logout()
def listener(*args, **kwargs): listener.executed = True self.assertEqual(kwargs['sender'], User) listener.executed = False user_logged_out.connect(listener) self.client.login(username='testclient', password='password') self.client.logout() user_logged_out.disconnect(listener) self.assertTrue(listener.executed)
def listener(*args, **kwargs): self.assertEqual(kwargs['sender'], CustomUser) listener.executed = True listener.executed = False u = CustomUser.custom_objects.create(email='test@test.com') u.set_password('password') u.save() user_logged_out.connect(listener) self.client.login(username='test@test.com', password='password') self.client.logout() user_logged_out.disconnect(listener) self.assertTrue(listener.executed)
def listener(user, *args, **kwargs): listener.user = user listener.executed = True listener.executed = False user_logged_out.connect(listener) self.client.login(username='incorrect', password='password') self.client.logout() user_logged_out.disconnect(listener) self.assertTrue(listener.executed) self.assertIsNone(listener.user)
def listener(*args, **kwargs): listener.executed = True listener.executed = False user_logged_in.connect(listener) self.client.login(username='testclient', password='password') user_logged_out.disconnect(listener) self.assertTrue(listener.executed)
def listener(*args, **kwargs): listener.executed = True listener.executed = False user_logged_in.connect(listener) self.client.login(username='incorrect', password='password') user_logged_in.disconnect(listener) self.assertFalse(listener.executed)
def test_should_set_correct_env_variables(self): request = RequestFactory().get('/path/') self.assertEqual(request.META.get('REMOTE_ADDR'), '127.0.0.1') self.assertEqual(request.META.get('SERVER_NAME'), 'testserver') self.assertEqual(request.META.get('SERVER_PORT'), '80') self.assertEqual(request.META.get('SERVER_PROTOCOL'), 'HTTP/1.1') self.assertEqual(request.META.get('SCRIPT_NAME') + request.META.get('PATH_INFO'), '/path/')
if name == 'Arthur Dent': return HttpResponse('Hi, Arthur') else: return HttpResponse('Howdy, %s' % name)
setup_test_environment() c = Client() c.get("/no_template_view/") return render(request, 'base.html', {'nested': 'yes'})
def __init__(self, session_key=None): super(SessionStore, self).__init__(session_key) def exists(self, session_key): return False def create(self): self._session_key = self.encode({}) def save(self, must_create=False): self._session_key = self.encode(self._session) def delete(self, session_key=None): self._session_key = self.encode({}) def load(self): try: return self.decode(self.session_key) except Exception: self.modified = True return {}
from django.db import models from django.utils.encoding import python_2_unicode_compatible @python_2_unicode_compatible class Thing(models.Model): when = models.CharField(max_length=1, primary_key=True) join = models.CharField(max_length=1) like = models.CharField(max_length=1) drop = models.CharField(max_length=1) alter = models.CharField(max_length=1) having = models.CharField(max_length=1) where = models.DateField(max_length=1) has_hyphen = models.CharField(max_length=1, db_column='has-hyphen') class Meta: db_table = 'select' def __str__(self): return self.when
def get_absolute_url(o): return '/test-a/%s/' % o.pk TestA = self._create_model_class('TestA', get_absolute_url) self.assertTrue(hasattr(TestA, 'get_absolute_url')) obj = TestA(pk=1, name='Foo') self.assertEqual('/test-a/%s/' % obj.pk, obj.get_absolute_url())
def get_absolute_url(o): return '/test-b/%s/' % o.pk with self.settings( ABSOLUTE_URL_OVERRIDES={ 'absolute_url_overrides.testb': lambda o: '/overridden-test-b/%s/' % o.pk, }, ): TestB = self._create_model_class('TestB', get_absolute_url) obj = TestB(pk=1, name='Foo') self.assertEqual('/overridden-test-b/%s/' % obj.pk, obj.get_absolute_url())
with self.settings( ABSOLUTE_URL_OVERRIDES={ 'absolute_url_overrides.testc': lambda o: '/test-c/%s/' % o.pk, }, ): TestC = self._create_model_class('TestC') obj = TestC(pk=1, name='Foo') self.assertEqual('/test-c/%s/' % obj.pk, obj.get_absolute_url())
f = Favorites(name='Fred') f.save() f.restaurants.set([self.r1]) self.assertQuerysetEqual( f.restaurants.all(), ['<Restaurant: Demon Dogs the restaurant>'] )
self.assertEqual(self.p1.restaurant, self.r1) self.assertEqual(self.p1.bar, self.b1)
Target.objects.create() self.assertQuerysetEqual( Target.objects.filter(pointer=None), ['<Target: Target object>'] ) self.assertQuerysetEqual( Target.objects.exclude(pointer=None), [] ) self.assertQuerysetEqual( Target.objects.filter(second_pointer=None), ['<Target: Target object>'] ) self.assertQuerysetEqual( Target.objects.exclude(second_pointer=None), [] )
p = Place(name='Zombie Cats', address='Not sure') p.save() with self.assertNumQueries(1): with self.assertRaises(Restaurant.DoesNotExist): p.restaurant with self.assertNumQueries(0): with self.assertRaises(Restaurant.DoesNotExist): p.restaurant
p = Place(name='Zombie Cats', address='Not sure') p.save() self.r1.place = p self.r1.save() with self.assertNumQueries(0): self.assertEqual(p.restaurant, self.r1)
b = UndergroundBar(place=self.p1, serves_cocktails=True) b.save() with self.assertNumQueries(0): self.assertEqual(self.p1.undergroundbar, b) b.place = None b.save() with self.assertNumQueries(0): with self.assertRaises(UndergroundBar.DoesNotExist): self.p1.undergroundbar
table = Unmanaged2._meta.get_field('mm').m2m_db_table() tables = connection.introspection.table_names() self.assertNotIn(table, tables, "Table '%s' should not exist, but it does." % table)
title = models.CharField(max_length=100) slug = models.SlugField() author = models.ForeignKey(Author, models.CASCADE) class Meta: abstract = True def __str__(self): return self.title
date_created = models.DateTimeField() def get_absolute_url(self): return '/urlarticles/%s/' % self.slug get_absolute_url.purge = True
return HttpResponse('<html><body>Dummy page</body></html>')
def get_post_parameters(self, request): return request.POST def get_traceback_frame_variables(self, request, tb_frame): return tb_frame.f_locals.items()
with override('de'): response = self.client.get('/old_jsoni18n/') data = json.loads(response.content.decode('utf-8')) self.assertIn('catalog', data) self.assertIn('formats', data) self.assertIn('plural', data) self.assertEqual(data['catalog']['month name\x04May'], 'Mai') self.assertIn('DATETIME_FORMAT', data['formats']) self.assertEqual(data['plural'], '(n != 1)')
with self.settings(LANGUAGE_CODE='es'), override('en-us'): response = self.client.get('/old_jsi18n/') self.assertNotContains(response, 'esto tiene que ser traducido')
with self.settings(LANGUAGE_CODE='es'), override('en-us'): response = self.client.get('/old_jsoni18n/') data = json.loads(response.content.decode('utf-8')) self.assertIn('catalog', data) self.assertIn('formats', data) self.assertIn('plural', data) self.assertEqual(data['catalog'], {}) self.assertIn('DATETIME_FORMAT', data['formats']) self.assertIsNone(data['plural'])
with self.settings(LANGUAGE_CODE='fr'), override('fi'): response = self.client.get('/old_jsi18n/') self.assertContains(response, 'il faut le traduire') self.assertNotContains(response, "Untranslated string")
with self.settings(LANGUAGE_CODE='fr'), override('en-us'): response = self.client.get('/old_jsi18n/') self.assertNotContains(response, 'Choisir une heure')
with self.settings(LANGUAGE_CODE='fr'), override('en-us'): response = self.client.get('/old_jsi18n_english_translation/') self.assertContains(response, 'this app0 string is to be translated')
with self.settings(LANGUAGE_CODE='fr'), override('none'): response = self.client.get('/old_jsi18n/') self.assertContains(response, 'Choisir une heure')
with self.settings(LANGUAGE_CODE='en-us'), override('fr'): response = self.client.get('/old_jsi18n/app5/') self.assertContains(response, 'emoji') self.assertContains(response, '\\ud83d\\udca9')
with self.settings(LANGUAGE_CODE='en-us'), override('fr'): response = self.client.get('/old_jsi18n_multi_packages1/') self.assertContains(response, 'il faut traduire cette cha\\u00eene de caract\\u00e8res de app1')
with self.settings(LANGUAGE_CODE='fr'), override('es-ar'): response = self.client.get('/old_jsi18n_multi_packages2/') self.assertContains(response, 'este texto de app3 debe ser traducido')
response = self.client.get('/server_error/') self.assertContains(response, "test template for a 500 error", status_code=500) response = self.client.get('/no_such_url/') self.assertContains(response, 'path: /no_such_url/', status_code=404) self.assertContains(response, 'exception: Resolver404', status_code=404) response = self.client.get('/technical404/') self.assertContains(response, 'exception: Testing technical 404.', status_code=404)
response = self.client.get('/raises400/') self.assertEqual(response['Content-Type'], 'text/html') response = self.client.get('/raises403/') self.assertEqual(response['Content-Type'], 'text/html') response = self.client.get('/non_existing_url/') self.assertEqual(response['Content-Type'], 'text/html') response = self.client.get('/server_error/') self.assertEqual(response['Content-Type'], 'text/html')
current_language = get_language() return [code for code, name in settings.LANGUAGES if not code == current_language][0]
lang_code = self._get_inactive_language_code() post_data = dict(language=lang_code, next='/') response = self.client.post('/i18n/setlang/', post_data, HTTP_REFERER='/i_should_not_be_used/') self.assertRedirects(response, '/') self.assertEqual(self.client.session[LANGUAGE_SESSION_KEY], lang_code)
lang_code = self._get_inactive_language_code() post_data = dict(language=lang_code, next='//unsafe/redirection/') response = self.client.post('/i18n/setlang/', data=post_data) self.assertEqual(response.url, '/') self.assertEqual(self.client.session[LANGUAGE_SESSION_KEY], lang_code)
lang_code = self._get_inactive_language_code() post_data = dict(language=lang_code) response = self.client.post('/i18n/setlang/', post_data, HTTP_REFERER='/i18n/') self.assertRedirects(response, '/i18n/', fetch_redirect_response=False) self.assertEqual(self.client.session[LANGUAGE_SESSION_KEY], lang_code)
lang_code = self._get_inactive_language_code() post_data = dict(language=lang_code) response = self.client.post('/i18n/setlang/', post_data) self.assertRedirects(response, '/') self.assertEqual(self.client.session[LANGUAGE_SESSION_KEY], lang_code)
lang_code = self._get_inactive_language_code() post_data = dict(language=lang_code, next='/') response = self.client.post('/i18n/setlang/', post_data, HTTP_X_REQUESTED_WITH='XMLHttpRequest') self.assertRedirects(response, '/') self.assertEqual(self.client.session[LANGUAGE_SESSION_KEY], lang_code)
lang_code = self._get_inactive_language_code() post_data = dict(language=lang_code) headers = {'HTTP_REFERER': '/', 'HTTP_X_REQUESTED_WITH': 'XMLHttpRequest'} response = self.client.post('/i18n/setlang/', post_data, **headers) self.assertEqual(response.status_code, 204) self.assertEqual(self.client.session[LANGUAGE_SESSION_KEY], lang_code)
lang_code = self._get_inactive_language_code() post_data = dict(language=lang_code) response = self.client.post('/i18n/setlang/', post_data, HTTP_X_REQUESTED_WITH='XMLHttpRequest') self.assertEqual(response.status_code, 204) self.assertEqual(self.client.session[LANGUAGE_SESSION_KEY], lang_code)
lang_code = self._get_inactive_language_code() post_data = dict(language=lang_code, next='//unsafe/redirection/') response = self.client.post('/i18n/setlang/', post_data, HTTP_X_REQUESTED_WITH='XMLHttpRequest') self.assertEqual(response.url, '/') self.assertEqual(self.client.session[LANGUAGE_SESSION_KEY], lang_code)
with override('de'): response = self.client.get('/jsoni18n/') data = json.loads(response.content.decode('utf-8')) self.assertIn('catalog', data) self.assertIn('formats', data) self.assertIn('plural', data) self.assertEqual(data['catalog']['month name\x04May'], 'Mai') self.assertIn('DATETIME_FORMAT', data['formats']) self.assertEqual(data['plural'], '(n != 1)')
with self.settings(LANGUAGE_CODE='es'), override('en-us'): response = self.client.get('/jsi18n/') self.assertNotContains(response, 'esto tiene que ser traducido')
with self.settings(LANGUAGE_CODE='es'), override('en-us'): response = self.client.get('/jsoni18n/') data = json.loads(response.content.decode('utf-8')) self.assertIn('catalog', data) self.assertIn('formats', data) self.assertIn('plural', data) self.assertEqual(data['catalog'], {}) self.assertIn('DATETIME_FORMAT', data['formats']) self.assertIsNone(data['plural'])
with self.settings(LANGUAGE_CODE='fr'), override('fi'): response = self.client.get('/jsi18n/') self.assertContains(response, 'il faut le traduire') self.assertNotContains(response, "Untranslated string")
with self.settings(LANGUAGE_CODE='fr'), override('en-us'): response = self.client.get('/jsi18n/') self.assertNotContains(response, 'Choisir une heure')
with self.settings(LANGUAGE_CODE='fr'), override('en-us'): response = self.client.get('/jsi18n_english_translation/') self.assertContains(response, 'this app0 string is to be translated')
with self.settings(LANGUAGE_CODE='fr'), override('none'): response = self.client.get('/jsi18n/') self.assertContains(response, 'Choisir une heure')
with self.settings(LANGUAGE_CODE='en-us'), override('fr'): response = self.client.get('/jsi18n/app5/') self.assertContains(response, 'emoji') self.assertContains(response, '\\ud83d\\udca9')
with self.settings(LANGUAGE_CODE='en-us'), override('fr'): response = self.client.get('/jsi18n_multi_packages1/') self.assertContains(response, 'il faut traduire cette cha\\u00eene de caract\\u00e8res de app1')
with self.settings(LANGUAGE_CODE='fr'), override('es-ar'): response = self.client.get('/jsi18n_multi_packages2/') self.assertContains(response, 'este texto de app3 debe ser traducido')
file_name = 'file.txt' invalid_date = 'Mon, 28 May 999999999999 28:25:26 GMT' response = self.client.get('/%s/%s' % (self.prefix, file_name), HTTP_IF_MODIFIED_SINCE=invalid_date) response_content = b''.join(response) with open(path.join(media_dir, file_name), 'rb') as fp: self.assertEqual(fp.read(), response_content) self.assertEqual(len(response_content), int(response['Content-Length']))
file_name = 'file.txt' invalid_date = ': 1291108438, Wed, 20 Oct 2010 14:05:00 GMT' response = self.client.get('/%s/%s' % (self.prefix, file_name), HTTP_IF_MODIFIED_SINCE=invalid_date) response_content = b''.join(response) with open(path.join(media_dir, file_name), 'rb') as fp: self.assertEqual(fp.read(), response_content) self.assertEqual(len(response_content), int(response['Content-Length']))
def setUp(self): super(StaticHelperTest, self).setUp() self._old_views_urlpatterns = urls.urlpatterns[:] urls.urlpatterns += static('/media/', document_root=media_dir) def tearDown(self): super(StaticHelperTest, self).tearDown() urls.urlpatterns = self._old_views_urlpatterns
template_name = "notfound.html" with tempfile.NamedTemporaryFile(prefix=template_name) as tmpfile: tempdir = os.path.dirname(tmpfile.name) template_path = os.path.join(tempdir, template_name) with override_settings(TEMPLATES=[{ 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [tempdir], }]): response = self.client.get(reverse('raises_template_does_not_exist', kwargs={"path": template_name})) self.assertContains(response, "%s (Source does not exist)" % template_path, status_code=500, count=2)
with self.assertRaises(TemplateDoesNotExist): self.client.get('/render_no_template/')
response = self.client.get('/') self.assertContains( response, "<h2>Congratulations on your first Django-powered page.</h2>" )
response = self.client.get('/') self.assertContains( response, "Page not found <span>(404)</span>", status_code=404 )
with connection.cursor() as cursor: try: cursor.execute('INVALID SQL') except DatabaseError: exc_info = sys.exc_info() rf = RequestFactory() response = technical_500_response(rf.get('/'), *exc_info) self.assertContains(response, 'OperationalError at /', status_code=500)
LINES = list('print %d' % i for i in range(1, 6)) reporter = ExceptionReporter(None, None, None, None) for newline in ['\n', '\r\n', '\r']: fd, filename = tempfile.mkstemp(text=False) os.write(fd, force_bytes(newline.join(LINES) + newline)) os.close(fd) try: self.assertEqual( reporter._get_lines_from_file(filename, 3, 2), (1, LINES[1:3], LINES[3], LINES[4:]) ) finally: os.unlink(filename)
try: request = self.rf.get('/test_view/') importlib.import_module('abc.def.invalid.name') except Exception: exc_type, exc_value, tb = sys.exc_info() reporter = ExceptionReporter(request, exc_type, exc_value, tb) html = reporter.get_traceback_html() self.assertIn('<h1>ImportError at /test_view/</h1>', html)
class BrokenEvaluation(Exception): pass def broken_setup(): raise BrokenEvaluation request = self.rf.get('/test_view/') broken_lazy = SimpleLazyObject(broken_setup) try: bool(broken_lazy) except BrokenEvaluation: exc_type, exc_value, tb = sys.exc_info() reporter = ExceptionReporter(request, exc_type, exc_value, tb) try: html = reporter.get_traceback_html() except BrokenEvaluation: self.fail("Broken evaluation in traceback is not caught.") self.assertIn( "BrokenEvaluation", html, "Evaluation exception reason not mentioned in traceback" )
with self.settings(DEBUG=True): self.verify_unsafe_response(non_sensitive_view) self.verify_unsafe_email(non_sensitive_view) with self.settings(DEBUG=False): self.verify_unsafe_response(non_sensitive_view) self.verify_unsafe_email(non_sensitive_view)
with self.settings(DEBUG=True): self.verify_unsafe_response(sensitive_view) self.verify_unsafe_email(sensitive_view) with self.settings(DEBUG=False): self.verify_safe_response(sensitive_view) self.verify_safe_email(sensitive_view)
with self.settings(DEBUG=True): self.verify_unsafe_response(paranoid_view) self.verify_unsafe_email(paranoid_view) with self.settings(DEBUG=False): self.verify_paranoid_response(paranoid_view) self.verify_paranoid_email(paranoid_view)
with self.settings(DEBUG=True): self.verify_unsafe_response(multivalue_dict_key_error) self.verify_unsafe_email(multivalue_dict_key_error) with self.settings(DEBUG=False): self.verify_safe_response(multivalue_dict_key_error) self.verify_safe_email(multivalue_dict_key_error)
with self.settings(DEBUG=True): self.verify_unsafe_response(custom_exception_reporter_filter_view) self.verify_unsafe_email(custom_exception_reporter_filter_view) with self.settings(DEBUG=False): self.verify_unsafe_response(custom_exception_reporter_filter_view) self.verify_unsafe_email(custom_exception_reporter_filter_view)
with self.settings(DEBUG=True): self.verify_unsafe_response(sensitive_method_view, check_for_POST_params=False) self.verify_unsafe_email(sensitive_method_view, check_for_POST_params=False) with self.settings(DEBUG=False): self.verify_safe_response(sensitive_method_view, check_for_POST_params=False) self.verify_safe_email(sensitive_method_view, check_for_POST_params=False)
with self.settings(DEBUG=True): self.verify_unsafe_response(sensitive_args_function_caller) self.verify_unsafe_email(sensitive_args_function_caller) with self.settings(DEBUG=False): self.verify_safe_response(sensitive_args_function_caller, check_for_POST_params=False) self.verify_safe_email(sensitive_args_function_caller, check_for_POST_params=False)
with self.settings(DEBUG=True): self.verify_unsafe_response(sensitive_kwargs_function_caller) self.verify_unsafe_email(sensitive_kwargs_function_caller) with self.settings(DEBUG=False): self.verify_safe_response(sensitive_kwargs_function_caller, check_for_POST_params=False) self.verify_safe_email(sensitive_kwargs_function_caller, check_for_POST_params=False)
def callable_setting(): return "This should not be displayed" with self.settings(DEBUG=True, FOOBAR=callable_setting): response = self.client.get('/raises500/') self.assertNotContains(response, "This should not be displayed", status_code=500)
class CallableSettingWithSlots(object): __slots__ = [] def __call__(self): return "This should not be displayed" with self.settings(DEBUG=True, WITH_SLOTS=CallableSettingWithSlots()): response = self.client.get('/raises500/') self.assertNotContains(response, "This should not be displayed", status_code=500)
with self.settings(DEBUG=True, FOOBAR={42: None}): response = self.client.get('/raises500/') self.assertContains(response, 'FOOBAR', status_code=500)
sensitive_settings = [ 'SECRET_KEY', 'PASSWORD', 'API_KEY', 'AUTH_TOKEN', ] for setting in sensitive_settings: with self.settings(DEBUG=True, **{setting: "should not be displayed"}): response = self.client.get('/raises500/') self.assertNotContains(response, 'should not be displayed', status_code=500)
sensitive_settings = [ 'SECRET_KEY', 'PASSWORD', 'API_KEY', 'AUTH_TOKEN', ] for setting in sensitive_settings: FOOBAR = { setting: "should not be displayed", 'recursive': {setting: "should not be displayed"}, } with self.settings(DEBUG=True, FOOBAR=FOOBAR): response = self.client.get('/raises500/') self.assertNotContains(response, 'should not be displayed', status_code=500)
with self.settings(DEBUG=True): self.verify_unsafe_response(non_sensitive_view, check_for_vars=False) with self.settings(DEBUG=False): self.verify_unsafe_response(non_sensitive_view, check_for_vars=False)
with self.settings(DEBUG=True): self.verify_unsafe_response(sensitive_view, check_for_vars=False) with self.settings(DEBUG=False): self.verify_safe_response(sensitive_view, check_for_vars=False)
with self.settings(DEBUG=True): self.verify_unsafe_response(paranoid_view, check_for_vars=False) with self.settings(DEBUG=False): self.verify_paranoid_response(paranoid_view, check_for_vars=False)
with self.settings(DEBUG=True): self.verify_unsafe_response(custom_exception_reporter_filter_view, check_for_vars=False) with self.settings(DEBUG=False): self.verify_unsafe_response(custom_exception_reporter_filter_view, check_for_vars=False)
response = self.client.get('/nonascii_redirect/') self.assertRedirects(response, self.redirect_target)
response = self.client.post('/') self.assertContains(response, "Forbidden", status_code=403) self.assertContains(response, "CSRF verification failed. Request aborted.", status_code=403) with self.settings(LANGUAGE_CODE='nl'), override('en-us'): response = self.client.post('/') self.assertContains(response, "Verboden", status_code=403) self.assertContains(response, "CSRF-verificatie mislukt. Verzoek afgebroken.", status_code=403)
response = self.client.post('/') self.assertContains(response, "Forbidden", status_code=403) self.assertContains(response, "CSRF verification failed. Request aborted.", status_code=403) with self.settings(LANGUAGE_CODE='nl'), override('en-us'): response = self.client.post('/') self.assertContains(response, "Verboden", status_code=403) self.assertContains(response, "CSRF-verificatie mislukt. Verzoek afgebroken.", status_code=403)
response = self.client.post('/', HTTP_X_FORWARDED_PROTO='https') self.assertContains(response, "You are seeing this message because this HTTPS " "site requires a &#39;Referer header&#39; to be " "sent by your Web browser, but none was sent.", status_code=403)
response = self.client.post('/') self.assertContains(response, "You are seeing this message because this site " "requires a CSRF cookie when submitting forms. " "This cookie is required for security reasons, to " "ensure that your browser is not being hijacked " "by third parties.", status_code=403)
response = self.client.post('/') self.assertContains(response, "Forbidden", status_code=403)
response = self.client.post('/') self.assertContains(response, "Test template for CSRF failure", status_code=403)
t = Engine(debug=True).from_string('{% url will_not_match %}') c = Context() with self.assertRaises(NoReverseMatch): t.render(c)
t = Engine().from_string('{% url will_not_match %}') c = Context() try: t.render(c) except NoReverseMatch: tb = sys.exc_info()[2] depth = 0 while tb.tb_next is not None: tb = tb.tb_next depth += 1 self.assertGreater(depth, 5, "The traceback context was lost when reraising the traceback.")
c = Context({}) t = self.engine.from_string('{% load inclusion %}{% inclusion_tag_use_l10n %}') self.assertEqual(t.render(c).strip(), 'None') c.use_l10n = True self.assertEqual(t.render(c).strip(), 'True')
engine = Engine(app_dirs=True, libraries=LIBRARIES) template = engine.from_string('{% load inclusion %}{% inclusion_no_params %}') count = template.nodelist.get_nodes_by_type(Node) template.render(Context({})) self.assertEqual(template.nodelist.get_nodes_by_type(Node), count)
engine = Engine(app_dirs=True, libraries=LIBRARIES) template = engine.from_string('{% load inclusion %}{% inclusion_extends1 %}{% inclusion_extends2 %}') self.assertEqual(template.render(Context({})).strip(), 'one\ntwo')
def test_correct_exception_index(self): tests = [ ('{% load bad_tag %}{% for i in range %}{% badsimpletag %}{% endfor %}', (38, 56)), ( '{% load bad_tag %}{% for i in range %}{% for j in range %}' '{% badsimpletag %}{% endfor %}{% endfor %}', (58, 76) ), ( '{% load bad_tag %}{% for i in range %}{% badsimpletag %}' '{% for j in range %}Hello{% endfor %}{% endfor %}', (38, 56) ), ( '{% load bad_tag %}{% for i in range %}{% for j in five %}' '{% badsimpletag %}{% endfor %}{% endfor %}', (38, 57) ), ('{% load bad_tag %}{% for j in five %}{% badsimpletag %}{% endfor %}', (18, 37)), ] context = Context({ 'range': range(5), 'five': 5, }) engine = Engine(debug=True, libraries={'bad_tag': 'template_tests.templatetags.bad_tag'}) for source, expected_error_source_index in tests: template = engine.from_string(source) try: template.render(context) except (RuntimeError, TypeError) as e: debug = e.template_debug self.assertEqual((debug['start'], debug['end']), expected_error_source_index)
output = self.engine.render_to_string('namedendblocks06') self.assertEqual(output, '1_2_3')
output = self.engine.render_to_string('ifchanged-param01', {'num': (1, 2, 3)}) self.assertEqual(output, '..1..2..3')
output = self.engine.render_to_string('ifchanged-param03', {'num': (1, 1, 2), 'numx': (5, 6, 6)}) self.assertEqual(output, '156156256')
output = self.engine.render_to_string( 'ifchanged-param04', {'days': [{'hours': [1, 2, 3], 'day': 1}, {'hours': [3], 'day': 2}]}, ) self.assertEqual(output, '112323')
output = self.engine.render_to_string( 'ifchanged-param05', {'days': [{'hours': [1, 2, 3], 'day': 1}, {'hours': [3], 'day': 2}]}, ) self.assertEqual(output, '112323')
output = self.engine.render_to_string('ifchanged-else01', {'ids': [1, 1, 2, 2, 2, 3]}) self.assertEqual(output, '1-first,1-other,2-first,2-other,2-other,3-first,')
output = self.engine.render_to_string('ifchanged-filter-ws', {'num': (1, 2, 3)}) self.assertEqual(output, '..1..2..3')
template = self.engine.from_string('{% ifchanged %}{% cycle "1st time" "2nd time" %}{% endifchanged %}') output = template.render(Context({})) self.assertEqual(output, '1st time')
with self.assertRaises(TemplateSyntaxError): self.engine.render_to_string('autoescape-filtertag01', {'first': '<a>'})
output = self.engine.render_to_string('autoescape-literals01') self.assertEqual(output, 'this & that')
output = self.engine.render_to_string('autoescape-stringiterations01', {'var': 'K&R'}) self.assertEqual(output, 'K,&amp;,R,')
output = self.engine.render_to_string('if-tag-shortcircuit01', {'x': TestObj()}) self.assertEqual(output, 'yes')
output = self.engine.render_to_string('if-tag-shortcircuit02', {'x': TestObj()}) self.assertEqual(output, 'no')
output = self.engine.render_to_string('if-tag-badarg01') self.assertEqual(output, '')
output = self.engine.render_to_string('widthratio06', {'a': 50, 'b': 80}) self.assertEqual(output, '62' if six.PY3 else '63')
output = self.engine.render_to_string('i18n01') self.assertEqual(output, 'xxxyyyxxx')
output = self.engine.render_to_string('i18n02') self.assertEqual(output, 'xxxyyyxxx')
output = self.engine.render_to_string('i18n03', {'anton': b'\xc3\x85'}) self.assertEqual(output, '')
output = self.engine.render_to_string('i18n04', {'anton': b'\xc3\x85'}) self.assertEqual(output, '')
output = self.engine.render_to_string('legacyi18n04', {'anton': b'\xc3\x85'}) self.assertEqual(output, '')
output = self.engine.render_to_string('i18n05', {'anton': 'yyy'}) self.assertEqual(output, 'xxxyyyxxx')
with translation.override('de'): output = self.engine.render_to_string('i18n06') self.assertEqual(output, 'Seite nicht gefunden')
output = self.engine.render_to_string('i18n07', {'number': 1}) self.assertEqual(output, 'singular')
output = self.engine.render_to_string('legacyi18n07', {'number': 1}) self.assertEqual(output, 'singular')
output = self.engine.render_to_string('i18n08', {'number': 2}) self.assertEqual(output, '2 plural')
output = self.engine.render_to_string('legacyi18n08', {'number': 2}) self.assertEqual(output, '2 plural')
with translation.override('de'): output = self.engine.render_to_string('i18n09') self.assertEqual(output, 'Page not found')
with translation.override('de'): output = self.engine.render_to_string('i18n10', {'bool': True}) self.assertEqual(output, 'Ja')
output = self.engine.render_to_string('i18n11', {'bool': True}) self.assertEqual(output, 'ja')
output = self.engine.render_to_string('i18n12') self.assertEqual(output, 'de')
with translation.override('de'): output = self.engine.render_to_string('i18n13') self.assertEqual(output, 'Passwort')
with translation.override('de'): output = self.engine.render_to_string('i18n14') self.assertEqual(output, 'foo Passwort Passwort')
with translation.override('de'): output = self.engine.render_to_string('i18n15', {'absent': ''}) self.assertEqual(output, 'Passwort')
with translation.override('de'): output = self.engine.render_to_string('i18n16') self.assertEqual(output, '<')
output = self.engine.render_to_string('i18n17', {'anton': ' & '}) self.assertEqual(output, ' &amp; ')
with translation.override('de'): output = self.engine.render_to_string('i18n23') self.assertEqual(output, 'nicht gefunden')
output = self.engine.render_to_string('i18n26', {'myextra_field': 'test', 'number': 1}) self.assertEqual(output, 'singular test')
with translation.override('ru'): output = self.engine.render_to_string('i18n27', {'number': 1}) self.assertEqual(output, '1 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442')
output = self.engine.render_to_string('i18n28', {'anton': '', 'berta': ''}) self.assertEqual(output, ' + ')
output = self.engine.render_to_string('filter-syntax01', {"var": "Django is the greatest!"}) self.assertEqual(output, "DJANGO IS THE GREATEST!")
output = self.engine.render_to_string('filter-syntax02', {"var": "Django is the greatest!"}) self.assertEqual(output, "django is the greatest!")
output = self.engine.render_to_string('filter-syntax03', {'var': 'Django is the greatest!'}) self.assertEqual(output, 'DJANGO IS THE GREATEST!')
output = self.engine.render_to_string('filter-syntax04', {'var': 'Django is the greatest!'}) self.assertEqual(output, 'DJANGO IS THE GREATEST!')
with self.assertRaises(TemplateSyntaxError): self.engine.get_template('filter-syntax05')
with self.assertRaises(TemplateSyntaxError): self.engine.get_template('filter-syntax06')
with self.assertRaises(TemplateSyntaxError): self.engine.get_template('filter-syntax07')
with self.assertRaisesMessage(TemplateSyntaxError, 'Empty block tag on line 1'): self.engine.get_template('filter-syntax08')
with self.assertRaisesMessage(TemplateSyntaxError, 'Empty block tag on line 3'): self.engine.get_template('filter-syntax08-multi-line')
output = self.engine.render_to_string('filter-syntax09', {'var': 'Foo'}) self.assertEqual(output, 'f')
output = self.engine.render_to_string('filter-syntax10', {"var": None}) self.assertEqual(output, ' endquote" hah')
output = self.engine.render_to_string('filter-syntax11', {"var": None, "var2": "happy"}) self.assertEqual(output, 'happy')
output = self.engine.render_to_string('filter-syntax12', {"var": True}) self.assertEqual(output, 'yup yes')
output = self.engine.render_to_string('filter-syntax13', {"var": SomeClass()}) if self.engine.string_if_invalid: self.assertEqual(output, "1INVALID2") else: self.assertEqual(output, "12")
with self.assertRaises(SomeOtherException): self.engine.render_to_string('filter-syntax14', {"var": SomeClass()})
output = self.engine.render_to_string('filter-syntax15', {"var": None}) self.assertEqual(output, r'foo\bar')
output = self.engine.render_to_string('filter-syntax16', {"var": None}) self.assertEqual(output, r'foo\now')
output = self.engine.render_to_string('filter-syntax17', {'var': ['a', 'b', 'c']}) self.assertEqual(output, 'abc')
output = self.engine.render_to_string('filter-syntax18', {'var': UTF8Class()}) self.assertEqual(output, '\u0160\u0110\u0106\u017d\u0107\u017e\u0161\u0111')
output = self.engine.render_to_string('filter-syntax19', {"var": "hello world"}) self.assertEqual(output, "hello ...")
output = self.engine.render_to_string('filter-syntax20') self.assertEqual(output, "")
output = self.engine.render_to_string('filter-syntax21', {"var": SomeClass()}) if self.engine.string_if_invalid: self.assertEqual(output, "1INVALID2") else: self.assertEqual(output, "12")
output = self.engine.render_to_string('filter-syntax22', {"var": SomeClass()}) if self.engine.string_if_invalid: self.assertEqual(output, "1INVALID2") else: self.assertEqual(output, "12")
with self.assertRaises(SomeOtherException): self.engine.render_to_string('filter-syntax23', {"var": SomeClass()})
with self.assertRaises(SomeOtherException): self.engine.render_to_string('filter-syntax24', {"var": SomeClass()})
output = self.engine.render_to_string('now03') self.assertEqual(output, "%d %d %d" % ( datetime.now().day, datetime.now().month, datetime.now().year, ))
with self.assertRaises(TemplateDoesNotExist): self.engine.render_to_string('exception01')
if self.engine.string_if_invalid: with self.assertRaises(TemplateDoesNotExist): self.engine.render_to_string('exception02') else: with self.assertRaises(TemplateSyntaxError): self.engine.render_to_string('exception02')
with self.assertRaises(TemplateSyntaxError): self.engine.get_template('exception03')
with self.assertRaises(TemplateSyntaxError): self.engine.get_template('exception04')
output = self.engine.render_to_string('regroup02', {}) self.assertEqual(output, '')
output = self.engine.render_to_string('regroup03', { 'data': [{'at': date(2012, 2, 14)}, {'at': date(2012, 2, 28)}, {'at': date(2012, 7, 4)}], }) self.assertEqual(output, '02:1428,07:04,')
output = self.engine.render_to_string('inheritance01') self.assertEqual(output, '1&3_')
output = self.engine.render_to_string('inheritance02') self.assertEqual(output, '1234')
output = self.engine.render_to_string('inheritance03') self.assertEqual(output, '1234')
output = self.engine.render_to_string('inheritance04') self.assertEqual(output, '1&3_')
output = self.engine.render_to_string('inheritance05') self.assertEqual(output, '1234')
output = self.engine.render_to_string('inheritance06', {'foo': 'inheritance02'}) self.assertEqual(output, '1234')
output = self.engine.render_to_string('inheritance07') self.assertEqual(output, '1&35')
output = self.engine.render_to_string('inheritance08') self.assertEqual(output, '1235')
output = self.engine.render_to_string('inheritance09') self.assertEqual(output, '1&3_')
output = self.engine.render_to_string('inheritance10') self.assertEqual(output, '1&3_')
output = self.engine.render_to_string('inheritance11') self.assertEqual(output, '1234')
output = self.engine.render_to_string('inheritance12') self.assertEqual(output, '1235')
output = self.engine.render_to_string('inheritance13') self.assertEqual(output, '1a3b')
output = self.engine.render_to_string('inheritance14') self.assertEqual(output, '1&3_')
output = self.engine.render_to_string('inheritance15') self.assertEqual(output, '12inner3_')
output = self.engine.render_to_string('inheritance16') self.assertEqual(output, '12out3_')
output = self.engine.render_to_string('inheritance17') self.assertEqual(output, '1234')
output = self.engine.render_to_string('inheritance18') self.assertEqual(output, 'this that theother5678')
output = self.engine.render_to_string('inheritance19') self.assertEqual(output, '140056783_')
output = self.engine.render_to_string('inheritance20') self.assertEqual(output, '1&a3_')
output = self.engine.render_to_string('inheritance21') self.assertEqual(output, '12a34')
output = self.engine.render_to_string('inheritance22') self.assertEqual(output, '1&a3_')
output = self.engine.render_to_string('inheritance23') self.assertEqual(output, '1&ab3_')
context_template = self.engine.from_string( "1{% block first %}_{% endblock %}3{% block second %}_{% endblock %}" ) output = self.engine.render_to_string('inheritance24', {'context_template': context_template}) self.assertEqual(output, '1234')
context_template = [ self.engine.from_string("Wrong"), self.engine.from_string("1{% block first %}_{% endblock %}3{% block second %}_{% endblock %}"), ] output = self.engine.render_to_string('inheritance25', {'context_template': context_template}) self.assertEqual(output, '1234')
output = self.engine.render_to_string('inheritance26') self.assertEqual(output, 'no tags')
output = self.engine.render_to_string('inheritance27') self.assertEqual(output, 'no tags')
output = self.engine.render_to_string('inheritance 28') self.assertEqual(output, '!')
output = self.engine.render_to_string('inheritance29') self.assertEqual(output, '!')
output = self.engine.render_to_string('inheritance33', {'optional': 1}) self.assertEqual(output, '123')
output = self.engine.render_to_string('inheritance34', {'optional': 1}) self.assertEqual(output, '1two3')
output = self.engine.render_to_string('inheritance35', {'optional': 2}) self.assertEqual(output, '13')
output = self.engine.render_to_string('inheritance36', {'numbers': '123'}) self.assertEqual(output, '_1_2_3_')
output = self.engine.render_to_string('inheritance37', {'numbers': '123'}) self.assertEqual(output, '_X_X_X_')
output = self.engine.render_to_string( 'numpy-array-index01', {'var': numpy.array(["first item", "second item"])}, ) self.assertEqual(output, 'second item')
class MultilineTests(SimpleTestCase): @setup({'multiline01': multiline_string}) def test_multiline01(self): output = self.engine.render_to_string('multiline01') self.assertEqual(output, multiline_string)
output = self.engine.render_to_string('list-index01', {'var': ['first item', 'second item']}) self.assertEqual(output, 'second item')
output = self.engine.render_to_string('list-index02', {'var': ['first item', 'second item']}) if self.engine.string_if_invalid: self.assertEqual(output, 'INVALID') else: self.assertEqual(output, '')
output = self.engine.render_to_string('list-index03', {'var': None}) if self.engine.string_if_invalid: self.assertEqual(output, 'INVALID') else: self.assertEqual(output, '')
output = self.engine.render_to_string('list-index04', {'var': {}}) if self.engine.string_if_invalid: self.assertEqual(output, 'INVALID') else: self.assertEqual(output, '')
output = self.engine.render_to_string('list-index05', {'var': {'1': "hello"}}) self.assertEqual(output, 'hello')
output = self.engine.render_to_string('list-index06', {"var": {1: "hello"}}) self.assertEqual(output, 'hello')
cases = [] @setup({}) def method(self): cases.append([ self.engine.string_if_invalid, self.engine.debug, ]) method(self) self.assertEqual(cases[0], ['', False]) self.assertEqual(cases[1], ['', False]) self.assertEqual(cases[2], ['INVALID', False]) self.assertEqual(cases[3], ['INVALID', False]) self.assertEqual(cases[4], ['', True]) self.assertEqual(cases[5], ['', True])
output = self.engine.render_to_string('for-tag-unpack09', {'items': (('one', 1), ('two', 2))}) self.assertEqual(output, 'one:1/two:2/')
output = self.engine.render_to_string('for-tag-filter-ws', {'s': 'abc'}) self.assertEqual(output, 'abc')
output = self.engine.render_to_string('basic-syntax01') self.assertEqual(output, "something cool")
output = self.engine.render_to_string('basic-syntax02', {'headline': 'Success'}) self.assertEqual(output, 'Success')
output = self.engine.render_to_string('basic-syntax03', {"first": 1, "second": 2}) self.assertEqual(output, '1 --- 2')
output = self.engine.render_to_string('basic-syntax04') if self.engine.string_if_invalid: self.assertEqual(output, 'asINVALIDdf') else: self.assertEqual(output, 'asdf')
with self.assertRaises(TemplateSyntaxError): self.engine.get_template('basic-syntax06')
with self.assertRaisesMessage(TemplateSyntaxError, 'Empty variable tag on line 1'): self.engine.get_template('basic-syntax07')
with self.assertRaisesMessage(TemplateSyntaxError, 'Empty variable tag on line 1'): self.engine.get_template('basic-syntax08')
output = self.engine.render_to_string('basic-syntax09', {'var': SomeClass()}) self.assertEqual(output, 'SomeClass.method')
output = self.engine.render_to_string('basic-syntax10', {'var': SomeClass()}) self.assertEqual(output, 'OtherClass.method')
output = self.engine.render_to_string('basic-syntax11', {'var': SomeClass()}) if self.engine.string_if_invalid: self.assertEqual(output, 'INVALID') else: self.assertEqual(output, '')
output = self.engine.render_to_string('basic-syntax18', {"foo": {"bar": "baz"}}) self.assertEqual(output, "baz")
output = self.engine.render_to_string('basic-syntax19', {"foo": {"bar": "baz"}}) if self.engine.string_if_invalid: self.assertEqual(output, 'INVALID') else: self.assertEqual(output, '')
output = self.engine.render_to_string('basic-syntax20', {'var': SomeClass()}) if self.engine.string_if_invalid: self.assertEqual(output, 'INVALID') else: self.assertEqual(output, '')
with self.assertRaises(TemplateSyntaxError): self.engine.get_template('basic-syntax23')
output = self.engine.render_to_string('basic-syntax37', {"callable": lambda: "foo bar"}) self.assertEqual(output, 'foo bar')
output = self.engine.render_to_string('basic-syntax38', {"var": {"callable": lambda: "foo bar"}}) self.assertEqual(output, 'foo bar')
output = self.engine.render_to_string('cache16', {'foo': 'foo', 'bar': 'with spaces'}) self.assertEqual(output, '')
output = self.engine.render_to_string( 'cache17', { 'poem': ( 'Oh freddled gruntbuggly/Thy micturations are to me/' 'As plurdled gabbleblotchits/On a lurgid bee/' 'That mordiously hath bitled out/Its earted jurtles/' 'Into a rancid festering/Or else I shall rend thee in the gobberwarts' 'with my blurglecruncheon/See if I dont.' ), } ) self.assertEqual(output, 'Some Content')
output = self.engine.render_to_string('cache18') self.assertEqual(output, 'cache18')
t1 = self.engine.from_string('{% load cache %}{% cache 1 fragment %}foo{% endcache %}') t2 = self.engine.from_string('{% load cache %}{% cache 1 fragment using="default" %}bar{% endcache %}') ctx = Context() o1 = t1.render(ctx) o2 = t2.render(ctx) self.assertEqual(o1, 'foo') self.assertEqual(o2, 'bar')
engine = Engine(app_dirs=True, debug=True) template = engine.get_template('test_include_error.html') with self.assertRaises(TemplateDoesNotExist) as e: template.render(Context()) self.assertEqual(e.exception.args[0], 'missing.html')
engine = Engine(app_dirs=True, debug=True) template = engine.get_template('test_extends_error.html') with self.assertRaises(TemplateDoesNotExist) as e: template.render(Context()) self.assertEqual(e.exception.args[0], 'missing.html')
engine = Engine() ctx = Context({ 'tmpl': engine.from_string('This worked!'), }) outer_tmpl = engine.from_string('{% include tmpl %}') output = outer_tmpl.render(ctx) self.assertEqual(output, 'This worked!')
Engine(debug=True).from_string('{% include "this_does_not_exist.html" %}')
return value
return "no_params - Expected result"
return "one_param - Expected result: %s" % arg
return "explicit_no_context - Expected result: %s" % arg
return "no_params_with_context - Expected result (context value: %s)" % context['value']
return "params_and_context - Expected result (context value: %s): %s" % (context['value'], arg)
return "simple_two_params - Expected result: %s, %s" % (one, two)
return "simple_one_default - Expected result: %s, %s" % (one, two)
return "simple_unlimited_args - Expected result: %s" % ( ', '.join(six.text_type(arg) for arg in [one, two] + list(args)) )
return "simple_only_unlimited_args - Expected result: %s" % ', '.join(six.text_type(arg) for arg in args)
return "Expected result"
return "Hello {0}!".format(context['name'])
return escape("Hello {0}!".format(context['name']))
return format_html("Hello {0}!", context['name'])
return "assignment_no_params - Expected result"
return {"result": "inclusion_no_params - Expected result"}
return {"result": "inclusion_no_params_from_template - Expected result"}
return {"result": "inclusion_one_param - Expected result: %s" % arg}
return {"result": "inclusion_one_param_from_template - Expected result: %s" % arg}
return {"result": "inclusion_explicit_no_context - Expected result: %s" % arg}
return {"result": "inclusion_explicit_no_context_from_template - Expected result: %s" % arg}
return {"result": "inclusion_no_params_with_context - Expected result (context value: %s)" % context['value']}
return { "result": ( "inclusion_no_params_with_context_from_template - Expected result (context value: %s)" % context['value'] ) }
return { "result": "inclusion_params_and_context - Expected result (context value: %s): %s" % (context['value'], arg) }
return { "result": ( "inclusion_params_and_context_from_template - Expected result " "(context value: %s): %s" % (context['value'], arg) ) }
return {"result": "inclusion_two_params - Expected result: %s, %s" % (one, two)}
return {"result": "inclusion_two_params_from_template - Expected result: %s, %s" % (one, two)}
return {"result": "inclusion_one_default - Expected result: %s, %s" % (one, two)}
return {"result": "inclusion_one_default_from_template - Expected result: %s, %s" % (one, two)}
return { "result": ( "inclusion_unlimited_args - Expected result: %s" % ( ', '.join(six.text_type(arg) for arg in [one, two] + list(args)) ) ) }
return { "result": ( "inclusion_unlimited_args_from_template - Expected result: %s" % ( ', '.join(six.text_type(arg) for arg in [one, two] + list(args)) ) ) }
return { "result": "inclusion_only_unlimited_args - Expected result: %s" % ( ', '.join(six.text_type(arg) for arg in args) ) }
return { "result": "inclusion_only_unlimited_args_from_template - Expected result: %s" % ( ', '.join(six.text_type(arg) for arg in args) ) }
return {}
return {}
token = Token(TOKEN_BLOCK, 'sometag _("Page not found") value|yesno:_("yes,no")') split = token.split_contents() self.assertEqual(split, ["sometag", '_("Page not found")', 'value|yesno:_("yes,no")'])
engine = Engine(dirs=[os.path.join(RECURSIVE, 'fs')]) template = engine.get_template('self.html') with self.assertRaises(TemplateDoesNotExist): template.render(Context({}))
engine = Engine( loaders=[ ['django.template.loaders.locmem.Loader', { 'base.html': '{% extends "base.html" %}{% block content %}{{ block.super }} loader1{% endblock %}', }], ['django.template.loaders.locmem.Loader', { 'base.html': '{% block content %}loader2{% endblock %}', }], ] ) template = engine.get_template('base.html') output = template.render(Context({})) self.assertEqual(output.strip(), 'loader2 loader1')
self.engine.debug = False with self.assertRaises(TemplateDoesNotExist): self.engine.get_template('prod-template-missing.html') e = self.engine.template_loaders[0].get_template_cache['prod-template-missing.html'] self.assertEqual(e, TemplateDoesNotExist)
self.engine.debug = True with self.assertRaises(TemplateDoesNotExist): self.engine.get_template('debug-template-missing.html') e = self.engine.template_loaders[0].get_template_cache['debug-template-missing.html'] self.assertIsInstance(e, TemplateDoesNotExist) self.assertEqual(e.args[0], 'debug-template-missing.html')
self.engine.debug = True with self.assertRaises(TemplateDoesNotExist): self.engine.get_template('no-traceback-in-cache.html') e = self.engine.template_loaders[0].get_template_cache['no-traceback-in-cache.html'] error_msg = "Cached TemplateDoesNotExist must not have been thrown." self.assertIsNone(e.__traceback__, error_msg) self.assertIsNone(e.__context__, error_msg) self.assertIsNone(e.__cause__, error_msg)
loader = self.engine.template_loaders[0] self.assertFalse('missing.html' in loader.template_cache) with self.assertRaises(TemplateDoesNotExist): loader.load_template("missing.html") self.assertEqual( loader.template_cache["missing.html"], TemplateDoesNotExist, "Cached loader failed to cache the TemplateDoesNotExist exception", )
self.assertEqual(self.engine.template_loaders[0].cache_key('-template.html', []), '-template.html')
self.assertEqual(self.engine.template_loaders[0].cache_key(lazystr('template.html'), []), 'template.html')
if six.PY2: name = name.encode('utf-8') class MockLoader(object): pass class MockProvider(pkg_resources.NullProvider): def __init__(self, module): pkg_resources.NullProvider.__init__(self, module) self.module = module def _has(self, path): return path in self.module._resources def _isdir(self, path): return False def get_resource_stream(self, manager, resource_name): return self.module._resources[resource_name] def _get(self, path): return self.module._resources[path].read() def _fn(self, base, resource_name): return os.path.normcase(resource_name) egg = types.ModuleType(name) egg.__loader__ = MockLoader() egg.__path__ = ['/some/bogus/path/'] egg.__file__ = '/some/bogus/path/__init__.pyc' egg._resources = resources sys.modules[name] = egg pkg_resources._provider_factories[MockLoader] = MockProvider try: yield finally: del sys.modules[name] del pkg_resources._provider_factories[MockLoader]
with self.create_egg('egg', {}): with override_settings(INSTALLED_APPS=['egg']): with self.assertRaises(TemplateDoesNotExist): self.engine.get_template('not-existing.html')
templates = { os.path.normcase('templates/y.html'): six.StringIO("y"), } with self.create_egg('egg', templates): with self.assertRaises(TemplateDoesNotExist): self.engine.get_template('y.html')
engine = Engine() loader = engine.template_loaders[0] with self.assertRaises(UnicodeDecodeError): list(loader.get_template_sources(b'\xc3\xc3', ['/dir1']))
@setup({'linebreaks01': '{{ a|linebreaks }} {{ b|linebreaks }}'}) def test_linebreaks01(self): output = self.engine.render_to_string('linebreaks01', {"a": "x&\ny", "b": mark_safe("x&\ny")}) self.assertEqual(output, "<p>x&amp;<br />y</p> <p>x&<br />y</p>") @setup({'linebreaks02': '{% autoescape off %}{{ a|linebreaks }} {{ b|linebreaks }}{% endautoescape %}'}) def test_linebreaks02(self): output = self.engine.render_to_string('linebreaks02', {"a": "x&\ny", "b": mark_safe("x&\ny")}) self.assertEqual(output, "<p>x&<br />y</p> <p>x&<br />y</p>")
@setup({'add01': '{{ i|add:"5" }}'}) def test_add01(self): output = self.engine.render_to_string('add01', {'i': 2000}) self.assertEqual(output, '2005') @setup({'add02': '{{ i|add:"napis" }}'}) def test_add02(self): output = self.engine.render_to_string('add02', {'i': 2000}) self.assertEqual(output, '') @setup({'add03': '{{ i|add:16 }}'}) def test_add03(self): output = self.engine.render_to_string('add03', {'i': 'not_an_int'}) self.assertEqual(output, '') @setup({'add04': '{{ i|add:"16" }}'}) def test_add04(self): output = self.engine.render_to_string('add04', {'i': 'not_an_int'}) self.assertEqual(output, 'not_an_int16') @setup({'add05': '{{ l1|add:l2 }}'}) def test_add05(self): output = self.engine.render_to_string('add05', {'l1': [1, 2], 'l2': [3, 4]}) self.assertEqual(output, '[1, 2, 3, 4]') @setup({'add06': '{{ t1|add:t2 }}'}) def test_add06(self): output = self.engine.render_to_string('add06', {'t1': (3, 4), 't2': (1, 2)}) self.assertEqual(output, '(3, 4, 1, 2)') @setup({'add07': '{{ d|add:t }}'}) def test_add07(self): output = self.engine.render_to_string('add07', {'d': date(2000, 1, 1), 't': timedelta(10)}) self.assertEqual(output, 'Jan. 11, 2000')
@setup({'iriencode01': '{{ url|iriencode }}'}) def test_iriencode01(self): output = self.engine.render_to_string('iriencode01', {'url': '?test=1&me=2'}) self.assertEqual(output, '?test=1&amp;me=2') @setup({'iriencode02': '{% autoescape off %}{{ url|iriencode }}{% endautoescape %}'}) def test_iriencode02(self): output = self.engine.render_to_string('iriencode02', {'url': '?test=1&me=2'}) self.assertEqual(output, '?test=1&me=2') @setup({'iriencode03': '{{ url|iriencode }}'}) def test_iriencode03(self): output = self.engine.render_to_string('iriencode03', {'url': mark_safe('?test=1&me=2')}) self.assertEqual(output, '?test=1&me=2') @setup({'iriencode04': '{% autoescape off %}{{ url|iriencode }}{% endautoescape %}'}) def test_iriencode04(self): output = self.engine.render_to_string('iriencode04', {'url': mark_safe('?test=1&me=2')}) self.assertEqual(output, '?test=1&me=2')
@setup({'autoescape-stringfilter01': '{{ unsafe|capfirst }}'}) def test_autoescape_stringfilter01(self): output = self.engine.render_to_string('autoescape-stringfilter01', {'unsafe': UnsafeClass()}) self.assertEqual(output, 'You &amp; me') @setup({'autoescape-stringfilter02': '{% autoescape off %}{{ unsafe|capfirst }}{% endautoescape %}'}) def test_autoescape_stringfilter02(self): output = self.engine.render_to_string('autoescape-stringfilter02', {'unsafe': UnsafeClass()}) self.assertEqual(output, 'You & me') @setup({'autoescape-stringfilter03': '{{ safe|capfirst }}'}) def test_autoescape_stringfilter03(self): output = self.engine.render_to_string('autoescape-stringfilter03', {'safe': SafeClass()}) self.assertEqual(output, 'You &gt; me') @setup({'autoescape-stringfilter04': '{% autoescape off %}{{ safe|capfirst }}{% endautoescape %}'}) def test_autoescape_stringfilter04(self): output = self.engine.render_to_string('autoescape-stringfilter04', {'safe': SafeClass()}) self.assertEqual(output, 'You &gt; me')
@setup({'upper01': '{% autoescape off %}{{ a|upper }} {{ b|upper }}{% endautoescape %}'}) def test_upper01(self): output = self.engine.render_to_string('upper01', {'a': 'a & b', 'b': mark_safe('a &amp; b')}) self.assertEqual(output, 'A & B A &AMP; B') @setup({'upper02': '{{ a|upper }} {{ b|upper }}'}) def test_upper02(self): output = self.engine.render_to_string('upper02', {'a': 'a & b', 'b': mark_safe('a &amp; b')}) self.assertEqual(output, 'A &amp; B A &amp;AMP; B')
with translation.override('fr'): output = self.engine.render_to_string('date02_l10n', {'d': datetime(2008, 1, 1)}) self.assertEqual(output, '1 janvier 2008')
@setup({ 'stringformat01': '{% autoescape off %}.{{ a|stringformat:"5s" }}. .{{ b|stringformat:"5s" }}.{% endautoescape %}' }) def test_stringformat01(self): output = self.engine.render_to_string('stringformat01', {'a': 'a<b', 'b': mark_safe('a<b')}) self.assertEqual(output, '. a<b. . a<b.') @setup({'stringformat02': '.{{ a|stringformat:"5s" }}. .{{ b|stringformat:"5s" }}.'}) def test_stringformat02(self): output = self.engine.render_to_string('stringformat02', {'a': 'a<b', 'b': mark_safe('a<b')}) self.assertEqual(output, '. a&lt;b. . a<b.')
@setup({'slugify01': '{% autoescape off %}{{ a|slugify }} {{ b|slugify }}{% endautoescape %}'}) def test_slugify01(self): output = self.engine.render_to_string('slugify01', {'a': 'a & b', 'b': mark_safe('a &amp; b')}) self.assertEqual(output, 'a-b a-amp-b') @setup({'slugify02': '{{ a|slugify }} {{ b|slugify }}'}) def test_slugify02(self): output = self.engine.render_to_string('slugify02', {'a': 'a & b', 'b': mark_safe('a &amp; b')}) self.assertEqual(output, 'a-b a-amp-b')
data = [ {'foo': {'bar': 1, 'baz': 'c'}}, {'foo': {'bar': 2, 'baz': 'b'}}, {'foo': {'bar': 3, 'baz': 'a'}}, ] sorted_data = dictsort(data, 'foo.baz') self.assertEqual([d['foo']['bar'] for d in sorted_data], [3, 2, 1])
@setup({'linenumbers01': '{{ a|linenumbers }} {{ b|linenumbers }}'}) def test_linenumbers01(self): output = self.engine.render_to_string( 'linenumbers01', {'a': 'one\n<two>\nthree', 'b': mark_safe('one\n&lt;two&gt;\nthree')}, ) self.assertEqual(output, '1. one\n2. &lt;two&gt;\n3. three 1. one\n2. &lt;two&gt;\n3. three') @setup({'linenumbers02': '{% autoescape off %}{{ a|linenumbers }} {{ b|linenumbers }}{% endautoescape %}'}) def test_linenumbers02(self): output = self.engine.render_to_string( 'linenumbers02', {'a': 'one\n<two>\nthree', 'b': mark_safe('one\n&lt;two&gt;\nthree')}, ) self.assertEqual(output, '1. one\n2. <two>\n3. three 1. one\n2. &lt;two&gt;\n3. three')
@setup({'make_list01': '{% autoescape off %}{{ a|make_list }}{% endautoescape %}'}) def test_make_list01(self): output = self.engine.render_to_string('make_list01', {"a": mark_safe("&")}) self.assertEqual(output, str_prefix("[%(_)s'&']")) @setup({'make_list02': '{{ a|make_list }}'}) def test_make_list02(self): output = self.engine.render_to_string('make_list02', {"a": mark_safe("&")}) self.assertEqual(output, str_prefix("[%(_)s&#39;&amp;&#39;]")) @setup({'make_list03': '{% autoescape off %}{{ a|make_list|stringformat:"s"|safe }}{% endautoescape %}'}) def test_make_list03(self): output = self.engine.render_to_string('make_list03', {"a": mark_safe("&")}) self.assertEqual(output, str_prefix("[%(_)s'&']")) @setup({'make_list04': '{{ a|make_list|stringformat:"s"|safe }}'}) def test_make_list04(self): output = self.engine.render_to_string('make_list04', {"a": mark_safe("&")}) self.assertEqual(output, str_prefix("[%(_)s'&']"))
self.assertEqual( urlize('http://hi.baidu.com/%E9%87%8D%E6%96%B0%E5%BC%80%E5%A7%8B'), '<a href="http://hi.baidu.com/%E9%87%8D%E6%96%B0%E5%BC%80%E5%A7%8B" rel="nofollow">' 'http://hi.baidu.com/%E9%87%8D%E6%96%B0%E5%BC%80%E5%A7%8B</a>', )
self.assertEqual( urlize('https://en.wikipedia.org/wiki/Django_(web_framework)'), '<a href="https://en.wikipedia.org/wiki/Django_(web_framework)" rel="nofollow">' 'https://en.wikipedia.org/wiki/Django_(web_framework)</a>', ) self.assertEqual( urlize('(see https://en.wikipedia.org/wiki/Django_(web_framework))'), '(see <a href="https://en.wikipedia.org/wiki/Django_(web_framework)" rel="nofollow">' 'https://en.wikipedia.org/wiki/Django_(web_framework)</a>)', )
self.assertEqual( urlize('foo@bar.com or www.bar.com'), '<a href="mailto:foo@bar.com">foo@bar.com</a> or ' '<a href="http://www.bar.com" rel="nofollow">www.bar.com</a>', )
self.assertEqual(urlize('http://c.ws'), '<a href="http://xn--c-lgq.ws" rel="nofollow">http://c.ws</a>') self.assertEqual(urlize('www.c.ws'), '<a href="http://www.xn--c-lgq.ws" rel="nofollow">www.c.ws</a>') self.assertEqual(urlize('c.org'), '<a href="http://xn--c-lgq.org" rel="nofollow">c.org</a>') self.assertEqual(urlize('info@c.org'), '<a href="mailto:info@xn--c-lgq.org">info@c.org</a>')
self.assertEqual(urlize('http:///www.google.com'), 'http:///www.google.com') self.assertEqual(urlize('http://.google.com'), 'http://.google.com') self.assertEqual(urlize('http://@foo.com'), 'http://@foo.com')
self.assertEqual(urlize('usa.gov'), '<a href="http://usa.gov" rel="nofollow">usa.gov</a>')
self.assertEqual(urlize('email@.stream.ru'), 'email@.stream.ru')
self.assertEqual( urlize('HTTPS://github.com/'), '<a href="https://github.com/" rel="nofollow">HTTPS://github.com/</a>', )
self.assertEqual( urlize('(Go to http://www.example.com/foo.)'), '(Go to <a href="http://www.example.com/foo" rel="nofollow">http://www.example.com/foo</a>.)', )
self.assertEqual( urlize('[see www.example.com]'), '[see <a href="http://www.example.com" rel="nofollow">www.example.com</a>]', ) self.assertEqual( urlize('see test[at[example.com'), 'see <a href="http://test[at[example.com" rel="nofollow">test[at[example.com</a>', ) self.assertEqual( urlize('[http://168.192.0.1](http://168.192.0.1)'), '[<a href="http://168.192.0.1](http://168.192.0.1)" rel="nofollow">' 'http://168.192.0.1](http://168.192.0.1)</a>', )
self.assertEqual( urlize('before "hi@example.com" afterwards', autoescape=False), 'before "<a href="mailto:hi@example.com">hi@example.com</a>" afterwards', ) self.assertEqual( urlize('before hi@example.com" afterwards', autoescape=False), 'before <a href="mailto:hi@example.com">hi@example.com</a>" afterwards', ) self.assertEqual( urlize('before "hi@example.com afterwards', autoescape=False), 'before "<a href="mailto:hi@example.com">hi@example.com</a> afterwards', ) self.assertEqual( urlize('before \'hi@example.com\' afterwards', autoescape=False), 'before \'<a href="mailto:hi@example.com">hi@example.com</a>\' afterwards', ) self.assertEqual( urlize('before hi@example.com\' afterwards', autoescape=False), 'before <a href="mailto:hi@example.com">hi@example.com</a>\' afterwards', ) self.assertEqual( urlize('before \'hi@example.com afterwards', autoescape=False), 'before \'<a href="mailto:hi@example.com">hi@example.com</a> afterwards', )
self.assertEqual( urlize('Email us at "hi@example.com", or phone us at +xx.yy', autoescape=False), 'Email us at "<a href="mailto:hi@example.com">hi@example.com</a>", or phone us at +xx.yy', )
self.assertEqual( urlize('Go to djangoproject.com! and enjoy.'), 'Go to <a href="http://djangoproject.com" rel="nofollow">djangoproject.com</a>! and enjoy.', ) self.assertEqual( urlize('Search for google.com/?q=! and see.'), 'Search for <a href="http://google.com/?q=" rel="nofollow">google.com/?q=</a>! and see.', ) self.assertEqual( urlize('Search for google.com/?q=dj!`? and see.'), 'Search for <a href="http://google.com/?q=dj%21%60%3F" rel="nofollow">google.com/?q=dj!`?</a> and see.', ) self.assertEqual( urlize('Search for google.com/?q=dj!`?! and see.'), 'Search for <a href="http://google.com/?q=dj%21%60%3F" rel="nofollow">google.com/?q=dj!`?</a>! and see.', )
self.assertEqual(floatformat(0, 6), '0.000000') self.assertEqual(floatformat(0, 7), '0.0000000') self.assertEqual(floatformat(0, 10), '0.0000000000') self.assertEqual(floatformat(0.000000000000000000015, 20), '0.00000000000000000002')
with localcontext() as ctx: ctx.prec = 2 self.assertEqual(floatformat(1.2345, 2), '1.23') self.assertEqual(floatformat(15.2042, -3), '15.204') self.assertEqual(floatformat(1.2345, '2'), '1.23') self.assertEqual(floatformat(15.2042, '-3'), '15.204') self.assertEqual(floatformat(Decimal('1.2345'), 2), '1.23') self.assertEqual(floatformat(Decimal('15.2042'), -3), '15.204')
@setup({'time00': '{{ dt|time }}'}) def test_time00(self): output = self.engine.render_to_string('time00', {'dt': time(16, 25)}) self.assertEqual(output, '4:25 p.m.') @override_settings(USE_L10N=True) @setup({'time00_l10n': '{{ dt|time }}'}) def test_time00_l10n(self): with translation.override('fr'): output = self.engine.render_to_string('time00_l10n', {'dt': time(16, 25)}) self.assertEqual(output, '16:25') @setup({'time01': '{{ dt|time:"e:O:T:Z" }}'}) def test_time01(self): output = self.engine.render_to_string('time01', {'dt': self.now_tz_i}) self.assertEqual(output, '+0315:+0315:+0315:11700') @setup({'time02': '{{ dt|time:"e:T" }}'}) def test_time02(self): output = self.engine.render_to_string('time02', {'dt': self.now}) self.assertEqual(output, ':' + self.now_tz.tzinfo.tzname(self.now_tz)) @setup({'time03': '{{ t|time:"P:e:O:T:Z" }}'}) def test_time03(self): output = self.engine.render_to_string('time03', {'t': time(4, 0, tzinfo=timezone.get_fixed_timezone(30))}) self.assertEqual(output, '4 a.m.::::') @setup({'time04': '{{ t|time:"P:e:O:T:Z" }}'}) def test_time04(self): output = self.engine.render_to_string('time04', {'t': time(4, 0)}) self.assertEqual(output, '4 a.m.::::') @setup({'time05': '{{ d|time:"P:e:O:T:Z" }}'}) def test_time05(self): output = self.engine.render_to_string('time05', {'d': self.today}) self.assertEqual(output, '') @setup({'time06': '{{ obj|time:"P:e:O:T:Z" }}'}) def test_time06(self): output = self.engine.render_to_string('time06', {'obj': 'non-datetime-value'}) self.assertEqual(output, '')
@setup({'default01': '{{ a|default:"x<" }}'}) def test_default01(self): output = self.engine.render_to_string('default01', {"a": ""}) self.assertEqual(output, "x<") @setup({'default02': '{% autoescape off %}{{ a|default:"x<" }}{% endautoescape %}'}) def test_default02(self): output = self.engine.render_to_string('default02', {"a": ""}) self.assertEqual(output, "x<") @setup({'default03': '{{ a|default:"x<" }}'}) def test_default03(self): output = self.engine.render_to_string('default03', {"a": mark_safe("x>")}) self.assertEqual(output, "x>") @setup({'default04': '{% autoescape off %}{{ a|default:"x<" }}{% endautoescape %}'}) def test_default04(self): output = self.engine.render_to_string('default04', {"a": mark_safe("x>")}) self.assertEqual(output, "x>")
@setup({'linebreaksbr01': '{{ a|linebreaksbr }} {{ b|linebreaksbr }}'}) def test_linebreaksbr01(self): output = self.engine.render_to_string('linebreaksbr01', {"a": "x&\ny", "b": mark_safe("x&\ny")}) self.assertEqual(output, "x&amp;<br />y x&<br />y") @setup({'linebreaksbr02': '{% autoescape off %}{{ a|linebreaksbr }} {{ b|linebreaksbr }}{% endautoescape %}'}) def test_linebreaksbr02(self): output = self.engine.render_to_string('linebreaksbr02', {"a": "x&\ny", "b": mark_safe("x&\ny")}) self.assertEqual(output, "x&<br />y x&<br />y")
empty_context = Context() with self.assertRaises(VariableDoesNotExist): Variable('no_such_variable').resolve(empty_context) with self.assertRaises(VariableDoesNotExist): Variable('new').resolve(empty_context) self.assertEqual( Variable('new').resolve(Context({'new': 'foo'})), 'foo', )
a = Context({'a': 2}) a.push(Context({'z': '8'})) self.assertEqual(a.flatten(), { 'False': False, 'None': None, 'True': True, 'a': 2, 'z': '8', })
RequestContext(HttpRequest()).new().new()
engine = Engine(loaders=[ ('django.template.loaders.locmem.Loader', { 'child': '{{ var|default:"none" }}', }), ]) request = RequestFactory().get('/') ctx = RequestContext(request, {'var': 'parent'}) self.assertEqual(engine.from_string('{% include "child" %}').render(ctx), 'parent') self.assertEqual(engine.from_string('{% include "child" only %}').render(ctx), 'none')
loaders = [ 'django.template.loaders.filesystem.Loader', 'django.template.loaders.app_directories.Loader', ] engine = Engine(dirs=[OTHER_DIR, TEMPLATE_DIR], loaders=loaders) template = engine.get_template('priority/foo.html') self.assertEqual(template.render(Context()), 'priority\n')
char_field = models.CharField(max_length=30, blank=True) integer_field = models.IntegerField(null=True) boolean_field = models.NullBooleanField()
int1 = models.IntegerField() int2 = models.IntegerField() related_field = models.ForeignKey(AggregateTestModel, models.SET_NULL, null=True)
self.assertQuerysetEqual( self.Model.objects.filter(field__unaccent__iexact="aeO"), ["", "aeO", "aeo"], transform=lambda instance: instance.field, ordered=False ) self.assertQuerysetEqual( self.Model.objects.filter(field__unaccent__endswith=""), ["", "aeO"], transform=lambda instance: instance.field, ordered=False )
from django.contrib.postgres.search import ( SearchQuery, SearchRank, SearchVector, ) from django.db.models import F from django.test import modify_settings from . import PostgreSQLTestCase from .models import Character, Line, Scene class GrailTestData(object): @classmethod def setUpTestData(cls): cls.robin = Scene.objects.create(scene='Scene 10', setting='The dark forest of Ewing') cls.minstrel = Character.objects.create(name='Minstrel') verses = [ ( 'Bravely bold Sir Robin, rode forth from Camelot. ' 'He was not afraid to die, o Brave Sir Robin. ' 'He was not at all afraid to be killed in nasty ways. ' 'Brave, brave, brave, brave Sir Robin!' ), ( 'He was not in the least bit scared to be mashed into a pulp, ' 'Or to have his eyes gouged out, and his elbows broken. ' 'To have his kneecaps split, and his body burned away, ' 'And his limbs all hacked and mangled, brave Sir Robin!' ), ( 'His head smashed in and his heart cut out, ' 'And his liver removed and his bowels unplugged, ' 'And his nostrils ripped and his bottom burned off,' 'And his --' ), ] cls.verses = [Line.objects.create( scene=cls.robin, character=cls.minstrel, dialogue=verse, ) for verse in verses] cls.verse0, cls.verse1, cls.verse2 = cls.verses cls.witch_scene = Scene.objects.create(scene='Scene 5', setting="Sir Bedemir's Castle") bedemir = Character.objects.create(name='Bedemir') crowd = Character.objects.create(name='Crowd') witch = Character.objects.create(name='Witch') duck = Character.objects.create(name='Duck') cls.bedemir0 = Line.objects.create( scene=cls.witch_scene, character=bedemir, dialogue='We shall use my larger scales!', dialogue_config='english', ) cls.bedemir1 = Line.objects.create( scene=cls.witch_scene, character=bedemir, dialogue='Right, remove the supports!', dialogue_config='english', ) cls.duck = Line.objects.create(scene=cls.witch_scene, character=duck, dialogue=None) cls.crowd = Line.objects.create(scene=cls.witch_scene, character=crowd, dialogue='A witch! A witch!') cls.witch = Line.objects.create(scene=cls.witch_scene, character=witch, dialogue="It's a fair cop.") trojan_rabbit = Scene.objects.create(scene='Scene 8', setting="The castle of Our Master Ruiz' de lu la Ramper") guards = Character.objects.create(name='French Guards') cls.french = Line.objects.create( scene=trojan_rabbit, character=guards, dialogue='Oh. Un cadeau. Oui oui.', dialogue_config='french', ) @modify_settings(INSTALLED_APPS={'append': 'django.contrib.postgres'}) class SimpleSearchTest(GrailTestData, PostgreSQLTestCase): def test_simple(self): searched = Line.objects.filter(dialogue__search='elbows') self.assertSequenceEqual(searched, [self.verse1]) def test_non_exact_match(self): searched = Line.objects.filter(dialogue__search='hearts') self.assertSequenceEqual(searched, [self.verse2]) def test_search_two_terms(self): searched = Line.objects.filter(dialogue__search='heart bowel') self.assertSequenceEqual(searched, [self.verse2]) def test_search_two_terms_with_partial_match(self): searched = Line.objects.filter(dialogue__search='Robin killed') self.assertSequenceEqual(searched, [self.verse0]) @modify_settings(INSTALLED_APPS={'append': 'django.contrib.postgres'}) class SearchVectorFieldTest(GrailTestData, PostgreSQLTestCase): def test_existing_vector(self): Line.objects.update(dialogue_search_vector=SearchVector('dialogue')) searched = Line.objects.filter(dialogue_search_vector=SearchQuery('Robin killed')) self.assertSequenceEqual(searched, [self.verse0]) def test_existing_vector_config_explicit(self): Line.objects.update(dialogue_search_vector=SearchVector('dialogue')) searched = Line.objects.filter(dialogue_search_vector=SearchQuery('cadeaux', config='french')) self.assertSequenceEqual(searched, [self.french]) class MultipleFieldsTest(GrailTestData, PostgreSQLTestCase): def test_simple_on_dialogue(self): searched = Line.objects.annotate( search=SearchVector('scene__setting', 'dialogue'), ).filter(search='elbows') self.assertSequenceEqual(searched, [self.verse1]) def test_simple_on_scene(self): searched = Line.objects.annotate( search=SearchVector('scene__setting', 'dialogue'), ).filter(search='Forest') self.assertSequenceEqual(searched, self.verses) def test_non_exact_match(self): searched = Line.objects.annotate( search=SearchVector('scene__setting', 'dialogue'), ).filter(search='heart') self.assertSequenceEqual(searched, [self.verse2]) def test_search_two_terms(self): searched = Line.objects.annotate( search=SearchVector('scene__setting', 'dialogue'), ).filter(search='heart forest') self.assertSequenceEqual(searched, [self.verse2]) def test_terms_adjacent(self): searched = Line.objects.annotate( search=SearchVector('character__name', 'dialogue'), ).filter(search='minstrel') self.assertSequenceEqual(searched, self.verses) searched = Line.objects.annotate( search=SearchVector('scene__setting', 'dialogue'), ).filter(search='minstrelbravely') self.assertSequenceEqual(searched, []) def test_search_with_null(self): searched = Line.objects.annotate( search=SearchVector('scene__setting', 'dialogue'), ).filter(search='bedemir') self.assertEqual(set(searched), {self.bedemir0, self.bedemir1, self.crowd, self.witch, self.duck}) def test_config_query_explicit(self): searched = Line.objects.annotate( search=SearchVector('scene__setting', 'dialogue', config='french'), ).filter(search=SearchQuery('cadeaux', config='french')) self.assertSequenceEqual(searched, [self.french]) def test_config_query_implicit(self): searched = Line.objects.annotate( search=SearchVector('scene__setting', 'dialogue', config='french'), ).filter(search='cadeaux') self.assertSequenceEqual(searched, [self.french]) def test_config_from_field_explicit(self): searched = Line.objects.annotate( search=SearchVector('scene__setting', 'dialogue', config=F('dialogue_config')), ).filter(search=SearchQuery('cadeaux', config=F('dialogue_config'))) self.assertSequenceEqual(searched, [self.french]) def test_config_from_field_implicit(self): searched = Line.objects.annotate( search=SearchVector('scene__setting', 'dialogue', config=F('dialogue_config')), ).filter(search='cadeaux') self.assertSequenceEqual(searched, [self.french]) @modify_settings(INSTALLED_APPS={'append': 'django.contrib.postgres'}) class TestCombinations(GrailTestData, PostgreSQLTestCase): def test_vector_add(self): searched = Line.objects.annotate( search=SearchVector('scene__setting') + SearchVector('character__name'), ).filter(search='bedemir') self.assertEqual(set(searched), {self.bedemir0, self.bedemir1, self.crowd, self.witch, self.duck}) def test_vector_add_multi(self): searched = Line.objects.annotate( search=( SearchVector('scene__setting') + SearchVector('character__name') + SearchVector('dialogue') ), ).filter(search='bedemir') self.assertEqual(set(searched), {self.bedemir0, self.bedemir1, self.crowd, self.witch, self.duck}) def test_query_and(self): searched = Line.objects.annotate( search=SearchVector('scene__setting', 'dialogue'), ).filter(search=SearchQuery('bedemir') & SearchQuery('scales')) self.assertSequenceEqual(searched, [self.bedemir0]) def test_query_or(self): searched = Line.objects.filter(dialogue__search=SearchQuery('kneecaps') | SearchQuery('nostrils')) self.assertSequenceEqual(set(searched), {self.verse1, self.verse2}) def test_query_invert(self): searched = Line.objects.filter(character=self.minstrel, dialogue__search=~SearchQuery('kneecaps')) self.assertEqual(set(searched), {self.verse0, self.verse2}) @modify_settings(INSTALLED_APPS={'append': 'django.contrib.postgres'}) class TestRankingAndWeights(GrailTestData, PostgreSQLTestCase): def test_ranking(self): searched = Line.objects.filter(character=self.minstrel).annotate( rank=SearchRank(SearchVector('dialogue'), SearchQuery('brave sir robin')), ).order_by('rank') self.assertSequenceEqual(searched, [self.verse2, self.verse1, self.verse0]) def test_rank_passing_untyped_args(self): searched = Line.objects.filter(character=self.minstrel).annotate( rank=SearchRank('dialogue', 'brave sir robin'), ).order_by('rank') self.assertSequenceEqual(searched, [self.verse2, self.verse1, self.verse0]) def test_weights_in_vector(self): vector = SearchVector('dialogue', weight='A') + SearchVector('character__name', weight='D') searched = Line.objects.filter(scene=self.witch_scene).annotate( rank=SearchRank(vector, SearchQuery('witch')), ).order_by('-rank')[:2] self.assertSequenceEqual(searched, [self.crowd, self.witch]) vector = SearchVector('dialogue', weight='D') + SearchVector('character__name', weight='A') searched = Line.objects.filter(scene=self.witch_scene).annotate( rank=SearchRank(vector, SearchQuery('witch')), ).order_by('-rank')[:2] self.assertSequenceEqual(searched, [self.witch, self.crowd]) def test_ranked_custom_weights(self): vector = SearchVector('dialogue', weight='D') + SearchVector('character__name', weight='A') searched = Line.objects.filter(scene=self.witch_scene).annotate( rank=SearchRank(vector, SearchQuery('witch'), weights=[1, 0, 0, 0.5]), ).order_by('-rank')[:2] self.assertSequenceEqual(searched, [self.crowd, self.witch]) def test_ranking_chaining(self): searched = Line.objects.filter(character=self.minstrel).annotate( rank=SearchRank(SearchVector('dialogue'), SearchQuery('brave sir robin')), ).filter(rank__gt=0.3) self.assertSequenceEqual(searched, [self.verse0])
from django.db import models try: from django.contrib.postgres.fields import ( ArrayField, BigIntegerRangeField, DateRangeField, DateTimeRangeField, FloatRangeField, HStoreField, IntegerRangeField, JSONField, ) from django.contrib.postgres.search import SearchVectorField except ImportError: class DummyArrayField(models.Field): def __init__(self, base_field, size=None, **kwargs): super(DummyArrayField, self).__init__(**kwargs) def deconstruct(self): name, path, args, kwargs = super(DummyArrayField, self).deconstruct() kwargs.update({ 'base_field': '', 'size': 1, }) return name, path, args, kwargs ArrayField = DummyArrayField BigIntegerRangeField = models.Field DateRangeField = models.Field DateTimeRangeField = models.Field FloatRangeField = models.Field HStoreField = models.Field IntegerRangeField = models.Field JSONField = models.Field SearchVectorField = models.Field
r = R.objects.create() h1 = HiddenUser.objects.create(r=r) h2 = HiddenUser.objects.create(r=r) HiddenUser.objects.create(r=r) HiddenUserProfile.objects.create(user=h1) HiddenUserProfile.objects.create(user=h2) m1 = M.objects.create() m2 = M.objects.create() MR.objects.create(r=r, m=m1) r.m_set.add(m1) r.m_set.add(m2) r.save() existed_objs = { R._meta.label: R.objects.count(), HiddenUser._meta.label: HiddenUser.objects.count(), A._meta.label: A.objects.count(), MR._meta.label: MR.objects.count(), HiddenUserProfile._meta.label: HiddenUserProfile.objects.count(), M.m2m.through._meta.label: M.m2m.through.objects.count(), } deleted, deleted_objs = r.delete() self.assertEqual(deleted, sum(existed_objs.values())) for k, v in existed_objs.items(): self.assertEqual(deleted_objs[k], v)
from __future__ import unicode_literals from django.db import models from django.utils.encoding import python_2_unicode_compatible @python_2_unicode_compatible class Employee(models.Model): firstname = models.CharField(max_length=50) lastname = models.CharField(max_length=50) salary = models.IntegerField(blank=True, null=True) def __str__(self): return '%s %s' % (self.firstname, self.lastname) @python_2_unicode_compatible class Company(models.Model): name = models.CharField(max_length=100) num_employees = models.PositiveIntegerField() num_chairs = models.PositiveIntegerField() ceo = models.ForeignKey( Employee, models.CASCADE, related_name='company_ceo_set') point_of_contact = models.ForeignKey( Employee, models.SET_NULL, related_name='company_point_of_contact_set', null=True) def __str__(self): return self.name @python_2_unicode_compatible class Number(models.Model): integer = models.BigIntegerField(db_column='the_integer') float = models.FloatField(null=True, db_column='the_float') def __str__(self): return '%i, %.3f' % (self.integer, self.float) class Experiment(models.Model): name = models.CharField(max_length=24) assigned = models.DateField() completed = models.DateField() estimated_time = models.DurationField() start = models.DateTimeField() end = models.DateTimeField() class Meta: ordering = ('name',) def duration(self): return self.end - self.start @python_2_unicode_compatible class Time(models.Model): time = models.TimeField(null=True) def __str__(self): return "%s" % self.time @python_2_unicode_compatible class UUID(models.Model): uuid = models.UUIDField(null=True) def __str__(self): return "%s" % self.uuid
f = F("foo") g = deepcopy(f) self.assertEqual(f.name, g.name)
Employee.objects.bulk_create([ Employee(firstname="%Joh\\nny", lastname="%Joh\\n"), Employee(firstname="Johnny", lastname="%John"), Employee(firstname="Jean-Claude", lastname="Claud_"), Employee(firstname="Jean-Claude", lastname="Claude"), Employee(firstname="Jean-Claude", lastname="Claude%"), Employee(firstname="Johnny", lastname="Joh\\n"), Employee(firstname="Johnny", lastname="John"), Employee(firstname="Johnny", lastname="_ohn"), ]) self.assertQuerysetEqual( Employee.objects.filter(firstname__contains=F('lastname')), ["<Employee: %Joh\\nny %Joh\\n>", "<Employee: Jean-Claude Claude>", "<Employee: Johnny John>"], ordered=False) self.assertQuerysetEqual( Employee.objects.filter(firstname__startswith=F('lastname')), ["<Employee: %Joh\\nny %Joh\\n>", "<Employee: Johnny John>"], ordered=False) self.assertQuerysetEqual( Employee.objects.filter(firstname__endswith=F('lastname')), ["<Employee: Jean-Claude Claude>"], ordered=False)
Employee.objects.bulk_create([ Employee(firstname="%Joh\\nny", lastname="%joh\\n"), Employee(firstname="Johnny", lastname="%john"), Employee(firstname="Jean-Claude", lastname="claud_"), Employee(firstname="Jean-Claude", lastname="claude"), Employee(firstname="Jean-Claude", lastname="claude%"), Employee(firstname="Johnny", lastname="joh\\n"), Employee(firstname="Johnny", lastname="john"), Employee(firstname="Johnny", lastname="_ohn"), ]) self.assertQuerysetEqual( Employee.objects.filter(firstname__icontains=F('lastname')), ["<Employee: %Joh\\nny %joh\\n>", "<Employee: Jean-Claude claude>", "<Employee: Johnny john>"], ordered=False) self.assertQuerysetEqual( Employee.objects.filter(firstname__istartswith=F('lastname')), ["<Employee: %Joh\\nny %joh\\n>", "<Employee: Johnny john>"], ordered=False) self.assertQuerysetEqual( Employee.objects.filter(firstname__iendswith=F('lastname')), ["<Employee: Jean-Claude claude>"], ordered=False)
self.assertQuerysetEqual( Number.objects.all(), [ '<Number: -1, -1.000>', '<Number: 42, 42.000>', '<Number: 1337, 1337.000>' ], ordered=False )
self.assertEqual( Number.objects.filter(integer__gt=0) .update(integer=F('integer') + 1), 2) self.assertQuerysetEqual( Number.objects.all(), [ '<Number: -1, -1.000>', '<Number: 43, 42.000>', '<Number: 1338, 1337.000>' ], ordered=False )
self.assertEqual( Number.objects.filter(integer__gt=0) .update(integer=F('integer') + 1), 2) self.assertQuerysetEqual( Number.objects.exclude(float=F('integer')), [ '<Number: 43, 42.000>', '<Number: 1338, 1337.000>' ], ordered=False )
n = Number.objects.create(integer=10, float=123.45) self.assertEqual(Number.objects.filter(pk=n.pk).update( float=F('integer') + F('float') * 2), 1) self.assertEqual(Number.objects.get(pk=n.pk).integer, 10) self.assertEqual(Number.objects.get(pk=n.pk).float, Approximate(256.900, places=3))
environ = RequestFactory().get('/').environ environ['PATH_INFO'] = b'\xed' if six.PY2 else '\xed' handler = WSGIHandler() response = handler(environ, lambda *a, **k: None) self.assertEqual(response.status_code, 400)
a = Article(None, 'Second article', datetime(2005, 7, 29)) a.save() self.assertEqual(a.headline, 'Second article') self.assertEqual(a.pub_date, datetime(2005, 7, 29, 0, 0))
a = Article(headline='Article 5', pub_date=datetime(2005, 7, 31)) a.save() self.assertEqual(a.headline, 'Article 5') self.assertNotEqual(a.id, None)
a1 = Article( headline='Article 7', pub_date=datetime(2005, 7, 31, 12, 30), ) a1.save() self.assertEqual(Article.objects.get(id__exact=a1.id).pub_date, datetime(2005, 7, 31, 12, 30)) a2 = Article( headline='Article 8', pub_date=datetime(2005, 7, 31, 12, 30, 45), ) a2.save() self.assertEqual(Article.objects.get(id__exact=a2.id).pub_date, datetime(2005, 7, 31, 12, 30, 45))
f1 = Field() f2 = Field(auto_created=True) f3 = Field() self.assertLess(f2, f1) self.assertGreater(f3, f1) self.assertIsNotNone(f1) self.assertNotIn(f2, (None, 1, ''))
self.assertEqual( sorted(BaseManager._get_queryset_methods(QuerySet).keys()), sorted(self.QUERYSET_PROXY_METHODS), )
application = get_wsgi_application() environ = RequestFactory()._base_environ( PATH_INFO="/", CONTENT_TYPE="text/html; charset=utf-8", REQUEST_METHOD="GET" ) response_data = {} def start_response(status, headers): response_data["status"] = status response_data["headers"] = headers response = application(environ, start_response) self.assertEqual(response_data["status"], "200 OK") self.assertEqual( response_data["headers"], [('Content-Type', 'text/html; charset=utf-8')]) self.assertEqual( bytes(response), b"Content-Type: text/html; charset=utf-8\r\n\r\nHello World!")
class FileWrapper(object): def __init__(self, filelike, blksize=8192): filelike.close() application = get_wsgi_application() environ = RequestFactory()._base_environ( PATH_INFO='/file/', REQUEST_METHOD='GET', **{'wsgi.file_wrapper': FileWrapper} ) response_data = {} def start_response(status, headers): response_data['status'] = status response_data['headers'] = headers response = application(environ, start_response) self.assertEqual(response_data['status'], '200 OK') self.assertIsInstance(response, FileWrapper)
app = get_internal_wsgi_application() from .wsgi import application self.assertIs(app, application)
lookup_name = 'exactly' def get_rhs_op(self, connection, rhs): return connection.operators['exact'] % rhs
test_list = ('1', '2', '3', '4', '11', '12', '13', '101', '102', '103', '111', 'something else', None) result_list = ('1<sup>er</sup>', '2<sup>e</sup>', '3<sup>e</sup>', '4<sup>e</sup>', '11<sup>e</sup>', '12<sup>e</sup>', '13<sup>e</sup>', '101<sup>er</sup>', '102<sup>e</sup>', '103<sup>e</sup>', '111<sup>e</sup>', 'something else', 'None') with translation.override('fr-fr'): self.humanize_tester(test_list, result_list, 'ordinal', lambda x: x)
time_format = '%d %b %Y %H:%M:%S' documented_now = datetime.datetime.strptime('17 Feb 2007 16:30:00', time_format) test_data = ( ('17 Feb 2007 16:30:00', 'now'), ('17 Feb 2007 16:29:31', '29 seconds ago'), ('17 Feb 2007 16:29:00', 'a minute ago'), ('17 Feb 2007 16:25:35', '4 minutes ago'), ('17 Feb 2007 15:30:29', '59 minutes ago'), ('17 Feb 2007 15:30:01', '59 minutes ago'), ('17 Feb 2007 15:30:00', 'an hour ago'), ('17 Feb 2007 13:31:29', '2 hours ago'), ('16 Feb 2007 13:31:29', '1 day, 2 hours ago'), ('16 Feb 2007 13:30:01', '1 day, 2 hours ago'), ('16 Feb 2007 13:30:00', '1 day, 3 hours ago'), ('17 Feb 2007 16:30:30', '30 seconds from now'), ('17 Feb 2007 16:30:29', '29 seconds from now'), ('17 Feb 2007 16:31:00', 'a minute from now'), ('17 Feb 2007 16:34:35', '4 minutes from now'), ('17 Feb 2007 17:30:29', 'an hour from now'), ('17 Feb 2007 18:31:29', '2 hours from now'), ('18 Feb 2007 16:31:29', '1 day from now'), ('26 Feb 2007 18:31:29', '1 week, 2 days from now'), ) class DocumentedMockDateTime(datetime.datetime): @classmethod def now(cls, tz=None): if tz is None or tz.utcoffset(documented_now) is None: return documented_now else: return documented_now.replace(tzinfo=tz) + tz.utcoffset(now) orig_humanize_datetime = humanize.datetime humanize.datetime = DocumentedMockDateTime try: for test_time_string, expected_natural_time in test_data: test_time = datetime.datetime.strptime(test_time_string, time_format) natural_time = humanize.naturaltime(test_time).replace('\xa0', ' ') self.assertEqual(expected_natural_time, natural_time) finally: humanize.datetime = orig_humanize_datetime
if isinstance(message, binary_type): message = message_from_bytes(message) msg_headers = set(message.items()) self.assertTrue(headers.issubset(msg_headers), msg='Message is missing ' 'the following headers: %s' % (headers - msg_headers),)
headers = {"date": "Fri, 09 Nov 2001 01:08:47 -0000", "Message-ID": "foo"} email = EmailMessage('subject', 'content', 'from@example.com', ['to@example.com'], headers=headers) self.assertMessageHasHeaders(email.message(), { ('Content-Transfer-Encoding', '7bit'), ('Content-Type', 'text/plain; charset="utf-8"'), ('From', 'from@example.com'), ('MIME-Version', '1.0'), ('Message-ID', 'foo'), ('Subject', 'subject'), ('To', 'to@example.com'), ('date', 'Fri, 09 Nov 2001 01:08:47 -0000'), })
email = EmailMessage( 'Subject', 'Content', 'bounce@example.com', ['to@example.com'], headers={'From': 'from@example.com'}, ) message = email.message() self.assertEqual(message['From'], 'from@example.com')
email = EmailMessage( 'Subject', 'Content', 'bounce@example.com', ['to@example.com'], reply_to=['foo@example.com'], headers={'Reply-To': 'override@example.com'}, ) message = email.message() self.assertEqual(message['Reply-To'], 'override@example.com')
email = EmailMessage( 'Subject', 'Content', 'bounce@example.com', ['to@example.com'], headers={'From': 'from@example.com'}, ) message = email.message() self.assertEqual(message['From'], 'from@example.com') message = email.message() self.assertEqual(message['From'], 'from@example.com')
email = EmailMessage( 'Subject', 'Content', 'from@example.com', ['"Firstname Srname" <to@example.com>', 'other@example.com'], ) self.assertEqual( email.message()['To'], '=?utf-8?q?Firstname_S=C3=BCrname?= <to@example.com>, other@example.com' ) email = EmailMessage( 'Subject', 'Content', 'from@example.com', ['"Srname, Firstname" <to@example.com>', 'other@example.com'], ) self.assertEqual( email.message()['To'], '=?utf-8?q?S=C3=BCrname=2C_Firstname?= <to@example.com>, other@example.com' )
headers = {"Date": "Fri, 09 Nov 2001 01:08:47 -0000", "Message-ID": "foo"} from_email, to = 'from@example.com', '"Srname, Firstname" <to@example.com>' text_content = 'This is an important message.' html_content = '<p>This is an <strong>important</strong> message.</p>' msg = EmailMultiAlternatives('Message from Firstname Srname', text_content, from_email, [to], headers=headers) msg.attach_alternative(html_content, "text/html") msg.encoding = 'iso-8859-1' self.assertEqual(msg.message()['To'], '=?iso-8859-1?q?S=FCrname=2C_Firstname?= <to@example.com>') self.assertEqual(msg.message()['Subject'], '=?iso-8859-1?q?Message_from_Firstname_S=FCrname?=')
headers = {"Date": "Fri, 09 Nov 2001 01:08:47 -0000", "Message-ID": "foo"} subject, from_email, to = 'hello', 'from@example.com', 'to@example.com' text_content = 'This is an important message.' html_content = '<p>This is an <strong>important</strong> message.</p>' msg = EmailMultiAlternatives(subject, text_content, from_email, [to], headers=headers) msg.attach_alternative(html_content, "text/html") msg.attach("an attachment.pdf", b"%PDF-1.4.%...", mimetype="application/pdf") msg_bytes = msg.message().as_bytes() message = message_from_bytes(msg_bytes) self.assertTrue(message.is_multipart()) self.assertEqual(message.get_content_type(), 'multipart/mixed') self.assertEqual(message.get_default_type(), 'text/plain') payload = message.get_payload() self.assertEqual(payload[0].get_content_type(), 'multipart/alternative') self.assertEqual(payload[1].get_content_type(), 'application/pdf')
connection = dummy.EmailBackend() email = EmailMessage( 'Subject', 'Content', 'bounce@example.com', ['to@example.com'], headers={'From': 'from@example.com'}, ) self.assertEqual(connection.send_messages([email, email, email]), 3)
c = mail.get_connection(fail_silently=True, foo='bar') self.assertTrue(c.fail_silently)
conn = mail.get_connection('mail.custombackend.EmailBackend') self.assertTrue(hasattr(conn, 'test_outbox')) email = EmailMessage( 'Subject', 'Content', 'bounce@example.com', ['to@example.com'], headers={'From': 'from@example.com'}, ) conn.send_messages([email]) self.assertEqual(len(conn.test_outbox), 1)
self.assertIsInstance(mail.get_connection('django.core.mail.backends.smtp.EmailBackend'), smtp.EmailBackend) self.assertIsInstance( mail.get_connection('django.core.mail.backends.locmem.EmailBackend'), locmem.EmailBackend ) self.assertIsInstance(mail.get_connection('django.core.mail.backends.dummy.EmailBackend'), dummy.EmailBackend) self.assertIsInstance( mail.get_connection('django.core.mail.backends.console.EmailBackend'), console.EmailBackend ) tmp_dir = tempfile.mkdtemp() try: self.assertIsInstance( mail.get_connection('django.core.mail.backends.filebased.EmailBackend', file_path=tmp_dir), filebased.EmailBackend ) finally: shutil.rmtree(tmp_dir) self.assertIsInstance(mail.get_connection(), locmem.EmailBackend)
def test_utf8(self): txt = MIMEText('UTF-8 encoded body', 'plain', 'utf-8') self.assertIn('Content-Transfer-Encoding: base64', txt.as_string()) def test_7bit(self): txt = MIMEText('Body with only ASCII characters.', 'plain', 'utf-8') self.assertIn('Content-Transfer-Encoding: base64', txt.as_string()) def test_8bit_latin(self): txt = MIMEText('Body with latin characters: .', 'plain', 'utf-8') self.assertIn(str('Content-Transfer-Encoding: base64'), txt.as_string()) def test_8bit_non_latin(self): txt = MIMEText('Body with non latin characters:                 .', 'plain', 'utf-8') self.assertIn(str('Content-Transfer-Encoding: base64'), txt.as_string())
email = EmailMessage('Subject', "Comment a va? " * 100, 'from@example.com', ['to@example.com']) email.send() message = self.get_the_message() self.assertMessageHasHeaders(message, { ('MIME-Version', '1.0'), ('Content-Type', 'text/plain; charset="utf-8"'), ('Content-Transfer-Encoding', 'quoted-printable'), })
send_mail('Subject', 'Content', 'sender@example.com', ['nobody@example.com']) message = self.get_the_message() self.assertEqual(message.get('subject'), 'Subject') self.assertEqual(message.get_all('to'), ['nobody@example.com']) self.assertFalse(message.is_multipart()) self.assertEqual(message.get_payload(), 'Content') self.assertEqual(message.get_content_type(), 'text/plain')
send_mail('Subject', 'Content', 'sender@example.com', ['nobody@example.com'], html_message='HTML Content') message = self.get_the_message() self.assertEqual(message.get('subject'), 'Subject') self.assertEqual(message.get_all('to'), ['nobody@example.com']) self.assertTrue(message.is_multipart()) self.assertEqual(len(message.get_payload()), 2) self.assertEqual(message.get_payload(0).get_payload(), 'Content') self.assertEqual(message.get_payload(0).get_content_type(), 'text/plain') self.assertEqual(message.get_payload(1).get_payload(), 'HTML Content') self.assertEqual(message.get_payload(1).get_content_type(), 'text/html')
mail_managers('Subject', 'Content', html_message='HTML Content') message = self.get_the_message() self.assertEqual(message.get('subject'), '[Django] Subject') self.assertEqual(message.get_all('to'), ['nobody@example.com']) self.assertTrue(message.is_multipart()) self.assertEqual(len(message.get_payload()), 2) self.assertEqual(message.get_payload(0).get_payload(), 'Content') self.assertEqual(message.get_payload(0).get_content_type(), 'text/plain') self.assertEqual(message.get_payload(1).get_payload(), 'HTML Content') self.assertEqual(message.get_payload(1).get_content_type(), 'text/html')
mail_admins('Subject', 'Content', html_message='HTML Content') message = self.get_the_message() self.assertEqual(message.get('subject'), '[Django] Subject') self.assertEqual(message.get_all('to'), ['nobody@example.com']) self.assertTrue(message.is_multipart()) self.assertEqual(len(message.get_payload()), 2) self.assertEqual(message.get_payload(0).get_payload(), 'Content') self.assertEqual(message.get_payload(0).get_content_type(), 'text/plain') self.assertEqual(message.get_payload(1).get_payload(), 'HTML Content') self.assertEqual(message.get_payload(1).get_content_type(), 'text/html')
mail_managers(ugettext_lazy('Subject'), 'Content') message = self.get_the_message() self.assertEqual(message.get('subject'), '[Django] Subject') self.flush_mailbox() mail_admins(ugettext_lazy('Subject'), 'Content') message = self.get_the_message() self.assertEqual(message.get('subject'), '[Django] Subject')
mail_admins('hi', 'there') self.assertEqual(self.get_mailbox_content(), []) mail_managers('hi', 'there') self.assertEqual(self.get_mailbox_content(), [])
email = EmailMessage('Subject', 'Content', 'from@example.com', ['to@example.com'], cc=['cc@example.com']) mail.get_connection().send_messages([email]) message = self.get_the_message() self.assertMessageHasHeaders(message, { ('MIME-Version', '1.0'), ('Content-Type', 'text/plain; charset="utf-8"'), ('Content-Transfer-Encoding', '7bit'), ('Subject', 'Subject'), ('From', 'from@example.com'), ('To', 'to@example.com'), ('Cc', 'cc@example.com')}) self.assertIn('\nDate: ', message.as_string())
self.assertTrue(send_mail('Subject', 'Content', 'from@.com', ['to@.com'])) message = self.get_the_message() self.assertEqual(message.get('subject'), 'Subject') self.assertEqual(message.get('from'), 'from@xn--4ca9at.com') self.assertEqual(message.get('to'), 'to@xn--4ca9at.com') self.flush_mailbox() m = EmailMessage('Subject', 'Content', 'from@.com', ['to@.com'], cc=['cc@.com']) m.send() message = self.get_the_message() self.assertEqual(message.get('subject'), 'Subject') self.assertEqual(message.get('from'), 'from@xn--4ca9at.com') self.assertEqual(message.get('to'), 'to@xn--4ca9at.com') self.assertEqual(message.get('cc'), 'cc@xn--4ca9at.com')
self.assertTrue(send_mail("Subject", "Content", "tester", ["django"])) message = self.get_the_message() self.assertEqual(message.get('subject'), 'Subject') self.assertEqual(message.get('from'), "tester") self.assertEqual(message.get('to'), "django")
_ = ugettext_lazy self.assertTrue(send_mail('Subject', 'Content', _('tester'), [_('django')])) message = self.get_the_message() self.assertEqual(message.get('from'), 'tester') self.assertEqual(message.get('to'), 'django') self.flush_mailbox() m = EmailMessage( 'Subject', 'Content', _('tester'), [_('to1'), _('to2')], cc=[_('cc1'), _('cc2')], bcc=[_('bcc')], reply_to=[_('reply')], ) self.assertEqual(m.recipients(), ['to1', 'to2', 'cc1', 'cc2', 'bcc']) m.send() message = self.get_the_message() self.assertEqual(message.get('from'), 'tester') self.assertEqual(message.get('to'), 'to1, to2') self.assertEqual(message.get('cc'), 'cc1, cc2') self.assertEqual(message.get('Reply-To'), 'reply')
conn = mail.get_connection(username='', password='') conn.close()
opened = [False] closed = [False] conn = mail.get_connection(username='', password='') def open(): opened[0] = True conn.open = open def close(): closed[0] = True conn.close = close with conn as same_conn: self.assertTrue(opened[0]) self.assertIs(same_conn, conn) self.assertFalse(closed[0]) self.assertTrue(closed[0])
connection = locmem.EmailBackend() connection2 = locmem.EmailBackend() email = EmailMessage( 'Subject', 'Content', 'bounce@example.com', ['to@example.com'], headers={'From': 'from@example.com'}, ) connection.send_messages([email]) connection2.send_messages([email]) self.assertEqual(len(mail.outbox), 2)
msg = EmailMessage( 'Subject', 'Content', 'bounce@example.com', ['to@example.com'], headers={'From': 'from@example.com'}, ) connection = mail.get_connection() connection.send_messages([msg]) self.assertEqual(len(os.listdir(self.tmp_dir)), 1) with open(os.path.join(self.tmp_dir, os.listdir(self.tmp_dir)[0]), 'rb') as fp: message = message_from_binary_file(fp) self.assertEqual(message.get_content_type(), 'text/plain') self.assertEqual(message.get('subject'), 'Subject') self.assertEqual(message.get('from'), 'from@example.com') self.assertEqual(message.get('to'), 'to@example.com') connection2 = mail.get_connection() connection2.send_messages([msg]) self.assertEqual(len(os.listdir(self.tmp_dir)), 2) connection.send_messages([msg]) self.assertEqual(len(os.listdir(self.tmp_dir)), 2) msg.connection = mail.get_connection() self.assertTrue(connection.open()) msg.send() self.assertEqual(len(os.listdir(self.tmp_dir)), 3) msg.send() self.assertEqual(len(os.listdir(self.tmp_dir)), 3) connection.close()
s = StringIO() connection = mail.get_connection('django.core.mail.backends.console.EmailBackend', stream=s) send_mail('Subject', 'Content', 'from@example.com', ['to@example.com'], connection=connection) message = force_bytes(s.getvalue().split('\n' + ('-' * 79) + '\n')[0]) self.assertMessageHasHeaders(message, { ('MIME-Version', '1.0'), ('Content-Type', 'text/plain; charset="utf-8"'), ('Content-Transfer-Encoding', '7bit'), ('Subject', 'Subject'), ('From', 'from@example.com'), ('To', 'to@example.com')}) self.assertIn(b'\nDate: ', message)
backend = smtp.EmailBackend( username='not empty username', password='not empty password') try: with self.assertRaisesMessage(SMTPException, 'SMTP AUTH extension not supported by server.'): backend.open() finally: backend.close()
backend = smtp.EmailBackend(username='', password='') self.assertFalse(backend.connection) opened = backend.open() backend.close() self.assertTrue(opened)
connection = mail.get_connection('django.core.mail.backends.smtp.EmailBackend') self.assertEqual(connection.timeout, None)
class MyEmailBackend(smtp.EmailBackend): def __init__(self, *args, **kwargs): kwargs.setdefault('timeout', 42) super(MyEmailBackend, self).__init__(*args, **kwargs) myemailbackend = MyEmailBackend() myemailbackend.open() self.assertEqual(myemailbackend.timeout, 42) self.assertEqual(myemailbackend.connection.timeout, 42) myemailbackend.close()
recipient = 'joe@example.com' call_command('sendtestemail', recipient) self.assertEqual(len(mail.outbox), 1) mail_message = mail.outbox[0] self.assertEqual(mail_message.subject[0:15], 'Test email from') self.assertEqual(mail_message.recipients(), [recipient])
recipients = ['joe@example.com', 'jane@example.com'] call_command('sendtestemail', recipients[0], recipients[1]) self.assertEqual(len(mail.outbox), 1) mail_message = mail.outbox[0] self.assertEqual(mail_message.subject[0:15], 'Test email from') self.assertEqual(sorted(mail_message.recipients()), [ 'jane@example.com', 'joe@example.com', ])
call_command('sendtestemail', '--managers') self.assertEqual(len(mail.outbox), 1) mail_message = mail.outbox[0] self.assertEqual(sorted(mail_message.recipients()), [ 'admin_and_manager@example.com', 'manager@example.com', ])
call_command('sendtestemail', '--admins') self.assertEqual(len(mail.outbox), 1) mail_message = mail.outbox[0] self.assertEqual(sorted(mail_message.recipients()), [ 'admin@example.com', 'admin_and_manager@example.com', ])
name = models.CharField(max_length=30, unique=True) def __str__(self): return self.name
def get_absolute_url(self): return "/users/%s/" % urlquote(self.name)
def get_absolute_url(self): return "/users/%s/" % self.unknown_field
title = models.CharField(max_length=200) content_type = models.ForeignKey(ContentType, models.CASCADE, null=True) object_id = models.PositiveIntegerField(null=True) parent = GenericForeignKey() children = GenericRelation('Post') class Meta: order_with_respect_to = 'parent' def __str__(self): return self.title
for obj in SchemeIncludedURL.objects.all(): short_url = '/shortcut/%s/%s/' % (ContentType.objects.get_for_model(SchemeIncludedURL).id, obj.pk) response = self.client.get(short_url) self.assertRedirects(response, obj.get_absolute_url(), status_code=302, fetch_redirect_response=False)
get_model.side_effect = lambda *args, **kwargs: MockSite if args[0] == 'sites.Site' else ModelWithNullFKToSite obj = ModelWithNullFKToSite.objects.create(title='title') url = '/shortcut/%s/%s/' % (ContentType.objects.get_for_model(ModelWithNullFKToSite).id, obj.pk) response = self.client.get(url) self.assertRedirects( response, '%s' % obj.get_absolute_url(), fetch_redirect_response=False, )
contenttypes_management.input = lambda x: force_str("yes") with captured_stdout() as stdout: contenttypes_management.update_contenttypes(self.app_config) self.assertIn("Deleting stale content type", stdout.getvalue()) self.assertEqual(ContentType.objects.count(), self.before_count)
with captured_stdout() as stdout: contenttypes_management.update_contenttypes(self.app_config, interactive=False) self.assertIn("Stale content types remain.", stdout.getvalue()) self.assertEqual(ContentType.objects.count(), self.before_count + 1)
apps = Apps() with self.assertNumQueries(0): contenttypes_management.update_contenttypes(self.app_config, interactive=False, verbosity=0, apps=apps) self.assertEqual(ContentType.objects.count(), self.before_count + 1)
ContentType.objects.clear_cache() with self.assertNumQueries(0, using='default'), \ self.assertNumQueries(1, using='other'): ContentType.objects.get_for_model(Author)
request = HttpRequest() request.META = { "SERVER_NAME": "Example.com", "SERVER_PORT": "80", } user_ct = ContentType.objects.get_for_model(FooWithUrl) obj = FooWithUrl.objects.create(name="john") with self.modify_settings(INSTALLED_APPS={'append': 'django.contrib.sites'}): response = shortcut(request, user_ct.id, obj.id) self.assertEqual( "http://%s/users/john/" % get_current_site(request).domain, response._headers.get("location")[1] ) with self.modify_settings(INSTALLED_APPS={'remove': 'django.contrib.sites'}): response = shortcut(request, user_ct.id, obj.id) self.assertEqual("http://Example.com/users/john/", response._headers.get("location")[1])
request = HttpRequest() request.META = { "SERVER_NAME": "Example.com", "SERVER_PORT": "80", } user_ct = ContentType.objects.get_for_model(FooWithoutUrl) obj = FooWithoutUrl.objects.create(name="john") with self.assertRaises(Http404): shortcut(request, user_ct.id, obj.id)
request = HttpRequest() request.META = { "SERVER_NAME": "Example.com", "SERVER_PORT": "80", } user_ct = ContentType.objects.get_for_model(FooWithBrokenAbsoluteUrl) obj = FooWithBrokenAbsoluteUrl.objects.create(name="john") with self.assertRaises(AttributeError): shortcut(request, user_ct.id, obj.id)
return self._get_full_name()
url = reverse('django-admindocs-views-detail', args=['urlpatterns_reverse.nonimported_module.view']) response = self.client.get(url) self.assertEqual(response.status_code, 404) self.assertNotIn("urlpatterns_reverse.nonimported_module", sys.modules)
markup = '<p><a class="reference external" href="/admindocs/%s">title</a></p>\n' self.assertEqual(utils.parse_rst('`title`', 'model'), markup % 'models/title/') self.assertEqual(utils.parse_rst('`title`', 'view'), markup % 'views/title/') self.assertEqual(utils.parse_rst('`title`', 'template'), markup % 'templates/title/') self.assertEqual(utils.parse_rst('`title`', 'filter'), markup % 'filters/#title') self.assertEqual(utils.parse_rst('`title`', 'tag'), markup % 'tags/#title')
import docutils self.assertNotEqual(docutils.parsers.rst.roles.DEFAULT_INTERPRETED_ROLE, 'cmsreference') source = 'reST, `interpreted text`, default role.' markup = '<p>reST, <cite>interpreted text</cite>, default role.</p>\n' parts = docutils.core.publish_parts(source=source, writer_name="html4css1") self.assertEqual(parts['fragment'], markup)
self.assertContains(self.response, "<td>get_full_name</td>") self.assertNotContains(self.response, "<td>_get_full_name</td>") self.assertNotContains(self.response, "<td>add_image</td>") self.assertNotContains(self.response, "<td>delete_image</td>") self.assertNotContains(self.response, "<td>set_status</td>") self.assertNotContains(self.response, "<td>save_changes</td>")
self.assertContains(self.response, "<h3>Methods with arguments</h3>") self.assertContains(self.response, "<td>rename_company</td>") self.assertContains(self.response, "<td>dummy_function</td>") self.assertContains(self.response, "<td>suffix_company_name</td>")
self.assertContains(self.response, "<td>new_name</td>")
self.assertContains(self.response, "<td>suffix=&#39;ltd&#39;</td>")
self.assertContains(self.response, "<td>baz, rox, *some_args, **some_kwargs</td>")
company = Company.objects.create(name="Django") person = Person.objects.create(first_name="Human", last_name="User", company=company) self.assertEqual(get_return_data_type(person.get_status_count.__name__), 'Integer') self.assertEqual(get_return_data_type(person.get_groups_list.__name__), 'List')
response = self.client.get(reverse('django-admindocs-models-detail', args=['admin_docs', 'family'])) fields = response.context_data.get('fields') self.assertEqual(len(fields), 2)
def setUp(self): self.docstring = self.__doc__ def test_trim_docstring(self): trim_docstring_output = utils.trim_docstring(self.docstring) trimmed_docstring = ( 'This __doc__ output is required for testing. I copied this ' 'example from\n`admindocs` documentation. (TITLE)\n\n' 'Display an individual :model:`myapp.MyModel`.\n\n' '**Context**\n\n``RequestContext``\n\n``mymodel``\n' ' An instance of :model:`myapp.MyModel`.\n\n' '**Template:**\n\n:template:`myapp/my_template.html` ' '(DESCRIPTION)\n\nsome_metadata: some data' ) self.assertEqual(trim_docstring_output, trimmed_docstring) def test_parse_docstring(self): title, description, metadata = utils.parse_docstring(self.docstring) docstring_title = ( 'This __doc__ output is required for testing. I copied this example from\n' '`admindocs` documentation. (TITLE)' ) docstring_description = ( 'Display an individual :model:`myapp.MyModel`.\n\n' '**Context**\n\n``RequestContext``\n\n``mymodel``\n' ' An instance of :model:`myapp.MyModel`.\n\n' '**Template:**\n\n:template:`myapp/my_template.html` ' '(DESCRIPTION)' ) self.assertEqual(title, docstring_title) self.assertEqual(description, docstring_description) self.assertEqual(metadata, {'some_metadata': 'some data'}) def test_title_output(self): title, description, metadata = utils.parse_docstring(self.docstring) title_output = utils.parse_rst(title, 'model', 'model:admindocs') self.assertIn('TITLE', title_output) title_rendered = ( '<p>This __doc__ output is required for testing. I copied this ' 'example from\n<a class="reference external" ' 'href="/admindocs/models/admindocs/">admindocs</a> documentation. ' '(TITLE)</p>\n' ) self.assertHTMLEqual(title_output, title_rendered) def test_description_output(self): title, description, metadata = utils.parse_docstring(self.docstring) description_output = utils.parse_rst(description, 'model', 'model:admindocs') description_rendered = ( '<p>Display an individual <a class="reference external" ' 'href="/admindocs/models/myapp.mymodel/">myapp.MyModel</a>.</p>\n' '<p><strong>Context</strong></p>\n<p><tt class="docutils literal">' 'RequestContext</tt></p>\n<dl class="docutils">\n<dt><tt class="' 'docutils literal">mymodel</tt></dt>\n<dd>An instance of <a class="' 'reference external" href="/admindocs/models/myapp.mymodel/">' 'myapp.MyModel</a>.</dd>\n</dl>\n<p><strong>Template:</strong></p>' '\n<p><a class="reference external" href="/admindocs/templates/' 'myapp/my_template.html/">myapp/my_template.html</a> (DESCRIPTION)' '</p>\n' ) self.assertHTMLEqual(description_output, description_rendered) def test_initial_header_level(self): header = 'should be h3...\n\nHeader\n------\n' output = utils.parse_rst(header, 'header') self.assertIn('<h3>Header</h3>', output)
from django.db import models from django.utils.encoding import python_2_unicode_compatible @python_2_unicode_compatible class Article(models.Model): headline = models.CharField(max_length=50) pub_date = models.DateTimeField() class Meta: ordering = ('pub_date',) def __str__(self): return self.headline
from __future__ import unicode_literals from django.db import models from django.utils.encoding import python_2_unicode_compatible @python_2_unicode_compatible class Author(models.Model): Author_ID = models.AutoField(primary_key=True, db_column='Author ID') first_name = models.CharField(max_length=30, db_column='firstname') last_name = models.CharField(max_length=30, db_column='last') def __str__(self): return '%s %s' % (self.first_name, self.last_name) class Meta: db_table = 'my_author_table' ordering = ('last_name', 'first_name') @python_2_unicode_compatible class Article(models.Model): Article_ID = models.AutoField(primary_key=True, db_column='Article ID') headline = models.CharField(max_length=100) authors = models.ManyToManyField(Author, db_table='my_m2m_table') primary_author = models.ForeignKey( Author, models.SET_NULL, db_column='Author ID', related_name='primary_set', null=True, ) def __str__(self): return self.headline class Meta: ordering = ('headline',)
r = Researcher.objects.create() email = Email.objects.create( label="office-email", email_address="carl@science.edu" ) r.contacts.add(email) email.delete()
apple = Food.objects.create(name="apple") Eaten.objects.create(food=apple, meal="lunch") apple.delete() self.assertFalse(Food.objects.exists()) self.assertFalse(Eaten.objects.exists())
tpl = Template( "{% load tz %}" "{{ dt }}|" "{% timezone tz1 %}" "{{ dt }}|" "{% timezone tz2 %}" "{{ dt }}" "{% endtimezone %}" "{% endtimezone %}" ) ctx = Context({'dt': datetime.datetime(2011, 9, 1, 10, 20, 30, tzinfo=UTC), 'tz1': ICT, 'tz2': None}) self.assertEqual( tpl.render(ctx), "2011-09-01T13:20:30+03:00|2011-09-01T17:20:30+07:00|2011-09-01T13:20:30+03:00" )
tpl = Template("{% load tz %}{% get_current_timezone as time_zone %}{{ time_zone }}") self.assertEqual(tpl.render(Context()), "Africa/Nairobi" if pytz else "EAT") with timezone.override(UTC): self.assertEqual(tpl.render(Context()), "UTC") tpl = Template( "{% load tz %}{% timezone tz %}{% get_current_timezone as time_zone %}" "{% endtimezone %}{{ time_zone }}" ) self.assertEqual(tpl.render(Context({'tz': ICT})), "+0700") with timezone.override(UTC): self.assertEqual(tpl.render(Context({'tz': ICT})), "+0700")
tpl = Template("{% load tz %}{% get_current_timezone as time_zone %}{{ time_zone }}") with timezone.override(pytz.timezone('Europe/Paris')): self.assertEqual(tpl.render(Context()), "Europe/Paris") tpl = Template( "{% load tz %}{% timezone 'Europe/Paris' %}" "{% get_current_timezone as time_zone %}{% endtimezone %}" "{{ time_zone }}" ) self.assertEqual(tpl.render(Context()), "Europe/Paris")
tpl = Template("{{ TIME_ZONE }}") context = Context() self.assertEqual(tpl.render(context), "") request_context = RequestContext(HttpRequest(), processors=[context_processors.tz]) self.assertEqual(tpl.render(request_context), "Africa/Nairobi" if pytz else "EAT")
return self.name
title = models.CharField(max_length=100) content = models.TextField() date = models.DateTimeField() section = models.ForeignKey(Section, models.CASCADE, null=True, blank=True) another_section = models.ForeignKey(Section, models.CASCADE, null=True, blank=True, related_name='+') sub_section = models.ForeignKey(Section, models.SET_NULL, null=True, blank=True, related_name='+') def __str__(self): return self.title def model_year(self): return self.date.year model_year.admin_order_field = 'date' model_year.short_description = '' def model_year_reversed(self): return self.date.year model_year_reversed.admin_order_field = '-date' model_year_reversed.short_description = ''
name = models.CharField(max_length=100, verbose_name='Name?') def __str__(self): return self.name
name = models.CharField(blank=False, max_length=80) def __str__(self): return self.name
username = models.CharField(blank=False, max_length=80) persona = models.ForeignKey(Persona, models.CASCADE, related_name="accounts") servicename = 'generic service' def __str__(self): return "%s: %s" % (self.servicename, self.username)
servicename = 'foo'
servicename = 'bar'
location = models.CharField(max_length=100) villain = models.ForeignKey(Villain, models.CASCADE) def __str__(self): return self.location
location = models.CharField(max_length=100) supervillain = models.ForeignKey(SuperVillain, models.CASCADE) def __str__(self): return self.location
name = models.CharField(max_length=255) bool = models.BooleanField(default=True)
name = models.CharField(max_length=255)
some_required_info = models.PositiveIntegerField() family_name = models.CharField(max_length=255, blank=False)
parent = models.ForeignKey(ParentWithDependentChildren, models.CASCADE) family_name = models.CharField(max_length=255)
admin_form = response.context['adminform'] fieldsets = list(admin_form) field_lines = [] for fieldset in fieldsets: field_lines += list(fieldset) fields = [] for field_line in field_lines: fields += list(field_line) return fields
return [f for f in self.get_admin_form_fields(response) if f.is_readonly]
admin_readonly_fields = self.get_admin_readonly_fields(response) for field in admin_readonly_fields: if field.field['name'] == field_name: return field
self.assertEqual(response.status_code, 200) self.assertLess( response.content.index(force_bytes(text1)), response.content.index(force_bytes(text2)), (failing_msg or '') + '\nResponse:\n' + response.content.decode(response.charset) )
add_url = reverse('admin:admin_views_article_add') response = self.client.get(add_url[:-1]) self.assertRedirects(response, add_url, status_code=301)
old_url = staticfiles_storage.base_url staticfiles_storage.base_url = '/test/' try: self.assertEqual(static('path'), '/test/path') finally: staticfiles_storage.base_url = old_url
response = self.client.get(reverse('admin:admin_views_section_add')) self.assertIsInstance(response, TemplateResponse) self.assertEqual(response.status_code, 200)
response = self.client.get(reverse('admin:admin_views_section_change', args=(self.s1.pk,))) self.assertIsInstance(response, TemplateResponse) self.assertEqual(response.status_code, 200)
response = self.client.get(reverse('admin:admin_views_section_change', args=('abc',))) self.assertEqual(response.status_code, 404)
response = self.client.get( reverse('admin:admin_views_section_change', args=(self.s1.pk,)).replace('change/', '') ) self.assertRedirects(response, reverse('admin:admin_views_section_change', args=(self.s1.pk,)))
response = self.client.get(reverse('admin:admin_views_supervillain_change', args=('abc',))) self.assertEqual(response.status_code, 404)
post_data = { '_popup': '1', 'title': 'title with a new\nline', 'content': 'some content', 'date_0': '2010-09-10', 'date_1': '14:55:39', } response = self.client.post(reverse('admin:admin_views_article_add'), post_data) self.assertContains(response, 'title with a new\\nline')
response = self.client.get(reverse('admin:admin_views_article_changelist'), {'o': 2}) self.assertContentBefore( response, 'Oldest content', 'Middle content', "Results of sorting on callable are out of order." ) self.assertContentBefore( response, 'Middle content', 'Newest content', "Results of sorting on callable are out of order." )
response = self.client.get(reverse('admin:admin_views_article_changelist'), {'o': '-3'}) self.assertContentBefore( response, 'Newest content', 'Middle content', "Results of sorting on Model method are out of order." ) self.assertContentBefore( response, 'Middle content', 'Oldest content', "Results of sorting on Model method are out of order." )
response = self.client.get(reverse('admin:admin_views_article_changelist'), {'o': '4'}) self.assertContentBefore( response, 'Oldest content', 'Middle content', "Results of sorting on ModelAdmin method are out of order." ) self.assertContentBefore( response, 'Middle content', 'Newest content', "Results of sorting on ModelAdmin method are out of order." )
p1 = Person.objects.create(name="Amy", gender=1, alive=True, age=80) p2 = Person.objects.create(name="Bob", gender=1, alive=True, age=70) p3 = Person.objects.create(name="Chris", gender=2, alive=False, age=60) link1 = reverse('admin:admin_views_person_change', args=(p1.pk,)) link2 = reverse('admin:admin_views_person_change', args=(p2.pk,)) link3 = reverse('admin:admin_views_person_change', args=(p3.pk,)) response = self.client.get(reverse('admin:admin_views_person_changelist'), {}) self.assertContentBefore(response, link3, link2) self.assertContentBefore(response, link2, link1)
response = self.client.get(reverse('admin:admin_views_thing_changelist')) self.assertContains( response, '<div id="changelist-filter">', msg_prefix="Expected filter not found in changelist view" ) self.assertNotContains( response, '<a href="?color__id__exact=3">Blue</a>', msg_prefix="Changelist filter not correctly limited by limit_choices_to" )
Article.objects.create(title="I Could Go Anywhere", content="Versatile", date=datetime.datetime.now()) changelist_url = reverse('admin:admin_views_article_changelist') response = self.client.get(changelist_url) self.assertContains(response, '4 articles') response = self.client.get(changelist_url, {'section__isnull': 'false'}) self.assertContains(response, '3 articles') response = self.client.get(changelist_url, {'section__isnull': '0'}) self.assertContains(response, '3 articles') response = self.client.get(changelist_url, {'section__isnull': 'true'}) self.assertContains(response, '1 article') response = self.client.get(changelist_url, {'section__isnull': '1'}) self.assertContains(response, '1 article')
link1 = reverse('admin:admin_views_fabric_change', args=(self.fab1.pk,)) link2 = reverse('admin:admin_views_fabric_change', args=(self.fab2.pk,)) response = self.client.get(reverse('admin:admin_views_fabric_changelist')) fail_msg = ( "Changelist table isn't showing the right human-readable values " "set by a model field 'choices' option named group." ) self.assertContains(response, '<a href="%s">Horizontal</a>' % link1, msg_prefix=fail_msg, html=True) self.assertContains(response, '<a href="%s">Vertical</a>' % link2, msg_prefix=fail_msg, html=True)
response = self.client.get(reverse('admin:admin_views_fabric_changelist')) fail_msg = ( "Changelist filter isn't showing options contained inside a model " "field 'choices' option named group." ) self.assertContains(response, '<div id="changelist-filter">') self.assertContains(response, '<a href="?surface__exact=x">Horizontal</a>', msg_prefix=fail_msg, html=True) self.assertContains(response, '<a href="?surface__exact=y">Vertical</a>', msg_prefix=fail_msg, html=True)
with self.settings(LANGUAGE_CODE='fr'), translation.override('en-us'): response = self.client.get(reverse('admin:jsi18n')) self.assertNotContains(response, 'Choisir une heure')
with self.settings(LANGUAGE_CODE='fr'), translation.override('none'): response = self.client.get(reverse('admin:jsi18n')) self.assertContains(response, 'Choisir une heure')
with self.settings(LANGUAGE_CODE='ru', USE_L10N=False), translation.override('none'): response = self.client.get(reverse('admin:jsi18n')) self.assertNotContains(response, '%d.%m.%Y %H:%M:%S') self.assertContains(response, '%Y-%m-%d %H:%M:%S')
actor = Actor.objects.create(name="Palin", age=27) response = self.client.get("%s?%s" % (reverse('admin:admin_views_actor_changelist'), IS_POPUP_VAR)) self.assertContains(response, 'data-popup-opener="%s"' % actor.pk)
user = User.objects.get(username='super') user.set_unusable_password() user.save() self.client.force_login(user) response = self.client.get(reverse('admin:index')) self.assertNotContains( response, reverse('admin:password_change'), msg_prefix='The "change password" link should not be displayed if a user does not have a usable password.' )
instance = UndeletableObject.objects.create(name='foo') response = self.client.get(reverse('admin:admin_views_undeletableobject_change', args=(instance.pk,))) self.assertNotContains(response, 'deletelink')
Simple.objects.create() with self.assertRaises(AttributeError): self.client.get(reverse('admin:admin_views_simple_changelist'))
good_url = '/test_admin/admin/admin_views/' confirm_good_url = reverse('admin:app_list', kwargs={'app_label': 'admin_views'}) self.assertEqual(good_url, confirm_good_url) with self.assertRaises(NoReverseMatch): reverse('admin:app_list', kwargs={'app_label': 'this_should_fail'}) with self.assertRaises(NoReverseMatch): reverse('admin:app_list', args=('admin_views2',))
url = reverse('admin:index') response = self.client.get(url) self.assertEqual(response.context['site_url'], '/my-site-url/') self.assertContains(response, '<a href="/my-site-url/">View site</a>')
response = self.client.get(reverse('admin:admin_views_section_add')) self.assertContains(response, 'bodyclass_consistency_check ')
user = User.objects.get(username='super') response = self.client.get(reverse('admin:auth_user_password_change', args=(user.id,))) self.assertContains(response, 'bodyclass_consistency_check ')
response = self.client.get(reverse('admin:index')) self.assertContains(response, 'bodyclass_consistency_check ')
response = self.client.get(reverse('admin:admin_views_article_changelist')) self.assertContains(response, 'bodyclass_consistency_check ')
self.client.logout() response = self.client.get(reverse('admin:login')) self.assertContains(response, 'bodyclass_consistency_check ')
group = Group.objects.create(name="foogroup") response = self.client.get(reverse('admin:auth_group_delete', args=(group.id,))) self.assertContains(response, 'bodyclass_consistency_check ')
group = Group.objects.create(name="foogroup") post_data = { 'action': 'delete_selected', 'selected_across': '0', 'index': '0', '_selected_action': group.id } response = self.client.post(reverse('admin:auth_group_changelist'), post_data) self.assertEqual(response.context['site_header'], 'Django administration') self.assertContains(response, 'bodyclass_consistency_check ')
response = self.client.get(reverse('admin:admin_views_color2_changelist')) self.assertTemplateUsed(response, 'custom_filter_template.html')
response = self.client.get( reverse('admin:admin_views_section_change', args=(self.s1.pk,), current_app=self.current_app) ) self.assertIn('form_url', response.context, msg='form_url not present in response.context') self.assertEqual(response.context['form_url'], 'pony')
with override_settings(DEBUG=False): response = self.client.get(reverse('admin:admin_views_section_add')) self.assertNotContains(response, 'vendor/jquery/jquery.js') self.assertContains(response, 'vendor/jquery/jquery.min.js') self.assertNotContains(response, 'prepopulate.js') self.assertContains(response, 'prepopulate.min.js') self.assertNotContains(response, 'actions.js') self.assertContains(response, 'actions.min.js') self.assertNotContains(response, 'collapse.js') self.assertContains(response, 'collapse.min.js') self.assertNotContains(response, 'inlines.js') self.assertContains(response, 'inlines.min.js') with override_settings(DEBUG=True): response = self.client.get(reverse('admin:admin_views_section_add')) self.assertContains(response, 'vendor/jquery/jquery.js') self.assertNotContains(response, 'vendor/jquery/jquery.min.js') self.assertContains(response, 'prepopulate.js') self.assertNotContains(response, 'prepopulate.min.js') self.assertContains(response, 'actions.js') self.assertNotContains(response, 'actions.min.js') self.assertContains(response, 'collapse.js') self.assertNotContains(response, 'collapse.min.js') self.assertContains(response, 'inlines.js') self.assertNotContains(response, 'inlines.min.js')
post_data = {'_saveasnew': '', 'name': 'John M', 'gender': 1, 'age': 42} response = self.client.post(reverse('admin:admin_views_person_change', args=(self.per1.pk,)), post_data) self.assertEqual(len(Person.objects.filter(name='John M')), 1) self.assertEqual(len(Person.objects.filter(id=self.per1.pk)), 1) new_person = Person.objects.latest('id') self.assertRedirects(response, reverse('admin:admin_views_person_change', args=(new_person.pk,)))
post_data = {'_saveasnew': '', 'name': 'John M', 'gender': 1, 'age': 42} url = reverse('admin:admin_views_person_change', args=(self.per1.pk,), current_app=site2.name) response = self.client.post(url, post_data) self.assertEqual(len(Person.objects.filter(name='John M')), 1) self.assertEqual(len(Person.objects.filter(id=self.per1.pk)), 1) self.assertRedirects(response, reverse('admin:admin_views_person_changelist', current_app=site2.name))
response = self.client.post(reverse('admin:admin_views_person_change', args=(self.per1.pk,)), { '_saveasnew': '', 'gender': 'invalid', '_addanother': 'fail', }) self.assertContains(response, 'Please correct the errors below.') self.assertFalse(response.context['show_save_and_add_another']) self.assertFalse(response.context['show_save_and_continue']) self.assertTrue(response.context['show_save_as_new'])
ct = ContentType.objects.get_for_model(Model) return Permission.objects.get(content_type=ct, codename=perm)
response = self.client.get(reverse('admin:login')) self.assertEqual(response.status_code, 200) self.assertEqual(response.context[REDIRECT_FIELD_NAME], reverse('admin:index'))
self.client.force_login(self.superuser) response = self.client.get(self.index_url) self.assertContains(response, 'admin_views') self.assertContains(response, 'Articles') self.client.logout() self.client.force_login(self.adduser) response = self.client.get(self.index_url) self.assertContains(response, 'admin_views') self.assertContains(response, 'Articles') self.client.logout() self.client.force_login(self.changeuser) response = self.client.get(self.index_url) self.assertContains(response, 'admin_views') self.assertContains(response, 'Articles') self.client.logout() self.client.force_login(self.deleteuser) response = self.client.get(self.index_url) self.assertContains(response, 'admin_views') self.assertContains(response, 'Articles')
index_url = reverse('admin7:index') self.client.force_login(self.superuser) response = self.client.get(index_url) self.assertNotContains(response, 'admin_views') self.assertNotContains(response, 'Articles') self.client.logout() self.client.force_login(self.adduser) response = self.client.get(index_url) self.assertNotContains(response, 'admin_views') self.assertNotContains(response, 'Articles') self.client.logout() self.client.force_login(self.changeuser) response = self.client.get(index_url) self.assertNotContains(response, 'admin_views') self.assertNotContains(response, 'Articles') self.client.logout() self.client.force_login(self.deleteuser) response = self.client.get(index_url) self.assertNotContains(response, 'admin_views') self.assertNotContains(response, 'Articles')
pattern = re.compile( force_bytes( r'<li>Plot: <a href="%s">World Domination</a>\s*<ul>\s*' r'<li>Plot details: <a href="%s">almost finished</a>' % ( reverse('admin:admin_views_plot_change', args=(self.pl1.pk,)), reverse('admin:admin_views_plotdetails_change', args=(self.pd1.pk,)), ) ) ) response = self.client.get(reverse('admin:admin_views_villain_delete', args=(self.v1.pk,))) six.assertRegex(self, response.content, pattern)
one = '<li>Cyclic one: <a href="%s">I am recursive</a>' % ( reverse('admin:admin_views_cyclicone_change', args=(self.cy1.pk,)), ) two = '<li>Cyclic two: <a href="%s">I am recursive too</a>' % ( reverse('admin:admin_views_cyclictwo_change', args=(self.cy2.pk,)), ) response = self.client.get(reverse('admin:admin_views_cyclicone_delete', args=(self.cy1.pk,))) self.assertContains(response, one, 1) self.assertContains(response, two, 1)
q = Question.objects.create(question='Why?') Answer.objects.create(question=q, answer='Because.') response = self.client.post(reverse('admin:admin_views_question_delete', args=(q.pk,)), {'post': 'yes'}) self.assertEqual(Question.objects.count(), 1) self.assertContains(response, "would require deleting the following protected related objects")
response = self.client.get(reverse('admin:admin_views_villain_delete', args=(self.v1.pk,))) self.assertContains(response, should_contain, 1)
should_contain = '<li>Plot: <a href="%s">World Domination</a>' % reverse( 'admin:admin_views_plot_change', args=(self.pl1.pk,) ) response = self.client.get(reverse('admin:admin_views_villain_delete', args=(self.v1.pk,))) self.assertContains(response, should_contain) response = self.client.get(reverse('admin:admin_views_villain_delete', args=(self.v2.pk,))) self.assertContains(response, should_contain)
should_contain = '<li>Plot: <a href="%s">World Peace</a></li>' % reverse( 'admin:admin_views_plot_change', args=(self.pl2.pk,) ) response = self.client.get(reverse('admin:admin_views_villain_delete', args=(self.v2.pk,))) self.assertContains(response, should_contain, 1)
should_contain = [ '<li>Villain: <a href="%s">Bob</a>' % reverse('admin:admin_views_villain_change', args=(self.sv1.pk,)), '<li>Super villain: <a href="%s">Bob</a>' % reverse( 'admin:admin_views_supervillain_change', args=(self.sv1.pk,) ), '<li>Secret hideout: floating castle', '<li>Super secret hideout: super floating castle!', ] response = self.client.get(reverse('admin:admin_views_villain_delete', args=(self.sv1.pk,))) for should in should_contain: self.assertContains(response, should, 1) response = self.client.get(reverse('admin:admin_views_supervillain_delete', args=(self.sv1.pk,))) for should in should_contain: self.assertContains(response, should, 1)
plot = self.pl3 tag = FunkyTag.objects.create(content_object=plot, name='hott') should_contain = '<li>Funky tag: <a href="%s">hott' % reverse( 'admin:admin_views_funkytag_change', args=(tag.id,)) response = self.client.get(reverse('admin:admin_views_plot_delete', args=(plot.pk,))) self.assertContains(response, should_contain)
bookmark = Bookmark.objects.create(name='djangoproject') tag = FunkyTag.objects.create(content_object=bookmark, name='django') tag_url = reverse('admin:admin_views_funkytag_change', args=(tag.id,)) should_contain = '<li>Funky tag: <a href="%s">django' % tag_url response = self.client.get(reverse('admin:admin_views_bookmark_delete', args=(bookmark.pk,))) self.assertContains(response, should_contain)
) cls.m1 = ModelWithStringPrimaryKey.objects.create(string_pk=cls.pk) content_type_pk = ContentType.objects.get_for_model(ModelWithStringPrimaryKey).pk user_pk = cls.superuser.pk LogEntry.objects.log_action(user_pk, content_type_pk, cls.pk, cls.pk, 2, change_message='Changed something')
response = self.client.get(reverse('admin:admin_views_modelwithstringprimarykey_history', args=(self.pk,))) self.assertContains(response, escape(self.pk)) self.assertContains(response, 'Changed something') self.assertEqual(response.status_code, 200)
self.assertContains(response, should_contain)
self.assertContains(response, should_contain) add_model2 = ModelWithStringPrimaryKey.objects.create(pk="add") add_url = reverse('admin:admin_views_modelwithstringprimarykey_add') change_url = reverse('admin:admin_views_modelwithstringprimarykey_change', args=(quote(add_model2.pk),)) self.assertNotEqual(add_url, change_url)
self.assertContains(response, should_contain)
self.assertContains(response, should_contain)
url = reverse( 'admin:%s_modelwithstringprimarykey_change' % ModelWithStringPrimaryKey._meta.app_label, args=(quote(self.pk),) ) response = self.client.get(url) self.assertEqual(response.status_code, 200) expected_link = reverse( 'admin:%s_modelwithstringprimarykey_history' % ModelWithStringPrimaryKey._meta.app_label, args=(quote(self.pk),) ) self.assertContains(response, '<a href="%s" class="historylink"' % escape(expected_link))
secure_url = reverse('secure_view') response = self.client.get(secure_url) self.assertRedirects(response, '%s?next=%s' % (reverse('admin:login'), secure_url)) response = self.client.get(secure_url, follow=True) self.assertTemplateUsed(response, 'admin/login.html') self.assertEqual(response.context[REDIRECT_FIELD_NAME], secure_url)
secure_url = '/test_admin/admin/secure-view2/' response = self.client.get(secure_url) self.assertRedirects(response, '%s?myfield=%s' % (reverse('admin:login'), secure_url))
delete_dict = {'post': 'yes'} delete_url = reverse('admin:admin_views_book_delete', args=(self.b1.pk,)) response = self.client.get(delete_url) self.assertEqual(response.status_code, 200) response = self.client.post(delete_url, delete_dict) self.assertRedirects(response, reverse('admin:admin_views_book_changelist'))
UnorderedObject.objects.create(id=1, name='Unordered object #1') UnorderedObject.objects.create(id=2, name='Unordered object #2') UnorderedObject.objects.create(id=3, name='Unordered object #3') response = self.client.get(reverse('admin:admin_views_unorderedobject_changelist')) self.assertContains(response, 'Unordered object #3') self.assertContains(response, 'Unordered object #2') self.assertNotContains(response, 'Unordered object #1') response = self.client.get(reverse('admin:admin_views_unorderedobject_changelist') + '?p=1') self.assertNotContains(response, 'Unordered object #3') self.assertNotContains(response, 'Unordered object #2') self.assertContains(response, 'Unordered object #1')
response = self.client.get(reverse('admin:admin_views_person_changelist')) self.assertNotEqual(response.context['cl'].list_editable, ()) response = self.client.get(reverse('admin:admin_views_person_changelist') + '?%s' % IS_POPUP_VAR) self.assertEqual(response.context['cl'].list_editable, ())
response = self.client.get(reverse('admin:auth_user_changelist') + '?q=joe&%s=id' % TO_FIELD_VAR) self.assertContains(response, "\n1 user\n") self.assertContains(response, '<input type="hidden" name="%s" value="id"/>' % TO_FIELD_VAR, html=True)
html=True
html=True
action_data = { ACTION_CHECKBOX_NAME: [1], 'action': 'external_mail', 'index': 0, } url = reverse('admin:admin_views_externalsubscriber_changelist') + '?o=1' response = self.client.post(url, action_data) self.assertRedirects(response, url)
action_data = { ACTION_CHECKBOX_NAME: [1], 'action': 'download', 'index': 0, } response = self.client.post(reverse('admin:admin_views_externalsubscriber_changelist'), action_data) content = b''.join(response.streaming_content) self.assertEqual(content, b'This is the content of the file') self.assertEqual(response.status_code, 200)
action_data = { ACTION_CHECKBOX_NAME: [1], 'action': 'no_perm', 'index': 0, } response = self.client.post(reverse('admin:admin_views_externalsubscriber_changelist'), action_data) self.assertEqual(response.status_code, 403) self.assertEqual(response.content, b'No permission to perform this action')
self.assertContains(response, msg) self.assertEqual(Subscriber.objects.count(), 2)
self.assertContains(response, msg) self.assertEqual(Subscriber.objects.count(), 2)
response = self.client.get(reverse('admin:admin_views_subscriber_changelist')) self.assertContains(response, '0 of 2 selected')
response = self.client.get(reverse('admin:admin_views_subscriber_changelist')) self.assertNotEqual(response.context["action_form"], None) response = self.client.get( reverse('admin:admin_views_subscriber_changelist') + '?%s' % IS_POPUP_VAR) self.assertEqual(response.context["action_form"], None)
response = self.client.post( reverse('admin:admin_views_actor_add') + '?%s=1' % IS_POPUP_VAR, {'name': 'Troy McClure', 'age': '55', IS_POPUP_VAR: '1'}) self.assertEqual(response.status_code, 200) self.assertEqual(response.template_name, 'admin/popup_response.html')
response = self.client.get(reverse('admin:admin_views_parent_add')) self.assertEqual(response.status_code, 200)
self.client.post(reverse('admin:login'), self.super_login) FilteredManager.objects.create(pk=1) FilteredManager.objects.create(pk=2) response = self.client.get(reverse('admin:admin_views_filteredmanager_changelist')) self.assertContains(response, "PK=1") self.assertContains(response, "PK=2") self.assertEqual( self.client.get(reverse('admin:admin_views_filteredmanager_history', args=(1,))).status_code, 200 ) self.assertEqual( self.client.get(reverse('admin:admin_views_filteredmanager_history', args=(2,))).status_code, 200 )
post_data = { "name": "Test Gallery", "pictures-TOTAL_FORMS": "2", "pictures-INITIAL_FORMS": "1", "pictures-MAX_NUM_FORMS": "0", "pictures-0-id": six.text_type(self.picture.id), "pictures-0-gallery": six.text_type(self.gallery.id), "pictures-0-name": "Test Picture", "pictures-0-image": "", "pictures-1-id": "", "pictures-1-gallery": str(self.gallery.id), "pictures-1-name": "Test Picture 2", "pictures-1-image": "", } response = self.client.post( reverse('admin:admin_views_gallery_change', args=(self.gallery.id,)), post_data ) self.assertContains(response, b"Currently")
self.admin_login(username='super', password='secret', login_url=reverse('admin:index')) self.selenium.get(self.live_server_url + reverse('admin:admin_views_article_add')) self.assertFalse(self.selenium.find_element_by_id('id_title').is_displayed()) self.selenium.find_elements_by_link_text('Show')[0].click() self.assertTrue(self.selenium.find_element_by_id('id_title').is_displayed()) self.assertEqual(self.selenium.find_element_by_id('fieldsetcollapser0').text, "Hide")
choice = Choice.objects.create(choice=None) response = self.client.get(reverse('admin:admin_views_choice_change', args=(choice.pk,))) self.assertContains(response, '<p>No opinion</p>', html=True) self.assertNotContains(response, '<p>(None)</p>')
topping = Topping.objects.create(name='Salami') pizza = Pizza.objects.create(name='Americano') pizza.toppings.add(topping) response = self.client.get(reverse('admin:admin_views_topping_add')) self.assertEqual(response.status_code, 200)
p = FieldOverridePost.objects.create(title="Test Post", content="Test Content") response = self.client.get(reverse('admin:admin_views_fieldoverridepost_change', args=(p.pk,))) self.assertContains(response, '<p class="help">Overridden help text for the date</p>') self.assertContains(response, '<label for="id_public">Overridden public label:</label>', html=True) self.assertNotContains(response, "Some help text for the date (with unicode )")
section = Section.objects.create(name='<a>evil</a>') response = self.client.get(reverse('admin:admin_views_section_change', args=(section.pk,))) self.assertNotContains(response, "<a>evil</a>", status_code=200) self.assertContains(response, "&lt;a&gt;evil&lt;/a&gt;", status_code=200)
actor = Actor.objects.create(name="Palin", age=27) Inquisition.objects.create(expected=True, leader=actor, country="England") response = self.client.get(reverse('admin:admin_views_inquisition_changelist')) self.assertContains(response, 'list-display-sketch')
response = self.client.get(reverse('admin:admin_views_album_add')) self.assertContains(response, reverse('admin:auth_user_add')) self.assertContains(response, 'class="related-widget-wrapper-link add-related" id="add_id_owner"') response = self.client.get(reverse('admin:auth_user_add') + '?_popup=1') self.assertNotContains(response, 'name="_continue"') self.assertNotContains(response, 'name="_addanother"') data = { 'username': 'newuser', 'password1': 'newpassword', 'password2': 'newpassword', '_popup': '1', '_save': '1', } response = self.client.post(reverse('admin:auth_user_add') + '?_popup=1', data, follow=True) self.assertContains(response, '&quot;obj&quot;: &quot;newuser&quot;')
response = self.client.get(reverse('admin:admin_views_album_add')) self.assertContains(response, reverse('admin:auth_user_change', args=('__fk__',))) self.assertContains(response, 'class="related-widget-wrapper-link change-related" id="change_id_owner"') user = User.objects.get(username='changeuser') url = reverse('admin:auth_user_change', args=(user.pk,)) + '?_popup=1' response = self.client.get(url) self.assertNotContains(response, 'name="_continue"') self.assertNotContains(response, 'name="_addanother"') data = { 'username': 'newuser', 'password1': 'newpassword', 'password2': 'newpassword', 'last_login_0': '2007-05-30', 'last_login_1': '13:20:10', 'date_joined_0': '2007-05-30', 'date_joined_1': '13:20:10', '_popup': '1', '_save': '1', } response = self.client.post(url, data, follow=True) self.assertContains(response, '&quot;obj&quot;: &quot;newuser&quot;') self.assertContains(response, '&quot;action&quot;: &quot;change&quot;')
response = self.client.get(reverse('admin:admin_views_album_add')) self.assertContains(response, reverse('admin:auth_user_delete', args=('__fk__',))) self.assertContains(response, 'class="related-widget-wrapper-link change-related" id="change_id_owner"') user = User.objects.get(username='changeuser') url = reverse('admin:auth_user_delete', args=(user.pk,)) + '?_popup=1' response = self.client.get(url) self.assertEqual(response.status_code, 200) data = { 'post': 'yes', '_popup': '1', } response = self.client.post(url, data, follow=True) self.assertContains(response, '&quot;action&quot;: &quot;delete&quot;')
response = self.client.get(reverse('admin:admin_views_section_add')) self.assertContains(response, '<body class=" app-admin_views model-section ')
response = self.client.get(reverse('admin:admin_views_section_changelist')) self.assertContains(response, '<body class=" app-admin_views model-section ')
response = self.client.get(reverse('admin:admin_views_section_delete', args=(self.s1.pk,))) self.assertContains(response, '<body class=" app-admin_views model-section ')
response = self.client.get(reverse('admin:app_list', args=('admin_views',))) self.assertContains(response, '<body class=" dashboard app-admin_views')
action_data = { ACTION_CHECKBOX_NAME: [1], 'action': 'delete_selected', 'index': 0, } response = self.client.post(reverse('admin:admin_views_section_changelist'), action_data) self.assertContains(response, '<body class=" app-admin_views model-section ')
Podcast.objects.create(name="Django Dose", release_date=datetime.date.today()) response = self.client.get(reverse('admin:admin_views_podcast_changelist')) self.assertContains(response, '<th class="field-name">') self.assertContains(response, '<td class="field-release_date nowrap">') self.assertContains(response, '<td class="action-checkbox">')
self.assertNotContains(response, formats.number_format(year))
response = self.client.get( reverse('admin:admin_views_podcast_changelist')) self.assertNotContains(response, 'release_date__year=') self.assertNotContains(response, 'release_date__month=') self.assertNotContains(response, 'release_date__day=')
DATE = datetime.date(2000, 6, 30) Podcast.objects.create(release_date=DATE) url = reverse('admin:admin_views_podcast_changelist') response = self.client.get(url) self.assert_contains_day_link(response, DATE) self.assert_non_localized_year(response, 2000)
DATES = (datetime.date(2000, 6, 30), datetime.date(2000, 6, 15), datetime.date(2000, 6, 3)) for date in DATES: Podcast.objects.create(release_date=date) url = reverse('admin:admin_views_podcast_changelist') response = self.client.get(url) for date in DATES: self.assert_contains_day_link(response, date) self.assert_non_localized_year(response, 2000)
@classmethod def setUpTestData(cls): cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com') def setUp(self): self.client.force_login(self.superuser) def test_should_be_able_to_edit_related_objects_on_add_view(self): post = { 'child_set-TOTAL_FORMS': '3', 'child_set-INITIAL_FORMS': '0', 'name': 'Josh Stone', 'child_set-0-name': 'Paul', 'child_set-1-name': 'Catherine', } self.client.post(reverse('admin:admin_views_parent_add'), post) self.assertEqual(1, Parent.objects.count()) self.assertEqual(2, Child.objects.count()) children_names = list(Child.objects.order_by('name').values_list('name', flat=True)) self.assertEqual('Josh Stone', Parent.objects.latest('id').name) self.assertEqual(['Catherine Stone', 'Paul Stone'], children_names) def test_should_be_able_to_edit_related_objects_on_change_view(self): parent = Parent.objects.create(name='Josh Stone') paul = Child.objects.create(parent=parent, name='Paul') catherine = Child.objects.create(parent=parent, name='Catherine') post = { 'child_set-TOTAL_FORMS': '5', 'child_set-INITIAL_FORMS': '2', 'name': 'Josh Stone', 'child_set-0-name': 'Paul', 'child_set-0-id': paul.id, 'child_set-1-name': 'Catherine', 'child_set-1-id': catherine.id, } self.client.post(reverse('admin:admin_views_parent_change', args=(parent.id,)), post) children_names = list(Child.objects.order_by('name').values_list('name', flat=True)) self.assertEqual('Josh Stone', Parent.objects.latest('id').name) self.assertEqual(['Catherine Stone', 'Paul Stone'], children_names) def test_should_be_able_to_edit_related_objects_on_changelist_view(self): parent = Parent.objects.create(name='Josh Rock') Child.objects.create(parent=parent, name='Paul') Child.objects.create(parent=parent, name='Catherine') post = { 'form-TOTAL_FORMS': '1', 'form-INITIAL_FORMS': '1', 'form-MAX_NUM_FORMS': '0', 'form-0-id': parent.id, 'form-0-name': 'Josh Stone', '_save': 'Save' } self.client.post(reverse('admin:admin_views_parent_changelist'), post) children_names = list(Child.objects.order_by('name').values_list('name', flat=True)) self.assertEqual('Josh Stone', Parent.objects.latest('id').name) self.assertEqual(['Catherine Stone', 'Paul Stone'], children_names)
parsed_url1 = urlparse(url1) path1 = parsed_url1.path parsed_qs1 = dict(parse_qsl(parsed_url1.query)) parsed_url2 = urlparse(url2) path2 = parsed_url2.path parsed_qs2 = dict(parse_qsl(parsed_url2.query)) for parsed_qs in [parsed_qs1, parsed_qs2]: if '_changelist_filters' in parsed_qs: changelist_filters = parsed_qs['_changelist_filters'] parsed_filters = dict(parse_qsl(changelist_filters)) parsed_qs['_changelist_filters'] = parsed_filters self.assertEqual(path1, path2) self.assertEqual(parsed_qs1, parsed_qs2)
@classmethod def setUpTestData(cls): cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com') def setUp(self): self.client.force_login(self.superuser) def test_all_fields_visible(self): response = self.client.get(reverse('admin:admin_views_emptymodelvisible_add')) self.assert_fieldline_visible(response) self.assert_field_visible(response, 'first') self.assert_field_visible(response, 'second') def test_all_fields_hidden(self): response = self.client.get(reverse('admin:admin_views_emptymodelhidden_add')) self.assert_fieldline_hidden(response) self.assert_field_hidden(response, 'first') self.assert_field_hidden(response, 'second') def test_mixin(self): response = self.client.get(reverse('admin:admin_views_emptymodelmixin_add')) self.assert_fieldline_visible(response) self.assert_field_hidden(response, 'first') self.assert_field_visible(response, 'second') def assert_field_visible(self, response, field_name): self.assertContains(response, '<div class="field-box field-%s">' % field_name) def assert_field_hidden(self, response, field_name): self.assertContains(response, '<div class="field-box field-%s hidden">' % field_name) def assert_fieldline_visible(self, response): self.assertContains(response, '<div class="form-row field-first field-second">') def assert_fieldline_hidden(self, response): self.assertContains(response, '<div class="form-row hidden')
@classmethod def setUpTestData(cls): cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com') def setUp(self): self.client.force_login(self.superuser) def test_explicitly_provided_pk(self): post_data = {'name': '1'} response = self.client.post(reverse('admin:admin_views_explicitlyprovidedpk_add'), post_data) self.assertEqual(response.status_code, 302) post_data = {'name': '2'} response = self.client.post(reverse('admin:admin_views_explicitlyprovidedpk_change', args=(1,)), post_data) self.assertEqual(response.status_code, 302) def test_implicitly_generated_pk(self): post_data = {'name': '1'} response = self.client.post(reverse('admin:admin_views_implicitlygeneratedpk_add'), post_data) self.assertEqual(response.status_code, 302) post_data = {'name': '2'} response = self.client.post(reverse('admin:admin_views_implicitlygeneratedpk_change', args=(1,)), post_data) self.assertEqual(response.status_code, 302)
return request.user.is_staff and (obj is not None) and (obj.id % 2 == 0)
change_list_template = 'custom_admin/change_list.html' change_form_template = 'custom_admin/change_form.html' add_form_template = 'custom_admin/add_form.html' object_history_template = 'custom_admin/object_history.html' delete_confirmation_template = 'custom_admin/delete_confirmation.html' delete_selected_confirmation_template = 'custom_admin/delete_selected_confirmation.html' def changelist_view(self, request): "Test that extra_context works" return super(CustomArticleAdmin, self).changelist_view( request, extra_context={ 'extra_var': 'Hello!' } )
def get_queryset(self, request): return super(CoverLetterAdmin, self).get_queryset(request).defer('date_written')
def get_queryset(self, request): return super(PaperAdmin, self).get_queryset(request).only('title')
def get_queryset(self, request): return super(ShortMessageAdmin, self).get_queryset(request).defer('timestamp')
def get_queryset(self, request): return super(TelegramAdmin, self).get_queryset(request).only('title')
def clean(self): parent = self.cleaned_data.get('parent') if parent.family_name and parent.family_name != self.cleaned_data.get('family_name'): raise ValidationError("Children must share a family name with their parents " + "in this contrived test case") return super(DependentChildAdminForm, self).clean()
from __future__ import unicode_literals from django.contrib import admin from django.contrib.auth import get_permission_codename from django.contrib.auth.forms import AuthenticationForm from . import admin as base_admin, models PERMISSION_NAME = 'admin_views.%s' % get_permission_codename('change', models.Article._meta) class PermissionAdminAuthenticationForm(AuthenticationForm): def confirm_login_allowed(self, user): from django import forms if not user.is_active or not (user.is_staff or user.has_perm(PERMISSION_NAME)): raise forms.ValidationError('permission denied') class HasPermissionAdmin(admin.AdminSite): login_form = PermissionAdminAuthenticationForm def has_permission(self, request): return ( request.user.is_active and (request.user.is_staff or request.user.has_perm(PERMISSION_NAME)) ) site = HasPermissionAdmin(name="has_permission_admin") site.register(models.Article, base_admin.ArticleAdmin)
response = self.client.get( '/syndication/rss2/guid_ispermalink_false/') doc = minidom.parseString(response.content) chan = doc.getElementsByTagName( 'rss')[0].getElementsByTagName('channel')[0] items = chan.getElementsByTagName('item') for item in items: self.assertEqual( item.getElementsByTagName('guid')[0].attributes.get( 'isPermaLink').value, "false")
response = self.client.get( '/syndication/rss2/guid_ispermalink_true/') doc = minidom.parseString(response.content) chan = doc.getElementsByTagName( 'rss')[0].getElementsByTagName('channel')[0] items = chan.getElementsByTagName('item') for item in items: self.assertEqual( item.getElementsByTagName('guid')[0].attributes.get( 'isPermaLink').value, "true")
response = self.client.get('/syndication/atom/') feed = minidom.parseString(response.content).firstChild self.assertEqual(feed.nodeName, 'feed') self.assertEqual(feed.getAttribute('xmlns'), 'http://www.w3.org/2005/Atom') self.assertChildNodes( feed, ['title', 'subtitle', 'link', 'id', 'updated', 'entry', 'rights', 'category', 'author'] ) for link in feed.getElementsByTagName('link'): if link.getAttribute('rel') == 'self': self.assertEqual(link.getAttribute('href'), 'http://example.com/syndication/atom/') entries = feed.getElementsByTagName('entry') self.assertEqual(len(entries), Entry.objects.count()) for entry in entries: self.assertChildNodes(entry, [ 'title', 'link', 'id', 'summary', 'category', 'updated', 'published', 'rights', 'author', ]) summary = entry.getElementsByTagName('summary')[0] self.assertEqual(summary.getAttribute('type'), 'html')
response = self.client.get('/syndication/atom/') feed = minidom.parseString(response.content).firstChild entries = feed.getElementsByTagName('entry') published = entries[0].getElementsByTagName('published')[0].firstChild.wholeText updated = entries[0].getElementsByTagName('updated')[0].firstChild.wholeText self.assertNotEqual(published, updated)
response = self.client.get('/syndication/rss2/') doc = minidom.parseString(response.content) for item in doc.getElementsByTagName('item'): link = item.getElementsByTagName('link')[0] if link.firstChild.wholeText == 'http://example.com/blog/4/': title = item.getElementsByTagName('title')[0] self.assertEqual(title.firstChild.wholeText, 'A &amp; B &lt; C &gt; D')
response = self.client.get('/syndication/aware-dates/') doc = minidom.parseString(response.content) published = doc.getElementsByTagName('published')[0].firstChild.wholeText self.assertEqual(published[-6:], '+00:42')
response = self.client.get('/syndication/naive-dates/') self.assertEqual(response['Last-Modified'], 'Tue, 26 Mar 2013 01:00:00 GMT')
response = self.client.get('/syndication/feedurl/') doc = minidom.parseString(response.content) for link in doc.getElementsByTagName('link'): if link.getAttribute('rel') == 'self': self.assertEqual(link.getAttribute('href'), 'http://example.com/customfeedurl/')
response = self.client.get('/syndication/rss2/', **{ 'wsgi.url_scheme': 'https', }) doc = minidom.parseString(response.content) chan = doc.getElementsByTagName('channel')[0] self.assertEqual( chan.getElementsByTagName('link')[0].firstChild.wholeText[0:5], 'https' ) atom_link = chan.getElementsByTagName('atom:link')[0] self.assertEqual(atom_link.getAttribute('href')[0:5], 'https') for link in doc.getElementsByTagName('link'): if link.getAttribute('rel') == 'self': self.assertEqual(link.getAttribute('href')[0:5], 'https')
with self.assertRaises(ImproperlyConfigured): self.client.get('/syndication/articles/')
response = self.client.get('/syndication/template/') doc = minidom.parseString(response.content) feed = doc.getElementsByTagName('rss')[0] chan = feed.getElementsByTagName('channel')[0] items = chan.getElementsByTagName('item') self.assertChildNodeContent(items[0], { 'title': 'Title in your templates: My first entry\n', 'description': 'Description in your templates: My first entry\n', 'link': 'http://example.com/blog/1/', })
response = self.client.get('/syndication/template_context/') doc = minidom.parseString(response.content) feed = doc.getElementsByTagName('rss')[0] chan = feed.getElementsByTagName('channel')[0] items = chan.getElementsByTagName('item') self.assertChildNodeContent(items[0], { 'title': 'My first entry (foo is bar)\n', 'description': 'My first entry (foo is bar)\n', })
self.assertEqual( views.add_domain('example.com', '/foo/?arg=value'), 'http://example.com/foo/?arg=value' ) self.assertEqual( views.add_domain('example.com', '/foo/?arg=value', True), 'https://example.com/foo/?arg=value' ) self.assertEqual( views.add_domain('example.com', 'http://djangoproject.com/doc/'), 'http://djangoproject.com/doc/' ) self.assertEqual( views.add_domain('example.com', 'https://djangoproject.com/doc/'), 'https://djangoproject.com/doc/' ) self.assertEqual( views.add_domain('example.com', 'mailto:uhoh@djangoproject.com'), 'mailto:uhoh@djangoproject.com' ) self.assertEqual( views.add_domain('example.com', '//example.com/foo/?arg=value'), 'http://example.com/foo/?arg=value' )
feed_type = feedgenerator.Atom1Feed subtitle = TestRss2Feed.description def items(self): return Entry.objects.exclude(pk=5)
def items(self): return Article.objects.all()
def item_enclosure_url(self, item): return 'http://example.com' def item_enclosure_size(self, item): return 0 def item_mime_type(self, item): return 'image/png'
def item_enclosures(self, item): return [ feedgenerator.Enclosure('http://example.com/hello.png', 0, 'image/png'), feedgenerator.Enclosure('http://example.com/goodbye.png', 0, 'image/png'), ]
title_template = 'syndication/title_context.html' description_template = 'syndication/description_context.html' def get_context_data(self, **kwargs): context = super(TemplateContextFeed, self).get_context_data(**kwargs) context['foo'] = 'bar' return context
def item_pubdate(self, item): return item.published
def root_attributes(self): attrs = super(MyCustomAtom1Feed, self).root_attributes() attrs['django'] = 'rocks' return attrs def add_root_elements(self, handler): super(MyCustomAtom1Feed, self).add_root_elements(handler) handler.addQuickElement('spam', 'eggs') def item_attributes(self, item): attrs = super(MyCustomAtom1Feed, self).item_attributes(item) attrs['bacon'] = 'yum' return attrs def add_item_elements(self, handler, item): super(MyCustomAtom1Feed, self).add_item_elements(handler, item) handler.addQuickElement('ministry', 'silly walks')
def item_enclosure_url(self, item): return 'http://example.com' def item_enclosure_size(self, item): return 0 def item_mime_type(self, item): return 'image/png'
def item_enclosures(self, item): return [ feedgenerator.Enclosure('http://example.com/hello.png', '0', 'image/png'), feedgenerator.Enclosure('http://example.com/goodbye.png', '0', 'image/png'), ]
bool = models.BooleanField(default=True)
name = models.CharField(max_length=255) bool = models.BooleanField(default=True) number = models.IntegerField(default=0, db_column='number_val') objects = OrderedObjectManager()
m = ChildAdmin(Child, custom_site) request = self.factory.get('/child/') cl = ChangeList( request, Child, *get_changelist_args(m, list_select_related=m.get_list_select_related(request)) ) self.assertEqual(cl.queryset.query.select_related, {'parent': {}})
new_child = Child.objects.create(name='name', parent=None) request = self.factory.get('/child/') m = ChildAdmin(Child, custom_site) cl = ChangeList(request, Child, *get_changelist_args(m)) cl.formset = None template = Template('{% load admin_list %}{% spaceless %}{% result_list cl %}{% endspaceless %}') context = Context({'cl': cl}) table_output = template.render(context) link = reverse('admin:admin_changelist_child_change', args=(new_child.id,)) row_html = ( '<tbody><tr class="row1"><th class="field-name"><a href="%s">name</a></th>' '<td class="field-parent nowrap">-</td></tr></tbody>' % link ) self.assertNotEqual(table_output.find(row_html), -1, 'Failed to find expected row element: %s' % table_output)
new_child = Child.objects.create(name='name', parent=None) request = self.factory.get('/child/') m = EmptyValueChildAdmin(Child, admin.site) cl = ChangeList(request, Child, *get_changelist_args(m)) cl.formset = None template = Template('{% load admin_list %}{% spaceless %}{% result_list cl %}{% endspaceless %}') context = Context({'cl': cl}) table_output = template.render(context) link = reverse('admin:admin_changelist_child_change', args=(new_child.id,)) row_html = ( '<tbody><tr class="row1"><th class="field-name"><a href="%s">name</a></th>' '<td class="field-age_display">&amp;dagger;</td><td class="field-age">-empty-</td></tr></tbody>' % link ) self.assertNotEqual(table_output.find(row_html), -1, 'Failed to find expected row element: %s' % table_output)
new_parent = Parent.objects.create(name='parent') new_child = Child.objects.create(name='name', parent=new_parent) request = self.factory.get('/child/') m = ChildAdmin(Child, custom_site) cl = ChangeList(request, Child, *get_changelist_args(m)) cl.formset = None template = Template('{% load admin_list %}{% spaceless %}{% result_list cl %}{% endspaceless %}') context = Context({'cl': cl}) table_output = template.render(context) link = reverse('admin:admin_changelist_child_change', args=(new_child.id,)) row_html = ( '<tbody><tr class="row1"><th class="field-name"><a href="%s">name</a></th>' '<td class="field-parent nowrap">Parent object</td></tr></tbody>' % link ) self.assertNotEqual(table_output.find(row_html), -1, 'Failed to find expected row element: %s' % table_output)
superuser = User.objects.create_superuser(username='super', email='super@localhost', password='secret') self.client.force_login(superuser) event = Event.objects.create(date=datetime.date.today()) response = self.client.get(reverse('admin:admin_changelist_event_changelist')) self.assertContains(response, formats.localize(event.date)) self.assertNotContains(response, six.text_type(event.date))
parent = Parent.objects.create(name='parent') for i in range(1, 10): Child.objects.create(id=i, name='child %s' % i, parent=parent, age=i) m = DynamicListDisplayLinksChildAdmin(Child, custom_site) superuser = self._create_superuser('superuser') request = self._mocked_authenticated_request('/child/', superuser) response = m.changelist_view(request) for i in range(1, 10): link = reverse('admin:admin_changelist_child_change', args=(i,)) self.assertContains(response, '<a href="%s">%s</a>' % (link, i)) list_display = m.get_list_display(request) list_display_links = m.get_list_display_links(request, list_display) self.assertEqual(list_display, ('parent', 'name', 'age')) self.assertEqual(list_display_links, ['age'])
p = Parent.objects.create(name='parent') m = NoListDisplayLinksParentAdmin(Parent, custom_site) superuser = self._create_superuser('superuser') request = self._mocked_authenticated_request('/parent/', superuser) response = m.changelist_view(request) link = reverse('admin:admin_changelist_parent_change', args=(p.pk,)) self.assertNotContains(response, '<a href="%s">' % link)
user = User(username='jondoe', password='secret', email='super@example.com') user.save() ct = ContentType.objects.get_for_model(User) LogEntry.objects.log_action(user.pk, ct.pk, user.pk, repr(user), 1) t = Template( '{% load log %}' '{% get_admin_log 100 as admin_log %}' '{% for entry in admin_log %}' '{{ entry|safe }}' '{% endfor %}' ) self.assertEqual(t.render(Context({})), 'Added "<User: jondoe>".')
response = self.client.get('/lastmod/date-sitemap.xml') self.assertEqual(response['Last-Modified'], 'Wed, 13 Mar 2013 00:00:00 GMT')
response = self.client.get('/lastmod/tz-sitemap.xml') self.assertEqual(response['Last-Modified'], 'Wed, 13 Mar 2013 15:00:00 GMT')
response = self.client.get('/lastmod-sitemaps/mixed-ascending.xml') self.assertFalse(response.has_header('Last-Modified'))
response = self.client.get('/lastmod-sitemaps/mixed-descending.xml') self.assertFalse(response.has_header('Last-Modified'))
response = self.client.get('/lastmod-sitemaps/ascending.xml') self.assertEqual(response['Last-Modified'], 'Sat, 20 Apr 2013 05:00:00 GMT')
response = self.client.get('/lastmod-sitemaps/descending.xml') self.assertEqual(response['Last-Modified'], 'Sat, 20 Apr 2013 05:00:00 GMT')
Site.objects.all().delete() with self.assertRaises(ImproperlyConfigured): Sitemap().get_urls()
with self.assertRaises(ImproperlyConfigured): Sitemap().get_urls()
test_sitemap = GenericSitemap({'queryset': TestModel.objects.all()}) def is_testmodel(url): return isinstance(url['item'], TestModel) item_in_url_info = all(map(is_testmodel, test_sitemap.get_urls())) self.assertTrue(item_in_url_info)
available_apps = ["migration_test_data_persistence"] serialized_rollback = True def test_persistence(self): self.assertEqual( Book.objects.count(), 1, )
def test_persistence(self): self.assertEqual( Book.objects.count(), 1, )
with self.assertRaises(RuntimeError): Apps(installed_apps=None)
with self.assertRaises(ImproperlyConfigured): with self.settings(INSTALLED_APPS=['apps.apps.BadConfig']): pass
with self.assertRaises(ImproperlyConfigured): with self.settings(INSTALLED_APPS=['apps.apps.NotAConfig']): pass
with self.assertRaises(ImportError): with self.settings(INSTALLED_APPS=['there is no such app']): pass with self.assertRaises(ImportError): with self.settings(INSTALLED_APPS=['apps.apps.NoSuchApp']): pass
with self.assertRaises(ImportError): with self.settings(INSTALLED_APPS=['apps.apps.NoSuchConfig']): pass
app_configs = apps.get_app_configs() self.assertListEqual( [app_config.name for app_config in app_configs], SOME_INSTALLED_APPS_NAMES)
app_config = apps.get_app_config('admin') self.assertEqual(app_config.name, 'django.contrib.admin') app_config = apps.get_app_config('staticfiles') self.assertEqual(app_config.name, 'django.contrib.staticfiles') with self.assertRaises(LookupError): apps.get_app_config('admindocs') msg = "No installed app with label 'django.contrib.auth'. Did you mean 'myauth'" with self.assertRaisesMessage(LookupError, msg): apps.get_app_config('django.contrib.auth')
self.assertTrue(apps.is_installed('django.contrib.admin')) self.assertTrue(apps.is_installed('django.contrib.auth')) self.assertTrue(apps.is_installed('django.contrib.staticfiles')) self.assertFalse(apps.is_installed('django.contrib.admindocs'))
with self.assertRaisesMessage(ImportError, "Oops"): with self.settings(INSTALLED_APPS=['import_error_package']): pass
self.assertEqual(apps.get_model("apps", "TotallyNormal"), TotallyNormal) with self.assertRaises(LookupError): apps.get_model("apps", "SoAlternative") with self.assertRaises(LookupError): new_apps.get_model("apps", "TotallyNormal") self.assertEqual(new_apps.get_model("apps", "SoAlternative"), SoAlternative)
apps.apps_ready = False try: with self.assertRaisesMessage(AppRegistryNotReady, "Apps aren't loaded yet"): apps.get_containing_app_config('foo') finally: apps.apps_ready = True
class MyAppConfig(AppConfig): path = 'foo' ac = MyAppConfig('label', Stub()) self.assertEqual(ac.path, 'foo')
class MyAppConfig(AppConfig): path = 'foo' ac = MyAppConfig('label', Stub(__path__=['a'], __file__='b/__init__.py')) self.assertEqual(ac.path, 'foo')
ac = AppConfig('label', Stub(__path__=['a'], __file__='b/__init__.py')) self.assertEqual(ac.path, 'a')
ac = AppConfig('label', Stub(__file__='b/__init__.py')) self.assertEqual(ac.path, 'b')
ac = AppConfig('label', Stub(__path__=[], __file__='b/__init__.py')) self.assertEqual(ac.path, 'b')
ac = AppConfig('label', Stub(__path__=['a', 'b'], __file__='c/__init__.py')) self.assertEqual(ac.path, 'c')
with self.assertRaises(ImproperlyConfigured): AppConfig('label', Stub())
with self.assertRaises(ImproperlyConfigured): AppConfig('label', Stub(__path__=[]))
with self.assertRaises(ImproperlyConfigured): AppConfig('label', Stub(__path__=['a', 'b']))
ac = AppConfig('label', Stub(__path__=['a', 'a'])) self.assertEqual(ac.path, 'a')
with extend_sys_path(self.base_location): with self.settings(INSTALLED_APPS=['nsapp']): app_config = apps.get_app_config('nsapp') self.assertEqual(app_config.path, upath(self.app_path))
with self.assertNumQueries(1): user = User.objects.select_related('userprofile').get(username='bob') with self.assertRaises(UserProfile.DoesNotExist): user.userprofile
Image.objects.create(name="imag1") with self.assertNumQueries(1): image = Image.objects.select_related('product').get() with self.assertRaises(Product.DoesNotExist): image.product
non_relational_error = "Non-relational field given in select_related: '%s'. Choices are: %s" invalid_error = "Invalid field name(s) given in select_related: '%s'. Choices are: %s" def test_reverse_related_validation(self): fields = 'userprofile, userstat' with self.assertRaisesMessage(FieldError, self.invalid_error % ('foobar', fields)): list(User.objects.select_related('foobar')) with self.assertRaisesMessage(FieldError, self.non_relational_error % ('username', fields)): list(User.objects.select_related('username'))
with self.assertNumQueries(3): self.italian_restaurant.save()
start_response('200 OK', []) http_environ_items = sorted( '%s:%s' % (k, v) for k, v in environ.items() if k.startswith('HTTP_') ) yield (','.join(http_environ_items)).encode('utf-8')
try: self.urlopen('/') except HTTPError as err: self.assertEqual(err.code, 404, 'Expected 404 response') else: self.fail('Expected 404 response')
with contextlib.closing(self.urlopen('/example_view/')) as f: self.assertEqual(f.read(), b'example view')
with contextlib.closing(self.urlopen('/static/example_static_file.txt')) as f: self.assertEqual(f.read().rstrip(b'\r\n'), b'example static file')
try: self.urlopen('/static/another_app/another_app_static_file.txt') except HTTPError as err: self.assertEqual(err.code, 404, 'Expected 404 response') else: self.fail('Expected 404 response (got %d)' % err.code)
with contextlib.closing(self.urlopen('/media/example_media_file.txt')) as f: self.assertEqual(f.read().rstrip(b'\r\n'), b'example media file')
with contextlib.closing(self.urlopen('/model_view/')) as f: self.assertEqual(f.read().splitlines(), [b'jane', b'robert'])
self.urlopen('/create_model_instance/') self.assertQuerysetEqual( Person.objects.all().order_by('pk'), ['jane', 'robert', 'emily'], lambda b: b.name )
bf = models.ForeignKey(BooleanModel, models.CASCADE) nbf = models.ForeignKey(NullBooleanModel, models.CASCADE)
out = models.ForeignKey(PrimaryKeyCharModel, models.CASCADE)
def __init__(self, *args, **kwargs): self.was_opened = False super(TestImageFieldFile, self).__init__(*args, **kwargs) def open(self): self.was_opened = True super(TestImageFieldFile, self).open()
name = models.CharField(max_length=50) mugshot = TestImageField(storage=temp_storage, upload_to='tests')
mugshot = TestImageField(storage=temp_storage, upload_to='tests', height_field='mugshot_height') mugshot_height = models.PositiveSmallIntegerField() class Meta: abstract = True
name = models.CharField(max_length=50)
name = models.CharField(max_length=50) mugshot = TestImageField(storage=temp_storage, upload_to='tests', height_field='mugshot_height', width_field='mugshot_width') mugshot_height = models.PositiveSmallIntegerField() mugshot_width = models.PositiveSmallIntegerField()
name = models.CharField(max_length=50) mugshot_height = models.PositiveSmallIntegerField() mugshot_width = models.PositiveSmallIntegerField() mugshot = TestImageField(storage=temp_storage, upload_to='tests', height_field='mugshot_height', width_field='mugshot_width')
name = models.CharField(max_length=50) mugshot_height = models.PositiveSmallIntegerField() mugshot_width = models.PositiveSmallIntegerField() mugshot = TestImageField(storage=temp_storage, upload_to='tests', height_field='mugshot_height', width_field='mugshot_width') headshot_height = models.PositiveSmallIntegerField( blank=True, null=True) headshot_width = models.PositiveSmallIntegerField( blank=True, null=True) headshot = TestImageField(blank=True, null=True, storage=temp_storage, upload_to='tests', height_field='headshot_height', width_field='headshot_width')
choices = [(0, 0), (1, 1)] model_field = models.Field(choices=choices) form_field = model_field.formfield(show_hidden_initial=True) self.assertTrue(form_field.show_hidden_initial) form_field = model_field.formfield(show_hidden_initial=False) self.assertFalse(form_field.show_hidden_initial)
f = Foo._meta.get_field('a') self.assertEqual(repr(f), '<django.db.models.fields.CharField: a>') f = models.fields.CharField() self.assertEqual(repr(f), '<django.db.models.fields.CharField>')
instance = RenamedField() self.assertTrue(hasattr(instance, 'get_fieldname_display')) self.assertFalse(hasattr(instance, 'get_modelname_display'))
choices = [('a', 'a')] field = models.CharField(choices=choices) klass = forms.TypedMultipleChoiceField self.assertIsInstance(field.formfield(choices_form_class=klass), klass)
bs = BigS.objects.create(s='slug' * 50) bs = BigS.objects.get(pk=bs.pk) self.assertEqual(bs.s, 'slug' * 50)
choices = [(1, 'Si'), (2, 'No')] f = models.BooleanField(choices=choices, default=1, null=False) self.assertEqual(f.formfield().choices, choices)
tf1 = models.TextField() tf2 = models.TextField(max_length=2345) self.assertIsNone(tf1.formfield().max_length) self.assertEqual(2345, tf2.formfield().max_length)
f = models.TextField() self.assertEqual(f.to_python(1), '1')
model_field = models.GenericIPAddressField(protocol='IPv4') form_field = model_field.formfield() with self.assertRaises(ValidationError): form_field.clean('::1') model_field = models.GenericIPAddressField(protocol='IPv6') form_field = model_field.formfield() with self.assertRaises(ValidationError): form_field.clean('127.0.0.1')
GenericIPAddress.objects.create() o = GenericIPAddress.objects.get() self.assertIsNone(o.ip)
cf1 = models.CharField() cf2 = models.CharField(max_length=1234) self.assertIsNone(cf1.formfield().max_length) self.assertEqual(1234, cf2.formfield().max_length)
a = Foo.objects.create(id=1, a='abc', d=Decimal('12.34')) b = Bar.objects.create(b='bcd') self.assertEqual(b.a, a)
char_model_empty = PrimaryKeyCharModel.objects.create(string='') fk_model_empty = FkToChar.objects.create(out=char_model_empty) fk_model_empty = FkToChar.objects.select_related('out').get(id=fk_model_empty.pk) self.assertEqual(fk_model_empty.out, char_model_empty)
pending_ops_before = list(apps._pending_operations.items()) class AbstractForeignKeyModel(models.Model): fk = models.ForeignKey('missing.FK', models.CASCADE) class Meta: abstract = True self.assertIs(AbstractForeignKeyModel._meta.apps, apps) self.assertEqual( pending_ops_before, list(apps._pending_operations.items()), 'Pending lookup added for a foreign key on an abstract model' )
min_value, max_value = self.documented_range instance = self.model(value=min_value) instance.full_clean() instance.save() qs = self.model.objects.filter(value__lte=min_value) self.assertEqual(qs.count(), 1) self.assertEqual(qs[0].value, min_value) instance = self.model(value=max_value) instance.full_clean() instance.save() qs = self.model.objects.filter(value__gte=max_value) self.assertEqual(qs.count(), 1) self.assertEqual(qs[0].value, max_value)
min_value, max_value = self.backend_range if min_value is not None: instance = self.model(value=min_value) instance.full_clean() instance.save() qs = self.model.objects.filter(value__lte=min_value) self.assertEqual(qs.count(), 1) self.assertEqual(qs[0].value, min_value) if max_value is not None: instance = self.model(value=max_value) instance.full_clean() instance.save() qs = self.model.objects.filter(value__gte=max_value) self.assertEqual(qs.count(), 1) self.assertEqual(qs[0].value, max_value)
min_value, max_value = self.backend_range if min_value is not None: instance = self.model(value=min_value - 1) expected_message = validators.MinValueValidator.message % { 'limit_value': min_value, } with self.assertRaisesMessage(ValidationError, expected_message): instance.full_clean() instance.value = min_value instance.full_clean() if max_value is not None: instance = self.model(value=max_value + 1) expected_message = validators.MaxValueValidator.message % { 'limit_value': max_value, } with self.assertRaisesMessage(ValidationError, expected_message): instance.full_clean() instance.value = max_value instance.full_clean()
if os.path.exists(temp_storage_dir): shutil.rmtree(temp_storage_dir) os.mkdir(temp_storage_dir) file_path1 = os.path.join(os.path.dirname(upath(__file__)), "4x8.png") self.file1 = self.File(open(file_path1, 'rb'), name='4x8.png') file_path2 = os.path.join(os.path.dirname(upath(__file__)), "8x4.png") self.file2 = self.File(open(file_path2, 'rb'), name='8x4.png')
self.file1.close() self.file2.close() shutil.rmtree(temp_storage_dir)
p = self.PersonModel(name="Joan") p.mugshot.save("shot", self.file1) p = self.PersonModel.objects.get(name="Joan") path = p.mugshot.path shutil.move(path, path + '.moved') self.PersonModel.objects.get(name="Joan")
p = self.PersonModel(name="Fred") p.mugshot.save("shot", self.file1) os.remove(p.mugshot.path) p.delete()
import pickle p = Person(name="Joe") p.mugshot.save("mug", self.file1) dump = pickle.dumps(p) p2 = Person(name="Bob") p2.mugshot = self.file1 loaded_p = pickle.loads(dump) self.assertEqual(p.mugshot, loaded_p.mugshot)
p = self.PersonModel(name='Joe', mugshot=self.file1) self.check_dimensions(p, 4, 8) p.save() self.check_dimensions(p, 4, 8)
p = self.PersonModel.objects.create(name='Joe', mugshot=self.file1) self.check_dimensions(p, 4, 8)
p = self.PersonModel() self.assertIsInstance(p.mugshot, TestImageFieldFile) self.assertEqual(bool(p.mugshot), False)
PersonModel = Person
PersonModel = PersonWithHeight
PersonModel = PersonDimensionsFirst
PersonModel = PersonDimensionsFirst File = File
d = Document(myfile='something.txt') self.assertEqual(d.myfile, 'something.txt') field = d._meta.get_field('myfile') field.save_form_data(d, False) self.assertEqual(d.myfile, '')
d = Document(myfile='something.txt') self.assertEqual(d.myfile, 'something.txt') field = d._meta.get_field('myfile') field.save_form_data(d, None) self.assertEqual(d.myfile, 'something.txt')
d = Document(myfile='something.txt') self.assertEqual(d.myfile, 'something.txt') field = d._meta.get_field('myfile') field.save_form_data(d, 'else.txt') self.assertEqual(d.myfile, 'else.txt')
d = Document() d.myfile.delete()
foo = Foo.objects.create(a='abc', d=Decimal('12.34')) self.assertEqual(list(Foo.objects.filter(d='12.34')), [foo])
bd = BigD(d='12.9') bd.save() bd = BigD.objects.get(pk=bd.pk) self.assertEqual(bd.d, Decimal('12.9'))
f = models.DateTimeField() self.assertEqual(f.to_python('2001-01-02 03:04:05.000006'), datetime.datetime(2001, 1, 2, 3, 4, 5, 6)) self.assertEqual(f.to_python('2001-01-02 03:04:05.999999'), datetime.datetime(2001, 1, 2, 3, 4, 5, 999999))
f = models.TimeField() self.assertEqual(f.to_python('01:02:03.000004'), datetime.time(1, 2, 3, 4)) self.assertEqual(f.to_python('01:02:03.999999'), datetime.time(1, 2, 3, 999999))
pending_ops_before = list(apps._pending_operations.items()) class AbstractManyToManyModel(models.Model): fk = models.ForeignKey('missing.FK', models.CASCADE) class Meta: abstract = True self.assertIs(AbstractManyToManyModel._meta.apps, apps) self.assertEqual( pending_ops_before, list(apps._pending_operations.items()), 'Pending lookup added for a many-to-many field on an abstract model' )
reset_warning_registry() with warnings.catch_warnings(record=True) as recorded: warnings.simplefilter('always') class Manager(six.with_metaclass(RenameManagerMethods)): def old(self): pass self.assertEqual(len(recorded), 1) msg = str(recorded[0].message) self.assertEqual(msg, '`Manager.old` method should be renamed `new`.')
with warnings.catch_warnings(record=True) as recorded: warnings.simplefilter('ignore') class Manager(six.with_metaclass(RenameManagerMethods)): def new(self): pass warnings.simplefilter('always') manager = Manager() manager.new() self.assertEqual(len(recorded), 0) manager.old() self.assertEqual(len(recorded), 1) msg = str(recorded.pop().message) self.assertEqual(msg, '`Manager.old` is deprecated, use `new` instead.')
with warnings.catch_warnings(record=True) as recorded: warnings.simplefilter('ignore') class Manager(six.with_metaclass(RenameManagerMethods)): def old(self): pass warnings.simplefilter('always') manager = Manager() manager.new() self.assertEqual(len(recorded), 0) manager.old() self.assertEqual(len(recorded), 1) msg = str(recorded.pop().message) self.assertEqual(msg, '`Manager.old` is deprecated, use `new` instead.')
with warnings.catch_warnings(record=True) as recorded: warnings.simplefilter('ignore') class Renamed(six.with_metaclass(RenameManagerMethods)): def new(self): pass class Deprecated(Renamed): def old(self): super(Deprecated, self).old() warnings.simplefilter('always') deprecated = Deprecated() deprecated.new() self.assertEqual(len(recorded), 1) msg = str(recorded.pop().message) self.assertEqual(msg, '`Renamed.old` is deprecated, use `new` instead.') recorded[:] = [] deprecated.old() self.assertEqual(len(recorded), 2) msgs = [str(warning.message) for warning in recorded] self.assertEqual(msgs, [ '`Deprecated.old` is deprecated, use `new` instead.', '`Renamed.old` is deprecated, use `new` instead.', ])
with warnings.catch_warnings(record=True) as recorded: warnings.simplefilter('ignore') class Deprecated(six.with_metaclass(RenameManagerMethods)): def old(self): pass class Renamed(Deprecated): def new(self): super(Renamed, self).new() warnings.simplefilter('always') renamed = Renamed() renamed.new() self.assertEqual(len(recorded), 0) renamed.old() self.assertEqual(len(recorded), 1) msg = str(recorded.pop().message) self.assertEqual(msg, '`Renamed.old` is deprecated, use `new` instead.')
with warnings.catch_warnings(record=True) as recorded: warnings.simplefilter('ignore') class Renamed(six.with_metaclass(RenameManagerMethods)): def new(self): pass class RenamedMixin(object): def new(self): super(RenamedMixin, self).new() class DeprecatedMixin(object): def old(self): super(DeprecatedMixin, self).old() class Deprecated(DeprecatedMixin, RenamedMixin, Renamed): pass warnings.simplefilter('always') deprecated = Deprecated() deprecated.new() self.assertEqual(len(recorded), 1) msg = str(recorded.pop().message) self.assertEqual(msg, '`RenamedMixin.old` is deprecated, use `new` instead.') deprecated.old() self.assertEqual(len(recorded), 2) msgs = [str(warning.message) for warning in recorded] self.assertEqual(msgs, [ '`DeprecatedMixin.old` is deprecated, use `new` instead.', '`RenamedMixin.old` is deprecated, use `new` instead.', ])
tag = models.SlugField() content_type = models.ForeignKey(ContentType, models.CASCADE) object_id = models.PositiveIntegerField() content_object = GenericForeignKey() class Meta: ordering = ["tag", "content_type__model"] def __str__(self): return self.tag
content_type2 = models.ForeignKey(ContentType, models.CASCADE, related_name="comparative2_set") object_id2 = models.PositiveIntegerField() other_obj = GenericForeignKey(ct_field="content_type2", fk_field="object_id2") def __str__(self): return "%s is %s than %s" % (self.first_obj, self.comparative, self.other_obj)
count = self.bacon.tags.count() tag, created = self.bacon.tags.update_or_create(tag='stinky') self.assertTrue(created) self.assertEqual(count + 1, self.bacon.tags.count())
count = self.bacon.tags.count() tag = self.bacon.tags.create(tag='stinky') self.assertEqual(count + 1, self.bacon.tags.count()) tag, created = self.bacon.tags.update_or_create(defaults={'tag': 'juicy'}, id=tag.id) self.assertFalse(created) self.assertEqual(count + 1, self.bacon.tags.count()) self.assertEqual(tag.tag, 'juicy')
count = self.bacon.tags.count() tag, created = self.bacon.tags.get_or_create(tag='stinky') self.assertTrue(created) self.assertEqual(count + 1, self.bacon.tags.count())
self.assertQuerysetEqual(self.lion.tags.all(), [ "<TaggedItem: hairy>", "<TaggedItem: yellow>" ]) self.assertQuerysetEqual(self.bacon.tags.all(), [ "<TaggedItem: fatty>", "<TaggedItem: salty>" ])
tagged_item = TaggedItem.objects.get(tag="salty") self.assertEqual(tagged_item.content_object, self.bacon)
self.lion.delete() self.platypus.tags.create(tag="fatty") ctype = ContentType.objects.get_for_model(self.platypus) self.assertQuerysetEqual( Animal.objects.filter(tags__content_type=ctype), ["<Animal: Platypus>"])
tag1 = TaggedItem.objects.create(content_object=self.quartz, tag="shiny") tag1.content_object = self.platypus tag1.save() self.assertQuerysetEqual( self.platypus.tags.all(), ["<TaggedItem: shiny>"])
self.assertQuerysetEqual(Animal.objects.order_by('common_name'), [ "<Animal: Lion>", "<Animal: Platypus>" ])
mpk = ManualPK.objects.create(id=self.lion.pk) mpk.tags.create(tag="fatty") self.platypus.tags.create(tag="fatty") self.assertQuerysetEqual( Animal.objects.filter(tags__tag='fatty'), ["<Animal: Platypus>"]) self.assertQuerysetEqual( Animal.objects.exclude(tags__tag='fatty'), ["<Animal: Lion>"])
self.assertQuerysetEqual(TaggedItem.objects.all(), [ ('fatty', Vegetable, self.bacon.pk), ('hairy', Animal, self.lion.pk), ('salty', Vegetable, self.bacon.pk), ('yellow', Animal, self.lion.pk) ], self.comp_func ) self.lion.delete() self.assertQuerysetEqual(TaggedItem.objects.all(), [ ('fatty', Vegetable, self.bacon.pk), ('salty', Vegetable, self.bacon.pk), ], self.comp_func )
TaggedItem.objects.create(content_object=self.quartz, tag="clearish") quartz_pk = self.quartz.pk self.quartz.delete() self.assertQuerysetEqual(TaggedItem.objects.all(), [ ('clearish', Mineral, quartz_pk), ('fatty', Vegetable, self.bacon.pk), ('hairy', Animal, self.lion.pk), ('salty', Vegetable, self.bacon.pk), ('yellow', Animal, self.lion.pk), ], self.comp_func )
ctype = ContentType.objects.get_for_model(self.lion) tag = TaggedItem.objects.get( content_type__pk=ctype.id, object_id=self.lion.id, tag="hairy") tag.delete() self.assertQuerysetEqual(self.lion.tags.all(), ["<TaggedItem: yellow>"]) self.assertQuerysetEqual(TaggedItem.objects.all(), [ ('fatty', Vegetable, self.bacon.pk), ('salty', Vegetable, self.bacon.pk), ('yellow', Animal, self.lion.pk) ], self.comp_func )
granite = Rock.objects.create(name='granite', hardness=5) TaggedItem.objects.create(content_object=granite, tag="countertop") self.assertEqual(Rock.objects.get(tags__tag="countertop"), granite)
bear = Carrot.objects.create(name='carrot') TaggedItem.objects.create(content_object=bear, tag='orange') self.assertEqual(Carrot.objects.get(tags__tag='orange'), bear)
quartz = Mineral.objects.create(name="Quartz", hardness=7) GenericFormSet = generic_inlineformset_factory(TaggedItem, extra=1) ctype = ContentType.objects.get_for_model(quartz) initial_data = [{ 'tag': 'lizard', 'content_type': ctype.pk, 'object_id': quartz.pk, }] formset = GenericFormSet(initial=initial_data) self.assertEqual(formset.forms[0].initial, initial_data[0])
quartz = Mineral(name="Quartz", hardness=7) with self.assertRaises(IntegrityError): TaggedItem.objects.create(tag="shiny", content_object=quartz)
Formset = generic_inlineformset_factory(TaggedItem, TaggedItemForm) form = Formset().forms[0] self.assertIsInstance(form['tag'].field.widget, CustomWidget)
class SaveTestForm(forms.ModelForm): def save(self, *args, **kwargs): self.instance.saved_by = "custom method" return super(SaveTestForm, self).save(*args, **kwargs) Formset = generic_inlineformset_factory(ForProxyModelModel, fields='__all__', form=SaveTestForm) instance = ProxyRelatedModel.objects.create() data = { 'form-TOTAL_FORMS': '1', 'form-INITIAL_FORMS': '0', 'form-MAX_NUM_FORMS': '', 'form-0-title': 'foo', } formset = Formset(data, instance=instance, prefix='form') self.assertTrue(formset.is_valid()) new_obj = formset.save()[0] self.assertEqual(new_obj.saved_by, "custom method")
base = ForConcreteModelModel() base.obj = rel = ProxyRelatedModel.objects.create() base.save() base = ForConcreteModelModel.objects.get(pk=base.pk) rel = ConcreteRelatedModel.objects.get(pk=rel.pk) self.assertEqual(base.obj, rel)
base = ForProxyModelModel() base.obj = rel = ConcreteRelatedModel.objects.create() base.save() base = ForProxyModelModel.objects.get(pk=base.pk) self.assertEqual(base.obj, rel)
base = ForProxyModelModel() base.obj = ProxyRelatedModel.objects.create() base.save() base = ForProxyModelModel.objects.get(pk=base.pk) self.assertIsInstance(base.obj, ProxyRelatedModel)
from django.db import models from django.utils.encoding import python_2_unicode_compatible @python_2_unicode_compatible class Category(models.Model): name = models.CharField(max_length=20) class Meta: ordering = ('name',) def __str__(self): return self.name @python_2_unicode_compatible class Article(models.Model): headline = models.CharField(max_length=50) pub_date = models.DateTimeField() primary_categories = models.ManyToManyField(Category, related_name='primary_article_set') secondary_categories = models.ManyToManyField(Category, related_name='secondary_article_set') class Meta: ordering = ('pub_date',) def __str__(self): return self.headline
valid_country = Country(name='Germany', iso_two_letter='DE') invalid_country = Country(id=0, name='Poland', iso_two_letter='PL') with self.assertRaises(ValueError): Country.objects.bulk_create([valid_country, invalid_country])
with override_settings(DEBUG=True): connection.queries_log.clear() TwoFields.objects.bulk_create([ TwoFields(id=i if i % 2 == 0 else None, f1=i, f2=i + 1) for i in range(100000, 101000)]) self.assertLess(len(connection.queries), 10)
qs = Celebrity.objects.order_by('greatest_fan__fan_of') self.assertIn('OUTER JOIN', str(qs.query)) qs = qs.order_by('id') self.assertNotIn('OUTER JOIN', str(qs.query))
with CaptureQueriesContext(connection) as captured_queries: Author.objects.order_by('name').get(pk=self.a1.pk) self.assertNotIn('order by', captured_queries[0]['sql'].lower())
original_ordering = Tag._meta.ordering Tag._meta.ordering = None try: self.assertQuerysetEqual( Tag.objects.all(), ['<Tag: t1>', '<Tag: t2>', '<Tag: t3>', '<Tag: t4>', '<Tag: t5>'], ordered=False ) finally: Tag._meta.ordering = original_ordering
def test_no_default_or_explicit_ordering(self): self.assertEqual(Annotation.objects.all().ordered, False) def test_cleared_default_ordering(self): self.assertEqual(Tag.objects.all().ordered, True) self.assertEqual(Tag.objects.all().order_by().ordered, False) def test_explicit_ordering(self): self.assertEqual(Annotation.objects.all().order_by('id').ordered, True) def test_order_by_extra(self): self.assertEqual(Annotation.objects.all().extra(order_by=['id']).ordered, True) def test_annotated_ordering(self): qs = Annotation.objects.annotate(num_notes=Count('notes')) self.assertEqual(qs.ordered, False) self.assertEqual(qs.order_by('num_notes').ordered, True)
query = DumbCategory.objects.filter(id__in=DumbCategory.objects.order_by('-id')[0:2])[0:2] self.assertEqual({x.id for x in query}, {3, 4}) query = DumbCategory.objects.filter(id__in=DumbCategory.objects.order_by('-id')[1:3])[1:3] self.assertEqual({x.id for x in query}, {3}) query = DumbCategory.objects.filter(id__in=DumbCategory.objects.order_by('-id')[2:])[1:] self.assertEqual({x.id for x in query}, {2})
generic = NamedCategory.objects.create(id=5, name="Generic") t1 = Tag.objects.create(name='t1', category=generic) t2 = Tag.objects.create(name='t2', category=generic) ManagedModel.objects.create(data='mm1', tag=t1, public=True) mm2 = ManagedModel.objects.create(data='mm2', tag=t2, public=True) query = ManagedModel.normal_manager.filter( tag__in=Tag.objects.order_by('-id')[:1] ) self.assertEqual({x.id for x in query}, {mm2.id})
opts_class = type(Note._meta) note_deepcopy = getattr(opts_class, "__deepcopy__", None) opts_class.__deepcopy__ = lambda obj, memo: self.fail("Model options shouldn't be cloned.") try: Note.objects.filter(pk__lte=F('pk') + 1).all() finally: if note_deepcopy is None: delattr(opts_class, "__deepcopy__") else: opts_class.__deepcopy__ = note_deepcopy
opts_class = type(Note._meta.get_field("misc")) note_deepcopy = getattr(opts_class, "__deepcopy__", None) opts_class.__deepcopy__ = lambda obj, memo: self.fail("Model fields shouldn't be cloned") try: Note.objects.filter(note=F('misc')).all() finally: if note_deepcopy is None: delattr(opts_class, "__deepcopy__") else: opts_class.__deepcopy__ = note_deepcopy
with self.assertRaisesMessage(AssertionError, "Negative indexing is not supported."): Article.objects.all()[-1]
with self.assertRaisesMessage(AssertionError, "Negative indexing is not supported."): Article.objects.all()[0:-5]
@classmethod def setUpTestData(cls): objectas = [] objectbs = [] objectcs = [] a_info = ['one', 'two', 'three'] for name in a_info: o = ObjectA(name=name) o.save() objectas.append(o) b_info = [('un', 1, objectas[0]), ('deux', 2, objectas[0]), ('trois', 3, objectas[2])] for name, number, objecta in b_info: o = ObjectB(name=name, num=number, objecta=objecta) o.save() objectbs.append(o) c_info = [('ein', objectas[2], objectbs[2]), ('zwei', objectas[1], objectbs[1])] for name, objecta, objectb in c_info: o = ObjectC(name=name, objecta=objecta, objectb=objectb) o.save() objectcs.append(o) def check_union(self, model, Q1, Q2): filter = model.objects.filter self.assertEqual(set(filter(Q1) | filter(Q2)), set(filter(Q1 | Q2))) self.assertEqual(set(filter(Q2) | filter(Q1)), set(filter(Q1 | Q2))) def test_A_AB(self): Q1 = Q(name='two') Q2 = Q(objectb__name='deux') self.check_union(ObjectA, Q1, Q2) def test_A_AB2(self): Q1 = Q(name='two') Q2 = Q(objectb__name='deux', objectb__num=2) self.check_union(ObjectA, Q1, Q2) def test_AB_ACB(self): Q1 = Q(objectb__name='deux') Q2 = Q(objectc__objectb__name='deux') self.check_union(ObjectA, Q1, Q2) def test_BAB_BAC(self): Q1 = Q(objecta__objectb__name='deux') Q2 = Q(objecta__objectc__name='ein') self.check_union(ObjectB, Q1, Q2) def test_BAB_BACB(self): Q1 = Q(objecta__objectb__name='deux') Q2 = Q(objecta__objectc__objectb__name='trois') self.check_union(ObjectB, Q1, Q2) def test_BA_BCA__BAB_BAC_BCA(self): Q1 = Q(objecta__name='one', objectc__objecta__name='two') Q2 = Q(objecta__objectc__name='ein', objectc__objecta__name='three', objecta__objectb__name='trois') self.check_union(ObjectB, Q1, Q2)
self.assertQuerysetEqual( Order.objects.exclude(items__status=1), ['<Order: 3>'])
self.assertQuerysetEqual( Order.objects.exclude(items__status=1).distinct(), ['<Order: 3>'])
self.assertQuerysetEqual( Order.objects.exclude(Q(items__status=1)).distinct(), ['<Order: 3>'])
self.assertQuerysetEqual( Order.objects.exclude(Q(items__status=1)), ['<Order: 3>'])
self.assertEqual( list(Order.objects.exclude(items__status=1).distinct()), list(Order.objects.exclude(Q(items__status=1)).distinct()))
self.assertEqual( list(Order.objects.exclude(items__status=1)), list(Order.objects.exclude(Q(items__status=1)).distinct()))
self.assertQuerysetEqual( Order.objects.exclude(~Q(items__status=1)).distinct(), ['<Order: 1>'])
def test_ticket15786(self): c1 = SimpleCategory.objects.create(name='c1') c2 = SimpleCategory.objects.create(name='c2') OneToOneCategory.objects.create(category=c1) OneToOneCategory.objects.create(category=c2) rel = CategoryRelationship.objects.create(first=c1, second=c2) self.assertEqual( CategoryRelationship.objects.exclude( first__onetoonecategory=F('second__onetoonecategory') ).get(), rel )
self.assertQuerysetEqual( NullableName.objects.exclude(name__in=[None]), ['i1'], attrgetter('name'))
@classmethod def setUpTestData(cls): cls.nc = NamedCategory.objects.create(name='') def test_direct_exclude(self): self.assertQuerysetEqual( NamedCategory.objects.exclude(name__in=['nonexisting']), [self.nc.pk], attrgetter('pk') ) def test_joined_exclude(self): self.assertQuerysetEqual( DumbCategory.objects.exclude(namedcategory__name__in=['nonexisting']), [self.nc.pk], attrgetter('pk') ) def test_21001(self): foo = NamedCategory.objects.create(name='foo') self.assertQuerysetEqual( NamedCategory.objects.exclude(name=''), [foo.pk], attrgetter('pk') )
ProxyCategory.objects.create() qs = ProxyCategory.objects.all() self.assertEqual(qs.count(), 1) str(qs.query) self.assertEqual(qs.count(), 1)
def test_fk_reuse(self): qs = Annotation.objects.filter(tag__name='foo').filter(tag__name='bar') self.assertEqual(str(qs.query).count('JOIN'), 1) def test_fk_reuse_select_related(self): qs = Annotation.objects.filter(tag__name='foo').select_related('tag') self.assertEqual(str(qs.query).count('JOIN'), 1) def test_fk_reuse_annotation(self): qs = Annotation.objects.filter(tag__name='foo').annotate(cnt=Count('tag__name')) self.assertEqual(str(qs.query).count('JOIN'), 1) def test_fk_reuse_disjunction(self): qs = Annotation.objects.filter(Q(tag__name='foo') | Q(tag__name='bar')) self.assertEqual(str(qs.query).count('JOIN'), 1) def test_fk_reuse_order_by(self): qs = Annotation.objects.filter(tag__name='foo').order_by('tag__name') self.assertEqual(str(qs.query).count('JOIN'), 1) def test_revo2o_reuse(self): qs = Detail.objects.filter(member__name='foo').filter(member__name='foo') self.assertEqual(str(qs.query).count('JOIN'), 1) def test_revfk_noreuse(self): qs = Author.objects.filter(report__name='r4').filter(report__name='r1') self.assertEqual(str(qs.query).count('JOIN'), 2)
t = Tag.objects.create(name='foo') a1 = Annotation.objects.create(tag=t, name='a1') a2 = Annotation.objects.create(tag=t, name='a2') a3 = Annotation.objects.create(tag=t, name='a3') n = Note.objects.create(note='foo', misc='bar') qs1 = Note.objects.exclude(annotation__in=[a1, a2]) qs2 = Note.objects.filter(annotation__in=[a3]) self.assertIn(n, qs1) self.assertNotIn(n, qs2) self.assertIn(n, (qs1 | qs2))
with self.assertRaisesMessage(ValueError, self.error % (self.oa, ObjectB._meta.object_name)): ObjectA.objects.filter(objectb__in=[self.oa, self.ob]) with self.assertRaisesMessage(ValueError, self.error % (self.oa, ObjectB._meta.object_name)): ObjectA.objects.exclude(objectb=self.oa) with self.assertRaisesMessage(ValueError, self.error % (self.wrong_type, ObjectB._meta.object_name)): ObjectA.objects.get(objectb=self.wrong_type)
i1 = Individual.objects.create(alive=True) RelatedIndividual.objects.create(related=i1) i2 = Individual.objects.create(alive=False) RelatedIndividual.objects.create(related=i2) i3 = Individual.objects.create(alive=True) i4 = Individual.objects.create(alive=False) self.assertQuerysetEqual( Individual.objects.filter(Q(alive=False), Q(related_individual__isnull=True)), [i4], lambda x: x ) self.assertQuerysetEqual( Individual.objects.exclude( Q(alive=False), Q(related_individual__isnull=True) ).order_by('pk'), [i1, i2, i3], lambda x: x )
results = list(model.objects.raw(query, params=params, translations=translations)) self.assertProcessed(model, results, expected_results, expected_annotations) self.assertAnnotations(results, expected_annotations)
self.assertAnnotations(results, ())
if expected_annotations: for index, result in enumerate(results): annotation, value = expected_annotations[index] self.assertTrue(hasattr(result, annotation)) self.assertEqual(getattr(result, annotation), value)
query = "SELECT * FROM raw_query_author" authors = Author.objects.all() self.assertSuccessfulRawQuery(Author, query, authors)
q = Author.objects.raw('SELECT * FROM raw_query_author') self.assertIsNone(q.query.cursor) list(q) self.assertIsNotNone(q.query.cursor)
query = "SELECT * FROM raw_query_book" books = Book.objects.all() self.assertSuccessfulRawQuery(Book, query, books)
query = "SELECT * FROM raw_query_coffee" coffees = Coffee.objects.all() self.assertSuccessfulRawQuery(Coffee, query, coffees)
selects = ( ('dob, last_name, first_name, id'), ('last_name, dob, first_name, id'), ('first_name, last_name, dob, id'), ) for select in selects: query = "SELECT %s FROM raw_query_author" % select authors = Author.objects.all() self.assertSuccessfulRawQuery(Author, query, authors)
query = "SELECT first_name AS first, last_name AS last, dob, id FROM raw_query_author" translations = {'first': 'first_name', 'last': 'last_name'} authors = Author.objects.all() self.assertSuccessfulRawQuery(Author, query, authors, translations=translations)
query = "SELECT * FROM raw_query_author WHERE first_name = %s" author = Author.objects.all()[2] params = [author.first_name] qset = Author.objects.raw(query, params=params) results = list(qset) self.assertProcessed(Author, results, [author]) self.assertNoAnnotations(results) self.assertEqual(len(results), 1) self.assertIsInstance(repr(qset), str)
query = "SELECT * FROM raw_query_author WHERE first_name = %(first)s" author = Author.objects.all()[2] params = {'first': author.first_name} qset = Author.objects.raw(query, params=params) results = list(qset) self.assertProcessed(Author, results, [author]) self.assertNoAnnotations(results) self.assertEqual(len(results), 1) self.assertIsInstance(repr(qset), str)
query = "SELECT * FROM raw_query_author WHERE last_name = %(last)s" qset = Author.objects.raw(query, {'last': 'foo'}) self.assertEqual(repr(qset), "<RawQuerySet: SELECT * FROM raw_query_author WHERE last_name = foo>") self.assertEqual(repr(qset.query), "<RawQuery: SELECT * FROM raw_query_author WHERE last_name = foo>") query = "SELECT * FROM raw_query_author WHERE last_name = %s" qset = Author.objects.raw(query, {'foo'}) self.assertEqual(repr(qset), "<RawQuerySet: SELECT * FROM raw_query_author WHERE last_name = foo>") self.assertEqual(repr(qset.query), "<RawQuery: SELECT * FROM raw_query_author WHERE last_name = foo>")
query = "SELECT * FROM raw_query_reviewer" reviewers = Reviewer.objects.all() self.assertSuccessfulRawQuery(Reviewer, query, reviewers)
query = "SELECT * FROM raw_query_author" translations = {'something': 'else'} authors = Author.objects.all() self.assertSuccessfulRawQuery(Author, query, authors, translations=translations)
b = BookFkAsPk.objects.create(book=self.b1) self.assertEqual(list(BookFkAsPk.objects.raw('SELECT not_the_default FROM raw_query_bookfkaspk')), [b])
def __iter__(self): raise IndexError
if not Article._meta.get_latest_by: Article._meta.get_latest_by = 'pub_date'
def test_file_wrapper_uses_sendfile(self): env = {'SERVER_PROTOCOL': 'HTTP/1.0'} handler = FileWrapperHandler(None, BytesIO(), BytesIO(), env) handler.run(wsgi_app_file_wrapper) self.assertTrue(handler._used_sendfile) self.assertEqual(handler.stdout.getvalue(), b'') self.assertEqual(handler.stderr.getvalue(), b'') def test_file_wrapper_no_sendfile(self): env = {'SERVER_PROTOCOL': 'HTTP/1.0'} handler = FileWrapperHandler(None, BytesIO(), BytesIO(), env) handler.run(wsgi_app) self.assertFalse(handler._used_sendfile) self.assertEqual(handler.stdout.getvalue().splitlines()[-1], b'Hello World!') self.assertEqual(handler.stderr.getvalue(), b'')
def __init__(self, *args, **kwargs): super(WriteChunkCounterHandler, self).__init__(*args, **kwargs) self.request_handler = DummyHandler() self.headers_written = False self.write_chunk_counter = 0 def send_headers(self): super(WriteChunkCounterHandler, self).send_headers() self.headers_written = True def _write(self, data): if self.headers_written: self.write_chunk_counter += 1 self.stdout.write(data)
def test_chunked_data(self): env = {'SERVER_PROTOCOL': 'HTTP/1.0'} handler = WriteChunkCounterHandler(None, BytesIO(), BytesIO(), env) handler.run(send_big_data_app) self.assertEqual(handler.write_chunk_counter, 2)
def test_max_recursion_error(self): pass
self.assertEqual(self.foo, 'override')
try: super(ClassDecoratedTestCase, self).test_max_recursion_error() except RuntimeError: self.fail()
self.settings_module.MEDIA_URL = '' self.assertEqual('', self.settings_module.MEDIA_URL) self.settings_module.STATIC_URL = '' self.assertEqual('', self.settings_module.STATIC_URL)
self.settings_module.MEDIA_URL = '/foo/' self.assertEqual('/foo/', self.settings_module.MEDIA_URL) self.settings_module.MEDIA_URL = 'http://media.foo.com/' self.assertEqual('http://media.foo.com/', self.settings_module.MEDIA_URL) self.settings_module.STATIC_URL = '/foo/' self.assertEqual('/foo/', self.settings_module.STATIC_URL) self.settings_module.STATIC_URL = 'http://static.foo.com/' self.assertEqual('http://static.foo.com/', self.settings_module.STATIC_URL)
with self.assertRaises(ImproperlyConfigured): self.settings_module.MEDIA_URL = '/foo' with self.assertRaises(ImproperlyConfigured): self.settings_module.MEDIA_URL = 'http://media.foo.com' with self.assertRaises(ImproperlyConfigured): self.settings_module.STATIC_URL = '/foo' with self.assertRaises(ImproperlyConfigured): self.settings_module.STATIC_URL = 'http://static.foo.com'
self.settings_module.MEDIA_URL = '/wrong//' self.assertEqual('/wrong//', self.settings_module.MEDIA_URL) self.settings_module.MEDIA_URL = 'http://media.foo.com/wrong//' self.assertEqual('http://media.foo.com/wrong//', self.settings_module.MEDIA_URL) self.settings_module.STATIC_URL = '/wrong//' self.assertEqual('/wrong//', self.settings_module.STATIC_URL) self.settings_module.STATIC_URL = 'http://static.foo.com/wrong//' self.assertEqual('http://static.foo.com/wrong//', self.settings_module.STATIC_URL)
list_or_tuple_settings = ( "INSTALLED_APPS", "TEMPLATE_DIRS", "LOCALE_PATHS", ) def test_tuple_settings(self): settings_module = ModuleType('fake_settings_module') settings_module.SECRET_KEY = 'foo' for setting in self.list_or_tuple_settings: setattr(settings_module, setting, ('non_list_or_tuple_value')) sys.modules['fake_settings_module'] = settings_module try: with self.assertRaises(ImproperlyConfigured): Settings('fake_settings_module') finally: del sys.modules['fake_settings_module'] delattr(settings_module, setting)
self.a1.headline = "This contains \u0001 control \u0011 chars" msg = "Article.headline (pk:%s) contains unserializable characters" % self.a1.pk with self.assertRaisesMessage(ValueError, msg): serializers.serialize(self.serializer_name, [self.a1]) self.a1.headline = "HT \u0009, LF \u000A, and CR \u000D are allowed" self.assertIn( "HT \t, LF \n, and CR \r are allowed", serializers.serialize(self.serializer_name, [self.a1]) )
xml = '<?xml version="1.0" standalone="no"?><!DOCTYPE example SYSTEM "http://example.com/example.dtd">' with self.assertRaises(DTDForbidden): next(serializers.deserialize('xml', xml))
serial_str = serializers.serialize(self.serializer_name, Article.objects.all()) self.assertTrue(self._validate_output(serial_str))
serial_str = serializers.serialize(self.serializer_name, Article.objects.all()) models = list(serializers.deserialize(self.serializer_name, serial_str)) self.assertEqual(len(models), 2)
AuthorProfile.objects.create(author=self.joe, date_of_birth=datetime(1970, 1, 1)) serial_str = serializers.serialize(self.serializer_name, AuthorProfile.objects.all()) self.assertFalse(self._get_field_values(serial_str, 'author')) for obj in serializers.deserialize(self.serializer_name, serial_str): self.assertEqual(obj.object.pk, self._comparison_value(self.joe.pk))
valid_fields = ('headline', 'pub_date') invalid_fields = ("author", "categories") serial_str = serializers.serialize(self.serializer_name, Article.objects.all(), fields=valid_fields) for field_name in invalid_fields: self.assertFalse(self._get_field_values(serial_str, field_name)) for field_name in valid_fields: self.assertTrue(self._get_field_values(serial_str, field_name))
actor_name = "Za\u017c\u00f3\u0142\u0107" movie_title = 'G\u0119\u015bl\u0105 ja\u017a\u0144' ac = Actor(name=actor_name) mv = Movie(title=movie_title, actor=ac) ac.save() mv.save() serial_str = serializers.serialize(self.serializer_name, [mv]) self.assertEqual(self._get_field_values(serial_str, "title")[0], movie_title) self.assertEqual(self._get_field_values(serial_str, "actor")[0], actor_name) obj_list = list(serializers.deserialize(self.serializer_name, serial_str)) mv_obj = obj_list[0].object self.assertEqual(mv_obj.title, movie_title)
ac = Actor(name='Actor name') ac.save() mv = Movie(title='Movie title', actor_id=ac.pk) mv.save() with self.assertNumQueries(0): serializers.serialize(self.serializer_name, [mv])
category = Category(name="Reference") serial_str = serializers.serialize(self.serializer_name, [category]) pk_value = self._get_pk_values(serial_str)[0] self.assertFalse(pk_value) cat_obj = list(serializers.deserialize(self.serializer_name, serial_str))[0].object self.assertEqual(cat_obj.id, None)
sc = Score(score=3.4) sc.save() serial_str = serializers.serialize(self.serializer_name, [sc]) deserial_objs = list(serializers.deserialize(self.serializer_name, serial_str)) self.assertEqual(deserial_objs[0].object.score, Approximate(3.4, places=1))
team_str = "Spartak Moskva" player = Player() player.name = "Soslan Djanaev" player.rank = 1 player.team = Team(team_str) player.save() serial_str = serializers.serialize(self.serializer_name, Player.objects.all()) team = self._get_field_values(serial_str, "team") self.assertTrue(team) self.assertEqual(team[0], team_str) deserial_objs = list(serializers.deserialize(self.serializer_name, serial_str)) self.assertEqual(deserial_objs[0].object.team.to_string(), player.team.to_string())
deserial_objs = list(serializers.deserialize(self.serializer_name, self.pkless_str)) for obj in deserial_objs: self.assertFalse(obj.object.id) obj.save() self.assertEqual(Category.objects.all().count(), 5)
output = serializers.serialize(self.serializer_name, [self.a1], indent=2) categories = self.a1.categories.values_list('pk', flat=True) self.assertEqual(output, self.mapping_ordering_str % { 'article_pk': self.a1.pk, 'author_pk': self.a1.author_id, 'first_category_pk': categories[0], 'second_category_pk': categories[1], })
serial_str = serializers.serialize(self.serializer_name, [self.a1]) deserial_obj = list(serializers.deserialize(self.serializer_name, serial_str))[0] with mock.patch('django.db.models.Model') as mock_model: deserial_obj.save(force_insert=False) mock_model.save_base.assert_called_with(deserial_obj.object, raw=True, using=None, force_insert=False)
from django.db import models class NaturalKeyAnchorManager(models.Manager): def get_by_natural_key(self, data): return self.get(data=data) class NaturalKeyAnchor(models.Model): objects = NaturalKeyAnchorManager() data = models.CharField(max_length=100, unique=True) title = models.CharField(max_length=100, null=True) def natural_key(self): return (self.data,) class FKDataNaturalKey(models.Model): data = models.ForeignKey(NaturalKeyAnchor, models.SET_NULL, null=True)
data = models.SlugField() content_type = models.ForeignKey(ContentType, models.CASCADE) object_id = models.PositiveIntegerField() content_object = GenericForeignKey() class Meta: ordering = ["data"]
from __future__ import unicode_literals from decimal import Decimal from django.db import models from django.utils import six from django.utils.encoding import python_2_unicode_compatible class CategoryMetaDataManager(models.Manager): def get_by_natural_key(self, kind, name): return self.get(kind=kind, name=name) @python_2_unicode_compatible class CategoryMetaData(models.Model): kind = models.CharField(max_length=10) name = models.CharField(max_length=10) value = models.CharField(max_length=10) objects = CategoryMetaDataManager() class Meta: unique_together = (('kind', 'name'),) def __str__(self): return '[%s:%s]=%s' % (self.kind, self.name, self.value) def natural_key(self): return (self.kind, self.name) @python_2_unicode_compatible class Category(models.Model): name = models.CharField(max_length=20) meta_data = models.ForeignKey(CategoryMetaData, models.SET_NULL, null=True, default=None) class Meta: ordering = ('name',) def __str__(self): return self.name @python_2_unicode_compatible class Author(models.Model): name = models.CharField(max_length=20) class Meta: ordering = ('name',) def __str__(self): return self.name @python_2_unicode_compatible class Article(models.Model): author = models.ForeignKey(Author, models.CASCADE) headline = models.CharField(max_length=50) pub_date = models.DateTimeField() categories = models.ManyToManyField(Category) meta_data = models.ManyToManyField(CategoryMetaData) class Meta: ordering = ('pub_date',) def __str__(self): return self.headline @python_2_unicode_compatible class AuthorProfile(models.Model): author = models.OneToOneField(Author, models.CASCADE, primary_key=True) date_of_birth = models.DateField() def __str__(self): return "Profile of %s" % self.author @python_2_unicode_compatible class Actor(models.Model): name = models.CharField(max_length=20, primary_key=True) class Meta: ordering = ('name',) def __str__(self): return self.name @python_2_unicode_compatible class Movie(models.Model): actor = models.ForeignKey(Actor, models.CASCADE) title = models.CharField(max_length=50) price = models.DecimalField(max_digits=6, decimal_places=2, default=Decimal('0.00')) class Meta: ordering = ('title',) def __str__(self): return self.title class Score(models.Model): score = models.FloatField() @python_2_unicode_compatible class Team(object): def __init__(self, title): self.title = title def __str__(self): raise NotImplementedError("Not so simple") def to_string(self): return "%s" % self.title class TeamField(models.CharField): def __init__(self): super(TeamField, self).__init__(max_length=100) def get_db_prep_save(self, value, connection): return six.text_type(value.title) def to_python(self, value): if isinstance(value, Team): return value return Team(value) def from_db_value(self, value, expression, connection, context): return Team(value) def value_to_string(self, obj): return self.value_from_object(obj).to_string() def deconstruct(self): name, path, args, kwargs = super(TeamField, self).deconstruct() del kwargs['max_length'] return name, path, args, kwargs @python_2_unicode_compatible class Player(models.Model): name = models.CharField(max_length=50) rank = models.IntegerField() team = TeamField() def __str__(self): return '%s (%d) playing for %s' % (self.name, self.rank, self.team.to_string()) class BaseModel(models.Model): parent_data = models.IntegerField() class ProxyBaseModel(BaseModel): class Meta: proxy = True class ProxyProxyBaseModel(ProxyBaseModel): class Meta: proxy = True class ComplexModel(models.Model): field1 = models.CharField(max_length=10) field2 = models.CharField(max_length=10) field3 = models.CharField(max_length=10)
def __init__(self): self._import_module = importlib.import_module def import_module(self, module_path): if module_path == serializers.BUILTIN_SERIALIZERS['yaml']: raise ImportError(YAML_IMPORT_ERROR_MESSAGE) return self._import_module(module_path)
jane = Author(name="Jane") with self.assertRaises(ImportError): serializers.serialize("yaml", [jane])
with self.assertRaises(ImportError): serializers.deserialize("yaml", "")
with self.assertRaisesMessage(management.CommandError, YAML_IMPORT_ERROR_MESSAGE): management.call_command('dumpdata', format='yaml')
pass
inlineformset_factory(Parent, Child, fk_name='mother', fields="__all__") inlineformset_factory(Parent, Child, fk_name='father', fields="__all__")
msg = "'inline_formsets.Child' has more than one ForeignKey to 'inline_formsets.Parent'." with self.assertRaisesMessage(ValueError, msg): inlineformset_factory(Parent, Child)
msg = "fk_name 'school' is not a ForeignKey to 'inline_formsets.Parent'." with self.assertRaisesMessage(ValueError, msg): inlineformset_factory(Parent, Child, fk_name='school')
with self.assertRaisesMessage(ValueError, "'inline_formsets.Child' has no field named 'test'."): inlineformset_factory(Parent, Child, fk_name='test')
poet = Poet.objects.create(name='test') poet.poem_set.create(name='first test poem') poet.poem_set.create(name='second test poem') poet.poem_set.create(name='third test poem') PoemFormSet = inlineformset_factory(Poet, Poem, fields=('name',), extra=0) formset = PoemFormSet(None, instance=poet) self.assertEqual(len(formset.forms), 3) self.assertEqual(['name', 'poet'], PoemFormSet.form._meta.fields)
request = self.rf.get('/slash/') self.assertEqual(CommonMiddleware().process_request(request), None) response = HttpResponseNotFound() self.assertEqual(CommonMiddleware().process_response(request, response), response)
request = self.rf.get('/noslash') self.assertEqual(CommonMiddleware().process_request(request), None) response = HttpResponse("Here's the text of the Web page.") self.assertEqual(CommonMiddleware().process_response(request, response), response)
request = self.rf.get('/unknown') response = HttpResponseNotFound() self.assertEqual(CommonMiddleware().process_response(request, response), response)
request = self.rf.get('/slash') r = CommonMiddleware().process_request(request) self.assertEqual(r.status_code, 301)
request = self.rf.get('/slash?test=1') response = HttpResponseNotFound() r = CommonMiddleware().process_response(request, response) self.assertEqual(r.url, '/slash/?test=1')
msg = "maintaining %s data. Change your form to point to testserver/slash/" request = self.rf.get('/slash') request.method = 'POST' response = HttpResponseNotFound() with self.assertRaisesMessage(RuntimeError, msg % request.method): CommonMiddleware().process_response(request, response) request = self.rf.get('/slash') request.method = 'PUT' with self.assertRaisesMessage(RuntimeError, msg % request.method): CommonMiddleware().process_response(request, response) request = self.rf.get('/slash') request.method = 'PATCH' with self.assertRaisesMessage(RuntimeError, msg % request.method): CommonMiddleware().process_response(request, response)
request = self.rf.get('/slash') response = HttpResponseNotFound() self.assertEqual(CommonMiddleware().process_response(request, response), response)
request = self.rf.get(quote('/needsquoting#')) response = HttpResponseNotFound() r = CommonMiddleware().process_response(request, response) self.assertEqual(r.status_code, 301) self.assertEqual(r.url, '/needsquoting%23/')
request = self.rf.get('/customurlconf/slash/') request.urlconf = 'middleware.extra_urls' self.assertEqual(CommonMiddleware().process_request(request), None) response = HttpResponseNotFound() self.assertEqual(CommonMiddleware().process_response(request, response), response)
request = self.rf.get('/customurlconf/noslash') request.urlconf = 'middleware.extra_urls' self.assertEqual(CommonMiddleware().process_request(request), None) response = HttpResponse("Here's the text of the Web page.") self.assertEqual(CommonMiddleware().process_response(request, response), response)
request = self.rf.get('/customurlconf/unknown') request.urlconf = 'middleware.extra_urls' self.assertEqual(CommonMiddleware().process_request(request), None) response = HttpResponseNotFound() self.assertEqual(CommonMiddleware().process_response(request, response), response)
request = self.rf.get('/customurlconf/slash') request.urlconf = 'middleware.extra_urls' response = HttpResponseNotFound() r = CommonMiddleware().process_response(request, response) self.assertIsNotNone(r, "CommonMiddleware failed to return APPEND_SLASH redirect using request.urlconf") self.assertEqual(r.status_code, 301) self.assertEqual(r.url, '/customurlconf/slash/')
request = self.rf.get('/customurlconf/slash') request.urlconf = 'middleware.extra_urls' request.method = 'POST' response = HttpResponseNotFound() with self.assertRaisesMessage(RuntimeError, 'end in a slash'): CommonMiddleware().process_response(request, response)
request = self.rf.get('/customurlconf/slash') request.urlconf = 'middleware.extra_urls' self.assertEqual(CommonMiddleware().process_request(request), None) response = HttpResponseNotFound() self.assertEqual(CommonMiddleware().process_response(request, response), response)
request = self.rf.get(quote('/customurlconf/needsquoting#')) request.urlconf = 'middleware.extra_urls' response = HttpResponseNotFound() r = CommonMiddleware().process_response(request, response) self.assertIsNotNone(r, "CommonMiddleware failed to return APPEND_SLASH redirect using request.urlconf") self.assertEqual(r.status_code, 301) self.assertEqual(r.url, '/customurlconf/needsquoting%23/')
request = self.rf.get('/slash') request.META['QUERY_STRING'] = force_str('drink=caf') r = CommonMiddleware().process_request(request) self.assertEqual(r.status_code, 301)
with override_settings(X_FRAME_OPTIONS='SAMEORIGIN'): r = XFrameOptionsMiddleware().process_response(HttpRequest(), HttpResponse()) self.assertEqual(r['X-Frame-Options'], 'SAMEORIGIN') with override_settings(X_FRAME_OPTIONS='sameorigin'): r = XFrameOptionsMiddleware().process_response(HttpRequest(), HttpResponse()) self.assertEqual(r['X-Frame-Options'], 'SAMEORIGIN')
with override_settings(X_FRAME_OPTIONS='DENY'): r = XFrameOptionsMiddleware().process_response(HttpRequest(), HttpResponse()) self.assertEqual(r['X-Frame-Options'], 'DENY') with override_settings(X_FRAME_OPTIONS='deny'): r = XFrameOptionsMiddleware().process_response(HttpRequest(), HttpResponse()) self.assertEqual(r['X-Frame-Options'], 'DENY')
with override_settings(X_FRAME_OPTIONS='DENY'): response = HttpResponse() response['X-Frame-Options'] = 'SAMEORIGIN' r = XFrameOptionsMiddleware().process_response(HttpRequest(), response) self.assertEqual(r['X-Frame-Options'], 'SAMEORIGIN') with override_settings(X_FRAME_OPTIONS='SAMEORIGIN'): response = HttpResponse() response['X-Frame-Options'] = 'DENY' r = XFrameOptionsMiddleware().process_response(HttpRequest(), response) self.assertEqual(r['X-Frame-Options'], 'DENY')
with override_settings(X_FRAME_OPTIONS='SAMEORIGIN'): response = HttpResponse() response.xframe_options_exempt = False r = XFrameOptionsMiddleware().process_response(HttpRequest(), response) self.assertEqual(r['X-Frame-Options'], 'SAMEORIGIN') response = HttpResponse() response.xframe_options_exempt = True r = XFrameOptionsMiddleware().process_response(HttpRequest(), response) self.assertIsNone(r.get('X-Frame-Options'))
r = GZipMiddleware().process_response(self.req, self.resp) self.assertEqual(self.decompress(r.content), self.compressible_string) self.assertEqual(r.get('Content-Encoding'), 'gzip') self.assertEqual(r.get('Content-Length'), str(len(r.content)))
r = GZipMiddleware().process_response(self.req, self.stream_resp) self.assertEqual(self.decompress(b''.join(r)), b''.join(self.sequence)) self.assertEqual(r.get('Content-Encoding'), 'gzip') self.assertFalse(r.has_header('Content-Length'))
r = GZipMiddleware().process_response(self.req, self.stream_resp_unicode) self.assertEqual( self.decompress(b''.join(r)), b''.join(x.encode('utf-8') for x in self.sequence_unicode) ) self.assertEqual(r.get('Content-Encoding'), 'gzip') self.assertFalse(r.has_header('Content-Length'))
with open(__file__, 'rb') as file1: file_resp = FileResponse(file1) file_resp['Content-Type'] = 'text/html; charset=UTF-8' r = GZipMiddleware().process_response(self.req, file_resp) with open(__file__, 'rb') as file2: self.assertEqual(self.decompress(b''.join(r)), file2.read()) self.assertEqual(r.get('Content-Encoding'), 'gzip') self.assertIsNot(r.file_to_stream, file1)
self.resp.status_code = 404 r = GZipMiddleware().process_response(self.req, self.resp) self.assertEqual(self.decompress(r.content), self.compressible_string) self.assertEqual(r.get('Content-Encoding'), 'gzip')
self.resp.content = self.short_string r = GZipMiddleware().process_response(self.req, self.resp) self.assertEqual(r.content, self.short_string) self.assertIsNone(r.get('Content-Encoding'))
self.resp['Content-Encoding'] = 'deflate' r = GZipMiddleware().process_response(self.req, self.resp) self.assertEqual(r.content, self.compressible_string) self.assertEqual(r.get('Content-Encoding'), 'deflate')
self.resp.content = self.incompressible_string r = GZipMiddleware().process_response(self.req, self.resp) self.assertEqual(r.content, self.incompressible_string) self.assertIsNone(r.get('Content-Encoding'))
request = self.rf.get('/', HTTP_ACCEPT_ENCODING='gzip, deflate') response = GZipMiddleware().process_response( request, CommonMiddleware().process_response(request, HttpResponse(self.compressible_string)) ) gzip_etag = response.get('ETag') request = self.rf.get('/', HTTP_ACCEPT_ENCODING='') response = GZipMiddleware().process_response( request, CommonMiddleware().process_response(request, HttpResponse(self.compressible_string)) ) nogzip_etag = response.get('ETag') self.assertNotEqual(gzip_etag, nogzip_etag)
self.assertEqual( self.process_response(secure=True)["strict-transport-security"], "max-age=3600")
response = self.process_response( secure=True, headers={"strict-transport-security": "max-age=7200"}) self.assertEqual(response["strict-transport-security"], "max-age=7200")
self.assertNotIn("strict-transport-security", self.process_response(secure=False))
self.assertNotIn("strict-transport-security", self.process_response(secure=True))
response = self.process_response(secure=True) self.assertEqual(response["strict-transport-security"], "max-age=600; includeSubDomains")
response = self.process_response(secure=True) self.assertEqual(response["strict-transport-security"], "max-age=600")
self.assertEqual(self.process_response()["x-content-type-options"], "nosniff")
response = self.process_response(secure=True, headers={"x-content-type-options": "foo"}) self.assertEqual(response["x-content-type-options"], "foo")
self.assertNotIn("x-content-type-options", self.process_response())
self.assertEqual( self.process_response()["x-xss-protection"], "1; mode=block")
response = self.process_response(secure=True, headers={"x-xss-protection": "foo"}) self.assertEqual(response["x-xss-protection"], "foo")
self.assertNotIn("x-xss-protection", self.process_response())
ret = self.process_request("get", "/some/url?query=string") self.assertEqual(ret.status_code, 301) self.assertEqual( ret["Location"], "https://testserver/some/url?query=string")
ret = self.process_request("get", "/some/url", secure=True) self.assertEqual(ret, None)
ret = self.process_request("get", "/insecure/page") self.assertEqual(ret, None)
ret = self.process_request("get", "/some/url") self.assertEqual(ret.status_code, 301) self.assertEqual(ret["Location"], "https://secure.example.com/some/url")
from __future__ import unicode_literals from django.db import models from django.utils.encoding import python_2_unicode_compatible from .fields import MyAutoField @python_2_unicode_compatible class Employee(models.Model): employee_code = models.IntegerField(primary_key=True, db_column='code') first_name = models.CharField(max_length=20) last_name = models.CharField(max_length=20) class Meta: ordering = ('last_name', 'first_name') def __str__(self): return "%s %s" % (self.first_name, self.last_name) @python_2_unicode_compatible class Business(models.Model): name = models.CharField(max_length=20, primary_key=True) employees = models.ManyToManyField(Employee) class Meta: verbose_name_plural = 'businesses' def __str__(self): return self.name @python_2_unicode_compatible class Bar(models.Model): id = MyAutoField(primary_key=True, db_index=True) def __str__(self): return repr(self.pk) class Foo(models.Model): bar = models.ForeignKey(Bar, models.CASCADE)
self.assertQuerysetEqual( Employee.objects.filter(pk=123), [ "Dan Jones", ], six.text_type ) self.assertQuerysetEqual( Employee.objects.filter(employee_code=123), [ "Dan Jones", ], six.text_type ) self.assertQuerysetEqual( Employee.objects.filter(pk__in=[123, 456]), [ "Fran Bones", "Dan Jones", ], six.text_type ) self.assertQuerysetEqual( Employee.objects.all(), [ "Fran Bones", "Dan Jones", ], six.text_type ) self.assertQuerysetEqual( Business.objects.filter(name="Sears"), [ "Sears" ], lambda b: b.name ) self.assertQuerysetEqual( Business.objects.filter(pk="Sears"), [ "Sears", ], lambda b: b.name )
self.assertQuerysetEqual( self.business.employees.all(), [ "Fran Bones", "Dan Jones", ], six.text_type ) self.assertQuerysetEqual( self.fran.business_set.all(), [ "Sears", ], lambda b: b.name )
self.assertQuerysetEqual( Employee.objects.filter(business__name="Sears"), [ "Fran Bones", "Dan Jones", ], six.text_type, ) self.assertQuerysetEqual( Employee.objects.filter(business__pk="Sears"), [ "Fran Bones", "Dan Jones", ], six.text_type, ) self.assertQuerysetEqual( Business.objects.filter(employees__employee_code=123), [ "Sears", ], lambda b: b.name ) self.assertQuerysetEqual( Business.objects.filter(employees__pk=123), [ "Sears", ], lambda b: b.name, ) self.assertQuerysetEqual( Business.objects.filter(employees__first_name__startswith="Fran"), [ "Sears", ], lambda b: b.name )
emps = Employee.objects.in_bulk([123, 456]) self.assertEqual(emps[123], self.dan) self.assertEqual(Business.objects.in_bulk(["Sears"]), { "Sears": self.business, })
fran = Employee.objects.get(pk=456) fran.last_name = "Jones" fran.save() self.assertQuerysetEqual( Employee.objects.filter(last_name="Jones"), [ "Dan Jones", "Fran Jones", ], six.text_type )
Employee.objects.create(employee_code=1234, first_name="Foo", last_name="Bar") Employee.objects.create(pk=1235, first_name="Foo", last_name="Baz") Business.objects.create(name="Bears") Business.objects.create(pk="Tears")
with connection.cursor() as cursor: return connection.introspection.get_indexes(cursor, table)
with connection.cursor() as cursor: return connection.introspection.get_constraints(cursor, table)
with connection.schema_editor() as editor: editor.create_model(Note) with self.assertRaises(IntegrityError): Note.objects.create(info=None) old_field = Note._meta.get_field("info") new_field = CharField(max_length=50) new_field.set_attributes_from_name("info") with connection.schema_editor() as editor: editor.alter_field(Note, old_field, new_field, strict=True) with self.assertRaises(IntegrityError): Note.objects.create(info=None)
with connection.schema_editor() as editor: editor.create_model(UniqueTest) with self.assertRaises(IntegrityError): UniqueTest.objects.create(year=None, slug='aaa') old_field = UniqueTest._meta.get_field("year") new_field = BigIntegerField() new_field.set_attributes_from_name("year") with connection.schema_editor() as editor: editor.alter_field(UniqueTest, old_field, new_field, strict=True) with self.assertRaises(IntegrityError): UniqueTest.objects.create(year=None, slug='bbb')
with connection.schema_editor() as editor: editor.create_model(IntegerPK) old_field = IntegerPK._meta.get_field('i') new_field = AutoField(primary_key=True) new_field.model = IntegerPK new_field.set_attributes_from_name('i') with connection.schema_editor() as editor: editor.alter_field(IntegerPK, old_field, new_field, strict=True)
with connection.schema_editor() as editor: editor.create_model(Note) with self.assertRaises(IntegrityError): Note.objects.create(info=None) old_field = Note._meta.get_field("info") new_field = TextField() new_field.set_attributes_from_name("detail_info") with connection.schema_editor() as editor: editor.alter_field(Note, old_field, new_field, strict=True) columns = self.column_classes(Note) self.assertEqual(columns['detail_info'][0], "TextField") self.assertNotIn("info", columns) with self.assertRaises(IntegrityError): NoteRename.objects.create(detail_info=None)
class SomeError(Exception): pass try: with connection.schema_editor(): raise SomeError except SomeError: self.assertFalse(connection.in_atomic_block)
def get_field(*args, **kwargs): kwargs['db_column'] = "CamelCase" field = kwargs.pop('field_class', IntegerField)(*args, **kwargs) field.set_attributes_from_name("CamelCase") return field model = Author field = get_field() table = model._meta.db_table column = field.column with connection.schema_editor() as editor: editor.create_model(model) editor.add_field(model, field) editor.execute( editor.sql_create_index % { "table": editor.quote_name(table), "name": editor.quote_name("CamelCaseIndex"), "columns": editor.quote_name(column), "extra": "", } ) editor.alter_field(model, get_field(db_index=True), field) editor.execute( editor.sql_create_unique % { "table": editor.quote_name(table), "name": editor.quote_name("CamelCaseUniqConstraint"), "columns": editor.quote_name(field.column), } ) editor.alter_field(model, get_field(unique=True), field) editor.execute( editor.sql_create_fk % { "table": editor.quote_name(table), "name": editor.quote_name("CamelCaseFKConstraint"), "column": editor.quote_name(column), "to_table": editor.quote_name(table), "to_column": editor.quote_name(model._meta.auto_field.column), "deferrable": connection.ops.deferrable_sql(), } ) editor.alter_field(model, get_field(Author, CASCADE, field_class=ForeignKey), field)
if connection.vendor == 'mysql' and connection.mysql_version < (5, 6, 6): self.skipTest('Skip known bug renaming primary keys on older MySQL versions (#24995).') old_field = Node._meta.get_field('node_id') new_field = AutoField(primary_key=True) new_field.set_attributes_from_name('id') with connection.schema_editor() as editor: editor.alter_field(Node, old_field, new_field)
def db_type(self, connection): return 'MEDIUMBLOB'
def test_regex_equality(self): self.assertEqual( RegexValidator(r'^(?:[a-z0-9\.\-]*)://'), RegexValidator(r'^(?:[a-z0-9\.\-]*)://'), ) self.assertNotEqual( RegexValidator(r'^(?:[a-z0-9\.\-]*)://'), RegexValidator(r'^(?:[0-9\.\-]*)://'), ) self.assertEqual( RegexValidator(r'^(?:[a-z0-9\.\-]*)://', "oh noes", "invalid"), RegexValidator(r'^(?:[a-z0-9\.\-]*)://', "oh noes", "invalid"), ) self.assertNotEqual( RegexValidator(r'^(?:[a-z0-9\.\-]*)://', "oh", "invalid"), RegexValidator(r'^(?:[a-z0-9\.\-]*)://', "oh noes", "invalid"), ) self.assertNotEqual( RegexValidator(r'^(?:[a-z0-9\.\-]*)://', "oh noes", "invalid"), RegexValidator(r'^(?:[a-z0-9\.\-]*)://'), ) self.assertNotEqual( RegexValidator('', flags=re.IGNORECASE), RegexValidator(''), ) self.assertNotEqual( RegexValidator(''), RegexValidator('', inverse_match=True), ) def test_regex_equality_nocache(self): pattern = r'^(?:[a-z0-9\.\-]*)://' left = RegexValidator(pattern) re.purge() right = RegexValidator(pattern) self.assertEqual( left, right, ) def test_regex_equality_blank(self): self.assertEqual( RegexValidator(), RegexValidator(), ) def test_email_equality(self): self.assertEqual( EmailValidator(), EmailValidator(), ) self.assertNotEqual( EmailValidator(message="BAD EMAIL"), EmailValidator(), ) self.assertEqual( EmailValidator(message="BAD EMAIL", code="bad"), EmailValidator(message="BAD EMAIL", code="bad"), ) def test_basic_equality(self): self.assertEqual( MaxValueValidator(44), MaxValueValidator(44), ) self.assertNotEqual( MaxValueValidator(44), MinValueValidator(44), ) self.assertNotEqual( MinValueValidator(45), MinValueValidator(11), ) def test_decimal_equality(self): self.assertEqual( DecimalValidator(1, 2), DecimalValidator(1, 2), ) self.assertNotEqual( DecimalValidator(1, 2), DecimalValidator(1, 1), ) self.assertNotEqual( DecimalValidator(1, 2), DecimalValidator(2, 2), ) self.assertNotEqual( DecimalValidator(1, 2), MinValueValidator(11), )
